<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Bipartite Flat-Graph Network for Nested Named Entity Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Luo</surname></persName>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
							<email>zhaohai@cs.sjtu.edu.cn</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science and Engineering</orgName>
								<orgName type="department" key="dep2">MoE Key Lab of Artificial Intelligence</orgName>
								<orgName type="laboratory">Laboratory of Shanghai Education Commission for Intelligent Interaction and Cognitive Engineering</orgName>
								<orgName type="institution" key="instit1">Shanghai Jiao Tong University Key</orgName>
								<orgName type="institution" key="instit2">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">AI Institute</orgName>
								<orgName type="institution" key="instit2">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Bipartite Flat-Graph Network for Nested Named Entity Recognition</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we propose a novel bipartite flatgraph network (BiFlaG) for nested named entity recognition (NER), which contains two subgraph modules: a flat NER module for outermost entities and a graph module for all the entities located in inner layers. Bidirectional LSTM (BiLSTM) and graph convolutional network (GCN) are adopted to jointly learn flat entities and their inner dependencies. Different from previous models, which only consider the unidirectional delivery of information from innermost layers to outer ones (or outside-toinside), our model effectively captures the bidirectional interaction between them. We first use the entities recognized by the flat NER module to construct an entity graph, which is fed to the next graph module. The richer representation learned from graph module carries the dependencies of inner entities and can be exploited to improve outermost entity predictions. Experimental results on three standard nested NER datasets demonstrate that our BiFlaG outperforms previous state-of-the-art models.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Named entity recognition (NER) aims to identify words or phrases that contain the names of predefined categories like location, organization or medical codes. Nested NER further deals with entities that can be nested with each other, such as the United States and third president of the United States shown in <ref type="figure" target="#fig_0">Figure 1</ref>, such phenomenon is quite common in natural language processing (NLP).</p><p>NER is commonly regarded as a sequence labeling task <ref type="bibr" target="#b15">(Lample et al., 2016;</ref><ref type="bibr" target="#b23">Ma and Hovy, 2016;</ref><ref type="bibr" target="#b27">Peters et al., 2017)</ref>. These approaches only work for non-nested entities (or flat entities), but neglect nested entities. There have been efforts to deal with the nested structure. <ref type="bibr" target="#b10">Ju et al. 2018</ref> introduced a layered sequence labeling model to first recognize innermost entities, and then feed them into the next layer to extract outer entities. However, this model suffers from obvious error propagation. The wrong entities extracted by the previous layer will affect the performance of the next layer. Also, such layered model suffers from the sparsity of entities at high levels. For instance, in the well-known ACE2005 training dataset, there are only two entities in the sixth level. Sohrab and Miwa 2018 proposed a region-based method that enumerates all possible regions and classifies their entity types. However, this model may ignore explicit boundary information. <ref type="bibr" target="#b41">Zheng et al. 2019</ref> combined the layered sequence labeling model and region-based method to locate the entity boundary first, and then utilized the region classification model to predict entities. This model, however, cares less interaction among entities located in outer and inner layers.</p><p>In this paper, we propose a bipartite flat-graph network (BiFlaG) for nested NER, which models a nested structure containing arbitrary many layers into two parts: outermost entities and inner entities in all remaining layers. For example, as shown in <ref type="figure" target="#fig_0">Figure 1</ref>, the outermost entity Thomas Jefferson, third president of the United States is considered as a flat (non-nested) entity, while third president of the United States (in the second layer) and the United States (in the third layer) are taken as inner entities. The outermost entities with the maximum coverage are usually identified in the flat NER module, which commonly adopts a sequence labeling model. All the inner entities are extracted through the graph module, which iteratively propagates information between the start and end nodes of a span using graph convolutional network (GCN) <ref type="bibr" target="#b13">(Kipf and Welling, 2017)</ref>. The benefits of our model are twofold: (1) Different from layered models such as <ref type="bibr" target="#b10">(Ju et al., 2018)</ref>, which suffers from the constraints of one-way propagation of information from lower to higher layers, our model fully captures the interaction between outermost and inner layers in a bidirectional way. Entities extracted from the flat module are used to construct entity graph for the graph module. Then, new representations learned from graph module are fed back to the flat module to improve outermost entity predictions. Also, merging all the entities located in inner layers into a graph module can effectively alleviate the sparsity of entities in high levels.</p><p>(2) Compared with region-based models <ref type="bibr" target="#b29">(Sohrab and Miwa, 2018;</ref><ref type="bibr" target="#b41">Zheng et al., 2019)</ref>, our model makes full use of the sequence information of outermost entities, which take a large proportion in the corpus.</p><p>The main contributions of this paper can be summarized as follows:</p><p>• We introduce a novel bipartite flat-graph network named BiFlaG for nested NER, which incorporates a flat module for outermost entities and a graph module for inner entities.</p><p>• Our BiFlaG fully utilizes the sequence information of outermost entities and meanwhile bidirectionally considers the interaction between outermost and inner layers, other than unidirectional delivery of information.</p><p>• With extensive experiments on three benchmark datasets (ACE2005, GENIA, and KBP2017), our model outperforms previous state-of-the-art models under the same settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model</head><p>Our BiFlaG includes two subgraph modules, a flat NER module and a graph module to learn outermost and inner entities, respectively. <ref type="figure" target="#fig_1">Figure 2</ref> illustrates the overview of our model. For the flat module, we adopt BiLSTM-CRF to extract flat (outermost) entities, and use them to construct the entity graph G 1 as in <ref type="figure" target="#fig_1">Figure 2</ref>. For the graph module, we use GCN which iteratively propagates information between the start and end nodes of potential entities to learn inner entities. Finally, the learned representation from the graph module is further fed back to the flat module for better outermost predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Token Representation</head><p>Given a sequence consisting of N tokens {t 1 , t 2 , ..., t N }, for each token t i , we first concatenate the word-level and character-level embedding t i = [w i ; c i ], w i is the pre-trained word embedding, character embedding c i is learned following the work of <ref type="bibr" target="#b34">(Xin et al., 2018)</ref>. Then we use a BiL-STM to capture sequential information for each token x i = BILSTM(t i ). We take x i as the word representation and feed it to subsequent modules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Flat NER Module</head><p>We adopt BiLSTM-CRF architecture <ref type="bibr" target="#b15">(Lample et al., 2016;</ref><ref type="bibr" target="#b23">Ma and Hovy, 2016;</ref><ref type="bibr" target="#b35">Yang and Zhang, 2018;</ref><ref type="bibr" target="#b22">Luo et al., 2020)</ref> in our flat module to recognize flat entities, which consists of a bidirectional LSTM (BiLSTM) encoder and a conditional random field (CRF) decoder.</p><p>BiLSTM captures bidirectional contextual information of sequences and can effectively represent the hidden states of words in context. BiLSTM represents the sequential information at each step, the hidden state h of BiLSTM can be expressed as follows.  2016; <ref type="bibr" target="#b23">Ma and Hovy, 2016;</ref><ref type="bibr" target="#b35">Yang and Zhang, 2018)</ref> to help make better decisions, which considers strong label dependencies by adding transition scores between neighboring labels. Viterbi algorithm is applied to search for the label sequence with highest probability during the decoding process. For y = {y 1 , ..., y N } being a sequence of predictions with length N . Its score is defined as follows.</p><formula xml:id="formula_0">− → h i = LST M (x i , − → h i−1 ; − → θ ) ← − h i = LST M (x i , ← − h i−1 ; ← − θ ) h i = [ − → h i ; ← − h i ]<label>(1)</label></formula><formula xml:id="formula_1">s(x, y) = N −1 i=0 T y i ,y i+1 + N i=1 P i,y i<label>(2)</label></formula><p>where T y i ,y i+1 represents the transmission score from y i to y i+1 , P i,y i is the score of the j th tag of the i th word from BiLSTM encoder. CRF model defines a family of conditional probability p(y|x) over all possible tag sequences y:</p><formula xml:id="formula_2">p(y|x) = exp s(x,y) ỹ∈y exp s(x,ỹ)<label>(3)</label></formula><p>during training phase, we consider the maximum log probability of the correct predictions. While decoding, we search the tag sequences with maxi-mum score:</p><formula xml:id="formula_3">y * = arg max y∈y score(x,ỹ)<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Graph Module</head><p>Since the original input sentences are plain texts without inherent graphical structure, we first construct graphs based on the sequential information of texts and the entity information from the flat module. Then, we apply GCN (Kipf and Welling, 2017; <ref type="bibr" target="#b28">Qian et al., 2019)</ref> which propagates information between neighboring nodes in the graphs, to extract the inner entities. Graph Construction. We create two types of graphs for each sentence as in <ref type="figure" target="#fig_1">Figure 2</ref>. Each graph is defined as G = (V, E), where V is the set of nodes (words), E is the set of edges.</p><p>• Entity graph G 1 : for all the nodes in an extracted entity extracted from the flat module, edges are added between any two nodes e ij = (v i , v j ), where start ≤ i &lt; j ≤ end, as shown in <ref type="figure" target="#fig_1">Figure 2</ref>, allowing the outermost entity information to be utilized.</p><p>• Adjacent graph G 2 : for each pair of adjacent words in the sentence, we add one directed edge from the left word to the right one, allowing local contextual information to be utilized.</p><p>Bi-GCN. In order to consider both incoming and outgoing features for each node, we follow the work of <ref type="bibr" target="#b24">(Marcheggiani and Titov, 2017;</ref><ref type="bibr" target="#b4">Fu et al., 2019)</ref>, which uses Bi-GCN to extract graph features. Given a graph G = (V, E), and the word representation</p><formula xml:id="formula_4">X = {x 1 , x 2 , ..., x N }, the graph feature f ∈ R N ×d f learned from Bi-GCN is ex- pressed as follows. − → f i = ReLU ( e ij ∈E ( − → W f x j + − → b f )) ← − f i = ReLU ( e ji ∈E ( ← − W f x j + ← − b f )) f i = [ − → f i ; ← − f i ] (5) where W f ∈ R dx×d f and b f ∈ R d f are train- able parameters, d x represents the dimension of word representation, d f is the hidden size of GCN,</formula><p>ReLU is the non-linear activation function. e ij represents the edge outgoing from token t i , and e ji represents the edge incoming to token t i . The features of the two graphs are aggregated to get impacts of both graphs</p><formula xml:id="formula_5">f = W c (f 1 ⊕ f 2 ) + b c<label>(6)</label></formula><p>where W c ∈ R 2d f ×d f is the weight to be learned, b c ∈ R d f is a bias parameter. f 1 and f 2 are graph features of G 1 and G 2 , respectively. After getting the graph representation F = {f 1 , f 2 , ..., f N } from Bi-GCN, we learn the entity score M ∈ R N ×N ×L for inner layers as</p><formula xml:id="formula_6">M ij = sof tmax(W 3 ReLU (W 1 f i ⊕ W 2 f j )) (7) where W 1 , W 2 ∈ R d f ×d f /2 , W 3 ∈ R d f ×L ,</formula><p>L is the number of entity types. M ij ∈ R L represents the type probability for a span starts from token t i and ends at token t j .</p><p>For inner entities, we define the ground truth entity of word pair (t i , t j ) asM ij , where t i and t j are start and end nodes of a span. Cross Entropy (CE) is used to calculate the loss</p><formula xml:id="formula_7">L inner = − ( (M ij log(M ij )) · I(O)+ λ 1 · (M ij log(M ij )) · (1 − I(O)))<label>(8)</label></formula><p>Algorithm </p><formula xml:id="formula_8">F N ×d f ← BI-GCN(X, G 1 ) 5: M N ×N ×L ← LINEAR(F × F ) 6:</formula><p>transform M to graph G 3 by Eq. <ref type="formula" target="#formula_0">(10)</ref> 7:</p><formula xml:id="formula_9">X new ← BI-GCN(X, G 3 ) 8: y new ← BILSTM-CRF(X new ) 9:</formula><p>entity set T ← entities in M and y new 10: end for 11: return entity set T where M ij ∈ R L denotes the entity score in the graph module. I(O) is a switching function to distinguish the loss of non-entity 'O' and other entity types. It is defined as follows.</p><formula xml:id="formula_10">I(O) = 1, if type = 'O' 0, if type = 'O'<label>(9)</label></formula><p>λ 1 is the bias weight. The larger λ 1 is, the greater impacts of entity types, and the smaller influences of non-entity 'O' on the graph module.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">BiFlaG Training</head><p>The entity score M in Eq. <ref type="formula">(7)</ref> carries the type probability of each word pair in the sentence. To further consider the information propagation from inner entities to outer ones, we use Bi-GCN to generate new representations from entity score M for the flat module. The largest type score r ij of the word pair (t i , t j ) indicates whether this span is an entity or non-entity and the confidence score of being such type, which is obtained by a max-pooling operation:</p><formula xml:id="formula_11">r ij = max(m ij ), if type = 'O' 0, if type = 'O'<label>(10)</label></formula><p>where type represents the entity type or non-entity 'O' corresponding to the maximum type score.</p><p>When the corresponding type is O, there exits no dependencies between t i and t j , thus we set r ij to 0.</p><p>A new graph that carries the boundary information  <ref type="formula" target="#formula_0">(75) 2,501 (77) 2,313 (76) 42,558 (90) 4,030 (90) 4,958 (89)</ref> inner entity 6,171 <ref type="formula" target="#formula_1">(25)</ref> 733 <ref type="formula" target="#formula_1">(23)</ref> 715 <ref type="formula" target="#formula_1">(24)</ref> 4,469 (10) 439 (10) 642 (11) of inner entities is defined as</p><formula xml:id="formula_12">G 3 = (V, E), where r ij ∈ E.</formula><p>The new representation used to update flat module consists of two parts. The first part carries the previous representation of each token</p><formula xml:id="formula_13">α 1 i = W r x i + b r (11) where W r ∈ R dx×d f , b r ∈ R d f .</formula><p>The second part aggregates inner entity dependencies of the new graph G 3</p><formula xml:id="formula_14">α 2 i = BI-GCN(x i , G 3 )<label>(12)</label></formula><p>Finally, α 1 i and α 2 i are added to obtain the new representation</p><formula xml:id="formula_15">x new i = α 1 i + α 2 i<label>(13)</label></formula><p>x new i is fed into the flat module to update the parameters and extract better outermost entities.</p><p>For outermost entities, we use the BIOES sequence labeling scheme and adopt CRF to calculate the loss. The losses corresponding to the two representations (X and X new ) are added together as the outermost loss</p><formula xml:id="formula_16">L outer = CRF X + CRF X new<label>(14)</label></formula><p>Entities in the sequence are divided into two disjoint sets of outermost and inner entities, which are modeled by flat module and graph module, respectively. Entities in each module share the same neural network structure. Between two modules, each entity in the flat module is either an independent node, or interacting with one or more entities in the graph module. Therefore, Our BiFlaG is indeed a bipartite graph. Our complete training procedure for BiFlaG is shown in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Loss Function</head><p>Our BiFlaG model predicts both outermost and inner entities. The total loss is defined as</p><formula xml:id="formula_17">L = L outer + λ 2 L inner<label>(15)</label></formula><p>where λ 2 is a weight between loss of flat module and graph module. We minimize this total loss during training phase.</p><p>3 Experiment</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset and Metric</head><p>We evaluate our BiFlaG on three standard nested NER datasets: GENIA, ACE2005, and TACKBP2017 (KBP2017) datasets, which contain 22%, 10% and 19% nested mentions, respectively. <ref type="table" target="#tab_3">Table 1</ref> lists the concerned data statistics. GENIA dataset <ref type="bibr" target="#b12">(Kim et al., 2003)</ref> is based on the GENIAcorpus3.02p 1 . We use the same setup as previous works <ref type="bibr" target="#b2">(Finkel and Manning, 2009;</ref><ref type="bibr" target="#b21">Lu and Roth, 2015;</ref><ref type="bibr" target="#b19">Lin et al., 2019a)</ref>. This dataset contains 5 entity categories and is split into 8.1:0.9:1 for training, development and test.</p><p>ACE2005 2 <ref type="bibr" target="#b31">(Walker et al., 2006)</ref> contains 7 finegrained entity categories. We preprocess the dataset following the same settings of <ref type="bibr" target="#b21">(Lu and Roth, 2015;</ref><ref type="bibr" target="#b32">Wang and Lu, 2018;</ref><ref type="bibr" target="#b11">Katiyar and Cardie, 2018;</ref><ref type="bibr" target="#b19">Lin et al., 2019a)</ref> by keeping files from bn, nw and wl, and splitting these files into training, development and test sets by 8:1:1, respectively.</p><p>KBP2017 Following <ref type="bibr" target="#b19">(Lin et al., 2019a)</ref>, we evaluate our model on the 2017 English evaluation dataset (LDC2017E55). The training and development sets contain previous RichERE annotated datasets (LDC2015E29, LDC2015E68, LDC2016E31 and LDC2017E02). The datasets are split into 866/20/167 documents for training, development and test, respectively.</p><p>Metric Precision (P ), recall (R) and F-score (F 1 ) are used to evaluate the predicted entities. An entity is confirmed correct if it exists in the target labels, regardless of the layer at which the model makes this prediction.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Parameter Settings</head><p>Our model 3 is based on the framework of <ref type="bibr" target="#b35">(Yang and Zhang, 2018)</ref>. We conduct optimization with the stochastic gradient descent (SGD) and Adam for flat and GCN modules, respectively. For GE-NIA dataset, we use the same 200-dimension pretrained word embedding as <ref type="bibr" target="#b10">(Ju et al., 2018;</ref><ref type="bibr" target="#b29">Sohrab and Miwa, 2018;</ref><ref type="bibr" target="#b41">Zheng et al., 2019)</ref>. For ACE2005 and KBP2017 datasets, we use the publicly available pre-trained 100-dimension GloVe <ref type="bibr" target="#b26">(Pennington et al., 2014)</ref> embedding. We train the character embedding as in <ref type="bibr" target="#b34">(Xin et al., 2018)</ref>. The learning rate is set to 0.015 and 0.001 for flat and GCN modules, respectively. We apply dropout to embeddings and the hidden states with a rate of 0.5. The hidden sizes of BiLSTM and GCN are both set to 256. The bias weights λ 1 and λ 2 are both set to 1.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results and Comparisons</head><p>Table 2 compares our model to some existing state-of-the-art approaches on the three benchmark datasets. Given only standard training data and publicly available word embeddings, the results in <ref type="table" target="#tab_5">Table 2</ref> show that our model outperforms all these models. Current state-of-the-art results on these datasets are tagged with † in <ref type="table" target="#tab_5">Table 2</ref>, we make improvements of 0.5/1.3/2.8 F 1 on ACE2005, GE-NIA, and KBP2017 respectively. KBP2017 contains much more entities than ACE2005 and GE-NIA. The number of entities on test set is four times that of ACE2005. Our model has the most significant improvement on such dataset, proving the effectiveness of our BiFlaG model. More notably, our model without POS tags surpasses the previous models <ref type="bibr" target="#b32">(Wang and Lu, 2018;</ref><ref type="bibr" target="#b19">Lin et al., 2019a)</ref>, which use POS tags as additional representations on all three datasets. Besides, <ref type="bibr" target="#b20">(Lin et al., 2019b)</ref> incorporate gazetteer information on ACE2005 dataset, our model also makes comparable results with theirs. Other works like <ref type="bibr">(Straková et al., 2019) 4</ref> , which train their model on both training and development sets, are thus not comparable to our model directly. <ref type="table" target="#tab_7">Table 3</ref> makes a detailed comparison on the five categories of GENIA test dataset with a layered model <ref type="bibr" target="#b10">(Ju et al., 2018)</ref> and a region-based model <ref type="bibr" target="#b41">(Zheng et al., 2019)</ref>. Compared with region-based model, layered model seems to have higher precision and lower recall, for they are subject to error propagate, the outer entities will not be identified if the inner ones are missed. Meanwhile, regionbased model suffers from low precision, as they may generate a lot of candidate spans. By contrast, our BiFlaG model well coordinates precision and recall. The entity types Protein and DNA have the most nested entities on GENIA dataset, the improvement of our BiFlaG on these two entity types   <ref type="bibr" target="#b41">(Zheng et al., 2019)</ref> and <ref type="bibr" target="#b10">(Ju et al., 2018)</ref> on GENIA dataset.</p><p>is remarkable, which can be attributed to the interaction of nested information between the two subgraph modules of our BiFlaG. <ref type="table" target="#tab_9">Table 4</ref> evaluates the performance of each module on ACE2005 and GENIA datasets. Our flat module performs well on both datasets for outermost entity recognition. However, the recall of the inner entities is low on GENIA dataset. According to the statistics in <ref type="table" target="#tab_3">Table 1</ref>, only 11% of the entities on GENIA are located in inner layers, while on ACE2005 dataset, the proportion is 24%. It can be inferred that the sparsity of the entity distribution in inner layers has a great impact on the results. If these inner entities are identified at each layer, the sparsity may be even worse. We can enhance the impact of sparse entities by increasing the weight λ 1 in Eq. <ref type="formula" target="#formula_0">(14)</ref>, but this may hurt precision, we set λ 1 = 1.5 to have a better tradeoff between precision and recall.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Analysis of Each Module</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Analysis of Entity Length</head><p>We conduct additional experiments on ACE2005 dataset to detect the effect of the lengths of the outermost entities on the extraction of their inner entities as shown in <ref type="table" target="#tab_13">Table 6</ref>. Our flat module can well predict outermost entities which account for a large proportion among all types of entities. In general, the performance of inner entities is affected by the extracting performance and length of their outermost entities. A shorter outermost entity is more ACE2005 GENIA KBP2017  likely to have its inner entities shared either the first token or the last token, making the constructed graph more instructive, thus its inner entities are easier to extract.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Ablation Study</head><p>In this paper, we use the interactions of flat module and graph module to respectively help better predict outermost and inner entities. We conduct ablation study to verify the effectiveness of the interactions. The first part is the information delivery from the flat module to the graph module. We conduct four experiments: (1) no graph: we skip Eq. (5)-(6) and let graph feature f = LINEAR(x). In this case, inner entities are independent of the outermost entities and only rely on the word representation (section 2.1) which carries contextualized information.</p><p>(2) adjacent graph: we further utilize the sequential information of the text to help inner entity prediction.</p><p>(3) entity graph: the boundary information of outer entities can be indicative for inner entities, we construct an entity graph based on the entities extracted by the flat module. (4) both graphs: when outer entities are not recognized by the flat module, their inner entities will fail to receive the boundary information, we use the se-  quential information of the text to make up for the deficiency of using only entity graph. Experimental results show that entity graph carries more useful information than adjacent graph, which enhances the baseline by 1.4/1.1/1.2 F 1 score, respectively. By combing these two graphs together, we get a larger gain of 1.7/1.6/1.6 F 1 score. The second part is the information delivery from the graph module to the flat module, the new representation X new learned from graph module is propagated back to the flat module. X new is equipped with the dependencies of inner entities and shows useful, yielding an improvement of 0.8/1.5/0.5 F 1 for the three benchmarks, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Inference Time</head><p>We examine the inference speed of our BiFlaG with <ref type="bibr" target="#b41">(Zheng et al., 2019)</ref>, <ref type="bibr" target="#b29">(Sohrab and Miwa, 2018)</ref> and <ref type="bibr" target="#b10">(Ju et al., 2018)</ref> in terms of the number of words decoded per second. For all the compared models, we use the re-implemented code released by <ref type="bibr" target="#b41">(Zheng et al., 2019)</ref> and set the same batch size 10. Compared with <ref type="bibr" target="#b41">(Zheng et al., 2019)</ref> and <ref type="bibr" target="#b29">(Sohrab and Miwa, 2018)</ref>, our BiFlaG does not need to compute region representation for each potential entity, thus we can take full advantage of GPU parallelism. Compared with <ref type="bibr" target="#b10">(Ju et al., 2018)</ref>, which requires CRF decoding for each layer, our model only needs to calculate two modules, by contrast, the cascaded CRF layers limit their inference speed.   <ref type="bibr" target="#b6">He et al., 2018</ref><ref type="bibr" target="#b16">Li et al., 2018a</ref><ref type="bibr">Li et al., ,b, 2019</ref><ref type="bibr" target="#b33">Xiao et al., 2019;</ref><ref type="bibr" target="#b36">Zhang et al., , 2020a</ref>, it is possible to build reliable NER systems without hand-crafted features. Nested named entity recognition requires to identity all the entities in texts that may be nested with each other. Though NER is a traditional NLP task, it is not until the very recent years that researches have been paid to this nested structure for named entities. <ref type="bibr" target="#b21">(Lu and Roth, 2015)</ref> introduce a novel hypergraph representation to handle overlapping mentions. (Muis and Lu, 2017) further develop a gapbased tagging schema that assigns tags to gaps between words to address the spurious structures issue, which can be modeled using conventional linear-chain CRFs. However, it suffers from the structural ambiguity issue during inference. <ref type="bibr" target="#b32">(Wang and Lu, 2018)</ref> propose a novel segmental hypergraph representation to eliminate structural ambiguity. <ref type="bibr" target="#b11">(Katiyar and Cardie, 2018)</ref> also propose a hypergraph-based approach based on the BILOU tag scheme that utilizes an LSTM network to learn the hypergraph representation in a greedy manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Case Study</head><p>Stacking sequence labeling models to extract entities from inner to outer (or outside-to-inside) can also handle such nested structures. <ref type="bibr" target="#b0">(Alex et al., 2007)</ref> propose several different modeling techniques (layering and cascading) to combine multiple CRFs for nested NER. However, their approach cannot handle nested entities of the same entity type. <ref type="bibr" target="#b10">(Ju et al., 2018)</ref> dynamically stack flat NER layers, and recognize entities from innermost layer to outer ones. Their approach can deal with nested entities of the same type, but suffers from error propagation among layers.</p><p>Region-based approaches are also commonly used for nested NER by extracting the subse-quences in sentences and classifying their types. (Sohrab and Miwa, 2018) introduce a neural exhaustive model that considers all possible spans and classify their types. This work is further improved by <ref type="bibr" target="#b41">(Zheng et al., 2019)</ref>, which first apply a single-layer sequence labeling model to identify the boundaries of potential entities using context information, and then classify these boundary-aware regions into their entity type or non-entity. <ref type="bibr" target="#b19">(Lin et al., 2019a)</ref> propose a sequence-to-nuggets approach named as Anchor-Region Networks (ARNs) to detect nested entity mentions. They first use an anchor detector to detect the anchor words of entity mentions and then apply a region recognizer to identity the mention boundaries centering at each anchor word. <ref type="bibr" target="#b3">(Fisher and Vlachos, 2019)</ref> decompose nested NER into two stages. Tokens are merged into entities through real-valued decisions, and then the entity embeddings are used to label the entities identified.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>This paper proposes a new bipartite flat-graph (Bi-FlaG) model for nested NER which consists of two interacting subgraph modules. Applying the divideand-conquer policy, the flat module is in charge of outermost entities, while the graph module focuses on inner entities. Our BiFlaG model also facilitates a full bidirectional interaction between the two modules, which let the nested NE structures jointly learned at most degree. As a general model, our BiFlaG model can also handle non-nested structures by simply removing the graph module. In terms of the same strict setting, empirical results show that our model generally outperforms previous state-of-the-art models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>An example of nested named entity mentions. Solid lines connect the starting and ending indices of inner nested entities.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>The framework of our BiFlaG model. G 1 and G 2 are entity graph and adjacent graph created for GCN, each dashed line connects the start and end nodes for a potential entity. Solid red lines indicate inner entities recognized by the graph module.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>1</head><label></label><figDesc>Bipartite Flat-Graph Algorithm Input: word representations X = {x 1 , .., x N }, number of entity types L the dimension of word embeddings d x , the hidden size of GCN d f Output: all the entities in this sequence 1: for numbers of training iterations do</figDesc><table><row><cell>2:</cell><cell>y ← BILSTM-CRF(X)</cell></row><row><cell>3:</cell><cell>create entity graph G 1 based on y</cell></row><row><cell>4:</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>Statistics of the datasets used in our experiments: ACE2005 and KBP2017. o.l.: overlapping mentions.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>Experimental results 5 on ACE2005, GENIA and KBP2017 datasets. POS and Gazetteer indicates using additional POS tags and gazetteers. † represents previous state-of-the-art results under the same settings with our experiments,</figDesc><table /><note>* represents state-of-the-art results with POS tags or gazetteers, values in parentheses are also compared with them.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 3 :</head><label>3</label><figDesc>Our results on five categories compared to</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 4 :</head><label>4</label><figDesc>Performance of each module on ACE2005 and GENIA datasets.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 5 :</head><label>5</label><figDesc>Ablation study on the three benchmark datasets.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 6 :</head><label>6</label><figDesc>Length-wise results on ACE2005 test dataset.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 7</head><label>7</label><figDesc>shows a case study of each module in our model. In this example, entities my, my town, that and Krispy Kreme are nested in the entity the lo-Starbucks is taking over the location in my town that was recently abandoned by Krispy Kreme. Gold Label ORG: {Starbucks, Krispy Kreme}; FAC: {the location in my town that was recently abandoned by Krispy Kreme; that}; GPE: {my town}; PER: {my} No Graph ORG: {Starbucks}; LOC: {the location in my town that was recently abandoned by Krispy Kreme}; PER: {my} No interaction ORG: {Starbucks, Krispy Kreme}; LOC: {the location in my town that was recently abandoned by Krispy Kreme}; GPE: {my town}; PER: {my} BiFlaG ORG: {Starbucks, Krispy Kreme }; FAC: {the location in my town that was recently abandoned by Krispy Kreme; that}; GPE: {my town}; PER: {my}</figDesc><table><row><cell>Figure 3: The inference speed of our BiFlaG and com-</cell></row><row><cell>pared models on GENIA test set. t/s indicates token per</cell></row><row><cell>second.</cell></row><row><cell>cation in my town that was recently abandoned</cell></row><row><cell>by Krispy Kreme. Our BiFlaG model successfully</cell></row><row><cell>extracts all these entities with exact boundaries</cell></row><row><cell>and entity categorical labels. Without graph con-</cell></row><row><cell>struction, nested entities my town, that and Krispy</cell></row><row><cell>Kreme are not identified. Without interaction be-</cell></row><row><cell>tween the two modules, the outermost entity the</cell></row><row><cell>location in my town that was recently abandoned</cell></row><row><cell>by Krispy Kreme is mislabeled as LOC (location),</cell></row><row><cell>which is actually a FAC (Facility) type, inner nested</cell></row><row><cell>entities my, my town and Krispy Kreme are not</cell></row><row><cell>propagated back to the flat module, which maybe</cell></row><row><cell>helpful to correct the extracting of the outermost</cell></row><row><cell>entity.</cell></row><row><cell>5 Related Work</cell></row><row><cell>Recently, with the development of deep neural net-</cell></row><row><cell>work in a wide range of NLP tasks (Bai and Zhao,</cell></row><row><cell>2018; Huang et al., 2018; Huang and Zhao, 2018;</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 7 :</head><label>7</label><figDesc>An example of predicted results in ACE2005 test dataset.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Code is available at: https://github.com/cslydia/BiFlaG. 4 This result is reported by<ref type="bibr" target="#b41">(Zheng et al., 2019)</ref>, consistent with our own re-implemented results.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Their reported results are 75.36 and 76.44 trained on concatenated train+dev sets on ACE2005 and GENIA, respectively. They also use lemmas and POS tags as additional features.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Recognising nested named entities in biomedical text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatrice</forename><surname>Alex</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Grover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Biological, translational, and clinical language processing</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="65" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep enhanced representation for implicit discourse relation recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongxiao</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="571" to="583" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Nested named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><forename type="middle">Rose</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="141" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Merge and label: A novel neural network architecture for nested NER</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1585</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5840" to="5850" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">GraphRel: Modeling text as relational graphs for joint entity and relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsu-Jui</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng-Hsuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Yun</forename><surname>Ma</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1136</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1409" to="1418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Syntaxaware multilingual semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shexia</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuchao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1538</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5350" to="5359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Syntax for semantic role labeling, to be, or not to be</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shexia</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuchao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongxiao</forename><surname>Bai</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1192</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2061" to="2071" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Moon IME: Neural-based Chinese pinyin aided input method with customizable association</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yafang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuchao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuosheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-4024</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2018, System Demonstrations</title>
		<meeting>ACL 2018, System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="140" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Chinese pinyin aided IME, input what you have not keystroked yet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yafang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1321</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2923" to="2929" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Overview of tac-kbp2017 13 languages entity discovery and linking. Theory and Applications of Categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoman</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boliang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Nothman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Mayfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Mcnamee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cash</forename><surname>Costello</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A neural layered model for nested named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meizhi</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makoto</forename><surname>Miwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sophia</forename><surname>Ananiadou</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-1131</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1446" to="1459" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Nested named entity recognition revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arzoo</forename><surname>Katiyar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-1079</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Long Papers</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="861" to="871" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Genia corpusa semantically annotated corpus for bio-textmining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J-D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoko</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuka</forename><surname>Tateisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="page" from="180" to="182" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Semisupervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><forename type="middle">C N</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Neural architectures for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandeep</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuya</forename><surname>Kawakami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N16-1030</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="260" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Seq2seq dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuchao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxun</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shexia</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3203" to="3214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A unified syntax-aware framework for semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuchao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shexia</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxun</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuosheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gongshen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linlin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luo</forename><surname>Si</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1262</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2401" to="2411" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Dependency or span, end-to-end uniform semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuchao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shexia</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiqing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuosheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6730" to="6737" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Sequence-to-nuggets: Nested entity mention detection via anchor-region networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaojie</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianpei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1511</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5182" to="5192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Gazetteerenhanced attentive neural networks for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaojie</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianpei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanshan</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1646</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6232" to="6237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Joint mention extraction and classification with mention hypergraphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D15-1102</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="857" to="867" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Hierarchical contextualized representation for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengshun</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI-2020)</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">End-to-end sequence labeling via bi-directional LSTM-CNNs-CRF</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P16-1101</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1064" to="1074" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Encoding sentences with graph convolutional networks for semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Marcheggiani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-1159</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1506" to="1515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Labeling gaps between words: Recognizing overlapping mentions with mention separators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aldrian</forename><surname>Obaja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muis</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-1276</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2608" to="2618" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/D14-1162</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Semi-supervised sequence tagging with bidirectional language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waleed</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chandra</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russell</forename><surname>Power</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1161</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1756" to="1765" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">GraphIE: A graph-based framework for information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujie</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enrico</forename><surname>Santus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhijing</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1082</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="751" to="761" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deep exhaustive model for nested named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Golam</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makoto</forename><surname>Sohrab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Miwa</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1309</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2843" to="2849" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Neural architectures for nested NER through linearization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jana</forename><surname>Straková</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milan</forename><surname>Straka</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1527</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5326" to="5331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephanie</forename><surname>Strassel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julie</forename><surname>Medero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuaki</forename><surname>Maeda</surname></persName>
		</author>
		<title level="m">Ace 2005 multilingual training corpus. Linguistic Data Consortium</title>
		<meeting><address><addrLine>Philadelphia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page">57</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Neural segmental hypergraphs for overlapping mention recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bailin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1019</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="204" to="214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Lattice-based transformer encoder for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengshun</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangtong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kehai</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1298</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3090" to="3097" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning better internal structure of words for sequence labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingwei</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vibhuti</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-David</forename><surname>Ruvini</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1279</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2584" to="2593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">NCRF++: An opensource neural sequence labeling toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-4013</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2018, System Demonstrations</title>
		<meeting>ACL 2018, System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="74" to="79" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">DCMN+: Dual co-matching network for multi-choice reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuailiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuwei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuosheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI-2020)</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Open vocabulary learning for neural Chinese pinyin IME</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuosheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yafang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1154</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1584" to="1594" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Semantics-aware BERT for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuosheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuwei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuchao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuailiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI-2020)</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">SG-Net: Syntaxguided machine reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuosheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuwei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junru</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sufeng</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI-2020)</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">One-shot learning for question-answering in Gaokao history challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuosheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="449" to="461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A boundary-aware neural model for nested named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changmeng</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingyun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guandong</forename><surname>Ho-Fung Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1034</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="357" to="366" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Head-driven phrase structure grammar parsing on Penn treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junru</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1230</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2396" to="2408" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
