<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Knowledge Graph Alignment Network with Gated Multi-hop Neighborhood Aggregation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zequn</forename><surname>Sun</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory for Novel Software Technology</orgName>
								<orgName type="institution">Nanjing University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengming</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory for Novel Software Technology</orgName>
								<orgName type="institution">Nanjing University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hu</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory for Novel Software Technology</orgName>
								<orgName type="institution">Nanjing University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">†</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhao</forename><surname>Chen</surname></persName>
							<email>muhaochen@ucla.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Dai</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Alibaba Group</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Alibaba Group</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuzhong</forename><surname>Qu</surname></persName>
							<email>yzqu@nju.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory for Novel Software Technology</orgName>
								<orgName type="institution">Nanjing University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Knowledge Graph Alignment Network with Gated Multi-hop Neighborhood Aggregation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T06:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Graph neural networks (GNNs) have emerged as a powerful paradigm for embedding-based entity alignment due to their capability of identifying isomorphic subgraphs. However, in real knowledge graphs (KGs), the counterpart entities usually have non-isomorphic neighborhood structures, which easily causes GNNs to yield different representations for them. To tackle this problem, we propose a new KG alignment network, namely AliNet, aiming at mitigating the non-isomorphism of neighborhood structures in an end-to-end manner. As the direct neighbors of counterpart entities are usually dissimilar due to the schema heterogeneity, AliNet introduces distant neighbors to expand the overlap between their neighborhood structures. It employs an attention mechanism to highlight helpful distant neighbors and reduce noises. Then, it controls the aggregation of both direct and distant neighborhood information using a gating mechanism. We further propose a relation loss to refine entity representations. We perform thorough experiments with detailed ablation studies and analyses on five entity alignment datasets, demonstrating the effectiveness of AliNet.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Entity alignment is the task of finding entities from different knowledge graphs (KGs) that refer to the same real-world identity. Recently, increasing attention has been paid to the utilization of KG representation learning rather than symbolic formalism for tackling this task. Representation learning models encode KGs into vector spaces, where relation semantics of entities can be assessed by the learned embedding operations, such as the relation-specific translation <ref type="bibr" target="#b1">(Bordes et al. 2013)</ref> or rotation . For embedding-based entity alignment, the similarity of entities is measured by the distance of entity embeddings. It has shown great potentials in dealing with the symbolic heterogeneity problem and benefits the entity alignment task in both monolingual and cross-lingual scenarios <ref type="bibr" target="#b38">(Zhu et al. 2017;</ref><ref type="bibr" target="#b4">Chen et al. 2017)</ref>.</p><p>Most recently, graph neural networks (GNNs) <ref type="bibr" target="#b14">(Kipf and Welling 2017;</ref><ref type="bibr" target="#b29">Velickovic et al. 2018</ref>; Abu-El-Haija et al. 2019) have emerged as a powerful model to learn vector representations for graph-structured data. In GNNs, the representation of a node is learned by recursively aggregating the representations of its neighboring nodes. A recent work <ref type="bibr" target="#b18">(Morris et al. 2019)</ref> has proved that GNNs have the same expressiveness as the Weisfeiler-Leman (WL) test <ref type="bibr" target="#b32">(Weisfeiler and Lehman 1968)</ref> in terms of identifying isomorphic subgraphs. It provides the theory basis of using GNNs for entity alignment between different KGs as similar entities usually have similar neighborhood. Recently, several studies <ref type="bibr" target="#b31">(Wang et al. 2018;</ref><ref type="bibr" target="#b35">Xu et al. 2019b;</ref><ref type="bibr" target="#b2">Cao et al. 2019;</ref><ref type="bibr" target="#b33">Wu et al. 2019;</ref><ref type="bibr" target="#b36">Ye et al. 2019</ref>) have exploited GNNs for embedding-based entity alignment, and have achieved promising results.</p><p>However, existing GNN-based entity alignment models still face a critical problem. As different KGs usually have heterogeneous schemas and data incompleteness <ref type="bibr" target="#b21">(Pujara et al. 2013)</ref>, the counterpart entities usually have dissimilar neighborhood structures. <ref type="figure" target="#fig_0">Figure 1</ref> gives an example. The neighborhood of the two entities referring to Kobe Bryant is inconsistent to each other, especially containing different sets of neighboring entities. The statistics on DBpedia-based benchmark datasets for entity alignment <ref type="bibr" target="#b26">(Sun, Hu, and Li 2017)</ref> also show that the majority of aligned entity pairs have different neighboring entities. Particularly, the percentages of such entity pairs reach 89.97% between Chinese-English, 86.19% between Japanese-English and 90.71% between French-English, respectively. Different neighborhood structures would easily cause a GNN to yield different representations for counterpart entities.</p><p>The challenge of resolving this issue lies in the difficulty of fully mitigating the non-isomorphism in the neighborhood structures of counterpart entities from different KGs. Even though we assume that the two KGs are complete (the goal of MuGNN <ref type="bibr" target="#b2">(Cao et al. 2019)</ref>), due to the schema heterogeneity, the counterpart entities still inevitably have dissimilar neighborhood structures. For example, in <ref type="figure" target="#fig_0">Figure 1</ref>, United States of America is among the one-hop (direct) neighbors of Kobe Bryant in Wikidata. However in DBpedia, it is a two-hop neighbor. Motivated by the fact that the semantically-related information can appear in both direct and distant neighbors of counterpart entities, we propose the KG alignment network AliNet which aggregates both direct and distant neighborhood information. Specifically, each AliNet layer has multiple functions to aggregate the neighborhood information within multiple hops. To reduce noise information, we further employ an attention mechanism for the distant neighborhood aggregation to find out important neighbors in an end-to-end manner. Finally, we use the gating mechanism to combine the output representations of the multiple aggregation functions, obtaining the hidden representations in the current layer. We also design a relation loss to refine entity representations and enable AliNet to capture some special structures such as the triangular relational structure. We perform thorough experiments with detailed ablation studies and analyses on five entity alignment datasets, demonstrating the effectiveness of AliNet and each of its technical contributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">GNNs</head><p>In GNNs, the representation of a node is learned by recursively aggregating the feature vectors of its neighbors. Different aggregation strategies lead to different variants of GNNs.</p><p>GCN A very popular variant of GNNs is the vanilla GCN <ref type="bibr" target="#b14">(Kipf and Welling 2017)</ref>. The hidden representation of node i at the l-th layer (l ≥ 1), denoted as h</p><formula xml:id="formula_0">(l) i , is computed by: h (l) i = σ j∈N1(i)∪{i} 1 c i W (l) h (l−1) j ,<label>(1)</label></formula><p>where N 1 (·) represents the set of one-hop neighbors of the given entity, W (l) is the weight matrix of the l-th layer and c i is the normalization constant. σ(·) is an activation function. The vanilla GCN encodes a node as the mean pooling of the representations of its neighbors and itself from the last layer. The input vector fed to the first layer is denoted as h</p><p>i . R-GCN Conventional GNNs only consider the node-wise connectivity in a graph and ignore edge labels such as the relations in KGs. R-GCN <ref type="bibr" target="#b22">(Schlichtkrull et al. 2018</ref>) addresses this issue by distinguishing different neighbors with relationspecific weight matrices. It computes h (l) i as follows:</p><formula xml:id="formula_2">h (l) i = σ W (l) 0 h (l−1) i + r∈R j∈Nr(i) 1 c i,r W (l) r h (l−1) j ,<label>(2)</label></formula><p>where W (l) 0 is the weight matrix for the node itself and W (l) r is used specifically for the neighbors having relation r, i.e., N r (i). R is the relation set and c i,r is for normalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Entity Alignment of KGs</head><p>We formally represent a KG as G = (E, R, T ), where E is the set of entities, R is the set of relations, and T = E × R × E is the set of triples. Without loss of generality, we consider the entity alignment task between two KGs, i.e., G 1 = (E 1 , R 1 , T 1 ) and G 2 = (E 2 , R 2 , T 2 ). Given partial prealigned entity pairs A + = {(i, j) ∈ E 1 × E 2 |i ≡ j} where ≡ means the alignment relationship, the goal of the task is to find alignment of remaining entities via entity embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">GNNs for Entity Alignment</head><p>Recent GNN-based entity alignment models include GCN-Align <ref type="bibr" target="#b31">(Wang et al. 2018)</ref>, GMNN <ref type="bibr" target="#b35">(Xu et al. 2019b</ref>), MuGNN <ref type="bibr" target="#b2">(Cao et al. 2019)</ref>, RDGCN ) and AVR-GCN <ref type="bibr" target="#b36">(Ye et al. 2019</ref>). GCN-Align and GMNN are built based on the vanilla GCN. RDGCN introduces dual relation graphs to enhance the vanilla GCN. AVR-GCN extends R-GCN using a TransE-like relation-specific translation operation <ref type="bibr" target="#b1">(Bordes et al. 2013)</ref>. Before aggregation, each entity representation is translated from its tail entity representations using relation vectors. We argue that such relation-specific translation and R-GCN introduce a high complexity with the overhead of trainable parameters. More importantly, the aforementioned models do not take the non-isomorphism in KG structures into consideration. While MuGNN <ref type="bibr" target="#b2">(Cao et al. 2019</ref>) notices the structure incompleteness of KGs and proposes a twostep method of rule-based KG completion and multi-channel GNNs for entity alignment. However, the learned rules rely on relation alignment to resolve schema heterogeneity.</p><p>Isomorphic structures are beneficial GNNs would learn the same representation for the entities that have isomorphic neighborhood structures with identical feature vectors representing corresponding neighbors <ref type="bibr" target="#b34">(Xu et al. 2019a)</ref>. We show that, in some cases, if two entities have isomorphic neighborhood structures and only partially pre-aligned neighbor representations, GNNs can also capture the similarity of other neighbors to be aligned. <ref type="figure">Figure 2</ref> (i) gives an example. For simplicity, here we consider a single-layer GCN. We can let pre-aligned entities have the same representation by minimizing their Euclidean distance, i.e., h</p><formula xml:id="formula_3">a = h (0) a , h (0) b = h (0) b and h (0) d = h (0) d as well as h (1) a = h (1) a , h (1) b = h (1) b and h (1) d = h<label>(0)</label></formula><p>(1) d in the ideal condition. By the mean-pooling based aggregation, we have h</p><formula xml:id="formula_4">(1) b = σ(W (1) (h (0) b + h (0) a + h (0) c )/3) and h (1) b = σ(W (1) (h (0) b + h (0) a + h (0) c )/3), yield- ing h (0) c = h (0)</formula><p>c . Finally, the counterpart entities would have the same representation. This indicates that the alignment information between entities can be propagated across the different GNN layers and different isomorphic graphs given partially pre-aligned neighborhood. However, for entity alignment between different KGs, it is impossible to require the two KGs to have isomorphic structures due to the schema heterogeneity. <ref type="figure">Figure 2</ref> (ii) gives an example of non-isomorphic graph structures, where c and c would have different representations due to their different neighborhood structures.</p><p>Only structures are not enough Conventional GNNs fall short of characterizing some special subgraph structures such  <ref type="figure">Figure 2</ref>: Illustration of GNNs for entity alignment. In (i), (ii) and (iii), (a, a ), (b, b ) and (d, d ) denote three pairs of pre-aligned entities while others are entities to be aligned. The dotted lines in (iv) means the alignment relationship.</p><p>as triangular graphs. <ref type="figure">Figure 2</ref> (iii) shows a simple example. In this case, if we use mean-pooling aggregation, we would get that h</p><p>(1)</p><formula xml:id="formula_5">a = h (1) a = h (1) b = h (1)</formula><p>b because the four entities have isomorphic neighborhood structures. While in fact, a and b are different entities with a specific relation. We should take relations into consideration. Although R-GCN <ref type="bibr" target="#b22">(Schlichtkrull et al. 2018)</ref> considers relations in the aggregation function, it relies on relation alignment for identifying similar entities. Let us review Eq. (2). R-GCN needs to learn a weight matrix W r for each relation r. If the relations of two KGs are not pre-aligned (e.g., r 1 ≡ r 1 and r 2 ≡ r 2 ), the relation-specific aggregation functions in R-GCN would fall short of propagating the alignment information of entities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Compensation with distant neighborhood and relations</head><p>The schema heterogeneity of different KGs usually brings about the mixture of direct and distant neighbors of counterpart entities. To reduce the effects of the non-isomorphism in neighborhood structures, we propose introducing distant neighborhood information. We show a toy example in <ref type="figure">Figure  2</ref> (iv). The one-hop neighbors of two counterpart entities a and a are different and only contain two pairs of counterpart entities (b, b ) and (c, c ). The one-hop neighbor d of a is in fact the distant neighbor d of a . The distant neighbors e and f of a are aligned with the one-hop neighbors e and f of a , respectively. It is intuitive that if we can include the distant neighbors e and f in the neighborhood aggregation for a, and also take d into consideration for a , the GNN would learn more similar representations for a and a . However, as can be seen, not all the distant neighbors are helpful. Therefore, the aggregation of distant neighbors should be attentive and selective. This is the key motivation of AliNet. To further enhance the expressiveness of AliNet, we also take relation semantics into consideration without introducing relation vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Knowledge Graph Alignment Network</head><p>In AliNet, the entity representations are learned by a controlled aggregation of their neighborhood information within k hops by the gating mechanism. Without loss of generality, in the following, we show the case of aggregating both the one-hop and two-hop neighborhood information (k = 2). The network architecture is illustrated in <ref type="figure" target="#fig_1">Figure 3</ref>. Note that AliNet can also be extended to more hops.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Gated Multi-hop Neighborhood Aggregation</head><p>The one-hop neighbors of an entity are the most important neighborhood for GNNs to characterize the entity. We aggre-gate these neighbor representations using the vanilla GCN layers. Specifically, at the i-th layer, the hidden representation of entity i by aggregating its one-hop neighbors, denoted as h (l) i,1 , can be computed using Eq. (1). As discussed before, it is not enough to only aggregate onehop neighbors. Although a GCN with L layers can capture the structural information within the entitys L-hop neighbors, such layer-by-layer propagation is not efficient. For two-hop neighborhood aggregation, we introduce the attention mechanism because directly employing the original aggregation of GCN would cause noise information to propagate through layers. Specifically, let N 2 (·) be the set of two-hop neighbors of the given entity. The hidden representation of entity i by aggregating its two-hop neighborhood information at the l-th layer, denoted as h</p><formula xml:id="formula_6">(l) i,2 , is computed as follows: h (l) i,2 = σ j∈N2(i)∪{i} α (l) ij W (l) 2 h (l−1) j ,<label>(3)</label></formula><p>where α (l)</p><p>ij is a learnable attention weight for entity i and its neighbor j. W (l) 2 is the weight matrix. The computation of attention weights is introduced in the next subsection.</p><p>Inspired by the skipping connections in neural networks <ref type="bibr" target="#b23">(Srivastava, Greff, and Schmidhuber 2015;</ref><ref type="bibr" target="#b11">He et al. 2016;</ref><ref type="bibr" target="#b10">Guo, Sun, and Hu 2019)</ref>. We propose to use the gating mechanism to combine the information from one-hop and two-hop neighbors directly. Specifically, the hidden representation h (l) i of entity i at the l-th layer is computed as follows:</p><formula xml:id="formula_7">h (l) i = g(h (l) i,2 ) · h (l) i,1 + (1 − g(h (l) i,2 )) · h (l) i,2 ,<label>(4)</label></formula><p>where g(h</p><formula xml:id="formula_8">(l) i,2 ) = σ(Mh (l)</formula><p>i,2 + b) serves as the gate to control the combination of both one-hop and two-hop neighborhood. M and b are the weight matrix and bias vector, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Attention for Distant Neighborhood</head><p>The number of the more distant neighbors of an entity can grow exponentially than the number of its one-hop neighbors. It is intuitive that not all the distant neighbors contribute to the characterization of the central entity. Hence, for two-hop neighborhood aggregation, we compute the attention weights between entities for highlighting useful neighbors. The graph attention network GAT <ref type="bibr" target="#b29">(Velickovic et al. 2018</ref>) applies a shared linear transformation to entities in each attention function. However, as the central entity and its neighbors in KGs can be quite different, such shared transformation would ij ∈ R between i and j at the l-th layer is computed as follows:</p><formula xml:id="formula_9">c (l) ij = LeaklyReLU[(M (l) 1 h (l) i ) (M (l) 2 h (l) j )],<label>(5)</label></formula><p>Finally, we normalize attention weights using the softmax function to make them comparable across different entities:</p><formula xml:id="formula_10">α (l) ij = softmax j (c (l) ij ) = exp(c (l) ij ) n∈N2(i)∪{i} exp(c (l) in )</formula><p>. <ref type="formula">(6)</ref> 3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>.3 Contrastive Alignment Loss</head><p>We minimize the contrastive alignment loss to let the representations of aligned entities have a very small distance while those of unaligned entities have a large distance:</p><formula xml:id="formula_11">L1 = (i,j)∈A + ||hi −hj||+ (i ,j )∈A − α1[λ−||h i −h j ||]+,<label>(7)</label></formula><p>where A − is the set of negative samples generated by randomly substituting one of the two pre-aligned entities. || · || denotes the L 2 vector norm.</p><p>[·] + = max(0, ·) The distance of negative samples is expected to be larger than a margin λ, i.e., ||h i − h j || &gt; λ. α 1 is a hyper-parameter for balance. Previous work usually uses the hidden outputs at the last layer as the final representations of entities, i.e. h i = h (L) i where L denotes the number of layers. However, as discussed in Section 2, the representations of each layer all contribute to propagating alignment information. Therefore, we use the hidden representations of all layers. Formally, we have</p><formula xml:id="formula_12">h i = L ⊕ l=1 norm(h (l) i ),<label>(8)</label></formula><p>where ⊕ represents concatenation and norm(·) is the L 2 normalization for reducing the trivial optimization procedure of artificially increasing vector norm <ref type="bibr" target="#b1">(Bordes et al. 2013</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Relation Semantics Modeling</head><p>As KGs provide semantic relations between entities, it is natural to incorporate the semantics of the relational facts into entity modeling. As discussed in Section 2, R-GCN needs the structures of two KGs to be highly similar or relation alignment for entity alignment. Here, we borrow the translational assumption from TransE <ref type="bibr" target="#b1">(Bordes et al. 2013)</ref>. To avoid overhead of parameters, we do not introduce additional relation-specific embeddings. The representation for r, denoted as r, can be retrieved via its related entity embeddings:</p><formula xml:id="formula_13">r = 1 |T r | (s,o)∈Tr (h s − h o ),<label>(9)</label></formula><p>where T r is the subject-object entity pairs of relation r. Then we minimize the following relation loss for refinement:</p><formula xml:id="formula_14">L 2 = r∈R 1 |T r | (s,o)∈Tr ||h s − h o − r||,<label>(10)</label></formula><p>where R is the set of the total relations in the two KGs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Implementation</head><p>Next, we introduce implementation details of AliNet.</p><p>Objective The final objective of AliNet is the combination of the contrastive alignment loss and relation loss, aiming at injecting relation semantics to the preserved graph structures:</p><formula xml:id="formula_15">L = L 1 + α 2 L 2 ,<label>(11)</label></formula><p>where α 2 is a hyper-parameter to weight the two losses. The objective is optimized using the Adam optimizer. All the learnable parameters including the input feature vectors of entities are initialized by the Xavier initialization <ref type="bibr" target="#b9">(Glorot and Bengio 2010)</ref>. The adjacency information is a sparse matrix obtained from the relational triples T 1 and T 2 . The neighborhood aggregation can be done by the sparse matrix multiplication between the adjacency matrix and the entity representation matrix, making the storage complexity linear to the number of entities and triples.</p><p>Generalization to k-hop neighborhood Here we consider aggregating the neighborhood information within k hops. Let</p><formula xml:id="formula_16">ρ 1 (h (l) i,1 , h<label>(l)</label></formula><p>i,2 ) be the gating combination for the one-hop and two-hop neighborhood aggregation in Eq. (4). We use k − 1 gating functions to combine the information recursively:</p><formula xml:id="formula_17">h (l) i = ρ k−1 (· · · ρ 2 (ρ 1 (h (l) i,1 , h (l) i,2 ), h (l) i,3 ) · · · ).<label>(12)</label></formula><p>Neighborhood augmentation The proposed gated multihop neighborhood aggregation expands the direct neighbors of an entity in an end-to-end manner. To further implement this idea, we propose a heuristic method to add edges among pre-aligned entities. Specifically, if two entities i and j of KG 1 have an edge while their counterparts i and j in KG 2 do not, we add an edge linking i and j . The goal is to mitigate the non-isomorphism by adding such balanced edges.</p><p>Alignment prediction Once trained AliNet, we can predict entity alignment based on the nearest neighbor search among entity representations in the cross-KG scope. Given a source entity i to be aligned in KG 1 , its counterpart in KG 2 is: i = arg min j∈E2 π(h i , h j ), where π() is a distance measure such as Euclidean distance. Here we still use the combined representations to measure the distance of entity embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we evaluate AliNet on the entity alignment task. The source code of AliNet is accessible online 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>Following the latest progress <ref type="bibr" target="#b2">Cao et al. 2019)</ref>, we use the following datasets and training-test splits.</p><p>• DBP15K (Sun, Hu, and Li 2017) has three datasets built from multi-lingual DBpedia, namely DBP ZH-EN (Chinese-English), DBP JA-EN (Japanese-English) and DBP FR-EN (French-English). Each dataset has 15, 000 reference entity alignment and about four hundred thousand triples.</p><p>• DWY100K  are extracted from DBpedia, Wikidata and YAGO3. It has two datasets, namely DBP-WD (DBpedia-Wikidata) and DBP-YG (DBpedia-YAGO3). Each dataset has 100, 000 reference entity alignment and more than nine hundred thousand triples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Comparative Models</head><p>We compare with recent embedding-based entity alignment models: MTransE <ref type="formula">(</ref> Note that some recent GNN-based models like GMNN <ref type="bibr" target="#b35">(Xu et al. 2019b</ref>) and RDGCN ) incorporate the surface information of entities into their representations. As our model solely relies on structure information, we do not take these models into comparison. For ablation study, we develop three variants of AliNet, i.e., AliNet (w/o rel. loss) that does not optimize the relation loss, AliNet (w/o rel. loss &amp; augment.) that does not employ the relation loss and neighborhood augmentation, and the full model AliNet.</p><p>For comprehensive comparison, we also choose some KG embedding models and GNN variants as baselines. Conventional KG embedding models are usually evaluated on the task of link prediction. However, as studied in , some of them can also be used for entity alignment. We select TransH <ref type="bibr" target="#b30">(Wang et al. 2014)</ref>, ConvE <ref type="bibr" target="#b8">(Dettmers et al. 2018)</ref> and RotatE . TransE <ref type="bibr" target="#b1">(Bordes et al. 2013</ref>) has already been exploited for entity alignment by MTransE and IPTransE. For GNNs, we choose GCN <ref type="bibr" target="#b14">(Kipf and Welling 2017)</ref>, GAT <ref type="bibr" target="#b29">(Velickovic et al. 2018</ref>) and R-CGN <ref type="bibr" target="#b22">(Schlichtkrull et al. 2018)</ref> as baselines. The re-tuned versions of GCN, GAT and R-GCN are implemented by ourselves following the same pipeline as AliNet for fair comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Implementation Details</head><p>We search among the following values for hyper-parameters, i.e., the learning rate in {0.0001, 0.0005, 0.001, 0.005, 0.01}, α 1 <ref type="figure" target="#fig_0">in {0.1, 0.2, . . . , 0.5}, α 2 in {0.01, 0.05, 0.1, 0.2}, λ in  {1.0, 1.1, . . . , 2.0}</ref>, the hidden representation dimension of each layer in {100, 200, 300, 400, 500}, the number of layers L <ref type="figure" target="#fig_0">in {1, 2, 3, 4}</ref>, and the number of negative alignment pairs in {5, 10, 15, 20}. The selected setting is that λ = 1.5, α 1 = 0.1, α 2 = 0.01. The learning rate is 0.001. The batch size for DBP15K is 4, 500, and for DWY100K is 10, 000. We stack two AliNet layers (L = 2) and each layer combines the one-hop and two-hop information (k = 2). The dimensions of three layers (including the input layer) are 500, 400 and 300, respectively. The activation function for neighborhood aggregation is tanh(), and the one for the gating mechanism is ReLU(). We sample 10 negative samples for each pre-aligned entity pair. We use early stopping to terminate training based on the Hits@1 performance with a patience of 5 epochs. We use CSLS <ref type="bibr" target="#b7">(Conneau et al. 2018)</ref> for nearest neighbor search.</p><p>Following convention, we report the Hits@1, Hits@10 and MRR (mean reciprocal rank) results to assess entity alignment performance. Higher Hits@1, Hits@10 and MRR scores indicate better performance. Note that, the Hits@1 is equivalent to precision. As the nearest neighbor search can always find a counterpart for each entity to be aligned, the recall and F1-measure also have the same value as Hits@1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Main Results</head><p>We present the entity alignment results in <ref type="table" target="#tab_1">Table 1</ref>. We can see that AliNet outperforms the state-of-the-art structure-based embedding models for entity alignment by Hits@1 and MRR. For example, on DBP FR-EN , AliNet achieves a gain of 0.036 by Hits@1 compared with RSN, and 0.057 against MuGNN. We think that these results have demonstrated the superiority of AliNet. As the DBP15K datasets are extracted from the multi-lingual DBpedia, the schema heterogeneity of them is much weaker than that of DWY100K which are extracted from different KGs. AliNet also achieves the best Hits@10 results on DWY100K, demonstrating its practicability. We find that the neighborhood augmentation method leads AliNet a gain of 0.012 − 0.037 by Hits@1. This is because it can reduce the non-isomorphism in the neighborhood structures of pre-aligned entities. The results further support our motivation of mitigating the non-isomorphism in KG structures for entity alignment. AliNet shows better performance than AliNet (w/o rel. loss), showing the effect of the relation loss.</p><p>In comparison to the re-tuned GNN variants GCN, GAT and R-GCN, AliNet also achieves better performance. As the GCN baseline has the same training process as AliNet and the difference only lies in the choice of GNN layers (i.e., GCN layers for one-hop neighborhood aggregation or AliNet layers for both one-hop and two-hop neighborhood aggregation), these results can demonstrate the effectiveness of integrating multi-hop information. Both GAT and R-GCN fail to outperform GCN. We attribute such observation to that  the direct neighbors of an entity are less dissimilar than distant neighbors, and hence may not require an attention-based neighborhood aggregation to select relevant neighboring entities. This is also the reason for choosing GCN layers rather than GAT layers in the one-hop neighborhood aggregation of AliNet. For R-GCN, as discussed in Section 2, it cannot well capture the similarity of neighborhood structures of counterpart entities. We also observe that the GCN baseline outperforms many other embedding-based entity alignment models including another GCN variant GCN-Align. This again validates the effectiveness of our framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Analyses</head><p>Aggregation strategies of multi-hop neighborhood The underlying idea of AliNet is to extend the neighborhood of entities by attentively aggregating multi-hop neighborhood with the gating mechanism. To gain a deep insight into this point, we further design three variants of AliNet using different strategies to aggregate multi-hop neighborhood. The first one, denoted as AliNet (mix), borrows the idea from MixHop <ref type="bibr" target="#b0">(Abu-El-Haija et al. 2019)</ref>, which has a similar motivation for node classification in general graphs. It takes the two-hop neighbors as one-hop and uses GCN layers to directly aggregate such mixed neighborhood information. The second one, denoted as AliNet (add), replaces the gating mechanism with addition operator. In the last variant AliNet (gat), we replace the proposed attention mechanism with GAT <ref type="bibr" target="#b29">(Velickovic et al. 2018)</ref>. Due to space limitation, we only show the results on DBP15K in <ref type="table" target="#tab_2">Table 2</ref>. We find that AliNet (mix) fails to achieve promising performance, which indicates that using GCN layers for two-hop neighborhood aggregation is not effective because it would introduce much noise information. AliNet (add) does not show very satisfactory results because addition cannot selectively combine important representations across dimensions like the gating mechanism. AliNet (gat) also achieves slightly lower performance than AliNet, showing the effect of our attention mechanism. Based on these results and the performance of the GCN baseline shown in <ref type="table" target="#tab_1">Table 1</ref>, we can come to the conclusion that the  The number of layers Impact of the number of layers and choice of k We first report the results of AliNet with 1 to 4 layers on DBP15K in <ref type="figure" target="#fig_5">Figure 4</ref>. AliNet with 2 layers achieves the best performance over all the three metrics. We observe that when AliNet has more layers, its performance declines as well. Although more layers allow AliNet to indirectly capture more distant neighborhood information by layer-to-layer propagation, such distant neighbors would introduce much noise and lead to more non-isomorphic neighborhood structures. Besides, we further show the results of the two-layer AliNet that considers different hops of neighborhood information in each layer in  Analysis of neighborhood overlap Furthermore, we make an empirical statistics on the overlap coefficient (OC) of the one-hop neighbors for each pair of counterpart entities in the correctly-found alignment. A high OC value for two entities means that they have a large overlap between their one-hop neighbors. We predict entity alignment and compute the average OC values of the correctly-predicted alignment every epoch. <ref type="figure">Figure 5</ref> shows the value changes during the first 200 training epochs of AliNet and GCN. We find that the values display a decreasing trend. This indicates that it is relatively easy for GNN-based models to find the counterpart entities having a large proportion of common one-hop neighbors. The OC values of AliNet are smaller than those of GCN. This indicates that AliNet can effectively align the entities with smaller overlap in their one-hop neighbors.</p><p>Performance based on different layers In AliNet, we propose to use the combined representations of all layers as the final entity representations for predicting entity alignment.</p><p>Here, we further examine the performance based on layerspecific entity representations. We report the entity alignment results on DBP15K in <ref type="figure">Figure 6</ref> due to space limitation. The input layer is the randomly initialized feature vectors for entities to be tuned in AliNet. On top of this, we stack two AliNet layers (i.e., Layer 1 and Layer 2). "Combination" means the combined representations computed by Eq. (8). We can see that the representations of different layers show different performance of entity alignment. Layer 1 shows the best results among the three layers. As expected, the combined representations finally outperform the layer-specific representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>We hereby discuss related work to this paper. Particularly, as we have covered the majority of GNN-based entity alignment models in Section 2, we focus on discussing other families  <ref type="figure">Figure 6</ref>: Hits@1 results w.r.t. different layers on DBP15K.</p><p>of models here. Most other models, such as MTransE <ref type="bibr" target="#b4">(Chen et al. 2017)</ref>, IPTransE <ref type="bibr" target="#b38">(Zhu et al. 2017)</ref>, JAPE <ref type="bibr" target="#b26">(Sun, Hu, and Li 2017)</ref>, AlignE and BootEA , NAEA <ref type="bibr" target="#b39">(Zhu et al. 2019)</ref> as well as OTEA , use TransE <ref type="bibr" target="#b1">(Bordes et al. 2013)</ref> to learn entity embeddings. Meanwhile they learn a linear mapping or minimize the distance between the embeddings of pre-aligned entities. On top of KG structures, some work like KDCoE <ref type="bibr">(Chen et al. 2018)</ref>, AttrE <ref type="bibr" target="#b27">(Trisedya, Qi, and Zhang 2019)</ref> and MultiKE ), incorporates additional profile information of entities such as textual descriptions and literal names for KG embedding. Differently, AliNet exploits the basic graph structures without using additional information. To further improve entity alignment performance, IPTransE, BootEA, KDCoE and NAEA use semi-supervised learning. We also notice the recent work ) that uses GNNs for comparing the similarity of two graphs. Differently, we focus on the node-level rather than graphlevel similarity comparison. <ref type="bibr" target="#b12">(Kampffmeyer et al. 2019</ref>) captures the hierarchical structures of entities by introducing hypernym-hyponym links between nodes and their ancestors/descendants. Our work is also related to KG embedding that aims at learning vector representations for KG completion. There are translational models such as TransE <ref type="bibr" target="#b1">(Bordes et al. 2013)</ref>, TransH <ref type="bibr" target="#b30">(Wang et al. 2014)</ref> and TransR <ref type="bibr" target="#b16">(Lin et al. 2015)</ref>, bilinear models such as ComplEx <ref type="bibr" target="#b28">(Trouillon et al. 2016)</ref>, SimplE <ref type="bibr" target="#b13">(Kazemi and Poole 2018)</ref> and RotatE , and deep models such as ConvE <ref type="bibr" target="#b8">(Dettmers et al. 2018)</ref>, R-GCN <ref type="bibr" target="#b22">(Schlichtkrull et al. 2018)</ref> and RSN . We refer interested readers to the recent survey <ref type="bibr" target="#b17">(Lin et al. 2018)</ref> for more details on KG embedding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>In this paper, we propose AliNet for entity alignment, aiming at mitigating the non-isomorphism among the neighborhood structures of counterpart entities in an end-to-end manner. AliNet captures the neighborhood information within multiple hops by a gating mechanism in each layer. It employs an attention mechanism for multi-hop neighborhood aggregation to reduce noises. We further propose a relation loss to enhance the expressiveness of AliNet. Our experiments on five datasets demonstrate the effectiveness of AliNet. For future work, we plan to incorporate side information of entities in other modalities into the preserved graph structures.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Non-isomorphic relational neighborhood of Kobe Bryant in DBpedia (left) and Wikidata (right), respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Overview of the KG alignment network (AliNet) with gated two-hop neighborhood aggregation. cause a deleterious effect to correctly distinguishing between them. Instead, we use two matrices M linear transformations of the central entity and its neighbors, respectively. Formally, the attention weight c(l)    </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc><ref type="bibr" target="#b4">Chen et al. 2017</ref>), IPTransE<ref type="bibr" target="#b38">(Zhu et al. 2017)</ref>, JAPE<ref type="bibr" target="#b26">(Sun, Hu, and Li 2017)</ref>, AlignE, GCN-Align<ref type="bibr" target="#b31">(Wang et al. 2018)</ref>, SEA, RSN and MuGNN<ref type="bibr" target="#b2">(Cao et al. 2019)</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>H@1 H@10 MRR H@1 H@10 MRR AliNet (mix) 0.227 0.611 0.350 0.294 0.696 0.426 0.258 0.674 0.391 AliNet (add) 0.498 0.801 0.602 0.515 0.813 0.618 0.501 0.839 0.585 AliNet (gat) 0.517 0.803 0.618 0.531 0.810 0.632 0.523 0.845 0.636 AliNet 0.539 0.826 0.628 0.549 0.831 0.645 0.552 0.852 0.657</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Results on DBP15K w.r.t. the number of layers. multi-hop neighborhood information indeed contributes to entity alignment while the gating and attention mechanisms are crucial to capture important information in distant neighbors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Result comparison on entity alignment</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Results on DBP15K w.r.t. aggregation strategies</figDesc><table><row><cell>1.0</cell><cell cols="3">(a) DBP ZH-EN</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Hits@1</cell><cell></cell><cell></cell></row><row><cell>0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Hits@10</cell><cell></cell><cell></cell></row><row><cell>0.4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>MRR</cell><cell></cell><cell></cell></row><row><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>We can see that considering two-hop neighborhood leads to the best results. This is similarly attributed to the aforementioned reasons regarding aggregation of multi-hop neighbors. .790 0.559 0.507 0.805 0.618 0.508 0.808 0.628 AliNet 0.539 0.826 0.628 0.549 0.831 0.645 0.552 0.852 0.657 AliNet (k = 3) 0.461 0.786 0.571 0.484 0.802 0.590 0.450 0.813 0.575 AliNet (k = 4) 0.386 0.721 0.501 0.407 0.706 0.516 0.373 0.745 0.499</figDesc><table><row><cell>This is further verified by an analysis about DBP15K. For</cell></row><row><cell>example, in DBP ZH-EN , each Chinese entity has 6.6 one-hop</cell></row><row><cell>neighbors on average and this number for each English entity</cell></row><row><cell>is 8.6. However, between their one-hop neighbors, there are</cell></row><row><cell>only 4.5 pairs of counterpart entities, leaving 2.1 Chinese</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Results on DBP15K w.r.t. k values</figDesc><table><row><cell>0.80</cell><cell cols="2">AliNet</cell><cell>GCN</cell><cell>0.76</cell><cell cols="2">AliNet</cell><cell>GCN</cell><cell>0.73</cell><cell cols="2">AliNet</cell><cell>GCN</cell></row><row><cell>0.79</cell><cell></cell><cell></cell><cell></cell><cell>0.75</cell><cell></cell><cell></cell><cell></cell><cell>0.72</cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.78</cell><cell></cell><cell></cell><cell></cell><cell>0.74</cell><cell></cell><cell></cell><cell></cell><cell>0.71</cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.77</cell><cell></cell><cell></cell><cell></cell><cell>0.73</cell><cell></cell><cell></cell><cell></cell><cell>0.70</cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.76</cell><cell></cell><cell></cell><cell></cell><cell>0.72</cell><cell></cell><cell></cell><cell></cell><cell>0.69</cell><cell></cell><cell></cell><cell></cell></row><row><cell>0.75</cell><cell></cell><cell></cell><cell></cell><cell>0.71</cell><cell></cell><cell></cell><cell></cell><cell>0.68</cell><cell></cell><cell></cell><cell></cell></row><row><cell>0</cell><cell>50</cell><cell>100</cell><cell>150</cell><cell>0</cell><cell>50</cell><cell>100</cell><cell>150</cell><cell>0</cell><cell>50</cell><cell>100</cell><cell>150</cell></row><row><cell></cell><cell></cell><cell>DBPZH-EN</cell><cell></cell><cell></cell><cell></cell><cell>DBPJA-EN</cell><cell></cell><cell></cell><cell></cell><cell>DBPFR-EN</cell><cell></cell></row><row><cell cols="12">Figure 5: Average OC of one-hop neighbor sets of correct</cell></row><row><cell cols="12">alignment during the first 200 training epochs on DBP15K.</cell></row><row><cell cols="12">one-hop neighbors and 4.1 English ones unaligned. If consid-</cell></row><row><cell cols="12">ering two-hop neighbors, the numbers of unaligned one-hop</cell></row><row><cell cols="12">neighbors are reduced to 0.5 for Chinese and 0.9 for English,</cell></row><row><cell cols="12">respectively. The numbers have less room to be reduced by</cell></row><row><cell cols="12">introducing more distant neighbors. This suggests us that</cell></row><row><cell cols="12">aggregating two-hop neighborhood information is enough.</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/nju-websoft/AliNet</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Mixhop: Higher-order graph convolutional architectures via sparsified neighborhood mixing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Abu-El-Haija</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Alipourfard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Harutyunyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">V</forename><surname>Steeg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Galstyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="21" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multi-relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>García-Durán</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2787" to="2795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multi-channel graph neural network for entity alignment</title>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<biblScope unit="page" from="1452" to="1461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Multilingual knowledge graph embeddings for cross-lingual knowledge alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zaniolo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1511" to="1517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Skiena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zaniolo</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Co-training embeddings of knowledge graphs and entity descriptions for cross-lingual entity alignment</title>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<biblScope unit="page" from="3998" to="4004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Word translation without parallel data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Denoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jégou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Convolutional 2D knowledge graph embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dettmers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Minervini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1811" to="1818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In AISTATS</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="249" to="256" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning to exploit long-term relational dependencies in knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2505" to="2514" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Rethinking knowledge graph propagation for zero-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kampffmeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="11487" to="11496" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Simple embedding for link prediction in knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Kazemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Poole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4289" to="4300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Graph matching networks for learning the similarity of graph structured objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dullien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kohli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3835" to="3845" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning entity and relation embeddings for knowledge graph completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2181" to="2187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Knowledge representation learning: A quantitative review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<idno>abs/1812.10901</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Weisfeiler and leman go neural: Higher-order graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ritzert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Lenssen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Rattan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Grohe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4602" to="4609" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Semisupervised entity alignment via knowledge graph embedding with awareness of degree difference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hoehndorf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3130" to="3136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Improving cross-lingual entity alignment via optimal transport</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3231" to="3237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Knowledge graph identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pujara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Getoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISWC</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="542" to="557" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Modeling relational data with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bloem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ESWC</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="593" to="607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno>abs/1505.00387</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Bootstrapping entity alignment with knowledge graph embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4396" to="4402" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Rotate: Knowledge graph embedding by relational rotation in complex space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-H</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Cross-lingual entity alignment via joint attribute-preserving embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISWC</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="628" to="644" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Entity alignment between knowledge graphs using attribute embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">D</forename><surname>Trisedya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="297" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Complex embeddings for simple link prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Trouillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">É</forename><surname>Gaussier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bouchard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2071" to="2080" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Graph attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Velickovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Knowledge graph embedding by translating on hyperplanes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1112" to="1119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Crosslingual knowledge graph alignment via graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="349" to="357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A reduction of a graph to a canonical form and an algebra arising during this reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Weisfeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lehman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nauchno-Technicheskaya Informatsia</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="12" to="16" />
			<date type="published" when="1968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Relation-aware entity alignment for heterogeneous knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5278" to="5284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">How powerful are graph neural networks?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Cross-lingual knowledge graph alignment via graph matching neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3156" to="3161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A vectorized relational graph convolutional network for multirelational network alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4135" to="4141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Multi-view knowledge graph embedding for entity alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5429" to="5435" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Iterative entity alignment via joint knowledge embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4258" to="4264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Neighborhood-aware attentional representation for multilingual knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1943" to="1949" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
