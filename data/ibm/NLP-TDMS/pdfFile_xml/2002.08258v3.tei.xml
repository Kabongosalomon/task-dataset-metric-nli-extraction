<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Knapsack Pruning with Inner Distillation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-06-03">3 Jun 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonathan</forename><surname>Aflalo</surname></persName>
							<email>johnaflalo@gmail.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asaf</forename><surname>Noy</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Lin</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Itamar</forename><surname>Friedman</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alibaba</forename><surname>Damo</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Academy</forename><forename type="middle">Tel</forename><surname>Aviv</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Israel</forename><forename type="middle">Lihi</forename><surname>Zelnik</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Alibaba Damo Academy Tel Aviv</orgName>
								<address>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Alibaba Damo Academy Tel Aviv</orgName>
								<address>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Alibaba Damo Academy Tel Aviv</orgName>
								<address>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Knapsack Pruning with Inner Distillation</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-06-03">3 Jun 2020</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T18:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Neural network pruning reduces the computational cost of an over-parameterized network to improve its efficiency. Popular methods vary from ℓ 1 -norm sparsification to Neural Architecture Search (NAS). In this work, we propose a novel pruning method that optimizes the final accuracy of the pruned network and distills knowledge from the over-parameterized parent network's inner layers. To enable this approach, we formulate the network pruning as a Knapsack Problem which optimizes the trade-off between the importance of neurons and their associated computational cost. Then we prune the network channels while maintaining the high-level structure of the network. The pruned network is fine-tuned under the supervision of the parent network using its inner network knowledge, a technique we refer to as the Inner Knowledge Distillation. Our method leads to state-of-theart pruning results on ImageNet, CIFAR-10 and CIFAR-100 using ResNet backbones. To prune complex network structures such as convolutions with skip-links and depth-wise convolutions, we propose a block grouping approach to cope with these structures. Through this we produce compact architectures with the same FLOPs as EfficientNet-B0 and MobileNetV3 but with higher accuracy, by 1% and 0.3% respectively on ImageNet, and faster runtime on GPU. * Corresponding author Preprint. Under review.</p><p>In this paper we present a pruning approach that optimizes explicitly on the trade-off between accuracy and computational cost. Our first key idea is to formulate the pruning as a Knapsack Problem which enables the trade-off optimization. The second key idea is to introduce an Inner Knowledge Distillation (IKD) mechanism between the inner layers of the pruned and unpruned network. The IKD guides the child network to reproduce the inner layer's mapping patterns of the unpruned parent network as much as possible, leading to higher accuracy after fine-tuning.</p><p>The integration of the above two key ideas allows us to develop a novel method with strong empirical performance. Our method is a one-shot method, it is fast and does not require iterative re-training during pruning. The Knapsack formulation we suggest enables the pruning of non-sequential convolutions such as skip-connections and Squeeze-and-Excitation modules which are common in modern architectures, for example, ResNet and EfficientNet <ref type="bibr" target="#b42">[43]</ref>. We show that our method leads to stateof-the-art results on ImageNet, CIFAR-10 and CIFAR-100 when using ResNets and EfficientNets as backbones.</p><p>The structure of the paper is as follows: In Section 2, we briefly review previous works on pruning and knowledge distillation. In Section 3, we describe the technical aspects of our method to prune sequential convolutions or convolutions that are not connected to a skip-connection. In Section 4, we extend our method to more complicated architectures, that include skip-connections, dilated convolutions or Squeeze-and-Excitation modules which enforce constraints on the convolutional channels to be pruned. In Section 5, we describe our fine-tuning method with IKD. Finally, in Section 6, we present the results of our pruning method on different benchmarks and backbones.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Deep and wide networks such as VGG <ref type="bibr" target="#b39">[40]</ref>, ResNet <ref type="bibr" target="#b11">[12]</ref> and EfficientNet <ref type="bibr" target="#b42">[43]</ref> achieve high classification accuracy on challenging benchmarks such as ImageNet <ref type="bibr" target="#b3">[4]</ref>. While these architectures perform well, in many scenarios it is desired to reduce their computational cost and model size. One approach to achieve this goal is via network pruning which has been a topic of research for decades <ref type="bibr" target="#b25">[26]</ref>. Network pruning is a way to identify and remove the insignificant parameters of a network. These are the ones with little effect on the accuracy.</p><p>Previous pruning methods show promising results. However, they suffer from two key shortcomings. The first is the relying on a coarse approximation of the contribution of each weight on the final accuracy. For example, NetAdapt <ref type="bibr" target="#b50">[51]</ref> measures the post-factum empirical influence of several pruning options in order to choose the best one. The second is not leveraging the expressive power of the parent network. Knowledge Distillation (KD) <ref type="bibr" target="#b18">[19]</ref> from the unpruned network could improve performance as shown by <ref type="bibr" target="#b7">[8]</ref> who used KD on the network outputs to fine-tune the child network. Their approach, however, does not leverage the fact to the full extent that the inner structures of the unpruned and pruned networks are highly isomorphic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Works</head><p>In this section, we briefly review previous works on pruning and knowledge distillation that closely relate to our work.</p><p>Network Pruning Network pruning dates back to <ref type="bibr" target="#b25">[26]</ref> where the importance of a neuron is estimated by the diagonal elements of the Hessian matrix of the network's loss function. For modern neural networks estimating the Hessian matrix is prohibitive due to the high dimensionality. Therefore, inspired by the success of compressed sensing techniques <ref type="bibr" target="#b8">[9]</ref>, many ℓ 1 -norm sparsification methods and sparse proximal projection methods have been introduced to prune over-parameterized networks <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b30">31]</ref>. These methods require iterative pruning during training which makes them inapplicable to pre-trained networks.</p><p>Methods that perform post-training pruning over pre-trained neural networks are under active research recently <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b20">21]</ref>. Their key idea is to estimate the importance of a neuron via some heuristics. A comprehensive comparison of pruning heuristics is presented in <ref type="bibr" target="#b34">[35]</ref>, including Minimum ℓ 2 Weight, Activation, Mutual Information, Taylor Expansion, and Average Percentage of Zeros. They show that the best criterion is the Taylor Expansion which approximates the change in the loss function induced by the pruning.</p><p>More recently, <ref type="bibr" target="#b33">[34]</ref> demonstrated the high correlation between the importance approximation to a reliable estimate of the true importance of the neurons. However, their decision of removing N neurons with the smallest importance scores is rather heuristic and does not account for the induced change of FLOPs.</p><p>Knowledge Distillation Knowledge distillation refers to training a student network using a teacher network by distilling information from the teacher to the student. <ref type="bibr" target="#b18">[19]</ref> uses a penalty term consisting of the cross entropy between the output logits of the teacher and that of the student in the loss function. A few methods use knowledge distillation inside the network. For example, <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b46">47]</ref> consider the ℓ 2 distance between the teacher and the student feature maps as part of the loss. When the dimensions of the feature maps of the two networks differ, a popular method is to penalize the distance between the embeddings of the features maps in a subspace of lower dimension. For instance, <ref type="bibr" target="#b1">[2]</ref> computes the ℓ 2 distance between the squared sum of the teacher and the student feature maps while <ref type="bibr" target="#b44">[45]</ref> penalizes the distance between the activation correlation matrices. A distillation at the level of the feature maps has been already studied by previous works such as <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b17">18]</ref>, but the internal feature maps on which the distillation is performed are chosen arbitrarily.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Knapsack Problem</head><p>The knapsack problem is extensively used in a wide variety of fields including financial trading <ref type="bibr" target="#b31">[32]</ref>, cryptography <ref type="bibr" target="#b35">[36]</ref> and resource distribution <ref type="bibr" target="#b45">[46]</ref>. Recent works utilize deep neural networks for efficient and accurate optimization for solving the knapsack problem <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b32">33]</ref> To the best of our knowledge, this work is the first to utilize a Knapsack Problem to improve deep neural networks pruning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology to Prune Sequential Convolutions</head><p>In this section, we present our method for pruning sequential convolutions. This allows us to prune networks such as VGG as well as all the convolutions inside ResNet that are not preceding a skipconnection. Generalization to non-sequential operations such as skip-connections or integration of operations, is presented in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Knapsack Problem and Pruning</head><p>Suppose we have a knapsack with a capacity C and a collection of n items I where every item o i ∈ I has a weight f i and a value v i . The Knapsack Problem aims to fill the knapsack with maximal value, considering the weight capacity C. That is</p><formula xml:id="formula_0">max b i v i b i (1) s.t i f i b i ≤ C, b i ∈ {0, 1} 1 ≤ i ≤ n where the indicator variable b i equals 1 if o i is selected and 0 otherwise.</formula><p>The above formulation is an integer programming problem which is NP-hard. If the weights f i are integers, the problem has an exact solution that can be found with a Dynamic Programming algorithm in a O n max i f i time complexity. An approximate solution of the problem can also be found with a greedy approximation algorithm <ref type="bibr" target="#b2">[3]</ref> in O(n log(n)) time complexity. The method relaxes the original problem by replacing the constraint b i ∈ {0, 1} with 0 ≤ b i ≤ 1 . Then the approximated solution can be derived in a closed form.</p><p>We formulate the network pruning task as a approximate Knapsack problem. Given a network N with convolutional layers C l , 1 ≤ l ≤ L, we seek to prune its output channels with the least impact on the classification accuracy under a target FLOPs budget C. Denote by P N the space of pruned versions of N and by Acc the accuracy on a validation set X . We formulate the problem as follows:</p><formula xml:id="formula_1">max Npruned Acc(N pruned , X ) (2) s.t N pruned ∈ P N , FLOPs(N pruned ) ≤ C</formula><p>Optimizing the above problem is not straightforward as the accuracy Acc is not differentiable. Therefore, it is common to use an approximated formulation that minimize the cross-entropy loss to replace the Acc.</p><p>Yet, Eq. (2) remains costly to solve, therefore we next propose an additional approximation. Instead of maximizing the accuracy (minimizing the cross-entropy loss), we minimize the change of the loss due to zeroing-out the pruned network neurons. Correspondingly, we adjust the constraint of FLOPs to constrain the accumulated FLOPs that are associated with the selected weights. The space P N can be represented with a binary indicator vector b where b i ∈ {0, 1} indicates if the network's weight w i is zero or not. We denote by I(w i ) the change of the loss L CE (x, N pruned ) and by F (w i ) the saving of the FLOPs when setting b i to zero. Problem (2) can be now approximated as:</p><formula xml:id="formula_2">max b i b i I(w i )<label>(3)</label></formula><formula xml:id="formula_3">s.t i b i F (w i ) ≤ C, b i ∈ {0, 1} ∀i</formula><p>The above Eq. (3) is equivalent to the Knapsack Problem Eq. (1). We will now describe how we compute I(w i ) and F (w i ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3</head><p>The change of loss I(w i ) can be approximated by the first order Taylor Expansion of the loss function <ref type="bibr" target="#b34">[35]</ref>. Formally, given a function f : R n → R and a vector w ∈ R n = i w i e i where e i is the i-th canonical vector of R n filled with 0 everywhere except for the 1-th coordinate. Denotẽ w j = i =j w i e i a copy of the vector w with the j-th coordinate replaced by zero. We have</p><formula xml:id="formula_4">f (w j ) = f ( i =j w i e i ) ≈ f (w) − w j ∂f (w) ∂w j .</formula><p>Therefore the impact on the loss of zeroing the weight w o l of the o-th output channel of the l-th layer can be approximated by:</p><formula xml:id="formula_5">I(w o l ) ≈ −E x w o l T ∂L(x, w) ∂w o l<label>(4)</label></formula><p>where x is the input instances (images for example). The higher this value, the higher the impact of the weight on the total loss. Unfortunately, the above approximation may be too noisy since the expectation of the gradient is zero at the convergence point of the loss function. In <ref type="bibr" target="#b34">[35]</ref>, they show that the variance of the quantity</p><formula xml:id="formula_6">z o l = w o l T ∂L(x, w) ∂w o l</formula><p>is usually non-zero and correlates with the stability of the local function with respect to w o l proposing the following approximation instead:</p><formula xml:id="formula_7">I(w o l ) ≈ E x w o l T ∂L(x, w) ∂w o l .<label>(5)</label></formula><p>Empirically, we observe that using the below approximation leads to better performances:</p><formula xml:id="formula_8">I(w o l ) ≈ E x w o l T ∂L(x, w) ∂w o l .<label>(6)</label></formula><p>In practice, the expectation in Eq. (4) can be approximated by averaging over a validation set.</p><p>Last, we need a formula to calculate the saving of FLOPs F (w i ) after removing the network weight w o l . Up to now, we focus on the single weight. But in pruning we remove weights in groups. More particularly, we remove a group of weights that are used to compute a channel, such as a filter in a common convolutional layer. Given a convolution with C l i input channels of size H l ×W l and C l o output channels with kernel size k l ×k l and stride s l , its FLOPs is</p><formula xml:id="formula_9">C l o C l i H l W l (k l ) 2 /(s l ) 2 .</formula><p>Zeroing a group of weights related to w o l requires removing both an output channel from layer C l and an input channel from layer C l+1 . Therefore, the saving of FLOPs is given by</p><formula xml:id="formula_10">F (w o l ) = C l i H l W l (k l ) 2 (s l ) 2 + C l+1 o H l+1 W l+1 (k l+1 ) 2 (s l+1 ) 2 .<label>(7)</label></formula><p>Solving the Knapsack Problem (3) could be done via dynamic programming. The complexity of the dynamic programming is O(nF max ), and in our case,</p><formula xml:id="formula_11">F max = max i F (w o l )</formula><p>represents the maximum FLOPs required by a convolutional channel of the network, and can be computed with Eq. <ref type="bibr" target="#b6">(7)</ref>. In practice, we can reduce the computational complexity from</p><formula xml:id="formula_12">O(nF max ) to O nF max g , where g is the Greatest Common Divisor (GCD) of the set {F (w o l ) ∀1 ≤ l ≤ L}. Dividing both F (w o l )</formula><p>and C by g accelerates the convergence time without changing the solution. The total knapsack runtime is negligible in comparison to the network fine-tuning process discussed in Section 5. The details of the optimization procedure are described in Algorithm (1) in the supplementary. In addition, we can replace the FLOPS constraint by a running time constraint. In the supplementary material, we present the results of some networks trained with such a method, and show that our formulation allows to get time-pruned networks with the highest accuracy for a given inference time constraint.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Pruning Non-Sequential Convolutions</head><p>To date, most pruning methods are restricted to sequential connections as non-sequential connections are non trivial to prune.</p><p>We next suggest a method that allows pruning of non-sequential connections as part of the proposed knapsack framework. The key idea is to group operations that together directly form a channel or a group of channels in a feature map. For example all the convolutions whose outputs are connected through a summation, a multiplication or any inherent constraint like the one in separable convolution. In this setting, the channels of every group are pruned together, and the pruned network structure is consistent with the unpruned one.</p><p>To make this more clear we take as an example a cell called inverted residual as shown in <ref type="figure" target="#fig_0">Figure 1</ref> where we neglect activation functions for brevity. This cell appears in EfficientNet <ref type="bibr" target="#b42">[43]</ref>, MNASnet <ref type="bibr" target="#b41">[42]</ref> and MobileNet <ref type="bibr" target="#b19">[20]</ref>. This cell contains both Squeeze-and-Excitation components <ref type="bibr" target="#b21">[22]</ref> and dilated convolutions. There are three constraints on the inverted residual block. First, the output channels of the 'Point-wise linear projection' have to match the input of the current block because of the skipconnection. Second, the output channels of the 'Point-wise expansion' have to match the output channels of the 'Depth-wise convolution' since a Depth-wise convolution has a number of output channels that corresponds the the number of input channels. Lastly, the output channels of the 'Depth-wise convolution' have to match the output channels of the 'Squeeze-and-Excitation Expansion Convolution' because of the skip multiplication.</p><p>In order to prune this cell we build three groups of convolutions. The first includes the successive 'Point-wise linear projections' of the different blocks. The second includes the 'Point-wise expansions', the 'Depth-wise convolutions' and 'Squeeze-and-Excitation Expansion convolutions' of the same block. The third consists of the 'Squeeze-and-Excitation Reduction Convolutions'. As mentioned above, for each of these three groups we prune their associated channels together.</p><p>To the best of our knowledge, we are the first to suggest a pruning method that applies effectively to a non-sequential architecture such as EfficientNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Inner Knowledge Distillation and Fine-Tuning</head><p>After we get the architecture of the pruned network, we fine-tune its weights. Here we present a method that accelerates the process of fine-tuning by reducing the number of steps. For instance, in TAS <ref type="bibr" target="#b7">[8]</ref>, they require 236 GPU hours to search for the pruned version of ResNet-18 using NVIDIA Tesla V100 GPUs. Our method finds the pruned network in less that 0.1 GPU hours and requires 19 GPU hours using the same NVIDIA Tesla V100 GPUs to fine-tune the network. That is 12 times faster.</p><p>A common practice in fine-tuning is to incorporate a Knowledge Distillation term <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b43">44]</ref> in the loss function. This has proven to be very efficient and increases the final accuracy of a student network when using a high accuracy teacher network.</p><p>Denote by N Teacher , N Student , the teacher and student networks, and their respective output logits by F t out , F s out . Let SM(·) denote the softmax operator defined by SM(y) i = exp(y i ) j exp(y j )</p><p>. The KD enforces the output logits distributions of the teacher and student networks to be as similar as possible. This is achieved by adding Kullback-Leibler divergence in the loss function as</p><formula xml:id="formula_13">L KD = x,i − log (SM (F s out (x)) i ) SM F t out (x) i .<label>(8)</label></formula><p>We next suggest a further loss term that aims for similarity between N Teacher and N Student , not only between their output logits but also between their internal feature maps.</p><p>A distillation at the level of the feature maps between two different networks has been already studied by previous works such as <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b17">18]</ref>, but the internal feature maps on which the distillation is performed are chosen arbitrarily, since the teacher and student networks have different structures.</p><p>In the scope of pruning, we do not have this limitation since the teacher and student networks have the same exact structure up to the number of channels in every convolution. As far as we know, we are the first to use a feature maps distillation on pruning method. What allows us to perform such a distillation is the fact that our method is one-shot, meaning that we choose only once the channel to be pruned, unlike other iterative methods such as <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b7">8]</ref> where the choice of the weights to be pruned is constantly updated during the process.</p><p>Let F t l be the output feature map at the l-th layer of N Teacher with C t l channels. Similarly, the output feature map at the l-th layer of N Student is F s l with C s l channels. In our case, N Teacher and N Student have the same structure apart from their convolutional channel numbers. Hence we could transfer the knowledge inside the network at the level of the convolutional layers. Since the convolution before activation is a linear operator, we require the pruned network to reconstruct the original feature map. We call this the Inner Knowledge Distillation (IKD). Mathematically, we define the IKD loss term as</p><formula xml:id="formula_14">L KD = x l F t l (x, W t ) − M l F s l (x, W s ) 2 2<label>(9)</label></formula><p>where W l represents the weight matrix at layer l and M l is a (C t l × C s l ) matrix that aims to reconstruct the features maps F t l from F s l , and is added to the list of learnable variables in the fine-tuning process. To avoid degenerate solutions, we add a weight decay regularization term to M l , that behaves like a ridge regression regularizer.</p><p>The final loss used in the fine-tuning combines the original cross-entropy loss L CE , the Knowledge Distillation loss (8) and the Inner Knowledge Distillation loss <ref type="formula" target="#formula_14">(9)</ref>:</p><formula xml:id="formula_15">L = L CE + λ IKD L IKD + λ KD L KD<label>(10)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>In this section, we present empirical results of our pruning method on three different benchmarks: ImageNet <ref type="bibr" target="#b3">[4]</ref>, CIFAR-10 and CIFAR-100 <ref type="bibr" target="#b24">[25]</ref>. To show robustness to the architecture, we experiment with a variety of depths of ResNet <ref type="bibr" target="#b11">[12]</ref> as well as EfficientNet <ref type="bibr" target="#b42">[43]</ref>. We further present more experiments on ImageNet since this benchmark is more challenging than CIFAR, and is the standard benchmark for evaluating modern networks.</p><p>The experimental protocol is as follows: We first train a full-size baseline network on the selected dataset, next we prune it using our Knapsack formulation and last we apply fine-tuning with IKD for 50 epochs only, even though most of the other methods fine-tune for more than 100 epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">ImageNet</head><p>Comparison to other pruning methods To test our method on ImageNet, we used three versions of ResNet <ref type="bibr" target="#b11">[12]</ref>: ResNet-18, ResNet-50, and ResNet-101. <ref type="table" target="#tab_4">Table 3</ref> and <ref type="figure">Figure 2b</ref> compare our results for different pruning ratios with previous works. It can be seen that our results are consistently better than the state-of-the-art.</p><p>Comparison to common classification networks To further evaluate the benefits of our pruning approach we present in <ref type="figure">Figure 2a</ref> a comparison of the performance of our pruned networks with popular architectures: Inception <ref type="bibr" target="#b40">[41]</ref>, DenseNet <ref type="bibr" target="#b22">[23]</ref>, ResNext <ref type="bibr" target="#b49">[50]</ref> and Xception <ref type="bibr" target="#b0">[1]</ref>. We compare both Top-1 accuracy and computational cost (FLOPs). It can be seen that our pruned networks consistently provide higher accuracy than other networks, for a given number of FLOPs.</p><p>Ablation study Next, we present an ablation study, to assess the contribution of the various components of our approach. We took ResNet-50 as backbone and experimented with two variants: (i) With and without IKD, and (ii) our baseline training vs. PyTorch baseline. Results are presented in <ref type="table">Table 1</ref>. For a fair comparison with regard to the impact of our baseline, we take the original implementation of FPGM <ref type="bibr" target="#b15">[16]</ref> and prune our own baseline ResNet-50 instead of the original PyTorch one. Next, we prune ResNet-50 using the same baseline of 77.46% top-1 accuracy as TAS <ref type="bibr" target="#b7">[8]</ref>. In both cases, we can see that our method provides better results, no matter the baseline we start from as can be seen in <ref type="figure">Figure 2b</ref>.</p><p>IKD: When using IKD, we have more than 1% improvement than when not using KID, both for pruning 50% of ResNet-50 and pruning 41%. As could be expected, when using as baseline the low-   <ref type="table">Table 1</ref>: Ablation study of pruned ResNet-50 on ImageNet.</p><p>Baseline: To measure the impact of the baseline on our method, we choose to prune ResNet-50 with the official PyTorch <ref type="bibr" target="#b36">[37]</ref> pre-trained weights that leads to 76.15% Top-1 accuracy on ImageNet. This is the common evaluation scheme adopted by most works. Comparing our results in <ref type="table">Table 1</ref> with those of previous work in <ref type="table" target="#tab_4">Table 3</ref> shows that our method still provides the highest accuracy.</p><p>Knapsack: To assess the contribution of the Knapsack formulation, we have pruned 42.6% of ResNet-50 on ImageNet on the official Pytorch baseline using Molchanov's criterion only <ref type="bibr" target="#b33">[34]</ref>, without the Knapsack formulation and have obtained 75.26% accuracy, while the addition of the Knapsack formulation (without IKD) led to 76.17% accuracy, an improvement 0.91%. This result stands to demonstrate the importance of the Knapsack formulation, and that our results are not due to the fact that we use the Taylor Expansion criterion.   <ref type="figure">Fig. 2a</ref>, our pruning method consistently provides networks with superior accuracy than other networks with same FLOPS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Pruning the Non-Sequential EfficientNet</head><p>As described in Section 4, our approach can be applied also to prune architectures with nonsequential convolutions and skip-connections such as EfficientNet <ref type="bibr" target="#b42">[43]</ref>. To the best of our knowledge, this is the first attempt to prune these types of networks.</p><p>We experimented with 4 variants, comparing pruned EfficientNet B{n} with EfficientNet B{n − 1}, where n ∈ {1, 2, 3, 4}. For a fair comparison with the unpruned baselines, we followed the published EfficientNet training protocol without IKD. Results are presented in <ref type="table" target="#tab_2">Table 2</ref>. It can be observed that the pruned net-  works achieve higher accuracy than the baselines with the same number of FLOPs. An interesting observation is that despite having the same theoretical computational complexity, the pruned networks run faster than the unpruned ones. Furthermore, our pruned version of Effi-cientNet B0 led to a network with the same amount of FLOPs as MobileNetV3-large <ref type="bibr" target="#b19">[20]</ref> and a better accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">CIFAR</head><p>For the CIFARs datasets, we train ResNet-56 on CIFAR-10 and CIFAR-100 according to the same protocol used for ImageNet while changing the number of epochs to 300. Our top-1 accuracy baseline is 94.2% for CIFAR-10 and 73.55% for CIFAR-100. Results and comparisons to other works can be seen on the left of <ref type="table" target="#tab_6">Table 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper we have presented a new formulation and method for the pruning task, which enables us to simultaneously optimize over both accuracy and FLOPs measures, as well as distill knowledge from the unpruned network. This method has provided state-of-the-art empirical results on ImageNet and CIFAR datasets, which demonstrate the effectiveness of our proposed solution. We have observed that pruning a heavy deep network with our method can provide better accuracy than a shallower one with the same computational complexity (whether the latter was designed with a Network Architecture Search method or manually). These findings may suggest that the Network  In this section, we present results that we obtained by pruning a neural network superior to ResNet50. We choose to prune ECA-ResNet-D. This network has a backbone of ResNet, but we add two modifications. First, we change the stem cell as presented in <ref type="bibr" target="#b12">[13]</ref>. In addition, we add ECA modules, as suggested in <ref type="bibr" target="#b47">[48]</ref>. The obtained architecture performs better than classical ResNet, and thus, pruning this network is more interesting. We have pruned different versions of ECA-ResNet-D with our method using two criteria: Flops based pruning, as described in the paper, and Inferencetime based pruning. In this setting, we measure the inference time of every convolutional layer of the network, and apply our knapsack method where, instead of imposing a constraint on the total FLOPS of the pruned network, we impose a constraint on the final inference time. Most of the pruning method focus on reducing the total FLOPS of the pruned networks, but this measure does not often reflects the real inference time on a GPU, and networks with few flops such as EfficientNet <ref type="bibr" target="#b42">[43]</ref> runs with a lower throughput than heavier architecture such as ResNet. In the below  We can see how time-based pruning using our knapsack method provided extremely fast networks. For example, time-pruning of 57% of ECA-ResNet-101D provided a network with 80.86% accuracy while inferring at 1010 images per seconds on a P100 GPU. To the best of our knowledge, this is the fastest network of a NVIDIA P100 GPU to get an accuracy above 80% on ImageNet. The above networks and their checkpoints have been integrated on the famous Ross Wightman repository <ref type="bibr" target="#b48">[49]</ref>, and are available to the public.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Knapsack Pruning Algorithm</head><p>Algorithm 1 Knapsack Pruning input C, w i ∀i for all 0 ≤ i ≤ n do  </p><formula xml:id="formula_16">Compute I i ← I(w i ) Compute F i ← F (w i ) end for Compute G ← GCD(F i ) for all i do F i ← F i /G end for C ← C/G Initialize T ← 0-float array of size 2 × C Initialize K ← False-binary array of size n × C for all i do I curr ← I i , F curr ← F i i prev ← (i − 1)%2, i curr ← i%2 for all 0 ≤ f ≤ C do if f ≥ F i then v 1 ← I i + T [i prev ][f − F i ] else v 1 ← 0 end if v 2 ← T [i prev ][f ] if F i ≤ f</formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Inverted Residual Block with Squeezeand-Excitation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Comparison of deep pruned and shallower unpruned networks. Pruning ResNet-101 provides a network with less FLOPs and better accuracy than other networks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>8. 3 Figure 3 :</head><label>33</label><figDesc>Pruning ratio and pruned output channels for ResNet 50 Pruning ratio of output channels for ResNet 50 Pruning ratio and pruned output channels for ResNet 50</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>Comparison of pruned and original versions of EfficientNet. Inference speed (im- ages/second) is measured on GPU NVIDIA P100. Similar to our observation on ResNets in</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Comparison of different pruning algorithms for different ResNet backbones on ImageNet.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Comparison of different pruning algorithms for ResNet-56 on CIFAR.Architecture Search task should focus on finding inflated over-parametrized networks, while leaving the designing of efficient networks for the pruning and knowledge distillation methods.</figDesc><table><row><cell>8 Supplementary Material</cell></row><row><cell>8.1 Pruning of ECA-ResNet-D</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table /><note>Performance of FLOPS based and Time based pruning of ECA-ResNet on Imagenet Dataset 9</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>and v 2 ≤ v 1 then T [i curr ][f ] ← v 1</figDesc><table><row><cell>K[i][f ] ← True</cell></row><row><cell>else</cell></row><row><cell>T [i curr ][f ] ← v 2</cell></row><row><cell>end if</cell></row><row><cell>end for</cell></row><row><cell>end for</cell></row><row><cell>P ← []</cell></row><row><cell>for i from n to 0 decreasing by 1 do</cell></row><row><cell>if K[i][F ] is True then</cell></row><row><cell>P ← [P, i]</cell></row><row><cell>K ← K − F i−1</cell></row><row><cell>end if</cell></row><row><cell>end for</cell></row><row><cell>output P</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Xception: Deep learning with depthwise separable convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chollet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Honolulu, HI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-07-21" />
			<biblScope unit="page" from="1800" to="1807" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Moonshine: Distilling with cheap convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Crowley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Storkey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Discrete-variable extremum problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dantzig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operation Research</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="266" to="288" />
			<date type="published" when="1957-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">ImageNet: A Large-Scale Hierarchical Image Database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">09</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Approximated oracle filter pruning for destructive CNN width optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning, ICML 2019</title>
		<meeting>the 36th International Conference on Machine Learning, ICML 2019<address><addrLine>Long Beach, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-06-15" />
			<biblScope unit="page" from="1607" to="1616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Global sparse momentum sgd for pruning very deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6379" to="6391" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">More is less: A more complicated network with less inference complexity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5840" to="5848" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Network pruning via transformable architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Compressed sensing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on information theory</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1289" to="1306" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A pointer network based deep learning algorithm for 0-1 knapsack problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Tenth International Conference on Advanced Computational Intelligence (ICACI)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="473" to="477" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning both weights and connections for efficient neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dally</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1135" to="1143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Bag of tricks for image classification with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="558" to="567" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Soft filter pruning for accelerating deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Joint Conference on Artificial Intelligence, IJCAI&apos;18</title>
		<meeting>the 27th International Joint Conference on Artificial Intelligence, IJCAI&apos;18</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2234" to="2240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Amc: Automl for model compression and acceleration on mobile devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="815" to="832" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Filter pruning via geometric median for deep convolutional neural networks acceleration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Channel pruning for accelerating very deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<meeting><address><addrLine>Venice, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-10-22" />
			<biblScope unit="page" from="1398" to="1406" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A comprehensive overhaul of feature distillation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Heo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Deep Learning and Representation Learning Workshop</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.02244</idno>
		<title level="m">Searching for MobileNetV3. arXiv e-prints</title>
		<imprint>
			<date type="published" when="2019-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Network trimming: A data-driven neuron pruning approach towards efficient deep architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tang</surname></persName>
		</author>
		<idno>abs/1607.03250</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Squeeze-and-excitation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Honolulu, HI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-07-21" />
			<biblScope unit="page" from="2261" to="2269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Data-driven sparse structure selection for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">University of</title>
		<meeting><address><addrLine>Toronto, Toronto</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Optimal brain damage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Denker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Solla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="1989" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="598" to="605" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Blockwisely supervised neural architecture search with knowledge distillation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Pruning filters for efficient convnets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kadav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Durdanovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Samet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">P</forename><surname>Graf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04-24" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Foroosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Tappen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pensky</surname></persName>
		</author>
		<title level="m">Sparse convolutional neural networks. In CVPR</title>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="806" to="814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Improvement of pruning method for convolution neural network compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 2Nd International Conference on Deep Learning Technologies, ICDLT &apos;18</title>
		<meeting>the 2018 2Nd International Conference on Deep Learning Technologies, ICDLT &apos;18<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="57" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning efficient convolutional networks through network slimming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2736" to="2744" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">On the solution of discrete programming problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">M</forename><surname>Markowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Manne</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1957" />
			<publisher>Econometric Society</publisher>
			<biblScope unit="page" from="84" to="110" />
		</imprint>
	</monogr>
	<note>Econometrica: journal of the</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Application of neural network for the knapsack problem. online PDF</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Martini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Importance estimation for neural network pruning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Molchanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mallya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tyree</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Frosio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Pruning convolutional neural networks for resource efficient inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Molchanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tyree</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04-24" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">The rise and fall of knapsack cryptosystems. Cryptology and computational number theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Odlyzko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="75" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Wallach, H. Larochelle, A. Beygelzimer, F. d&apos;Alché-Buc, E. Fox, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Collaborative channel pruning for deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning</title>
		<editor>K. Chaudhuri and R. Salakhutdinov</editor>
		<meeting>the 36th International Conference on Machine Learning<address><addrLine>Long Beach, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-06" />
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="9" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Fitnets: Hints for thin deep nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Kahou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Montréal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">D</forename><surname>Montréal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Kahou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chassang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gatta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<publisher>ICLR</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Las Vegas, NV, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06-27" />
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Mnasnet: Platform-aware neural architecture search for mobile</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Rethinking model scaling for convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Efficientnet</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning</title>
		<editor>K. Chaudhuri and R. Salakhutdinov</editor>
		<meeting>the 36th International Conference on Machine Learning<address><addrLine>Long Beach, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-06" />
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="9" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Contrastive representation distillation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Similarity-preserving knowledge distillation. ArXiv, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Mori</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1907" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Resource allocation on computational grids using a utility model and the knapsack problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Vanderster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Dimopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Parra-Hernandez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Sobie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Future Generation computer systems</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="35" to="50" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Progressive blockwise knowledge distillation for neural network acceleration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Joint Conference on Artificial Intelligence, IJCAI&apos;18</title>
		<meeting>the 27th International Joint Conference on Artificial Intelligence, IJCAI&apos;18</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2769" to="2775" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Eca-net: Efficient channel attention for deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Hu</surname></persName>
		</author>
		<idno>abs/1910.03151</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">PyTorch image models repository</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wightman</surname></persName>
		</author>
		<ptr target="https://github.com/rwightman/pytorch-image-models" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Aggregated residual transformations for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Honolulu, HI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-07-21" />
			<biblScope unit="page" from="5987" to="5995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Netadapt: Platform-aware neural network adaptation for mobile applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Go</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2018 -15th European Conference</title>
		<meeting><address><addrLine>Munich, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="289" to="304" />
		</imprint>
	</monogr>
	<note>Proceedings, Part X</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Rethinking the smaller-norm-less-informative assumption in channel pruning of convolution layers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Network slimming by slimmable networks: Towards one-shot architecture search for channel numbers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>In arXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<title level="m">Slimmable neural networks. In International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Nisp: Pruning networks using neuron importance score propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-H</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Morariu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-Y.</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Davis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018-06" />
			<biblScope unit="page" from="9194" to="9203" />
		</imprint>
	</monogr>
	<note>In arXiv e-prints</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
