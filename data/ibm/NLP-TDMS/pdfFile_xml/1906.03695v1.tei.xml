<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Gendered Pronoun Resolution using BERT and an extractive question answering formulation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rakesh</forename><surname>Chada</surname></persName>
							<email>rakesh.chada@gmail.com</email>
							<affiliation key="aff0">
								<address>
									<settlement>Jersey City</settlement>
									<region>NJ</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Gendered Pronoun Resolution using BERT and an extractive question answering formulation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T06:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The resolution of ambiguous pronouns is a longstanding challenge in Natural Language Understanding. Recent studies have suggested gender bias among state-of-the-art coreference resolution systems. As an example, Google AI Language team recently released a genderbalanced dataset and showed that performance of these coreference resolvers is significantly limited on the dataset. In this paper, we propose 1 an extractive question answering (QA) formulation of pronoun resolution task that overcomes this limitation and shows much lower gender bias (0.99) on their dataset. This system uses fine-tuned representations from the pre-trained BERT model and outperforms the existing baseline by a significant margin (22.2% absolute improvement in F1 score) without using any hand-engineered features. This QA framework is equally performant even without the knowledge of the candidate antecedents of the pronoun. An ensemble of QA and BERT-based multiple choice and sequence classification models further improves the F1 (23.3% absolute improvement upon the baseline). This ensemble model was submitted to the shared task for the 1st ACL workshop on Gender Bias for Natural Language Processing. It ranked 9th on the final official leaderboard.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Coreference resolution is a task that aims to identify spans in a text that refer to the same entity. This is central to Natural Language Understanding. We focus on a specific aspect of the coreference resolution that caters to resolving ambiguous pronouns in English. Recent studies have shown that state-of-the-art coreference resolution systems exhibit gender bias <ref type="bibr" target="#b13">(Webster et al., 2018</ref>) <ref type="bibr" target="#b11">(Rudinger et al., 2018)</ref>  <ref type="bibr" target="#b16">(Zhao et al., 2018)</ref>. <ref type="bibr" target="#b13">(Webster et al., 2018)</ref> released a dataset that contained an equal number of male and female examples to encourage gender-fair modeling on the pronoun resolution task. A shared task for this dataset was then published on Kaggle 2 . The task involves classifying a specific ambiguous pronoun in a given Wikipedia passage as coreferring with one of the three classes: first candidate antecedent (hereby referred to as A), second candidate antecedent (hereby referred to as B) or neither of them (hereby referred to as N). The authors show that even the best of the baselines such as <ref type="bibr" target="#b0">(Clark and Manning, 2015)</ref>, <ref type="bibr" target="#b14">(Wiseman et al., 2016)</ref>, <ref type="bibr" target="#b4">(Lee et al., 2017)</ref> achieve an F1 score of just 66.9% on this dataset. The limited number of annotated labels available in this unbiased setting makes the modeling a challenging task. To that end, we propose an extractive question answering formulation of the task that leverages BERT <ref type="bibr" target="#b1">(Devlin et al., 2018)</ref> pre-trained representations and significantly improves (22.2% absolute improvement in F1 score) upon the best baseline <ref type="bibr" target="#b13">(Webster et al., 2018)</ref>. In this formulation, the task is similar to a SQUAD <ref type="bibr" target="#b10">(Rajpurkar et al., 2016)</ref> style question answering (QA) problem where the question is the context window (neighboring words) surrounding the pronoun to be resolved and the answer is the antecedent of the pronoun. The answer is contained in the provided Wikipedia passage. The intuition behind using the pronoun's context window as a question is that it allows the model to rightly identify the pronoun to be resolved as there can be multiple tokens that match the given pronoun in a passage. There has been previous work that cast the coreference resolution as a Question Answering problem <ref type="bibr" target="#b3">(Kumar et al., 2016)</ref>. But the questions used in their approach take the form "Who does "she" refer to?". This would necessitate including additional information such as an indicator vector to identify the exact pronoun to be resolved when there are multiple of them in a given passage. Furthermore, their approach doesn't impose that the answer should be contained within the passage or the question text. <ref type="bibr" target="#b6">(McCann et al., 2018</ref>) model the pronoun resolution task of the Winograd schema challenge <ref type="bibr" target="#b5">(Levesque et al., 2012)</ref> as a question answering problem by including the candidate antecedents as part of the question. An unique feature of the question answering framework (referred to as CorefQA) we propose is that it doesn't require the knowledge of the candidate antecedents in order to produce an answer for the pronoun resolution task. The model "learns", from training on the QA version of the shared task dataset, the specific task of extracting the appropriate antecedent of the pronoun given just the Wikipedia passage and the pronoun's context window. We also demonstrate other modeling variants for the shared task that use the knowledge of the candidate antecedents A and B. The first variant (CorefQAExt) is an extension of the CorefQA model that uses its predictions to produce probabilities over A, B and N. The second variant (CorefMulti) takes the formulation of a SWAG <ref type="bibr" target="#b15">(Zellers et al., 2018)</ref> style multiple choice classification and the final variant (CorefSeq) takes the standard sequence classification formulation. An ensemble of CorefQAExt, CorefMulti and CorefSeq models shows further performance gains (23.3% absolute improvement in F1 score).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Number of examples</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data</head><p>The dataset used for this shared task is the GAP dataset <ref type="bibr" target="#b13">(Webster et al., 2018)</ref> where each row contains a Wikipedia text snippet, the corresponding page's URL, the pronoun to be resolved, the two candidate antecedents (A and B) of the pronoun, the text offsets corresponding to A, B, pronoun and boolean flags indicating the pronoun's coref-erence with A and B. The Kaggle competition for this shared task was conducted in two stages. Table 1 shows the aggregate statistics for each stage. The 5-Fold Dev row represents the number of examples used for 5-fold stratified cross validation done based on the gender of the pronoun. This could lead to different distributions of A and B during the training of each fold. We chose to do so because we wanted to retain the perfect balance between male and female representations during training and thereby minimize the bias from the data. The columns T, A, B and N refer to the total number of examples, the number of examples where the pronoun's antecedent is A, B and neither respectively. We should note that for the question answering model, we exclude all the neither examples from the training data as we dont have an exact answer. While this seems destructive, the model doesn't need, by design, an explicit supervision on the "neither" examples to predict an antecedent that's neither A nor B. The male and female pronoun examples are equally represented (50-50 split) in the development, validation and test datasets -with the exception of stage 2 test dataset. The stage 2 test dataset has 377 male and 383 female examples. We use lowercased BERT word-piece tokenizer for preprocessing. This comes with a pre-built vocabulary of size 30522.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">System Description</head><p>The final model used for submission is an ensemble of the question answering (CorefQAExt), multiple choice (CorefMulti) and sequence classification (CorefSeq) models. We describe each of these models in the following sections. We chose the pytorch-pretrained-bert 3 library to implement all models. The source code is available at https: //github.com/rakeshchada/corefqa The question text Q is the pronoun context window of up to 5 words. The context window is the pronoun itself and its two neighboring words to the left and right. So, if W is "They say John and his wife Carol had a son", then Q would be "John and his wife Carol" assuming "his" is the pronoun to be resolved. In the case where there are less than two words on a given side, we just use the words available within the window -so these cases would lead to the window with less than 5 words. The text at this point is still un-tokenized so the "words" are just space separated tokens in a given text. The an-swer text is either A's or B's name ("neither" cases have been initially filtered). The rest of the architecture until the Span-wise Max Pooling layer follows the standard SQUAD formulation in <ref type="bibr" target="#b1">(Devlin et al., 2018)</ref>. It's worth noting that the architecture until this point (before the Span-wise Max Pooling layer) doesn't use candidate antecedents' A and B text or offset information. The output at this intermediate layer (Dense Layer) contains two sets of logits: start and end logits for each token. These can then be used to extract the maximum scoring span as an answer as demonstrated in <ref type="bibr" target="#b1">(Devlin et al., 2018)</ref>. We refer to the architecture until the Span-wise Max Pooling Layer as CorefQA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Probability Estimation</head><p>The shared task requires the output to be probabilities over the given A, B and N spans. So, we implement a mechanism that combines Span-wise Max Pooling and Logistic Regression to extract probabilities from start and end logits obtained in the previous step. Since we have access to offsets of A and B, we simply extract span logits corresponding to those offsets. Span logits are calculated by taking the maximum value of each of the individual token logits in a span. This gives us four values that represent maximum logits for the start and end of A and B spans. We also calculate maximum start and end logits over the entire sequence. These six logits are then fed as input features to a multi-class logistic regression. The output of this classifier then gives us the desired probabilities P A , P B &amp;P N . We refer to this endto-end architecture (from input layer to the Multiclass Logistic Regression layer) as CorefQAExt.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Training &amp; Hyperparameters</head><p>We use Adam optimizer with learning rate of 1e-5, β 1 =0.9, β 2 =0.999, L2 weight decay of 0.01, learning rate warmup over the first 10% of total training steps, and linear decay of the learning rate. The maximum sequence length is set to 300 and batch size of 12 is used during training. We use BERT Large Uncased pre-trained model for initializing the weights of BERT layers. This model has 24 layers with each producing a 1024 dimensional hidden representation. The whole system is trained in an end-to-end fashion. We fine-tune the last 12 BERT Encoder layers (layer 13 to layer 24) and freeze layers 1 to 12 -meaning the parameters of those layers aren't updated during training. This leads to total trainable parameters in the order of 150 million. We didn't use any dropout. The hyperparameter C for the logistic regression is set to 0.1. This model was trained for 2 epochs on a NVIDIA K80 GPU. The training with the 5-fold cross validation finished in about 30 minutes. The average of the predictions of each fold on the test dataset is used as the final prediction. We had experimented with different choices for each of these hyperparameters -such as freezing or unfreezing more layers, choosing different learning rates, different batch sizes -but these numbers gave us the best results. Another hyperparameter the model was sensitive to was the context window size. Lower window sizes gave us better results with 5 being the ideal size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Multiple Choice classification (CorefMulti)</head><p>Here, we formulate the task as a SWAG <ref type="bibr" target="#b15">(Zellers et al., 2018)</ref> style multiple choice problem among A, B and N classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Inputs and Architecture</head><p>For each example, we construct four input sequences, which each contain the concatenation of the the two sequences S1 and S2. S1 is a concatenation of the given Wikipedia passage with an additional sentence of the form "P is " where P is the text of the pronoun in question. So, for a passage that ends with the sentence "They say John and his wife Carol had a son", the sequence S1 would be "They say John and his wife Carol had a son. his is " assuming "his" is the pronoun to be resolved.</p><p>The sequence S2 is one of A's name, B's name or the word "neither" if the pronoun in the example doesn't co-refer with A and B. Once we represent the inputs in this fashion, the rest of the architecture follows the design of BERT based SWAG task architecture discussed in <ref type="bibr" target="#b1">(Devlin et al., 2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Training &amp; Hyperparameters</head><p>We use a batch size of 4 for training, initialize the BERT layers with the weights from the BERT Large Uncased pre-trained model and maintain the rest of the hyperparameters the same as the ones used for CorefQAExt model. Layers 12 to 24 of the BERT Encoder are fine-tuned and the rest of the layers are frozen. We use 5-fold cross validation with test prediction averaging from each fold. This model took about 100 minutes to run on Stage 1 data on a NVIDIA K80 GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Sequence classification (CorefSeq)</head><p>This involves framing the problem as a standard sequence classification task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Inputs and Architecture</head><p>The input is the given Wikipedia passage without any additional augmentation. The sequence features are extracted by concatenating token embeddings corresponding to the A, B and the pronoun spans. These span embeddings are calculated by concatenating token embeddings of the start token, end token and the result of an element-wise multiplication of start and end token embeddings. The token embeddings are the output of the last encoder layer of the (fine-tuned) BERT. These features are then fed to a single hidden layer feedforward neural network with a ReLU activation. This hidden layer has 512 hidden units. A softmax layer at the output then provides the desired A, B and N probabilities.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Training &amp; Hyperparameters</head><p>A dropout of 0.1 is applied before the inputs are fed from the BERT's last encoder layer to the feed forward neural network. The model is trained for 30 epochs with a batch size of 10. Layers 12 to 24 of the BERT Encoder are fine-tuned and the rest of the layers are frozen. A learning rate of 1e-5 is used with a triangular learning rate scheduler (Smith, 2017) whose steps per cycle is set to 100 times the length of training data. We use 5fold cross validation with test prediction averaging from each fold. This model took 105 minutes to run on Stage 1 data on a NVIDIA K80 GPU. ). The ensemble model had the best log loss in stage 2 even though the CorefQAExt model had the best Overall F1 score. This might be a reflection of the issues with probability calibration. Another explanation of this might be just the smaller stage 2 data size as compared to stage 1. Finally, although the CorefSeq model doesn't individually outperform other models, we get a better ensemble performance by including it rather than by excluding it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Freezing BERT weights</head><p>We tried freezing all BERT layer weights for some of our initial experiments but hadn't seen much success -especially when we used the weights from the last encoder layer of the BERT. The Stage 1 Overall F1 score for the CorefQAExt model dropped down significantly to 63.6% in this setting. This improved to 72.1% if we used layer 18 weights. We also tried concatenating the last four encoder layer outputs of BERT. This resulted in an slightly better Overall F1 score of 74.4% for Stage 1. So, the performance seemed to be sensitive to the choice of the encoder layer outputs. However, from the preliminary experiments, there seemed to be a big gap of about 15% on the Overall F1 when compared to the fine-tuned model. A more principled &amp; thorough analysis of this phenomena makes an important future area of work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Post Stage 2 deadline Results</head><p>After the competition had finished, we experimented with a few model variations on the final stage 2 test dataset that gave us interesting insights. Firstly, we tried excluding each model from the full ensemble. We noticed that we obtained a better Log Loss of 0.195 when we excluded CorefSeq. This model is listed as QAMul Ensemble in <ref type="table" target="#tab_3">Table 2</ref>. We carried another experiment where we trained the CorefQAExt using the cased version of the BERT model. An ensembling of the uncased version with this cased version delivered further performance gains (3% absolute F1 improvement upon uncased CorefQAExt). Then, we tried ensembling the cased and uncased versions of all the three individual models -Core-fQAExt, CorefMulti and CorefSeq on stage 2 test data. This resulted in an overall F1 score of 94.7% , Male F1 of 94.8%, Female F1 of 94.6%, bias of 1.0 and a log loss of 0.197.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Failed Experiments</head><p>1. We tried fine-tuning the BERT model in an unsupervised manner by training a language model on the texts extracted from the Wikipedia pages corresponding to the URLs provided in the dataset. The idea behind this one was to see if we can get better BERT layer representations by tuning them to the shared task's dataset. However, this is a computationally expensive step to run and we didn't see promising gains from initial runs. We hypothesize that this may be due to the fact that BERT representations were originally obtained by training on Wikipedia as one of the sources. So, fine-tuning on the task's dataset which is also from Wikipedia might not have added an extra signal.</p><p>2. For the CorefMulti model, we tried adding to the token embedding vector, an additional entity embedding vector that encodes the wordpiece token level info of whether it belongs to one of A, B or P. We hypothesized this should help the model focus its attention on the relevant entities to the coreference task.</p><p>But we weren't able to make a successful use of these embeddings to improve the model performance within the competition deadline. However, this is a promising future direction.</p><p>3. For the CorefQAExt model, we appended the title extracted from the provided wikipedia page's URL into the input token sequence to evaluate if the page URL provides useful signal to the model. This made the performance slightly worse.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We proposed an extractive question answering (QA) formulation of the pronoun resolution task that uses BERT fine-tuning and shows strong performance on the gender-balanced dataset. We have shown that this system can also effectively extract the antecedent of the pronoun without using the knowledge of candidate antecedents. We demonstrated three other formulations of the task that uses this knowledge. The ensemble of all these models obtained further gains <ref type="table" target="#tab_3">(Table  2</ref>). This work showed that the pre-trained BERT representations provide a strong signal for the coreference resolution task. Furthermore, thanks to training on the gender-balanced dataset, this modeling framework was able to generate unbiased predictions despite using pre-trained representations. An important future work would be to analyze the gains obtained from BERT representations in more detail and perhaps compare it with alternate contextual token representations and fine-tuning mechanisms <ref type="bibr" target="#b7">(Peters et al., 2018</ref>) <ref type="bibr" target="#b2">(Howard and Ruder, 2018)</ref>. We also would like to apply our techniques to the Winograd schema challenge <ref type="bibr" target="#b5">(Levesque et al., 2012)</ref>, the Definite Pronoun Resolution dataset <ref type="bibr" target="#b9">(Rahman and Ng, 2012)</ref>, the Winogender schema dataset <ref type="bibr" target="#b11">(Rudinger et al., 2018)</ref> and explore extensions to other languages perhaps using the CoNLL 2012 shared task dataset <ref type="bibr" target="#b8">(Pradhan et al., 2012)</ref>.</p><p>Context: "Alice (19), Kathleen Mary <ref type="formula">(12)</ref>, Gertrude (10) and Mabel <ref type="formula">(7)</ref> Context: "I would never write a book about the bad parts. I would mostly revel in the fantastic parts, of which there were so many." In early 2007, reports surfaced concerning Lindsay Lohan's interest in buying the rights to Nicks' life story and developing a motion picture in which she planned to play her." Question: "in which she planned to" Predicted Answer (Wrong): "Lindsay Lohan's interest in buying the rights to Nicks" InfoBox 4: CorefQA Prediction Sample 4. The model wrongly predicts a bigger span as an answer.</p><p>Context: "The president of SAG -future United States President Ronald Reagan -also known to the FBI as Confidential Informant "T-10", testified before the committee but never publicly named names. Instead, according to an FBI memorandum in 1947: "T-10 advised Special Agent (name deleted) that he has been made a member of a committee headed by Mayer, the purpose of which is allegedly is to 'purge' the motion-picture industry of Communist party members, which committee was an outgrowth of the Thomas committee hearings in Washington and subsequent meetings ...." Question: ") that he has been" Predicted Answer (Correct): "Special Agent" </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Stage 1 and Stage 2 Test Results. Bold indicates best performance.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>constraint wasn't explicitly encoded in its design.</cell></row><row><cell>The CorefQA model doesn't produce probabili-</cell></row><row><cell>ties over A, B and N classes as that information</cell></row><row><cell>isn't available to the model. Hence, we report</cell></row><row><cell>Log-loss as "N/A" in Table 2. The probabilities</cell></row><row><cell>from the CorefQAExt, CorefMulti and CorefSeq</cell></row><row><cell>are averaged to obtain the ensemble models prob-</cell></row><row><cell>abilities. This ensemble model, with an Overall F1</cell></row><row><cell>score of 90.2, improves upon the baseline by 23.3</cell></row><row><cell>percentage points. This model ranked ninth on</cell></row><row><cell>the final leaderboard of the Kaggle competition.</cell></row><row><cell>The CorefMulti model seemed most robust to bias</cell></row><row><cell>(0.99</cell></row><row><cell>shows the results of all models for Stage 1</cell></row><row><cell>and Stage 2. We calculate Log-Loss, Male F1, Fe-</cell></row><row><cell>male F1, Overall F1 score and Bias (Female F1</cell></row><row><cell>/ Male F1) as metrics on the test data sets. As</cell></row><row><cell>the results show, all individual models improve</cell></row><row><cell>upon the baseline model by a significant margin</cell></row><row><cell>with the CorefQAExt model showing the high-</cell></row><row><cell>est absolute improvement of 22.2%. It is inter-</cell></row><row><cell>esting to note that the CorefQA model 4 still im-</cell></row><row><cell>proved upon the baseline by 21.4% despite not us-</cell></row><row><cell>ing the knowledge of candidate antecedents A and</cell></row><row><cell>B. Infact, it slightly outperforms, on the Overall</cell></row><row><cell>Stage 1 F1 score, both CorefMulti and CorefSeq</cell></row><row><cell>models that explicitly encode the knowledge of A</cell></row><row><cell>and B. A few input/output samples of the Core-</cell></row><row><cell>fQA model are shown in the Supplemental Section</cell></row><row><cell>A. It is worth noticing that this model (correctly)</cell></row><row><cell>selects, most of the time, the spans correspond-</cell></row><row><cell>ing to named entities as answers even though that</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>. In the 1901 census Allen was living at Fox Lane in Leyland with his 2nd wife Margaret (Whittle), daughter of James Whittle, a coachman, &amp; Ann Mills, whom he had married in 1900. She was some 18 years his junior." Question: "1900. She was some"</figDesc><table><row><cell>Predicted Answer (Correct): "Margaret</cell></row><row><cell>(Whittle)"</cell></row><row><cell>InfoBox 1: CorefQA Prediction Sample 1</cell></row><row><cell>Context: "He then announced that CMU will</cell></row><row><cell>celebrate Pausch's impact on the world by</cell></row><row><cell>building and naming after Pausch a raised</cell></row><row><cell>pedestrian bridge to connect CMU's new</cell></row><row><cell>Computer Science building and the Center for</cell></row><row><cell>the Arts, symbolizing the way Pausch linked</cell></row><row><cell>those two disciplines. Brown University pro-</cell></row><row><cell>fessor Andries van Dam followed Pausch's last</cell></row><row><cell>lecture with a tearful and impassioned speech</cell></row><row><cell>praising him for his courage and leadership,</cell></row><row><cell>calling him a role model."</cell></row><row><cell>Question: "speech praising him for his"</cell></row><row><cell>Predicted Answer (Correct): "Pausch"</cell></row><row><cell>InfoBox 2: CorefQA Prediction Sample 2</cell></row><row><cell>Context: "Walter S. Sheffer (August 7, 1918 -</cell></row><row><cell>July 14, 2002) was an American photographer</cell></row><row><cell>and teacher, born in Youngsville, Pennsylva-</cell></row><row><cell>nia. He moved to Milwaukee, Wisconsin in</cell></row><row><cell>1945 to work at the studio of John Platz, Mil-</cell></row><row><cell>waukee's main society photographer. When</cell></row><row><cell>Platz retired, Sheffer inherited his clientele and</cell></row><row><cell>was able to establish his own "look" and very</cell></row><row><cell>successful portrait studio by 1953."</cell></row><row><cell>Question: "Sheffer inherited his clientele and"</cell></row><row><cell>Predicted Answer (Wrong): "Sheffer'</cell></row><row><cell>InfoBox 3: CorefQA Prediction Sample 3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Context: "Emily Thorn Vanderbilt(1852- 1946)  was a member of the prominent United States Vanderbilt family. The second daughter of William Henry Vanderbilt (1821-1885) and Maria Louisa Kissam (1821-1896), Emily Thorn Vanderbilt was named after her aunt, Emily Almira (Vanderbilt) Thorn, daughter of dynasty founder Cornelius Vanderbilt." Question: 'named after her aunt," Predicted Answer (Correct): "Emily Thorn Vanderbilt"</figDesc><table><row><cell>InfoBox 5: CorefQA Prediction Sample 5</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Source Code is available at https://github.com/ rakeshchada/corefqa</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://www.kaggle.com/c/ gendered-pronoun-resolution</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://github.com/huggingface/ pytorch-pretrained-BERT</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Sample predictions shown in the Supplemental Material Section A</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">InfoBox 6: CorefQA Prediction Sample 6</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the GeBNLP committee reviewers for comments on the work and thank Thomas Wolf, Prashant Jayannavar, Hema Priya Darshini, Aquila Khanam for helpful feedback on the draft. We also thank the Google AI Language team for the Kaggle competition and the team at Hugging Face Inc. for the "pytorch-pretrained-bert" library.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Supplemental Material</head><p>This section lists a few example input/outputs of the CorefQA model that predicts answers to the gendered pronoun resolution task using just the Context and the Question (without the knowledge of the candidate antecedents A and B).</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Entity-centric coreference resolution with model stacking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/P15-1136</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1405" to="1415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Universal language model fine-tuning for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="328" to="339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Ask me anything: Dynamic memory networks for natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankit</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>Irsoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Ondruska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romain</forename><surname>Paulus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 33rd International Conference on Machine Learning</title>
		<meeting>The 33rd International Conference on Machine Learning<address><addrLine>New York, New York, USA. PMLR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="1378" to="1387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">End-to-end neural coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-1018</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="188" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The winograd schema challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hector</forename><surname>Levesque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ernest</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leora</forename><surname>Morgenstern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirteenth International Conference on the Principles of Knowledge Representation and Reasoning</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The natural language decathlon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Shirish Keskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.08730</idno>
	</analytic>
	<monogr>
		<title level="m">Multitask learning as question answering</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Deep contextualized word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-1202</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2227" to="2237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Conll-2012 shared task: Modeling multilingual unrestricted coreference in ontonotes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sameer Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchen</forename><surname>Uryupina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint Conference on EMNLP and CoNLL-Shared Task</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Resolving complex cases of definite pronouns: the winograd schema challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Altaf</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="777" to="789" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Squad: 100, 000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-11-01" />
			<biblScope unit="page" from="2383" to="2392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Gender bias in coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachel</forename><surname>Rudinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Naradowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Leonard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Cyclical learning rates for training neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Leslie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Winter Conference on Applications of Computer Vision (WACV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="464" to="472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Mind the gap: A balanced corpus of gendered ambiguou</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kellie</forename><surname>Webster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><surname>Recasens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vera</forename><surname>Axelrod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions of the ACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>page to appear</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning global features for coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Wiseman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stuart</forename><forename type="middle">M</forename><surname>Shieber</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N16-1114</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="994" to="1004" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rowan</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.05326</idno>
		<title level="m">Swag: A large-scale adversarial dataset for grounded commonsense inference</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Gender bias in coreference resolution: Evaluation and debiasing methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jieyu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianlu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Yatskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vicente</forename><surname>Ordonez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-2003</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="15" to="20" />
		</imprint>
	</monogr>
	<note>Short Papers. Association for Computational Linguistics</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
