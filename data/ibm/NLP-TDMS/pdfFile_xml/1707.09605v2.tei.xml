<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CNN-based Cascaded Multi-task Learning of High-level Prior and Density Estimation for Crowd Counting</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishwanath</forename><forename type="middle">A</forename><surname>Sindagi</surname></persName>
							<email>vishwanath.sindagi@rutgers.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Rutgers University</orgName>
								<address>
									<addrLine>94 Brett Road</addrLine>
									<postCode>08854</postCode>
									<settlement>Piscataway</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishal</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
							<email>vishal.m.patel@rutgers.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Rutgers University</orgName>
								<address>
									<addrLine>94 Brett Road</addrLine>
									<postCode>08854</postCode>
									<settlement>Piscataway</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">CNN-based Cascaded Multi-task Learning of High-level Prior and Density Estimation for Crowd Counting</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Estimating crowd count in densely crowded scenes is an extremely challenging task due to non-uniform scale variations. In this paper, we propose a novel end-to-end cascaded network of CNNs to jointly learn crowd count classification and density map estimation. Classifying crowd count into various groups is tantamount to coarsely estimating the total count in the image thereby incorporating a high-level prior into the density estimation network. This enables the layers in the network to learn globally relevant discriminative features which aid in estimating highly refined density maps with lower count error. The joint training is performed in an end-to-end fashion. Extensive experiments on highly challenging publicly available datasets show that the proposed method achieves lower count error and better quality density maps as compared to the recent state-of-the-art methods. Furthermore, source code and pre-trained models are made available at</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Crowd analysis has gained a lot of interest in recent years due to it's variety of applications such as video surveillance, public safety design and traffic monitoring. Researchers have attempted to address various aspects of analyzing crowded scenes such as counting <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b9">10]</ref>, density estimation <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b1">2]</ref>, segmentation <ref type="bibr" target="#b10">[11]</ref>, behavior analysis <ref type="bibr" target="#b23">[24]</ref>, tracking <ref type="bibr" target="#b20">[21]</ref>, scene understanding <ref type="bibr" target="#b24">[25]</ref> and anomaly detection <ref type="bibr" target="#b18">[19]</ref>. In this paper, we specifically focus on the joint task of estimating crowd count and density map from a single image.</p><p>One of the many challenges faced by researchers working on crowd counting is the issue of large variations in scale and appearance of the objects that occurs due to severe perspective distortion of the scene. Many methods have been developed that incorporate scale information into (a) (b) (c) (d) <ref type="figure">Figure 1</ref>: Proposed method and results. (a) Cascaded architecture for learning high-level prior and density estimation. (b) Input image (from the ShanghaiTech dataset <ref type="bibr" target="#b31">[32]</ref>. (c) Ground truth density map. (d) Density map generated by the proposed method. the learning process using different methods. Some of the early methods relied on multi-source and hand-crafted representations and catered only to low density crowded scenes <ref type="bibr" target="#b9">[10]</ref>. These methods are rendered ineffective in high density crowds and the results are far from optimal. Inspired by the success of Convolutional Neural Networks (CNNs) for various computer vision tasks, many CNN-based methods have been developed to address the problem of crowd counting <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b30">31]</ref>. Considering scale issue as a limiting factor to achieve better accuracies, certain CNN-based methods specifically cater to the issue of scale changes via multicolumn or multi-resolution network <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b22">23]</ref>. Though these methods demonstrated robustness to scale changes, they are still restricted to the scales that are used during training and hence are limited in their capacity to learn wellgeneralized models.</p><p>The aim of this work is to learn models that cater to a wide variety of density levels present in the dataset by incorporating a high-level prior into the network. The high-level prior learns to classify the count into various groups whose class labels are based on the number of people present in the image. By exploiting count labels, the high-level prior is able to estimate coarse count of people in the entire image irrespective of scale variations thereby enabling the network to learn more discriminative global features. The high-level prior is jointly learned along with density map estimation using a cascade of CNN networks as shown in <ref type="figure">Fig. 1 (a)</ref>. The two tasks (crowd count classification and density estimation) share an initial set of convolutional layers which is followed by two parallel set of networks that learn highdimensional feature maps relevant to high-level prior and density estimation, respectively. The global features learned by the high-level prior are concatenated with the feature maps obtained from the second set of convolutional layers and further processed by a set of fractionally strided convolutional layers to produce high resolution density maps. Results of the proposed method on a sample input image are shown in <ref type="figure">Fig. 1</ref> (c)-(d).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Traditional approaches for crowd counting from single images relied on hand-crafted representations to extract low level features. These features were then mapped to count or density map using various regression techniques. Loy et al. <ref type="bibr" target="#b13">[14]</ref> categorized existing methods into (1) detectionbased methods (2) regression-based methods and (3) density estimation-based methods.</p><p>Detection-based methods typically employ sliding window-based detection algorithms to count the number of object instances in an image <ref type="bibr" target="#b25">[26]</ref>. These methods are adversely affected by the presence of high density crowd and background clutter. To overcome these issues, researchers attempted to count by regression where they learn a mapping between features extracted from local image patches to their counts <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b5">6]</ref>. Using a similar approach, Idrees et al. <ref type="bibr" target="#b9">[10]</ref> fused count from multiple sources. The authors also introduced an annotated dataset (UCF CC 50) of 50 images containing 64000 humans.</p><p>Detection and regression methods ignore key spatial information present in the images as they regress on the global count. Hence, in order to incorporate spatial information present in the images, Lempitsky et al. <ref type="bibr" target="#b11">[12]</ref> introduced a new approach of learning a linear mapping between local patch features and corresponding object density maps. Instead of a linear mapping, Pham et al. in <ref type="bibr" target="#b17">[18]</ref> proposed to learn a non-linear function using a random forest framework. Wang and Zou <ref type="bibr" target="#b28">[29]</ref> computed the relationship between image patches and their density maps in two distinct feature spaces. Recently, Xu and Qiu <ref type="bibr" target="#b29">[30]</ref> proposed to use much richer and extensive set of features for crowd density estimation. A more comprehensive survey of different crowd counting methods can be found in <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b12">13]</ref>.</p><p>More recently, due to the success of CNNs in various computer vision tasks, several CNN-based approaches have been developed for crowd counting <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16]</ref>. Walach et al. <ref type="bibr" target="#b26">[27]</ref> used CNNs with layered training approach. In contrast to the existing patch-based estimation methods, Shang et al. <ref type="bibr" target="#b22">[23]</ref> proposed an end-to-end estimation method using CNNs by simultaneously learning local and global count on the whole sized input images. Observing that the existing approaches cater to a single scale due to their fixed receptive fields, Zhang et al. <ref type="bibr" target="#b31">[32]</ref> proposed a multicolumn architecture to extract features at different scales. In addition, they also introduced a large scale annotated dataset (ShanghaiTech dataset). Onoro-Rubio and López-Sastre in <ref type="bibr" target="#b16">[17]</ref> addressed the scale issue by proposing a scale aware counting model called Hydra CNN. Boominathan et al. in <ref type="bibr" target="#b1">[2]</ref> proposed to tackle the issue of scale variation using a combination of shallow and deep networks along with an extensive data augmentation by sampling patches from multi-scale image representations.</p><p>Zhang et al. <ref type="bibr" target="#b31">[32]</ref> and Onoro et al. <ref type="bibr" target="#b16">[17]</ref> demonstrated that designing networks that are robust to scale variations is crucial for achieving better performance as compared to other CNN-based approaches. However, these methods rely on architectures that cater to selected set of scales thereby limiting their abilities to learn more generalized models. Additionally, the recent approaches individually regress either on crowd count or density map. Among the approaches that estimate density maps, the presence of pooling layers in the existing approaches reduce the resolution of the output density map prohibiting one to regress on full resolution density maps. This results in the loss of crucial details especially in images containing large variation in scales. Considering these drawbacks, we present a novel end-to-end cascaded CNN network that jointly learns a high-level global prior and density estimation. The high-level prior enables the network to learn globally relevant and discriminative features that aid in estimating density maps from images with large variations in scale and appearance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed method</head><p>Inspired by the success of cascaded convolutional networks for related multiple tasks <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b19">20]</ref>, we propose to learn two related sub-tasks: crowd count classification (which we call as high-level prior) and density map estimation in a cascaded fashion as shown in <ref type="figure" target="#fig_0">Fig. 2</ref>. The network takes an image of arbitrary size, and outputs crowd density map. The cascaded network has two stages corresponding to the two sub-tasks, with the first stage learning high-level prior and the second stage preforming density map estimation. Both stages share a set of convolutional features. The first stage consists of a set of convolutional layers and spatial pyramid pooling to handle arbitrarily sized images followed by a set of fully connected layers. The second stage consists of a set of convolutional layers followed by fractionally-strided convolutional layers for upsampling the previous layer's output to account for the loss of details due to earlier pooling layers. Two different set of loss layers are used at the end of the two stages, however, the loss of the second layer is dependent on the output of the earlier stage. The following sub-sections discuss the details of all the components of the proposed network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Shared convolutional layers</head><p>The initial shared network consists of 2 convolutional layers with a Parametric Rectified Linear Unit (PReLU) activation function after every layer. The first convolutional layer has 16 feature maps with a filter size of 9 × 9 and the second convolutional layer has 32 feature maps with a filter size of 7 × 7. The feature maps generated by this shallow network are shared by the two stages: high-level prior stage and density estimation stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">High-level prior stage</head><p>Classifying the crowd into several groups is an easier problem as compared to directly performing classification or regression for the whole count range which requires a larger amount of training data. Hence, we quantize the crowd count into ten groups and learn a crowd count group classifier which also performs the task of incorporating high-level prior into the network. The high-level prior stage takes feature maps from the previous shared convolutional layers. This stage consists of 4 convolutional layers with a PReLU activation function after every layer. The first two layers are followed by max pooling layers with a stride of 2. At the end, the high-level prior stage consists of three fully connected (FC) layers with a PReLU activation function after every layer. The first FC layer consists of 512 neurons whereas the second FC layer consists of 256 neurons. The final layer consists of a set of 10 neurons followed by a sigmoid layer, indicating the count class of the input image. To enable the use of arbitrarily sized images for training, Spatial Pyramid Pooling (SPP) <ref type="bibr" target="#b8">[9]</ref> is employed as it eliminates the fixed size constraint of deep networks which contain fully connected layers. The SPP layer is inserted after the last convolutional layer. The SPP layer aggregates features from the convolutional layers to produce fixed size outputs and can be fed to the fully connected layers. Cross-entropy error is used as the loss layer for this stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Density estimation</head><p>The feature maps obtained from the shared layers are processed by an another CNN network that consists of 4 convolutional layers with a PReLU activation function after every layer. The first two layers are followed by max pooling layers with a stride of 2, due to which the output of CNN layers is downsampled by a factor of 4. The first convolutional layer has 20 feature maps with a filter size of 7 × 7, the second convolutional layer has 40 feature maps with a filter size of 5 × 5, the third layer has 20 feature maps with a filter size of 5 × 5 and the fourth layer has 10 feature maps with a filter size of 5 × 5. The output of this network is combined with that of the last convolutional layer of high-level prior stage using a set of 2 convolutional and 2 fractionally strided convolutional layers. The first two convolutional layers have a filter size of 3 × 3 with 24 and 32 feature maps, respectively. These layers are followed by 2 sets of fractionally strided convolutional layers with 16 and 18 feature maps, respectively. In addition to integrating high-level prior from an earlier stage, the fractionally strided convolutions learn to upsample the feature maps to the original input size thereby restoring the details lost due to earlier max-pooling layers. The use of these layers results in upsampling of the CNN output by a factor of 4, thus enabling us to regress on full resolution density maps. Standard pixel-wise Euclidean loss is used as the loss layer for this stage. Note that this loss depends on intermediate output of the earlier cascade, thereby enforcing a causal relationship between count classification and density estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Objective function</head><p>The cross-entropy loss function for the high-level prior stage is defined as follows:</p><formula xml:id="formula_0">L c = − 1 N N i=1 M j=1 [(y i = j)F c (X i , Θ)],<label>(1)</label></formula><p>where N is number of training samples, Θ is a set of network parameters, X i is the i th training sample, F c (X i , Θ) is the classification output, y i is the ground truth class and M is the total number of classes.</p><p>The loss function for the density estimation stage is defined as:</p><formula xml:id="formula_1">L d = 1 N N i=1 F d (X i , C i , Θ) − D i 2 ,<label>(2)</label></formula><p>where F d (X i , C i , Θ) is the estimated density map, D i is the ground truth density map, and C i are the feature maps obtained from the last convolutional layer of the high-level prior stage.</p><p>The entire cascaded network is trained using the following unified loss function:</p><formula xml:id="formula_2">L = λL c + L d ,<label>(3)</label></formula><p>where λ is a weighting factor. This loss function is unlike traditional multi-task learning, because the loss term of the last stage depends on the output of the earlier one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Training and implementation details</head><p>In this section, details of the training procedure are discussed. To create the training dataset, patches of size 1/4 th the size of original image are cropped from 100 random locations. Other augmentation techniques like horizontal flipping and noise addition are used to create another 200 patches. The random cropping and augmentation resulted in a total of 300 patches per image in the training dataset. Note that the cropping is used only as a data augmentation technique and the resulting patches are of arbitrary sizes.</p><p>Several sophisticated methods are proposed in the literature for calculating the ground truth density map <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b31">32]</ref>. We use a simple method in order to ensure that the improvements achieved are due to the proposed method and are not dependent on the sophisticated methods for calculating the ground truth density maps. Ground truth density map D i corresponding to the i th training patch is calculated by summing a 2D Gaussian kernel centered at every person's location x g as defined below:</p><formula xml:id="formula_3">D i (x) = xg∈S N (x − x g , σ),<label>(4)</label></formula><p>where σ is the scale parameter of the 2D Gaussian kernel and S is the set of all points at which people are located.</p><p>The training and evaluation was performed on NVIDIA GTX TITAN-X GPU using Torch framework <ref type="bibr" target="#b6">[7]</ref>. λ was set to 0.0001 in <ref type="bibr" target="#b2">(3)</ref>. Adam optimization with a learning rate of 0.00001 and momentum of 0.9 was used to train the model. Additionally, for the classification (high-level prior) stage, to account for the imbalanced datasets, the losses for each class were weighted based on the number of samples available for that particular class. The training took approximately 6 hours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental results</head><p>In this section, we present the experimental details and evaluation results on two publicly available datasets: ShanghaiTech <ref type="bibr" target="#b31">[32]</ref> and UCF CROWD 50 <ref type="bibr" target="#b9">[10]</ref>. For the purpose of evaluation, the standard metrics used by many existing methods for crowd counting were used. These metrics are defined as follows:</p><formula xml:id="formula_4">M AE = 1 N N i=1 |y i − y i |, M SE = 1 N N i=1 |y i − y i | 2 ,</formula><p>where MAE is mean absolute error, MSE is mean squared error, N is number of test samples, y i is ground truth count and y i is estimated count corresponding to the i th sample.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">ShanghaiTech dataset</head><p>The ShanghaiTech dataset was introduced by Zhang et al. <ref type="bibr" target="#b31">[32]</ref> and it contains 1198 annotated images with a total of 330,165 people. This dataset consists of two parts: Part A with 482 images and Part B with 716 images. Both parts are further divided into training and test datasets with training set of Part A containing 300 images and that of Part B containing 400 images. Rest of the images are used as test set. The results of the proposed method are compared with two recent approaches: Zhang et al. <ref type="bibr" target="#b30">[31]</ref> and MCNN by Zhang et al. <ref type="bibr" target="#b31">[32]</ref> ( <ref type="table" target="#tab_0">Table 1</ref>). The authors in <ref type="bibr" target="#b30">[31]</ref> proposed a switchable learning function where they learned their network by alternatively training on two objective functions: crowd count and density estimation. In the other approach by Zhang et al. in <ref type="bibr" target="#b31">[32]</ref>, the authors proposed a multi-column convolutional network (MCNN) to address scale issues and a sophisticated ground truth density map generation technique. It can be observed from <ref type="table" target="#tab_0">Table 1</ref>, that the proposed method is able to achieve significant improvements without the use of multi-column networks or sophisticated ground truth map generation. Furthermore, to demonstrate the improvements obtained by incorporating high-level prior via cascaded architecture, we evaluated our network without the high-level prior stage (Single stage CNN) on Shang-haiTech dataset. It can be observed from <ref type="table" target="#tab_0">Table 1</ref>, that the cascaded learning of count classification and density estimation reduces the count error by a large margin as compared to the single stage CNN. <ref type="figure" target="#fig_1">Fig. 3</ref> illustrates the density map results obtained using the proposed method as compared to Zhang et al. <ref type="bibr" target="#b31">[32]</ref> and single stage CNN. It can be observed that in addition to achieving lower count error, the proposed method results in higher quality density maps due to the use of fractionally strided convolutional layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">UCF CC 50 dataset</head><p>The UCF CC 50 is an extremely challenging dataset introduced by Idrees et al.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>In this paper, we presented a multi-task cascaded CNN network for jointly learning crowd count classification and density map estimation. By learning to classify the crowd count into various groups, we are able to incorporate a highlevel prior into the network which enables it to learn globally relevant discriminative features thereby accounting for large count variations in the dataset. Additionally, we employed fractionally strided convolutional layers at the end so as to account for the loss of details due to max-pooling layers in the earlier stages there by allowing us to regress on full resolution density maps. The entire cascade was trained in an end-to-end fashion. Extensive experiments performed on challenging datasets and comparison with recent stateof-the-art approaches demonstrated the significant improvements achieved by the proposed method.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Overview of the proposed cascaded architecture for jointly learning high-level prior and density estimation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc><ref type="bibr" target="#b9">[10]</ref>. The dataset contains 50 Density estimation results using proposed method on ShanghaiTech dataset. (a) Input (b) Ground truth (c) Output.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Density estimation results using proposed method on UCF CC 50 dataset. (a) Input (b) Ground truth (c) Output.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Comparison results: Estimation errors on the ShanghaiTech dataset. The proposed method achieves lower error compared to existing approaches involving multi column CNNs and sophisticated density maps. -fold cross-validation was performed for evaluating the proposed method. The results are compared with five recent approaches: Idrees et al.<ref type="bibr" target="#b9">[10]</ref>, Zhang et al.<ref type="bibr" target="#b30">[31]</ref>, MCNN<ref type="bibr" target="#b31">[32]</ref>, Onoro et al.<ref type="bibr" target="#b16">[17]</ref> and Walach et al.<ref type="bibr" target="#b26">[27]</ref>. The authors in<ref type="bibr" target="#b9">[10]</ref> proposed to combine information from multiple sources such as head detections, Fourier analysis and texture features (SIFT). Onoro et al. in<ref type="bibr" target="#b16">[17]</ref> proposed a scale aware CNN to learn a multi-scale non-linear regression model using a pyramid of image patches extracted at multiple scales. Walach et al.<ref type="bibr" target="#b26">[27]</ref> proposed a layered approach of learning CNNs for crowd counting by iteratively adding CNNs where every new CNN is trained on residual error of the previous layer. It can be observed from Table 2 that our network achieves the lowest MAE and comparable MSE score. Density maps obtained using the proposed method on sample images from UCF CC 50 dataset are shown inFig. 4.</figDesc><table><row><cell></cell><cell>Part A</cell><cell cols="2">Part B</cell></row><row><cell>Method</cell><cell cols="3">MAE MSE MAE MSE</cell></row><row><cell>Zhang et al. [31]</cell><cell cols="2">181.8 277.7 32.0</cell><cell>49.8</cell></row><row><cell>MCNN [32]</cell><cell cols="2">110.2 173.2 26.4</cell><cell>41.3</cell></row><row><cell cols="3">Single stage CNN 130.4 190.9 29.3</cell><cell>40.5</cell></row><row><cell cols="3">Proposed method 101.3 152.4 20.0</cell><cell>31.1</cell></row><row><cell cols="4">annotated images of different resolutions and aspect ratios</cell></row><row><cell cols="4">crawled from the internet. There is a large variation in den-</cell></row><row><cell cols="4">sities across images. Following the standard protocol dis-</cell></row><row><cell>cussed in [10], a 5</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Comparison results: Estimation errors on the UCF CC 50 dataset. Walach et al. [27] 364.4 341.4 Proposed method 322.8 397.9</figDesc><table><row><cell>Method</cell><cell>MAE MSE</cell></row><row><cell>Idrees et al. [10]</cell><cell>419.5 541.6</cell></row><row><cell>Zhang et al. [31]</cell><cell>467.0 498.5</cell></row><row><cell>MCNN [32]</cell><cell>377.6 509.1</cell></row><row><cell>Onoro et al. [17]</cell><cell>465.7 371.8</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>This work was supported by US Office of Naval Research (ONR) Grant YIP N00014-16-1-3134.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Venkatesh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1507.08445</idno>
		<title level="m">People counting in high density crowds from still images</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Crowdnet: A deep convolutional network for dense crowd counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Boominathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Kruthiventi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">V</forename><surname>Babu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM on Multimedia Conference</title>
		<meeting>the 2016 ACM on Multimedia Conference</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="640" to="644" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Privacy preserving crowd monitoring: Counting people without people models or tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-S</forename><forename type="middle">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Counting people with lowlevel features and bayesian regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2160" to="2177" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A cascaded convolutional neural network for age estimation of unconstrained faces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ranjan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on BTAS</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Feature mining for localised crowd counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Torch7: A matlab-like environment for machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Farabet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BigLearn, NIPS Workshop, number EPFL-CONF-192376</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Instance-aware semantic segmentation via multi-task network cascades</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3150" to="3158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Spatial pyramid pooling in deep convolutional networks for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="346" to="361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multi-source multi-scale counting in extremely dense crowd images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Idrees</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Saleemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Seibert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2547" to="2554" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Fully convolutional neural networks for crowd segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1411.4464</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning to count objects in images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1324" to="1332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Crowded scene analysis: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Circuits and Systems for Video Technology</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="367" to="386" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Crowd counting and profiling: Methodology and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Modeling, Simulation and Visual Analysis of Crowds</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="347" to="382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Fully convolutional crowd counting on highly congested scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marsden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mcguinnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Little</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>O&amp;apos;connor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The International Conference on Computer Vision Theory and Applications</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Resnetcrowd: A residual deep learning architecture for crowd counting, violent behaviour detection and crowd density level classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marsden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mcguinness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Little</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">E</forename><surname>O&amp;apos;connor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.10698</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Towards perspective-free object counting with deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Onoro-Rubio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>López-Sastre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="615" to="629" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Count forest: Co-voting uncertain number of targets using random forest for crowd density estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V.-Q</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kozakaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Yamaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Okada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE ICCV</title>
		<meeting>the IEEE ICCV</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3253" to="3261" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Novel dataset for fine-grained abnormal behavior understanding in crowd</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rabiee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Haddadnia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mousavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kalantarzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Murino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on AVSS</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="95" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Hyperface: A deep multi-task learning framework for face detection, landmark localization, pose estimation, and gender recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ranjan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on PAMI</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Density-aware person detection and tracking in crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Audibert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE ICCV</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2423" to="2430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Crowd counting using multiple local features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ryan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Denman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fookes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sridharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Digital Image Computing: Techniques and Applications, 2009. DICTA&apos;09</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="81" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">End-to-end crowd counting via joint learning local and global count</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE ICIP</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1215" to="1219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Scene-independent group profiling in crowd</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2219" to="2226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deeply learned attributes for crowded scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE CVPR</title>
		<meeting>the IEEE CVPR</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4657" to="4666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Counting people by clustering person detector outputs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">S</forename><surname>Topkaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Erdogan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Porikli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on AVSS</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="313" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning to count with cnn boosting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Walach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="660" to="676" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Deep people counting in extremely dense crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM international conference on Multimedia</title>
		<meeting>the 23rd ACM international conference on Multimedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1299" to="1302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Fast visual object counting via example-based density estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE ICIP</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3653" to="3657" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Crowd density estimation based on rich features and random projection forest</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE WACV</title>
		<imprint>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2016" />
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Cross-scene crowd counting via deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE CVPR</title>
		<meeting>the IEEE CVPR</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="833" to="841" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Singleimage crowd counting via multi-column convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE CVPR</title>
		<meeting>the IEEE CVPR</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="589" to="597" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
