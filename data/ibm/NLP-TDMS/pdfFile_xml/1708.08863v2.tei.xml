<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Gradual Learning of Recurrent Neural Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2018-05-21">21 May 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziv</forename><surname>Aharoni</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="institution">Ben-Gurion University Beer-Sheva</orgName>
								<address>
									<postCode>8410501</postCode>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gal</forename><surname>Rattner</surname></persName>
							<email>rattner@post.bgu.ac.il</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Electrical Engineering Ben-Gurion University Beer-Sheva</orgName>
								<address>
									<postCode>8410501</postCode>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haim</forename><surname>Permuter</surname></persName>
							<email>haimp@bgu.ac.il</email>
							<affiliation key="aff2">
								<orgName type="department">Department of Electrical Engineering Ben-Gurion University Beer-Sheva</orgName>
								<address>
									<postCode>8410501</postCode>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Gradual Learning of Recurrent Neural Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2018-05-21">21 May 2018</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T06:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recurrent Neural Networks (RNNs) achieve state-of-the-art results in many sequence-to-sequence modeling tasks. However, RNNs are difficult to train and tend to suffer from overfitting. Motivated by the Data Processing Inequality (DPI), we formulate the multi-layered network as a Markov chain, introducing a training method that comprises training the network gradually and using layer-wise gradient clipping. We found that applying our methods, combined with previously introduced regularization and optimization methods, resulted in improvements in state-of-the-art architectures operating in language modeling tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Several forms of Recurrent Neural Network (RNN) architecture, such as <ref type="bibr">LSTM Hochreiter and Schmidhuber [1997]</ref> and <ref type="bibr">GRU Cho et al. [2014a]</ref>, have achieved state-of-theart results in many sequential classification tasks <ref type="bibr" target="#b4">Cho et al. [2014b]</ref>, <ref type="bibr" target="#b8">Ha et al. [2016]</ref>, <ref type="bibr" target="#b9">He et al. [2015]</ref>, <ref type="bibr" target="#b21">Smith et al. [2015]</ref>, <ref type="bibr" target="#b22">Sutskever et al. [2013]</ref>, <ref type="bibr" target="#b25">Zilly et al. [2016]</ref> during the past few years. The number of stacked RNN layers, i.e. the network depth, has key importance in extending the ability of the architecture to express more complex dynamic systems <ref type="bibr" target="#b1">Bianchini and Scarselli [2014]</ref>, <ref type="bibr" target="#b17">Montufar et al. [2014]</ref>. However, training deeper networks poses problems that are yet to be solved.</p><p>Training a deep RNN network to exploit its performance potential can be a very difficult task. One of the problems in training deep networks (not recurrent necessarily) is the degradation problem, as studied in <ref type="bibr" target="#b9">He et al. [2015]</ref>. Moreover, RNNs are exposed to exponential vanishing or exploding gradients through the Back-Propagation-Through-Time (BPTT) algorithm. Many studies have attempted to address those problems by regularizing the network <ref type="bibr" target="#b5">Cooijmans et al. [2016]</ref>, <ref type="bibr" target="#b7">Gal and Ghahramani [2016]</ref>, <ref type="bibr" target="#b24">Zaremba et al. [2014]</ref>, using different layer initialization methods <ref type="bibr" target="#b0">Bengio et al. [2007]</ref>, <ref type="bibr" target="#b11">Hinton et al. [2006]</ref>, or using shortcut connections between layers <ref type="bibr" target="#b9">He et al. [2015]</ref>, <ref type="bibr" target="#b21">Smith et al. [2015]</ref>, Zilly et al. <ref type="bibr">[2016]</ref>.</p><p>An additional problem in training a deep architecture is the covariate shift. Previous studies <ref type="bibr" target="#b5">Cooijmans et al. [2016]</ref>, <ref type="bibr" target="#b13">Ioffe and Szegedy [2015]</ref>, <ref type="bibr" target="#b20">Shimodaira [2000]</ref> have shown that the covariate shift has a negative effect on the training process among deep neural architectures. Covariate shift is the change in a layer's input distribution during training, also manifested as internal covariate shift, when a network internal layer input distribution is changed due to a shallower layer training process.</p><p>In this paper, we revisit the constructive/incremental approach that breaks the optimization process into several learning phases. Each learning phase includes training an increasingly deeper architecture than the previous ones. We show that given a specific architecture is capable of approximating a specific function/dynamic system, one can train it gradually to obtain the same performance. In this way, one can train the network gradually, reducing the deleterious effects of degradation and backpropagation problems. Additionally, we suggest that by adjusting the gradient clipping norms in a layerwise manner, we are able to improve the network performance even further by reducing the covariate shift.</p><p>In order to evaluate our method's performance, we conducted experiments over the word-level Penn Treebank (PTB) and the Wikitext-2 datasets, which are commonly used in evaluating language modeling tasks from the field of natural language processing. We demonstrated that combining the Gradual Learning (GL) method and layerwise regularization adjustments can significantly improve the results over the traditional training method of LSTM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Research</head><p>In the past years, the idea of incremental/constructive learning has been explored in many various previous works. <ref type="bibr" target="#b21">Smith et al. [2015]</ref> introduced the method of gradually adding layers to the network by a Dropin layer. <ref type="bibr" target="#b2">Chen et al. [2015]</ref> introduced a method for expanding a feedforward network using a function preserving transformation. <ref type="bibr" target="#b10">Hermans and Schrauwen [2013]</ref> studied training deep RNNs and their ability to process the data at multiple timescales. They proposed two configurations, one of which (DRNN-1O) comprises the same training scheme as that we present in our work. The main difference from the preceding works is that we do not intend to find the best incremental training scheme for training a RNN (or DNN). Instead, we seek to claim that using these methods could yield optimal models, and due to the difficulties of training deep networks, using these methods could yield improved results. <ref type="bibr" target="#b0">Bengio et al. [2007]</ref> proposed that a proper initialization of the network parameters by a layer-bylayer greedy unsupervised initialization process could recognize features in the input structure that would be valuable to the classifier at the network's output. This process is done by a reconstruction objective that encourages the network states to preserve all the information of the input. This constitutes the main difference from our method that seeks to preserve only the information of the inputs that is relevant for estimating the labels. <ref type="bibr" target="#b13">Ioffe and Szegedy [2015]</ref> and <ref type="bibr" target="#b5">Cooijmans et al. [2016]</ref> introduced and addressed the covariate shift problem in deep architectures, using batch normalization as a straightforward solution by fixing the layer activation distribution. While this method may be effective in overcoming the covariate shift phenomena and claimed to accelerate the training process, it poses restrictions such as large batch size. Our work approaches this issue from a different perspective and suggests a way to reduce the covariate shift by clipping the norm of the update step per layer while training the network gradually. Our proposed methods avoid the addition of excessive normalization layers and allow training using smaller batches, such that the training process is slower yet ends up with improved performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Notation</head><p>Let us represent a network with l layers as a mapping from an input sequence X ∈ X to an output sequenceŶ l ∈ Y byŶ</p><formula xml:id="formula_0">l = S l • f l • f l−1 • · · · • f 1 (X; Θ l ),<label>(1)</label></formula><p>where f 2 • f 1 represents the composition of f 2 over f 1 . The term Θ l = {θ 1 , . . . , θ l , θ S l } denotes the network parameters, such that θ k is the parameters of the k th layer, that is f k . The term θ S l denotes the parameters of the softmax mapping S l that is applied to a network with l layers. For convenience, we denote F l = f l • f l−1 • · · · • f 1 . We also define the l th layer state sequence by T l = F l (X; θ l ), where θ l = {θ 1 , . . . , θ l }, and we define the l th layer cost function by J(Θ l ) = cost(Ŷ l , Y ). Next, we define the gradient vector with respect to J(Θ) by g = ∂ ∂Θ J(Θ), and the gradient vector of the k th layer parameters with respect to J(Θ) by g k = ∂ ∂θ k J(Θ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Gradual Learning</head><p>In this section, we discuss a theoretical motivation that explains why a greedy training scheme is a reasonable approach for training a deep neural network. Then, we elaborate on the implementation of the method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Theoretical motivation</head><p>The structure of a neural network comprises a sequential processing scheme of its inputs. This structure constitutes the Markov chain</p><formula xml:id="formula_1">Y − X − T 1 − T 2 − · · · − T L .</formula><p>(2) This Markov chain has an elementary and well-known property that is used in our analysis, hence it is given without a proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Property 1 Given a Markov chain</head><formula xml:id="formula_2">A 1 − A 2 − · · · − A N , for any ordered triplet i, j, k ∈ {1, . . . , N }, such that i &lt; j &lt; k, the Markov chain A i − A j − A k holds.</formula><p>Hence, for every T l we can consider the Markov chain Y − X − T l that induces the conditional probabilities p(y|x) and p(y|t l ). Note that within the scope of training a neural network, p(y, x, t l ) can be factorized by</p><formula xml:id="formula_3">p(y, x, t l ) = p(y|x)p(x)q Θ l (t l |x),<label>(3)</label></formula><p>where the terms p(y|x), p(x) are induced entirely from the underlying distribution that generated the data, namely P X,Y . Yet, the term q Θ l (t|x) is determined by the network parameters. Hence, any modification of the joint distribution p(y, x, t l ) could be achieved only by modifying q Θ l (t|x).</p><p>In particular, this means that p(y|t l ) is also affected by the network through the term q Θ l (t|x), as shown below:</p><formula xml:id="formula_4">p(y|t l ) = p(y, t l ) p(t l ) = x p(x, y)q Θ l (t l |x) x ′ p(x ′ )q Θ l (t l |x ′ ) .<label>(4)</label></formula><p>Next, we estimate p(y|t l ) by the Maximum Likelihood Estimator (MLE) or, equivalently, by the negative log loss function. Given a training set of N examples S = {(x i , y i )} N i=1 drawn i.i.d from an unknown distribution P X,Y = P X P Y |X , we want to estimate P Y |TL by a L-layered neural network that is parameterized by Θ L . Let us denote the estimator by Q Θ Y |TL , where T L = F L (X). Thus, the MLE is given by</p><formula xml:id="formula_5">Θ * L = argmax Θ 1 N N i=1 log Q Θ Y |TL (y i |t L i ) (5) = argmin θ − 1 N N i=1 log Q Θ Y |TL (y i |t L i ) ,<label>(6)</label></formula><p>where t L i denotes F L (x i ). Next, we optimize the maximum likelihood criteria. The following theorem is well-known, but for completeness we present a proof which is helpful for understanding the subsequent arguments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 1 (MLE and minimal negative log-likelihood) Given a training set of</head><formula xml:id="formula_6">N examples S = {(x i , y i )} N i=1 drawn i.i.d from an unknown distribution P X,Y = P X P Y |X ,</formula><p>the MLE is given by P Y |X and the optimal value of the criteria is H(Y |X).</p><p>Proof By the law of large numbers, the maximum likelihood criteria in (6) converges to</p><formula xml:id="formula_7">− 1 N N i=1 log Q Θ Y |TL (y i |t L i ) N →∞ −→ E PX,Y − log Q Θ Y |TL (Y |T L ) (7) = E PX,Y − log P Y |X (Y |X) + E PX,Y log P Y |X (Y |X) Q Θ Y |TL (Y |T L ) (8) = H(Y |X) + D KL (P Y |X Q Θ Y |TL ),<label>(9)</label></formula><p>where, H(Y |X) denotes the conditional entropy of Y given X and D KL (P Y |X Q Θ Y |TL ) denotes the Kullback-Leibler (KL) divergence between P Y |X and Q Θ Y |TL . Due the non-negativity of the KL divergence, and since only Q Θ Y |TL depends on Θ, the negative log likelihood is minimized when</p><formula xml:id="formula_8">D KL (P Y |X Q Θ Y |TL ) = 0, which happens if and only if Q Θ Y |TL = P Y |X .</formula><p>Hence, the MLE is P Y |X and the optimal bound for the negative log-likelihood loss is H(Y |X).</p><p>Thus, under the optimality conditions of Theorem (1) we obtain that the estimate for p(y|t L ), that is Q Θ Y |TL , satisfies p(y|t L ) = p(y|x). We proceed by using the data processing inequality, which is is given as follows.</p><p>Theorem 2 (Data-processing inequality [Cover and <ref type="bibr" target="#b6">Thomas, 2012</ref>, section 2.8]) For X, Y, Z random variables, if the Markov relation X − Y − Z holds, then I(X; Y ) ≥ I(X; Z), where I(X; Y ) denotes the mutual-information between X and Y .</p><p>By the Data Processing Inequality (DPI) and Property (1), we can claim that for all l = 1, . . . , L the following statement hold</p><formula xml:id="formula_9">I(Y ; X) ≥ I(Y ; T l ).<label>(10)</label></formula><p>This means that by processing the inputs X, one cannot increase the information between X and Y .</p><p>Next, we show that under the conditions of Theorem (1), Equation <ref type="formula" target="#formula_0">(10)</ref> holds with equality.</p><p>Theorem 3 If Q Θ Y |TL satisfies the optimality conditions of Theorem <ref type="formula" target="#formula_0">(1)</ref>, then I(X; Y ) = I(T l ; Y ), ∀l = 1, . . . , L.</p><p>Proof By the Markov relation of the network (2) and Property (1) we can say that</p><formula xml:id="formula_10">Y − X − T L ,<label>(11)</label></formula><p>and hence, by definition, p(y|x, t L ) = p(y|x).</p><p>(12) By the optimatilty condition of Theorem (1) we can say that p(y|x) = p(y|t L ).</p><p>Combining <ref type="formula" target="#formula_0">(12)</ref> and <ref type="formula" target="#formula_0">(13)</ref> we get p(y|x, t L ) = p(y|t L ),</p><p>which shows by definition that the following Markov chain holds:</p><formula xml:id="formula_13">Y − T L − X.<label>(15)</label></formula><p>According to the Markov relations (11) and (15) the following hold:</p><formula xml:id="formula_14">p(y, t L |x) = p(y|x)p(t L |x) (16) p(y, x|t L ) = p(y|t L )p(x|t L ).<label>(17)</label></formula><p>Therefore, by definition, I(T L ; Y |X) = 0 and I(X; Y |T L ) = 0. Hence,</p><formula xml:id="formula_15">I(X, T L ; Y ) = I(X; Y ) + I(T L ; Y |X) (18) = I(T L ; Y ) + I(X; Y |T L ),<label>(19)</label></formula><p>where the equalities follow the chain rule for mutual information as given in [Cover and <ref type="bibr" target="#b6">Thomas, 2012</ref>, Section 2.5.2]. Thus we concluded that I(X; Y ) = I(T L ; Y ). According to the DPI we can claim directly that I(X; Y ) = I(T l ; Y ), ∀l = 1, . . . , L, as desired.</p><p>We showed that a necessary condition to achieve the MLE is that the network states, namely {T l } L l=1 , will satisfy I(Y ; X) = I(Y ; T l ). This means that an optimal model with L layers will satisfy that all the relevant information about Y within X must pass through every layer of the network, in particular layer 1. Due to the fact that shallow networks are easier to train, and since minimizing cross-entropy "drives" the network states to contain all the relevant information about Y (Theorem (3)), we propose a greedy training scheme. In this way we can overcome the difficulties of training a deep architecture and simultaneously assure that an optimal model could be achieved.</p><p>Comment 1 We cannot guarantee that after training a layer, say layer l 0 , the negative log likelihood is minimized, either because of the model limitation or because the optimization yielded a local minimum and not a global one. Hence, we cannot claim that we maximized the mutual information between Y and T l0 . But since this is a necessary condition to achieve the optimal condition of Theorem (1) (and not a sufficient condition), we assume that by the end of training, when the negative log-likelihood is small, I(Y ; T l0 ) is maximized (or relatively close to it). At phase 1 we optimize the parameters of layer 1 according to cost 1. At phase 2, we add layer 2 to the network, and then we optimize the parameters of layers 1,2, when layer 1 is copied from phase 1 and layer 2 is initialized randomly. At phase 3, we add layer 3 to the network, and then we optimize all of the network's parameters, when layers 1,2 are copied from phase 2 and layer 3 is initialized randomly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Implementation</head><p>Now, motivated by the conclusions of the preceding section, we propose to break up the optimization process into L phases, as the number of layers, optimizing J(Θ l ) sequentially as l increases from 1 to L. In each phase l, the network is optimized with respect toŶ l until convergence. Once the training of phase l is done, phase l + 1 is initiated with layers 1, . . . , l initialized with weights θ l learned in the previous phase, and θ l+1 is initialized randomly. Initialization of the softmax layer's weights θ S l+1 can be done either randomly or by inheritance of θ S l from the preceding training phase. An example for a training scheme is depicted in <ref type="figure" target="#fig_0">Figure 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Layer-wise Regularization Adjustments</head><p>Driven by the Markov chain realtion of the neural network and the DPI, we conclude that exploiting the training procedure at any of the training phases will be most beneficial. Adjusting hyperparameters for each training phase separately, such that it improves the minimization of the loss function is a necessary step to ensure the quality of our method implementation. However, adjusting the hyper-parameters might increase the robustness of the experiments and add variance to the experiments results as suggested in <ref type="bibr" target="#b15">Melis et al. [2017]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Layer-wise Gradient Clipping (LWGC)</head><p>Performing gradient clipping over the norm of the entire gradient vector g, as suggested in <ref type="bibr" target="#b18">Pascanu et al. [2013]</ref>, may cause a contraction of the relatively small elements in the gradient vector on each update step, due to presence of much larger gradient elements in the vector that are much more dominant in the squared elements sum of the global norm g . Due to this phenomenon, global gradient clipping, although proven to be useful and widely used in many architectures <ref type="bibr" target="#b16">Merity et al. [2017]</ref>, <ref type="bibr" target="#b23">Yang et al. [2017]</ref>, <ref type="bibr" target="#b24">Zaremba et al. [2014]</ref>, may have negative impact on the update step size for some weights elements in the network. Clipping the gradients of each layer separately will eliminate the influence of gradient contraction between the different layers of the network. Global gradient norm clipping of vector g is formulated asĝ := µ max(µ, g ) g, where µ is the fixed maximum gradient norm hyper-parameter. When training layers gradually, at the beginning of each training phase the randomly initialized newly added layer tends to have a significantly larger gradient norm compared to the shallower pretrained layers. Considering the differences in the layers' gradient norms, we suggest that treating each layer weights' gradient vector individually and clipping the gradients vector layerwise can reduce internal covariate shift significantly, as depicted in <ref type="figure" target="#fig_1">Figure 2</ref>. In our experiments, we clipped each layer's gradient separately, increasing the clipping norm as the layer is deeper in the network. Moreover, we used a strictly low gradient clipping norm on the encoder matrix to restrict the entire network's covariate shift during training.</p><p>The formulation of the LWGC method for a network with N layers is given by</p><formula xml:id="formula_16">ĝ T 1 , . . . ,ĝ T L T := µ 1 max(µ 1 , g 1 ) g T 1 , . . . , µ N max(µ N , g N ) g T N T ,<label>(20)</label></formula><p>where g i is the gradient vector w.r.t the weights of layer i, and µ i is a fixed maximum gradient hyper-parameter of layer i.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>We present results on two datasets from the field of natural language processing, the word-level Penn Tree-Bank (PTB) and Wikitext-2 (WT2). We conducted most of the experiments on the PTB dataset and used the best configuration (except for minor modifications) to evaluate the WT2 dataset.</p><p>Following previous work <ref type="bibr" target="#b15">Melis et al. [2017]</ref>, we established our experiments based on the pytorch implementation of <ref type="bibr" target="#b23">Yang et al. [2017]</ref>. We have added our methods (GL, LWGC) to the implementation, closely following the hyper-parameter settings, for fair comparison. This implementation includes variational dropout as proposed by <ref type="bibr" target="#b7">Gal and Ghahramani [2016]</ref>, Weight Tying (WT) method as proposed in <ref type="bibr" target="#b19">Press and Wolf [2016]</ref>, the regularization and optimization techniques as proposed in <ref type="bibr" target="#b16">Merity et al. [2017]</ref> and the mixture of softmaxes as proposed by <ref type="bibr" target="#b23">Yang et al. [2017]</ref>. Dynamic evaluation <ref type="bibr" target="#b14">Krause et al. [2017]</ref> was applied on the trained model to evaluate the performance of our model compared to previous state-of-the-art results.</p><p>We conducted two models in our experiments, a reference model and a GL-LWGC LSTM model that was used to check the performance of our methods. The reference model is 3 layered LSTM optimized and regularized with the properties described in <ref type="bibr" target="#b23">Yang et al. [2017]</ref> ‡ with a slight change in the form of enlarging the third layer from 620 to 960 cells, in order to even the total number of parameters. The model was trained for 1000 epochs until the validation score stopped improving. Our reference model failed to improve the previous results presented by <ref type="bibr" target="#b23">Yang et al. [2017]</ref>.  In our GL-LSTM model we applied the GL method with 3 training phases, at each we added a single layer of 960 cells and applied LWGC with an increasing maximum gradient norm at deeper layers. The LWGC max gradient norm for the LSTM and softmax layers was set in the range of 0.12-0.17, and for the embedding matrix a maximum gradient norm of 0.035-0.05 was set in order to lower the covariate shift along the training process. Other than that, regularization methods and hyper-parameter settings similar to those of the reference model were used. Our GL-LSTM model overcame the state-of-the-art results with only two layers and 19M parameters, and further improved the state-of-the-art results with the third layer phase. Results of the reference model and GL-LWGC LSTM model are shown in <ref type="table" target="#tab_0">Table 1</ref>.</p><p>Experiments on the WT2 database were conducted with the same parameters as were used with the PTB model except for enlarging the embedding size to 300 units and changing the LSTM hidden size to 1050 units. Results of the WT2 model are shown in <ref type="table" target="#tab_1">Table 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Ablation Analysis</head><p>In order to evaluate the benefit gained by each of our proposed methods, we measured the performance of our best-performing model removing one of the methods each time. Other than that, in order to provide a fair comparison with the previously suggested state-of-the-art methods Yang et al. ‡ https://github.com/zihangdai/mos <ref type="bibr">[2017]</ref> we evaluated a reference AWD-LSTM-MoS model with an enlarged third layer, to make the comparison with the same number of parameters as in our models.  <ref type="table" target="#tab_2">Table 3</ref>: Ablation analysis of the best-performing LSTM models over the Penn Treebank dataset. All models with 26M parameters.</p><p>Performance measurement of the GL ablated model, required setting the hyper-parameters ahead of initializing the training process. In this case we set the hyper-parameters as in the last phase of training of our best-performing GL-LWGC model, yet allowing a larger number of epochs to exploit the convergence. The ablated LWGC model was trained in three phases, each equivalent in length and hyper-parameter settings to the parallel phase in the best-performing GL-LWGC model, except for the global gradient norm clipping. While training the ablated LWGC model we set the maximum global gradient norm to be µ global,l = µ 2 L1,l + µ 2 L2,l + · · · + µ 2 LN ,l , where µ Li,l is the maximum gradient norm for element i in phase l using LWGC, and µ global,l is the maximum gradient norm for the non-LWGC case in phase l.</p><p>Each of the ablated GL and ablated LWGC models outperformed the previous state-of-the-art results, Yet combining both of the methods showed improved results. The ablation analysis shows that the LWGC method has a stronger impact on the final results, while the GL method reduces the effectiveness of premature fine-tuning. Applying fine-tuning on the ablated LWGC model was not effective.</p><p>We tested several hyper-parameters settings for our reference model, yet failed to improve the results presented by <ref type="bibr" target="#b23">Yang et al. [2017]</ref>. This result empowers our conclusions that the GL method decreases the degradation problem caused by increasing the depth or layer size of a model.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Depiction of our training scheme for a 3 layered network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Depiction of the covariate shift reduction at the initial stage of the training process, offering a comparison of the histograms of the third layer activations during the first 500 updates on training. Figure (a) shows the histogram of an AWD-MoS-LSTM network on traditional training. Figure (b) shows the histogram of the AWD-MoS-LSTM network trained using GL-LWGC.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Single model test perplexity of the PTB dataset</figDesc><table><row><cell>Model</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Single model perplexity of the WikiText-2 dataset Yang et al. [2017] AWD-LSTM-MoS + dynamic evaluation † 35M 42.41 40.68 Ours -GL-LWGC-AWD-MoS-LSTM + dynamic evaluation † 38M 42.19 40.46</figDesc><table><row><cell>Model</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3</head><label>3</label><figDesc>shows validation and test results for the ablated models.</figDesc><table><row><cell>PTB</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">† Marking dynamic eval methods that update the model while evaluating, to distinguish from static evaluation models.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusions</head><p>We presented an effective technique to train RNNs. GL increases the network depth gradually as training progresses, and LWGC adjusts a gradient clipping norm in a layerwise manner at every learning phase of the training. Our techniques are implemented easily and do not involve increasing the amount of parameters of a network. We demonstrated the effectiveness of our techniques on the PTB and WikiText-2 datasets. We believe that our techniques would be useful for additional neural network architectures, such as GRUs and stacked RHNs, and in additional settings, such as in reinforcement learning.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Greedy layer-wise training of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Popovici</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 19</title>
		<editor>P. B. Schölkopf, J. C. Platt, and T. Hoffman</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="153" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">On the complexity of neural network classifiers: A comparison between shallow and deep architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Monica</forename><surname>Bianchini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franco</forename><surname>Scarselli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Net2net: Accelerating learning via knowledge transfer. CoRR, abs/1511.05641</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1511.05641" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">On the properties of neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1259</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">Encoder-decoder approaches. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno>arXiv:1406.107</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Cooijmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C?sar</forename><surname>Laurent</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.09025</idno>
		<title level="m">aglar G?l?ehre, and Aaron Courville. Recurrent batch normalization</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Elements of information theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joy A</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Thomas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A theoretically grounded application of dropout in recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1019" to="1027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hypernetworks</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.09106</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.03385</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Training and analysing deep recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michiel</forename><surname>Hermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Schrauwen</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/5166-training-and-analysing-deep-recurrent-neural-networks.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="190" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A fast learning algorithm for deep belief nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee-Whye</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1527" to="1554" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03167</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Dynamic evaluation of neural sequence models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emmanuel</forename><surname>Kahembwe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iain</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Renals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.07432</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">On the state of the art of evaluation in neural language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gábor</forename><surname>Melis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.05589</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Regularizing and Optimizing LSTM Language Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Merity</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shirish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Keskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Socher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017-08" />
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guido</forename><surname>Montufar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1402.1869</idno>
		<title level="m">On the number of linear regions of deep neural networks</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">On the difficulty of training recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1310" to="1318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Using the output embedding to improve language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ofir</forename><surname>Press</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lior</forename><surname>Wolf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.05859</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Improving predictive inference under covariate shift by weighting the log-likelihood function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hidetoshi</forename><surname>Shimodaira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of statistical planning and inference</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="227" to="244" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Gradual dropin of layers to train very deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leslie</forename><forename type="middle">N</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><forename type="middle">M</forename><surname>Hand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Doster</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06951</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">On the importance of initialization and momentum in deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<idno>III-1139-III-1147. JMLR.org</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference on International Conference on Machine Learning</title>
		<meeting>the 30th International Conference on International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">28</biblScope>
		</imprint>
	</monogr>
	<note>ICML&apos;13</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.03953</idno>
		<title level="m">Breaking the softmax bottleneck: a high-rank rnn language model</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.2329</idno>
		<title level="m">Ilya Sutskever, and Oriol Vinyals. Recurrent neural network regularization</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Georg Zilly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rupesh</forename><forename type="middle">Kumar</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Koutn?k</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.03474</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Recurrent highway networks</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01578</idno>
		<title level="m">Neural architecture search with reinforcement learning</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
