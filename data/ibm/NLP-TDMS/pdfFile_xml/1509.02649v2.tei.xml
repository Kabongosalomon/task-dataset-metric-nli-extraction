<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Shape Interaction Matrix Revisited and Robustified: Efficient Subspace Clustering with Corrupted and Incomplete Data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pan</forename><surname>Ji</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Australian National University</orgName>
								<address>
									<settlement>Canberra</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Salzmann</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">CVLab</orgName>
								<orgName type="institution">EPFL</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">NICTA</orgName>
								<address>
									<settlement>Canberra</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongdong</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Australian National University</orgName>
								<address>
									<settlement>Canberra</settlement>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="laboratory">ARC Centre of Excellence for Robotic Vision (ACRV)</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Shape Interaction Matrix Revisited and Robustified: Efficient Subspace Clustering with Corrupted and Incomplete Data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The Shape Interaction Matrix (SIM) is one of the earliest approaches to performing subspace clustering (i.e., separating points drawn from a union of subspaces). In this paper, we revisit the SIM and reveal its connections to several recent subspace clustering methods. Our analysis lets us derive a simple, yet effective algorithm to robustify the SIM and make it applicable to realistic scenarios where the data is corrupted by noise. We justify our method by intuitive examples and the matrix perturbation theory. We then show how this approach can be extended to handle missing data, thus yielding an efficient and general subspace clustering algorithm. We demonstrate the benefits of our approach over state-of-the-art subspace clustering methods on several challenging motion segmentation and face clustering problems, where the data includes corrupted and missing measurements.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In this paper, we tackle the problem of subspace clustering, which consists of finding the subspace memberships of points drawn from a union of subspaces. This problem has attracted a lot of attention in the community due to its applicability to many different tasks, such as motion segmentation and face clustering.</p><p>Most of the research in this area takes its roots in the pioneering work of Costeira and Kanade <ref type="bibr" target="#b4">[5]</ref>, which introduced the Shape Interaction Matrix (SIM) to solve the motion segmentation problem, i.e., the problem of clustering point trajectories into the motions of multiple rigid objects. More specifically, the SIM was defined as the orthogonal projection matrix onto the row space of the trajectory matrix, and was proven to directly encode the motion membership of each trajectory. This result was later shown to extend to the general problem of subspace clustering <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref>.</p><p>While the SIM provably yields perfect clusters given (a) (b) (c) <ref type="figure" target="#fig_0">Figure 1</ref>: Subspace clustering example: (a) Two motions, each forming one subspace; (b) Shape Interaction Matrix of the trajectories in (a), which is sensitive to noise; (c) Affinity matrix obtained by our method: a much clearer block-diagonal structure.</p><p>ideal measurements from independent subspaces, the quality of the clusters quickly degrades in the presence of noise, as illustrated by <ref type="figure" target="#fig_0">Fig. 1</ref>. As a consequence, many algorithms have been proposed to improve the robustness of subspace clustering. However, these methods typically work either by using discriminant criteria to reduce the effects of noise <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b33">34]</ref>, which may be sensitive to the noise level, or by formulating subspace clustering as a regularized optimization problem <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21]</ref>, thus requiring to tune the regularization weight to the data at hand. Furthermore, little work has been done to address the missing data scenario, for which, to the best of our knowledge, expensive two-steps methods (i.e., data completion followed by clustering) are typically employed <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b31">32]</ref>.</p><p>In this paper, we revisit the use of the SIM for subspace clustering and study its connections to several recent algorithms. Based on our analysis, we show that simple, yet effective modifications of the SIM can significantly improve its robustness to data corruptions. This, in turn, lets us introduce an efficient approach to handling missing data, whose presence is inevitable in real-world scenarios.</p><p>We demonstrate the effectiveness of our algorithms on motion segmentation and face clustering in different scenarios, including the presence of noise, outliers and missing data. Our experiments evidence the benefits of our approach  <ref type="figure" target="#fig_3">Figure 2</ref>: SIM for clustering two lines in 3D: (a) Two lines (each forming one subspace) with an arbitrary angle; (b) New data representation with V r . Note that the lines have become orthogonal; (c) SIM (absolute value) normalized by its maximum value; the darker the SIM image, the greater the value. over existing methods in all these scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">SIM Revisited: Review and Analysis</head><p>The Shape Interaction Matrix (SIM) was originally introduced by Costeira and Kanade <ref type="bibr" target="#b4">[5]</ref> to extend Tomasi and Kanade's groundbreaking work <ref type="bibr" target="#b28">[29]</ref> on factorization-based structure-from-motion from a single motion to the multibody case. In the single-motion scenario, the trajectory matrix X ∈ R 2F ×N (for N points in F frames) can be factorized into the product of a motion matrix M ∈ R 2F ×4 and a shape matrix S ∈ R 4×N with metric (rotation and translation) constraints. However, for multi-body motions, the metric constraints no longer directly apply, but require the knowledge of the membership of each point to each motion.</p><p>In their work <ref type="bibr" target="#b4">[5]</ref>, Costeira and Kanade showed that these motion memberships could be obtained from the data itself. To this end, they introduced the SIM, defined as</p><formula xml:id="formula_0">Q = V r V T r ,<label>(1)</label></formula><p>where V r ∈ R N ×r is the matrix containing the first r right singular vectors of X, with r = 4K in the case of K non-degenerate motions. Mathematically, the SIM is the orthogonal projection matrix onto the column space of V r , or, equivalently, onto the row space of X. Importantly, it can be shown that Q ij = 0 if points i and j belong to different motions, and Q ij = 0 if points i and j belong to the same motion. Therefore, in <ref type="bibr" target="#b4">[5]</ref>, segmentation was achieved by block-diagonalizing Q, which at the time involved an expensive operation. Intuitively, we can think of V r as a new data representation of the original X, with each row of V r a data point. Then, the theory of the SIM shows that different independent subspaces become orthogonal to each other in the new representation. In <ref type="figure" target="#fig_3">Fig. 2</ref>, we demonstrate this via a toy example.</p><p>The main drawback of the SIM arises from the fact that, while it yields provably correct clusters for independent motions and noise-free measurements, its accuracy decreases in the presence of noise, outliers, or degenerate motions. Over the years, many methods have therefore been proposed to improve the SIM. In the remainder of this section, we review these methods in a rough chronological order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">The Pre-Spectral-Clustering Era</head><p>Earlier approaches to accounting for noise, outliers and degeneracies <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b35">36]</ref> were mostly focused on modifications of the SIM itself, or on directly related formulations. For instance, Gear <ref type="bibr" target="#b11">[12]</ref> advocated the use of the reduced row echelon method instead of the SVD to better account for noise and automatically find the rank of the trajectory matrix. Wu et al. <ref type="bibr" target="#b33">[34]</ref> presented an orthogonal subspace decomposition method to make the SIM more robust to noise by reasoning at group-level instead of considering individual point trajectories.</p><p>From a more general perspective, Kanatani <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref> reformulated motion segmentation as a subspace separation problem, and showed that under the condition that the subspaces are linearly independent, the SIM is block-diagonal (up to a permutation of the data). Later, Zelnik-Manor and Irani <ref type="bibr" target="#b35">[36]</ref> considered the degenerate cases of the motion segmentation problem when the motions are not independent. They analyzed the causes of these degeneracies and proposed to overcome some of them by using the eigenvectors E = [e T 1 · · · e T N ] T of the row-normalized matrix X T X and constructing a new shape interaction matrix as Q ij = r k=1 exp((e i (k) − e j (k)) 2 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">The Post-Spectral-Clustering Era</head><p>An important advance in the subspace clustering research was achieved by Park et al. <ref type="bibr" target="#b23">[24]</ref>, who, based on the then recent success of spectral clustering methods <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b27">28]</ref>, showed that the absolute value of the SIM could be employed as an affinity matrix in spectral clustering, thus yielding more accurate results than much more sophisticated methods, such as <ref type="bibr" target="#b17">[18]</ref>. This then moved the focus of the subspace clustering community away from the SIM (at least in appearance, as discussed below) and towards designing better affinity matrices for spectral clustering.</p><p>In this context, Yan and Pollefeys <ref type="bibr" target="#b34">[35]</ref> introduced a Local Subspace Affinity (LSA) measure to build affinity matrices. LSA measures the affinity between two points as the principal angle between their local subspaces. Instead of using the original data points X, LSA represents the data with the row-normalized singular vectors V of X. More recently, Lauer and Schnörr <ref type="bibr" target="#b18">[19]</ref> proposed a spectralclustering-based method that directly relies on the angles between the data points. As in LSA, instead of computing the angles from the original data, they also represented the data with its normalized singular vectors.</p><p>The recent trends in the subspace clustering literature exploit the notion of self-expressiveness of the data to build affinity matrices <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21]</ref>. The idea of self-expressiveness was introduced in [9] to describe the fact that each data point can be represented as a linear combination of the other points. To exploit this idea to construct an affinity matrix, one has to ensure that such a linear combination for a point has non-zero coefficients only for the points in the same subspace. In other words, with the coefficients grouped in a matrix C, C ij = 0 if points i and j belong to different subspaces, and C ij = 0 otherwise. This can be achieved by minimizing certain norms of C. In particular, Sparse Subspace Clustering (SSC) <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref> considered the 1 norm of C; Low Rank Representation (LRR) <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref> the nuclear norm of C; and Efficient Dense Subspace Clustering (EDSC) <ref type="bibr" target="#b14">[15]</ref> the Frobenius norm of C. Interestingly, in <ref type="bibr" target="#b14">[15]</ref>, it was shown that LRR and EDSC are equivalent to the SIM in the noise-free case. The difference lies in their ability to handle noise and outliers via additional regularization terms in their objective functions. Note that, even in the noisy case, it was shown <ref type="bibr" target="#b24">[25]</ref> that the optimal solutions of LRR and EDSC take the form VP(Σ)V T , where P(·) denotes the shrinkage-thresholding operator. Therefore, these solutions essentially correspond to a modified version of the SIM. More importantly, the effect of the regularizers introduced by these methods is sensitive to their weights, which therefore need to be tuned for the data at hand. While many methods address the problem of robustness to noise with complete data, little work has been done to handle the missing data scenario with only a few exceptions such as <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b37">38]</ref>. However, these methods <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b37">38]</ref> typically follow an expensive two-step procedure, i.e., data matrix completion followed by subspace clustering. In <ref type="bibr" target="#b36">[37]</ref>, the missing entries are simply set to zero so that they have no contribution in computing affinities by data correlations. This method, although directly handling missing data, does not make full use of the data itself because some observed entries are also discarded by the simple zeroing out strategy.</p><p>By contrast, we introduce an efficient subspace clustering method that is directly motivated by the SIM, but does not require additional regularization terms to handle data corruptions. More specifically, we show how the SIM can be robustified to data corruptions via three simple steps. We then further introduce an algorithm that robustly recovers the row-space of the data from incomplete measurements via an efficient iterative update on the Grassmann manifold, thus effectively making the powerful SIM representation applicable to the missing data scenario.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">SIM Robustified: Corrupted Data</head><p>In this section, we introduce a robust subspace clustering method inspired by the SIM, but that lets us handle cor- rupted measurements.</p><p>To make the SIM method robust to data corruptions, we design a series of three steps: (i) row normalization of V r , (ii) elementwise powering of the new SIM, and (iii) determining the best rank r. While the first two steps aim at making direct modifications to the SIM, the third step is designed to account for degenerate cases, e.g., planar motions. In the remainder of this section, we present these steps and explain the rationale behind them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Row Normalization</head><p>A closer look at the SIM method reveals that there is a magnitude bias within it, i.e., although the inter-cluster (subspace) affinities are guaranteed to be zero, the intracluster (subspace) affinities depend on the magnitude of data points. More specifically, for points drawn from the same subspace, the affinities between those that are closer to the origin will be smaller than between those that are further away. For example, in <ref type="figure" target="#fig_3">Fig. 2(c)</ref>, the affinity values are much smaller in the center (i.e., points close to the origin) than in the corners. However, ideally all points on the same subspace should be treated equally, since they belong to the same class. Moreover, this magnitude bias is also undesirable because it makes the points close to the origin more sensitive to noise.</p><p>To avoid the magnitude bias, we introduce an extra step, row normalization of V r , so that all data points in the new representation have the same magnitude 1. As a consequence, in an ideal scenario, the new SIM will become uniform within each subspace, as illustrated in <ref type="figure" target="#fig_1">Fig. 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Elementwise Powering</head><p>In an ideal scenario (i.e., without noise), after row normalization the inter-cluster affinities are all zero and the intra-cluster affinities all one. However, in noisy cases, the elements of the affinity matrix (i.e., the absolute value of the new SIM) lie in the interval [0, 1], and the intercluster affinities are often nonzero, but have rather small values. Elementwise powering of the new SIM will thus virtually suppress these small values while keeping the large affinities mostly unaffected. This operation is quite intuitive and just aims to denoise the SIM (affinity matrix). It was first used in <ref type="bibr" target="#b18">[19]</ref> to increase the gap between intercluster and intra-cluster affinities. The result of this step is illustrated in <ref type="figure" target="#fig_2">Fig. 4</ref>. Since, after row normalization, the data in V r always has a similar magnitude, independently of the problem of interest, the same powering factor can always be employed, thus preventing the need to tune a parameter for the data at hand. In our experiments, we observed that values in <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b4">5]</ref> generally yield good results.</p><p>Remark The first two steps are simple and intuitive. However, we can also interpret them in a more theoretical way with kernel methods. Note that each row of V r is a point in the new data representation, so the SIM Q = V r V T r indeed consists of the inner product of every pair of these points. Now we show that the first two steps, i.e. row normalization and elementwise powering, are equivalent to applying a normalized polynomial kernel. Given a poly-</p><formula xml:id="formula_1">nomial kernel κ(v i , v j ) = (v T i v j ) α and its correspond- ing feature mapping φ, the normalized polynomial kernel κ(v i , v j ) corresponds to the feature map v i −→ φ(v i ) φ(v i ) .<label>(2)</label></formula><p>Then the kernelκ can be expressed aŝ</p><formula xml:id="formula_2">κ(v i , v j ) = φ(v T i ) φ(v i ) φ(v j ) φ(v j ) (3) = κ(v i , v j ) κ(v i , v i )κ(v j , v j ) (4) = (v T i v j ) α (v T i v i ) α (v T j v j ) α (5) = v T i v j (v T i v i )(v T j v j ) α (6) = v T i v i v j v j α ,<label>(7)</label></formula><p>where the last equality indicates two steps, i.e. normalization and powering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Rank Determination</head><p>Determining the correct rank r is crucial for the success of the SIM method. As early as in <ref type="bibr" target="#b11">[12]</ref>, it was shown that the SIM yields poor results if the incorrect rank is employed. Therefore, several approaches to determining the correct rank have been studied. In <ref type="bibr" target="#b5">[6]</ref> the rank was obtained by examining the gaps in the singular values, which is typically sensitive to the level of noise. Inspired by the sparse representation community, ALC <ref type="bibr" target="#b21">[22]</ref> uses the sparsity-</p><formula xml:id="formula_3">preserving dimension d sp = min d s.t. d ≥ 2D log(2F/d),</formula><p>where D is the estimated intrinsic dimensionality of each subspace. SC <ref type="bibr" target="#b18">[19]</ref> estimates the rank by looking at the relative eigenvalue gaps of the Laplacian matrix.</p><p>Here, we draw inspiration from the matrix perturbation theory and introduce a simple, yet effective method to detect the correct rank of the SIM. In general, one can easily define a range of possible ranks [r min , r max ]. Our rank selection method then works by simply exhaustively searching over all possible rank values, and selecting the r which minimizes</p><formula xml:id="formula_4">C(r) = minCut(A r 1 , · · · , A r K ) |λ K − λ K+1 | ,<label>(8)</label></formula><p>where A r i is the i th cluster of the graph defined by the affinity matrix A r , λ i is the i th largest eigenvalue of the Laplacian matrix L r = D −1 A r (where D is the degree matrix of A r ), and the minimal cut minCut(A r 1 , · · · , A r K ) can be obtained via the Ncuts algorithm <ref type="bibr" target="#b27">[28]</ref>. Intuitively, the smaller the minCut and the larger the eigengap, the better the segmentation.</p><p>Our rank selection criterion can be justified by the Davis-Kahan Theorem from the matrix perturbation theory, which provides an upper bound on the distance between the eigenspaces of two Hermitian matrices that differ by some perturbations. This theorem is stated below.</p><p>Theorem 1 (Davis-Kahan Theorem <ref type="bibr" target="#b6">[7]</ref>) Let L and L be two N-by-N Hermitian matrices.</p><p>Let {λ 1 , · · · , λ k , λ k+1 , · · · , λ N } (λ i ≥ λ j , i &lt; j) denote the eigenvalues of L, and U 1 the matrix containing its first k eigenvectors. Let {λ 1 , · · · ,λ k ,λ k+1 , · · · ,λ N } and U 1 be the analogous quantities for L. Then, by defining σ := min 1≤i≤k,1≤j≤n−k</p><formula xml:id="formula_5">|λ i −λ k+j |, we have sin Θ(U 1 ,Ũ 1 ) F ≤ L − L F σ ,<label>(9)</label></formula><p>where Θ(U 1 ,Ũ 1 ) is the vector of principal angles between U 1 andŨ 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Robust Shape Interaction Matrix (RSIM)</head><p>Input: Data matrix X, minimum rank r min , and maximum rank r max for r := r min to r max do 1. SVD: Compute the SVD of the data matrix X, i.e., X = UΣV T , and take the first r right singular vectors V r . 2. Normalization: Normalize each row of V r to have unit norm → V r . 3. New SIM: Build the new Shape Interaction Matrix as Q = V r V T r . 4. Powering: Take the elementwise power of Q, i.e., A ij = (Q ij ) γ . 5. Rank Determination: Apply the normalized cuts algorithm to get the cluster labels, and compute the value C(r) as in Eq. 8. end for r best = argmin r C(r).</p><p>Output: The cluster labels s, the best rank r best .</p><p>The Davis-Kahan Theorem states that the distance between the eigenspaces of two Hermitian matrices that differ by some perturbations is bounded by the ratio between the perturbation level and their eigengap. In our case, since we do not have access to the true Laplacian, we make use of the eigenvalues of the noisy Laplacian to estimate the eigengap σ, which will then occur between the K th and K + 1 th eigenvalues for K clusters. Furthermore, we rely on minCut to approximate the noise level of the Laplacian matrix L. This approximation is reasonable because L is nothing but a normalized version of the affinity matrix. So by minimizing C(r), we aim to find the lowest upper bound of the distance between the noisy Laplacian and the true one. This minimum should correspond to the optimal rank.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Robust Shape Interaction Matrix</head><p>Our complete Robust Shape Interaction Matrix (RSIM) algorithm is outlined in Algorithm 1. Note that, while its steps are simple, to the best of our knowledge, it is the first time that such an algorithm is proposed. Furthermore, our experiments clearly evidence the effectiveness of RSIM and its benefits over more sophisticated methods, such as SSC and LRR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">SIM Robustified: Missing Data</head><p>Our previous solution to handling data corruption relies on the computation of the row space V of the data X. When the data contains missing entries, computing the row-space cannot simply be achieved by SVD. Here, we exploit the idea that our goal truly is to estimate the subspace on which the data lies (which V is an orthogonal basis of). Linear subspaces of a fixed rank form a Riemannian manifold known as the Grassmannian. Therefore, we propose to make use of an optimization technique on the Grassmann manifold to obtain an estimate of V in the presence of missing data.</p><p>More formally, let G(N, r) denote the Grassmann manifold of r-dimensional linear subspaces of R N [4] 1 . A point Y ∈ G(N, r), i.e., an r-dimensional subspace of R N , can be represented by any orthogonal matrix V ∈ R N ×r whose columns span the r-dimensional subspace Y. Estimating the row space V (an orthogonal matrix) of the data matrix can then be thought of as finding the corresponding linear subspace on G(N, r).</p><p>To estimate V, we utilize the GROUSE (Grassmannian Rank-One Update Subspace Estimation) algorithm <ref type="bibr" target="#b0">[1]</ref>. GROUSE is an efficient online algorithm that recovers the column space of a highly incomplete observation matrix. To this end, it utilizes a gradient descent method on the Grassmannian to incrementally update the subspace by considering one column of the observation matrix at a time.</p><p>More specifically, in our context, at each iteration t, we take as input a vector x Ωt ∈ R Nt , which corresponds to the partial observation of a single vector x t ∈ R N in the data matrix X 2 , with observed indices defined by Ω t ⊂ {1, · · · , N }. Let V Ωt be the submatrix of V consisting of the rows indexed by Ω t . Following the GROUSE formalism, which relies on the least-squares reconstruction of the data, we can formulate the update at iteration t as the solution to the optimization problem (10)</p><formula xml:id="formula_6">s. t. V T V = I r×r ,</formula><p>where a corresponds to the representation (or weights) of the data x Ωt in the current estimate of the subspace, and I r×r is the identity matrix.</p><p>Since <ref type="formula" target="#formula_0">(10)</ref> is not jointly convex in a and V, the two variables are obtained in a sequential manner: First, the optimal weights w are computed for the current subspace, and then the subspace is updated given those weights. Due to the least-squares form of the objective function, the solution for the weights can be obtained in closed-form as w = V † Ωt x Ωt , where V † Ωt is the pseudoinverse of V Ωt . To update the subspace, i.e., the orthogonal basis matrix V, GROUSE exploits an incremental gradient descent method on the Grassmann manifold, which we describe below.</p><p>Let I Ωt ∈ R N ×Nt be the N t columns of the N × N identity matrix indexed by Ω t . Then, the objective function of (10) can be rewritten as</p><formula xml:id="formula_7">E t = I Ωt (V Ωt w − x Ωt ) 2 2 .<label>(11)</label></formula><p>The update of the subspace is achieved by taking a step in the direction of the gradient of this objective function on the Grassmannian, i.e., moving along the geodesic defined by the negative Grassmannian gradient. To this end, we first need to compute the regular gradient of the objective function with respect to V. This gradient can be written as</p><formula xml:id="formula_8">∂E t ∂V = −(I Ωt (x Ωt − Ωt w))w T (12) = −rw T ,<label>(13)</label></formula><p>where r = I Ωt (x Ωt − V Ωt w) denotes the (zero-padded) vector of residuals. The gradient on the Grassmannian can then be obtained by projecting the regular gradient on the tangent space of the Grassmannian at the current point. Following <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b7">8]</ref>, this can be written as</p><formula xml:id="formula_9">∇E t = (I − VV T ) ∂E t ∂V (14) = −(I − VV T )rw T (15) = −rw T .<label>(16)</label></formula><p>As shown in <ref type="bibr" target="#b7">[8]</ref>, a gradient step along the geodesic with tangent vector −∇E t is defined as a function of the singular values and vectors of ∇E t . Since ∇E t has rank one, its singular value decomposition is trivial to compute. This lets us write a step of length η in the direction −∇E t , and thus the update of V at time t, as</p><formula xml:id="formula_10">V t+1 = V t + (cos(ση) − 1) w 2 Vww T + sin(ση) r r w T w ,<label>(17)</label></formula><p>where σ = r w . The Grassmannian update is very efficient since each subspace update only involves linear operations. Furthermore, for a specific diminishing step-size η, it is guaranteed to converge to a locally optimal estimate of V <ref type="bibr" target="#b0">[1]</ref>. After getting an estimate of V using this method, we can directly apply the RSIM to perform subspace clustering.</p><p>The pseudocode of our robust SIM with missing data (RSIM-M) algorithm is given in Algorithm 2. Note that:</p><p>1. Stochastic gradient descent may require a relatively large number of steps to be stable. With small amounts of data, we run multiple passes over the data. For example, in our experiments on motion segmentation with incomplete trajectories, we iterated over all the frames 100 times. Thanks to the high efficiency of rank-one Grassmannian update, RSIM-M remains very efficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2 RSIM with Missing Data (RSIM-M)</head><p>Input: An incomplete data matrix X, a subspace initialization V 0 , a step size η, bounds r min , r max for t = 1,· · · ,T do 1. Take the t th row of X with observed entry Ω t .</p><p>2. Update the current V t via Eq. 17. end for Run Algorithm 1 to perform robust subspace clustering.</p><p>Output: The cluster labels s, the best rank r best .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Due to the non-convexity of this problem, initialization</head><p>is important for convergence speed and optimality. In practice, we start with the subspace spanned by the most complete r rows of X, which we found to be very effective in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experimental Evaluation</head><p>We evaluate the performance of our algorithms with four sets of experiments that represent different scenarios: (i) Hopkins155 for motion segmentation; (ii) Extended Yale Face B for face clustering; (iii) Hopkins12Real: 12 additional real-world sequences with missing data; (iv) Hopkins outdoor sequences for semi-dense motion segmentation. We compare the results of our algorithms with the following baselines: SIM (followed by spectral clustering) ( <ref type="bibr" target="#b23">[24]</ref>), SSC ( <ref type="bibr" target="#b9">[10]</ref>), LRSC ( <ref type="bibr" target="#b30">[31]</ref>), LRR ( <ref type="bibr" target="#b19">[20]</ref>), and EDSC <ref type="bibr" target="#b14">[15]</ref>. Note that the last two methods have proposed to make use of an additional post-processing step (called a heuristic in <ref type="bibr" target="#b9">[10]</ref>), which yields the additional baselines LRR-H and EDSC-H. For the case of LRR, this heuristic relies on the following steps: r , and normalize each row of Z. 4. Build the affinity matrix A as ZZ T with elementwise powering such that A ij = [ZZ T ] 4 ij . Interestingly, this post-processing is nothing else but another way to build an improved SIM. Indeed, Z can be thought of approximately as the row space of the denoised data X − E from the equality constraint in <ref type="bibr" target="#b17">(18)</ref>. In other words, one can also think of LRR (and EDSC) as a preprocessing step to denoise the data before computing the SIM. In contrast, the proposed method does not require any pre-processing step and, as evidenced below, achieves much better results.</p><p>The parameters of the baselines are tuned to the best results for each experiment. For our method, we report the results of all the four sets of experiments with the same powering factor γ = 4.5. Note that we could potentially get better results if we fine-tuned the parameter γ. For motion segmentation, the rank is selected iteratively from the integers in [K, 4K]; for the face clustering experiment, the rank is in [4K, 6K] with K the number of clusters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Hopkins155: Complete Data with Noise</head><p>Hopkins155 <ref type="bibr" target="#b29">[30]</ref> is a standard benchmark to test pointbased motion segmentation algorithms. It includes 155 sequences, each of which contains 39-550 point trajectories sampled from two or three motions. Each trajectory is complete and contaminated with a moderate amount of noise, but with no outliers. The dataset contains general motions, such as rigid and nonrigid motions, indoor checkerboard sequences and outdoor traffic sequences. The results of our RSIM algorithm and of the baselines are reported in <ref type="table" target="#tab_0">Table 1</ref>. Note that our method achieves the lowest overall average clustering error. The average runtimes (in seconds) per sequence for different methods are: SIM -0.0229s, SSC -0.9187s, LRR -1.0795s, LRR-H -1.0930s, EDSC -0.0378s, EDSC-H -0.0762s, and RSIM -0.1766s.</p><p>We also performed an ablation study on this dataset to see the contributions of the proposed steps. We denote the SIM with our first two steps (i.e., normalization and polynomial kernel) by SIM+1&amp;2, and denote the SIM with our third step (i.e., rank determination) by SIM+3. The results are shown in <ref type="table" target="#tab_1">Table 2</ref>. Note that the proposed first two steps improve the motion segmentation accuracy over the original SIM, the proposed third step boosts the segmentation results with a big margin, and our complete robust shape interaction matrix method achieves the best results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Extended Yale B: Complete Data with Outliers</head><p>Under Lambertian reflectance assumption, face images of the same subject with a fixed pose and varying lighting lie approximately in a low dimensional subspace <ref type="bibr" target="#b1">[2]</ref>. We therefore make use of the Extended Yale B face dataset to evaluate our method on the task of face clustering. This dataset is composed of face images of 38 subjects, each of which has 64 frontal face images acquired under different lighting conditions. We follow exactly the same experimental settings as in <ref type="bibr" target="#b9">[10]</ref> and divide the 38 subjects into four groups (i.e., group 1 -subject 1 to 10, group 2 -subject 11 to 20, group 3 -subject 21 to 30, and group 4 -subject 31 to 38). Within each group, we test all the combinations of K subjects, for K ∈ <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b9">10]</ref>.</p><p>Note that, since this data is grossly corrupted, the baselines ( <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b19">20]</ref>) use an additional regularizer to account for outliers, with weight specifically tuned for this dataset.</p><p>In contrast, our method doesn't have this extra term and parameter. The results are presented in <ref type="table" target="#tab_2">Table 3</ref>. Interestingly, although our method does not handle the outliers explicitly, it achieves the comparable accuracies for 2 and 3 subjects, and get far better accuracies for 5, 8 and 10 subjects. In contrast to the baselines, our method remains stable as the number of subjects increases. From a different perspective, this dataset can be thought of as being contaminated with both Gaussian noise and Laplacian noise, so the baseline methods (SSC, LRR and EDSC) all have two regularization terms, one for the Gaussian noise and the other for the Laplacian one, and their weight parameters, therefore, need to be tuned for the data at hand. In contrast, our method relies on no specific assumptions about the distributions of the noise, and is thus robust to a mixture of different types of noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Hopkins12Real: Incomplete Data with Noise</head><p>To demonstrate that our method can handle missing data gracefully, we employed the Hopkins 12 additional sequences containing incomplete data and noise. Most of the baselines used previously cannot deal with missing data. Therefore, we only compare our method with those that have proposed to tackle this challenging scenario. In particular, we compare our results against those published by <ref type="bibr" target="#b25">[26]</ref>, where ALC was employed after filling in the missing entries of the data matrix with a matrix completion method, e.g., Power Factorization (PF) ( <ref type="bibr" target="#b12">[13]</ref>), Robust Principal Component Analysis (RPCA) ( <ref type="bibr" target="#b2">[3]</ref>), and 1 sparse representation ( <ref type="bibr" target="#b25">[26]</ref>). We also evaluate SSC ( <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>), which works with missing data by either removing the trajectories with missing entries (SSC-R), or treating the missing entries as outliers (SSC-O). In contrast, our method doesn't require any matrix completion or trajectory removal. The results in <ref type="table" target="#tab_3">Table 4</ref> clearly evidence the benefits of our method in the presence of missing data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Hopkins Outdoor: Semi-dense, Incomplete Data with Outliers</head><p>To study a more realistic scenario, where outliers and missing data are ubiquitous due to occlusions and tracking failures, we took 18 outdoor sequences from the Hop-kins155 dataset and obtained semi-dense trajectories by applying the tracking method of <ref type="bibr" target="#b32">[33]</ref>  <ref type="bibr" target="#b2">3</ref> . For the 18 sequences, the tracking method found an average of 3026 trajectories per sequence, among which 16.66% (684 out of 3026) on average contained missing entries, which were set to zero. We compare our results to those of the same SSC-O and SSC-R baselines used previously.</p><p>Since there is no ground-truth for this data, we can only provide a qualitative comparison. In particular, we observed  that our method performed either better, or on par with SSC-R, and consistently outperformed SSC-O. We found that SSC-O tends to group the trajectories with missing entries in a single cluster. This is mainly due to the fact that, according to the self-expressiveness criterion, incomplete trajectories are poorly represented by complete ones, and thus end up being grouped together. <ref type="figure">Fig. 5</ref> shows some typical behaviors of SSC-R and of our approach. It can easily be checked that our approach yields better clusters on average. The results of SSC-O are shown in <ref type="figure">Fig. 6</ref>, where the behavior described above can be observed. Finally, in <ref type="figure">Fig. 7</ref>, we show some failure cases where both SSC-R and our approach were unable to find the right clusters. The results for all the sequences are provided in the appendix. Since SSC-R removes the missing trajectories, it utilized only 2522 trajectories on average out of the original average of 3026. In contrast, our method makes use of all the available trajectories. Nonetheless, while SSC-R takes 150.48 seconds per sequence on average, our method only takes about 5.22 seconds on average.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper, we have revealed that many recent subspace clustering methods actually did not go far beyond the 20-year-old SIM method, but rather had indirect connections to it. While recent methods exploit notions of compressed sensing and self-expressiveness, our method performs simple and direct modifications of the SIM itself and makes it robust to corruptions. Furthermore, we have extended our method to the case of missing data. Our experimental evaluation has demonstrated that our algorithms are not only efficient, but also generally applicable to subspace segmentation in realistic scenarios. In the future, we plan to adapt our method to online motion segmentation on longer sequences.   <ref type="figure">Figure 5</ref>: Comparison of SSC-R and RSIM-M on semi-dense data: While SSC-R removes the trajectories with missing entries, and thus gets less dense results, our method can handle missing data robustly. Each image is a frame sampled from one of the video sequences. The points marked with the same color are clustered into the same group by the respective methods. Best viewed in color. <ref type="figure">Figure 6</ref>: Typical behavior of SSC-O on semi-dense data: By treating missing entries as outliers, SSC-O tends to cluster the trajectories with missing entries into same group. The points marked with the same color are clustered into the same group by SSC-O. Best viewed in color.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SSC-R</head><p>RSIM-M SSC-R RSIM-M <ref type="figure">Figure 7</ref>: Failure cases of SSC-R and of RSIM-M: We conjecture that these failures are due to tracking failures (e.g., very few trajectories), or to highly dependence between motions. Best viewed in color.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>1 arXiv</head><label>1</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Clustering two lines in 3D: Row normalization (a) Two lines (each forming one subspace) with an arbitrary angle; (b) New data representation with row-normalized V r . Note that the lines collapse four points on the unit circle, corresponding to orthogonal vectors; (c) New SIM (absolute value) without magnitude bias.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Clustering two lines with noise in 3D: (a) Two lines with Gaussian noise; (b) New SIM after row normalization, with noise in the off-diagonal blocks; (c) Affinity matrix after elementwise powering. Note that the block-diagonal structure is much cleaner.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>2 V</head><label>2</label><figDesc>Ωt a − x Ωt 2 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>1 .</head><label>1</label><figDesc>Solve the optimization problem min C,E C * + λ E 2,1 s.t. X = XC + E . (18) 2. Compute the SVD of C, i.e. C = UΣV T , and take the first r singular vectors V r . 3. Construct Z = V r Σ 1 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Clustering error (in %) on Hopkins 155.</figDesc><table><row><cell cols="6">Methods SIM SSC LRR LRR-H EDSC EDSC-H RSIM</cell></row><row><cell>2 motions Mean Median 3 motions Mean Median Overall Mean Median</cell><cell>6.50 1.53 4.10 1.14 0.00 0.22 12.26 4.40 9.89 6.12 6.22 0.56 7.80 2.18 5.41 1.53 0.00 0.53</cell><cell>2.13 0.00 4.03 1.43 2.56 0.00</cell><cell>2.67 0.00 8.06 2.53 4.04 0.30</cell><cell>0.86 0.00 2.49 0.21 1.23 0.00</cell><cell>0.65 0.00 1.71 0.28 0.89 0.00</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Ablation study on Hopkins 155.</figDesc><table><row><cell cols="5">Methods SIM SIM+1&amp;2 SIM+3 RSIM</cell></row><row><cell>Mean Median</cell><cell>7.80 1.53</cell><cell>5.77 0.24</cell><cell>3.17 0.31</cell><cell>0.89 0.00</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Clustering error (in %) on Extended Yale B.</figDesc><table><row><cell cols="2">Methods SIM</cell><cell>SSC</cell><cell cols="4">LRR LRR-H EDSC EDSC-H RSIM</cell></row><row><cell>2 subjects Mean Median 3 subjects Mean Median 5 subjects Mean Median 8 subjects Mean Median 10 subjects Mean Median</cell><cell cols="3">8.10 6.25 24.64 3.10 19.52 1.86 9.52 0.00 5.47 16.67 1.04 14.58 45.62 4.31 34.16 48.13 2.50 35.00 57.05 5.85 41.19 55.96 4.49 43.75 65.10 10.94 38.85 64.06 5.63 41.09</cell><cell>2.54 0.78 4.21 2.60 6.90 5.63 14.34 14.34 22.92 23.59</cell><cell>5.42 4.69 14.05 8.33 36.99 30.63 54.24 48.73 59.58 50.47</cell><cell>2.65 1.56 3.86 3.13 5.11 3.75 6.07 4.88 7.24 6.09</cell><cell>2.36 1.56 3.21 2.60 3.56 3.13 3.60 3.32 3.70 3.44</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Clustering error (in %) on Hopkins 12 Real Motion Sequences with Incomplete Data.</figDesc><table><row><cell>%</cell><cell cols="2">PF+ALC RPCA+ALC</cell><cell>1+ALC</cell><cell cols="2">SSC-R SSC-O RSIM-M</cell></row><row><cell>Mean Median Max Std</cell><cell>10.81 7.85 34.57 0.04</cell><cell>13.78 8.27 41.36 12.25</cell><cell>1.28 1.07 4.35 1.29</cell><cell>3.82 0.31 20.25 26.34 8.78 4.80 6.80 8.79</cell><cell>0.61 0.61 1.64 0.53</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">For example, the Grassmann manifold G(N, 1) consists of all lines in R N passing through the origin.<ref type="bibr" target="#b1">2</ref> Note that even though we consider xt to be a column vector, it really corresponds to one row of the data matrix X.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">While there are 21 outdoor videos in Hopkins155, the tracking code that we used was unable to read the 3 Kanatani videos.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>NICTA is funded by the Australian Government through the Department of Communications and the Australian Research Council through the ICT Centre of Excellence Program. HL thanks the supports of ARC Discovery grants DP120103896, DP130104567, and the ARC Centre of Excellence.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix -Hopkins Outdoor: Semi-dense, Incomplete Data with Outliers</head><p>Here, we show the results of our algorithm (RSIM-M) and of the baselines SSC-O and SSC-R on all the 18 sequences described in Section 5.4 of this paper. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RSIM-M SSC-O SSC-R</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Online identification and tracking of subspaces from highly incomplete information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Balzano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nowak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">48th Annual Allerton Conference on Communication, Control, and Computing</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Lambertian reflectance and linear subspaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Basri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Jacobs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="218" to="233" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Robust principal component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Candès</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chikuse</surname></persName>
		</author>
		<title level="m">Statistics on Special Manifolds</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A multi-body factorization method for motion analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Costeira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A multibody factorization method for independently moving objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Costeira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The rotation of eigenvectors by a perturbation. iii</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">M</forename><surname>Kahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Numerical Analysis</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="46" />
			<date type="published" when="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The geometry of algorithms with orthogonality constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Edelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Arias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Matrix Analysis and Applications</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="303" to="353" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Sparse subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Elhamifar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Sparse subspace clustering: Algorithm, theory, and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Elhamifar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>PAMI</publisher>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="2765" to="2781" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Feature grouping in moving objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gear</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Motion of Non-Rigid and Articulated Objects</title>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multibody grouping from motion images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gear</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Powerfactorization: 3d reconstruction with missing or uncertain data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hartley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schaffalitzky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Australia-Japan Advanced Workshop on Computer Vision</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Motion segmentation based on factorization method and discriminant criterion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ichimura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Efficient dense subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WACV</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Motion segmentation by subspace separation and model selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kanatani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Evaluation and selection of models for motion segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kanatani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multi-stage optimization for multi-body motion segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kanatani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sugaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Australia-Japan Advanced Workshop on Computer Vision</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Spectral clustering of linear subspaces for motion segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schnorr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Robust recovery of subspace structures by low-rank representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="171" to="184" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Robust subspace segmentation by low-rank representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Segmentation of multivariate mixed data via lossy data coding and compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Derksen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>PAMI</publisher>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1546" to="1562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">On spectral clustering: Analysis and an algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Spectral clustering for robust motion segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kasturi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.07423</idno>
		<title level="m">Connections between nuclear norm and frobenius norm based representation</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Motion segmentation via robust subspace separation in the presence of outlying, incomplete, or corrupted trajectories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Motion segmentation in the presence of outlying, incomplete, or corrupted trajectories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>PAMI</publisher>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Normalized cuts and image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Shape and motion from image streams under orthography: a factorization method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="137" to="154" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A benchmark for the comparison of 3-d motion segmentation algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Low rank subspace clustering (lrsc)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Favaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="47" to="61" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Multiframe motion segmentation with missing data using powerfactorization and gpca</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hartley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">IJCV</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Action recognition by dense trajectories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Klaser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Multibody grouping via orthogonal subspace decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A general framework for motion segmentation: Independent, articulated, rigid, non-rigid, degenerate and non-degenerate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pollefeys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Degeneracies, dependencies and their implications in multi-body and multi-sequence factorizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zelnik-Manor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Heckel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bölcskei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1307.4891</idno>
		<title level="m">Robust subspace clustering via thresholding</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">High-rank matrix completion and subspace clustering with missing data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Eriksson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Balzano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nowak</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1112.5629</idno>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
