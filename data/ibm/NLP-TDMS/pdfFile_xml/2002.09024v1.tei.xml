<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MaxUp: A Simple Way to Improve Generalization of Neural Network Training</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-02-20">20 Feb 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengyue</forename><surname>Gong</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongzheng</forename><surname>Ren</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mao</forename><surname>Ye</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Liu</surname></persName>
						</author>
						<title level="a" type="main">MaxUp: A Simple Way to Improve Generalization of Neural Network Training</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-02-20">20 Feb 2020</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T11:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose MaxUp, an embarrassingly simple, highly effective technique for improving the generalization performance of machine learning models, especially deep neural networks. The idea is to generate a set of augmented data with some random perturbations or transforms, and minimize the maximum, or worst case loss over the augmented data. By doing so, we implicitly introduce a smoothness or robustness regularization against the random perturbations, and hence improve the generation performance. For example, in the case of Gaussian perturbation, MaxUp is asymptotically equivalent to using the gradient norm of the loss as a penalty to encourage smoothness. We test MaxUp on a range of tasks, including image classification, language modeling, and adversarial certification, on which MaxUp consistently outperforms the existing best baseline methods, without introducing substantial computational overhead. In particular, we improve ImageNet classification from the state-of-the-art top-1 accuracy 85.5% without extra data to 85.8%. Code will be released soon.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>A central theme of machine learning is to alleviate the issue of overfitting, improving the generalization performance on testing data. This is often achieved by leveraging important prior knowledge of the models and data of interest. For example, the regularization-based methods introduce penalty on the complexity of the model, which often amount to enforcing certain smoothness properties. Data augmentation techniques, on the other hand, leverage important invariance properties of the data (such as the shift and rotation invariance of images) to improve performance. Novel approaches that exploit important knowledge of the models and data hold the potential of substantially improving the performance of machine learning systems. * Equal contribution 1 UT Austin.</p><p>Correspondence to: Chengyue Gong &lt;cygong@cs.utexas.edu&gt;.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Preprint</head><p>We propose MaxUp, a simple yet powerful training method to improve the generalization performance and alleviate the over-fitting issue. Different from standard methods that minimize the average risk on the observed data, MaxUp generates a set of random perturbations or transforms of each observed data point, and minimizes the average risk of the worst augmented data of each data point. This allows us to enforce robustness against the random perturbations and transforms, and hence improve the generalization performance. MaxUp can easily leverage arbitrary stateof-the-art data augmentation schemes (e.g. <ref type="bibr" target="#b36">Zhang et al., 2018;</ref><ref type="bibr" target="#b6">DeVries &amp; Taylor, 2017;</ref><ref type="bibr" target="#b2">Cubuk et al., 2019a)</ref>, and substantially improves over them by minimizing the worst (instead of average) risks on the augmented data, without adding significant computational ahead.</p><p>Theoretically, in the case of Gaussian perturbation, we show that MaxUp effectively introduces a gradient-norm regularization term that serves to encourage smoothness of the loss function, which does not appear in standard data augmentation methods that minimize the average risk.</p><p>MaxUp can be viewed as a "lightweight" variant of adversarial training against adversarial input pertubrations (e.g. <ref type="bibr" target="#b27">Tramèr et al., 2018;</ref><ref type="bibr" target="#b16">Madry et al., 2017)</ref>, but is mainly designed to improve the generalization on the clean data, instead of robustness on perturbed data (although MaxUp does also increase the adversarial robustness in Gaussian adversarial certification as we shown in our experiments <ref type="bibr">(Section 4.4)</ref>). In addition, compared with standard adversarial training methods such as projected gradient descent (PGD) <ref type="bibr" target="#b16">(Madry et al., 2017)</ref>, MaxUp is much simpler and computationally much faster, and can be easily adapted to increase various robustness defined by the corresponding data augmentation schemes.</p><p>We test MaxUp on three challenging tasks: image classification, language modeling, and certified defense against adversarial examples <ref type="bibr" target="#b1">(Cohen et al., 2019)</ref>. We find that MaxUp can leverage the different state-of-the-art data augmentation methods and boost their performance to achieve new state-of-the-art on a range of tasks, datasets, and neural architectures. In particular, we set up a new state-of-the-art result on ImageNet classification without extra data, which improves the best 85.5% top1 accuracy by <ref type="bibr" target="#b31">Xie et al. (2019)</ref> to 85.8%. For the adversarial certification task, we find Maxup allows us to train more verifiably robust classifiers than prior arts such as the PGD-based adversarial training proposed by <ref type="bibr" target="#b21">Salman et al. (2019)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Main Method</head><p>We start with introducing the main idea of MaxUp, and then discuss its effect of introducing smoothness regularization in Section 2.1.</p><p>ERM Giving a dataset D n = {x i } n i=1 , learning often reduces to a form of empirical risk minimization (ERM):</p><formula xml:id="formula_0">min θ E x∼Dn [L(x, θ)] ,<label>(1)</label></formula><p>where θ is a parameter of interest (e.g., the weights of a neural network), and L(x, θ) denotes the loss associated with data point x. A key issue of ERM is the risk of overfitting, especially when the data information is insufficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MaxUp</head><p>We propose MaxUp to alleviate overfitting. The idea is to generate a set of random augmented data and minimize the maximum loss over the augmented data.</p><p>Formally, for each data point x in D n , we generate a set of perturbed data points {x ′ i } m i=1 that are similar to x, and estimate θ by minimizing the maximum loss over {x ′ i }:</p><formula xml:id="formula_1">MaxUp: min θ E x∼Dn max i∈[m] L(x ′ i , θ) .<label>(2)</label></formula><p>This loss can be easily minimized with stochastic gradient descent (SGD). Note that the gradient of the maximum loss is simply the gradient of the worst copy, that is,</p><formula xml:id="formula_2">∇ θ max i∈[m] L(x ′ i , θ) = ∇ θ L(x ′ i * , θ),<label>(3)</label></formula><p>where i * = arg max i∈[m] L(x ′ i , θ). This yields a simple and practical algorithm shown in Algorithm 1.</p><p>In our work, we assume the augmented data {x ′ i } m i=1 is i.i.d. generated from a distribution P(·|x). The P(·|x) can be based on small perturbations around x, e.g., P(·|x) = N (x, σ 2 I), the Gaussian distribution with mean x and isotropic variance σ 2 . The P(·|x) can also be constructed based on invariant data transformations that are widely used in the data augmentation literature, such as random crops, equalizing, rotations, and clips for images (see e.g <ref type="bibr" target="#b2">Cubuk et al., 2019a;</ref><ref type="bibr" target="#b6">DeVries &amp; Taylor, 2017;</ref><ref type="bibr" target="#b3">Cubuk et al., 2019b)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">MaxUp as a Smoothness Regularization</head><p>We provide a theoretical interpretation of Maxup as introducing a gradient-norm regularization to the original ERM objective to encourage smoothness. Here we consider the simple case of isotropic Gaussian perturbation, when P(·|x) = N (x, σ 2 I). For simplifying notation, we definẽ</p><formula xml:id="formula_3">L P,m (x, θ) := E {x ′ i } m i=1 ∼P(·|x) m max i∈[m] L(x ′ i , θ) ,<label>(4)</label></formula><p>which represents the expected MaxUp risk of data point x with m augmented copies.</p><p>Theorem 1 (MaxUp as Gradient-Norm Regularization).</p><formula xml:id="formula_4">ConsiderL P,m (x, θ) defined in (4) with P(·|x) = N (x, σ 2 I). Assume L(x, θ) is second-order differentiable w.r.t. x. Theñ L P,m (x, θ) = L(x, θ) + c m,σ ∇ x L(x, θ) 2 + O(σ 2 ),</formula><p>where c m,σ is a constant and c m,σ = Θ(σ √ log m), where Θ(·) denotes the big-Theta notation.</p><p>Theorem 1 shows that, the expected MaxUp risk can be viewed as introducing a Lipschitz-like regularization with the gradient norm ∇ x L(x, θ) 2 , which encourages the smoothness of L(x, θ) w.r.t. the input x. The strength of the regularization is controlled by c m,σ , which depends on the number of samples m and perturbation magnitude σ.</p><p>Proof. Using Taylor expansion, we havẽ</p><formula xml:id="formula_5">L P,m (x, θ) = E max i∈[m] L(x ′ i , θ) = L(x, θ) + E max i∈[m] (L(x ′ i , θ) − L(x, θ)) = L(x, θ) + E max i∈[q] ∇ x L(x, θ), z i + O(σ 2 ),</formula><p>where we assume z i = x ′ i − x, which follows N (0, σ 2 I). The rest of the proof is due to the Lemma 1 below.</p><formula xml:id="formula_6">Lemma 1. Let g be a fixed vector in R d , and {z i } m i=1 are m i.i.d. random variables from N (0, σ 2 I). We have E max i∈[m] g, z i = c m,σ g 2 , where c m,σ = Θ σ √ log m . Proof. Define y i = g, z i / g 2 . Then {y i } m i=1 is i.i.d. from N (0, σ 2 ). Therefore, c m,σ = E[max i∈[m] y i ],</formula><p>which is well known to be Θ(σ √ log m). See e.g., <ref type="bibr" target="#b20">Orabona &amp; Pál (2015)</ref>; <ref type="bibr" target="#b12">Kamath (2015)</ref> for bounds related to E[max i∈ <ref type="bibr">[m]</ref> y i ]. More specifically, we have <ref type="bibr" target="#b12">Kamath (2015)</ref>.</p><formula xml:id="formula_7">0.23σ √ log m ≤ c m,σ ≤ √ 2σ √ log m following</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 MaxUp with Stochastic Gradient Descent</head><p>Input: Dataset D n = {x i } n i=1 ; transformation distribution P(·|x); number of augmented data m; initialization θ 0 ; SGD parameters (batch size, step size η, etc). repeat Draw a mini-batch M from D n , and update θ via</p><formula xml:id="formula_8">θ ← θ − ηE x∼M ∇ θ max i∈[m] L(x ′ i , θ) , where {x ′ i } m i=1 are drawn i.i.d. from P(·|x) for each x in the mini batch M. See Equation 3. until convergence</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Related Methods and Discussion</head><p>MaxUp is closely related to both data augmentation and adversarial training. It can be viewed as an adversarial variant of data augmentation, in that it minimizes the worse case loss on the perturbed data, instead of an average loss like typical data augmentation methods. MaxUp can also be viewed as a "lightweight" variant of adversarial training, in that the maximum loss is calculated by simple random sampling, instead of more accurate gradient-based optimizers for finding the adversarial loss, such as projected gradient descent (PGD); MaxUp is much simpler and faster than the PGD-based adversarial training, and is more suitable for our purpose of alleviating over-fitting on clean data (instead of adversarial defense). We now elaborate on these connections in depth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Data Augmentation</head><p>Data augmentation has been widely used in machine learning, especially on image data which admits a rich set of invariance transforms (e.g. translation, rotation, random cropping). Recent augmentation techniques, such as MixUp <ref type="bibr" target="#b36">(Zhang et al., 2018)</ref>, CutMix <ref type="bibr" target="#b34">(Yun et al., 2019)</ref> and manifold MixUp <ref type="bibr" target="#b29">(Verma et al., 2019)</ref> have been found highly useful in training deep neural networks, especially in achieving state-of-the-art results on important image classification benchmarks such as SVHN, CIFAR and Im-ageNet. More recently, more advanced methods have been developed to find the optimal data augmentation policies using reinforcement learning or adversarial generative network (e.g. <ref type="bibr" target="#b2">Cubuk et al., 2019a;</ref><ref type="bibr" target="#b38">Zhang et al., 2020)</ref>.</p><p>MaxUp can easily leverage these advanced data augmentation techniques to achieve good performance. The key difference, however, is that MaxUp in (2) minimizes the maximum loss on the augmented data, while typical data augmentation methods minimize the average loss, that is,</p><formula xml:id="formula_9">min θ E x∼Dn 1 m m i=1 L(x ′ i , θ) ,<label>(5)</label></formula><p>which we refer to as standard data augmentation through-out the paper. It turns out <ref type="formula" target="#formula_1">(2)</ref> and <ref type="formula" target="#formula_9">(5)</ref> behave very different as regularization mechanisms, in that (5) does not introduce the gradient-norm regularization as <ref type="formula" target="#formula_1">(2)</ref>, and hence does not have the benefit of having gradient-norm regularization. This is because the first-order term in the Taylor expansion is canceled out due to the averaging in (5).</p><p>Specifically, let P(·|x) be any distribution whose expectation is x and L(x, θ) is second-order differentiable w.r.t x.</p><p>Define the expected loss related to (5) on data point x:</p><formula xml:id="formula_10">L P,m (x, θ) := E {x ′ i } m i=1 ∼P(·|x) m 1 m m i=1 L(x ′ i , θ) . (6)</formula><p>Then with a simple Taylor expansion, we havê</p><formula xml:id="formula_11">L P,m (x, θ) = L(x, θ) + O(σ 2 ),</formula><p>which misses the gradient-norm regularization term when compared with MaxUp decomposition in Theorem 1.</p><p>Note that the MaxUp update is computationally faster than the solving (5) with the same m, because we only need to backpropagate on the worst augmented copy for each data point (see <ref type="table">Equation 3</ref>), while solving (5) requires to backpropagate on all the m copies at each iteration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Adversarial Training</head><p>Adversarial training has been developed to defense various adversarial attacks on the data inputs <ref type="bibr" target="#b16">(Madry et al., 2017)</ref>. It estimates θ by solving the following problem:</p><formula xml:id="formula_12">min θ E x∼Dn max x ′ ∈B(x,r) L(x ′ , θ) ,<label>(7)</label></formula><p>where B(x, r) represents a ball centered at x with radius r under some metrics (e.g. ℓ 0 , ℓ 1 , ℓ 2 , or ℓ ∞ distances). The inner maximization is often solved by running projected gradient descent (PGD) for a number of iterations.</p><p>MaxUp in <ref type="formula" target="#formula_1">(2)</ref> can be roughly viewed as solving the inner adversarial maximization problem in (7) using a "mild", or "lightweight" optimizer by randomly drawing m points from P(·|x) and finding the best. Such mild adversarial optimization increases the robustness against the random perturbation it introduces, and hence enhance the generalization performance. Adversarial ideas have also been used to improvement generalization in a series of recent works (e.g., <ref type="bibr" target="#b31">Xie et al., 2019;</ref><ref type="bibr" target="#b39">Zhu et al., 2020)</ref>.</p><p>Different from our method, typical adversarial training methods, especially these based PGD <ref type="bibr" target="#b16">(Madry et al., 2017)</ref>, tend to solve the adversarial optimization much more aggressively to achieve higher robustness, but at the cost of scarifying the accuracy on clean data. There has been shown a clear trade-off between the accuracy of a classifier on clean data and its robustness against adversarial attacks (see e.g., <ref type="bibr" target="#b28">Tsipras et al., 2019;</ref><ref type="bibr" target="#b37">Zhang et al., 2019;</ref><ref type="bibr" target="#b33">Yin et al., 2019;</ref><ref type="bibr" target="#b22">Schmidt et al., 2018)</ref>. By using a mild adversarial optimizer, MaxUp strikes a better balance between the accuracy on clean data and adversarial robustness.</p><p>Besides, MaxUp is much more computationally efficient than PGD-based adversarial training, because it does not introduce additional back-propagation steps as PGD. In practice, MaxUp can be equipped with various complex data augmentation methods (in which case P(·|x) can be discrete distributions), while PGD-based adversarial training mostly focuses on perturbations in ℓ p balls.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Online Hard Example Mining</head><p>Online hard example mining (OHEM) <ref type="bibr" target="#b23">(Shrivastava et al., 2016)</ref> is a training method originally developed for regionbased objective detection, which improves the performance of neural networks by picking the hardest examples within mini batches of stochastic gradient descent (SGD). It can be viewed as running SGD for minimizing the following expected loss</p><formula xml:id="formula_13">min θ E M max x∈M L(x, θ) ,</formula><p>which amounts to randomly picking a mini-batch M at each iteration and minimizing the loss of the hardest example within M. By doing so, OHEM can focus more on the hard examples and hence improves the performance on borderline cases. This makes OHEM particularly useful for class-imbalance tasks, e.g. object detection <ref type="bibr" target="#b23">(Shrivastava et al., 2016)</ref>, person reidentification <ref type="bibr" target="#b15">(Luo et al., 2019)</ref>.</p><p>Different with MaxUp, the hardest examples in OHEM are selected in mini-batches consisting of independently selected examples, with no special correlation or similarity. Mathematically, it can be viewed as reweighing the data distribution to emphasize harder instances. This is substantially different from MaxUp, which is designed to enforce the robustness against existing random data augmentation/perturbation schemes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Top-1 error Top-5 error Vanilla <ref type="bibr" target="#b11">(He et al., 2016b)</ref> 76.3 -Dropout <ref type="bibr" target="#b24">(Srivastava et al., 2014)</ref> 76.8 93.4 DropPath <ref type="bibr" target="#b14">(Larsson et al., 2017)</ref> 77.1 93.5 Manifold Mixup <ref type="bibr" target="#b29">(Verma et al., 2019)</ref> 77.5 93.8 AutoAugment <ref type="bibr" target="#b2">(Cubuk et al., 2019a)</ref> 77.6 93.8 Mixup <ref type="bibr" target="#b36">(Zhang et al., 2018)</ref> 77.9 93.9 DropBlock <ref type="bibr" target="#b7">(Ghiasi et al., 2018)</ref> 78.3 94.1 CutMix <ref type="bibr" target="#b34">(Yun et al., 2019)</ref> 78 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>We test our method using both image classification and language modeling for which a variety of strong regularization techniques and data augmentation methods have been proposed. We show that MaxUp can outperform all of these methods on the most challenging datasets (e.g. ImageNet, Penn Treebank, and Wikitext-2) and state-of-the-art models (e.g. ResNet, EfficientNet, AWD-LSTM). In addition, we apply our method to adversarial certification via Gaussian smoothing <ref type="bibr" target="#b1">(Cohen et al., 2019)</ref>, for which we find that MaxUp can outperform both the augmented data baseline and PGD-based adversarial training baseline.</p><p>For all the tasks, if training from scratch, we first train the model with standard data augmentation with 5 epochs and then switch to MaxUp.</p><p>Time and Memory Cost MaxUp only slightly increase the time and memory cost compared with standard training. During MaxUp, we only need to find the worst instance out of the m augmented copies through forward-propagation, and then only back-propagate on the worst instance. Therefore, the additional cost of MaxUp over standard training is m forward-propagation, which introduces no significant overhead on both memory and time cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">ImageNet</head><p>We evaluate MaxUp on ILSVRC2012, a subset of Im-ageNet classification dataset <ref type="bibr" target="#b4">(Deng et al., 2009</ref>  <ref type="table">Table 2</ref>. Top1 accuracies of different models on the validation set of ImageNet 2012. The " * " indicates that MaxUp is applied to the pre-trained model and trained for 5 epochs.</p><p>CutMix randomly cuts and pasts patches among training images, while the ground truth labels are also mixed proportionally to the area of the patches. MaxUp+CutMix applies CutMix on one image for m times (cutting different randomly sampled patches), and select the worst case to do backpropagation.</p><p>We test our method on ResNet-50, ResNet-101 <ref type="bibr" target="#b11">(He et al., 2016b)</ref>, as well as recent energy-efficient architectures, including ProxylessNet <ref type="bibr" target="#b0">(Cai et al., 2019)</ref> and Efficient-Net . We resize the images to 600 × 600 and 845 × 845 for EfficientNet-B7 and EfficientNet-B8, respectively , for which we process the images with the data processing pipelines proposed by <ref type="bibr" target="#b26">Touvron et al. (2019)</ref>. For the other models, the input image size is 224 × 224. To save computation resources, we only fine-tune the pre-trained models with MaxUp for a few epochs. We set m = 4 for MaxUp in the ImageNet-2012 experiments unless indicated otherwise. This means that we optimize the worst case in 4 augmented samples for each image.</p><p>For ResNet-50, ResNet-101 and ProxylessNets, we train the models for 20 epochs with learning rate 10 −5 and batch size 256 on 4 GPUs for 20 epochs. For EfficientNet, we fix the parameters in the batch normalization layers and train the other parameters with learning rate 10 −4 and batch size 1000 for 5 epochs.</p><p>As shown in <ref type="table">Table 2</ref>, for ResNet-50 and ResNet-101, we achieve the best results among all the data augmentation method. For EfficientNet-B8, we further improve the stateof-the-art result on ImageNet with no extra data. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ResNet-50 on ImageNet</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">CIFAR-10 and CIFAR-100</head><p>We test MaxUp equipped with Cutout (DeVries &amp; Taylor, 2017) on CIFAR-10 and CIFAR-100, and denote it by MaxUp+Cutout. We conduct our method on several neural architectures, including ResNet-110 <ref type="bibr" target="#b11">(He et al., 2016b)</ref>, PreAct-ResNet-110 <ref type="bibr" target="#b10">(He et al., 2016a)</ref> and WideResNet-28-10 <ref type="bibr" target="#b35">(Zagoruyko &amp; Komodakis, 2016)</ref>. We set m = 10 for WideResNet and m = 4 for the other models. We use the public code 2 and keep their hyper-parameters. starts at 0.1 and is divided by 10 after 100 and 150 epochs for ResNet-110 and PreAct-ResNet-110. For WideResNet-28-10, we follow the settings in the original paper <ref type="bibr" target="#b35">(Zagoruyko &amp; Komodakis, 2016)</ref>, where the learning rate is divided by 10 after 60, 120 and 180 epochs. Weight decay is set to 2.5 −4 for all the models, and we do not use dropout.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>The results on CIFAR-10 and CIFAR-100 are summarized in <ref type="table">Table 3 and Table 4</ref>. We can see that the models trained using MaxUp+Cutout significantly outperform the standard Cutout for all the cases.</p><p>On CIAFR-10, MaxUp improves the standard Cutout baseline from 94.84% ± 0.11% to 95.41% ± 0.08% on ResNet-110. It also improves the accuracy from 95.02% ± 0.15% to 95.52% ± 0.06% on PreAct-ResNet-110.</p><p>On CIFAR-100, MaxUp obtains improvements by a large margin. On ResNet-110 and PreAct-ResNet-110, MaxUp improves the performance of Cutout from 73.64% ± 0.15% and 74.37% ± 0.13% to 75.26% ± 0.21% and 75.63% ± 0.26%, respectively. MaxUp+Cutout also improves the standard Cutout from 81.59% ± 0.27% to 82.48% ± 0.23% on WideResNet-28-10 on CIFAR-100.</p><p>Ablation Study We test MaxUp with different sample size m and investigate its impact on the performance on ResNet-100 (a relatively small model) and WideResNet-28-10 (a larger model). <ref type="table">Table 5</ref> shows the result when we vary the sample size in m ∈ {1, 4, 10, 20}. Note that MaxUp reduces to the naïve data augmentation method when m = 1. As shown in <ref type="table">Table 5</ref>, MaxUp with all m &gt; 1 can improve the result of standard augmentation (m = 1). Setting m = 4 or m = 10 achieves best performance on ResNet-110 , and m = 10 obtains best performance on WideResNet-28-10. We can see that the results are not sensitive once m is in a proper range (e.g., m ∈ [4 : 10]), and it is easy to outperform the standard data augmentation (m = 1) without much tuning of m. Furthermore, we suggest to use a large m for large models, and a small m for relatively small models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Language Modeling</head><p>For language modeling, we test MaxUp on two benchmark datasets: Penn Treebank (PTB) and Wikitext-2 (WT2). We use the code provided by <ref type="bibr" target="#b30">Wang et al. (2019)</ref> as our baseline 3 , which stacks a three-layer LSTM and implements a bag of regularization and optimization tricks for neural language modeling proposed by <ref type="bibr" target="#b18">Merity et al. (2018)</ref>, such as weight tying, word embedding drop and Averaged SGD.</p><p>For this task, we apply MaxUp using word embedding dropout <ref type="bibr" target="#b18">(Merity et al., 2018)</ref> as the random data augmentation method. Word embedding dropout implements dropout on the embedding matrix at the word level, where the dropout is broadcasted across all the embeddings of all the word vectors. For the selected words, their embedding vectors are set to be zero vectors. The other word embeddings in the vocabulary are scaled by 1 1−p , where p is the probability of embedding dropout.</p><p>As the word embedding layer serves as the first layer in a neural language model, we apply MaxUp in this layer. We do feed-forward for m times and select the worst case to do backpropagation for each given sentence. In this section, we set a small m = 2 since the models are already wellregularized by other regularization techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implement Details</head><p>The PTB corpus <ref type="bibr" target="#b17">(Marcus et al., 1993</ref>) is a standard dataset for benchmarking language models. It consists of 923k training, 73k validation and 82k test words. We use the processed version provided by <ref type="bibr" target="#b19">Mikolov et al. (2010)</ref> that is widely used for PTB.</p><p>The WT2 dataset is introduced in <ref type="bibr" target="#b18">Merity et al. (2018)</ref> as an alternative to PTB. It contains pre-processed Wikipedia articles, and the training set contains 2 million words.</p><p>The training procedure can be decoupled into two stages: 1) optimizing the model with SGD and averaged SGD (ASGD); 2) restarting ASGD for fine-tuning twice. We apply MaxUp in both stages, and report the perplexity scores at the end of the second stage. We also report the perplexity scores with a recently-proposed post-process method, dy-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Params Valid Test NAS-RNN <ref type="bibr" target="#b40">(Zoph &amp; Le, 2017)</ref> 54M -62.40 AWD-LSTM <ref type="bibr" target="#b18">(Merity et al., 2018)</ref> 24M 58.50 56.50 AWD-LSTM + FRAGE <ref type="bibr" target="#b8">(Gong et al., 2018)</ref> 24M 58.10 56.10 AWD-LSTM + MoS <ref type="bibr" target="#b32">(Yang et al., 2018)</ref> 22M 56.54 54.44 w/o dynamic evaluation ADV-AWD-LSTM  24M 57.15 55.01 ADV-AWD-LSTM + MaxUp 24M 56.25 54.27 + dynamic evaluation <ref type="bibr" target="#b13">(Krause et al., 2018)</ref> ADV-AWD-LSTM  24M 51.60 51.10 ADV-AWD-LSTM + MaxUp 24M 50.83 50.29 namical evaluation <ref type="bibr" target="#b13">(Krause et al., 2018)</ref> after the training process.</p><p>Results on PTB and WT2 The results on PTB and WT2 corpus are illustrated in <ref type="table">Table 6 and Table 7</ref>, respectively. We calculate the perplexity on the validation and test set for each method to evaluate its performance.</p><p>We can see that MaxUp outperforms the state-of-the-art results achieved by Frage <ref type="bibr" target="#b8">(Gong et al., 2018)</ref> and Mixture of SoftMax <ref type="bibr" target="#b32">(Yang et al., 2018)</ref>. We further compare MaxUp to the result of <ref type="bibr" target="#b30">Wang et al. (2019)</ref> based on AWD-LSTM <ref type="bibr" target="#b18">(Merity et al., 2018)</ref> at two checkpoints, with or without dynamic evaluation <ref type="bibr" target="#b13">(Krause et al., 2018</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Adversarial Certification</head><p>Modern image classifiers are known to be sensitive to small, adversarially-chosen perturbations on inputs <ref type="bibr" target="#b9">(Goodfellow et al., 2014)</ref>. Therefore, for making high-stakes decisions, it is of critical importance to develop methods with certified robustness, which provide (high probability) provable guarantees on the correctness of the prediction subject to arbitrary attacks within certain perturbation ball.</p><p>Recently, <ref type="bibr" target="#b1">Cohen et al. (2019)</ref> proposed to construct certifiably robust classifiers against ℓ 2 attacks by introducing Gaussian smoothing on the inputs, which is shown to outperform all the previous ℓ 2 -robust classifiers in CIFAR-10. There has been two major methods for training such smoothed classifiers: <ref type="bibr" target="#b1">Cohen et al. (2019)</ref> trains the classifier with a Gaussian data augmentation technique, while <ref type="bibr" target="#b21">Salman et al. (2019)</ref> improves the original Gaussian data augmentation by using PGD (projected gradient descent) adversarial training, in which PGD is used to find a local maximal within a given ℓ 2 perturbation ball.</p><p>In our experiment, we use MaxUp with Gaussian perturbation (referred to as MaxUp+Gauss) to train better ℓ 2 RADIUS (CIFAR-10) 0.25 0.5 0.75 1.0 1.25  <ref type="table">Table 8</ref>. Certified accuracy on CIFAR-10 of the best classifiers by different methods, evaluated against ℓ2 attacks of different radiuses.</p><p>smoothed classifiers than the methods by <ref type="bibr" target="#b1">Cohen et al. (2019)</ref> and <ref type="bibr" target="#b21">Salman et al. (2019)</ref>. Like how MaxUp improves upon standard data augmentation, it is natural to expect that our MaxUp+Gauss can learn more robust classifiers than the standard Gaussian data augmentation method in <ref type="bibr" target="#b1">Cohen et al. (2019)</ref>.</p><p>Training Details We applied MaxUp to Gaussian augmented data on CIFAR-10 with ResNet-110 <ref type="bibr" target="#b11">(He et al., 2016b)</ref>. We follow the training pipelines described in <ref type="bibr" target="#b21">Salman et al. (2019)</ref>. We set a batch size of 256, an initial learning rate of 0.1 which drops by a factor of 10 every 50 epochs, and train the models for 150 epochs.</p><p>Evaluation After training the smoothed classifiers, we evaluation the certified accuracy of different models under different ℓ 2 perturbation sets. Given an input image x and a perturbation region B, the smoothed classifier is called certifiably correct if its prediction is correct and has a guaranteed lower bound larger than 0.5 in B. The certified accuracy is the percentage of images that are certifiably correct. Following <ref type="bibr" target="#b21">Salman et al. (2019)</ref>, we calculate the certified accuracy of all the classifiers for various radius and report the best results overall of the classifiers. We use the codes provided by <ref type="bibr" target="#b1">Cohen et al. (2019)</ref> to calculate certified accuracy. 4</p><p>Following <ref type="bibr" target="#b21">Salman et al. (2019)</ref>, we select the best hyperparameters with grid search. The only two hyperparameters of our MaxUp+Gauss are the sample size m and the variance σ 2 of the Gaussian perturbation, which we search in m ∈ {5, 25, 50, 100, 150} and σ ∈ {0.12, 0.25, 0.5, 1.0}. In comparison, <ref type="bibr" target="#b21">Salman et al. (2019)</ref> requiers to search a larger number of hyper-parameters, including the number of steps of the PGD, the number of noise samples, the maximum ℓ 2 perturbation, and the variance of Gaussian data augmentation during training and testing. Overall, <ref type="bibr" target="#b21">Salman et al. (2019)</ref> requires to train and evaluate over 150 models for hyperparmeter tuning, while MaxUp+Gauss requires only 20 models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>We show the certified accuraries on CIFAR-10 in <ref type="table">Table 8</ref> under ℓ 2 attacks for each ℓ 2 radius. We find that MaxUp outperforms <ref type="bibr" target="#b1">Cohen et al. (2019)</ref> for all the ℓ 2 radiuses by a large margin. For example, MaxUp can im-4 https://github.com/locuslab/smoothing prove the certified accuracy at radius 0.25 from 60% to 74% and improve the 4% accuracy on radius 2.75 to 15%.</p><p>MaxUp also outperforms the PGD-based adversarial training of <ref type="bibr" target="#b21">Salman et al. (2019)</ref> for all the radiuses, boosting the accuracy from 14% to 17% at radius 2.5, and from 12% to 15% at radius 2.75.</p><p>In summary, MaxUp clearly outperforms both <ref type="bibr" target="#b1">Cohen et al. (2019)</ref> and <ref type="bibr" target="#b21">Salman et al. (2019)</ref>. MaxUp is also much faster and requires less hyperparameter tuning than <ref type="bibr" target="#b21">Salman et al. (2019)</ref>. Although the PGD-based method of <ref type="bibr" target="#b21">Salman et al. (2019)</ref> was designed to outperform the original method by <ref type="bibr" target="#b1">Cohen et al. (2019)</ref>, MaxUp+Gauss further improves upon <ref type="bibr" target="#b21">Salman et al. (2019)</ref>, likely because MaxUp with Gaussian perturbation is more compatible with the Gaussian smoothing based certification of <ref type="bibr" target="#b1">Cohen et al. (2019)</ref> than PGD adversarial optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we propose MaxUp, a simple and efficient training algorithms for improving generalization, especially for deep neural networks. MaxUp can be viewed as a introducing a gradient-norm smoothness regularization for Gaussian perturbation, but does not require to evaluate the gradient norm explicitly, and can be easily combined with any existing data augmentation methods. We empirically show that MaxUp can improve the performance of data augmentation methods in image classification, language modeling, and certified defense. Especially, we achieve SOTA performance on ImageNet.</p><p>For future works, we will apply MaxUp to more applications and models, such as BERT <ref type="bibr" target="#b5">(Devlin et al., 2019)</ref>. Furthermore, we will generalize MaxUp to apply mild adversarial optimization on feature and label spaces for other challenging tasks in machine learning, including transfer learning, semi-supervised learning.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>). This dataset contains around 1.3 million training images and 50,000 validation images. We follow the standard data processing pipeline including scale and aspect ratio distortions, random crops, and horizontal flips in training. During the evaluation, we only use the single-crop setting.</figDesc><table><row><cell>Model</cell><cell>Model Size</cell><cell>FLOPs</cell><cell cols="2">+CutMix (%) +MaxUp+CutMix (%)</cell></row><row><cell>ResNet-101</cell><cell>44.55M</cell><cell>7.85G</cell><cell>79.83</cell><cell>80.26</cell></row><row><cell>ProxylessNet-CPU</cell><cell>7.12M</cell><cell>481M</cell><cell>75.32</cell><cell>75.65</cell></row><row><cell>ProxylessNet-GPU</cell><cell>4.36M</cell><cell>470M</cell><cell>75.08</cell><cell>75.42</cell></row><row><cell>ProxylessNet-Mobile ×1.4 EfficientNet-B7</cell><cell>6.86M 66.35M</cell><cell>603M 38.20G</cell><cell>76.71 85.22  *</cell><cell>77.17 85.45  *</cell></row><row><cell>Fix-EfficientNet-B8</cell><cell>87.42M</cell><cell>101.79G</cell><cell>85.57  *</cell><cell>85.80  *</cell></row></table><note>Implementation Details We test MaxUp with P(·|x) defined by the CutMix data augmentation tech- nique (Yun et al., 2019) (referred to as MaxUp+CutMix).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1</head><label>1</label><figDesc>MaxUp obtains the state-of-the-art 85.80% top1 accuracy. The previous state-of-the-art top1 accuracy, 85.50%, is achieved by EfficientNet-L2.</figDesc><table><row><cell>compares a num-</cell></row><row><cell>ber of state-of-the-art regularization techniques with</cell></row><row><cell>MaxUp+CutMix on ImageNet with ResNet-50. 1 We can</cell></row><row><cell>see that MaxUp+CutMix achieves better performance com-</cell></row><row><cell>pared to all the strong data augmentation and regularization</cell></row><row><cell>baselines. From Table 1, we see that CutMix gives the best</cell></row><row><cell>top1 error (78.6%) among all the augmentation tasks, but</cell></row><row><cell>our method further improves it to 78.9%. DropBlock out-</cell></row></table><note>More Results on Different Architectures Table 2 shows the result of ImageNet on ResNet-101, ProxylessNet- CPU/GPU/Mobile (Cai et al., 2019) and EfficientNet. We can see that MaxUp consistently improves the results in all these cases. On ResNet-101, it improves the 79.83% baseline to 80.26%. On ProxylessNet-CPU and ProxylessNet-GPU, MaxUp enhances the 75.32% and 75.08% top1 accuracy to 75.65% and 75.42%, respectively. On ProxylessNet-Mobile, we improve the 76.71% top1 ac- curacy to 77.17%.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>ResNet-110 95.02 ± 0.15 95.52 ± 0.06 WideResNet-28-10 96.92 ± 0.16 97.18 ± 0.06 Table 3. Test accuracy on CIFAR10 for different architectures.</figDesc><table><row><cell>Model</cell><cell>+ Cutout</cell><cell>+ MaxUp+Cutout</cell><cell></cell><cell></cell></row><row><cell>ResNet-110 PreAct-Model</cell><cell>94.84 ± 0.11 + Cutout</cell><cell>95.41 ± 0.08 + MaxUp+Cutout</cell><cell></cell><cell></cell></row><row><cell cols="2">ResNet-110 PreAct-ResNet-110 74.37 ± 0.13 73.64 ± 0.15 WideResNet-28-10 81.59 ± 0.27</cell><cell>75.26 ± 0.21 75.63 ± 0.26 82.48 ± 0.23</cell><cell></cell><cell></cell></row><row><cell cols="3">Table 4. Test accuracy on CIFAR100 for different architectures.</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="4">Implementation Details For CIFAR-10 and CIFAR-</cell></row><row><cell></cell><cell></cell><cell cols="4">100, we use the standard data processing pipeline (mirror+</cell></row><row><cell></cell><cell></cell><cell cols="4">crop) and train the model with 200 epochs. All the results</cell></row><row><cell></cell><cell></cell><cell cols="4">reported in this section are averaged over five runs.</cell></row><row><cell></cell><cell></cell><cell cols="4">We train the models for 200 epochs on the training</cell></row><row><cell></cell><cell></cell><cell cols="4">set with 256 examples per mini-batch, and evaluate</cell></row><row><cell></cell><cell></cell><cell cols="4">the trained models on the test set. The learning rate</cell></row><row><cell></cell><cell></cell><cell>2 The</cell><cell>code</cell><cell>is</cell><cell>downloaded</cell><cell>from</cell></row><row><cell></cell><cell></cell><cell cols="4">https://github.com/junyuseu/pytorch-cifar-models</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 .Table 7 .</head><label>67</label><figDesc>Perplexities on the validation and test sets on the Penn Treebank dataset. Smaller perplexities refer to better language modeling performance. Params denotes the number of model parameters. Perplexities on the validation and test sets on the WikiText-2 dataset. Smaller perplexities refer to better language modeling performance. Params denotes the number of model parameters.</figDesc><table><row><cell>Method</cell><cell>Params</cell><cell>Valid</cell><cell>Test</cell></row><row><cell>AWD-LSTM (Merity et al., 2018)</cell><cell>33M</cell><cell>68.60</cell><cell>65.80</cell></row><row><cell>AWD-LSTM + FRAGE (Gong et al., 2018)</cell><cell>33M</cell><cell>66.50</cell><cell>63.40</cell></row><row><cell>AWD-LSTM + MoS (Yang et al., 2018)</cell><cell>35M</cell><cell>63.88</cell><cell>61.45</cell></row><row><cell>w/o dynamic evaluation</cell><cell></cell><cell></cell><cell></cell></row><row><cell>ADV-AWD-LSTM (Wang et al., 2019)</cell><cell>33M</cell><cell>63.68</cell><cell>61.34</cell></row><row><cell>ADV-AWD-LSTM + MaxUp</cell><cell>33M</cell><cell>62.48</cell><cell>60.19</cell></row><row><cell>+ dynamic evaluation (Krause et al., 2018)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>ADV-AWD-LSTM (Wang et al., 2019)</cell><cell>33M</cell><cell>42.36</cell><cell>40.53</cell></row><row><cell>ADV-AWD-LSTM + MaxUp</cell><cell>33M</cell><cell>41.29</cell><cell>39.61</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">All the FLOPS and model size reported in this paper is calculated by https://pypi.org/project/ptflops.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://github.com/ChengyueGongR/advsoft</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Proxylessnas</surname></persName>
		</author>
		<title level="m">Direct neural architecture search on target task and hardware. ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Certified adversarial robustness via randomized smoothing. ICML</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rosenfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Z</forename><surname>Kolter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Autoaugment</surname></persName>
		</author>
		<title level="m">Learning augmentation policies from data. CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Randaugment: Practical data augmentation with no separate search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.13719</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Improved regularization of convolutional neural networks with cutout</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.04552</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Dropblock: A regularization method for convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ghiasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="10727" to="10737" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Frage: Frequency-agnostic word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1334" to="1345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Explaining and harnessing adversarial examples. ICLR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Identity mappings in deep residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="630" to="645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Bounds on the expectation of the maximum of samples from a gaussian</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kamath</surname></persName>
		</author>
		<ptr target="http://www.gautamka-math.com/writings/gaussianmax.pdf" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Dynamic evaluation of neural sequence models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kahembwe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Renals</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">ICML</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Fractalnet: Ultra-deep neural networks without residuals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Larsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Shakhnarovich</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Bag of tricks and a strong baseline for deep person reidentification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPRW</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="0" to="0" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Towards deep learning models resistant to adversarial attacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Madry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Makelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vladu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Building a large annotated corpus of english: The penn treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Santorini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Marcinkiewicz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Regularizing and optimizing lstm language models. ICLR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Merity</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">S</forename><surname>Keskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Recurrent neural network based language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Karafiát</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Burget</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Černockỳ</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Khudanpur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISCA</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Optimal non-asymptotic lower bound on the minimax regret of learning with expert advice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Orabona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pál</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.02176</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Provably robust deep learning via adversarially trained smoothed classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Salman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Razenshteyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bubeck</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Adversarially robust generalization requires more data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Santurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Madry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5014" to="5026" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Training region-based object detectors with online hard example mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="761" to="769" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Efficientnet</surname></persName>
		</author>
		<title level="m">Rethinking model scaling for convolutional neural networks. ICML</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jégou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.06423</idno>
		<title level="m">Fixing the train-test resolution discrepancy</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Ensemble adversarial training: Attacks and defenses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tramèr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Boneh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mcdaniel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Robustness may be at odds with accuracy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Santurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Engstrom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Madry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Beckham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Mitliagkis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manifold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mixup</surname></persName>
		</author>
		<title level="m">Encouraging meaningful on-manifold interpolation as a regularizer. ICML</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Improving neural language modeling via adversarial training. ICML</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.09665</idno>
		<title level="m">Adversarial examples improve image recognition</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Breaking the softmax bottleneck: A high-rank RNN language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Rademacher complexity for adversarially robust generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bartlett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7085" to="7094" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cutmix</surname></persName>
		</author>
		<title level="m">Regularization strategy to train strong classifiers with localizable features. ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Wide residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<meeting><address><addrLine>Septem</addrLine></address></meeting>
		<imprint>
			<publisher>BMVA Press</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="87" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">mixup: Beyond empirical risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Theoretically principled trade-off between robustness and accuracy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">E</forename><surname>Ghaoui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<editor>Chaudhuri, K. and Salakhutdinov, R.</editor>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7472" to="7482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhong</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Z. Adversarial autoaugment. ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Freelb</surname></persName>
		</author>
		<title level="m">Enhanced adversarial training for language understanding. ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Neural architecture search with reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
