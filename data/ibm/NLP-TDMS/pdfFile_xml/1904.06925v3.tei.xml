<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Comprehensive Correlation Mining for Image Clustering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Wu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keyu</forename><surname>Long</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of EECS</orgName>
								<orgName type="laboratory">SenseTime Research 3 Key Laboratory of Machine Perception (MOE)</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of EECS</orgName>
								<orgName type="laboratory">SenseTime Research 3 Key Laboratory of Machine Perception (MOE)</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Qian</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of EECS</orgName>
								<orgName type="laboratory">SenseTime Research 3 Key Laboratory of Machine Perception (MOE)</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Li</surname></persName>
							<email>chengli@sensetime.com</email>
							<affiliation key="aff1">
								<orgName type="department">School of EECS</orgName>
								<orgName type="laboratory">SenseTime Research 3 Key Laboratory of Machine Perception (MOE)</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouchen</forename><surname>Lin</surname></persName>
							<email>zlin@pku.edu.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongbin</forename><surname>Zha</surname></persName>
							<email>zha@cis.pku.edu.cn</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Shandong University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Deep Comprehensive Correlation Mining for Image Clustering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T19:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent developed deep unsupervised methods allow us to jointly learn representation and cluster unlabelled data. These deep clustering methods mainly focus on the correlation among samples, e.g., selecting high precision pairs to gradually tune the feature representation, which neglects other useful correlations. In this paper, we propose a novel clustering framework, named deep comprehensive correlation mining (DCCM), for exploring and taking full advantage of various kinds of correlations behind the unlabeled data from three aspects: 1) Instead of only using pairwise information, pseudo-label supervision is proposed to investigate category information and learn discriminative features. 2) The features' robustness to image transformation of input space is fully explored, which benefits the network learning and significantly improves the performance.</p><p>3) The triplet mutual information among features is presented for clustering problem to lift the recently discovered instance-level deep mutual information to a triplet-level formation, which further helps to learn more discriminative features. Extensive experiments on several challenging datasets show that our method achieves good performance, e.g., attaining 62.3% clustering accuracy on CIFAR-10, which is 10.1% higher than the state-of-the-art results 1 .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Clustering is one of the fundamental tasks in computer vision and machine learning. Especially with the development of the Internet, we can easily collect thousands of images and videos every day, most of which are unlabeled. It is very expensive and time-consuming to manually label these data. In order to make use of these unlabeled data and investigate their correlations, unsupervised clustering draws much attention recently, which aims to categorize similar data into one cluster based on some similarity measures. * Equal contribution and the work was done during interns at SenseTime Research <ref type="bibr" target="#b0">1</ref>    <ref type="bibr" target="#b8">[9]</ref> on CIFAR-10 <ref type="bibr" target="#b28">[29]</ref>. Best viewed in color! Image clustering is a challenging task due to the image variance of shape and appearance in the wild. Traditional clustering methods <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b6">7]</ref>, such as K-means, spectral clustering <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b50">51]</ref>, and subspace clustering <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b16">17]</ref> may fail for two main issues: first, hand-crafted features have limited capacity and cannot dynamically adjust to capture the prior distribution, especially when dealing with large-scale real-world images; second, the separation of feature extraction and clustering will make the solution sub-optimal. Recently, with the booming of deep learning <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b53">54]</ref>, many researchers shift their attention to deep unsupervised feature learning and clustering <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b8">9]</ref>, which can well solve the aforementioned limitations. Typically, to learn a better representation, <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b54">55]</ref> adopt the auto-encoder and <ref type="bibr" target="#b22">[23]</ref> maximizes the mutual information between features. DAC <ref type="bibr" target="#b8">[9]</ref> constructs positive and negative pairs to guide network training.</p><p>However, for these methods, several points are still missing. Firstly, feature representations that only consider reconstruction or mutual information lack discriminative power. Secondly, traditional cluster method like K-means effectively use category assumption on data. Contrast to that, DAC only focuses on pair-wise correlation and neglects the category information, which limits its performance. Thirdly, there are also other correlations that are helpful for deep image feature learning, for example, <ref type="bibr" target="#b31">[32]</ref> shows that measuring feature equivariance can benefit image representation understanding.</p><p>To tackle above issues, as shown in <ref type="figure" target="#fig_0">Figure 1</ref>(a), we propose a novel method, namely deep comprehensive correlation mining (DCCM), which comprehensively explores correlations among different samples (red line), local robustness to geometry transformation (yellow line), between different layer features of the same sample (blue line), and their inter-correlations (green lines) to learn discriminative representations and train the network in a progressive manner. First of all, for the correlation among different samples, we adopt the deep convolutional neural network (CNN) to generate prediction feature for the input image. With proper constraints, the learned prediction feature will tend to be one-hot. Then we can compute the cosine similarity and construct the similarity graph. Based on the similarity graph and prediction feature, we assign a large threshold to get highly-confident pseudo-graph and pseudo-label to guide the feature learning. Secondly, for the local robustness to small perturbations, we add small perturbation or transformation on the original input image to generate a transformed image. Under the local robustness assumption, the prediction of the transformed image should be consistent with that of the original image. So we can use the prediction of the original image to guide the feature learning of the transformed image. Thirdly, feature representation of deep layer should preserve distinct information of the input. So we maximize the mutual information between the deep layer feature and shallow layer feature of the same sample. To make the representation more discriminative, we further extend it to a triplet form by incorporating the graph information above. Finally, we combine the loss function of these three different aspects and jointly investigate these correlations in an end-to-end way. Results in <ref type="figure" target="#fig_0">Figure 1</ref>(c) show the superiority of our method (purple curve) over the state-of-the-art method DAC <ref type="bibr" target="#b8">[9]</ref> (red curve).</p><p>Our main contributions are summarized as follows:</p><p>1) We propose a novel end-to-end deep clustering framework to comprehensively mine various kinds of correlations, and select highly-confident information to train the network in a progressive way;</p><p>2) We first derive the rationality of pseudo-label and introduce the highly-confident pseudo-label loss to di-rectly investigate the category information and guide the unsupervised training of deep network;</p><p>3) We make use of the local robustness assumption and utilize above pseudo-graph and pseudo-label to learn better representation; 4) We extend the instance-level mutual information to triplet-level, and come up with triplet mutual information loss to learn more discriminative features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Deep Clustering</head><p>Existing deep clustering methods <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b8">9]</ref> mainly aim to combine the deep feature learning <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b56">57]</ref> with traditional clustering methods <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b6">7]</ref>. Autoencoder (AE) <ref type="bibr" target="#b2">[3]</ref> is a very popular feature learning method for deep clustering, and many methods are proposed to minimize the loss of traditional clustering methods to regularize the learning of latent representation of auto-encoder. For example, <ref type="bibr" target="#b52">[53,</ref><ref type="bibr" target="#b20">21]</ref> proposes the deep embedding clustering to utilize the KL-divergence loss. <ref type="bibr" target="#b17">[18]</ref> also uses the KLdivergence loss, but adds a noisy encoder to learn more robust representation. <ref type="bibr" target="#b54">[55]</ref> adopts the K-means loss, and <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b43">44]</ref> incorporate the self-representation based subspace clustering loss.</p><p>Besides the auto-encoder, some methods directly design specific loss function based on the last layer output. <ref type="bibr" target="#b55">[56]</ref> introduces a recurrent-agglomerative framework to merge clusters that are close to each other. <ref type="bibr" target="#b8">[9]</ref> explores the correlation among different samples based on the label features, and uses such similarity as supervision. <ref type="bibr" target="#b46">[47]</ref> extends the spectral clustering into deep formulation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Deep Unsupervised Feature Learning</head><p>Instead of clustering, several approaches <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b51">52]</ref> mainly focus on deep unsupervised learning of representations. Based on Generative Adversarial Networks (GAN), <ref type="bibr" target="#b12">[13]</ref> proposes to add an encoder to extract visual features. <ref type="bibr" target="#b3">[4]</ref> directly uses the fixed targets which are uniformly sampled from a unit sphere to constrain the deep features assignment. <ref type="bibr" target="#b7">[8]</ref> utilizes the pseudo-label computed by the K-means on output features as supervision to train the deep neural networks. <ref type="bibr" target="#b22">[23]</ref> proposes the deep infomax to maximize the mutual information between the input and output of a deep neural network encoder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Self-supervised Learning</head><p>Self-supervised learning <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b27">28]</ref> generally needs to design a pretext task, where a target objective can be computed without supervision. They assume that the learned representations of the pretext task contain high-level semantic information that is useful for solving downstream tasks of interest, such as image classification. For example, <ref type="bibr" target="#b11">[12]</ref> tries to predict the relative location of image patches, and <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b39">40]</ref> predict the permutation of a jigsaw puzzle created from the full image. <ref type="bibr" target="#b14">[15]</ref> regards each image as an individual class and generates multiple images of it by data augmentation to train the network. <ref type="bibr" target="#b18">[19]</ref> rotates an image randomly by one of four different angles and lets the deep model predict the rotation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Deep Comprehensive Correlation Mining</head><p>Without labels, correlation stands in the most important place in deep clustering. In this section, we first construct pseudo-graph to explore binary correlation between samples to start the network training. Then we propose the pseudo-label loss to make full use of category information behind the data. Next, we mine the local robustness of predictions before and after adding transform on input image. We also lift the instance level mutual information to triplet level to make it more discriminative. Finally, we combine them together to get our proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Preliminary: Pseudo-graph Supervision</head><p>We first compute the similarity among samples and select highly-confident pair-wise information to guide the network training by constructing pseudo-graph. Let X = {x i } N i=1 be the unlabeled dataset, where x i is the i-th image and N is the total number of images. Denote K as the total number of classes. We aim to learn a deep CNN based mapping function f which is parameterized by θ. Then we can use z i = f θ (x i ) ∈ R K to represent the prediction feature of image x i after the softmax layer of CNN. It has the following properties: K t=1 z it = 1, ∀i = 1, · · · , N, and z it ≥ 0, ∀t = 1, · · · , K. (1)</p><p>Based on the label feature z, the cosine similarity between the i-th and the j-th samples can be computed by S ij = zi·zj zi 2 zj 2 , where · is the dot production of two vectors. Similar to DAC <ref type="bibr" target="#b8">[9]</ref>, we can construct the pseudo-graph W by setting a large threshold thres 1 :</p><formula xml:id="formula_0">W ij = 1, if s ij ≥ thres 1 , 0, otherwise.<label>(2)</label></formula><p>If the similarity between two samples is larger than the threshold, then we judge that these two samples belong to the same class (W ij = 1), and the similarity of these samples should be maximized. Otherwise (W ij = 0), the similarity of these samples should be minimized. The pseudograph supervision can be defined by:</p><formula xml:id="formula_1">2 min θ L P G (θ) = xi,xj ∈X g (f θ (x i ), f θ (x j ); W ij ). (3)</formula><p>2 For the loss function g , there are many choices, such as the contrastive Siamese net loss <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b34">35]</ref> regularizing the distance between two samples, and the binary cross-entropy loss <ref type="bibr" target="#b8">[9]</ref> regularizing the similarity.</p><p>Please note that there are two differences between our pseudo-graph and that in DAC <ref type="bibr" target="#b8">[9]</ref>: 1) Unlike the strong 2 -norm constrain in DAC, we relax this assumption which only needs to take the output after softmax layer. This relaxation increases the capacity of labeling feature and finally induces a better result in our experiment. 2) Instead of dynamically decreasing threshold in DAC, we only need a fixed threshold of thres 1 . This prevents the training from the disadvantage caused by noisy false positive pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Pseudo-label Supervision</head><p>The correlation explored in pseudo-graph is not transitive and limited to pair-wise samples. Towards this issue, in this subsection, we propose the novel pseudo-label loss and prove its rationality. We first prove the existence of K-partition of the pseudo-graph, which could be naturally regarded as pseudo-label. And then we state that this partition would make the optimal solution θ * in Eq. (3) lead to one-hot prediction, which formulates the pseudo-label. Finally, the pseudo-label loss will be introduced to optimize convolutional neural networks. Existence of K-partition. The binary relation W ij between samples x i and x j defined in Eq. <ref type="formula">(3)</ref> is not transitive: W ij is not deterministic given W ik and W jk , and this may lead to unstability in training. Therefore, we introduce Lemma (1) to extend it to a stronger relation. Lemma 1. For any weighted complete graph G = (V, E) with weight ω(e) for edge e, if ω(e i ) = ω(e j ) for ∀i = j, then there exists a threshold t that G t = (V, E t ) has exactly K partitions, where</p><formula xml:id="formula_2">E t = {e i |ω(e) &gt; t, e i ∈ E}.<label>(4)</label></formula><p>If we take the assumption that S ij is distinctive to each other in similarity graph S, it can be seen as a weighted complete graph under the assumption of Lemma <ref type="bibr" target="#b0">(1)</ref>. Then there exists a threshold t dividing X into exactly K partitions {P 1 , P 2 , · · · , P K }. Formulation of the Pseudo-label. Let x k denote the sample belongs to partition P k , and we can define a transitive relation δ as:</p><formula xml:id="formula_3">δ(x l i , x k j ) = 1, if l = k, 0, otherwise,<label>(5)</label></formula><p>which indicates that pairs with high cosine similarity are guaranteed to be in the same partition. This is to say, as the quality of similarity matrix S increases during training, this partition gets closer to the ground truth partition, therefore can be regarded as a target to guide and speed up training. Hence, we set the partition k of each x as its pseudo label.</p><p>The following claim reveals the relationship between the assigned pseudo-label and the prediction after softmax:  <ref type="figure">Figure 2</ref>. The pipeline of the proposed DCCM method. Based on the ideally one-hot prediction feature, we compute the highly-confident pseudo-graph and pseudo-label to guide the feature learning of both original and transformed samples, investigating both correlations among different samples and local robustness after small perturbation. Meanwhile, to investigate discriminative feature correspondence, the pseudo-graph is utilized to select highly-confident positive and negative pairs for triplet mutual information optimization. Claim 1. <ref type="bibr" target="#b2">3</ref> Let θ * denote the optimal solution to Eq. (3). If W has K partitions, then the prediction would be one-hot:</p><formula xml:id="formula_4">f θ * (x) = (0, · · · , 0, 1, 0, · · · , 0), for ∀x.<label>(6)</label></formula><p>Hence we can formulate our pseudo-label as:</p><formula xml:id="formula_5">y i = arg max k [f θ (x i )] k ,<label>(7)</label></formula><p>where [·] k denotes the k-th component of the prediction vector. Its corresponding probability of the predicted pseudolabel can be computed by</p><formula xml:id="formula_6">p i = max [f θ (x i )] k .</formula><p>In practice, f θ (x i ) does not strictly follow the one-hot property, since it is difficult to attain the optimal solution for the problem in Eq. (3) due to the non-convex property. So we also set a large threshold thres 2 for probability p i to select highlyconfident pseudo-label for supervision:</p><formula xml:id="formula_7">V i = 1, if p i ≥ thres 2 , 0, otherwise.<label>(8)</label></formula><p>V i = 1 indicates the predicted pseudo-label is highlyconfident, and only under this situation, will the pseudolabel y i of the i-th samples join the network training.</p><p>Pseudo-label Loss. The pseudo-label supervision loss is formulated as:</p><formula xml:id="formula_8">L P L (θ) = xi∈X V i · l (f θ (x i ), y i ) .<label>(9)</label></formula><p>The loss function l is often defined by the cross-entropy loss. By combining the supervision of highly-confident pseudo-graph and pseudo-label, we explore the correlation among different samples by minimizing:</p><formula xml:id="formula_9">L CDS = L P G (θ) + αL P L (θ),<label>(10)</label></formula><p>where α is a balance parameter. Those selected highlyconfident information can supervise the training of deep network in a progressive manner. <ref type="bibr" target="#b2">3</ref> The proof is presented in supplementary materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">The Local Robustness</head><p>An ideal image representation should be invariant to the geometry transformation, which can be regarded as the local robustness assumption. Mathematically, given an image sample x and a geometry transformation G, we denote x = G · x as the transformed sample, then a good feature extractor f θ should satisfy that these two samples have the same label and f θ (x) ≈ f θ (x ). Thus we can incorporate the distance between f θ (x) and f θ (x ) as a feature invariant loss as:</p><formula xml:id="formula_10">min θ N i=1 r (f θ (x i ), f θ (x i )) ,<label>(11)</label></formula><p>where r is the 2 -norm to measure the distance between predictions of original and transformed samples. x and G · x generated by the transformation can be regarded as the 'easy' positive pair, which can well stabilize the training and boost the performance. Moreover, please recall that for the original samples, we compute the pseudo-graph and pseudo-label as supervision. Instead of simply minimizing the distance of predictions, we hope the graph and label information computed based on transformed samples should be consistent with those of original samples. On the one hand, given an image x i with highly-confident pseudo-label y i , we also force x i has same pseudo-label. On the other hand, we also investigate the correlation among the transformed samples x with the highly-confident pseudo-graph W computed on the original samples x i , which is beneficial to increase the network robustness. The loss function to achieve above targets can be formulated as:</p><formula xml:id="formula_11">L LR = x i ,x j ∈X g (f θ (x i ), f θ (x j ); W ij )+α x i ∈X V i · l (f θ (x i ), y i ) = L P G (θ) + αL P L (θ),<label>(12)</label></formula><p>where</p><formula xml:id="formula_12">X = {x i } N i=1</formula><p>is the transformed data set, W and V are same to those of original set in Eqs. <ref type="formula" target="#formula_0">(2)</ref> and <ref type="formula" target="#formula_7">(8)</ref>.</p><p>The deep unsupervised learning can benefit a lot from the above strategy. As we set high confidence for the construction of pseudo-graph and pseudo-label, it can be regarded as the easy sample, which will contribute little to the parameter learning <ref type="bibr" target="#b15">[16]</ref>. By adding small perturbation, the prediction of transformed sample will not be easy as that of original sample, which will contribute a lot in return.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Triplet Mutual Information</head><p>In this section, we explore the correlation between deep and shallow layer representations of each instance and propose a novel loss, named triplet mutual information loss, to make full use of the feature correspondence information. Firstly, we introduce the mutual information loss which is proposed in <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b22">23]</ref> and analyze its limitation. Next, the concept of triplet correlations is described. Finally, we propose the triplet mutual information loss that enables convolutional neural networks to learn discriminative features.</p><p>The mutual information (MI) between deep and shallow layer features of the same sample should be maximized, which guarantees the consistency of representation. Similar to <ref type="bibr" target="#b40">[41]</ref>, we also convert the MI of two random variables (D and S) to the Jensen-Shannon divergence (JSD) between samples coming from the joint distribution J and their product of marginals M. Correspondingly, features of different layers should follow the joint distribution only when they are features of the same sample, otherwise, they follow the marginal product distribution. So JSD version MI is defined as:</p><formula xml:id="formula_13">MI (JSD) (D, S) = E J [−sp(−T (d, s))]−E M [sp(T (d, s))],<label>(13)</label></formula><p>where d corresponds to the deep layer features, s corresponds to the shallow layer features, T is a discriminator trained to distinguish whether d and s are sampled from the joint distribution or not, and sp(z) = log(1 + e z ) is the softplus function. For discriminator implementation, <ref type="bibr" target="#b22">[23]</ref> shows that incorporating knowledge about locality in the input can improve the representations' quality.</p><p>Please note that currently, we do not incorporate any class information. For two different samples x 1 and x 2 , the mutual information between x 1 's shallow-layer representation and x 2 's deep-layer representation will be minimized even if they belong to the same class, which is not reasonable. So we consider fixing this issue by introducing the mutual information loss of positive pairs. As shown in the bottom right of <ref type="figure">Figure 2</ref>, with the generated pseudo-graph W described in Section 3.1, we select positive pairs and negative pairs with the same anchor to construct triplet correlations. Analogous to supervised learning, this approach lifts the instance-level mutual information supervision to triplet-level supervision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Deep Comprehensive Correlation Mining</head><p>Input: Unlabeled dataset X = {x i } N i=1 , thres 1 , thres 2 . 1: Initialize the network parameter θ randomly; 2: for t in [1, num epoches] do <ref type="bibr">3:</ref> for each minibatch X B do <ref type="bibr">4:</ref> Compute the prediction feature f (x i ) for each sample x i in the minibatch set X B ;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>Compute the similarity s ij , pseudo-graph W and pseudo-label based on Eqs. (2), <ref type="bibr" target="#b6">(7)</ref> and <ref type="formula" target="#formula_7">(8)</ref>; <ref type="bibr">6:</ref> Select positive and negative pairs based on W; <ref type="bibr">7:</ref> Compute the DCCM loss by Eq. (15); <ref type="bibr">8:</ref> Update θ using optimizers; <ref type="bibr">9:</ref> end for 10: end for Output: Compute the cluster label by Eq. <ref type="formula" target="#formula_5">(7)</ref>.</p><p>Then we show how this approach is theoretically formulated by extending Eq. <ref type="bibr" target="#b12">(13)</ref>. We set the samples of random variable D and S to be sets, instead of instances. Denote the deep layer feature of sample j belongs to class i as d i j and its shallow layer feature as s i j , then D i = {d i 1 , d i 2 , · · · , d i n } and S i = {s i 1 , s i 2 , · · · , s i n } are feature sets of class i. Variables D and S are defined by D = {D 1 , D 2 , · · · , D K } and S = {S 1 , S 2 , · · · , S K }, respectively. Then we can get the following extension of Eq. <ref type="formula" target="#formula_13">(13)</ref>:</p><formula xml:id="formula_14">L M I = −MI (JSD) set (D, S) = − E (D,S)=J [−sp(−T (d, s))] −E D×S=M [sp(T (d, s))]) ,<label>(14)</label></formula><p>where we investigate the mutual information based on classrelated feature sets. In this case, besides considering the features of same sample, we also maximize the mutual information between different layers' features for samples belongs to the same class. The overview of triplet mutual information loss is shown in the bottom right of <ref type="figure">Figure 2</ref>. Specifically, we compute the loss function in Eq. (14) by pair-wise sampling. For each sample, we construct the positive pairs and negative pairs based on the pseudo-graph W to compute the triplet mutual information loss, which is very helpful to learn more discriminative representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">The Unified Model and Optimization</head><p>By combining the investigations of these three aspects in above subsections and jointly train the network, we come up with our deep comprehensive correlation mining for unsupervised learning and clustering. The final objective function of DCCM can be formulated as:</p><formula xml:id="formula_15">min θ L DCCM = L P G + α L P L + βL M I ,<label>(15)</label></formula><p>where α and β are constants to balance the contributions of different terms, L P G = L P G + L P G is the overall pseudo-graph loss, and L P L = L P L + L P L is the overall pseudo-label loss. The framework of DCCM is presented in <ref type="figure">Figure 2</ref>. Based on the ideally one-hot prediction feature, we compute the highly-confident pseudo-graph and pseudolabel to guide the feature learning of both original and transformed samples, investigating both correlations among different samples and local robustness for small perturbation. In the meantime, to investigate feature correspondence for discriminative feature learning, the pseudo-graph is also utilized to select highly-confident positive and negative pairs for triplet mutual information optimization. Our proposed method can be trained in a minibatch based end-to-end way, which can be optimized efficiently. After the training, the predicted feature is ideally one-hot. The predicted cluster label for sample x i is exactly same to the pseudo-label y i , which is easily computed by Eq. <ref type="bibr" target="#b6">(7)</ref>. We summarize the overall training process in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>We distribute our experiments into a few sections. We first examine the effectiveness of DCCM by comparing it against other state-of-the-art algorithms. After that, we conduct more ablation studies by controlling several influence factors. Finally, we do a series of analysis experiments to verify the effectiveness of the unified model training framework. Next, we introduce the experimental setting. Datasets. We select six challenging image datasets for deep unsupervised learning and clustering, including the CIFAR-10 <ref type="bibr" target="#b28">[29]</ref>, CIFAR-100 <ref type="bibr" target="#b28">[29]</ref>, STL-10 [10], Imagenet-10, and ImageNet-dog-15, and Tiny-ImageNet <ref type="bibr" target="#b10">[11]</ref> datasets. We summarize the statistics of these datasets in <ref type="table" target="#tab_1">Table 1</ref>.</p><p>For the clustering task, we adopt the same setting as that in <ref type="bibr" target="#b8">[9]</ref>, where the training and validation images of each dataset are jointly utilized, and the 20 superclasses are considered for the CIFAR-100 dataset in experiments. ImageNet-10 and ImageNet-dog-15 used in our experiments are same as <ref type="bibr" target="#b8">[9]</ref>, where they randomly choose 10 subjects and 15 kinds of dog images from the ImageNet dataset, and resize these images to 96 × 96 × 3. As for the Tiny-ImageNet dataset, a reduced version of the ImageNet dataset <ref type="bibr" target="#b10">[11]</ref>, it totally contains 200 classes of 110, 000 images, which is a very challenging dataset for clustering.</p><p>For the transfer learning classification task, we adopt the similar setting as that in <ref type="bibr" target="#b22">[23]</ref>, where we mainly consider the CIFAR-10, CIFAR-100 of 100 classes. Training and testing samples are separated. Evaluation Metrics. To evaluate the performance of clustering, we adopt three commonly used metrics including normalized mutual information (NMI), accuracy (ACC), adjusted rand index (ARI). These three metrics favour different properties in clustering task. For details, please refer to the appendix. For all three metrics, the higher value indicates the better performance.</p><p>To evaluate the quality of feature representation, we adopt the non-linear classification task which is the same as that in <ref type="bibr" target="#b22">[23]</ref>. Specifically, after the training of DCCM, we fix the parameter of deep neural network and train a multilayer perception network with a single hidden layer (200 units) on top of the last convolutional layer and fully-connected layer features separately in a supervised way. Implementation Details. The network architecture used in our framework is a shallow version of the AlexNet (details for different datasets are described in the supplementary materials). Similar to <ref type="bibr" target="#b8">[9]</ref>, we adopt the RMSprop optimizer with lr = 1e −4 . For hyper-parameters, we set α = 5 and β = 0.1 for all datasets, which are relatively stable within a certain range. The thresholds to construct highlyconfident pseudo-graph and select highly-confident pseudolabel are set to 0.95 and 0.9, respectively. The small perturbations used in the experiments include rotation, shift, rescale, etc. For discriminator of mutual information estimation, we adopt the network with three 1 × 1 convolutional layers, which is same to <ref type="bibr" target="#b22">[23]</ref>. We use pytorch <ref type="bibr" target="#b42">[43]</ref> to implement our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Main Results</head><p>We first compare the DCCM with other state-of-the-art clustering methods on the clustering task. The results are shown in the <ref type="table" target="#tab_2">Table 2</ref>. Most results of other methods are directly copied from DAC <ref type="bibr" target="#b8">[9]</ref>. DCCM significantly surpasses other methods by a large margin on these benchmarks under all three evaluation metrics. Concretely, the improvement of DCCM is very significant even compared with the state-of-the-art method DAC <ref type="bibr" target="#b8">[9]</ref>. Take the clustering ACC for example, our result 0.623 is 10.1% higher than the performance 0.522 of DAC <ref type="bibr" target="#b8">[9]</ref> on the CIFAR-10 dataset. On the CIFAR-100 dataset, the gain of DCCM is 8.9% over DAC <ref type="bibr" target="#b8">[9]</ref>. <ref type="figure" target="#fig_2">Figure 3</ref> visualizes feature embeddings of the DCCM and DAC on CIFAR-10 using t-SNE <ref type="bibr" target="#b35">[36]</ref>. We can see that compared with DAC, DCCM exhibits more discriminative feature representation. Above results can sufficiently verify the effectiveness and superiority of our proposed DCCM.</p><p>To further evaluate the quality of feature representations, we adopt the classification task and compare DCCM with other deep unsupervised feature learning methods. We compare DCCM against several unsupervised feature learning  <ref type="bibr" target="#b19">[20]</ref> 0  methods, including variational AE (VAE) <ref type="bibr" target="#b26">[27]</ref>, adversarial AE (AAE) <ref type="bibr" target="#b36">[37]</ref>, BiGAN <ref type="bibr" target="#b12">[13]</ref>, noise as targets (NAT) <ref type="bibr" target="#b3">[4]</ref>, and deep infomax (DIM) <ref type="bibr" target="#b22">[23]</ref>. The top 1 non-linear classification accuracy comparison is presented in <ref type="figure" target="#fig_3">Figure 4</ref>. We can also observe that DCCM achieves much better results than other methods on CIFAR-10 and CIFAR-100 datasets. Especially on the CIFAR-10 dataset, our results on both convolutional and fully-connected layer features are more than 8% higher than these of the second best method DIM.</p><p>Since we incorporate the graph-based class information and transform the instance-level mutual information into the triplet-level, our method can learn much more discriminative features, which accounts for the obvious improvement. We also compare with several state-of-the-art methods under the same architecture and analyze the influence of various sampling strategy in the supplementary materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Correlation Analysis</head><p>We analyze the effectiveness of various correlations from three aspects: Local Robustness, Pseudo-label and Triplet Mutual Information in this section. The results are shown in <ref type="table" target="#tab_3">Table 3</ref>. Local Robustness Influence. The only difference between methods M2 and M1 lies in whether to use the local robustness mechanism or not. We can see that M2 significantly surpasses the M1, which demonstrates the robustness and effectiveness of local robustness. Because we set high threshold to select positive pairs, without transforma-  tion, these easy pairs have limited contribution to parameter learning. With the local robustness loss, we construct many hard sample pairs to benefit the network training. So it significantly boosts the performance. Effectiveness of Pseudo-label. With the help of pseudolabel, M3 (with both pseudo-graph and pseudo-label) achieves much better results than M2 (with only pseudograph) under all metrics. Specifically, there is a 7.1% improvement on clustering ACC. The reason is that pseudolabel can make full use of the category information behind the feature distribution, which can benefit the clustering. Triplet Mutual Information Analysis. Comparing the results of M4 and M3, we can see that the triplet mutual information can further improve the clustering ACC by 4.0%. As we analyzed in Section 3.4, with the help of pseudograph, triplet mutual information can not only make use of the features correspondence of the same sample, but also introduce discriminative property by constructing positive and negative pairs. So it can further improve the result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Overall Study of DCCM</head><p>In this section, we conducted experiments on CIFAR-10 <ref type="bibr" target="#b28">[29]</ref> to investigate the behavior of deep comprehensive correlations mining. The model is trained with the unified model optimization which is introduced in Section 3.5. BCubed Precision and Recall of Pseudo-graph. BCubed <ref type="bibr" target="#b0">[1]</ref> is a metric to evaluate the quality of partitions in clustering. We validate that our method can learn better representation in a progressive manner by using the BCubed <ref type="bibr" target="#b0">[1]</ref> precision and recall curves, which are computed based on the pseudo-graphs of different epochs in <ref type="figure" target="#fig_5">Figure 5</ref>. It is obvious that with the increasing of epochs, the precision of the pseudo-graph becomes much better, which will improve the clustering performance in return. Statistics of Prediction Features. According to Claim 1, the ideal prediction features have the one-hot property, so that we can use the highly-confident pseudo-label to guide the training. To verify it, we compare the distribution of the (a) Distribution of the largest probability  largest prediction probability between the initial stage and the final stage. The results on the CIFAR-10 dataset is presented in <ref type="figure" target="#fig_6">Figure 6(a)</ref>. For the CIFAR-10 dataset, the largest probability p is in the range of [0. <ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b0">1]</ref>. We count the probability in nine disjoint intervals, such as [0.1, 0.2], [0.2, 0.3], · · · , and [0.9, 1]. We can see that in the initial stage, less than 10% of all samples have the probability that is larger than 0.7, while after training, nearly 80% of all samples have the probability that is larger than 0.9. The above results imply that the largest probability tends to be 1, and others tend to be 0, which is consistent with our Claim 1. Influence of Thresholds. In <ref type="figure" target="#fig_6">Figure 6</ref>, we test the influence of threshold to select highly-confident pseudo-label for training. We can see that with the increase of threshold, the performance also increases. The reason is that with low threshold, some incorrect pseudo-label will be adopted for network training, which will affect the performance. So it is important to set relatively high threshold to select highlyconfident pseudo-label for supervision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>For deep unsupervised learning and clustering, we propose the DCCM to learn discriminative feature representation by mining comprehensive correlations. Besides the correlation among different samples, we also make full use of the mutual information between corresponding features, local robustness to small perturbations, and their intercorrelations. We conduct extensive experiments on several challenging datasets and two different tasks to thoroughly evaluate the performance. DCCM achieves significant improvement over the state-of-the-art methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Supplementary Material</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Proof of Lemma 1 and Claim 1</head><p>Proof of Lemma 1: Since ω(e i ) = ω(e j ) for ∀i = j, there exists a strongly increasing sequence of weights {ω 1 , ω 2 , · · · , ω N (N +1) 2 }, and we can remove edges from G in the order from smallest weight to largest by increasing threshold t. This action would either increase the current partition number n to n + 1 or remain it unchanged. At the beginning of the process we have 1 partition and at the end of the process we have N partitions. Since 1 ≤ K ≤ N , there exists a K partition in the process.</p><p>Proof of Claim 1: Select samples x 1 , x 2 , · · · , x K from partition P 1 , P 2 , · · · , P K , denote the cosine similarity matrix of their corresponding optimal features f θ * (x 1 ), f θ * (x 2 ), · · · , f θ * (x K ) as S, and S equals to its K partitions pseudo graph W, which is an identity matrix. De-</p><formula xml:id="formula_16">note f θ * (x i ) as [z 1 i , z 2 i , · · · , z K i ],</formula><p>where z k i denotes the k-th element of the vector z i .</p><p>The set {z 1 1 , z 2 1 , · · · , z K 1 , · · · , z 1 K , · · · , z K K } can only have no more than K positive elements, otherwise, according to Pigeonhole principle, there exists a k that z k i = z k j and cos(z i , z j ) &gt; 0, which is contradicted to S ij = 0.</p><p>On the other hand, for the output of a softmax layer, every vector has at least one positive entry. Therefore, every vector has and only has one positive element that equals to 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Defenitions of Metrics</head><p>We introduce the following three standarded metrics we used to evaluate our model:</p><p>• Normalized Mutual Information (NMI): Let C and C denote the predicted partition and the ground truth partition respectively, the NMI metric is calculated as:</p><formula xml:id="formula_17">NMI(C, C ) = K i=1 S j=1 |Ci ∩ C j | log N |C i ∩C j | |C i ||C j | ( K i=1 |Ci| log C i N )( S j=1 |C j | log C j N ) .<label>(16)</label></formula><p>• Adjusted Rand Index (ARI): Given a set S of n elements, and two groupings or partitions (e.g. clustering results) of these elements with r and s groups, namely X = {X 1 , X 2 , . . . , X r } and Y = {Y 1 , Y 2 , . . . , Y s }, the overlap between X and Y can be summarized in a contingency table [c ij ], where each element c ij denotes the number of objects in common between X i and Y j :</p><formula xml:id="formula_18">c ij = |X i ∩ Y j |.<label>(17)</label></formula><p>The contingent table is of the following shape:</p><formula xml:id="formula_19">X Y Y 1 Y 2 . . . Y s Sums X 1 c 11 c 12 . . . c 1s a 1 X 2 c 21 c 22 . . . c 2s a 2 . . . . . . . . . . . . . . . . . . X r c r1 c r2 . . . c rs a r Sums b 1 b 2 . . . b s</formula><p>and ARI is defined by:</p><formula xml:id="formula_20">ARI = ij nij 2 − [ i ai 2 j bj 2 ]/ n 2 1 2 [ i ai 2 + j bj 2 ] − [ i ai 2 j bj 2 ]/ n 2 .<label>(18)</label></formula><p>• Accuracy (ACC): Suppose the clustering algorithm is tested on N samples. For a sample x i , we denote its cluster label as r i and its ground truth as t i . The clustering accuracy is defined by:</p><formula xml:id="formula_21">ACC(R, T ) = N i=1 δ(t i , map(r i )) N ,<label>(19)</label></formula><p>where</p><formula xml:id="formula_22">δ(a, b) = 1, if a = b, 0, otherwise,<label>(20)</label></formula><p>and function map(x) denotes the best permutation mapping function gained by Hungarian algorithm [6].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Compared Methods</head><p>For clustering, we adopt both traditional methods and deep learning based methods, including Kmeans, spectral clustering (SC) <ref type="bibr" target="#b57">[58]</ref>, agglomerative clustering (AC) <ref type="bibr" target="#b19">[20]</ref>, the nonnegative matrix factorization (NMF) based clustering <ref type="bibr" target="#b6">[7]</ref>, auto-encoder (AE) <ref type="bibr" target="#b2">[3]</ref>, denoising auto-encoder (DAE) <ref type="bibr" target="#b47">[48]</ref>, GAN <ref type="bibr" target="#b45">[46]</ref>, deconvolutional networks (DECNN) <ref type="bibr" target="#b56">[57]</ref>, variational auto-encoding (VAE) <ref type="bibr" target="#b26">[27]</ref>, deep embedding clustering (DEC) <ref type="bibr" target="#b52">[53]</ref>, jointly unsupervised learning (JULE) <ref type="bibr" target="#b55">[56]</ref>, and deep adaptive image clustering (DAC) <ref type="bibr" target="#b8">[9]</ref>.</p><p>For classification task, we compare DCCM against several unsupervised feature learning methods, including variational auto-encoder (VAE) <ref type="bibr" target="#b26">[27]</ref>, adversarial auto-encoder (AAE) <ref type="bibr" target="#b36">[37]</ref>, BiGAN <ref type="bibr" target="#b12">[13]</ref>, noise as targets (NAT) <ref type="bibr" target="#b3">[4]</ref>, and deep infomax (DIM) <ref type="bibr" target="#b22">[23]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.">Architechtures Details</head><p>In <ref type="table">Table 6</ref>.1, we present the architectures for different datasets.</p><p>For CIFAR-10/CIFAR-100 <ref type="bibr" target="#b29">[30]</ref>, we set 4 conv layers and 3 pooling layers, followed with 2 fully-connected layers. Batch Normalization <ref type="bibr" target="#b23">[24]</ref> and ReLU are used on all  hidden layers. The output features after the second conv layer (S for shallow) and the first fc layer (D for deep) are used to compute the mutual information (MI) loss, concatenated as the input of discriminator. For other datasets, such as Tiny-ImageNet <ref type="bibr" target="#b10">[11]</ref> and STL-10 [10], we set 5 conv layers instead of 4. Due to their larger input size, we use the feature maps after the third conv layer as S. For all experiments, the output was a class num dimensional vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5.">Comparison Under the Same Architecture</head><p>In <ref type="table" target="#tab_6">Table 5</ref>, we present the additional comparisons using the same network. On CIFAR-10/100, DeepCluster does not work well based on its released official PyTorch code. DAC has similar performance with that in their paper. Our DCCM achieves the best results.</p><p>Please note that we only use a simple shallow version of AlexNet in the paper, and our results are much better than the best reported results of other methods.</p><p>Besides, our algorithm is relatively efficient. On CIFAR-100, it costs 19 hours for training on a single GTX 1080Ti GPU. Multiple GPU cards and better GPU can improve this.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6.">Sampling Strategy</head><p>The experiment result corresponding to the analysis in line 836-843 is listed in <ref type="table">Table 6</ref>. We tried four strategies to fetch positive and negative pairs from pseudo-graph W, <ref type="table">Table 6</ref>. Classification accuracy of different pair-sampling strategies on CIFAR-10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>Classification ACC(Y64) V1 nearest pos + random* neg 0.744 V2 nearest pos + farthest neg 0.713 V3 random* pos + random* neg 0.731 V4 top-n pos + random* neg 0.698 and the terms used in the table refer to:</p><p>• nearest means that for each sample, we select its nearest sample from the minibatch to construct a positive pair, while farthest means taking the farthest one to construct a negative pair.</p><p>• random* means that we randomly take a positive sample that satisfies W ij = 1 as a positive pair or a negative sample that satisfies W ij = 0 as a negative pair.</p><p>• top-n pos means that we select the top n confident pairs from the graph W to construct positive pairs.</p><p>For each strategy, we take n positive pairs and n negative pairs into account, where n is our batch size. This is to make sure that the computational complexity of each approach is nearly the same for fair comparison, while we also have explored more costly approaches and find that the improvement is negligible. To clearly illustrate how L M I is effected, here we set a fixed model trained with only L PG + L PL . Then with the pseudo-graph W generated by it, we train a new model using only L MI from scratch. It can be concluded that the positive pairs are sensitive to noise since strategy V1 achieves better results than V3, and harder negative pairs are beneficial for training as strategy V1 also achieves better results than V2. Besides, we also notice the importance of uniform sampling within the minibatch, as the top-n pairs in V4 has higher confidence than that in V1, but the training collapses since only part of samples in the batch are included in the top-n strategy.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Comprehensive correlations mining. (a) Various correlations; (b) Connect pair-wise items in higher semantic level progressively; (c) Better results of DCCM than the state-of-the-art DAC</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>.105 0.228 0.065 0.098 0.138 0.034 0.239 0.332 0.140 0.138 0.242 0.067 0.037 0.139 0.021 0.069 0.027 0.005 NMF<ref type="bibr" target="#b6">[7]</ref> 0.081 0.190 0.034 0.079 0.118 0.026 0.096 0.180 0.046 0.132 0.230 0.065 0.044 0.118 0.016 0.072 0.029 0.005 AE<ref type="bibr" target="#b2">[3]</ref> 0.239 0.314 0.169 0.100 0.165 0.048 0.250 0.303 0.161 0.210 0.317 0.152 0.104 0.185 0.073 0.131 0.041 0.007 DAE [48] 0.251 0.297 0.163 0.111 0.151 0.046 0.224 0.302 0.152 0.206 0.304 0.138 0.104 0.190 0.078 0.127 0.039 0.007 GAN [46] 0.265 0.315 0.176 0.120 0.151 0.045 0.210 0.298 0.139 0.225 0.346 0.157 0.121 0.174 0.078 0.135 0.041 0.007 DeCNN [57] 0.240 0.282 0.174 0.092 0.133 0.038 0.227 0.299 0.162 0.186 0.313 0.142 0.098 0.175 0.073 0.111 0.035 0.006 VAE [27] 0.245 0.291 0.167 0.108 0.152 0.040 0.200 0.282 0.146 0.193 0.334 0.168 0.107 0.179 0.079 0.113 0.036 0.006 JULE [56] 0.192 0.272 0.138 0.103 0.137 0.033 0.182 0.277 0.164 0.175 0.300 0.138 0.054 0.138 0.028 0.102 0.033 0.006 DEC [53] 0.257 0.301 0.161 0.136 0.185 0.050 0.276 0.359 0.186 0.282 0.381 0.203 0.122 0.195 0.079 0.115 0.037 0.007 DAC [9] 0.396 0.522 0.306 0.185 0.238 0.088 0.366 0.470 0.257 0.394 0.527 0.302 0.219 0.275 0.111 0.190 0.066 0.017 DCCM (ours) 0.496 0.623 0.408 0.285 0.327 0.173 0.376 0.482 0.262 0.608 0.710 0.555 0.321 0.383 0.182 0.224 0.108 0.038 (a) Initial stage of DCCM (b) Middle stage of DCCM (c) Final stage of DCCM (d) Final stage of DAC Visualizations of embeddings for different stages of DCCM and DAC on the CIFAR-10 dataset. Different colors denote various clusters. From (a) to (c), with the increasing of epochs, DCCM tends to progressively learn more discriminative features. Based on (c) and (d), features of DCCM are more discriminative than that of DAC.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Non-linear classification accuracy (top 1) results of different deep unsupervised feature learning methods on two datasets. 'Conv' denotes the features after the last convolutional layer, and 'Y(64)' denotes the 64-dimensional feature of fullyconnected layer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>BCubed precision and recall curves<ref type="bibr" target="#b0">[1]</ref> for the pseudographs of various epochs on CIFAR-10. These circle points on the lines correspond to the fixed pseudo-graph threshold 0.95 in experiments.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>The distribution of the largest probability in all prediction features and the influence of threshold for highly-confident pseudo-label on the CIFAR-10 dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Statistics of different datasets.</figDesc><table><row><cell>Dataset</cell><cell cols="3">Train Images Test Images Clusters Image size</cell></row><row><cell>CIFAR-10</cell><cell>50, 000</cell><cell>10, 000</cell><cell>10 32 × 32 × 3</cell></row><row><cell>CIFAR-100</cell><cell>50, 000</cell><cell cols="2">10, 000 20/100 32 × 32 × 3</cell></row><row><cell>STL-10</cell><cell>13, 000</cell><cell>-</cell><cell>10 96 × 96 × 3</cell></row><row><cell>ImageNet-10</cell><cell>13, 000</cell><cell>-</cell><cell>10 96 × 96 × 3</cell></row><row><cell cols="2">ImageNet-dog-15 19, 500</cell><cell>-</cell><cell>15 96 × 96 × 3</cell></row><row><cell>Tiny-ImageNet</cell><cell>100, 000</cell><cell>-</cell><cell>200 64 × 64 × 3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Clustering performance of different methods on six challenging datasets. The best results are highlighted in bold. ImageNet Methods\Metrics NMI ACC ARI NMI ACC ARI NMI ACC ARI NMI ACC ARI NMI ACC ARI NMI ACC ARI K-means 0.087 0.229 0.049 0.084 0.130 0.028 0.125 0.192 0.061 0.119 0.241 0.057 0.055 0.105 0.020 0.065 0.025 0.005 SC<ref type="bibr" target="#b57">[58]</ref> 0.103 0.247 0.085 0.090 0.136 0.022 0.098 0.159 0.048 0.151 0.274 0.076 0.038 0.111 0.013 0.063 0.022 0.004 AC</figDesc><table><row><cell>Datasets</cell><cell>CIFAR-10</cell><cell>CIFAR-100</cell><cell>STL-10</cell><cell>ImageNet-10</cell><cell>Imagenet-dog-15</cell><cell>Tiny-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Ablation study of DCCM on the CIFAR-10 dataset. LR, PL, and MI corresponds to local robustness, pseudo-label, and mutual information, respectively.</figDesc><table><row><cell></cell><cell>Methods</cell><cell>Correlations</cell><cell>Metrics</cell></row><row><cell></cell><cell></cell><cell cols="2">LR PL MI NMI ACC ARI</cell></row><row><cell>M1</cell><cell>LP G</cell><cell></cell><cell>0.304 0.405 0.232</cell></row><row><cell>M2</cell><cell>LP G</cell><cell></cell><cell>0.412 0.512 0.323</cell></row><row><cell>M3</cell><cell>LP G + LP L</cell><cell></cell><cell>0.448 0.583 0.358</cell></row><row><cell cols="2">M4 LP G + LP L + LMI</cell><cell></cell><cell>0.496 0.623 0.408</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 1 - 1</head><label>11</label><figDesc></figDesc><table><row><cell>0.05</cell><cell>0.1</cell><cell>0.3</cell><cell>0.5</cell><cell>0.7</cell><cell cols="2">0.9 0.95</cell><cell></cell><cell></cell><cell></cell></row><row><cell>0</cell><cell>0.1</cell><cell>0.3</cell><cell>0.5</cell><cell>0.7</cell><cell>0.9</cell><cell>1</cell><cell></cell><cell>ACC</cell><cell>NMI</cell><cell>ARI</cell></row><row><cell>ACC</cell><cell cols="5">0.522 0.535 0.552 0.573 0.623</cell><cell></cell><cell>0.65</cell><cell></cell><cell></cell></row><row><cell>NMI</cell><cell cols="5">0.415 0.445 0.458 0.475 0.496</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ARI</cell><cell cols="5">0.314 0.359 0.366 0.384 0.408</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.538</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>performance</cell><cell>0.425</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.313</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.2</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0</cell><cell cols="3">0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>threshold</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 .</head><label>4</label><figDesc>Network architecture for various datasets we used in experiments.</figDesc><table><row><cell>CIFAR-10 / CIFAR-100</cell><cell>Tiny-ImageNet</cell><cell>ImageNet-10/ImageNet-dog-15/STL-10</cell></row><row><cell>32×32×3</cell><cell>64×64×3</cell><cell>96×96×3</cell></row><row><cell>3×3 conv. 64 BN ReLU (S) 3×3 conv. 64 BN ReLU 2×2 MaxPooling with stride 2 3×3 conv. 128 BN ReLU 2×2 MaxPooling with stride 2 3×3 conv. 256 BN ReLU 4×4 AvgPooling with stride 2</cell><cell>5×5 conv. 64 BN ReLU 5×5 conv. 64 BN ReLU 4×4 MaxPooling with stride 4 (S) 3×3 conv. 128 BN ReLU 3×3 conv. 128 BN ReLU 4×4 MaxPooling with stride 4 1×1 conv. 256 BN ReLU 2×2 AvgPooling with stride 2</cell><cell>5×5 conv. 64 BN ReLU 5×5 conv. 64 BN ReLU 4×4 MaxPooling with stride 4 (S) 3×3 conv. 128 with BN ReLU 3×3 conv. 128 BN ReLU 4×4 MaxPooling with stride 4 1×1 conv. 256 with BN ReLU 4×4 AvgPooling with stride 4</cell></row><row><cell>(D) Linear(256, 64) BN ReLU</cell><cell>(D) Linear(256, 256) BN ReLU</cell><cell>(D) Linear(256, 64) BN ReLU</cell></row><row><cell>Linear(64, c)</cell><cell>Linear(256, c)</cell><cell>Linear(64, c)</cell></row><row><cell>SoftMax</cell><cell>SoftMax</cell><cell>SoftMax</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 .</head><label>5</label><figDesc>Result comparison under the same architecture (except the last layer of RotNet) on CIFAR-10/100. '&lt;' denotes 'less than'.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">CIFAR-10</cell><cell></cell><cell></cell><cell cols="2">CIFAR-100</cell></row><row><cell></cell><cell>NMI</cell><cell>Clustering ACC</cell><cell>ARI</cell><cell>Classify ACC</cell><cell>NMI</cell><cell>Clustering ACC</cell><cell>ARI</cell><cell>Classify ACC</cell></row><row><cell>RotNet [19]</cell><cell>0.316</cell><cell>0.389</cell><cell cols="3">0.139 0.755 0.208</cell><cell>0.225</cell><cell cols="2">0.070 0.453</cell></row><row><cell cols="2">DeepCluster [8] &lt;0.3</cell><cell>&lt;0.3</cell><cell cols="3">&lt;0.1 &lt;0.75 &lt;0.2</cell><cell>&lt;0.2</cell><cell cols="2">&lt;0.07 &lt;0.45</cell></row><row><cell>DAC [9]</cell><cell>0.439</cell><cell>0.514</cell><cell cols="3">0.335 0.787 0.228</cell><cell>0.254</cell><cell cols="2">0.121 0.485</cell></row><row><cell cols="2">DCCM (ours) 0.496</cell><cell>0.623</cell><cell cols="3">0.408 0.818 0.285</cell><cell>0.327</cell><cell cols="2">0.173 0.512</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A comparison of extrinsic clustering evaluation metrics based on formal constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enrique</forename><surname>Amigó</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Artiles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felisa</forename><surname>Verdejo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="461" to="486" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Cliquecnn: Deep unsupervised exemplar learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Miguel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Artsiom</forename><surname>Bautista</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekaterina</forename><surname>Sanakoyeu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bjorn</forename><surname>Tikhoncheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ommer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3846" to="3854" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Greedy layer-wise training of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Popovici</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="153" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Unsupervised learning by predicting noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="517" to="526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Signature verification using a&quot; siamese&quot; time delay neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jane</forename><surname>Bromley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Säckinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roopak</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="737" to="744" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Document clustering using locality preserving indexing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deng</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1624" to="1637" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Locality preserving nonnegative matrix factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deng</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hujun</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Deep clustering for unsupervised learning of visual features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Shiming Xiang, and Chunhong Pan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingfeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaofeng</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5879" to="5887" />
		</imprint>
	</monogr>
	<note>Deep adaptive image clustering</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An analysis of single-layer networks in unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="215" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Unsupervised visual representation learning by context prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1422" to="1430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Adversarial feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Krähenbühl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Discriminative unsupervised feature learning with exemplar convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jost</forename><forename type="middle">Tobias</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1734" to="1747" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Discriminative unsupervised feature learning with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jost</forename><forename type="middle">Tobias</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="766" to="774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep adversarial metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yueqi</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenzhao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2780" to="2789" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Sparse subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehsan</forename><surname>Elhamifar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">René</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE CVPR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="2790" to="2797" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep clustering via joint convolutional autoencoder embedding and relative entropy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amirhossein</forename><surname>Kamran Ghasedi Dizaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Herandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weidong</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5736" to="5745" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Unsupervised representation learning by predicting image rotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Agglomerative clustering using the concept of mutual nearest neighbourhood</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chidananda</forename><surname>Gowda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Krishna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="105" to="112" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Improved deep embedded clustering with local structure preservation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xifeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinwang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1753" to="1759" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning deep representations by mutual information estimation and maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>R Devon Hjelm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Fedorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karan</forename><surname>Lavoie-Marchildon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Grewal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03167</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deep subspace clustering networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pan</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongdong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="24" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Self-supervised visual feature learning with deep neural networks: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Longlong</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingli</forename><surname>Tian</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.06162</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Revisiting self-supervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.09005</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Citeseer</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Cifar-10 and cifar-100 datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinod</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<ptr target="https://www.cs.toronto.edu/kriz/cifar.html" />
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Understanding image representations by measuring their equivariance and equivalence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karel</forename><surname>Lenc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="991" to="999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Recurrent squeeze-and-excitation context aggregation net for single image deraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouchen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongbin</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="254" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Robust recovery of subspace structures by low-rank representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangcan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouchen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ju</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="171" to="184" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Smooth neighbors on teacher graphs for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yucen</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengxi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8896" to="8905" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alireza</forename><surname>Makhzani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendan</forename><surname>Frey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.05644</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">Adversarial autoencoders. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">On spectral clustering: Analysis and an algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="849" to="856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Unsupervised learning of visual representations by solving jigsaw puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Noroozi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Favaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="69" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Boosting self-supervised learning via knowledge transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Noroozi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ananth</forename><surname>Vinjimoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Favaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamed</forename><surname>Pirsiavash</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="9359" to="9367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">fgan: Training generative neural samplers using variational divergence minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Botond</forename><surname>Cseke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryota</forename><surname>Tomioka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="271" to="279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Deep roto-translation scattering for object classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Oyallon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stéphane</forename><surname>Mallat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2865" to="2873" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Automatic differentiation in pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Cascade subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Yun</forename><surname>Yau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhang</forename><surname>Yi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Deep subspace clustering with sparsity prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shijie</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Yun</forename><surname>Yau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJ-CAI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1925" to="1931" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06434</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Spectralnet: Spectral clustering using deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uri</forename><surname>Shaham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelly</forename><surname>Stanton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henry</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boaz</forename><surname>Nadler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronen</forename><surname>Basri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Kluger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Lajoie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre-Antoine</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="3371" to="3408" />
			<date type="published" when="2010-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Residual attention network for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengqing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honggang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3156" to="3164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Unsupervised joint mining of deep features and image labels for large-scale radiology image categorization and scene recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaosong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoo-Chang</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lauren</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammadhadi</forename><surname>Bagheri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabella</forename><surname>Nogues</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianhua</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald M</forename><surname>Summers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE WACV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="998" to="1007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Essential tensor learning for multi-view spectral clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouchen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongbin</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Unsupervised feature learning via non-parametric instance discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhirong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Stella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3733" to="3742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Unsupervised deep embedding for clustering analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyuan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="478" to="487" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Differentiable linearized admm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyu</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangcan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhisheng</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouchen</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6902" to="6911" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Towards K-means-friendly spaces: Simultaneous deep learning and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Nicholas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingyi</forename><surname>Sidiropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3861" to="3870" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Joint unsupervised learning of deep representations and image clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="5147" to="5156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Deconvolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Matthew D Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE CVPR</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="2528" to="2535" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Self-tuning spectral clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihi</forename><surname>Zelnik-Manor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="1601" to="1608" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
