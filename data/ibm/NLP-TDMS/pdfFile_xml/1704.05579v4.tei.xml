<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Large Self-Annotated Corpus for Sarcasm</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikhail</forename><surname>Khodak</surname></persName>
							<email>mkhodak@cs.princeton.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">Princeton University</orgName>
								<address>
									<addrLine>35 Olden St</addrLine>
									<postCode>08540</postCode>
									<settlement>Princeton</settlement>
									<country>New Jersey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikunj</forename><surname>Saunshi</surname></persName>
							<email>nsaunshi@cs.princeton.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">Princeton University</orgName>
								<address>
									<addrLine>35 Olden St</addrLine>
									<postCode>08540</postCode>
									<settlement>Princeton</settlement>
									<country>New Jersey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiran</forename><surname>Vodrahalli</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">Princeton University</orgName>
								<address>
									<addrLine>35 Olden St</addrLine>
									<postCode>08540</postCode>
									<settlement>Princeton</settlement>
									<country>New Jersey</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Large Self-Annotated Corpus for Sarcasm</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T11:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>sarcasm</term>
					<term>classification</term>
					<term>conversation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We introduce the Self-Annotated Reddit Corpus (SARC), a large corpus for sarcasm research and for training and evaluating systems for sarcasm detection. The corpus has 1.3 million sarcastic statements -10 times more than any previous dataset -and many times more instances of non-sarcastic statements, allowing for learning in both balanced and unbalanced label regimes. Each statement is furthermore self-annotated -sarcasm is labeled by the author, not an independent annotator -and provided with user, topic, and conversation context. We evaluate the corpus for accuracy, construct benchmarks for sarcasm detection, and evaluate baseline methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Sarcasm detection is an important component in many natural language processing (NLP) systems, directly relevant to natural language understanding, dialogue systems, and text mining. However, detecting sarcasm is difficult because it occurs infrequently and is difficult for even humans to discern <ref type="bibr" target="#b16">(Wallace et al., 2014)</ref>. Despite these properties, existing datasets either have balanced labels -data with roughly the same number of examples of each label <ref type="bibr" target="#b4">(González-Ibánez et al., 2011;</ref><ref type="bibr" target="#b2">Bamman and Smith, 2015;</ref><ref type="bibr" target="#b5">Joshi et al., 2015;</ref><ref type="bibr" target="#b0">Amir et al., 2016;</ref><ref type="bibr" target="#b9">Oraby et al., 2016)</ref> -or use humans to annotate sarcastic statements <ref type="bibr" target="#b13">(Riloff et al., 2013;</ref><ref type="bibr" target="#b14">Swanson et al., 2014;</ref><ref type="bibr" target="#b17">Wallace et al., 2015)</ref>. In this work, we make available the first corpus 1 for sarcasm detection that has both unbalanced and self-annotated labels and does not consist of short text snippets from Twitter 2 . With more than a million examples of sarcastic statements, each provided with author, topic, and contex information, the dataset exceeds all previous sarcasm corpora by an order of magnitude in size. This is possible due to the comment structure of the social media site Reddit 3 as well as its frequently-used and standardized annotation for sarcasm. Following a discussion of corpus construction and relevant statistics in Section 3, we discuss the quality of this dataset compared to alternative sources in Section 4, manually evaluating our corpus for noise. Then in Section 5 we use our dataset to construct suitable benchmarks for sarcasm detection systems and examine the performance of simple baseline methods and human evaluators on these subsets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Since our main contribution is a corpus and not a method for sarcasm detection, we point the reader to a recent survey by <ref type="bibr" target="#b6">Joshi et al. (2016)</ref> that discusses many interesting efforts in this area. Note that many of the works the authors mention will be discussed by us in this section, with many papers using their own datasets and illustrating the need for common evaluation baselines. Sarcasm datasets can largely be distinguished by the sources used to get sarcastic and non-sarcastic statements, the amount of human annotation, and whether the dataset is balanced or unbalanced. Reddit has been used before, notably by <ref type="bibr" target="#b17">Wallace et al. (2015)</ref>; while the authors allow unabalanced labeling, they do not exploit the possibility of using self-annotation and generate around 10,000 human-labeled sentences. Twitter is a frequent source due to the self-annotation provided by hashtags such as #sarcasm, #notsarcasm, and #irony <ref type="bibr" target="#b12">(Reyes et al., 2013;</ref><ref type="bibr" target="#b2">Bamman and Smith, 2015;</ref><ref type="bibr" target="#b5">Joshi et al., 2015)</ref>. As discussed in Section 4.2, its abbreviated language and other properties make Twitter a less attractive source for annotated comments. However, it is by far the largest raw source of data for this purpose and has led to some large unbalanced corpora in previous efforts <ref type="bibr" target="#b13">(Riloff et al., 2013;</ref><ref type="bibr" target="#b11">Ptácek et al., 2014)</ref>. A further source of comments is the Internet Argument Corpus (IAC) <ref type="bibr" target="#b15">(Walker et al., 2012)</ref>, a scraped corpus of Internet discussions that can be further annotated for sarcasm by humans or by machine learning; this is done by <ref type="bibr" target="#b7">Lukin and Walker (2013)</ref> and <ref type="bibr" target="#b9">Oraby et al. (2016)</ref>, in both cases resulting in around 10,000 labeled statements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Corpus Details</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Reddit Structure and Annotation</head><p>Reddit is a social media site in which users communicate by commenting on submissions, which are titled posts consisting of embedded media, external links, and/or text, that are posted on topic-specific forums known as subreddits; examples of subreddits include funny, pics, and science. Users comment on submissions and on other comments, resulting in tree-like conversation structure such that each comment has a parent comment. We refer to elements as any nodes in the tree of a Reddit link (i.e., comments or submissions). Reddit users have adopted a common method for sarcasm annotation consisting of adding the marker "/s" to the end of sarcastic statements; this originates from the HTML text delineation &lt;sarcasm&gt;...&lt;/sarcasm&gt;. As with Twitter hashtags, using these markers as indicators of sarcasm is noisy <ref type="bibr">(</ref>  <ref type="figure">Figure 1</ref>: A Reddit submission and one of its comments. Note the conventional annotation "/s" indicating sarcasm. many users do not use the marker, do not know about it, or only use it where sarcastic intent is not otherwise obvious. We discuss the extent of this noise in Section 4.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Constructing SARC</head><p>Reddit comments from December 2005 have been made available due to web-scraping 4 ; we construct our dataset as a subset of comments from January 2009-April 2017, comprising the vast majority of comments and excluding noisy data from earlier years. For each comment we provide a sarcasm label, author, the subreddit it appeared in, the comment score as voted on by users, the date of the comment, and identifiers linking back to the original dataset of all comments. To reduce noise, we use several filters to remove noisy and uninformative comments. Many of these are standard preprocessing steps such as excluding URLs and limiting characters to be ASCII. To handle Reddit data, we also exclude comments that are descendants of sarcastic comments in the conversation tree, as annotation in such cases is extremely noisy, with authors agreeing or disagreeing with the previously expressed sarcasm with their own sarcasm but often with no marking. Our raw corpus consists of three files:</p><p>1. An array in CSV format containing 533 million comments, of which around 1.3 million are sarcastic. This file only contains those comments whose authors know about the standard sarcasm annotation; this is determined by whether they have used the annotation in the same month as the comment was made or earlier. This limitation is added in order to reduce false negatives due to authors not annotating their sarcasm. Each row also contains the parent comment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">A hashtable in JSON format containing all comments</head><p>and posts in the conversation thread of a sarcastic comment as well as all siblings of sarcastic comments.</p><p>3. An array in CSV format, with each row containing a sequence of comments leading up to a sarcastic comment, the (sarcastic and non-sarcastic) responses to the last element in that sequence, and the labels of those responses. Each element is given as a key to the previous file.</p><p>This raw corpus is very large and suitable for both largescale machine learning and statistical analysis as well for deriving smaller benchmark tasks for evaluating sarcasm In addition to a million sarcastic comments our dataset also provides many millions more non-sarcastic statements by the same authors.</p><p>detection systems. These benchmarks, whether in the balanced or unbalanced regimes, require further subsampling of the corpus and an approach for dealing with noisy data in the face of sparse signals. We specify and evaluate an approach for doing so in Section 5.1, followed by the evaluation of learning algorithms on the output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Corpus Evaluation</head><p>There are three major metrics of interest for evaluating our corpora: (1) size, (2) the proportion of sarcastic to nonsarcastic comments, and (3) the rate of false positives and false negatives. Of interest is also the quality of the text in the corpus and its applicability to other NLP tasks. Thus in this section we evaluate error in the raw corpus and provide comparison with other corpora used to construct sarcasm datasets. We also discuss the potential limitations of our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Manual Evaluation</head><p>To investigate the noisiness of using Reddit as a source of self-annotated sarcasm we estimate the proportion of false positives and false negatives induced by our filtering. This is done by manually checking a random subset of 500 comments from SARC tagged as sarcastic and 500 tagged as non-sarcastic, with full access to the comment's context. A comment was determined to be false positive if "/s" tag was not an annotation but part of the sentence and a false negative if the comment author was clearly being sarcastic to the human rater. This procedure yielded a false positive rate of 1.0% and a false negative rate of 2.0%. Although the false positive rate is reasonable, the false negative rate is significant compared to the sarcasm proportion (0.25%), indicating large variation in the working definition of sarcasm and the need for methods that can handle noisy data in the unbalanced setting. In the balanced setting this is still a fairly small amount of noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Comparison with other Sources</head><p>As noted before, Twitter has been the most common source for sarcasm in previous corpora; this is likely due to the explicit annotation provided by its hashtags. However, using Reddit as a source of sarcastic comments holds many research advantages. Unlike Reddit comments, which are not <ref type="figure">Figure 2</ref>: Sarcasm percentage for subreddits with more than a million comments in SARC. Well-moderated and special-interest forums such as science and asoiaf (referring to fantasy series A Song of Ice and Fire) have less sarcasm than controversial and less-moderated subreddits.</p><p>constrained by length and contain fewer hashtags, tweets are written in abbreviated English. Hashtagged tokens are also frequently used as a part of the statement itself (e.g. "that was #sarcasm"), blurring the line between text and annotation; on Reddit "/s" is generally only used as something other than annotation when its use as an annotation is being referred to (e.g. "you forgot the /s"). The full conversation context is also much easier to provide on Reddit due to the shallow tree structure of an individual post and its comments. Furthermore, from a subsample of Twitter and Reddit data from July 2014 we determined that a vastly smaller percentage (.002% vs. .927%) of Twitter authors make use of sarcasm annotation (#sarcasm, #sarcastic, or #sarcastictweet). We hypothesize that Reddit users require sarcastic annotation more frequently and in a more standardized form because they are largely anonymous and so cannot rely on a shared context to communicate sarcasm. Finally, Reddit also benefits from having subreddits, which enable featurization and data exploration based on an explicit topic assignment.</p><p>The Internet Argument Corpus (IAC) has also been used as a source of sarcastic comments <ref type="bibr" target="#b15">(Walker et al., 2012)</ref>. The corpus developers found 12% of examples in the IAC to be sarcastic, which is a much nicer class proportion for sarcasm detection than ours. As the Reddit data consists of arbitrary conversations, not just arguments, it is not surprising that our sarcasm percentage is much smaller, even when accounting for false negatives; this property also makes our dataset more realistic. Unlike Reddit and Twitter, the IAC also requires manual annotation of sarcasm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Limitations of Our Approach</head><p>There are a few noteworthy limitations to our method of collecting a self-annotated sarcasm dataset. Despite our efforts to filter noisy "/s" labels, there remain instances where no simple rule reliably eliminates incorrect labels. We describe the difficulties for both false positives and false negatives:</p><p>• False positives are instances where a comment is incorrectly labeled as sarcastic due to the presence of a "/s" tag. This case only occurs when a "/s" tag appears in the comment with a meaning different from indicating sarcasm. As previously noted, this possibility is more likely to occur if a user is unaware of the "/s" notation. Similarly, if "/s" is used to refer to the convention of its use as an annotation, the naive approach of merely detecting the "/s" string also fails. Finally, it is possible that "/s" has other connotations: For instance, in HTML, &lt;s&gt;...&lt;/s&gt; denotes a strike-through. Therefore a subreddit focusing on the discussion of web programming, for example, might include instances where "/s" is used with a different meaning.</p><p>To combat the first issue, we restrict to users aware of the sarcasm notation by ensuring they have used "/s" previously. This filter helps ensure that the users are aware of the semantic usage of "/s". For the second case, we only keep comments which have the "/s" at the end of the comment. All comments we inspected which terminated in "/s" used the annotation to indicate sarcasm. The third case amounts to solving word sense disambiguation, and we did not find a universally simple approach to reduce noise of this form. However, it is possible to reduce the likelihood of this form of sense mismatch by restricting to subreddits which are known to not have alternate senses for "/s" (e.g., politics).</p><p>• False negatives are instances where a comment is sarcastic, but not annotated with a "/s". False negatives are harder to detect than false positives since the portion of comments which have no sarcasm annotation is much larger than the portion that do. There are two primary ways a false negative can arise: Either a user does not know of the "/s" convention, or the user believes their use of sarcasm is obvious enough to warrant not including the tag. Notably, such a belief depends on what community the user is communicating in, who the user is communicating with (another user they routinely have arguments with, or a stranger), and also on prior comments on the thread. As noted previously, a comment which is sarcastic often spawns a chain of subsequent comments which are all sarcastic, but which lack the "/s" symbol. In short, context matters a lot for determining whether or not a sarcastic comment is obvious.</p><p>The first issue is solved by our first filter. The second issue is difficult to address, and remains a limitation of our approach. We avoid the particular case of sarcastic comment chains by discarding the child comments of sarcastic comments in a thread.</p><p>All of our filters are validated by manual evaluation of the false positive and false negative rates as described in Section 4.1, which improved considerably after implementing the filters. Our manual evaluation approach has one central limitation: Though we provide local context to the human annotators, if the ability to distinguish the sarcastic intent of a comment relies on knowledge of, for instance, the   <ref type="table">Table 2</ref>: Accuracy percentage of baseline methods for sarcasm detection compared to human performance. Tests conducted in the balanced regime for the all subreddits task and balanced and unbalanced regimes for the politics subreddit task commenter's comment history or relevant news, then human annotators may not perform well. We tried to resolve this issue by using a voting scheme which required several humans to agree about whether or not a comment with its context was sarcastic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Benchmarks for Sarcasm Detection</head><p>A direct application of our corpus is for training and evaluating sarcasm detection systems. Thus we use the raw corpus described in Section 3 to construct several useful benchmarks for the task of classifying statements as sarcastic or non-sarcastic. All benchmarks provide the full conversation thread leading up to the target statements to the learning algorithm, along with comment metadata. Following their specification we consider a few context-free baseline methods depending only on linear classification over simple featurizations. Code to reproduce our results is provided at https://github.com/NLPrinceton/ SARC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Evaluation Task</head><p>In the most general case, we use the provided raw files to construct datapoints for systems to learn the following task: given a post and a sequence of comments, determine which comments among the responses to the last comment in the sequence are sarcastic. Thus each datapoint consists of a conversation thread followed by a series of responses and sarcasm labels. Performance on this task is measured by average precision, recall and F 1 scores. Before constructing this subcorpus we first remove from consideration all comments that are not complete sentences and not between 2 and 50 tokens long, allowing for cleaner comments in the evaluation. Although the responses are still largely non-sarcastic, the proportion of sarcastic comments is much greater here as each datapoint must correspond to a thread where at least one sarcastic annotation occurred. In total we construct 8.44 million sequences, with the average proportion of sarcastic responses being 28.1%. <ref type="figure">Figure 3</ref>: Score distributions of sarcastic and non-sarcastic comments in the raw SARC dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Balanced Labels</head><p>We construct a balanced learning task by taking only one sarcastic and one non-sarcastic response from each set of responses to a comment sequence. The task then becomes one of picking which of two statements that share a context is sarcastic, with performance measured by accuracy. While having only posts with at least one sarcastic response is useful, it also increases the false negative rate as comments warranting a sarcastic response often draw other sarcastic statements that are similar in content to the labeled sarcastic responses, but which themselves may not be labeled. Thus to reduce this issue when picking the nonsarcastic statement, we featurize all statements using the normalized sum of Common Crawl GloVe embeddings of the words and pick from only those non-sarcastic statements that have similarity ≤ 0.95 with the sarcastic statement <ref type="bibr" target="#b10">(Pennington et al., 2014)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Politics</head><p>The difficulty of detecting sarcasm rests not only on the need to understand the context of previous statements but also on understanding background information on the topic being discussed. Even humans will struggle with sarcastic comments drawn from unfamiliar topics, for instance, obscure hobbies or art forms. Thus we also test human and machine performance on comments drawn solely from the politics subreddit, a topic for which all evaluators had sufficient background information. This subsample contains 17 thousand sequences, with the average proportion of sarcastic responses being 23.2%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Methods</head><p>For the case of balanced labels, a simple, no-context baseline method for the above task is to featurize the two responses and to train a logistic regression classifier to distinguish between the sarcastic and non-sarcastic response as separate classes. On the testing set, we pick the response with the highest probability of being labeled sarcastic as the sarcastic one. We split both datasets we test on 80%-20% between train-test subsets and report the results of the following three approaches in <ref type="table">Table 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 4:</head><p>Length distributions of sarcastic and nonsarcastic comments in the raw SARC dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Bag-of-n-Grams</head><p>The Bag-of-n-Grams representation consists of using a document's n-gram counts as features in a vector. We test two variants, the Bag-of-Words and the Bag-of-Bigrams. For the subsample containing all subreddits we use only those features that occur at least 5 times in the training comments. We considered including other comment features, such as comment length and scores, but empirical results and the distributions of these features (see <ref type="figure">Figures 3  and 4</ref>) indicate that they are not particularly informative. More sophisticated featurization, such as the noun-phrase and feature interaction indicators proposed by <ref type="bibr" target="#b16">(Wallace et al., 2014)</ref>, is left to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Sentence Embeddings</head><p>Given a document, taking the elementwise sum of embeddings of its words provides a simple low-dimensional document representation. This particular technique of constructing word sequence featurizations has been previously studied and established as a strong baseline for a multitude of supervised NLP prediction tasks <ref type="bibr" target="#b1">(Arora et al., 2017)</ref>. We use 1600-dimensional GloVe representations trained on the Amazon product corpus, which is used instead of Common Crawl because of the semantic closeness between sentiment and sarcasm <ref type="bibr" target="#b8">(McAuley et al., 2015)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">Human</head><p>Human sarcasm detection performance was measured by giving 5 human evaluators 100 samples and asking them to perform the same task as the algorithm: determining which of two statements is sarcastic. We provide links to the evaluation survey for the full corpus 5 as well as the politics subreddit 6 . The full context was provided, and the final human classifier was taken as the majority vote of all 5 evaluators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.4">Random</head><p>We use a simple baseline where all responses are labeled sarcastic randomly and independently with a fixed probability. This probability is chosen as the average fraction of responses that are sarcastic in the training set.  <ref type="table">Table 3</ref>: Most positive and negative n-grams based on weights assigned by the Bag-of-Bigrams classifier. Positive (negative) weight for an n-gram implies it is a strong indicator for the comment being sarcastic (non-sarcastic). The weights indicate that positive n-grams are more important for linear classification of sarcasm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Baselines</head><p>The baselines in <ref type="table">Table 2</ref> perform reasonably well and much better than the random baseline, but none of them match human performance on either dataset. There is clear scope for improvement for machine learning methods, starting with the use of context provided to make better decisions about sarcasm. As evident in <ref type="table">Table 2</ref>, Bag-of-Word and Bag-of-Bigram representations perform better than sentence embeddings; however, distributed representations may be necessary for incorporating context in future methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Human</head><p>As expected, human evaluators performed significantly better, both as a majority and on-average, than the baseline methods. There was significant but not perfect agreement among annotators: on the main dataset the Fleiss kappa score <ref type="bibr" target="#b3">(Fleiss, 1971</ref>) was 0.5, indicating moderate agreement, while on the politics subsample it was 0.67, indicating substantial agreement. Interestingly, while individually human performance was worse on average on sequences drawn from all subreddits than on the politics subsample, taking a majority vote among humans led to much better performance in the former case. This performance boost indicates that while individuals may not have enough context for all topics of discussion on Reddit, in aggregate there is enough information to do well, even surpassing the performance on a well-known topic such as politics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We introduce a large sarcasm dataset based on selfannotated Reddit comments. Both the raw data and evaluation subsamples are made freely available, with the former having over 1 million sarcastic sentences, larger than any existing dataset. We evaluate the baseline performance of simple machine learning methods and compare them with human performance. We hope that future users of this dataset will improve upon these benchmarks and find new ways of utilizing the large quantities of self-annotated information we provide.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Methodall-bal * pol-bal pol-unbal †</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>76 comments share save hide give gold [-] Quexana 50 points 4 months ago Finally, the bankers have a voice in Washington! permalink embed save report give gold REPLY Welcome to / r/ Politics! Please read the wiki before participating.</head><label></label><figDesc></figDesc><table><row><cell cols="2">Bankers celebrate dawn of the Trump era (politico.com)</cell></row><row><cell cols="2">submitted 4 months ago by Boartar</cell></row><row><cell>sorted by:</cell><cell>top</cell></row><row><cell></cell><cell>/s</cell></row><row><cell>arXiv:1704.05579v4 [cs.CL] 22 Mar 2018</cell><cell></cell></row><row><cell></cell><cell>Bamman and Smith, 2015), especially since</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1</head><label>1</label><figDesc></figDesc><table><row><cell cols="2">Corpus Dataset</cell><cell cols="2">Sarcastic Total</cell></row><row><cell>IAC</cell><cell>Joshi et al. '15 Oraby et al. '16</cell><cell>751 4.7K</cell><cell>1502 9.4K</cell></row><row><cell></cell><cell>Joshi et al. '16</cell><cell>4.2K</cell><cell>5.2K</cell></row><row><cell></cell><cell>Bamman &amp; Smith '15</cell><cell>9.7K</cell><cell>19.5K</cell></row><row><cell>Twitter</cell><cell>Reyes et al. '13</cell><cell>10K</cell><cell>40K</cell></row><row><cell></cell><cell>Riloff et al. '13</cell><cell>35K</cell><cell>175K</cell></row><row><cell></cell><cell>Ptácek et al. '13</cell><cell>130K</cell><cell>780K</cell></row><row><cell>Reddit</cell><cell>Wallace et al. '15 SARC</cell><cell>753 1.34M</cell><cell>14124 533M</cell></row></table><note>4 http://files.pushshift.io/reddit: SARC compared with previous sarcasm corpora.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Pos. n-Grams Weights Neg. n-Grams Weights</figDesc><table><row><cell>obviously</cell><cell>1.79</cell><cell>:)</cell><cell>-1.37</cell></row><row><cell>clearly</cell><cell>1.66</cell><cell>lmao</cell><cell>-1.27</cell></row><row><cell>so fun</cell><cell>1.49</cell><cell>:(</cell><cell>-1.17</cell></row><row><cell>totally</cell><cell>1.39</cell><cell>:/</cell><cell>-1.17</cell></row><row><cell>good thing</cell><cell>1.35</cell><cell>, but</cell><cell>-1.10</cell></row><row><cell>shocked</cell><cell>1.32</cell><cell>lol</cell><cell>-1.00</cell></row><row><cell>shocking</cell><cell>1.23</cell><cell>the original</cell><cell>-0.98</cell></row><row><cell>m sure</cell><cell>1.15</cell><cell>wat</cell><cell>-0.97</cell></row><row><cell>omg</cell><cell>1.13</cell><cell>why</cell><cell>-0.96</cell></row><row><cell>how dare</cell><cell>1.13</cell><cell>oh god</cell><cell>-0.95</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://nlp.cs.princeton.edu/SARC/ 2 https://www.twitter.com 3 https://www.reddit.com</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">www.surveygizmo.com/s3/3878814/SARCmain 6 www.surveygizmo.com/s3/3878798/SARCpol</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Modelling context with user embeddings for sarcasm detection in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Amir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Carvalho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Silva</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">A simple but tough-to-beat baseline for sentence embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Contextualized sarcasm detection on twitter. Association for the Advancement of Artificial Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bamman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Measuring nominal scale agreement among many raters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Fleiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="378" to="382" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Identifying sarcasm in twitter: A closer look</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>González-Ibánez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Muresan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wacholder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="581" to="586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Harnessing context incongruity for sarcasm detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bhattacharyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="757" to="762" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Automatic sarcasm detection: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Carman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Really? well. apparently bootstrapping improves the performance of sarcasm and nastiness classifiers for online dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lukin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Language in Social Media</title>
		<meeting>the Workshop on Language in Social Media</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="30" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Inferring networks of substitutable and complementary products</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Creating and characterizing a diverse corpus of sarcasm in dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Oraby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hernandez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGDIAL 2016 Conference</title>
		<meeting>the SIGDIAL 2016 Conference</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="31" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Sarcasm detection on czech and english twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ptácek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Habernal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">25th International Conference on Computational Linguistics: Technical Papers</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="213" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A multidimensional approach for detecting irony in twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Reyes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Veale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Knowledge Engineering</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">47</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Sarcasm as contrast between a positive sentiment and negative situation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Qadir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Surve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">D</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="704" to="741" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Getting reliable annotations for sarcasm in online dialogues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Swanson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lukin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Eisenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">C</forename><surname>Corcoran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Language Resources and Evaluation Conference</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A corpus for research on deliberation and debate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E F</forename><surname>Tree</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Abbott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Language Resources and Evaluation Conference</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Humans require context to infer ironic intent (so computers probably do, too</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kertz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Charniak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="512" to="516" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Charniak</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Sparse, contextually informed models for irony detection: Exploiting user communities, entities, and sentiment</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="1035" to="1044" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
