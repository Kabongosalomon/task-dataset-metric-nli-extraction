<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CorGAN: Correlation-Capturing Convolutional Generative Adversarial Networks for Generating Synthetic Healthcare Records</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amirsina</forename><surname>Torfi</surname></persName>
							<email>atorfi@vt.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science Blacksburg</orgName>
								<orgName type="institution">Virginia Polytechnic Institute and State University</orgName>
								<address>
									<postCode>24061</postCode>
									<region>Virginia Tech, Virginia</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><forename type="middle">A</forename><surname>Fox</surname></persName>
							<email>fox@vt.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science Blacksburg</orgName>
								<orgName type="institution">Virginia Polytechnic Institute and State University</orgName>
								<address>
									<postCode>24061</postCode>
									<region>Virginia Tech, Virginia</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">CorGAN: Correlation-Capturing Convolutional Generative Adversarial Networks for Generating Synthetic Healthcare Records</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T19:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep learning models have demonstrated high-quality performance in areas such as image classification and speech processing. However, creating a deep learning model using electronic health record (EHR) data, requires addressing particular privacy challenges that are unique to researchers in this domain. This matter focuses attention on generating realistic synthetic data while ensuring privacy. In this paper, we propose a novel framework called correlationcapturing Generative Adversarial Network (CorGAN), to generate synthetic healthcare records. In CorGAN we utilize Convolutional Neural Networks to capture the correlations between adjacent medical features in the data representation space by combining Convolutional Generative Adversarial Networks and Convolutional Autoencoders. To demonstrate the model fidelity, we show that CorGAN generates synthetic data with performance similar to that of real data in various Machine Learning settings such as classification and prediction. We also give a privacy assessment and report on statistical analysis regarding realistic characteristics of the synthetic data. The software of this work is open-source and is available at: https://github.com/astorfi/ cor-ganhttps://github.com/astorfi/cor-gan.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Adoption of Electronic Health Records (EHRs) by the healthcare community, along with the massive quantity of available data, has led to calls for employing promising data-driven methods inspired by Artificial Intelligence (AI). Data-powered tools alter how clinicians and healthcare bureaus approach and satisfy patients' needs for care. However, extending EHR adoption to also support data access for research and development purposes, is far from being practical in the healthcare domain, due to privacy restrictions.</p><p>De-identification of EHR data is often employed for mitigation of privacy risks. However, questions and doubts have increased about the safety of prolonged use of deidentification methods regarding their vulnerability to information leakage <ref type="bibr" target="#b4">(El Emam et al. 2011)</ref>. Accordingly, more recent attention has focused on Synthetic Data Generation (SDG) which can satisfy reliably the needs for privacy.</p><p>Copyright c 2020, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.</p><p>We aim to create realistic synthetic EHR data by Generative Adversarial Networks (GANs), which have been successfully employed in applications such as image generation <ref type="bibr" target="#b10">(Reed et al. 2016;</ref><ref type="bibr" target="#b2">Brock, Donahue, and Simonyan 2018;</ref><ref type="bibr" target="#b6">Karras, Laine, and Aila 2018)</ref>, video generation <ref type="bibr" target="#b12">(Vondrick, Pirsiavash, and Torralba 2016;</ref><ref type="bibr" target="#b10">Tulyakov et al. 2018)</ref>, and image translation <ref type="bibr" target="#b6">(Isola et al. 2017;</ref><ref type="bibr" target="#b6">Kim et al. 2017a;</ref><ref type="bibr" target="#b3">Dong et al. 2017)</ref>. Contributions of this work include:</p><p>• We propose an efficient architecture to generate synthetic healthcare records using Convolutional GANs and Convolutional Autoencoders (CAs) which we call "CorGAN". We demonstrate that CorGAN can effectively generate both discrete and continuous synthetic records.</p><p>• We demonstrate the effectiveness of utilizing Convolutional Neural Networks (CNNs) as opposed to Multilayer Perceptrons to capture inter-correlation between features.</p><p>• We show that CorGAN can generate realistic synthetic data that performs similarly to real data on classification tasks, according to our analysis and assessments.</p><p>• We report on a privacy assessment of the model and demonstrate that CorGAN provides an acceptable level of privacy, by varying the amount of synthetically generated data and amount of data known to an adversary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Works</head><p>Some distinguished efforts were conducted in a variety of domains about synthetic data generation <ref type="bibr" target="#b13">(Walonoski et al. 2017;</ref><ref type="bibr" target="#b2">Buczak, Babin, and Moniz 2010;</ref><ref type="bibr" target="#b6">McLachlan, Dube, and Gallagher 2016;</ref><ref type="bibr" target="#b8">Park, Ghosh, and Shankar 2013)</ref>. But some of these works are overly disease-specific, unrealistic, or have failed to provide any substantial measurements regarding privacy. Highly relevant is "medGAN" <ref type="bibr" target="#b3">(Choi et al. 2017</ref>), using GANs for synthetic discrete EHR data. But in contrast to medGAN, we consider the temporal nature of the data and local correlation between features. Instead of regular multilayer perceptrons, we base our architecture on CNNs and provide empirical results to demonstrate the superior performance in capturing inter-correlations between data features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>arXiv:2001.09346v2 [cs.LG] 4 Mar 2020</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method Discrete EHR Data Description</head><p>Many discrete variables (e.g., diagnosis, procedure code) are available in the dataset. Let's assume there are |D| discrete variables and the vector V C ∈ N 0 |D| (where N 0 indicates natural numbers including zero) is in a vector space. The j th dimension designates the number of incidents of the j th variable in a subject's medical records. We can represent a patient's visit (encounter event) by a binary vector</p><formula xml:id="formula_0">V B ∈ {0, 1} |D| ,</formula><p>where the j th dimension shows whether the j th variable occurred in the patient record. We represent the input space as a matrix in which columns indicate discrete variables in the EHR record. Such representation extracts multiple patients' records representing different points in time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generative Adversarial Networks</head><p>A Generative Adversarial Network (GAN), introduced in (Goodfellow et al. 2014), is a combination of two neural networks, a discriminator and a generator. The whole network is trained in an iterative process. First the generator network produces a fake sample. Then the discriminator network tries to determine whether this sample (ex.: an input image) is real or fake, i.e., whether it came from the real training data. The goal of the generator is to fool the discriminator so it believes the artificial (i.e., generated) samples synthesized by the generator are real.</p><p>The generator goal is to learn the distribution p g over data x. In that regard, p z (z) represents the input noise variables distribution which generates random data shown by G(z; θ g ). The function G is differentiable with parameters θ g . The discriminator, D(x; θ d ), decides if its input data is real or fake. D is trained to distinguish the training samples from G by minimizing log(1 − D(G(z))). D and G perform the following min-max game with value function V(G, D):</p><formula xml:id="formula_1">M in G M ax D V (G, D) = E x∼p data (x) [logD(x)]+ E z∼pz(z) [1 − logD(G(z))]</formula><p>(1)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proposed Architecture</head><p>We use the architecture in <ref type="figure" target="#fig_0">Fig. 1</ref>. The discrete input X represents the source EHR data; z is the random distribution for the generator G; G is the employed neural network architecture; Dec(G(z)) refers to the decoding function which is used to transform the generator G continuous output to their equivalent discrete values. The discriminator D attempts to distinguish real input X from the discrete synthetic output Dec(G(z)). For the generator and the discriminator, a 1-Dimensional Convolutional GAN architecture is utilized.</p><p>Consider the decoding function Dec(.). GANs are known for generating continuous values and encountering trouble when dealing with discrete variables. Recently, researchers proposed solutions to the problem of generating discrete variables <ref type="bibr" target="#b5">(Hjelm et al. 2017;</ref><ref type="bibr" target="#b14">Wang et al. 2017;</ref><ref type="bibr" target="#b6">Kim et al. 2017b;</ref><ref type="bibr" target="#b14">Yu et al. 2017)</ref>. Some approaches use the indirect method such that they create a separate model to transform continuous to discrete data <ref type="bibr" target="#b3">(Choi et al. 2017)</ref>. Regarding EHR data generation, we are dealing with discrete data. Hence, our generative model should create discrete data directly, or there should be a function to transform the continuous data samples into discrete equivalents. We chose the second approach, and employed autoencoders.</p><p>Considering <ref type="figure" target="#fig_0">Fig. 1</ref>, the autoencoder digests (right part of the figure) discrete values and reconstructs the same discrete values as well. The autoencoder structure consists of two main elements: encoder and decoder. While encoding, the autoencoder transforms the discrete space into a corresponding (we call it equivalent as well) continuous space (the output of the hidden layer) and the decoder reverses the process. The Binary Cross-Entropy (BCE) loss function is used for training the autoencoder:</p><formula xml:id="formula_2">BCE loss = − 1 N N i=1 x i log(y i ) + (1 − x i )log(1 − y i ) (2) y i = Dec(Enc(x i ))<label>(3)</label></formula><p>We used denoising autoencoders <ref type="bibr" target="#b11">(Vincent et al. 2010</ref>) to create a more robust pretrained model as we do not expect our model to always generate perfect discrete samples. After training the autoencoder, we need to use its decoder to convert continuous values to their associated discrete values. The cost function to train our proposed architecture is similar to Eq. 1 with the exception of operating the decoder on top of the generator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M in</head><formula xml:id="formula_3">G M ax D V (G, D) = E x∼p data (x) [logD(x)]+ E z∼pz(z) [1 − logD(Dec(G(z)))]<label>(4)</label></formula><p>As we are dealing with 1D data, we chose the 1-Dimensional Convolutional Autoencoders (1D-CAEs) as a particular form of the regular CAEs. This approach enables us to capture the neighboring feature correlations. We call our proposed architecture CorGAN. It is worth noting that for our experiments with discrete variables, we round the values of Dec(G(z)) to their nearest integers (the outcome is zero or one) to guarantee that we train and evaluate the discriminator on discrete values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training Augmentation</head><p>One of the primary crash forms for GAN is for the generator to collapse to a set of parameters and always generate the same sample. This phenomenon is called Mode Collapse. Some approaches have been proposed to handle the mode collapse issue such as minibatch discrimination <ref type="bibr" target="#b10">(Salimans et al. 2016</ref>) and unrolled GANs <ref type="bibr" target="#b7">(Metz et al. 2016)</ref>. We utilized minibatch discrimination due to its better stability. We also utilized batch normalization (Ioffe and Szegedy 2015) to improve the generator's learning abilities. Furthermore, we used LeakyRelu activation unit <ref type="bibr" target="#b6">(Maas, Hannun, and Ng 2013)</ref> as it consistently demonstrated equal or better results over other common activation functions <ref type="bibr" target="#b14">(Xu et al. 2015)</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Privacy</head><p>We utilize the Membership Inference (MI) attack as an approach to measure the privacy. Membership Inference (MI), proposed in (Shokri et al. 2017), refers to determining whether a given record generated by a known machine learning model was used as part of the training data. If the adversary has complete access to the records of a particular patient and can recognize their employment in the model training, that is an indication of information leakage, as it can jeopardize the whole dataset privacy or at least the particular patient's private information. Here, we will assume the adversary has the synthetically generated data as well as a portion of the compromised real data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments</head><p>We evaluated CorGAN with two datasets. First, we explain the datasets and baseline models. Then, we provide the results regarding the evaluation of the synthetic data in terms of the realistic characteristics. Finally, we report on a privacy assessment of the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Datasets</head><p>We used two publicly available datasets in this study. The first is the MIMIC-III dataset (Johnson et al. 2016) consisting of the medical records of almost 46K patients. From MIMIC-III, we extracted ICD-9 codes only. We represent a patient record as a fixed-size vector with 1071 entries for each patient record. This dataset is used for experiments with binary discrete variables.</p><p>We conducted our experiments regarding continuous variables with the UCI Epileptic Seizure Recognition dataset <ref type="bibr" target="#b0">(Andrzejak et al. 2001</ref>). This dataset characterizes </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Models</head><p>To show the effectiveness of our proposed architecture, we compare our results with different baseline methods as below:</p><p>• Stacked Deep Boltzmann Machines (DBMs): We trained a stacked Deep Boltzmann Machine (DBM) (Hinton and Salakhutdinov 2009). After which, we used Gibbs sampling to generate synthetic binary samples. All hidden layers have 256 dimensions. We employed greedy contrastive divergence to create the model. We ran Gibbs sampling for 500 iterations per sample.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• Variational Autoencoder (VAE):</head><p>We used VAEs (Kingma and Welling 2013) as one of our baseline models. For both the encoder and the decoder, we used 1D convolutional neural networks, each having two hidden layers. All hidden layers have the size of 128. We trained VAE with Adam optimizer for 500 epochs and for the batch size of 500.</p><p>• medGan: The medGan <ref type="bibr" target="#b3">(Choi et al. 2017</ref>) architecture consists of the following elements; (1) regular multilayer perceptrons for autoencoder, discriminator, and generator.</p><p>(2) shortcut connections to improve the power of generator.</p><p>(3) minibatch-averaging <ref type="bibr" target="#b3">(Choi et al. 2017)</ref> to cope with the mode collapse.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation</head><p>In this section, we report our evaluation results regarding the quality of the synthetic data and the privacy risks. Here, we divide the dataset into a training S tr ∈ {0, 1} R×|M| and a test set S te ∈ {0, 1} T ×|M| , where |M| is the feature size and is consistent for all sets. We use S tr to train the models, then generate synthetic samples S syn ∈ {0, 1} S×|M| using the trained model. Noted that we usually use the same number of samples for S syn and S tr .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation of the Synthetic Data Quality</head><p>We use the following two metrics to evaluate our synthetically generated data.</p><p>• Dimension-wise probability: As a basic sanity check to see if our proposed models learned the distribution of the real data (for each dimension), we report the dimensionwise probability. This measurement refers to the Bernoulli success probability of each dimension (each dimension is a unique ICD-9 code).</p><p>• For Dimension-wise probability and Dimension-wise prediction experiments, we used MIMIC-III dataset and for Binary Classification experiments we used UCI Epileptic Seizure Recognition dataset. The results regarding the investigation of dimension-wise probability are depicted in <ref type="figure" target="#fig_1">Fig. 2</ref>. As can be seen, the CorGAN is superior compared to other methods. An interesting observation is that the VAE is never generating any synthetic data for which the probability of occurrence of a diagnosis code is higher than its counterpart in the real data.</p><p>For dimension-wise prediction <ref type="table" target="#tab_2">(Table 2)</ref>, we use the following classifiers the predictive model types: Logistic Regression, Random Forests <ref type="bibr" target="#b1">(Breiman 2001)</ref>, Linear SVM (Cortes and Vapnik 1995), and Decision Tree (Quinlan 1986). For our experiments, we conduct E=100 number of runs. In each run, we pick a random testing dimension from test set (S syn,k ∈ {0, 1} N ×1 ) and will train each predictive model on S syn,\k and S tr,\k . This results in having two models as M odel type syn and M odel type real . The superscript refers to the kind of model that was used to be trained on both real and synthetic sets. We then report the performance over all predictive models and for all experiments using the F1-score variation. F1-score variation means the difference between the F-1 score obtained from training the model on synthetic and real datasets.  <ref type="bibr" target="#b3">(Choi et al. 2017)</ref> 0.043 ± 0.049 <ref type="bibr">CorGAN [ours]</ref> 0.021 ± 0.045 0.92 ± 0.012 0.41 ± 0.015</p><p>For the MIMIC dataset experiments, although the temporal information is ignored, the medical health diagnosis are sorted in terms of similarity in the feature vector of the MIMIC data. Therefore, 1D CNNs capture the correlation between features rather than the temporal information.</p><p>For binary classification experiments, we used the same predictive models as for the dimension-wise predictions. We reported the averaged AUROC (averaged area under the ROC for all models) and AUPRC (averaged area under the PR curve for all models) for the models' evaluations. The difference with our experiments here is that we are not dealing with binary variables. Hence, for the medGAN and Cor-GAN methods we eliminate the autoencoder as depicted in <ref type="figure" target="#fig_0">Fig. 1</ref>. As can be observed in <ref type="table">Table.</ref> 3, our proposed method outperforms the other methods. As the UCI Epileptic Seizure Recognition dataset features contain termporal information, our method is able to capture temporal data information more effectively due to the usage of 1D CNNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Privacy Assessment</head><p>In this section, the experiments are conducted on the MIMIC-III dataset regarding the membership inference attack. For privacy assessment, we randomly take P samples from each S tr and S te and call them S P tr and S P tr . We assume the attacker has the complete knowledge of both S P tr and S P te . Clearly, S P tr was used to train the generating model, but S P te wasn't. So we have R = 2 × P records. Then, we compared each of these records with the synthetically generated data samples S syn ∈ {0, 1} S×|M| . We compared each of the samples in the set of S P te + S P tr with each samples in the set of S syn and we calculate cosine similarity score. Cosine similarity is used since it provides a more meaningful correlation metric as opposed to distance metrics (Mateo-Sanz, Sebé, and Domingo-Ferrer 2004) used in previous research efforts <ref type="bibr" target="#b3">(Choi et al. 2017</ref>). If the score is higher than a threshold, then it flags the match, otherwise,  we call it a mismatch. For threshold, we randomly select 100 threshold values from a Gaussian distribution with a mean of 0.5 and a standard deviation of 0.01 (ignoring possible negative values), and we report the results which demonstrate the best adversary attack. For evaluation, we use precision and recall metrics. We conduct two sets of experiments here: (1) investigating the effect of the number of records known by the attacker (Table. 4) and (2) examining the effect of synthetic data volume on the privacy risk ( <ref type="figure">Fig. 3)</ref>.</p><p>As can be seen in <ref type="table">Table.</ref> 4, by increasing the number of the real patient records known to the adversary, the attack will be even less accurate. It also demonstrates the fact that higher precision is possible at lower recall rates when the number of known records is not high. However, as is evident, a higher amount of revealed data increases the privacy risk significantly.</p><p>Regarding the effect of number of generated synthetic data on the privacy risk, as can be observed in <ref type="figure">Fig. 3</ref>, the increasing number of synthetic records does not have a significant effect on the recall, but it causes a dramatic decrease in precision. Henceforth, by having a fixed amount of known records, a higher number of synthetic patient's records can be very misleading for the adversary. This empirical observation indicates that the increasing the number of synthetic records, with a fixed number or revealed patient's records to the attacker, does not necessarily raise privacy risk.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>In this work, we proposed CorGAN, which utilizes the convolutional generative adversarial networks to learn the distribution of real patient records. Through precise evaluation using real and synthetic datasets, CorGAN demonstrated decent results for both discrete and continuous records. We empirically proved the superiority of CNNs over MLPs to capture the correlated features. We believe our method can be <ref type="figure">Figure 3</ref>: The recall/precision as a function of the number of generated synthetic records. The number of records known to the adversary is considered fixed and is equal to 100. effectively extended and employed to longitudinal records as well for which the goal is to capture the temporal characteristics of the data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>The architecture for generating synthetic data from real samples. The right side of the figures, shows the pretrained convolutional autoencoder which its decoder part is being used to transform the generated continuous samples to their discrete equivalents.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>he scatter plots of dimension-wise probability. Each point depicts one of 1071 unique diagnosis codes. The x-axis and y-axis represent the Bernoulli success probability for real and synthetic datasets, respectively. The diagonal line shows the ideal case.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Statistics of the UCI Epileptic Seizure Recognition dataset.</figDesc><table><row><cell>Dataset</cell><cell>UCI</cell></row><row><cell># of patients</cell><cell>500</cell></row><row><cell>Each patient's data points</cell><cell>4097</cell></row><row><cell>Each patient's duration of recording</cell><cell>23.5 seconds</cell></row><row><cell># data points chunks per patient</cell><cell>23</cell></row><row><cell># of data points per chunk</cell><cell>178</cell></row><row><cell>Duration per chunk</cell><cell>1 second</cell></row><row><cell>Data type</cell><cell>Continuous EEG</cell></row><row><cell cols="2">brain activities. The core task is classification, regarding if a</cell></row><row><cell cols="2">sample indicates a seizure activity. The number of features</cell></row><row><cell cols="2">and samples are 179 and 11500, respectively. Almost 20%</cell></row><row><cell cols="2">of the samples are categorized as seizure activity. So, we are</cell></row><row><cell cols="2">dealing with an unbalanced dataset in a binary classifica-</cell></row><row><cell cols="2">tion setting. The first 178 features are the values of the Elec-</cell></row><row><cell cols="2">troencephalogram (EEG) recordings at different time points,</cell></row></table><note>and the last feature is the class. There are five values for the class label (y = 1, ..., 5). Except for y = 1, the rest of the classes indicate subjects who do not have an epileptic seizure. Dataset statistics are given in Table 1.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Dimension-wise prediction: This approach measures how robust the model catches the inter-dimensional connections of the real data samples. Assume S tr is used to generate S syn . Then, one random fixed dimension (k) from each S syn and S tr are selected as S syn,k ∈ {0, 1} N ×1 and S tr,k ∈ {0, 1} N ×1 . We call it the testing dimension. The rest of the dimensions (S syn,\k ∈ {0, 1} N ×1 and S tr,\k ∈ {0, 1} N ×1 ) are used to train a classifier, which aims to predict the value of the testing dimension of the test set S te,k ∈ {0, 1} N ×1 . We use this metric for our experiments with continuous data. To empirically verify the quality of the synthetic data, we consider two different settings. (A) Train and test the predictive models on the real data. (B) train the predictive model on synthetic data and test it on the real data. If the model evaluated in setting (B), represents competitive results with the same model performed in setting (A), we can conclude the synthetic data has good predictive modeling similar to the real data.</figDesc><table /><note>• Binary Classification:</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Comparison of different baseline architectures. The reported metric demonstrate the mean and standard deviation of the F-1 score differences. A better model has a closer score to zero.</figDesc><table><row><cell>Generative Model</cell><cell>F1-Score</cell></row><row><cell cols="2">DBM (Hinton and Salakhutdinov 2009) 0.12 ± 0.052</cell></row><row><cell>VAE (Kingma and Welling 2013)</cell><cell>0.069 ± 0.043</cell></row><row><cell>medGAN</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell cols="3">: Comparison of different generative models for bi-</cell></row><row><cell cols="3">nary classification. The averaged AUROC and AUROC for</cell></row><row><cell cols="3">utilizing the predictive models on the real data are 0.95 and</cell></row><row><cell>0.46.</cell><cell></cell><cell></cell></row><row><cell>Generative Model</cell><cell>AUROC</cell><cell>AUPRC</cell></row><row><cell>DBM</cell><cell cols="2">0.81 ± 0.017 0.27 ± 0.013</cell></row><row><cell>VAE</cell><cell cols="2">0.84 ± 0.021 0.31 ± 0.022</cell></row><row><cell>medGAN</cell><cell cols="2">0.89 ± 0.023 0.35 ± 0.014</cell></row><row><cell>CorGAN [ours]</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>The precision and recall demonstrated as a function of the number of patients whose data is revealed to the attacker. U = # of Known Records to the attacker.</figDesc><table><row><cell>U</cell><cell>100</cell><cell>1k</cell><cell>2k</cell><cell>3k</cell><cell>4k</cell><cell>5k</cell></row><row><cell cols="7">Precision 0.60 0.51 0.41 0.40 0.40 0.39</cell></row><row><cell>Recall</cell><cell cols="6">0.05 0.10 0.19 0.28 0.27 0.28</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Indications of nonlinear deterministic and finite-dimensional structures in time series of brain electrical activity: Dependence on recording region and brain state</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>References</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Andrzejak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review E</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">61907</biblScope>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Random forests. Machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="5" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Data-driven approach for creating synthetic electronic medical records</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donahue</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Buczak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Babin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Moniz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Buczak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Babin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Moniz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.11096</idno>
	</analytic>
	<monogr>
		<title level="j">BMC medical informatics and decision making</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">59</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Large scale GAN training for high fidelity natural image synthesis</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Generating multi-label discrete patient records using generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Choi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.06490</idno>
		<idno>arXiv:1701.02676</idno>
	</analytic>
	<monogr>
		<title level="m">Unsupervised image-to-image translation with generative adversarial networks</title>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="273" to="297" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Support-vector networks</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The re-identification risk of Canadians from longitudinal demographics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Emam</surname></persName>
		</author>
		<idno>Goodfellow et al. 2014</idno>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1607" to="1614" />
		</imprint>
	</monogr>
	<note>Advances in neural information processing systems</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Hjelm</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.08431</idno>
		<idno>arXiv:1502.03167</idno>
		<title level="m">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Boundaryseeking generative adversarial networks</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Using the caremap with health incidents statistics for generating the realistic synthetic electronic healthcare record</title>
		<idno type="arXiv">arXiv:1812.04948</idno>
		<idno>arXiv:1312.6114</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<editor>JMLR. org. [Kim et al. 2017b</editor>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2004" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="439" to="448" />
		</imprint>
	</monogr>
	<note type="report_type">Auto-encoding variational Bayes. arXiv preprint</note>
	<note>IEEE International Conference on Healthcare Informatics (ICHI)</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Unrolled generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Metz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Perturbed Gibbs samplers for generating large-scale privacy-safe synthetic health data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ghosh</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shankar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 IEEE International Conference on Healthcare Informatics</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="493" to="498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Induction of decision trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Quinlan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="81" to="106" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Membership inference attacks against machine learning models</title>
		<idno type="arXiv">arXiv:1605.05396</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1526" to="1535" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Advances in neural information processing systems</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="3371" to="3408" />
			<date type="published" when="2010-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Generating videos with scene dynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pirsiavash</forename><surname>Vondrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Vondrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pirsiavash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances In Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="613" to="621" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Synthea: An approach, method, and software mechanism for generating synthetic patients and the synthetic electronic health care record</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Walonoski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="230" to="238" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Irgan: A minimax game for unifying generative and discriminative information retrieval models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.00853</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th International ACM SIGIR conference on Research and Development in Information Retrieval</title>
		<meeting>the 40th International ACM SIGIR conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="515" to="524" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Thirty-First AAAI Conference on Artificial Intelligence</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
