<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">TPLinker: Single-stage Joint Extraction of Entities and Relations Through Token Pair Linking</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yucheng</forename><surname>Wang</surname></persName>
							<email>wangyucheng@iie.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Cyber Security</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute of Information Engineering</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Yu</surname></persName>
							<email>yubowen@iie.ac.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yueyang</forename><surname>Zhang</surname></persName>
							<email>zhangyueyang@baidu.com</email>
							<affiliation key="aff0">
								<orgName type="department">School of Cyber Security</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute of Information Engineering</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Baidu, Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tingwen</forename><surname>Liu</surname></persName>
							<email>liutingwen@iie.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Cyber Security</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute of Information Engineering</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsong</forename><surname>Zhu</surname></persName>
							<email>zhuhongsong@iie.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Cyber Security</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute of Information Engineering</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Sun</surname></persName>
							<email>sunlimin@iie.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Cyber Security</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute of Information Engineering</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">TPLinker: Single-stage Joint Extraction of Entities and Relations Through Token Pair Linking</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:19+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Extracting entities and relations from unstructured text has attracted increasing attention in recent years but remains challenging, due to the intrinsic difficulty in identifying overlapping relations with shared entities. Prior works show that joint learning can result in a noticeable performance gain. However, they usually involve sequential interrelated steps and suffer from the problem of exposure bias. At training time, they predict with the ground truth conditions while at inference it has to make extraction from scratch. This discrepancy leads to error accumulation. To mitigate the issue, we propose in this paper a one-stage joint extraction model, namely, TPLinker, which is capable of discovering overlapping relations sharing one or both entities while immune from the exposure bias. TPLinker formulates joint extraction as a token pair linking problem and introduces a novel handshaking tagging scheme that aligns the boundary tokens of entity pairs under each relation type. Experiment results show that TPLinker performs significantly better on overlapping and multiple relation extraction, and achieves state-of-the-art performance on two public datasets 1 . * Corresponding author. 1  The source code of this paper can be obtained from https://github.com/131250208/TPlinker-joint-extraction This work is licensed under a Creative Commons Attribution 4.0 International License. License details:</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Extracting entities and relations from unstructured texts is an essential step in automatic knowledge base construction <ref type="bibr" target="#b15">(Takanobu et al., 2019)</ref>. Traditional pipelined approaches first extract entity mentions and then classify the relation types between candidate entity pairs. However, due to the complete separation of entity detection and relation classification, these models ignore the interaction and correlation between the two subtasks, being susceptible to cascading errors <ref type="bibr" target="#b7">(Li and Ji, 2014)</ref>.</p><p>In the last few years, there has been increasing research interest in building joint models to simultaneously extract entities and relations. Recent works show that joint learning approaches can effectively integrate the information of entity and relation, and therefore achieve better performance in both subtasks <ref type="bibr" target="#b2">(Dai et al., 2019;</ref><ref type="bibr" target="#b16">Tan et al., 2019)</ref>. <ref type="bibr" target="#b24">Zheng et al. (2017)</ref> proposed a unified tagging scheme to convert joint extraction to a sequence labeling problem but lacks the elegance to identify overlapping relations: one entity may participate in multiple relations in the same text <ref type="figure" target="#fig_0">(Figure 1</ref>).</p><p>Most existing models in handling EntityPairOverlap (EPO) and SingleEntiyOverlap (SEO) cases can be categorized into two classes: decoder-based and decomposition-based. Decoder-based models use encoder-decoder architecture where the decoder extracts one word or one tuple at a time like machine translation models <ref type="bibr" target="#b21">(Zeng et al., 2018;</ref><ref type="bibr" target="#b11">Nayak and Ng, 2020)</ref>. Decomposition-based models first distinguish all the candidate subject entities that may be involved with target relations, then label corresponding object entities and relations for each extracted subject <ref type="bibr" target="#b19">Yu et al., 2020;</ref><ref type="bibr" target="#b17">Wei et al., 2020)</ref>. Although these methods have achieved reasonable performance, they all suffer from the same problem: exposure bias. For the decoder-based method, at training time, the ground truth tokens are used as context while at inference the entire sequence is generated by the resulting model on its own, and hence the previous tokens generated by the model are fed as context. As a result, the predicted tokens at training and inference are drawn from different distributions, namely, from the data distribution as opposed to the model distribution . Similarly, the decomposition-based method uses the gold subject entity as specific input to guide the model extract object entities and relations during the training process while at inference the input head-entity is given by a trained model, leading to a gap between training and inference.</p><p>In this paper, we present a one-stage method for joint extraction of entities and overlapping relations, namely TPLinker, which bridges the gap between training and inference. TPLinker transforms the joint extraction task as a Token Pair Linking problem. Given a sentence, two positions p 1 , p 2 and a specific relation r, TPLinker is to answer three Yes/No pseudo questions: "Whether p 1 and p 2 are the start and end positions of the same entity respectively?", "Whether p 1 and p 2 are the start positions of two entities with r relation respectively?" and "Whether p 1 and p 2 are the end positions of two entities with r relation respectively?" To this end, we design a handshaking tagging scheme that annotates three token link matrices for each relation to answer the above three questions. These link matrices are then used to decode different tagging results, from which we can extract all entities and their overlapping relations. Intuitively, TPLinker does not contain any inter-dependency extraction steps, so it avoids the dependence on ground truth conditions at training time, realizing the consistency of training and testing.</p><p>We evaluate our method on two public datasets: NYT <ref type="bibr" target="#b13">(Riedel et al., 2010)</ref> and WebNLG <ref type="bibr" target="#b4">(Gardent et al., 2017)</ref>. Experimental results show that TPLinker outperforms previous works and achieves the stateof-the-art results on the benchmark datasets. Further analysis demonstrates that TPLinker significantly improves the performance on Normal, SEO, EPO, and multiple relation extraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Researchers proposed several methods to extract both entities and relations. Traditional pipelined methods <ref type="bibr" target="#b20">(Zelenko et al., 2003;</ref><ref type="bibr" target="#b1">Chan and Roth, 2011)</ref> neglect the relevance of entity extraction and relation prediction. To resolve this problem, several joint models have been proposed. Feature-based works <ref type="bibr" target="#b18">(Yu and Lam, 2010;</ref><ref type="bibr" target="#b10">Miwa and Sasaki, 2014)</ref> need a complicated process of feature engineering and heavily depend on NLP tools for feature extraction. Neural models for joint relation extraction are investigated in recent studies <ref type="bibr" target="#b5">(Gupta et al., 2016;</ref><ref type="bibr" target="#b24">Zheng et al., 2017)</ref>, they show promising results but completely giving up overlapping relations. To address this problem, a variety of neural networks for joint extraction of entities and overlapping relations are proposed. <ref type="bibr" target="#b2">Dai et al. (2019)</ref> extracted triplets by tagging one sentence for n times with a position-aware attention mechanism. <ref type="bibr" target="#b16">Tan et al. (2019)</ref> solved this task via ranking with translation mechanism. <ref type="bibr" target="#b15">Takanobu et al. (2019)</ref> firstly determined relations and then recognized entity pairs via reinforcement learning.  cast joint extraction as a multi-turn QA problem and generated questions by relation-specific templates.  constructed an entity-relation bipartite graph to perform inference on entity types and relation types. <ref type="bibr" target="#b19">Yu et al. (2020)</ref> presented a unified sequence labeling framework based on a novel decomposition strategy. However, these methods can only recognize SEO relations in the sentence and fail to extract EPO triplets.</p><p>To handle the EPO cases, <ref type="bibr" target="#b21">Zeng et al. (2018)</ref> proposed a sequence-to-sequence model to decode overlapping relations but fail to generate multi-word entities. As the improvement, <ref type="bibr" target="#b11">Nayak and Ng (2020)</ref> employed an encoder-decoder model where the decoder extracts one word at a time like machine translation models. Besides, <ref type="bibr" target="#b17">Wei et al. (2020)</ref> proposed a novel cascade binary tagging framework that first identifies all possible subject entities in a sentence then identifies all possible relations and object entities for each subject entity. Actually, these methods decompose the extraction of overlapping relations into several inner-dependency steps, since the decoder needs a recursive decoding process and cascade tagging has to identify subject entities in advance. Such decomposition makes the task easy to conduct but inevitably causes the exposure bias problem, which leads to error accumulation. At training time, they predict the triplets with the ground truth tokens or subjects while at inference they have to rely on the predicted results. In this paper, we propose a unified tagging method to extract entities and overlapping relations. Different from previous methods, our model performs in one stage and generates triplets without a gap between training and inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>In this section, we first introduce our handshaking tagging scheme and its decoding algorithm. Then we detail the TPLinker model structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Handshaking Tagging Scheme</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Tagging</head><p>According to the insight that a triplet (s, r, o) can be determined by aligning the boundary tokens of subject entity s and object entity o conditioned on the relation r, we realize one-stage joint extraction by tagging token pairs with link labels.</p><p>As shown in the left panel of <ref type="figure" target="#fig_1">Figure 2</ref>, given a sentence, we enumerate all possible token pairs and use matrices to tag token links. Formally, three types of links are defined as follows 2 : 1) entity head <ref type="figure">Figure 3</ref>: The Framework of TPLinker. SH is short for subject head, OH is short for object head, ST is short for subject tail, and OT is short for object tail. By decoding, 5 triplets can be extracted: (New York, mayor, De Blasio), (De Blasio, born in, New York), (De Blasio, born in, New York City), (De Blasio, live in, New York), (De Blasio, live in, New York City).</p><p>to entity tail (EH-to-ET). The purple tag in the matrix refers to that the two corresponding positions are respectively the start and end token of an entity. For example, "New York City" and "De Blasio" are two entities in the sentence, therefore, token pair ("New", "City") and ("De", "Blasio") are assigned with purple tag 1. 2) subject head to object head (SH-to-OH). The red tag means that two positions are respectively the start token of a paired subject entity and object entity. For example, there is a "mayor" relation between "New York City" and "De Blasio", so the token pair ("New", and "De") is assigned with red tag 1. 3) subject tail to object tail (ST-to-OT). The blue tag shares a similar logic with the red tag, which means two positions are respectively the end token of a paired subject entity and object entity. For instance, the token pair ("City", "Blasio") is assigned with blue tag 1.</p><p>As we can see from the left panel of <ref type="figure" target="#fig_1">Figure 2</ref>, the matrix is quite sparse, especially the lower triangular region. Because the entity tail is impossible to appear before the entity head, the tags in the lower triangular region are all zeros, which is a huge waste of memory. However, the object entity could appear before the corresponding subject entity, which means it is not reasonable to drop the lower triangular region directly. Before doing that, we map all tag 1 in the lower triangular region to tag 2 in the upper triangular region, then drop the lower triangular region. After doing this, it is not a complete matrix anymore, in the practical operation, we flatten the rest items into a sequence (the orange sequences in <ref type="figure">Figure 3</ref>) for the convenience of tensor calculation and use a map to remember the positions in the original matrix. The sequence is like the handshaking of all tokens, which is the reason why we refer to this scheme as the handshaking tagging scheme.</p><p>The case in the left panel of <ref type="figure" target="#fig_1">Figure 2</ref> suggests that this tagging scheme can naturally address the SingleEntiyOverlap problem and the nested entity problem from design. In this case, "New York City" and "New York" are nested and share the same object "De Blasio", which is a challenging problem for many previous methods. However, by this tagging scheme, both the three entities and the two triplets can be easily decoded (see Section 3.1.2). However, this scheme cannot handle the EntityPairOverlap problem because different relations can not be tagged together in the same matrix for the same entity pair. To address this issue, we do the same matrix tagging job for each relation type. Note that EH-to-ET Similarly, entity/subject/object tail is defined as the end position.</p><p>tagging is shared by all relations because it focuses on the general entity extraction without considering the specific relation types. Overall, as depicted in <ref type="figure">Figure 3</ref>, the joint extraction task is deconstructed into 2N +1 sequence labeling subtasks where N denotes the number of pre-defined relation types, each subtask builds a tag sequence of length n 2 +n 2 , where n is the length of the input sentence. It seems that our tagging scheme is extremely inefficient because the length of the tagging sequence increases in a square number with increasing sentence length. Fortunately, our experiment reveals that by utilizing a lightweight tagging model on the top of the encoder, TPLinker can achieve competitive running efficiency compared with the state-of-the-art model, since the encoder is shared by all taggers (see <ref type="figure">Figure 3</ref>) and only needs to generate n token representations for once.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Decoding</head><p>In the case of <ref type="figure">Figure 3</ref>, ("New", "York"), ("New", "City") and ("De", "Blasio") are tagged as 1 in the EH-to-ET sequence, which means "New York", "New York City", and "De Blasio" are three entities. For relation "mayor", ("New", "De") is tagged as 1 in the SH-to-OH sequence, which means the mayor of the subject starting with "New" is the object starting with "De". ("City", "Blasio") is tagged as 1 in the ST-to-OT sequence, which means that the subject and object are the entities ending with "City" and "Blasio", respectively. Based on the information represented by these three sequences, a triplet can be decoded: ("New York City", mayor, "De Blasio").</p><p>The same logic goes for other relations, but note that the tag 2 has an opposite meaning to the tag 1, which represents a reversal link between tokens. For example, ("York", "Blasio") is tagged as 2 in the ST-to-OT sequence of relation "born in", which means "York" and "Blasio" are respectively the tail of a paired object and subject. Combined with the other two sequences, the decoded triplet should be ("De Blasio", born in, "New York").</p><p>Formally, the decoding process is summarized in Algorithm 1. For each relation, in the beginning, we extract all entity spans from the EH-to-ET sequence and map each head position to the corresponding entities starting with this position by a dictionary D. Next, for each relation, we firstly decode (subject tail position, object tail position) tuples from the ST-to-OT sequence and add them into a set E, and then decode (subject head position, object head position) tuples from the SH-to-OH sequence and lookup all possible entities starting with the head positions in the dictionary D. Finally, we iterate all candidate subject-object pairs to check whether their tail positions are in E. If so, a new triplet is extracted and added into the resulting set T .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Token Pair Representation</head><p>Given a sentence [w 1 , · · · , w n ] of length n, we first map each token w i into a low-dimensional contextual vector h i by a basic encoder. Then we can generate a representation h i,j for the token pair (w i , w j ) as follows:</p><formula xml:id="formula_0">h i,j = tanh(W h · [h i ; h j ] + b h ), j ≥ i,<label>(1)</label></formula><p>where W h is a parameter matrix and b h is a bias vector to be learned during training. Equation 1 is also denoted as Handshaking Kernel in <ref type="figure">Figure 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Handshaking Tagger</head><p>We utilize a unified architecture for EH-to-ET, SH-to-OH and ST-to-OT tagging. Given a token pair representation h i,j , the link label of token pair (w i , w j ) is predicted by Equation <ref type="formula" target="#formula_2">3</ref>.</p><formula xml:id="formula_1">P (y i,j ) = Softmax(W o · h i,j + b o ),<label>(2)</label></formula><formula xml:id="formula_2">link(w i , w j ) = arg max l P (y i,j = l),<label>(3)</label></formula><p>where P (y i,j = l) represents the probability of identifying the link of (w i , w j ) as l.</p><p>Algorithm 1 Handshaking sequence decoding Input: The EH-to-ET sequence, Se;</p><p>The SH-to-OH sequences of relation r, {S r h , r ∈ R}, where R is the pre-defined relation set; The ST-to-OT sequences of relation r, {S r t , r ∈ R}; The map from sequence indices to matrix indices, M . Output: the predicted triplet set, T . 1 Initialize D ← dict // the dictionary that maps entity head position to a set of entities that begin with this head position 2 Initialize E ← set // the set of (subject tail position, object tail position) 3 Initialize T ← set 4 for i ← 1 to tag sequence length do 5</p><p>if </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Loss Function</head><p>We define the training loss as below:</p><formula xml:id="formula_3">L link = − 1 N N i=1,j≥i * ∈{E,H,T } log P (y * i,j =l * )<label>(4)</label></formula><p>Here, N is the length of the input sentence,l is the true tag, E, H, and T denote the taggers of EH-to-ET, SH-to-OH and ST-to-OT, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>For the convenience to compare our model with previous work, we follow the popular choice of datasets: NYT <ref type="bibr" target="#b13">(Riedel et al., 2010)</ref> and WebNLG <ref type="bibr" target="#b4">(Gardent et al., 2017)</ref>. There are two versions of these two datasets according to the annotation standard: 1) annotating the last word of the entities and 2) annotating the whole entity span. <ref type="bibr">Zeng</ref>    <ref type="bibr" target="#b17">(Wei et al., 2020)</ref> and <ref type="bibr" target="#b19">(Yu et al., 2020)</ref>, which is the number of the original WebNLG dataset instead of the subsets they used. We recount and give the correct numbers. marks the relation number of WebNLG . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation</head><p>In our experiments, to keep in line with previous works, we use Partial Match for NYT and WebNLG , an extracted triplet is regarded as correct if the relation and the head of both subject entity and object entity are all correct, and Exact Match for NYT and WebNLG, the whole spans of subject and object are needed to be matched. We follow popular choice to report the standard micro Precision (Prec.), Recall (Rec.), and F1-score as in line with all the baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Implementation Details</head><p>Our TPLinker is implemented with PyTorch and the network weights are optimized with Adam (Kingma and Ba, 2014). We try two encoders in this paper. One is the combination of 300-dimensional GloVe embeddings <ref type="bibr" target="#b12">(Pennington et al., 2014)</ref> and 2-layer stacked BiLSTM, the hidden dimension of the 2 layers are set as 300 and 600 respectively. Dropout is applied to word embeddings and hidden states with a rate of 0.1. Another is BERT, where we use the base cased English model 3 . The learning rate is set as 1e-3/5e-5 in the backbone of BiLSTM/BERT. We also conduct Cosine Annealing Warm Restarts learning rate schedule <ref type="bibr" target="#b9">(Loshchilov and Hutter, 2016)</ref>. Following previous works <ref type="bibr" target="#b21">(Zeng et al., 2018;</ref><ref type="bibr" target="#b3">Fu et al., 2019;</ref><ref type="bibr" target="#b17">Wei et al., 2020)</ref>, we set the max length of input sentence to 100. The batch size is set as 24/6 in NYT/WebNLG. We use Tesla V100 to train the model for at most 100 epochs and choose the model with the best performance on the validation set to output results on the test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Comparison Models</head><p>For comparison, we employ the following models as baselines: (1) NovelTagging <ref type="bibr" target="#b24">(Zheng et al., 2017)</ref> applies a novel tagging strategy that incorporates both entity and relation roles, thus the joint extraction task is converted to a sequence labeling problem. This model fails to solve the overlapping problem; (2) CopyRE <ref type="bibr" target="#b21">(Zeng et al., 2018)</ref> first explores the encoder-decoder architecture for this task, trying to face overlapping problem by generating all triples in the sentence. This model can only copy the last word of an entity; (3) MultiHead <ref type="bibr" target="#b0">(Bekoulis et al., 2018)</ref> first identifies all candidate entities, then formulates the task as a multi-head selection problem; (4) GraphRel <ref type="bibr" target="#b3">(Fu et al., 2019)</ref> utilizes graph convolutional network to extract overlapping relations by splitting entity mention pairs into several word pairs and considering all pairs for prediction; (5) OrderCopyRE <ref type="bibr" target="#b22">(Zeng et al., 2019)</ref> is an extension of CopyRE, which applies the reinforcement learning into an encoder-decoder model to generate multiple triplets; (6) ETL-Span <ref type="bibr" target="#b19">(Yu et al., 2020)</ref> applies a span-based tagging strategy and hierarchically decode triplets to model the internal dependencies; (7) WDec <ref type="bibr" target="#b11">(Nayak and Ng, 2020)</ref> is the improvement of CopyRE, which extracts one word at each time step, can extract overlapping relations and triplets with multi-token entities; (8) CasRel <ref type="bibr" target="#b17">(Wei et al., 2020)</ref> is the state-of-the-art method on the NYT and WebNLG datasets based on the BERT backbone, which first identifies all possible head-entities in a sentence then identifies all possible relations and corresponding tail-entities for each head-entity.  <ref type="bibr" target="#b2">(Dai et al., 2019)</ref> and <ref type="bibr" target="#b21">(Zeng et al., 2018)</ref>. * marks results produced with official implementation. marks the datasets that only annotating the last word.  <ref type="bibr" target="#b21">(Zeng et al., 2018)</ref> 61.0 56.6 58.7 ---37.7 36.4 37.1 ---MultiHead * <ref type="figure" target="#fig_0">(Bekoulis et al., 2018)</ref> ---60.7 58.6 59.6 ---57.5 54.1 55.7 GraphRel ‡ <ref type="bibr" target="#b3">(Fu et al., 2019)</ref> 63.9 60.0 61.9 ---44.7 41.1 42.9 ---OrderCopyRE ‡ <ref type="figure" target="#fig_0">(Zeng et al., 2019)</ref> 77.9 67.2 72.1 ---63.3 59.9 61.6 ---ETL-Span ‡ * <ref type="bibr" target="#b19">(Yu et al., 2020)</ref> 84.9 72.3 78.1 85.5 71.7 78.0 84.0 91.5 87.6 84.3 82.0 83.1 WDec ‡ <ref type="bibr" target="#b11">(Nayak and Ng, 2020)</ref> 94.5 76.2 84.4 -  <ref type="table" target="#tab_3">Table 2</ref> reports the results of our models against other baseline methods on all datasets. We can observe that TPLinker outperforms all the baselines in terms of F1-score. Especially, TPLinker BERT improves 2.3 percentages on NYT , 14.0 on NYT, and 3.6 on WebNLG over the state-of-the-art models. To validates the utility of our handshaking tagging scheme, we ablate the BERT and use BiLSTM as the substituted encoder to output results. It can be seen that TPLinker BiLST M is still very competitive to existing state-of-the-art models, CasRel BERT . What is more, TPLinker BiLST M outperforms CasRel BiLST M by 6.8 percentages on WebNLG , which suggests the superiority of our scheme. Even though the two SOTA models, CasRel and ETL-Span, achieve encouraging scores, they still suffer from some problems. For CasRel, it is inherently a two-stage method, which suffers from both exposure bias and error propagation. For ETL-Span, it has the same problems with CasRel and fails to handle the EPO problem. TPLinker solves all these problems and offers a bonus capability that it can extract a triplet with nested entities. For all we know, CasRel and ETL-Span cannot extract nested subject entities. TPLinker performs well on both the dataset annotating the last word and the one annotating the whole span. Supporting this point, TPLinker achieves almost the same scores on NYT and NYT , which also suggests that the dataset only annotating the last word is not always easier than the one that annotates the whole span. Even on the contrary, it could be harder because different entities may share the same last word, which makes the number of overlapping cases increase. Granted, We figure out that there is a significant gap between the performance on WebNLG and WebNLG , which may disprove the above point. However, we also find out that there are 127 wrong triplets in WebNLG, containing a meaningless empty entity. Plus, WebNLG has 216 relations but WebNLG has only 171. Therefore, we attribute the performance gap to these two reasons. For a fair comparison with the state-of-the-art model on this dataset, we do not fix these problems in the experiments.</p><formula xml:id="formula_4">- - - - - - - - CasRel ‡ LST M (</formula><p>We can also observe that TPLinker BERT achieves a similar F1 score with CasRel BERT on WebNLG . We consider that it is because (1) the performances on WebNLG are already saturated since extracting triplets with 171 predefined relations is very hard, especially the training data is very small (5019 sentences). These methods achieving a 90+ F1 score might have already surpassed human-level performance. In other words, the room for boosting is too limited. (2) Many relations in WebNLG share the same meaning, e.g. LeaderName and Leader, affiliation and affiliations, which are confusing to the model. In many cases, our model will extract both of them, but normally only one of them has been annotated in the test set. The absence of these correct annotations seriously hurts the precision of TPLinker BERT because our model has greater ability in extracting overlapping relations and achieves better recall rate.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.2">Analysis on Different Sentence Types</head><p>To verify the ability of our model in handling the overlapping problem and extracting multiple relations, we conduct further experiments on different subsets of NYT and WebNLG . Results suggest the advantages of TPLinker in handling sentences with overlapping relations or multiple relations. As shown in <ref type="table" target="#tab_6">Table 3</ref>, most baselines present an obvious decreasing trend with the increasing complexity of sentences. However, TPLinker presents a significant improvement on the harder sentences, ones with overlapping relations, or more than two relations. Even though CasRel also presents an increasing trend, TPLinker outperforms CasRel on all subsets except some simpler ones without overlapping or with less than three relations. Especially, TPLinker outperforms CasRel by 6.3 percentages on sentences with more than or equal to 5 relations. <ref type="table" target="#tab_7">Table 4</ref> shows the comparison of computational efficiency between CasRel BERT and TPLinker BERT . In this comparison experiment, we use the official implementation and default configuration of CasRel BERT to produce the statistics data. In the inference phase, the decoding speed of TPLinker BERT is almost 3.6 times as CasRel BERT . Since the number of subjects is uncertain in a given sentence, it is difficult for CasRel BERT to predict objects in batch for each subject. In the official implementation, CasRel BERT is restricted to processes one sentence at a time, which means it is seriously inefficient and difficult to deploy. On the contrary, TPLinker BERT is capable of handling data in batch mode because it is a one-stage model. Besides, even though we set the batch size of TPLinker BERT to 1, the inference speed is still competitive, which again confirms the efficiency of TPLinker BERT . Actually, CasRel BERT and TPLinker BERT both use BERT as the basic encoder, which is the most time-consuming part and takes up the most of model parameters, so the time cost of handshaking tagging is not significant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.3">Analysis on Computational Efficiency</head><p>In this paper, we propose an end-to-end sequence labeling model TPLinker for joint extraction of entities and relations based on a novel handshaking tagging strategy, by which the joint extraction task is converted to a token pair linking game. To the best of our knowledge, TPLinker is the first one-stage joint extraction model that can extract all kinds of overlapping relations without the influence of exposure bias. Experimental results show that our model outperforms all baselines and achieves a new state-ofthe-art on two public datasets. Further analysis especially demonstrates the capabilities of our model on handling sentences with overlapping relations and multiple relations. The results also prove that it is of benefit to close up the gap between training and inference. In the future, we would like to generalize the token linking idea and explore its performance on other information extraction problems, such as nested name entity extraction and event extraction.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>oFigure 1 :</head><label>1</label><figDesc>Examples of the Normal, SingleEntityOverlap (SEO), and EntityPairOverlap (EPO) cases. The overlapping entities are marked in blue.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>(Best viewed in color.) Left: A tagging matrix. For the convenience to illustrate, we show all tags in one matrix, in which each color corresponds to a specific kind of tag. Right: An example of the Handshaking Tagging Scheme, the region in shade is not included in the tag sequence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>et al. (2018),<ref type="bibr" target="#b22">Zeng et al. (2019)</ref>,<ref type="bibr" target="#b3">Fu et al. (2019)</ref> and<ref type="bibr" target="#b17">Wei et al. (2020)</ref> used the first version while<ref type="bibr" target="#b19">Yu et al. (2020)</ref> chose the second version. For fair comparisons, we evaluate our model on both settings. The first version datasets are denoted as NYT and WebNLG and the second ones are denoted as NYT and WebNLG, respectively. Following<ref type="bibr" target="#b21">Zeng et al. (2018)</ref>, to further study</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Statistics of the datasets in our experiments. Normal set contains sentences without overlapping triple. SPO is short for Single Pair Overlapping. EPO is short for Entity Pair Overlapping. Note that the relation number of WebNLG and WebNLG were miswritten as 246 in</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Main results. Bold marks the highest score. ‡ marks results quoted directly from the original papers.</figDesc><table /><note>† marks results reported by</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Rec. F1 Prec. Rec. F1 Prec. Rec. F1 Prec. Rec. F1</figDesc><table><row><cell>Model Prec. NovelTagging  † (Zheng et al., 2017) -</cell><cell>NYT -</cell><cell>-</cell><cell>NYT 32.8 30.6 31.7</cell><cell>-</cell><cell>WebNLG -</cell><cell>-</cell><cell>WebNLG 52.5 19.3 28.3</cell></row><row><cell>CopyRE  ‡</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>F1 score on sentences with different overlapping pattern and different triplet number. Results of baselines are all quoted directly from<ref type="bibr" target="#b17">(Wei et al., 2020)</ref> except for ETL-Span, of which the results are reproduced by the official implementation.</figDesc><table><row><cell>Model</cell><cell cols="2">NYT Normal SEO EPO N = 1 N = 2 N = 3 N = 4 N ≥ 5 Normal SEO EPO N = 1 N = 2 N = 3 N = 4 N ≥ 5 WebNLG</cell></row><row><cell>CopyRE</cell><cell>66.0 48.6 55 67.1 58.6 52.0 53.6 30.0</cell><cell>59.2 33.0 36.6 59.2 42.5 31.7 24.2 30.0</cell></row><row><cell>GraphRel</cell><cell>69.6 51.2 58.2 71.0 61.5 57.4 55.1 41.1</cell><cell>65.8 38.3 40.6 66.0 48.3 37.0 32.1 32.1</cell></row><row><cell>OrderCopyRE</cell><cell>71.2 69.4 72.8 71.7 72.6 72.5 77.9 45.9</cell><cell>65.4 60.1 67.4 63.4 62.2 64.4 57.2 55.7</cell></row><row><cell>ETL-Span</cell><cell>88.5 87.6 60.3 85.5 82.1 74.7 75.6 76.9</cell><cell>87.3 91.5 80.5 82.1 86.5 91.4 89.5 91.1</cell></row><row><cell>CasRelBERT</cell><cell>87.3 91.4 92 88.2 90.3 91.9 94.2 83.7</cell><cell>89.4 92.2 5 94.7 5 89.3 90.8 94.2 92.4 90.9</cell></row><row><cell cols="2">TPLinkerLST M 80.7 85.5 86.5 80.8 85.4 85.8 87.8 81.5</cell><cell>86.2 91.4 92.5 85.9 89.1 92.9 92.4 91.4</cell></row><row><cell cols="2">TPLinkerBERT 90.1 93.4 94.0 90.0 92.8 93.1 96.1 90.0</cell><cell>87.9 92.5 95.3 88.0 90.1 94.6 93.3 91.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>Comparison on Computational Efficiency. Params all denotes the number of parameters of the entire model. Prop encoder is the proportion of encoder parameters in the total model parameters. Inference Time represents the the average time (ms) the model takes to process a sample. † marks the inference time when the batch size is set to 1.</figDesc><table><row><cell>Model</cell><cell>Params all</cell><cell cols="3">NYT Prop encoder Inference Time Params all</cell><cell cols="2">WebNLG Prop encoder Inference Time</cell></row><row><cell>CasRelBERT</cell><cell>107,719,680</cell><cell>99.96%</cell><cell>54.0</cell><cell>107,984,216</cell><cell>99.76%</cell><cell>76.8</cell></row><row><cell cols="2">TPLinkerBERT 109,602,962</cell><cell>98.82%</cell><cell>15.2 / 82.7  †</cell><cell>110,281,220</cell><cell>98.21%</cell><cell>25.6 / 112.6  †</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">For ease of exposition, we use "entity/subject/object head" to represent the start position of one entity/subject/object.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Available at https://huggingface.co/bert-base-cased</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">The original paper confuses the score on WebNLG-EPO and the score on WebNLG-SEO. The author has corrected them and updated the paper on arXiv (https://arxiv.org/abs/1909.03227). We use the correct scores here.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was supported by the National Key R&amp;D Program of China (Grant No. 2017YFB0802804).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Joint entity recognition and relation extraction as a multi-head selection problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giannis</forename><surname>Bekoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Deleu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Demeester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Develder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Exploiting syntactico-semantic structures for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee</forename><surname>Seng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Joint extraction of entities and overlapping relations using position-attentive sequence labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dai</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyan</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yajuan</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shan</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaoqiao</forename><surname>She</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Graphrel: Modeling text as relational graphs for joint entity and relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsu-Jui</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng-Hsuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Yun</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Creating training corpora for nlg micro-planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Gardent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anastasia</forename><surname>Shimorina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashi</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Perez-Beltrachini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Table filling multi-task recurrent neural network for joint entity and relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pankaj</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schtze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Andrassy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
		<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Incremental joint extraction of entity mentions and relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Entityrelation extraction as multi-turn question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoya</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zijun</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiayu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arianna</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duo</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.03983</idno>
		<title level="m">Sgdr: Stochastic gradient descent with warm restarts</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Modeling joint entity and relation extraction with table representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makoto</forename><surname>Miwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutaka</forename><surname>Sasaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1858" to="1869" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Effective modeling of encoder-decoder architecture for joint entity and relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tapas</forename><surname>Nayak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee Tou</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Modeling relations and their mentions without labeled text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECML-PKDD</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Joint type inference on entities and relations via graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changzhi</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yeyun</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanbin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daxin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Man</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sun</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A hierarchical framework for relation extraction with reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryuichi</forename><surname>Takanobu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiexi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Jointly extracting multiple triplets with multilayer translation constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weidong</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A novel cascade binary tagging framework for relational triple extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhepei</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlin</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Jointly identifying entities and extracting relations in encyclopedia text via a graphical model approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofeng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wai</forename><surname>Lam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
		<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1399" to="1407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Joint extraction of entities and relations based on a novel decomposition strategy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobo</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yubin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tingwen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ECAI</title>
		<meeting>ECAI</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Kernel methods for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Zelenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chinatsu</forename><surname>Aone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Richardella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Extracting relational facts by an end-to-end neural model with copy mechanism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangrong</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daojian</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shizhu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning the extraction order of multiple relational facts in a sentence with reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangrong</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shizhu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daojian</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengping</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-IJCNLP</title>
		<meeting>EMNLP-IJCNLP</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Bridging the gap between training and inference for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fandong</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Joint extraction of entities and relations based on a novel tagging scheme</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suncong</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyun</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuexing</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
