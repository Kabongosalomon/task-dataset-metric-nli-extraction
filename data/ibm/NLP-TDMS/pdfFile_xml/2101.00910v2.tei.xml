<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Global2Local: Efficient Structure Search for Video Action Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021">CVPR 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shang-Hua</forename><surname>Gao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Han</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhong-Yu</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pai</forename><surname>Peng</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Cheng</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>CS</roleName><forename type="first">†</forename><surname>Tklndst</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nankai</forename><surname>University</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tencent</forename><forename type="middle">2</forename><surname>Nlpr</surname></persName>
						</author>
						<title level="a" type="main">Global2Local: Efficient Structure Search for Video Action Segmentation</title>
					</analytic>
					<monogr>
						<title level="m">IEEE International Conference on Computer Vision and Pattern Recognition</title>
						<imprint>
							<date type="published" when="2021">CVPR 2021</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T19:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Temporal receptive fields of models play an important role in action segmentation. Large receptive fields facilitate the long-term relations among video clips while small receptive fields help capture the local details. Existing methods construct models with hand-designed receptive fields in layers. Can we effectively search for receptive field combinations to replace hand-designed patterns? To answer this question, we propose to find better receptive field combinations through a global-to-local search scheme. Our search scheme exploits both global search to find the coarse combinations and local search to get the refined receptive field combination patterns further. The global search finds possible coarse combinations other than human-designed patterns. On top of the global search, we propose an expectation guided iterative local search scheme to refine combinations effectively. Our global-to-local search can be plugged into existing action segmentation methods to achieve stateof-the-art performance. The source code is publicly available on https://github.com/ShangHua-Gao/ G2L-search.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Action recognition segments the action of each video frame, playing an important role in computer vision applications such as clips tagging <ref type="bibr" target="#b58">[59]</ref>, video surveillance <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref>, and anomaly detection <ref type="bibr" target="#b53">[54]</ref>. While conventional works <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b55">56]</ref> have continuously refresh the recognition performance of short trimmed videos containing a single activity, segmenting each frame densely in long untrimmed videos remains challenging as those videos contain many activities with different temporal lengths. Temporal convolutional networks (TCN) <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b64">65]</ref> are widely adapted in action segmentation tasks with their ability to capture both long-term and short-term information. Appropriate re- ceptive fields in layers are crucial for TCN as large receptive fields contribute to long-term dependencies while small receptive fields benefit the local details. State-of-the-art (SOTA) methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b64">65]</ref> rely on human-designed receptive field combinations, i.e., dilation rate or pooling size in each layer, to make the trade-off between capturing long and short term dependencies. Questions have raised: Are there other effective receptive field combinations that perform comparable or better than hand-designed patterns? Will the receptive field combinations vary among different datasets? To answer those questions, we propose to find the possible receptive field combinations in a coarse-to-fine scheme through the global-to-local search.</p><p>As shown in <ref type="figure" target="#fig_0">Fig. 1</ref>, unlike the existing network architecture search spaces <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b42">43]</ref> that only contain several operation options within a layer, the available search space of receptive field combinations could be huge. Suppose a TCN has L convolutional layers and D possible receptive fields in each layer. There are D L possible combinations, i.e., the number of possible receptive field combinations in MS-TCN <ref type="bibr" target="#b11">[12]</ref> is 1024 <ref type="bibr" target="#b39">40</ref> . Directly apply network architecture searching algorithms <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b65">66]</ref> to such a huge search space is impractical. For example, conventional reward-based searching methods <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b65">66]</ref> are not suitable for CNN-based models with a huge search space. The model training and performance evaluation of each possible combination are too costly. Differentiable architecture searching methods (DARTS) <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b42">43]</ref> rely on shared big networks to save training time, thus only supporting several operators within a layer due to the model size constraint. Moreover, they heavily dependent on the initial combination and fail to find new combinations with a huge difference from the initial one. While our goal is to explore effective receptive field combinations other than human-designed patterns in the huge search space, those algorithms are either too costly or cannot support the large search space.</p><p>To explore the search space with low cost, we exploit both a genetic-based global search to find the coarse receptive field combinations and an expectation guided iterative (EGI) local search to get the refined combinations. Specifically, we follow the MS-TCN <ref type="bibr" target="#b11">[12]</ref> to use dilation rates to determine layers' receptive fields. A genetic-based global search scheme is proposed to find coarse combinations within a sparsely sampled search space at an affordable cost. The global search discovers various combinations that achieve even better performance than human designings but have completely different patterns. Based on the globalsearched coarse combinations, we propose the local search to determine fine-grained dilation rates. Our proposed convolutional weight-sharing scheme enforces learned dilation weights to approximate the probability mass distribution for calculating the expectation of dilation rates. The expectation guided searching transfer the discrete dilation rates into a distribution, allowing fine-grained dilation rates searching. With an iteratively searching process, the local search gradually finds more effective fine-grained receptive field combinations with low cost. Our proposed global-to-local search scheme can be plugged into existing models, surpassing human-designed structures with impressive performance gain. In summary, we make two major contributions:</p><p>• The expectation guided iterative local search scheme enables searching fine-grained receptive field combinations in the dense search space.</p><p>• The global-to-local search discovers effective receptive field combinations with better performance than hand-designed patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Action Segmentation</head><p>Many approaches have been proposed for modeling dependencies for action segmentation. Early works <ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref> mostly model the changing state of appearance and actions with sliding windows <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b50">51]</ref>. Thus they mainly focus on short-term dependencies. Capturing both short-term and long-term dependencies then gradually becomes the focus of action segmentation. Sequential Model. Sequential models capture long-short term dependencies in an iterative form. Vo and Bobick <ref type="bibr" target="#b63">[64]</ref> apply the Bayes network to segment actions represented with the stochastic context-free grammar. Tang et al. <ref type="bibr" target="#b62">[63]</ref> use a hidden Markov model to model transitions between states and durations. Later, hidden Markov models are combined with context-free grammar <ref type="bibr" target="#b31">[32]</ref>, Gaussian mixture model <ref type="bibr" target="#b32">[33]</ref>, and recurrent networks <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b49">50]</ref> to model longterm action dependencies. Cheng et al. <ref type="bibr" target="#b6">[7]</ref> apply the sequence memorizer to capture long-range dependencies in visual words learned from the video. However, these sequential models are inflexible in parallel modeling longterm dependencies and usually suffer from information forgetting <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b39">40]</ref>.</p><p>Multi-stream Architecture. Some researchers <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b57">58]</ref> utilize multi-stream models to model dependencies from both the long and short term. Richard and Gall employ <ref type="bibr" target="#b48">[49]</ref> dynamic programming to inference models composed of length model, language model, and action classifier. Singh et al. <ref type="bibr" target="#b56">[57]</ref> learn short video chunks representation with a two-stream network and pass these chunks to a bi-directional network to predict action segmentation results sequentially. A three-stream architecture is proposed in <ref type="bibr" target="#b57">[58]</ref>, which contains egocentric cues, spatial and temporal streams. Tricornet <ref type="bibr" target="#b9">[10]</ref> utilizes a hybrid temporal convolutional and recurrent network to capture local motion and memorize long-term action dependencies. Cou-pledGAN <ref type="bibr" target="#b18">[19]</ref> uses a GAN model to utilize multi-modal data to better model human actions' evolution. Capturing long-short term information with multiple streams increases the computational redundancy.</p><p>Temporal Convolutional Network. Recently, temporal convolutional networks (TCN) are introduced to model dependencies of different ranges within a unified structure by adjusting receptive fields and can process long videos in parallel. <ref type="bibr">Lea et al. [35]</ref> propose the encoder-decoder style TCN for action segmentation to capture long-range temporal patterns and apply the dilated convolution to enlarge the receptive field. TDRN <ref type="bibr" target="#b36">[37]</ref> further introduces the deformable convolution to process the full-resolution residual stream and low-resolution pooled stream. MS-TCN <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b39">40]</ref> utilizes multi-stage dilated TCNs with hand-designed dilation rate combinations to capture information from various temporal receptive fields. However, the adjustment of receptive fields still relies on human design, which may not be appropriate. Our proposed efficient receptive field combinations searching scheme can automatically discover more efficient structures, improving these TCN based methods.</p><p>Complementary Techniques. Instead of capturing longterm and short-term information, some works <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b64">65]</ref> further improve the action segmentation performance with boundary refinement. Li et al. <ref type="bibr" target="#b10">[11]</ref> utilize an iterative training procedure with transcript refinement and soft boundary assignment. Wang et al. <ref type="bibr" target="#b64">[65]</ref> leverage semantic boundary information to refine the prediction results. Other researchers focus on action segmentation under the weakly supervised <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b49">50]</ref> or unsupervised <ref type="bibr" target="#b54">[55]</ref> settings. These works still rely on the efficient TCN to model the action dependencies, thus complementing the proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Network Architecture Search</head><p>The genetic algorithm <ref type="bibr" target="#b44">[45]</ref> has achieved remarkable performance on a wide range of applications. Many geneticbased methods are recently introduced for the neural networks architecture search of vision tasks <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b65">66</ref>]. An evolutionary coding scheme is proposed in Genetic CNN <ref type="bibr" target="#b65">[66]</ref> to encode the network architecture to a binary string. A hierarchical representation is presented by Liu et al. <ref type="bibr" target="#b41">[42]</ref> to constrain the search space. Real et al. <ref type="bibr" target="#b46">[47]</ref> regularize the evolution by an age property selection operation. Sun et al. <ref type="bibr" target="#b60">[61]</ref> introduce a variable-length encoding method for effective architecture designing. However, the genetic algorithm requires the training of each candidate, consuming too much computational cost when faced with a huge search space.</p><p>Differentiable architecture search <ref type="bibr" target="#b42">[43]</ref> saves the training time by introducing a large network containing subnetworks with different searching options. The importance of searched blocks is determined by gradient backpropagation <ref type="bibr" target="#b52">[53]</ref>. This differentiable search idea is further extended <ref type="bibr" target="#b66">[67]</ref> to deal with semantic segmentation <ref type="bibr" target="#b40">[41]</ref> and other tasks beyond image classification <ref type="bibr" target="#b2">[3]</ref>. However, these network architecture search methods are designed for finding a limited number of operations such as convolution, ReLU, batch normalization, short connection, etc. Thus, they cannot handle the huge receptive field combinations search space. In this paper, we propose a global search to handle the huge search space with sparse sampling. The expectation guided iterative local search then transfers the sparse search space of receptive fields into the dense one for fine-level searching.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>The pipeline of our proposed global-to-local search method has two components: (i) a genetic-based global search algorithm that produces coarse but competitive combinations of the receptive fields; (ii) an expectation guided iterative local search scheme that locally refines the globalsearched coarse structures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Description</head><p>Our objective is to efficiently search for optimal receptive field combinations for the given dataset. The receptive field can be represented with multiple forms, such as the dilation rate, kernel size, pooling size, stride, and the stack number of layers. In this work, we mainly follow the MS-TCN <ref type="bibr" target="#b11">[12]</ref> to formulate the receptive fields using the combinations of dilation rates in layers and propose to evolve these combinations during the searching process. Note that other receptive field representations can also be applied to the proposed global-to-local search with some minor adjustments.</p><p>Suppose a TCN has L convolutional layers and D = {d 1 , d 2 , ..., d N } is the possible dilation-rates/receptivefields in each layer. The combination of receptive fields is</p><formula xml:id="formula_0">represented with C = {c 1 , ..., c l , ..., c L }, where l ∈ [1, L]</formula><p>is the index of layers with dilated convolutions, and c l ∈ D is the receptive field of each layer. There are |D| L possible combinations of receptive fields, i.e., the possible receptive field combinations in MS-TCN <ref type="bibr" target="#b11">[12]</ref> is 1024 40 when dilation rates ranging from 1 to 1024. Directly searching for effective combinations in such a large search space is impractical. We thus decompose the searching process into the global and local search to find the combination in a coarseto-fine manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Global Search</head><p>The objective of the global search is to find the coarse receptive field combinations with affordable cost. Therefore, we reduce the search space by sparsely sampling the dilation rates within layers. Multiple sparse discrete sampling strategies such as uniform sampling, gradually sparse sampling, and gradually dense sampling can be applied to sparse the search space. A gradually sparse sampling scheme from small to large dilation rates is appropriate for the action segmentation task. Because small receptive fields benefit the extraction of precise local details while large receptive fields contribute to coarse long-term dependencies of video sequences. Therefore we formulate the receptive field space in global search as:</p><formula xml:id="formula_1">D g = {d i = k i , i ∈ [0, 1, · · · T ]},<label>(1)</label></formula><p>where k is the controller of the search space sparsity, and T determines the largest available receptive field. With the same maximum receptive field, |D g | |D|. The search space is greatly reduced. i.e., when set k = 2, and set the maximum receptive field to 1024 as in MS-TCN, the search space is reduced from 1024 40 to 11 <ref type="bibr" target="#b39">40</ref> .</p><p>However, the reduced space of receptive field combinations can still be huge, unaffordable for a brute force search. We propose a genetic algorithm <ref type="bibr" target="#b44">[45]</ref> based method to find coarse combinations that are competitive or even better than  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Crossover</head><p>Mutation Selection human designing. We illustrate one iteration of our proposed genetic-based global search in <ref type="figure" target="#fig_1">Fig. 2</ref>. We now detail the selection, crossover, mutation process within our proposed global search method.</p><formula xml:id="formula_2">E(C i )</formula><p>Selection. The population of receptive field combinations can be described as a group of candidate structures P =</p><formula xml:id="formula_3">{C i , i ∈ [1, M ]},</formula><p>where C i is the candidate structure in the global search space, and M is the number of individuals in the population. The selection operation selects individuals to be kept in P based on the estimated performance of each structure C i , denoted by E(C i ):</p><formula xml:id="formula_4">E(C i ) = f (V |C i , θ n ),<label>(2)</label></formula><p>where f (·) is the evaluation metric detailed in Sec. 4, and V , θ n are the cross-validation set and model trained with n epochs, respectively.</p><p>Crossover. This operation generates new samples of receptive field combinations. Every two combinations in the population are exchanged to born new patterns of the combination while maintaining the local structures. Each C i will be selected for the crossover operation with probability p(C i ):</p><formula xml:id="formula_5">p(C i ) = E(C i ) M i E(C i ) .<label>(3)</label></formula><p>Instead of randomly exchanging individual points, we choose to exchange random segments of the receptive field combination since the representation ability lies in the combination patterns. Specifically, we randomly choose two anchors and exchange combinations within anchors to generate new samples.</p><p>Mutation. The mutation operation avoids getting stuck in local optimal results by choosing an individual with probability p m and randomly changing a value within the selected combination.</p><p>The global search process can be summarised as Algorithm (1), and a simple example is given in <ref type="figure" target="#fig_1">Fig. 2</ref>. With the coarse search space and the global search method, we can find receptive field combinations with different patterns than human-designed structures while having similar or even better performance. We further propose the local search to locally find the more efficient combinations on top of the global-searched structures. We show in Tab. 5 that local search heavily relies on the initial structure, revealing the importance of global search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Expectation Guided Iterative Local Search</head><p>The local search aims to find more efficient receptive field combinations in a fine-grained level at a low cost. A naive approach is to sample finer-grained dilation rates near the initial dilation rate searched by the global search and apply existing DARTS algorithms <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b42">43]</ref> to choose for the proper one. However, even with the good initial structure provided by the global search, the available range of finegrained dilation rates is still large. Existing search algorithms are designed for searching sparse operators with several choices in each layer, thus cannot handle dilation rates with hundreds of choices. While too sparsely sampling is in conflict with our goal of searching for the finer-grained receptive fields. Also, DARTS methods search operators with different functionality <ref type="bibr" target="#b42">[43]</ref>, while the searching on receptive fields only contains one functional dimension. Different subsets in the dataset sometimes prefer different searching options. Searching within a functional dimension enables us to determine dilation rates with the expectation of all subsets instead of choosing the option required by one majority subset. Therefore, we propose an expectation guided iterative (EGI) local search scheme to determine the finer-level dilation rates on top of the global-searched structures.</p><p>Suppose that the receptive field of a layer l is D l . For a dataset, once we get the probability mass distribution of dilation rates around D l , we can obtain the expected dilation rate with the weighted average of the dilation rates required by all subsets. However, the probability mass of di- <ref type="figure">Figure 3</ref>. The approximated probability mass function of dilation rates is determined by the multi-dilated convolutional layer with shared weights. di is the dilation rate and αi is the PMF in Eqn. (4).</p><formula xml:id="formula_6">d 0 d 1 d 2 d 3 d S α 0 α 1 α 2 α 3 α S +</formula><p>lation rates for the dataset is inaccessible. Therefore, we utilize a convolutional weight-sharing scheme to enforce the learned importance weights of dilation rates to approximate the probability mass. To get the approximated probability mass function of dilation rates, we first evenly sample S dilation rates near the initial dilation rate D l within the range of [D l ± ∆D l ]. The set of available dilation rates within this layer is</p><formula xml:id="formula_7">T l = {d i |i ∈ [1, S]}, where d i = D l − ∆D l + (i − 1) · 2∆D l /(S − 1)</formula><p>. ∆D l is the finer controller of the search space that is smaller than the sampling sparsity in the global search. With the dilation rates set T l , we propose a multi-dilated layer composed of a shared convolutional weight and multiple branches with different dilation rates, as shown in <ref type="figure">Fig. 3</ref>. Each branch has a unique weight to determine the importance of the dilation rate. During the searching process, the weights are updated with the gradient backpropagation to reflect the receptive field requirements of the dataset. Existing DARTS schemes <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b66">67]</ref> have separated weights in each branch. In contrast, our convolutional weight-sharing strategy forces the model to learn the approximated probability of receptive fields and ease the model convergence. Specifically, the dilation rates in the multi-dilated convolutional layer are set to T l . Apart from the shared convolutional θ, the multi-dilated layer contains weight W = Output Input <ref type="figure">Figure 4</ref>. Visualization of receptive field combinations changes during the EGI local searching process. {w 1 , w 2 , ..., w i , i ∈ [1, S]} to determine the importance of the dilation rates. W is unbounded, thus cannot be directly used to determine the dilation rates probability. Therefore, we propose a normalization function to get the approximated probability mass function P M F (d i ) of dilation rates through normalizing w i :</p><formula xml:id="formula_8">P M F (d i ) = α i = |w i | S i |w i | .<label>(4)</label></formula><p>With the probability mass function, given the input feature x, the output y of the multi-dilated convolutional layer can be written as follows:</p><formula xml:id="formula_9">y = S i α i Ψ(x, d i , θ),<label>(5)</label></formula><p>where Ψ(x, d i , θ) is the convolutional operation with the shared weight θ and dilation rate d i . α i is updated with gradient optimization. Once we get the probability mass function, the newly searched dilation rate D l is obtained with the expectation:</p><formula xml:id="formula_10">D l = di∈T l P M F (d i ) · d i .<label>(6)</label></formula><p>To reduce the computational cost during the local search process, we reduce the number of dilation rates in T l to 3 by default and apply the iterative search scheme to find the more suitable dilation rate based on the D l from the last iteration. The local search process can be summarised as Algorithm <ref type="bibr" target="#b1">(2)</ref>. Furthermore, <ref type="figure">Fig. 4</ref> visualizes the dilation rates changes during the local searching process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>We introduce the implementation details, verify the effectiveness, and analyze the property of our proposed global-to-local search scheme in this section. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Implementation Details</head><p>Structure Searching and Training. Our proposed method is implemented with the PyTorch <ref type="bibr" target="#b45">[46]</ref>, Mind-Spore <ref type="bibr" target="#b0">[1]</ref>, and Jittor <ref type="bibr" target="#b27">[28]</ref> frameworks. Following existing works <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b39">40]</ref>, features are first extracted from videos using the I3D network <ref type="bibr" target="#b3">[4]</ref> and then passed to action segmentation models to get the temporal segmentation. Since our proposed global-to-local search scheme is model-agnostic, the training settings for model evaluation, i.e., training epochs, optimizer, learning rate, batch size, keep the same with the cooperation methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b64">65]</ref>. In the global search stage, we set the total iterations N = 100, k = 2 in Eqn. (1), the initialized population size M = 50, and mutation probability p m = 0.2. The T in Eqn. (1) is set to 10, indicating the maximum dilation rate of the global search space is 1024. We observe that 5 epochs of training can reflect the structure performance, and therefore models are trained with 5 epochs for evaluation. In the EGI local search stage, ∆D l and S are set to be 0.1D l and 3, respectively. We train the model for 30 epochs during local search and update the structure every 3 epochs.</p><p>Datasets. Following <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b64">65]</ref>, we evaluate our proposed method on three popular action segmentation datasets: Breakfast <ref type="bibr" target="#b30">[31]</ref>, 50Salads <ref type="bibr" target="#b59">[60]</ref>, and GTEA <ref type="bibr" target="#b14">[15]</ref>. The details of the three datasets are summarised in Tab. 2.</p><p>As far as we know, the Breakfast dataset is the largest public dataset for action segmentation task, which has a larger number of categories and samples compared with the other two datasets. So we perform our ablations mainly on the Breakfast dataset if not otherwise stated. Following common settings <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b64">65]</ref>, we perform 4-fold crossvalidation for the Breakfast and GTEA dataset and 5-fold cross-validation for the 50Salads dataset.  <ref type="table">Table 3</ref>. Cooperating with SOTA methods. We perform the whole search pipeline based on MS-TCN <ref type="bibr" target="#b11">[12]</ref>. Because of the limited computing resources, we only perform the EGI local search on MS-TCN++ <ref type="bibr" target="#b39">[40]</ref> and BCN <ref type="bibr" target="#b64">[65]</ref>, denoted by †. SSTDA <ref type="bibr" target="#b4">[5]</ref> uses MS-TCN <ref type="bibr" target="#b11">[12]</ref> as a backbone, so we directly add our searched structure to SSTDA, denoted by ‡.</p><p>Evaluation Metrics. We follow previous works <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b64">65]</ref> to use the frame-wise accuracy (Acc), segmental edit score (Edit) <ref type="bibr" target="#b34">[35]</ref>, and segmental F1 score <ref type="bibr" target="#b37">[38]</ref> at temporal intersection over union with thresholds 0.1, 0.25, 0.5 (F@0.1, F@0.25, F@0.5) as our evaluation metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Performance Evaluation</head><p>Global2Local Search. Our proposed global-to-local search aims to find new combinations of receptive fields better than human designings. We mainly take MS-TCN <ref type="bibr" target="#b11">[12]</ref> as our baseline architecture to perform the global-to-local search. When testing the MS-TCN on the Breakfast dataset, we train all models with the batch size 8 to save training time. The reproduced results shown in Tab. 1 indicates that large batch size achieves much better performance. Tab. 1 shows that global-to-local searched structures achieve considerable performance improvements than human-designed baselines, i.e., the searched structure surpasses the reproduced baseline with 5.8% in terms of F@0.  TCN++ <ref type="bibr" target="#b39">[40]</ref>, BCN <ref type="bibr" target="#b64">[65]</ref>, and SSTDA <ref type="bibr" target="#b4">[5]</ref>. Also, we give comparisons on two small scale datasets, 50Salads and GTEA dataset in Tab. 10 and supplementary, proving the effectiveness of our proposed global-to-local search.</p><p>Global Search. Global search reduces the computational cost with the sparse search space and our proposed geneticbased searching scheme. <ref type="figure">Fig. 5</ref> shows the performance change of models during the global searching process. Compared with the random search, the genetic-based global search convergences faster. The standard division of model performance searched by genetic-based search is smaller than the random search, showing the stability of our proposed search scheme. The visualized well-performed global-searched structures shown in the supplementary prove that the global search discovers various structures completely different from human-designed patterns. Tab. 5 also shows that the local search heavily relies on globalsearched structures to achieve better performance.</p><p>Local Search. Based on the global-searched structures, our proposed EGI local search aims to fine-tune the receptive field in a finer search space. Compared with the DARTS <ref type="bibr" target="#b42">[43]</ref> method that only supports several search options, the EGI local search iteratively finds the accurate dilations in a dense space, obtaining structures with better performance, as shown in Tab. 4. As shown in Tab. 6, EGI local search is insensitive to the number of sampling dilation rates S, as it searches dilation rates with the expectation. Tab. 5 shows that the EGI local search can boost the performance of randomly generated, human-designed, and global-searched structures. Still, the performance of the local-searched structures is related to the initial structures, as local search focuses on searching for receptive fields within a finer local search space. We visualize the searching process of the iterative local search in <ref type="figure">Fig. 4</ref>. The dilation rates for each layer gradually converge to a suitable state during the iterative searching process. Tab. 7 verifies different ways to get the approximated probability mass function P M F (d i ) from weight w. Eqn. (4) is more superior than the sigmoid function and softmax function as it maintains the probability distribution while the other two functions change the distribution non-linearly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Observations</head><p>In this section, we try to exploit the common knowledge contained in the global-to-local searched structures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Connections between Receptive Fields and Data.</head><p>We want to know if receptive field combinations vary among data. Therefore, we evaluate the generalization ability of the searched structures on the subsets of the same dataset and different datasets, respectively. Within the BreakFast dataset, we perform the global-to-local search on one fold and then evaluate the searched structures on other folds. Tab. 9 shows that there is almost no obvious performance gap on different folds, indicates that receptive field combinations almost have no difference within a dataset. However, when search and evaluate structures across different datasets, different structures searched on different datasets have a large performance gap as shown in Tab. 8. We can conclude that different data distribution will result in different receptive field combinations. We visualize the structures searched from different datasets in <ref type="figure">Fig. 6</ref>. The struc- <ref type="bibr">40 24 9 464</ref>  <ref type="table" target="#tab_1">582 1067 227 977 87 14   8 20 59 4 191 1222 3 1 3 446  230 1 1 3 57 27 9 14 6 111  522 16 123 3 32 8 12 74 197 531   3 1080 11 153 531 72 1245 20 42 432  6 11 37 99 527 29 14 1243 197 9  1 54 15 5 1 13 20 10 136 6  1 24 6 37 182 9 1053 85 241 23   4 5 3 26 449 9 274 64 3 25  12 462 23 1 1 3 1 11 2 34  23 2 129 2 13 220 2 102 7 144  2 3 29 4 2 2 482 73 34</ref>  ture searched on 50Salads dataset trends to have larger receptive fields, while the structure searched on the GTEA dataset has smaller receptive fields. The number of video frames shown in Tab. 2 is positively correlated with receptive fields. Longer videos need larger receptive fields to capture the context. We also show more searched structures in the supplementary.</p><p>Receptive Fields for Different Stages. Our global-tolocal search is based on MS-TCN. MS-TCN contains four stages, and all stages share the same receptive field combination in human designing. The visualized searched structures shown in <ref type="figure">Fig. 6</ref> demonstrate that different stages have different receptive field combinations, which conflicts with human designing. We further count the average receptive fields of each stage among all individuals. The range of performance and the average dilation rates of each stage are shown in <ref type="figure">Fig. 7</ref>. The average dilation rate in the first stage of MS-TCN tends to be large on high-performance structures. In contrast, the average dilation rate in the third stage of MS-TCN is relatively small on high-performance structures. We assume that the first stage of MS-TCN requires large receptive fields to get the long-term context for coarse prediction, while the following stages need small receptive fields to refine the results locally.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We propose a global-to-local search scheme to search for effective receptive field combinations in a coarse-tofine scheme. The global search discovers effective receptive field combinations with better performance than hand MS-TCN Arch-50Salads Arch-GTEA Arch-BF designings but completely different patterns. The expectation guided iterative local search scheme enables searching fine-grained receptive field combinations in the dense search space. Our proposed global-to-local search can be plugged into multiple tasks, i.e., action segmentation, probabilistic forecasting <ref type="bibr" target="#b5">[6]</ref>, classification <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b23">24]</ref>, segmentation <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b61">62]</ref>, detection <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b47">48]</ref> methods to further boost the performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Search space comparison between searching for network architecture and receptive field combinations. Left: Network architecture search mostly search for several operations with different functions. Right: The search space of receptive field combinations is huge. The white, green, blue nodes and orange shade represent the dilation rate candidates, the sparse search space in global search, one of the global searched results, and the local search space.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>2</head><label>2</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>Illustration of one iteration in our genetic-based global search algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Algorithm 1</head><label>1</label><figDesc>Global Search. Input: Iterations N , training epoch n, randomly initialized P , mutation probability p m , and population size M ; for iter in [1, N ] do Select individuals for crossover based on Eqn. (3) and crossover for every two selected individuals; Mutate the new individuals with probability p m ; Training each individual with n epochs; Select the top M individuals based on Eqn. (2) as the new population P ; end for return P .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Algorithm 2</head><label>2</label><figDesc>Expectation Guided Iterative Local Search. Input: Iterations N , initial receptive fields D; Initialize model using given D; for iter in [1, N ] do Construct T l for each layer based on D; Train model to get the P M F in Eqn. (4); Obtain new dilation rates through Eqn. (6); Update D; end for return local-searched D.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>1 .Figure 5 .</head><label>15</label><figDesc>The globalto-local search focuses on the receptive field combinations, thus can cooperate with existing SOTA action segmentation methods to further improve their performance. As shown in Tab. 3, on the large scale BreakFast dataset, global-tolocal search consistently boosts the performance of MS-Performance comparison between our proposed geneticbased search and random search during the global search stage.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .Figure 7 .</head><label>67</label><figDesc>Visualization of the global-to-local searched structures of three datasets with the MS-TCN baseline. Each row represents the dilations of one structure, which contains four stages. Visualization of average dilation rates in each stage and the range of performance of global-searched structures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .Table 2 .</head><label>12</label><figDesc>TCN [12] 52.6 48.1 37.9 61.7 66.3 76.3 74.0 64.5 67.9 80.7 87.5 85.4 74.6 81.4 79.2 Reproduce 69.1 63.7 50.1 69.9 67.3 78.8 75.3 64.4 71.4 77.8 87.1 83.6 70.4 81.1 75.5 Global 72.2 66.0 51.5 71.0 69.2 79.3 76.5 68.1 71.9 81.2 89.1 87.1 74.4 84.2 78.6 Local 74.9 69.0 55.2 73.3 70.7 80.3 78.0 69.8 73.4 82.2 89.9 87.3 75.8 84.6 78.5Performance of the global and local searching stages of our global-to-local searching method using MS-TCN<ref type="bibr" target="#b11">[12]</ref> as the baseline. Details of three action segmentation datasets. #Cls and #Vid are the numbers of classes and videos, respectively. #Frame is the average frames of videos.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">BreakFast</cell><cell></cell><cell></cell><cell>50Salads</cell><cell></cell><cell></cell><cell>GTEA</cell></row><row><cell></cell><cell cols="3">F@{10,25,50}</cell><cell>Edit</cell><cell>Acc</cell><cell>F@{10,25,50}</cell><cell>Edit</cell><cell>Acc</cell><cell>F@{10,25,50}</cell><cell>Edit</cell><cell>Acc</cell></row><row><cell cols="4">MS-#Cls #Vid #Frame</cell><cell></cell><cell>Scene</cell><cell></cell><cell></cell><cell></cell></row><row><cell>GTEA [15]</cell><cell>11</cell><cell>28</cell><cell>1115</cell><cell></cell><cell cols="2">daily activities</cell><cell></cell><cell></cell></row><row><cell>50Salads [60]</cell><cell>17</cell><cell>50</cell><cell>11552</cell><cell cols="3">preparing salads</cell><cell></cell><cell></cell></row><row><cell>BreakFast [31]</cell><cell>48</cell><cell>1712</cell><cell>2097</cell><cell cols="3">cooking breakfast</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 6 .Table 7 .</head><label>67</label><figDesc>Ablation of the value of S in the EGI local search. Ablation of possible probability mass functions in EGI local search.</figDesc><table><row><cell>BreakFast</cell><cell></cell><cell cols="5">F@0.1 F@0.25 F@0.5 Edit Acc</cell></row><row><cell>random</cell><cell></cell><cell>67.7</cell><cell>61.8</cell><cell>48.3</cell><cell cols="2">68.4 67.0</cell></row><row><cell>random + local</cell><cell></cell><cell>73.6</cell><cell>67.8</cell><cell>53.7</cell><cell cols="2">72.3 69.9</cell></row><row><cell>baseline [12]</cell><cell></cell><cell>69.1</cell><cell>63.7</cell><cell>50.1</cell><cell cols="2">71.0 69.2</cell></row><row><cell cols="2">baseline + local</cell><cell>74.1</cell><cell>68.5</cell><cell>55.3</cell><cell cols="2">72.3 70.2</cell></row><row><cell>global</cell><cell></cell><cell>72.2</cell><cell>66.0</cell><cell>51.8</cell><cell cols="2">71.5 69.4</cell></row><row><cell>global + local</cell><cell></cell><cell>74.9</cell><cell>69.0</cell><cell>55.2</cell><cell cols="2">73.3 70.7</cell></row><row><cell cols="7">Table 5. Performance of the EGI local search initialized by differ-</cell></row><row><cell>ent structures.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>BreakFast</cell><cell cols="2">F@0.1</cell><cell>F@0.25</cell><cell>F@0.5</cell><cell>Edit</cell><cell>Acc</cell></row><row><cell>S = 2</cell><cell></cell><cell>74.8</cell><cell>68.9</cell><cell>55.0</cell><cell>73.4</cell><cell>70.4</cell></row><row><cell>S = 3</cell><cell></cell><cell>74.9</cell><cell>69.0</cell><cell>55.2</cell><cell>73.3</cell><cell>70.7</cell></row><row><cell>S = 4</cell><cell></cell><cell>74.9</cell><cell>68.8</cell><cell>55.1</cell><cell>73.3</cell><cell>70.9</cell></row><row><cell>BreakFast</cell><cell cols="2">F@0.1</cell><cell>F@0.25</cell><cell>F@0.5</cell><cell>Edit</cell><cell>Acc</cell></row><row><cell>sigmoid</cell><cell></cell><cell>72.7</cell><cell>66.9</cell><cell>52.7</cell><cell>71.8</cell><cell>69.4</cell></row><row><cell>softmax</cell><cell></cell><cell>73.2</cell><cell>67.2</cell><cell>52.0</cell><cell>71.6</cell><cell>69.7</cell></row><row><cell>Eqn. (4)</cell><cell></cell><cell>74.9</cell><cell>69.0</cell><cell>55.2</cell><cell>73.3</cell><cell>70.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 9 .Table 10 .</head><label>910</label><figDesc>Table 8. Cross-validation performance (F@0.1) of searched structures among the fold 1 of different datasets. Arch-dataset indicates the structure is searched on which dataset. Cross-validation performance (F@0.1) of searched structures among different folds of the BreakFast dataset. Arch-n means the structure is searched on fold n. Comparison with SOTA on the 50Salads dataset.</figDesc><table><row><cell>50Salads</cell><cell>67.1</cell><cell></cell><cell>75.4</cell><cell>68.8</cell><cell>72.6</cell></row><row><cell>GTEA</cell><cell>83.8</cell><cell></cell><cell>82.4</cell><cell>88.9</cell><cell>85.6</cell></row><row><cell>BF</cell><cell>69.9</cell><cell></cell><cell>75.1</cell><cell>72.5</cell><cell>76.4</cell></row><row><cell>BreakFast</cell><cell cols="2">Arch-1</cell><cell>Arch-2</cell><cell>Arch-3</cell><cell>Arch-4</cell></row><row><cell>fold1</cell><cell></cell><cell>76.4</cell><cell>76.3</cell><cell>76.2</cell><cell>75.7</cell></row><row><cell>fold2</cell><cell></cell><cell>74.1</cell><cell>75.3</cell><cell>75.1</cell><cell>74.6</cell></row><row><cell>fold3</cell><cell></cell><cell>76.1</cell><cell>76.6</cell><cell>76.1</cell><cell>75.4</cell></row><row><cell>fold4</cell><cell></cell><cell>71.7</cell><cell>72.1</cell><cell>72.0</cell><cell>71.8</cell></row><row><cell>50Salads</cell><cell></cell><cell cols="4">F@0.1 F@0.25 F@0.5 Edit Acc</cell></row><row><cell cols="2">Spatial CNN [36]</cell><cell>32.3</cell><cell>27.1</cell><cell>18.9</cell><cell>24.8 54.9</cell></row><row><cell cols="2">Bi-LSTM [57]</cell><cell>62.6</cell><cell>58.3</cell><cell>47.0</cell><cell>55.6 55.7</cell></row><row><cell cols="2">Dilated TCN [35]</cell><cell>52.2</cell><cell>47.6</cell><cell>37.4</cell><cell>43.1 59.3</cell></row><row><cell cols="2">ST-CNN [36]</cell><cell>55.9</cell><cell>49.6</cell><cell>37.1</cell><cell>45.9 59.4</cell></row><row><cell>TUnet [52]</cell><cell></cell><cell>59.3</cell><cell>55.6</cell><cell>44.8</cell><cell>50.6 60.6</cell></row><row><cell cols="2">ED-TCN [35]</cell><cell>68.0</cell><cell>63.9</cell><cell>52.6</cell><cell>59.8 64.7</cell></row><row><cell cols="2">TResNet [26]</cell><cell>69.2</cell><cell>65.0</cell><cell>54.4</cell><cell>60.5 66.0</cell></row><row><cell cols="2">TricorNet [10]</cell><cell>70.1</cell><cell>67.2</cell><cell>56.6</cell><cell>62.8 67.5</cell></row><row><cell>TRN [37]</cell><cell></cell><cell>70.2</cell><cell>65.4</cell><cell>56.3</cell><cell>63.7 66.9</cell></row><row><cell>TDRN [37]</cell><cell></cell><cell>72.9</cell><cell>68.5</cell><cell>57.2</cell><cell>66.0 68.1</cell></row><row><cell cols="2">MS-TCN [12]</cell><cell>76.3</cell><cell>74.0</cell><cell>64.5</cell><cell>67.9 80.7</cell></row><row><cell cols="2">Ours-MS-TCN</cell><cell>80.3</cell><cell>78.0</cell><cell>69.8</cell><cell>73.4 82.2</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgement This research was supported by the Major Project for New Generation of AI under Grant No. 2018AAA0100400, NSFC (61922046), and S&amp;T innovation project from Chinese Ministry of Education. We thank MindSpore <ref type="bibr" target="#b0">[1]</ref> for the partial support of this work.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<ptr target="http://www.mindspore.cn" />
		<title level="m">Mindspore</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Recognition of complex events: Exploiting temporal dynamics between underlying concepts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhabrata</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mahdi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Kalayeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubarak</forename><surname>Sukthankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2235" to="2242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">ProxylessNAS: Direct neural architecture search on target task and hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ligeng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Quo vadis, action recognition? a new model and the kinetics dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joao</forename><surname>Carreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Action segmentation with joint selfsupervised temporal domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min-Hung</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baopu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingze</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ghassan</forename><surname>Al-Regib</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zsolt</forename><surname>Kira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="9454" to="9463" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Probabilistic forecasting with temporal convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yitian</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanfei</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixiong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhuo</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">399</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="491" to="501" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Sharath Pankanti, and Alok Choudhary. Temporal sequence modeling for video event detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanfu</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2227" to="2234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Introduction to the special section on video surveillance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">T</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">J</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeo</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="745" to="746" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A system for video surveillance and monitoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">J</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeo</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hironobu</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Fujiyoshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanghai</forename><surname>Duggins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Tsin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nobuyoshi</forename><surname>Tolliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Osamu</forename><surname>Enomoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Hasegawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Burt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">VSAM final report</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="68" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Tricornet: A hybrid temporal convolutional and recurrent network for video action segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenliang</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.07818</idno>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Weakly-supervised action segmentation with iterative soft boundary assignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenliang</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Ms-tcn: Multi-stage temporal convolutional network for action segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yazan</forename><surname>Abu Farha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jurgen</forename><surname>Gall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="3575" to="3584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Understanding egocentric activities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alireza</forename><surname>Fathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">M</forename><surname>Rehg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="407" to="414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Modeling actions through state changes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alireza</forename><surname>Fathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>James M Rehg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2579" to="2586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning to recognize objects in egocentric activities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alireza</forename><surname>Fathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofeng</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">M</forename><surname>Rehg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="3281" to="3288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Sct: Set constrained temporal transformer for set supervised action segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohsen</forename><surname>Fayyaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jurgen</forename><surname>Gall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="501" to="510" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Slowfast networks for video recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Feichtenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6202" to="6211" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Spatiotemporal multiplier networks for video action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Feichtenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Axel</forename><surname>Pinz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">P</forename><surname>Wildes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4768" to="4777" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Coupled generative adversarial network for continuous fine-grained action segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harshala</forename><surname>Gammulle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tharindu</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Denman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sridha</forename><surname>Sridharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clinton</forename><surname>Fookes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE WACV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="200" to="209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Res2net: A new multi-scale backbone architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shang-Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin-Yu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Representative batch normalization with feature calibration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shang-Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pai</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Highly efficient salient object detection with 100k parameters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shang-Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong-Qiang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengze</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunpeng</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Pyramid constrained selfattention network for fast video salient object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchao</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lijuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziqin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shao-Ping</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="10869" to="10876" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Dots: Decoupling operation and topology in differentiable architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Chao</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Juan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Huan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shao-Ping</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deep hough transform for semantic line detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Ruoming Pang, Vijay Vasudevan, et al. Searching for mo-bilenetv3</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grace</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1314" to="1324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Jittor: a novel deep learning framework with meta-operators and unified graph execution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shi-Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dun</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guo-Ye</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guo-Wei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Yang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science China Information Sciences</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Improving action segmentation via graph-based temporal reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Sugano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoichi</forename><surname>Sato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Fast saliency based pooling of fisher encoded dense trajectories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svebor</forename><surname>Karaman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Seidenari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><forename type="middle">Del</forename><surname>Bimbo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The language of actions: Recovering the syntax and semantics of goaldirected human activities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hilde</forename><surname>Kuehne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Arslan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Serre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="780" to="787" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">An end-toend generative framework for video segmentation and recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hilde</forename><surname>Kuehne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juergen</forename><surname>Gall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Serre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE WACV</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Weakly supervised learning of actions from transcripts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hilde</forename><surname>Kuehne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juergen</forename><surname>Gall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vis. and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">163</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A hybrid rnn-hmm approach for weakly supervised temporal action segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hilde</forename><surname>Kuehne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juergen</forename><surname>Gall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Temporal convolutional networks for action segmentation and detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Lea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rene</forename><surname>Flynn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Austin</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory D</forename><surname>Reiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hager</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="156" to="165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Segmental spatiotemporal cnns for fine-grained action segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Lea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Austin</forename><surname>Reiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">René</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory D</forename><surname>Hager</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="36" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Temporal deformable residual networks for action segmentation in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sinisa</forename><surname>Todorovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="6742" to="6751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A convolutional neural network cascade for face detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoxiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohui</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Brandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Hua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="5325" to="5334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Set-constrained viterbi for setsupervised action segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sinisa</forename><surname>Todorovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="10820" to="10829" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Ms-tcn++: Multi-stage temporal convolutional network for action segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Jie</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yazan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Abufarha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juergen</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Autodeeplab: Hierarchical neural architecture search for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Hierarchical representations for efficient architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chrisantha</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Darts: Differentiable architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Nsga-net: neural architecture search using multi-objective genetic algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhichao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Whalen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishnu</forename><surname>Boddeti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yashesh</forename><surname>Dhebar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kalyanmoy</forename><surname>Deb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Banzhaf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Genetic and Evolutionary Computation Conference</title>
		<meeting>the Genetic and Evolutionary Computation Conference</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="419" to="427" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">An introduction to genetic algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melanie</forename><surname>Mitchell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8026" to="8037" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Regularized evolution for image classifier architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esteban</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alok</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanping</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.01497</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Temporal action detection using a statistical language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juergen</forename><surname>Gall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3131" to="3140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Weakly supervised action learning with rnn based fine-to-coarse modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hilde</forename><surname>Kuehne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juergen</forename><surname>Gall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A database for fine grained activity detection of cooking activities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sikandar</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mykhaylo</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1194" to="1201" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Unet: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Medical image computing and computerassisted intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Learning representations by back-propagating errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>David E Rumelhart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald J</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">nature</title>
		<imprint>
			<biblScope unit="volume">323</biblScope>
			<biblScope unit="issue">6088</biblScope>
			<biblScope unit="page" from="533" to="536" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Video anomaly detection based on local statistical aggregates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Venkatesh</forename><surname>Saligrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhu</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2112" to="2119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Unsupervised learning and segmentation of complex activities from video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fadime</forename><surname>Sener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8368" to="8376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Two-stream convolutional networks for action recognition in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="568" to="576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">A multi-stream bi-directional recurrent neural network for fine-grained action detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharat</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><forename type="middle">K</forename><surname>Marks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oncel</forename><surname>Tuzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="1961" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">First person action recognition using deep learned descriptors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suriya</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chetan</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">V</forename><surname>Jawahar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2620" to="2628" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">A multimodal database for affect recognition and implicit tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Soleymani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeroen</forename><surname>Lichtenauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thierry</forename><surname>Pun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maja</forename><surname>Pantic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Affect. Comput</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="42" to="55" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Combining embedded accelerometers with computer vision for recognizing food preparation activities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mckenna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The ACM International Joint Conference on Pervasive and Ubiquitous Computing</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="729" to="738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Automatically designing cnn architectures using the genetic algorithm for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengjie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiancheng</forename><surname>Gary G Yen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Cybernetics</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Vecroad: Point-based iterative graph exploration for road graphs extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong-Qiang</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shang-Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuan-Yi</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Learning latent temporal structure for complex event detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daphne</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1250" to="1257" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">From stochastic grammar to bayes network: Probabilistic parsing of complex activity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><forename type="middle">F</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bobick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2641" to="2648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Boundary-aware cascade networks for temporal action segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenzhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziteng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gangshan</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Genetic cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Understanding and robustifying differentiable architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arber</forename><surname>Zela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Elsken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tonmoy</forename><surname>Saikia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yassine</forename><surname>Marrakchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
