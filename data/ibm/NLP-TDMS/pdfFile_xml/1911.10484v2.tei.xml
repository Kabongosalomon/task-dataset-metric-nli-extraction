<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Task-Oriented Dialog Systems that Consider Multiple Appropriate Responses under the Same Context</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichi</forename><surname>Zhang</surname></persName>
							<email>zhangyic17@mails.tsinghua.edu.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhijian</forename><surname>Ou</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhou</forename><surname>Yu</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Davis Davis</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Task-Oriented Dialog Systems that Consider Multiple Appropriate Responses under the Same Context</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Conversations have an intrinsic one-to-many property, which means that multiple responses can be appropriate for the same dialog context. In task-oriented dialogs, this property leads to different valid dialog policies towards task completion. However, none of the existing task-oriented dialog generation approaches takes this property into account. We propose a Multi-Action Data Augmentation (MADA) framework to utilize the one-to-many property to generate diverse appropriate dialog responses. Specifically, we first use dialog states to summarize the dialog history, and then discover all possible mappings from every dialog state to its different valid system actions. During dialog system training, we enable the current dialog state to map to all valid system actions discovered in the previous process to create additional state-action pairs. By incorporating these additional pairs, the dialog policy learns a balanced action distribution, which further guides the dialog model to generate diverse responses. Experimental results show that the proposed framework consistently improves dialog policy diversity, and results in improved response diversity and appropriateness. Our model obtains state-of-the-art results on MultiWOZ.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>One big challenge in dialog system generation is that multiple responses can be appropriate under the same conversation context. This challenge originated from the intrinsic diversity of human conversations. Although recent progress in sequence-to-sequence (seq2seq) learning <ref type="bibr" target="#b22">(Sutskever, Vinyals, and Le 2014)</ref> improves dialog systems performance <ref type="bibr" target="#b21">(Serban et al. 2017;</ref><ref type="bibr" target="#b24">Wen et al. 2017;</ref><ref type="bibr" target="#b11">Lei et al. 2018)</ref>. These systems still ignore this one-to-many property in conversation. Therefore, they are not able to handle diverse user behaviors in real-world settings <ref type="bibr" target="#b20">Rajendran et al. 2018</ref>).</p><p>Previous studies model this one-to-many conversation property to improve utterance-level diversity in opendomain dialog generation <ref type="bibr"></ref> I am so hungry -can you find me a place to eat in the city center?</p><p>Sure. Which kind of food do you like?</p><p>I have French and Italian food, any preference? I can do that. Which price range do you prefer?  <ref type="bibr" target="#b28">Zhou et al. 2017;</ref>). None of previous task-oriented systems consider such one-to-many property, since they focus on task completion policies instead of language variations. However, the one-to-many phenomenon is also prevalent in task-oriented dialogs, in the form of different responding policies for the same dialog context ( <ref type="figure" target="#fig_0">Fig.1</ref>). Since in collected dialog datasets each dialog context has only one reference response, the distribution of valid system actions for each dialog state rely on their occurring frequencies in the datasets which are usually highly unbalanced. Models trained on these unbalanced datasets tend to capture the most common dialog policy but ignore rarely occurred yet feasible user behaviors, which results in learning skewed and low-coverage policies.</p><p>Our goal is to address such data bias and model this oneto-many property in task-oriented dialogs to enrich dialog policy diversity, therefore building dialog systems that can generate more diverse system responses. Instead of simply learning how to map one user response to many system responses <ref type="bibr" target="#b20">(Rajendran et al. 2018)</ref> , we propose to discover the mapping from one dialog state (condensed dialog history) to multiple system actions and then generate system responses conditioned on learned actions. Since the number of unique dialog states and system actions are much smaller than the number of unique user and system responses, the mapping is more structured and easier to incorporate in learning.</p><p>Specifically, we propose a general Multi-Action Data Augmentation (MADA) framework to achieve such mapping. We first delexicalize all utterances to reduce surface language diversity. Then we use dialog states and system actions to achieve condensed but sufficient information representation. We accumulate all mappings from dialog states to valid system actions from the entire training corpus. Finally in the dialog system training process, we force the model to not only take the ground truth system action as training sample, but also create extra training samples by including other possible system actions that are valid under that dialog state based on the state-action mapping obtained earlier. Then the learned policy is able to produce a more balanced system action distribution given a dialog context. Therefore, the dialog system can produce a set of diverse and valid system actions, which further guide the model to generate diverse and appropriate responses. We evaluate the proposed method on <ref type="bibr">MultiWOZ (Budzianowski et al. 2018)</ref>, a large-scale human-human task-oriented dialog dataset covering multiple domains. We show that our data augmentation method significantly improves response generation quality on various learning models. To utilize the one-to-many mapping under the challenging multi-domain scenario, we propose Domain Aware Multi-Decoder (DAMD) network to accommodate stateaction pair structure in generation. Our model obtains the new state-of-the-art results on MultiWOZ's response generation task. Human evaluation results show that DAMD with data augmentation generates diverse and valid responses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Work</head><p>The trend of building task-oriented systems is changing from training separate dialog models independently <ref type="bibr" target="#b25">(Young et al. 2013;</ref><ref type="bibr" target="#b23">Wen et al. 2015;</ref><ref type="bibr" target="#b15">Liu and Lane 2016;</ref><ref type="bibr" target="#b18">Mrkšić et al. 2017)</ref> to end-to-end trainable dialog models <ref type="bibr" target="#b24">Wen et al. 2017;</ref><ref type="bibr" target="#b6">Eric and Manning 2017)</ref>. Specifically, <ref type="bibr" target="#b11">Lei et al. (2018)</ref> propose a two stage seq2seq model (Sequicity) with copy mechanism <ref type="bibr" target="#b8">(Gu et al. 2016)</ref> that completes the dialog state tracking and response generation jointly via a single seq2seq architecture. These systems achieve promising results, however, all of these models are designed for a specific domain which lacks the generalization ability to multi-domains, e.g. the recently proposed multi-domain dataset <ref type="bibr">MultiWOZ (Budzianowski et al. 2018)</ref>. Although several models are proposed to handle the multi-domain response generation task <ref type="bibr" target="#b26">(Zhao, Xie, and Eskenazi 2019;</ref><ref type="bibr" target="#b17">Mehri, Srinivasan, and Eskenazi 2019;</ref><ref type="bibr" target="#b4">Chen et al. 2019)</ref>, the generation quality is far from perfect, presumably due to the complex task definitions, large policy coverage and flexible language styles. We believe by modeling the one-to-many dialog property, we can improve multidomain dialog system generation.</p><p>The one-to-many problem is more noticeable in opendomain social dialog systems since "I don't know" can be valid response to all questions, but such response is not very useful or engaging. Therefore, previous social response generation methods attempt to model the one-tomany property by modeling responses with other meta information, such as response specificity <ref type="bibr" target="#b28">(Zhou et al. 2017;</ref>. By considering these meta information, the model can generate social dialog response with larger diversity. However, for task-oriented dialog systems, the only work that models this one-to-many property utilizes this property to retrieve dialog system responses instead of generating response <ref type="bibr" target="#b20">(Rajendran et al. 2018)</ref>. We propose to take advantage of this one-to-many mapping property to generate more diverse dialog responses in task-oriented dialog systems. Moreover, one key advantage of our proposed framework is that the multiple actions decoded by the dialog model are interpretable and controllable. We leverage different diverse decoding methods <ref type="bibr" target="#b14">(Li, Monroe, and Jurafsky 2016;</ref><ref type="bibr" target="#b6">Fan, Lewis, and Dauphin 2018;</ref><ref type="bibr" target="#b9">Holtzman et al. 2019)</ref> to improve the diversity of generated system actions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-Action Data Augmentation Framework</head><p>We introduce the Multi-Action Data Augmentation (MADA) framework that is generalizable to all taskoriented dialog scenarios. MADA is suitable to all dialog models that take system action supervision. It aims to increase dialog response generation diversity through learning a dialog policy that decodes a diverse set of valid system actions when given a dialog context. In MADA, we first discover the one-to-many mapping of a summarized dialog context (i.e. dialog state) to a set of system actions that are appropriate under that context. We then make the dialog model to include all the additional actions that are valid according to the one state to many system action mapping during training. In this way, the dialog policy is trained by a balanced mapping between dialog state and different system actions. Therefore, in the end the policy can generate a diverse set of system actions that are all appropriate under a give context. Such a diverse set of system actions will naturally lead to diverse system responses. <ref type="figure" target="#fig_1">Fig.2</ref> shows an example dialog state to multiple actions mapping.</p><p>To learn this one-to-many mapping, we first need to design suitable dialog state and system action that are sufficient to represent dialog policy learning. Dialog state needs to summarize the dialog history that contains sufficient information for a dialog system to decide what actions to take next. So we define dialog state S t at turn t to have four types of information: 1) current dialog domain, 2) belief state, 3) database search results and 4) current user action. Current dialog domain D t is essential, because one single task can have multiple dialog domains, so the active domain is necessary to include in the dialog state representation. Belief state B t is necessary because the belief state records slots and corresponding values informed by user in each turn, e.g. "price=cheap, location=west", these slots are useful in searching database to obtain task information. Database (DB) search results DB t also influence the next system action, because based on the data search results, the system may request for an unmentioned slot to reduce the search range. Finally current user action A U t can also influence the system policy, because sometimes the system need to give direct feedback to the user, such as providing a phone number when it is asked.</p><formula xml:id="formula_0">S t D t , B t , DB t , A U t<label>(1)</label></formula><p>System action is the semantic representation of the sys-  tem utterance. We define system action consists of dialog domains, dialog acts, and slots. One example system action is "hotel-request(price, area)". We then go through the entire training data to find system response that share the same dialog state to form all the one state to many action mappings. Finally, we introduce how to train a dialog policy that produces a balanced valid action distribution under each dialog state.</p><p>Training a dialog policy is to learn the optimal mapping from dialog states to system actions towards achieving task goals efficiently. In another way, we are learning the correct dialog actions conditioned on a dialog state:</p><formula xml:id="formula_1">L = t∈D log P (A t |S t )<label>(2)</label></formula><p>Due to the one-to-many property, for a specific dialog state S, there exists K different system actions A (1) , . . . , A (K) that are valid for this state, i.e. for i = 1, . . . , K, ∃t ∈ D s.t. (S t , A t ) = (S, A (i) ), and we denote the valid system action set as V(S). If some state-action pairs (S, A (j) ) have much lower frequency than other pairs (S, A (k) ), then the model tends to only capture the majority mappings and ignores the minority ones. So the trained dialog policy lacks diversity. This problem is also known as a general drawback of the maximum likelihood estimate over unbalance dataset <ref type="bibr" target="#b9">(Jennrich and Schluchter 1986)</ref>.</p><p>We address this issue by balancing the valid action distribution in every dialog state, S t . Specifically, for each dialog turn t with state-action pair (S t , A t ), we incorporate other valid system actions under the state S t , i.e. A t , t = t with S t = S t , as additional training data for turn t. The new objective function is:</p><formula xml:id="formula_2">L aug = t∈D A t ∈V * (St) log P (A t |S t ) (3) where V * (S t ) ⊆ V(S t ) is a subset of the valid action set V(S t ) of dialog state S i . If we simply choose V * (S t ) = V(S t )</formula><p>, as every P (A|S t ) is optimized by exactly the same number of each valid system action corresponding to state S t , the overall conditional probability P (A|S) is optimized on a balanced set of dialog actions. ??? Our data augmentation framework over-samples training data to handle the unbalanced data problem. We choose over-sampling instead of under-sampling to make sure the dialog model can learn from all available dialogs. In practice, we can choose different V * (S t ) to achieve different level of action diversity. For example, we find that for some system actions such as recommending a hotel name, a combination of other slots such as "price", "stars", "parking", "wifi" etc are often informed together as additional information, which makes the number of "recommend" actions exponentially larger. However, they are semantically similar to each other. To avoid over-sampling of these actions, we group valid system actions with the same dialog act type together and uniformly sample from each group to form V * (S t ). This trick improve the learning efficiency and achieves a higher action diversity over different action types.</p><p>In our experiments, we find some system actions are labeled incorrectly in MultiWOZ, which makes many dialog states only have one corresponding valid system action. To address this problem, we sample min(K, |G|) actions in each group, where K &gt; 1 is the predefined sample number and |G| is the group size. This setting mitigates the influence of those unexpected single action groups but maintains the ability to learn from real single group action groups, e.g. rare cases in the dataset. Because large K has a negative influence on the act-level balance over small groups. We empirically set K = 3, as it yields the best experimental results.</p><p>As a general learning framework, MADA is applicable to any task-oriented dialog system model that takes system actions as supervision, because without the system action annotation, we would not be able to obtain state-action mappings. Our framework is suitable for all types of tasks as well. We choose the most challenging multi-domain taskoriented dialog corpus, <ref type="bibr">MultiWOZ (Budzianowski et al. 2018)</ref> to validate our framework's performance. We also designed a model, Domain Aware Multi-Decoder Network to take the full advantage of our data augmentation framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Domain Aware Multi-Decoder Network</head><p>We propose a Domain Aware Multi-Decoder (DAMD) network, an end-to-end model designed to handle the multidomain response generation problem through leveraging the proposed multi-action data augmentation framework. <ref type="figure" target="#fig_2">Fig.3</ref> shows an overview of the proposed model. There are one encoder that encodes dialog context and three decoders that decodes belief span, system action and system response respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Domain-Adaptive Delexicalization</head><p>We first perform delexicalization to pre-process dialog utterances to reduce surface form language variability. Similar to <ref type="bibr" target="#b24">Wen et al. (2017)</ref>, we generate delexicalized responses with placeholders for specific slot values (see examples in <ref type="figure" target="#fig_2">Fig.3</ref>), which can be filled according to  database search results afterwards. However, we find that there is a drawback in the current multi-domain delexicalization scheme <ref type="bibr" target="#b3">(Budzianowski et al. 2018;</ref><ref type="bibr" target="#b4">Chen et al. 2019)</ref>. Previous methods only delexicalize the same slots in different dialog domains such as phone, address, name etc as different tokens, e.g. &lt;restaurant.phone&gt; and &lt;hotel.phone&gt;, which adds extra burdens for the system to generate these critical tokens during task completion. We propose an adaptive delexicalization scheme using one token to represent the same slot name such as &lt;v.phone&gt; in different dialog domains. Therefore the expressions in all relevant domains can be used to learn to generate the delexicalized value token. Since our model is domain-aware, the active domain is automatically updated based on dialog state. Therefore, there is no ambiguity in response generation process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Belief Span Decoder</head><p>After data preprocessing, the model first learn to decode belief span. The belief span B t of turn t is updated based on the previous belief span B t−1 , previous system response R t−1 and the current user utterance U t through a sequence to sequence fashion:</p><formula xml:id="formula_3">B t = seq2seq(R t−1 , U t , B t−1 )<label>(4)</label></formula><p>where the context vectors obtained by attention mechanism from the three sequences are concatenated to calculate the copy score. See <ref type="bibr" target="#b11">Lei et al. (2018)</ref> for more details. The copy mechanism is used to copy slot names, new slot values from utterances and unchanged parts of the previous belief span. Note that the entire history utterances are not used as the context information, since all the information is already contained and summarized in belief span. But the previous response is required, since the user may have some ellipsis in current utterance that refers to some slot values offered by system in the previous turn. The cross entropy between the generated and the ground truth belief spans are used as the loss of the belief span decoder.</p><p>In multi-domain dialog tasks, simply remembering the slot values instead of its dialog domain can lead to confusion. For example a time value can be either a reservation time in the restaurant domain or an arrival/leaving time for taxi booking. Therefore, we extend the belief span by decoding additional domain and slot tokens to address this ambiguity. An example multi-domain dialog state looks like "[restaurant] name Curry Garden time 18:00 [taxi] leave 20:00 destination Kings Street". The active dialog domain can automatically be determined by selecting the domain that recently changed semantic slot value.</p><p>For search results DB t , we use an one-hot vector to indicate the number of matched entities and whether the booking is available or not following <ref type="bibr" target="#b3">Budzianowski et al. (2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System Action Span Decoder</head><p>The system action span decoder enables DAMD to utilize the multi-action data augmentation framework. We represent the system action as a sequence of tokens in the order of domains, acts and slots, as shown in the third text box in <ref type="figure" target="#fig_2">Fig. 3</ref>.</p><formula xml:id="formula_4">A t = seq2seq(U t , B t , DB t )<label>(5)</label></formula><p>where the database search results are concatenated with the hidden state of the utterance and the belief states. We use the method described in the augmentation framework to enrich the training data. Specifically, for each system utterance in training, we find its dialog state based on annotation, which includes its dialog domain, belief state, database search result and its dialog act. Then we find this state's appropriate system action based on the previously learned one state to many system actions obtained in our data augmentation framework. The possible state-action pairs are used to enlarge the training set.</p><p>In testing, our action decoder naturally has the ability to generate different system actions. Traditional beam search suffers from a diversity problem that the decoder tends to generate sequences with the same root 1 <ref type="bibr" target="#b7">(Finkel, Manning, and Ng 2006;</ref><ref type="bibr" target="#b14">Li, Monroe, and Jurafsky 2016)</ref>, we address the issue by diversity promoting decoding techniques such as the diverse beam search (Li, Monroe, and Jurafsky 2016), top-k sampling (Fan, Lewis, and Dauphin 2018) and nucleus sampling <ref type="bibr" target="#b9">(Holtzman et al. 2019</ref>) to further introduce dialog policies diversity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System Response Decoder</head><p>The final step is to generate response based on the dialog state and system action, which can be formulated as:</p><formula xml:id="formula_5">R t = seq2seq(A t , U t , B t , DB t )<label>(6)</label></formula><p>where the hidden states of the belief span decoder and the action span decoder are used as B t and A t . Previous response decoder methods only base on system dialog act to decode sentences. Our model is trained in an end-to-end manner, where all three decoders' loss are summed together and optimized jointly. During evaluation, different responses are generated based on different system actions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>We evaluate our proposed framework and model on the </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Settings</head><p>Pre-processing The dataset is pre-processed through the proposed domain-adaptive delexicalization scheme as described in the previous section. The original belief state labels and system action labels are converted to the span form to train our domain-aware multi-decoder network model. The user action labels are adopted from the automatic annotations proposed by <ref type="bibr" target="#b10">Lee et al. (2019)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Automatic Evaluation Metrics</head><p>We focus on the contextto-response generation task proposed for MultiWOZ <ref type="bibr" target="#b3">(Budzianowski et al. 2018</ref>) and follow their automatic evaluation metrics. There are four automatic metrics to evaluate the response quality -if the system provides an correct entity (inform rate), answers all the requested information (success rate), is fluent BLEU <ref type="bibr" target="#b19">(Papineni et al. 2002</ref>) and a combined score combined score computed via (Inf orm + Success) × 0.5 + BLEU as an overall quality measure suggested in <ref type="bibr" target="#b17">Mehri et al. (2019)</ref>. Since our goal is to learn diversed valid actions, we introduce two additional metrics to measure the action diversity: the number of unique type of dialog acts (act number) and slots (slot number) in all generated system actions in each dialog turn. In all of our experiments we report the average score of each metric over 5 runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Baselines and Model Variations</head><p>We compare several model variations of our domain aware multi-decoder (DAMD) network together with other baselines on MultiWOZ.</p><p>• Seq2Seq + Attention <ref type="bibr" target="#b3">(Budzianowski et al. 2018)</ref>: a basic seq2seq model with attention <ref type="bibr" target="#b3">(Bahdanau et al. 2014</ref>).</p><p>• Seq2Seq + Copy: a simplified version of DAMD where the belief and action span decoders are removed, which  <ref type="table">Table 1</ref>: Multi-action evaluation results. The "w" and "w/o" column denote with and without data augmentation respectively, and the better score between them is in bold. We report the average performance over 5 runs.</p><p>is equivalent to the copy-based seq2seq model <ref type="bibr" target="#b8">(Gu et al. 2016</ref>). • MD-Sequicity: a simplified version of DAMD with the action span decoder removed. We call it MD-Sequicity since it only extends the belief span to support multidomain belief tracking comparing to the original Sequicity model <ref type="bibr" target="#b11">(Lei et al. 2018</ref>). • SFN + RL <ref type="bibr" target="#b17">(Mehri et al. 2019</ref>): a seq2seq network comprised of several pre-trained dialog modules which are connected through hidden states. Reinforcement fine tuning is used additionally to train the model. SFN is similar to our model in the spirit of modeling belief state and system action jointly in an end-to-end manner, but they use binary vectors for state and action modeling and do not take advantage of copying mechanism. • HDSA: a hierarchical disentangled self-attention network <ref type="bibr" target="#b4">(Chen et al. 2019)</ref>. A BERT-based <ref type="bibr" target="#b5">(Devlin et al. 2018</ref>) action predictor is used to predict system actions in HDSA.</p><p>Since the original multi-label classification with a fixed active threshold is not able to generate multiple actions, we alternatively samples a threshold for each dimension of the action vector independently. The actions are used to control the structure of a self-attention network afterwards for response generation, which is trained separately with the action predictor. • DAMD: our proposed domain aware multi-decoder network. The belief state, system action and response are generated in a seq2seq manner in DAMD. We use greedy decoding for all single-sequence decoding process. When decoding multiple actions, we leverage the standard beam search algorithm and several diversity-promoted decoding schemes :</p><p>(1) the diverse beam search ) which adds a penalty term to intra-sibling sequences thus favors choosing hypotheses from diverse parents.  <ref type="table">Table 2</ref>: Comparison of response generation results on MultiWOZ. The oracle/generated denotes either using ground truth or generated results. The results are grouped according to whether and how system action is modeled.</p><p>(2) the top-k sampling algorithm <ref type="bibr" target="#b6">(Fan et al. 2018</ref>) which samples the next word from the k most probable choices according to vocabulary distribution.</p><p>(3) the top-p sampling algorithm <ref type="bibr" target="#b9">(Holtzman et al. 2019)</ref> which samples from the set of top possible words where their summed probability reaches a fixed value p.</p><p>Parameter Setting In our implementation of DAMD, we use a one-layer bi-directional GRU with hidden size of 100 as encoder and three standard GRUs with the same hidden size as decoders. The embedding size, vocabulary size and batch size are 50, 3,000 and 128 respectively. The combined score on development set is used as the validation check metric. We use the Adam optimizer with a initial learning rate of 0.005. The learning rate decays by half every 3 epochs if no improvement is observed on development set. Training early stops when no improvement is observed on development set for 5 epochs. For multi-action decoding, the beam size and sampling number k are the same as action number, which is 5 or 10 in our experiments. We use 0.2 as the diverse beam search penalty and p = 0.9 for top-p sampling. The fixed active threshold for HDSA is 0.4, and the sampling range is [0.3, 0.5] in multi-action experiments.</p><p>All of the hyperparameters are selected through grid search. The code is available here 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and Analysis</head><p>We first evaluate whether our data augmentation framework efficiently improves dialog policy diversity. We conduct experiments of 5-action and 10-action generation, where different model variations with and without utilizing the proposed multi-action data augmentation framework are compared. The results are shown in <ref type="table">Table 1</ref>. After applying our data augmentation, both the action and slot diversity are improved consistently, which indicates that our data augmentation framework is applicable to different models. Topk sampling achieves the highest act-level diversity, where there are 3.43 unique dialog acts on average in five generated actions. HDSA has the worse performance and benefits less from data augmentation comparing to our proposed 2 https://gitlab.com/ucdavisnlp/damd-multiwoz domain-aware multi-decoder network, because HDSA does not decode its dialog act but perform multi-label classification. While the appropriateness of multiple actions is hard to judge by automatic evaluation , we leave it for human evaluation, where we also take a further step to directly evaluate the corresponding responses. We evaluate our domain-aware multi-decoder (DAMD) network on the context-to-response generation task based on MultiWOZ. Each model generates one response for fair comparison. Experiments with ground truth belief state feed the oracle belief state as input and database search condition. Specifically in DAMD, we feed the oracle token at each decoding step of belief span to produce the oracle hidden states as input of subsequent modules. Results are shown in <ref type="table">Table 2</ref>. The first group shows that after applying our domain-adaptive delexcalization and domain-aware belief span modeling, the task completion ability of seq2seq models becomes better. The relative lower BLEU score is potentially due to that task-promoting structures (e.g. copy) make the model focus less on learning the language surface. Our DAMD model significantly outperforms other models with different system action forms in terms of inform and success rates, which shows the superiority of our action span. While we find applying our data augmentation achieves a limited improvement on combined score (6 vs 7), which suggests learning from a balanced state-action training data can improve the robustness of model but the benefit of learning diverse policy for single response generation is hard to evaluate. Moreover, if a model has access to ground truth system action, the model further improves its task performance. Finally, we find conditioned on generated belief state greatly harm the response quality, due to the error propagation from previous decoders to the final response decoder. Note that HDSA cannot track belief state thus has no results here. <ref type="table" target="#tab_5">Table 3</ref> shows an example where learning policy diversity is beneficial for task completion. Since there are still nine hotels which fit the user's requirement, a common policy should be requesting a slot (e.g. area located) to further reduce database search range. However, the dialogs are carried  out by a large number of different crowd workers. Some workers may choose to make a direct recommendation instead. This less frequency seen policy is difficult for the system to capture without a balanced data set, as the model tend to generate only the majority request actions. After applying data augmentation, the recommend actions are also captured as a valid action.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Case Study and Error Analysis</head><p>Although better than models trained on unbalanced stateaction dataset, our model still makes several types of errors shown in <ref type="table" target="#tab_6">Table 4</ref>. The example on the left shows the model makes an error on the slot type. This is because our data augmentation method mainly focuses on improving the actlevel policy diversity and the slot-level diversity is ignored.</p><p>The example on the right shows an error where our system failed to collect enough information, such as number of people, before offering to make a restaurant reservation. This suggests that more prior task knowledge should be injected in the dialog model to address such issue. Moreover, besides policy level errors, there is also errors in the response generation process. In the bottom example shown in <ref type="table">Table 5</ref>, the address information of the restaurant is missing. Such error might be caused by the generation model forgetting the distant information when the conditioned action span is too long.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Human Evaluation</head><p>Automatic metrics only validate systems performance on one single dimension at a time. While human can provide an ultimate holistic evaluation. We conduct human evaluation to show that learning a balanced dialog policy can eventually improve the dialog system responding quality, in terms of higher appropriateness of individual responses and higher diversity among multiple responses.</p><p>In our experiments, appropriateness is scored on a Likert scale of 1-3 which denotes invalid, ok and good respectively, for each generated response. Diversity is scored on a Likert scale of 1-5 for all of the responses (we generate 5 responses for each model in our experiments). We suggest the judges to score according to the number of different policies in responses. We evaluate three models: DAMD without data augmentation, DAMD with data augmentation and HDSA with data augmentation. The top-k sampling is selected as our decoding methods since it achieves highest action diversity as shown in <ref type="table">Table 1</ref>. We sample one hundred dialog turns and the 15 responses (five responses for each model) of each turn are scored by three judges given the dialog history.</p><p>The results are shown in <ref type="table">Table 5</ref>. We report the average value of diversity and appropriateness, and the percentage of responses scored for each appropriateness level. With data augmentation, our model obtains a significant improvement in diversity score and achieves the best average appropriateness score as well. Due to the larger diversity, DAMD with augmentation is more likely to generate responses with better quality. However, the slightly increased invalid response percentage indicates that some invalid actions are also captured, which may due to that noisy state and action labels lead to wrong valid state-action set. We also observe our DAMD model outperforms HDSA in both diversity and appropriateness scores. This is mainly because our model considers the dialog domain information in a more effective manner and our model is able to leverage the state-action augmentation better by decoding system actions instead of performing classification. In summary, the overall results suggest that our framework can effectively improve the ability of dialog systems to generate appropriate responses with different dialog policies.  <ref type="table">Table 5</ref>: Human evaluation results. Models with data augmentation are noted as (+). App denotes the average appropriateness score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>We focus on generating appropriate responses with higher diversity in task-oriented dialog systems, by learning a diversified dialog policy through considering the one-to-many dialog property. Specifically, we propose the Multi-Action Data Augmentation (MADA) framework to enable dialog models to learn a more balanced state-to-action mapping.</p><p>Our framework generalizes to all dialog tasks with belief state and system action annotated. We also propose a new domain aware multi-decoder (DAMD) model to leverage the proposed data augmentation framework. DAMD learns a more diverse state-to-action policy which not only achieves the state-of-the-art task success rate on the challenging Mul-tiWOZ dataset, but also generates a set of responses that are both appropriate and diverse. In the future we plan to apply our method to help the modeling of diverse user behaviors.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Multiple responses produced by different dialog policies (shown in clouds) are proper for the same context.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>The overview of our Multi-Action Data Augmentation (MADA) framework. The green blocks denotes the same dialog state, and bars with different colors are different valid system actions corresponding to this state. Other valid state-action pairs are additional training data to learn the state-to-action mapping.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>The overview of Domain Aware Multi-Decoder (DAMD) network. The left figure shows the information flow among all modules. The explicit inputs and outputs of each module are described on the right.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Collection of valid system actions for the state Belief State Database Search Results</head><label></label><figDesc></figDesc><table><row><cell cols="4">Domain hotel User Action Dialogue State</cell><cell cols="2">inform</cell><cell>All dialogue turns with the same dialogue state</cell></row><row><cell></cell><cell></cell><cell cols="4">area=west, price=any, wifi=yes</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">match # : 3</cell></row><row><cell>name</cell><cell>type</cell><cell>price</cell><cell>area</cell><cell cols="2">stars …</cell></row><row><cell cols="3">Avalon hotel moderate</cell><cell>north</cell><cell>4</cell><cell>…</cell></row><row><cell>…</cell><cell>…</cell><cell>…</cell><cell>…</cell><cell>…</cell><cell>…</cell></row><row><cell></cell><cell cols="4">Valid System Actions</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">request(stars)</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">select(type)</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="4">inform(name), offerbook</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>: What price range do you want for the hotel?: A cheap one works for me. By the way it should be in the west.</figDesc><table><row><cell cols="2">−1</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">−1 Context</cell><cell></cell></row><row><cell cols="3">Encoder</cell><cell></cell><cell></cell><cell></cell></row><row><cell>−1</cell><cell></cell><cell></cell><cell></cell><cell>:</cell><cell cols="2">[hotel] area west ; price cheap</cell></row><row><cell cols="3">Belief Span Decoder</cell><cell></cell><cell></cell><cell cols="2">match = 3; booking = available</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">name</cell><cell>price</cell><cell>area Stars booking …</cell></row><row><cell></cell><cell>⊕</cell><cell></cell><cell>DB</cell><cell cols="3">Avalon cheap … …</cell><cell>west …</cell><cell>4 …</cell><cell>available … … …</cell></row><row><cell cols="4">Action Span Decoder</cell><cell>1 2</cell><cell cols="2">[hotel] [inform] name [offerbook] [hotel] [request] stars</cell></row><row><cell>1</cell><cell>2</cell><cell>3</cell><cell>…</cell><cell>3</cell><cell cols="2">[hotel] [recommend] name wifi</cell></row><row><cell cols="3">Response Decoder</cell><cell></cell><cell cols="3">1 The &lt;v.name&gt; is a great choice meet your criteria! Do you want me to book it for you? 2 Sure! What star rating do you want?</cell></row><row><cell>1 ,</cell><cell>2 ,</cell><cell cols="2">3 , …</cell><cell cols="3">3 I would recommend the &lt;v.name&gt;! It is …</cell></row></table><note>:: inform</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Our model's example generation responses with and without data augmentation. GT denotes the ground truth. The generated action candidate closest to the ground truth action is marked in bold.</figDesc><table><row><cell>USER: I will be travelling from Cambridge</cell><cell>USER: Yes, i would like a reservation.</cell></row><row><cell>actually and going to London Kings Cross.</cell><cell></cell></row><row><cell>Policy</cell><cell></cell></row><row><cell>Error</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Examples of errors made by DAMD. GT denotes ground truth.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">For example, the model is more likely to generate "[hotel] inform name price" together with "[hotel] inform name" than "[hotel] recommend name" by standard beam search algorithm.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Could you give me some direction? USER: Sure. 4 star, nothing but the best, free wifi moderately priced and free parking too. STATE: [hotel] parking yes</title>
		<imprint/>
	</monogr>
	<note>SYS: I also have 3 pricing options and amenity options. pricerange moderate; stars 4. internet yes</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Generated Actions w/o MADA Generated Actions w/ MADA [inform] area choice price</title>
		<idno>DB-match:9</idno>
		<imprint/>
	</monogr>
	<note>inform] choice [request] area [inform] area price choice type [inform] name internet parking area [offerbook] [inform] choice [request] area [recommend] name [inform] choice</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">May I recommend acorn guest house? It is moderate and fits all your criteria. Would you like me to reserve you any rooms? GT Action</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">T</forename><surname>Sys</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>request] day GT Action: [request] people Generated Actions: Generated Actions: [request] leave [offerbook] [request] leave arrive [offerbook] [general] [reqmore</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">SYS: I would suggest the &lt;v.name&gt;. The postcode is &lt;v.postcode&gt;. Is there anything else I can help you with today? References</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Budzianowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-H</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-H</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Casanueva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ultes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ramadan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gašić</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.0473</idno>
		<idno>arXiv:1810.00278</idno>
	</analytic>
	<monogr>
		<title level="m">Multiwoz-a large-scale multi-domain wizard-of-oz dataset for task-oriented dialogue modelling</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Neural machine translation by jointly learning to align and translate</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Semantically conditioned dialog response generation via hierarchical disentangled self-attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.12866</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Key-value retrieval networks for task-oriented dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dauphin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.05414</idno>
		<idno>arXiv:1805.04833</idno>
	</analytic>
	<monogr>
		<title level="m">Hierarchical neural story generation</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Solving the problem of cascading errors: Approximate bayesian inference for linguistic annotation pipelines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2006 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="618" to="626" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Incorporating copying mechanism in sequence-to-sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">O</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.06393</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Unbalanced repeatedmeasures models with structured covariance matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Buys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">I</forename><surname>Jennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Schluchter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.09751</idno>
	</analytic>
	<monogr>
		<title level="m">The curious case of neural text degeneration</title>
		<imprint>
			<date type="published" when="1986" />
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="805" to="820" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Takanobu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.08637</idno>
		<title level="m">Convlab: Multi-domain end-to-end dialog system platform</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Sequicity: Simplifying task-oriented dialogue systems with single sequence-to-sequence architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-Y</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th</title>
		<meeting>the 56th</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<publisher>Long Papers</publisher>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1437" to="1447" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A diversity-promoting objective function for neural conversation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="110" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">A simple, fast diverse decoding algorithm for neural generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.08562</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Attention-based recurrent neural network models for joint intent detection and slot filling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Lane</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.01454</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">How not to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Noseworthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2122" to="2132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mehri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eskenazi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.10016</idno>
		<title level="m">Structured fusion networks for dialog</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Neural belief tracker: Data-driven dialogue state tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mrkšić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">Ó</forename><surname>Séaghdha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-H</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1777" to="1788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th annual meeting on association for computational linguistics</title>
		<meeting>the 40th annual meeting on association for computational linguistics</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning end-to-end goal-oriented dialog with multiple answers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rajendran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ganhotra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Polymenakos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3834" to="3843" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A hierarchical latent variable encoder-decoder model for generating dialogues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">V</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-First AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Semantically conditioned lstm-based natural language generation for spoken dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-H</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mrksic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Young</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1508.01745</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A network-based end-to-end trainable task-oriented dialogue system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-H</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mrkšić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M R</forename><surname>Barahona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ultes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter</title>
		<meeting>the 15th Conference of the European Chapter</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="438" to="449" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Pomdp-based statistical spoken dialog systems: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gašić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1160" to="1179" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Rethinking action spaces for reinforcement learning in end-to-end dialog agents with latent variable models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eskenazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eskenazi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.08476</idno>
		<idno>arXiv:1902.08858</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Generative encoder-decoder models for task-oriented spoken dialog systems with chatting capability</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Learning discourselevel diversity for neural dialog models using conditional variational autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eskenazi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.10960</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Mechanism-aware neural machine for dialogue response generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-First AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Elastic responding machine for dialog generation with dynamically mechanism selecting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
