<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Reinforced Topic-Aware Convolutional Sequence-to-Sequence Model for Abstractive Text Summarization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Wang</surname></persName>
							<email>lilianwang@tencent.com</email>
							<affiliation key="aff0">
								<orgName type="department">Tencent Data Center</orgName>
								<address>
									<country>SNG</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junlin</forename><surname>Yao</surname></persName>
							<email>jyao@student.ethz.ch</email>
							<affiliation key="aff1">
								<orgName type="institution">ETH Zürich</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunzhe</forename><surname>Tao</surname></persName>
							<email>y.tao@columbia.edu</email>
							<affiliation key="aff2">
								<orgName type="institution">Columbia University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhong</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Tencent Data Center</orgName>
								<address>
									<country>SNG</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Tencent AI Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Du</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Columbia University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A Reinforced Topic-Aware Convolutional Sequence-to-Sequence Model for Abstractive Text Summarization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T10:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we propose a deep learning approach to tackle the automatic summarization tasks by incorporating topic information into the convolutional sequence-to-sequence (ConvS2S) model and using self-critical sequence training (SCST) for optimization. Through jointly attending to topics and word-level alignment, our approach can improve coherence, diversity, and informativeness of generated summaries via a biased probability generation mechanism. On the other hand, reinforcement training, like SCST, directly optimizes the proposed model with respect to the non-differentiable metric ROUGE, which also avoids the exposure bias during inference. We carry out the experimental evaluation with state-of-the-art methods over the Gigaword, DUC-2004, and LCSTS datasets. The empirical results demonstrate the superiority of our proposed method in the abstractive summarization.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Automatic text summarization has played an important role in a variety of natural language processing (NLP) applications, such as news headlines generation <ref type="bibr" target="#b1">[Kraaij et al., 2002]</ref> and feeds stream digests <ref type="bibr" target="#b0">[Barzilay and McKeown, 2005]</ref>. It is of interest to generate informative and representative natural language summaries which are capable of retaining the main ideas of source articles. The key challenges in automatic text summarization are correctly evaluating and selecting important information, efficiently filtering redundant contents, and properly aggregating related segments and making humanreadable summaries. Compared to other NLP tasks, the automatic summarization has its own difficulties. For example, unlike machine translation tasks where input and output sequences often share similar lengths, summarization tasks are more likely to have input and output sequences greatly imbalanced. Besides, machine translation tasks usually have some direct word-level alignment between input and output sequences, which is less obvious in summarization.</p><p>There are two genres of automatic summarization techniques, namely, extraction and abstraction. The goal of extractive summarization <ref type="bibr" target="#b1">[Neto et al., 2002]</ref> is to produce a summary by selecting important pieces of the source document and concatenating them verbatim, while abstractive summarization  generates summaries based on the core ideas of the document, therefore the summaries could be paraphrased in more general terms. Other than extraction, abstractive methods should be able to properly rewrite the core ideas of the source document and assure that the generated summaries are grammatically correct and human readable, which is close to the way how humans do summarization and thus is of interest to us in this paper.</p><p>Recently, deep neural network models have been widely used for NLP tasks. In particular, the attention based sequence-to-sequence framework <ref type="bibr" target="#b0">[Bahdanau et al., 2014]</ref> with recurrent neural networks (RNNs) <ref type="bibr">[Sutskever et al., 2014]</ref> prevails in the NLP tasks. However, RNN-based models are more prone to gradient vanishing due to their chain structure of non-linearities compared to the hierarchical structure of CNN-based models <ref type="bibr" target="#b0">[Dauphin et al., 2016]</ref>. In addition, the temporal dependence among the hidden states of RNNs prevents parallelization over the elements of a sequence, which makes the training inefficient. In this paper, we propose a new approach based on the convolutional sequence-to-sequence (ConvS2S) framework <ref type="bibr" target="#b0">[Gehring et al., 2017]</ref> jointly with a topic-aware attention mechanism. To the best of our knowledge, this is the first work for automatic abstractive summarization that incorporates the topic information, which can provide themed and contextual alignment information into deep learning architectures. In addition, we also optimize our proposed model by employing the reinforcement training <ref type="bibr">[Paulus et al., 2017]</ref>. The main contributions of this paper include:</p><p>• We propose a joint attention and biased probability generation mechanism to incorporate the topic information into an automatic summarization model, which introduces contextual information to help the model generate more coherent summaries with increased diversity.</p><p>• We employ the self-critical sequence training technique in ConvS2S to directly optimize the model with respect to the non-differentiable summarization metric ROUGE, which also remedies the exposure bias issue.</p><p>• Extensive experimental results on three datasets demonstrate that by fully exploiting the power of the ConvS2S architecture enhanced by topic embedding and SCST, our proposed model yields high accuracy for abstractive summarization, advancing the state-of-the-art methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Automatic text summarization has been widely investigated. Various methods <ref type="bibr" target="#b1">[Neto et al., 2002]</ref> focus on the extractive summarization, which select important contents of text and combine them verbatim to produce a summary. On the other hand, abstractive summarization models are able to produce a grammatical summary with a novel expression, most of which <ref type="bibr" target="#b1">[Rush et al., 2015;</ref><ref type="bibr" target="#b1">Nallapati et al., 2016a]</ref> are built upon the neural attention-based sequence-tosequence framework <ref type="bibr">[Sutskever et al., 2014]</ref>.</p><p>The predominant models are based on RNNs <ref type="bibr" target="#b1">[Nallapati et al., 2016b;</ref><ref type="bibr" target="#b1">Shen et al., 2016;</ref><ref type="bibr">Paulus et al., 2017]</ref>, where the encoder and decoder are constructed using either Long Short-Term Memory (LSTM) <ref type="bibr" target="#b1">[Hochreiter and Schmidhuber, 1997]</ref> or Gated Recurrent Unit (GRU) <ref type="bibr" target="#b0">[Cho et al., 2014]</ref>. However, very few methods have explored the performance of convolutional structure on summarization tasks. Compared to RNNs, convolutional neural networks (CNNs) enjoy several advantages, including efficient training by leveraging parallel computing, and mitigating the gradient vanishing problem due to fewer non-linearities <ref type="bibr" target="#b0">[Dauphin et al., 2016]</ref>. Notably, the recently proposed gated convolutional network <ref type="bibr" target="#b0">[Dauphin et al., 2016;</ref><ref type="bibr" target="#b0">Gehring et al., 2017]</ref> outperforms RNN-based models in the language modeling and machine translation tasks. While the ConvS2S model is also evaluated on the abstractive summarization <ref type="bibr" target="#b0">[Gehring et al., 2017]</ref>, there are several limitations. First, the model is trained by minimizing a maximum-likelihood loss which is sometimes inconsistent with the metric that is evaluated on the sentence level, e.g., ROUGE <ref type="bibr" target="#b1">[Lin, 2004]</ref>. In addition, the exposure bias <ref type="bibr" target="#b1">[Ranzato et al., 2015]</ref> occurs due to only exposing the model to the training data distribution instead of its own predictions. More importantly, the ConvS2S model utilizes only wordlevel alignment which may be insufficient for summarization and prone to incoherent generated summaries. Therefore, the higher level alignment could be a potential assist. For example, the topic information has been introduced to a RNN-based sequence-to-sequence model <ref type="bibr" target="#b1">[Xing et al., 2017]</ref> for chatbots to generate more informative responses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Reinforced Topic-Aware Convolutional</head><p>Sequence-to-Sequence Model</p><p>In this section, we propose the Reinforced Topic-Aware Convolutional Sequence-to-Sequence model, which consists of a convolutional architecture with both input words and topics, a joint multi-step attention mechanism, a biased generation . Then we jointly attend to words and topics by computing dot products of decoder representations (top left) and word/topic encoder representations. Finally, we produce the target sequence through a biased probability generation mechanism. structure, and a reinforcement learning procedure. The graphical illustration of the topic-aware convolutional architecture can be found in <ref type="figure" target="#fig_0">Figure 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">ConvS2S Architecture</head><p>We exploit the ConvS2S architecture <ref type="bibr" target="#b0">[Gehring et al., 2017]</ref> as the basic infrastructure of our model. In this paper, two convolutional blocks are employed, associated with the wordlevel and topic-level embeddings, respectively. We introduce the former in this section and the latter in next, along with the new joint attention and the biased generation mechanism.</p><p>Position Embeddings Let x = (x 1 , . . . , x m ) denote the input sentence. We first embed the input elements (words) in a distributional space as w = (w 1 , . . . , w m ), where w i ∈ R d are rows of a randomly initialized matrix D word ∈ R V ×d with V being the size of vocabulary. We also add a positional embedding, p = (p 1 , . . . , p m ) with p i ∈ R d , to retain the order information. Thus, the final embedding for the input is e = (w 1 + p 1 , . . . , w m + p m ). Similarly, let q = (q 1 , . . . , q n ) denote the embedding for output elements that were already generated by the decoder and being fed back to the next step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Convolutional Layer</head><p>Both encoder and decoder networks are built by stacking several convolutional layers. Suppose that the kernel has width of k and the input embedding dimension is d. The convolution takes a concatenation of k input elements X ∈ R kd and maps it to an output element Y ∈ R 2d , namely,</p><formula xml:id="formula_0">Y = f conv (X) . = W Y X + b Y ,<label>(1)</label></formula><p>where the kernel matrix W Y ∈ R 2d×kd and the bias term b Y ∈ R 2d are the parameters to be learned. Rewrite the output as Y = [A; B], where A, B ∈ R d . Then the gated linear unit (GLU) <ref type="bibr" target="#b0">[Dauphin et al., 2016]</ref> is given by</p><formula xml:id="formula_1">g([A; B]) = A ⊗ σ(B) ,</formula><p>(2) where σ is the sigmoid function, ⊗ is the point-wise multiplication, and the output of GLU is in R d .</p><p>We denote the outputs of the l-th layer as h l = (h l 1 , . . . , h l n ) for the decoder, and z l = (z l 1 , . . . , z l m ) for the encoder. Take the decoder for illustration. The convolution unit i on the l-th layer is computed by residual connections as</p><formula xml:id="formula_2">h l i = g • f conv h l−1 i−k/2 ; · · · ; h l−1 i+k/2 + h l−1 i ,<label>(3)</label></formula><p>where h l i ∈ R d and • is the function composition operator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-step Attention</head><p>The attention mechanism is introduced to make the model access historical information. To compute the attention, we first embed the current decoder state h l i as</p><formula xml:id="formula_3">d l i = W l d h l i + b l d + q i ,<label>(4)</label></formula><p>where q i ∈ R d is the embedding of the previous decoded element. Weight matrix W l d ∈ R d×d and bias b l d ∈ R d are the parameters to be learned.</p><p>The attention weights α l ij of state i and source input element j is computed as a dot product between d l i and the output z uo j of the last encoder block u o , namely,</p><formula xml:id="formula_4">α l ij = exp(d l i · z uo j ) m t=1 exp(d l i · z uo t )</formula><p>.</p><p>The conditional input c l i ∈ R d for the current decoder layer is computed as</p><formula xml:id="formula_6">c l i = m j=1 α l ij (z uo j + e j ) ,<label>(6)</label></formula><p>where e j is the input element embedding that can provide point information about a specific input element. Once c l i has been computed, it is added to the output of the corresponding decoder layer h l i and serves as a part of the input to h l+1 i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Topic-Aware Attention Mechanism</head><p>A topic model is a type of statistical model for discovering the abstract ideas or hidden semantic structures that occur in a collection of source articles. In this paper, we employ the topic model to acquire latent knowledge of documents and incorporate a topic-aware mechanism into the multi-step attention-based ConvS2S model, which is expected to bring prior knowledge for text summarization. Now we present the novel approach on how to incorporate the topic model into the basic ConvS2S framework via the joint attention mechanism and biased probability generation process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Topic Embeddings</head><p>The topic embeddings are obtained by classical topic models such as Latent Dirichlet Allocation (LDA) <ref type="bibr" target="#b0">[Blei et al., 2003]</ref>. During pre-training, we use LDA to assign topics to the input texts. The top N non-universal words with the highest probabilities of each topic are chosen into the topic vocabulary K. More details will be given in Section 4. While the vocabulary of texts is denoted as V , we assume that K ⊂ V . Given an input sentence x = (x 1 , . . . , x m ), if a word x i / ∈ K, we embed it as before to attain w i . However, if a word x i ∈ K, we can embed this topic word as t i ∈ R d , which is a row in the topic embedding matrix D topic ∈ R K×d , where K is the size of topic vocabulary. The embedding matrix D topic is normalized from the corresponding pre-trained topic distribution matrix, whose row is proportional to the number of times that each word is assigned to each topic. In this case, the positional embedding vectors are also added to the encoder and decoder elements, respectively, to obtain the final topic embeddings r = (r 1 , . . . , r m ) and s = (s 1 , . . . , s n ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Joint Attention</head><p>Again we take the decoder for illustration. Following the convolutional layer introduced before, we can obtain the convolution unit i on the l-th layer in the decoder of topic level as</p><formula xml:id="formula_7">h l i ∈ R d . Similar to (4), we havẽ d l i =W l dh l i +b l d + s i .<label>(7)</label></formula><p>We then incorporate the topic information into the model through a joint attention mechanism. During decoding, the joint attention weight β l ij is given by</p><formula xml:id="formula_8">β l ij = exp(d l i · z uo j +d l i · z ut j ) m t=1 exp(d l i · z uo t +d l i · z ut t ) ,<label>(8)</label></formula><p>where z ut j is the output of the last topic-level encoder block u t . Then the conditional inputc l i ∈ R d is computed as</p><formula xml:id="formula_9">c l i = m j=1 β l ij (z ut j + r j ) .<label>(9)</label></formula><p>In the joint attention mechanism, bothc l i and c l i are added to the output of the corresponding decoder layerh l i and are a part of the input toh l+1 i . Biased Probability Generation Finally, we compute a distribution over all possible next target elements y i+1 ∈ R T , namely</p><formula xml:id="formula_10">p θ (y i+1 ) := p(y i+1 |y 1 , . . . , y i , x) ∈ R T ,<label>(10)</label></formula><p>by transforming the top word-level decoder outputs h Lo and topic-level decoder outputsh Lt via a linear layer Ψ(·), which is computed by</p><formula xml:id="formula_11">Ψ(h) = W o h + b o ,<label>(11)</label></formula><p>where W o ∈ R T ×d and b o ∈ R T are the parameters to be learned. Then the biased generation distribution is given as</p><formula xml:id="formula_12">p θ (y i+1 ) = 1 Z exp Ψ(h Lo i ) + exp Ψ(h Lt i ) ⊗ I {w∈K} ,<label>(12)</label></formula><p>where Z is the normalizer, h Lo i andh Lt i denote the i-th top decoder outputs of word and topic, respectively, and I is the one-hot indicator vector of each candidate word w in y i+1 . When the candidate word w is a topic word, we bias the generation distribution by the topic information. Otherwise, we ignore the topic part. To some extent, the complexity of the search space is reduced by introducing the topic bias since important words are more likely to be generated directly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Reinforcement Learning</head><p>The teacher forcing algorithm <ref type="bibr" target="#b1">[Williams and Zipser, 1989]</ref> aims to minimize the maximum-likelihood loss at each decoding step, namely,</p><formula xml:id="formula_13">L ml = − T i=1 log p θ (y * i |y * 1 , y * 2 , . . . , y * i−1 , x) ,<label>(13)</label></formula><p>where x refers to an input sequence and y * = (y * 1 ,y * 2 ,. . . ,y * T ) is the corresponding ground-truth output sequence.</p><p>Minimizing the objective in Eq. (13) often produces suboptimal results with respect to the evaluation metrics, such as ROUGE which measures the sentence-level accuracy of the generated summaries. The sub-optimality is related to the problem called exposure bias <ref type="bibr" target="#b1">[Ranzato et al., 2015]</ref>, which is caused by only exposing a model to the distribution of training data instead of its own distribution. During the training process, models are fed by ground-truth output sequences to predict the next word, whereas during inference they generate the next word given the predicted words as inputs. Therefore, in the test process, the error of each step accumulates and leads to the deterioration of performance.</p><p>The second reason for sub-optimality comes from the flexibility of summaries. The maximum-likelihood objective rewards models that can predict exactly the same summaries as references while penalizing those that produce different texts even though they are semantically similar. Providing multiple reference summaries is helpful yet insufficient since there are alternatives to rephrase a given summary. Therefore, minimizing the objective in Eq. (13) neglects the intrinsic property of summarization. ROUGE, on the other hand, provides more flexible evaluation, encouraging models to focus more on semantic meanings than on word-level correspondences.</p><p>In order to address such issues, we utilize self-critical sequence training (SCST) <ref type="bibr" target="#b1">[Rennie et al., 2016]</ref>, a policy gradient algorithm for reinforcement learning, to directly maximize the non-differentiable ROUGE metric. During reinforcement learning, we generate two output sequences given the input sequence x. The first sequenceŷ is obtained by greedily selecting words that maximize the output probability distribution, and the other output sequence y s is generated by sampling from the distribution. After obtaining ROUGE scores of both sequences as our rewards, i.e., r(y s ) and r(ŷ), we minimize the reinforcement loss</p><formula xml:id="formula_14">L rl = −(r(y s ) − r(ŷ)) log p θ (y s ),<label>(14)</label></formula><p>and update model parameters by gradient descent techniques. With SCST, we can directly optimize the discrete evaluation metric. In addition, the "self-critical" test-time estimate of the reward r(ŷ) provides a simple yet effective baseline</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>No.</head><p>Topic <ref type="table" target="#tab_0">Words  1  prime, minister, talks, leader, elections, visit  2  bird, flu, officials, opens, poultry, die  3  trade, free, EU, army, urges, ban  4</ref> Bush, world, talks, foreign, investment, markets 5 world, Malaysia, Thailand, meet, Vietnam, U.S. In this paper, we consider three datasets to evaluate the performance of different methods in the abstractive text summarization task. First, we consider the annotated Gigaword corpus <ref type="bibr" target="#b1">[Graff and Cieri, 2003]</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Topic Information</head><p>The classical LDA with Gibbs Sampling technique is used to pre-train the corpus for topic embedding initialization and provide candidates for the biased probability generation process. The topic embedding values are normalized to a distribution with mean zero and variance of 0.1 for adaption to the neural network structure. In this paper, we pick top N = 200 words with the highest probabilities in each topic to obtain the topic word set. Note that the universal words are filtered out during pre-training. Randomly selected examples of topic words of the Gigaword corpus are presented in <ref type="table" target="#tab_0">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Model Parameters and Optimization</head><p>We employ six convolutional layers for both the encoder and decoder. All embeddings, including the initialized embed-   ding and the output produced by the decoder before the final linear layer, have a dimensionality of 256. We also adopt the same dimensionality for the size of linear layer mapping between hidden and embedding states. We use a learning rate of 0.25 and reduce it by a decay rate of 0.1 once the validation ROUGE score stops increasing after each epoch until the learning rate falls below 10 −5 . We first train the basic topic-aware convolutional model with respect to a standard maximum likelihood objective, and then switch to further minimize a mixed training objective <ref type="bibr">[Paulus et al., 2017]</ref>, incorporating the reinforcement learning objective L rl and the original maximum likelihood L ml , which is given as</p><formula xml:id="formula_15">L mixed = λL rl + (1 − λ)L ml ,<label>(15)</label></formula><p>where the scaling factor λ is set to be 0.99 in our experiments. Moreover, we choose the ROUGE-L metric as the reinforcement reward function. Nesterov's accelerated gradient method <ref type="bibr">[Sutskever et al., 2013]</ref> is used for training, with the mini-batch size of 32 and the learning rate of 0.0001. All models are implemented in PyTorch <ref type="bibr">[Paszke et al., 2017]</ref> and trained on a single Tesla M40 GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Analysis</head><p>We follow the existing work and adopt the ROUGE metric <ref type="bibr" target="#b1">[Lin, 2004]</ref> for evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Gigaword Corpus</head><p>We demonstrate the effectiveness of our proposed model via a step-by-step justification. First, the basic ConvS2S structure with topic-aware model or reinforcement learning is tested, respectively. Then we combine the two to show the performance of our Reinforced-Topic-ConvS2S model. We report Examples of summaries D: the sri lankan government on wednesday announced the closure of government schools with immediate effect as a military campaign against tamil separatists escalated in the north of the country. R: sri lanka closes schools as war escalates OR: sri lanka closes schools with immediate effect OT: sri lanka closes schools in wake of military attacks D: a us citizen who spied for communist east germany was given a suspended jail sentence of ## months here friday. R: us citizen who spied for east germans given suspended sentence OR: us man gets suspended jail term for communist spying OT: us man jailed for espionage D: malaysian prime minister mahathir mohamad indicated he would soon relinquish control of the ruling party to his deputy anwar ibrahim. R: mahathir wants leadership change to be smooth OR: malaysia's mahathir to relinquish control of ruling party OT: malaysia's mahathir to submit control of ruling party D: a french crocodile farm said it had stepped up efforts to breed one of the world's most endangered species, the indian UNK, with the hope of ultimately returning animals to their habitat in south asia. R: french farm offers hope for endangered asian crocs UNK picture OR: french crocodile farm steps up efforts to breed endangered species OT: french crocodile farm says steps up efforts to save endangered species the full-length F-1 scores of the ROUGE-1 (RG-1), ROUGE-2 (RG-2), and ROUGE-L (RG-L) metrics and compare the results with various neural abstractive summarization methods, which are presented in <ref type="table" target="#tab_3">Table 2</ref>. The ABS and ABS+ models are attention-based neural models for text summarization. The RAS-Elman model introduces a conditional RNN, in which the conditioner is provided by a convolutional attention-based encoder. The words-lvt5k-1sent model is also a RNN-based attention model which implements a largevocabulary trick. Besides, RNN+MRT employs the minimum risk training strategy which directly optimizes model parameters in sentence level with respect to the evaluation metrics. SEASS (beam) extends the sequence-to-sequence framework with a selective encoding model. The results have demonstrated that both the topic-aware module and the reinforcement learning process can improve the accuracy on text summarization. Moreover, our proposed model exhibits best scores of RG-1, RG-2 and RG-L. In addition, <ref type="bibr" target="#b1">[Zhou et al., 2017]</ref> further selects 2000 pairs of summaries as an internal test set of Gigaword. We also evaluate our proposed model on this set and present the results in <ref type="table" target="#tab_4">Table 3</ref>. Again, our proposed model achieves the best performance in terms of all the three ROUGE scores.</p><p>To further demonstrate the improvement of readability and diversity by the topic information, we also present some qualitative results by randomly extracting several summaries from test. We compare the reference summaries to the summaries generated by our proposed model with or without topic-aware mechanism. The examples are presented in <ref type="table" target="#tab_5">Table 4</ref>. We can observe that when the topic model is adopted, it can generate some accurately delivered topic words which are not in RG-1 (R) RG-2 (R) RG-L (R) ABS <ref type="bibr" target="#b1">[Rush et al., 2015]</ref> 26.55 7.06 22.05 ABS+ <ref type="bibr" target="#b1">[Rush et al., 2015]</ref> 28  the reference summaries or the original texts. It is believed that the joint learning with a pre-trained topic model can offer more insightful information and improve the diversity and readability for the summarization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">DUC-2004 Dataset</head><p>Since the DUC-2004 dataset is an evaluation-only dataset, we train the models on the Gigaword corpus first and then evaluate their performance on the DUC dataset. As the standard practice, we report the recall-based scores of the RG-1, RG-2, and RG-L metrics in this experiment, which are given in <ref type="table" target="#tab_7">Table 5</ref>. From <ref type="table" target="#tab_7">Table 5</ref> we can observe that the proposed Reinforced-Topic-ConvS2S model achieves best scores of the RG-1 and RG-L metrics, and is comparable on the RG-2 score. Due to the similarity of the two datasets, we do not provide qualitative summarization examples in this experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">LCSTS Dataset</head><p>We now consider the abstractive summarization task on the LCSTS dataset. Since this is a large-scale Chinese dataset, suitable data preprocessing approaches should be proposed first. Basically, there are two approaches to preprocessing the Chinese dataset: character-based and word-based. The former takes each Chinese character as the input, while the latter splits an input sentence into Chinese words. <ref type="bibr" target="#b1">[Hu et al., 2015]</ref> provides a baseline result on both preprocessing approaches. <ref type="bibr" target="#b1">[Shen et al., 2016]</ref> also conducts experiments on the LCSTS corpus based on character inputs. <ref type="bibr" target="#b1">[Gu et al., 2016]</ref> proposes a neural model, the COPYNET, with both character-based and word-based preprocessing by incorporating the copying mechanism into the sequence-to-sequence framework. In this work, we adopt the word-based approach as we believe that in the case of Chinese, words are more relevant to latent knowledge of documents than characters are. Since the standard ROUGE package 2 is usually used to evaluate the English summaries, directly employing the package to evaluate Chinese summaries would yield underrated results. In order to evaluate the summarization on the LC-STS dataset, we follow the suggestion of <ref type="bibr" target="#b1">[Hu et al., 2015]</ref> by mapping Chinese words/characters to numerical IDs, on which we then perform the ROUGE evaluation. Since not all previous work explicitly mentioned whether word-based  RG-2 (F) RG-L (F) character-based preprocessing RNN context <ref type="bibr" target="#b1">[Hu et al., 2015]</ref> 29.90 <ref type="bibr">17.40 27.20 COPYNET [Gu et al., 2016]</ref> 34.40 21.60 31.30 <ref type="bibr">RNN+MLE [Shen et al., 2016]</ref> 34.90 23.30 32.70 <ref type="bibr">RNN+MRT [Shen et al., 2016</ref><ref type="bibr">] 38.20 25.20 35.40 word-based preprocessing RNN context [Hu et al., 2015</ref> 26.80 16.10 24.10 COPYNET <ref type="bibr" target="#b1">[Gu et al., 2016]</ref> 35  <ref type="table">Table 6</ref>: Accuracy on the LCSTS dataset in terms of the full-length RG-1, RG-2, and RG-L. In last three rows, the word-level ROUGE scores are presented on the left and the character-level on the right.</p><p>or character-based ROUGE metrics were reported, we evaluate our proposed model with both metrics in order to obtain a comprehensive comparison. The results of both scores are presented in <ref type="table">Table 6</ref>, which are displayed as word-based score/character-based score.</p><p>From the results shown in <ref type="table">Table 6</ref>, we see that one can always achieve higher ROUGE scores in the character level than that based on Chinese words by our proposed model. We can also observe that the character-based results of our Reinforced-Topic-ConvS2S model outperforms every other method. Regarding to word-based ROUGE scores, our model obtains the best performance in terms of RG-1 and RG-L metrics. However, our best model does not achieve a good RG-2 score as its RG-1 and RG-L scores. We suspect that it may be partly caused by the biased probability generation mechanism that influences word order, which requires further studies.</p><p>In addition to ROUGE scores, we also present randomly picked examples of generated summaries in <ref type="table">Table 7</ref>. The original examples (in Chinese) are shown and all the texts are carefully translated for the convenience of reading. The examples demonstrate that the topic-aware mechanism can also improve the diversity in Chinese summarization tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>In this work, we propose a topic-aware ConvS2S model with reinforcement learning for abstractive text summarization. It is demonstrated that the new topic-aware attention mechanism introduces some high-level contextual information for summarization. The performance of the proposed model advances state-of-the-art methods on various benchmark datasets. In addition, our model can produce summaries with better informativeness, coherence, and diversity.</p><p>Note that the experiments in this work are mainly based on the sentence summarization. In the future, we aim to evaluate our model on the datasets where the source texts can be long paragraphs or multi-documents. Moreover, we also note that how to evaluate the performance on Chinese summaries remains an open problem. It is also of great interest to study on this subject in the future.</p><p>Examples of summaries D: 根据#### 年# 月# 日国家发改委等部门联合发布的《关于进一步做好新能源汽车推广应用工作的通知》，#### 年的 补贴金额相比#### 年将降低##% 。(分享自@ 电动邦) D: According to the notice On the further promotion and application of new energy vehicles, jointly released by the National Development and Reform Commission and other departments on ##/##/#### (date), the compensation of #### (year) will be reduced by ##% compared to #### (year). (reposted from @electric nation) R: 补贴金额再缩水#### 年新能源车政策解读 R: The compensation has been reduced again: #### (year) policy analysis of new energy automobiles OR: #### 年新能源汽车推广应用工作的通知 OR: #### (year) notice on the promotion and application of new energy vehicles OT : 国家发改委 发文 进一步做好 新能源汽车 推广应用工作 OT : The National Development and Reform Commission issued a policy on further promotion and application of new energy vehicles D: 成都市软件和信息技术服务业近年来一直保持快速增长势头，稳居中西部城市之首，已成为我国西部" 硅谷" 。 《#### 年度成都市软件和信息技术服务产业发展报告》日前发布. . . . . . 详情请见: @ 成都日报@ 成都发布 D: In recent years, the service industry of software and information technology in Chengdu has been growing rapidly, ranking first among the cities in Midwest China. Chengdu has become China's western "Silicon Valley". The #### (year) Annual Chengdu Software and Information Technology Service Industry Development Report has been released recently ... ... see details: @ Chengdu Daily @ Chengdu release R: 成都倾力打造西部" 硅谷" R: Chengdu makes every effort to build the western "Silicon Valley" OR: 成都软件 和信息技术服务业发展报告发布 OR: The report of Chengdu software and information technology service industry development has been released OT : 成都软件 和信息技术服务业 跃居 西部" 硅谷" OT : The service industry of software and information technology in Chengdu rockets to make it the western "Silicon Valley" D: 新疆独特的区位优势，使其成为" 一带一路" 战略重要一环。记者从新疆发改委获悉，库尔勒至格尔木铁路先期开工 段已进入招投标阶段，计划#### 年## 月中旬正式开工建设。#### 年计划完成投资## 亿元。 D: Xinjiang's unique geographical advantages make it an important part of The Belt and Road strategy. The reporter learned from the Xinjiang Development and Reform Commission that the initial railway construction project from Korla to Golmud had been on tendering procedure. The project was scheduled to officially launch in mid ## (month) of #### (year) and attract the investment of ## billion yuan by #### (year). R: " 一带一路" 战略惠及新疆&lt;unk&gt;, 铁路年底开建 R: The Belt and Road strategy benefits Xinjiang &lt;unk&gt; and the railway construction starts by the end of #### (year) OR: 新疆&lt;unk&gt; 至格尔木铁路计划#### 年开建 OR: The railway from &lt;unk&gt; to Golmud is scheduled to start construction in #### (year) OT : 库尔勒至格尔木铁路拟 ## 月开工建设 OT : The railway construction project from Korla to Golmud is planned to launch in ## (month) D: 昨日，商报记者从代表国内婚尚产业" 风向标" 的上海国际婚纱摄影器材展览会上了解到，部分商家开始将婚庆布 置、婚礼流程、形式交给新人决定以迎合## 后新人的需求。此次展览会的规模超过# 万平方米，吸引参展企业超过### 家。 D: The day before, the reporters of Commercial News learned from the Shanghai International Wedding Photographic Equipment Exhibition, which has been leading and defining the domestic wedding industry, that some companies began to cater for the requirements of ##s-generation newly married couples by self-decided wedding decoration, wedding process and forms. The venue of the exhibition is more than # tens of thousands square meters, attracting more than ### exhibitors. R: 婚庆" 私人定制" 受## 后新人追捧 R: The personalized wedding is admired by ##s-generation newly married couples OR: 上海 国际婚纱摄影 器材展览会举行 OR: Shanghai International Wedding Photographic Equipment Exhibition was held OT : 上海 国际婚纱摄影 器材展览会昨 举行 OT : Shanghai International Wedding Photographic Equipment Exhibition was held yesterday <ref type="table">Table 7</ref>: Examples of generated summaries on the LCSTS dataset. D: source document, R: reference summary, OR: output of the Reinforced-ConvS2S model, OT: output of the Reinforced-Topic-ConvS2S model. The words marked in blue are topic words not in the reference summaries. The words marked in red are topic words neither in the reference summaries nor in the source documents. All the texts are carefully translated from Chinese.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>A graphical illustration of the topic-aware convolutional architecture. Word and topic embeddings of the source sequence are encoded by the associated convolutional blocks (bottom left and bottom right)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Examples of topic words for the Gigaword corpus. and improves training/test time consistency. Since during learning we set the baseline of the REINFORCE algorithm as the reward obtained by the current model in the test-time inference, the SCST exposes the model to its own distribution and encourages it to produce the sequence outputŷ with a high ROUGE score, avoiding the exposure bias issue and thus improving the test performance.</figDesc><table><row><cell>4 Experimental Setup</cell></row><row><cell>4.1 Datasets</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell cols="4">: Accuracy on the Gigaword corpus in terms of the full-</cell></row><row><cell cols="4">length ROUGE-1 (RG-1), ROUGE-2 (RG-2), and ROUGE-L (RG-</cell></row><row><cell cols="4">L). Best performance on each score is displayed in boldface.</cell></row><row><cell></cell><cell cols="3">RG-1 (F) RG-2 (F) RG-L (F)</cell></row><row><cell>ABS (beam) [Rush et al., 2015]</cell><cell>37.41</cell><cell>15.87</cell><cell>34.70</cell></row><row><cell>s2s+att (greedy) [Zhou et al., 2017]</cell><cell>42.41</cell><cell>20.76</cell><cell>39.84</cell></row><row><cell>s2s+att (beam) [Zhou et al., 2017]</cell><cell>43.76</cell><cell>22.28</cell><cell>41.14</cell></row><row><cell>SEASS (greedy) [Zhou et al., 2017]</cell><cell>45.27</cell><cell>22.88</cell><cell>42.20</cell></row><row><cell>SEASS (beam) [Zhou et al., 2017]</cell><cell>46.86</cell><cell>24.58</cell><cell>43.53</cell></row><row><cell>Topic-ConvS2S</cell><cell>46.80</cell><cell>24.74</cell><cell>43.92</cell></row><row><cell>Reinforced-ConvS2S</cell><cell>46.68</cell><cell>24.22</cell><cell>43.76</cell></row><row><cell>Reinforced-Topic-ConvS2S</cell><cell>46.92</cell><cell>24.83</cell><cell>44.04</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table /><note>Accuracy on the internal test set of Gigaword corpus in terms of the full-length RG-1, RG-2, and RG-L. Best performance on each score is displayed in boldface.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Examples of generated summaries on the Gigaword corpus. D: source document, R: reference summary, OR: output of the Reinforced-ConvS2S model, OT: output of the Reinforced-Topic-ConvS2S model. The words marked in blue are topic words not in the reference summaries. The words marked in red are topic words neither in the reference summaries nor in the source documents.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Accuracy on the DUC-2004 dataset in terms of the recallonly RG-1, RG-2, and RG-L. Best performance on each score is displayed in boldface.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://duc.nist.gov/data.html Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence (IJCAI-18)</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence </note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">http://www.berouge.com/Pages/default.aspx</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>Qiang Du is supported in part by the US NSF TRIPODs project through CCF-170483.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>References</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bahdanau</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.0473</idno>
		<idno>arXiv:1705.03122</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Michael Auli</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-01" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="93" to="98" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Jonas Gehring. David Grangier, Denis Yarats, and Yann N Dauphin. Convolutional sequence to sequence learning</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Ilya Sutskever, Oriol Vinyals, and Quoc V Le. Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cieri ; David</forename><surname>Graff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Gu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.06393</idno>
		<idno>arXiv:1704.07073</idno>
	</analytic>
	<monogr>
		<title level="m">Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive summarization. CoRR, abs/1705.04304</title>
		<editor>Ilya Sutskever, James Martens, George Dahl, and Geoffrey Hinton</editor>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Williams and Zipser</publisher>
			<date type="published" when="1989-06" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="3351" to="3357" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence. IJCAI-18</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
