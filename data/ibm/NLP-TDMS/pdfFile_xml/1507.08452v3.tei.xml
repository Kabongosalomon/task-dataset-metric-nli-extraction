<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Unsupervised Sentence Simplification Using Deep Semantics</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2016-09-07">7 Sep 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashi</forename><surname>Narayan</surname></persName>
							<email>shashi.narayan@ed.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">School of Informatics</orgName>
								<orgName type="institution">The University of Edinburgh Edinburgh</orgName>
								<address>
									<postCode>EH8 9AB</postCode>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Gardent</surname></persName>
							<email>claire.gardent@loria.fr</email>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">CNRS</orgName>
								<orgName type="institution" key="instit2">LORIA</orgName>
								<address>
									<postCode>7503, F-54500</postCode>
									<settlement>Vandoeuvre-l√®s-Nancy</settlement>
									<region>UMR</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Unsupervised Sentence Simplification Using Deep Semantics</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2016-09-07">7 Sep 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T20:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a novel approach to sentence simplification which departs from previous work in two main ways. First, it requires neither hand written rules nor a training corpus of aligned standard and simplified sentences. Second, sentence splitting operates on deep semantic structure. We show (i) that the unsupervised framework we propose is competitive with four state-of-the-art supervised systems and (ii) that our semantic based approach allows for a principled and effective handling of sentence splitting.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Sentence simplification maps a sentence to a simpler, more readable one approximating its content. As has been argued in <ref type="bibr" target="#b12">(Shardlow, 2014)</ref>, sentence simplification has many potential applications. It is useful as a preprocessing step for a variety of NLP systems such as parsers and machine translation systems <ref type="bibr" target="#b4">(Chandrasekar et al., 1996)</ref>, summarisation <ref type="bibr" target="#b8">(Knight and Marcu, 2000)</ref>, sentence fusion <ref type="bibr">(Filippova and Strube, 2008)</ref> and semantic role labelling <ref type="bibr" target="#b18">(Vickrey and Koller, 2008)</ref>. It also has wide ranging potential societal applications as a reading aid for people with aphasia <ref type="bibr" target="#b2">(Carroll et al., 1999)</ref>, for low literacy readers <ref type="bibr" target="#b19">(Watanabe et al., 2009</ref>) and for non native speakers <ref type="bibr" target="#b14">(Siddharthan, 2002)</ref>.</p><p>In this paper, we present a novel approach to sentence simplification which departs from previous work in two main ways. First, it requires neither hand written rules nor a training corpus of aligned standard and simplified sentences. Instead, we exploit non aligned Simple and English Wikipedia to learn the probability of lexical simplifications, of the semantics of simple sentences and of optional phrases i.e., phrase which may be deleted when simplifying. Second, sentence splitting is semantic based. We show (i) that our unsupervised framework is competitive with four stateof-the-art systems and (ii) that our semantic based approach allows for a principled and effective handling of sentence splitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Earlier work on sentence simplification relied on handcrafted rules to capture syntactic simplification e.g., to split coordinated and subordinated sentences into several, simpler clauses or to model e.g., active/passive transformations <ref type="bibr" target="#b14">(Siddharthan, 2002;</ref><ref type="bibr" target="#b3">Chandrasekar and Srinivas, 1997;</ref><ref type="bibr" target="#b1">Canning, 2002;</ref><ref type="bibr" target="#b16">Siddharthan, 2011;</ref><ref type="bibr" target="#b15">Siddharthan, 2010)</ref>. While these hand-crafted approaches can encode precise and linguistically well-informed syntactic transformations, they do not account for lexical simplifications and their interaction with the sentential context. <ref type="bibr" target="#b13">Siddharthan and Mandya (2014)</ref> therefore propose an approach where hand-crafted syntactic simplification rules are combined with lexical simplification rules extracted from aligned English and simple English sentences, and revision histories of Simple Wikipedia.</p><p>Using the parallel dataset formed by Simple English Wikipedia (SWKP) 1 and traditional English Wikipedia (EWKP) 2 , further work has focused on developing machine learning approaches to sentence simplification. <ref type="bibr" target="#b24">Zhu et al. (2010)</ref> constructed a parallel Wikipedia corpus (PWKP) of 108,016/114,924 complex/simple sentences by aligning sentences from EWKP and SWKP and used the resulting bitext to train a simplification model inspired by syntax-based machine translation <ref type="bibr" target="#b23">(Yamada and Knight, 2001</ref>). Their simplification model encodes the probabilities for four rewriting operations on the parse tree of an input sentences namely, substitution, reordering, splitting and deletion. It is combined with a language model to improve grammaticality and the decoder translates sentences into simpler ones by greedily selecting the output sentence with highest probability.</p><p>Using both the PWKP corpus developed by <ref type="bibr" target="#b24">Zhu et al. (2010)</ref> and the edit history of simple Wikipedia, <ref type="bibr" target="#b20">Woodsend and Lapata (2011)</ref> learn a quasi synchronous grammar <ref type="bibr">(Smith and Eisner, 2006)</ref> describing a loose alignment between parse trees of complex and of simple sentences. Following <ref type="bibr" target="#b6">Dras (1999)</ref>, they then generate all possible rewrites for a source tree and use integer linear programming to select the most appropriate simplification. They evaluate their model on the same dataset used by <ref type="bibr" target="#b24">Zhu et al. (2010)</ref> namely, an aligned corpus of 100/131 EWKP/SWKP sentences. <ref type="bibr">Wubben et al. (2012), Coster and</ref><ref type="bibr">Kauchak (2011)</ref> and <ref type="bibr" target="#b22">Xu et al. (2016)</ref> saw simplification as a monolingual translation task where the complex sentence is the source and the simpler one is the target. To account for deletions, reordering and substitution, Coster and Kauchak (2011) trained a phrase based machine translation system on the PWKP corpus while modifying the word alignment output by GIZA++ in Moses to allow for null phrasal alignments. In this way, they allow for phrases to be deleted during translation. Similarly, <ref type="bibr" target="#b21">Wubben et al. (2012)</ref> used Moses and the PWKP data to train a phrase based machine translation system augmented with a post-hoc reranking procedure designed to rank the output based on their dissimilarity from the source sentence.</p><p>Unlinke <ref type="bibr" target="#b21">Wubben et al. (2012)</ref> and Coster and Kauchak (2011) who used machine translation as a black box, <ref type="bibr" target="#b22">Xu et al. (2016)</ref> proposed to modify the optimization function of SMT systems by tuning them for the sentence simplification task. However, in their work they primarily focus on lexical simplification.</p><p>Finally, Narayan and Gardent (2014) present a hybrid approach combining a probabilistic model for sentence splitting and deletion with a statistical machine translation system trained on PWKP for substitution and reordering.</p><p>Our proposal differs from all these approaches in that it does not use the parallel PWKP corpus for training. Nor do we use hand-written rules. Another difference is that we use a deep semantic representation as input for simplification. While a similar approach was proposed in <ref type="bibr" target="#b10">(Narayan and Gardent, 2014)</ref>, the probabilistic models differ in that we determine splitting points based on the maximum likelihood of sequences of thematic role sets present in SWKP whereas <ref type="bibr" target="#b10">Narayan and Gardent (2014)</ref> derive the probability of a split from the aligned EWKP/SWKP corpus using expectation maximisation. As we shall see in Section 4, because their data is more sparse, Narayan and Gardent (2014) predicts less and lower quality simplifications by sentence splitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Simplification Framework</head><p>Our simplification framework pipelines three dedicated modules inspired from previous work on lexical simplification, syntactic simplification and sentence compression. All three modules are unsupervised.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Example Simplification</head><p>Before describing the three main modules of our simplification framework, we illustrate its working with an example. <ref type="figure">Figure 1</ref> shows the input semantic representation associated with sentence (1C) and illustrates the successive simplification steps yielding the intermediate and final simplified sentences shown in (1S 1 -S).</p><p>(1) C. In 1964 Peter Higgs published his second paper in Physical Review Letters describing Higgs mechanism which predicted a new massive spin-zero boson for the first time. S1 (Lex Simp). In 1964 Peter Higgs wrote his second paper in Physical Review Letters explaining Higgs mechanism which predicted a new massive elementary particle for the first time. S2 (Split). In 1964 Peter Higgs wrote his second paper in Physical Review Letters explaining Higgs mechanism. Higgs mechanism predicted a new massive elementary particle for the first time. S (Deletion). In 1964 Peter Higgs wrote his paper explaining Higgs mechanism. Higgs mechanism predicted a new elementary particle.</p><p>First, the input (1C) is rewritten as (1S 1 ) by replacing standard words with simpler ones using the context aware lexical simplification method proposed in <ref type="bibr" target="#b0">(Biran et al., 2011)</ref>.</p><p>Splitting is then applied to the semantic representation of (1S 1 ).</p><p>Following <ref type="bibr" target="#b10">Narayan and Gardent (2014)</ref>, we use Boxer 3</p><p>In 1964 Peter Higgs published his second paper in Physical Review Letters describing Higgs mechanism which predicted a new massive spin-zero boson for the first time .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lex Simpl.</head><p>In 1964 Peter Higgs wrote his second paper in Physical Review Letters explaining Higgs mechanism which predicted a new massive elementary particle for the first time .</p><p>(( X0 named(X0, higgs, per) named(X0, peter, per)</p><formula xml:id="formula_0">‚àß( X1 male(X1) ‚àß( X2 second(X2) paper(X2) of(X2, X1) ‚àß( X3 write(X3) agent(X3, X0) patient(X3, X2) ; ( X4 named(X4, physical, org) named(X4, review, org) named(X4, letters, org) ‚àß X5 thing(X5) event(X3) in(X3, X4) in(X3, X5) timex(X5) = 1964</formula><p>))))) ; ( X6 ; ( </p><formula xml:id="formula_1">X7, X8 mechanism(X8) nn(X7, X8) named(X7, higgs, org) ‚àß X9, X10, X11, X12 new(X9) massive(X9) elementary(X9) particle(X9) predict(X10) event(X10) explain(X11) event(X11) first(X12) time(X12) agent(X10, X8) patient(X10, X9) agent(X11, X6) patient(X11, X8) for(X10, X12) )) [Discourse Representation Structure produced by BOXER] ROOT O1 X10 X12 X9 R10 R11 X11 X8 X7 R8 X6 R6 R7 X3 X5 X4 X2 X1 R3 X0 R1 R2 R4 R5 R9 [DRS Graph Representation]<label>O1</label></formula><formula xml:id="formula_2">R11 23 f or, X10 ‚Üí X12 R10 17 patient, X10 ‚Üí X9 R9 17 agent, X10 ‚Üí X8 R8 ‚àí‚àí nn, X8 ‚Üí X7 R7 13 patient, X11 ‚Üí X8 R6 13 agent, X11 ‚Üí X6 R5 1 in, X3 ‚Üí X5 R4 9 in, X3 ‚Üí X4 R3 6 of, X2 ‚Üí X1 R2 5 patient, X3 ‚Üí X2 R1 5 agent, X3 ‚Üí X0 rel pos. in S predicate ROOT X11 X8 X7 R8 X6 R6 R7 X3 X5 X4 X2 X1 R3 X0 R1 R2 R4 R5 ROOT X10 X12 X9 X8 X7 R8 R9 R10 R11 ( ) Split ROOT X11 X8 X7 R8 X6 R6 R7 X3 X5 X ‚Ä≤ 2 X1 R3 X0 R1 R2 R5</formula><p>In 1964 Peter Higgs wrote his paper explaining Higgs mechanism.</p><p>ROOT X10 X ‚Ä≤ 9 X8 X7 R8</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>R9 R10</head><p>Higgs mechanism predicted a new elementary particle.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>( )</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Deletion</head><p>Figure 1: Simplification of "In 1964 Peter Higgs published his second paper in Physical Review Letters describing Higgs mechanism which predicted a new massive spin-zero boson for the first time." <ref type="bibr" target="#b5">(Curran et al., 2007)</ref> to map the output sentence from the lexical simplification step (here S 1 ) to a Discourse Representation Structure (DRS, <ref type="bibr" target="#b7">(Kamp, 1981)</ref>). The DRS for S 1 is shown at the top of <ref type="figure">Figure 1</ref> and a graph representation 4 of the dependencies between its variables is shown immediately below. In this graph, each DRS variable labels a node in the graph and each edge is labelled with the relation holding between the variables labelling its end vertices. The two tables to the right of the picture show the predicates (top table) associated with each variable and the relation label (bottom table) associated with each edge. Boxer also outputs the associated positions in the complex sentence for each predicate (not shown in the DRS but shown in the graph tables). Orphan words i.e., words which have no corresponding material in the DRS (e.g., which at position 16), are added to the graph (node O 1 ) thus ensuring that the position set associated with the graph exactly generates the input sentence.</p><p>Using probabilities over sequences of thematic role sets acquired from the DRS representations of SWKP, the split module determines where and how to split the input DRS. In this case, one split is applied between X 11 (explain) and X 10 (predict). The simpler sentences resulting from the split are then derived from the DRS using the word order information associated with the predicates, duplicating or pronominalising any shared element (e.g., Higgs mechanism in <ref type="figure">Figure 1</ref>) and deleting any Orphan words (e.g., which) which occurs at the split boundary. Splitting thus derives S 2 from S 1 .</p><p>Finally, deletion or sentence compression applies transforming S 2 into S 3 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Context-Aware Lexical Simplification</head><p>We extract context-aware lexical simplification rules from EWKP and SWKP 5 using the approach described by <ref type="bibr" target="#b0">Biran et al. (2011)</ref>. The underlying intuition behind these rules is that the word C from EWKP can be replaced with a word S from SWKP 4 The DRS to graph conversion goes through several preprocessing steps: the relation nn is inverted making modifier noun (higgs) dependent of modified noun (mechanism), named and timex are converted to unary predicates, e.g., named(x, peter) is mapped to peter(x) and timex(x) = 1964 is mapped to 1964(x); and nodes are introduced for orphan words (e.g., which). <ref type="bibr">5</ref> We downloaded the snapshots of English Wikipedia dated 2013-12-31 and of Simple English Wikipedia dated 2014-01-01 available at http://dumps.wikimedia.org.</p><p>if C and S share similar contexts (ten token window) in EWKP and SWKP respectively. Given an input sentence and the set of simplification rules extracted from EWKP and SWKP, we then consider all possible (C, S) substitutions licensed by the extracted rules and we identify the best combination of lexical simplifications using dynamic programming and rule scores which capture the adequacy, in context, of each possible substitution 6 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Sentence Splitting</head><p>A distinguishing feature of our approach is that splitting is based on deep semantic representations rather than phrase structure trees -as in <ref type="bibr" target="#b24">(Zhu et al., 2010;</ref><ref type="bibr" target="#b20">Woodsend and Lapata, 2011</ref>) -or dependency trees -as in <ref type="bibr" target="#b13">(Siddharthan and Mandya, 2014)</ref>.</p><p>While Woodsend and Lapata (2011) report learning 438 splitting rules for their simplification approach operating on phrase structure trees <ref type="bibr" target="#b13">Siddharthan and Mandya (2014)</ref> defines 26 handcrafted rules for simplifying apposition and/or relative clauses in dependency structures and 85 rules to handle subordination and coordination.</p><p>In contrast, we do not need to specify or to learn complex rewrite rules for splitting a complex sentence into several simpler sentences. Instead, we simply learn the probability of sequences of thematic role sets likely to cooccur in a simplified sentence.</p><p>The intuition underlying our approach is that:</p><p>Semantic representations give a clear handle on events, on their associated roles sets and on shared elements thereby facilitating both the identification of possible splitting points and the reconstruction of shared elements in the sentences resulting from a split.</p><p>For instance, the DRS in <ref type="figure">Figure 1</ref> makes clear that sentence (1S 1 ) contains 3 main events and that Higgs mechanism is shared between two propositions.</p><p>To determine whether and where to split the input sentence, we use a probabilistic model trained on the DRSs of the Simple Wikipedia sentences and a language model also trained on Simple Wikipedia. Given the event variables contained in the DRS of the input sentence, we consider all possible splits between subsequences of events and choose the split(s) with maximum split score. For instance, in the sentence shown in <ref type="figure">Figure 1</ref>, there are three event variables X 3 , X 10 and X 11 in the DRS. So we will consider 5 split possibilities namely, no split ({X 3 , X 10 , X 11 }), two splits resulting in three sentences describing an event each ({X 3 }, {X 10 }, {X 11 }) and one split resulting in two sentences describing one and two events respectively (i.e., ({X 3 }, {X 10 , X 11 }), ({X 3 , X 10 }, {X 11 }) and {X 10 }, {X 3 , X 11 }). The split {X 10 }, {X 3 , X 11 } gets the maximum split score and is chosen to split the sentence (1S 1 ) producing the sentences (1S 2 ). <ref type="bibr">Semantic Pattern prob. (agent, patient)</ref> 0.059 <ref type="bibr">(agent, in, in, patient)</ref> 0.002 (agent, patient), <ref type="bibr">(agent, in, in, patient)</ref> 0.023 Formally, the split score P split associated with the splitting of a sentence S into a sequence of sentences s 1 ...s n is defined as:</p><formula xml:id="formula_3">P split = 1 n s i L split L split + | L split ‚àí Ls i | √ó lms i √ó SF Ts i</formula><p>where n is the number of sentences produced after splitting; L split is the average length of the split sentences (L split = L S n where L S is the length of the sentence S); L s i is the length of the sentence s i ; lm s i is the probability of s i given by the language model and SF T s i is the likelihood of the semantic pattern associated with s i . The Split Feature <ref type="table" target="#tab_1">Table (SFT, Table 1</ref>) is derived from the corpus of DRSs associated with the SWKP sentences and the counts of sequences of thematic role sets licenced by the DRSs of SWKP sentences. Intuitively, P split favors splits involving frequent semantic patterns (frequent sequences of thematic role sets) and sub-sentences of roughly equal length. This way of semantic pattern based splitting also avoids over-splitting of a complex sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Phrasal Deletion</head><p>Following Filippova and Strube (2008), we formulate phrase deletion as an optimization problem which is solved using integer linear programming 7 . Given the DRS K associated with a sentence to be simplified, for each relation r ‚àà K, 7 In our implementation, we use lp solve, http://sourceforge.net/projects/lpsolve. the deletion module determines whether r and its associated DRS subgraphs should be deleted by maximising the following objective function:</p><formula xml:id="formula_4">x x r h,w √óP (r|h)√óP (w) r ‚àà {agent, patient, theme, eq}</formula><p>where for each relation r ‚àà K, x r h,w = 1 if r is preserved and x r h,w = 0 otherwise; P (r|h) is the conditional probability (estimated on the DRS corpus derived from SWKP) of r given the head label h; and P (w) is the relative frequency of w in SWKP 8 .</p><p>Intuitively, this objective function will favor obligatory dependencies over optional ones and simple words (i.e., words that are frequent in SWKP). In addition, the objective function is subjected to constraints which ensure (i) that some deletion takes place and (ii) that the resulting DRS is a well-formed graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head><p>We evaluate our approach both globally and by module focusing in particular on the splitting component of our simplification approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Global evaluation</head><p>The testset provided by <ref type="bibr" target="#b24">Zhu et al. (2010)</ref> was used by four supervised systems for automatic evaluation using metrics such as BLEU, sentence length and number of edits. In addition, most recent simplification approaches carry out a human evaluation on a small set of randomly selected complex/simple sentence pairs. Thus <ref type="bibr" target="#b21">Wubben et al. (2012)</ref>, <ref type="bibr" target="#b10">Narayan and Gardent (2014)</ref> and <ref type="bibr" target="#b13">Siddharthan and Mandya (2014)</ref> carry out a human evaluation on 20, 20 and 25 sentences respectively.</p><p>Accordingly, we perform an automatic comparative evaluation using <ref type="bibr" target="#b24">(Zhu et al., 2010)</ref>'s testset namely, an aligned corpus of 100/131 EWKP/SWKP sentences; and we carry out a human-based evaluation. <ref type="bibr">8</ref> To account for modifiers which are represented as predicates on nodes rather than relations, we preprocess the DRSs and transform each of these predicates into a single node subtree of the node it modifies. For example in <ref type="figure">Figure 1</ref>, the node X2 labeled with the modifier predicate second is updated to a new node X ‚Ä≤ 2 dominating a child labeled with that predicate and related to X ‚Ä≤ 2 by a modifier relation.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Automatic</head><p>Evaluation Following <ref type="bibr" target="#b21">Wubben et al. (2012)</ref>, <ref type="bibr" target="#b24">Zhu et al. (2010)</ref> and <ref type="bibr" target="#b20">Woodsend and Lapata (2011)</ref>, we use metrics that are directly related to the simplification task namely, the number of splits in the overall data, the number of output sentences with no edits (i.e., sentences which have not been simplified) and the average Levenshtein distance (LD) between the system output and both the complex and the simple reference sentences. We use BLEU 9 as a means to evaluate how close the systems output are to the reference corpus. <ref type="table" target="#tab_3">Table 2</ref> shows the results of the automatic evaluation. The most noticeable result is that our unsupervised system yields results that are similar to those of the supervised approaches.</p><p>The results also show that, in contrast to Woodsend system which often leaves the input unsimplified (24% of the input), our system almost always modifies the input sentence (only 3% of the input are not simplified); and that the number of simplifications including a split is relatively high (49% of the cases) suggesting a good ability to split complex sentences into simpler ones.</p><p>Human Evaluation Human judges were asked to rate input/output pairs w.r.t. to adequacy (How much does the simplified sentence(s) preserve the 9 Moses support tools: multi-bleu http://www.statmt.org/moses/?n=Moses.SupportTools. meaning of the input?), to simplification (How much does the generated sentence(s) simplify the complex input?) and to fluency (how grammatical and fluent are the sentences?).</p><p>We randomly selected 18 complex sentences from Zhu's test corpus and included in the evaluation corpus: the corresponding simple (Gold) sentence from Zhu's test corpus, the output of our system (UNSUP) and the output of the other four systems <ref type="bibr">(Zhu, Woodsend, Narayan and Wubben)</ref> which were provided to us by the system authors 10 . We collected ratings from 18 participants. All were either native speakers or proficient in English, having taken part in a Master taught in English or lived in an English speaking country for an extended period of time. The evaluation was done online using the LG-Eval toolkit <ref type="bibr" target="#b9">(Kow and Belz, 2012)</ref>  <ref type="bibr">11</ref> and a Latin Square Experimental Design (LSED) was used to ensure a fair distribution of the systems and the data across raters. <ref type="table" target="#tab_7">Table 4</ref> shows the average ratings of the human evaluation on a scale from 0 to 5. Pairwise comparisons between all models and their statistical significance were carried out using a one-way ANOVA with post-hoc Tukey HSD tests.   If we group together systems for which there is no significant difference (significance level: p &lt; 0.05), our system is in the first group together with Narayan and Zhu for simplicity; in the first group for fluency; and in the second group for adequacy (together with <ref type="bibr">Woodsend and Zhu)</ref>. A manual examination of the results indicates that UN-SUP achieves good simplicity rates through both deletion and sentence splitting. Indeed, the average word length of simplified sentences is smaller for UNSUP (26.22) than for <ref type="bibr">Wubben (28.25)</ref> and <ref type="bibr">Woodsend (28.10)</ref>; comparable with <ref type="bibr">Narayan (26.19)</ref> and higher only than <ref type="bibr">Zhu (24.21)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Modular Evaluation</head><p>To assess the relative impact of each module (lexical simplification, deletion and sentence splitting), we also conduct an automated evaluation on each module separately. The results are shown in <ref type="table" target="#tab_4">Table 3</ref>. One first observation is that each module has an impact on simplification. Thus the average Levenshtein Edit distance (LD) to the source clause (complex) is never null for any module while the number of "No edit" indicates that lexical simplification modifies the input sentence in 78%, sentence splitting 49% and deletion 96% of the cases.</p><p>In terms of output quality and in particular, similarity with respect to the target clause, deletion is the most effective (smallest LD, best BLEU score w.r.t. target). Further, the results for average token length indicate that lexical simplification is effec-tive in producing shorter words (smaller average length for this module compared to the other two modules).</p><p>Predictably, combining modules yields systems that have stronger impact on the source clause (higher LD to complex, lower number of No Edits) with the full system (i.e., the system combining the 3 modules) showing the largest LD to the sources (LD to complex) and the smallest number of source sentences without simplification (3 No Edits).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Sentence Splitting Using Deep Semantics</head><p>To compare our sentence splitting approach with existing systems, we collected in a second human evaluation, all the outputs for which at least one system applied sentence splitting. The raters were then asked to compare pairs of split sentences produced by two distinct systems and to evaluate the quality (0:very bad to 5:very good) of these split sentences taking into account boundary choice, sentence completion and sentence reordering. <ref type="table" target="#tab_6">Table 5</ref> shows the results of this second evaluation. For each system pair comparing UNSUP (A) with another system (B), the Table gives the scores and the number of splits of both systems: for the inputs on which both systems split (BOTH-AB), on which only UNSUP splits (ONLY-A) and on which only the compared system split (ONLY-B).</p><p>UNSUP achieves a better average score (ALL-A = 2.37) than all other systems (ALL-B column) except <ref type="bibr">Wubben (2.73)</ref>. However Wubben only achieves one split and on that sentence, UNSUP score is 4.75 while Wubben has a score of 2.73 and produces an incorrect split (cf. S 3 in <ref type="figure">Figure 6</ref>). UNSUP</p><p>In terms of numbers of splits, three systems often simplify by splitting namely Zhu (80 splits), <ref type="bibr">Woodsend (63)</ref> and UNSUP (49).</p><p>Interestingly, Narayan, trained on the parallel corpus of Wikipedia and Simplified Wikipedia splits less of-S1 Complex. This array distributes data across multiple disks, but the array is seen by the computer user and operating system as one single disk. Zhu. This array sells data across multiple disks but the array is seen.  ten (10 splits vs 49 for UNSUP) and less well (2.09 average score versus 2.37 for UNSUP). This is unsurprising as the proportion of splits in SWKP was reported in <ref type="bibr" target="#b10">(Narayan and Gardent, 2014)</ref> to be a low 6%. In contrast, the set of observations we use to learn the splitting probability is the set of all sequences of thematic role sets derived from the DRSs of the SWKP corpus. In sum, the unsupervised, semantic-based splitting strategy allows for a high number (49%) of good quality (2.37 score) sentence splits . Because there are less possible patterns of thematic role sets in simple sentences than possible configurations of parse/dependency trees for complex sentences, it is less prone to data sparsity than the syntax based approach. Because the probabilities learned are not tied to specific syntactic structures but to more abstract semantic patterns, it is also perhaps less sensitive to parse errors. <ref type="table" target="#tab_9">Table 6</ref> shows some examples from the evaluation dataset which were selected to illustrate the workings of our approach and to help interpret the results in <ref type="table" target="#tab_3">Table 2</ref>, 4 and 5. S1 and S2 and S3 show examples of contextaware unsupervised lexical substitutions which are nicely performed by our system. In S1, The array distributes data is correctly simplified to The array moves data whereas Zhu's system incorrectly simplifies this clause to The array sells data. Similarly, in S2, our system correctly simplifies Papers on simulation of artificial selection to Papers on models of selection while the other systems either do not simplify or simplify to Papers on feeling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Examples from the Test Set</head><p>For splitting, the examples show two types of splitting performed by our approach namely, splitting of coordinated sentences (S1) and splitting between a main and a relative clause (S2,S3). S2 illustrates how the Woodsend system over-splits, an issue already noticed in <ref type="bibr" target="#b13">(Siddharthan and Mandya, 2014)</ref>; and how Zhu's system predicts an incorrect split between a verb (seen) and its agent argument (by the user). Barring a parse error, such incorrect splits will not be predicted by our approach since, in our cases, splits only occur between (verbalisations of) events. S1, S2 and S3 also illustrates how our semantic based approach allows for an adequate reconstruction of shared elements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>A major limitation for supervised simplification systems is the limited amount of available paral-lel standard/simplified data. In this paper, we have shown that it is possible to take an unsupervised approach to sentence simplification which requires a large corpus of standard and simplified language but no alignment between the two. This allowed for the implementation of contextually aware substitution module; and for a simple, linguistically principled account of sentence splitting and shared element reconstruction.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table /><note>Split Feature Table (SFT) showing some of the semantic patterns from Figure 1.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Automatic evaluation results. Zhu, Woodsend, Wubben, Narayan are the best output of the models of Zhu et al.</figDesc><table><row><cell cols="9">(2010), Woodsend and Lapata (2011), Wubben et al. (2012) and Narayan and Gardent (2014) respectively. UNSUP is our</cell></row><row><cell>model.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="3">Levenshtein Edit distance</cell><cell></cell><cell cols="2">BLEU Scores</cell><cell>Average</cell><cell>Average</cell></row><row><cell>System</cell><cell>Complex</cell><cell>to</cell><cell cols="2">System to Sim-</cell><cell cols="2">with respect to</cell><cell>sentence</cell><cell>token</cell></row><row><cell></cell><cell cols="2">System LD No edit</cell><cell cols="4">ple LD No edit complex simple</cell><cell>length</cell><cell>length</cell></row><row><cell>complex</cell><cell>0</cell><cell cols="2">100 12.24</cell><cell>3</cell><cell>100</cell><cell>49.85</cell><cell>27.80</cell><cell>4.62</cell></row><row><cell>LexSimpl</cell><cell>2.07</cell><cell cols="2">22 13.00</cell><cell>1</cell><cell>82.05</cell><cell>44.29</cell><cell>27.80</cell><cell>4.46</cell></row><row><cell>Split</cell><cell>2.27</cell><cell cols="2">51 13.62</cell><cell>1</cell><cell>89.70</cell><cell>46.15</cell><cell>29.10</cell><cell>4.63</cell></row><row><cell>Deletion</cell><cell>2.39</cell><cell cols="2">4 12.34</cell><cell>0</cell><cell>85.15</cell><cell>47.33</cell><cell>25.41</cell><cell>4.54</cell></row><row><cell>LexSimpl-Split</cell><cell>4.43</cell><cell cols="2">11 14.39</cell><cell>0</cell><cell>73.20</cell><cell>41.18</cell><cell>29.15</cell><cell>4.48</cell></row><row><cell>LexSimpl-Deletion</cell><cell>4.29</cell><cell cols="2">3 13.09</cell><cell>0</cell><cell>69.84</cell><cell>41.91</cell><cell>25.42</cell><cell>4.38</cell></row><row><cell>Split-Deletion</cell><cell>4.63</cell><cell cols="2">4 13.42</cell><cell>0</cell><cell>77.82</cell><cell>43.44</cell><cell>26.19</cell><cell>4.55</cell></row><row><cell>LexSimpl-Split-Deletion</cell><cell>6.75</cell><cell cols="2">3 14.29</cell><cell>0</cell><cell>63.41</cell><cell>38.47</cell><cell>26.22</cell><cell>4.40</cell></row><row><cell>GOLD (simple)</cell><cell>12.24</cell><cell>3</cell><cell>0</cell><cell>100</cell><cell>49.85</cell><cell>100</cell><cell>23.38</cell><cell>4.40</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table /><note>Automated Metrics for Simplification: Modular evaluation. LexSimpl-Split-Deletion is our final system UNSUP.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Pairwise split evaluation: Each row shows the pairwise comparison of the quality of splits in UNSUP and some other system. Last six columns show the average scores and number of associated split sentences. The second column (ALL-A) and the third column (ALL-B) present the quality of all splits by systems A and B respectively. The fourth column (ONLY-A) represents sentences where A splits but not B. The fifth and sixth columns represents sentences where both A and B split. The seventh column (ONLY-B) represents sentences where B splits but not A.</figDesc><table><row><cell>Systems</cell><cell cols="3">Simplicity Fluency Adequacy</cell></row><row><cell>GOLD</cell><cell>3.62</cell><cell>4.69</cell><cell>3.80</cell></row><row><cell>Zhu</cell><cell>2.62</cell><cell>2.56</cell><cell>2.47</cell></row><row><cell>Woodsend</cell><cell>1.69</cell><cell>3.15</cell><cell>3.15</cell></row><row><cell>Wubben</cell><cell>1.52</cell><cell>3.05</cell><cell>3.38</cell></row><row><cell>Narayan</cell><cell>2.30</cell><cell>3.03</cell><cell>3.35</cell></row><row><cell>UNSUP</cell><cell>2.83</cell><cell>3.56</cell><cell>2.83</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>Average Human Ratings for simplicity, fluency and adequacy.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>The computer user and operating as one disk.[0]   Woodsend. This array distributes data across several disks. The array is seen by the computer user and operating system as one single disk.[4.85]   UNSUP. This array moves data across disks. The array is seen by the computer user and operating system as one disk.[4.83] S2 Complex. Here, simulations of evolution using evolutionary algorithms and artificial life started with the work of Nils Aall Barricelli in the 1960s, and was extended by Alex Fraser, who published a series of papers on simulation of artificial selection. Zhu. Here, simulations of evolution using evolutionary algorithms and artificial life started with the work of nils aall barricelli in the 1960s, and was extended by alex fraser. Alex fraser published a series of papers on feeling of artificial selection. [3.6] Woodsend. It has Genetic algorithms. Evolution is using artificial life. This is Nils Aall Barricelli in the 1960s. Here, simulations started with the work. He was extended by Alex Fraser. He published a group of papers on simulation of artificial selection. [0.33] UNSUP. Here, models of evolution using evolutionary algorithms and artificial life started with the work in the 1960s, and was led by Alex Fraser. Alex Fraser wrote a series of papers on model of selection.[5] S3 Complex. By 1928, the regional government was moved from the old Cossack capital Novocherkassk to Rostov, which also engulfed the nearby Armenian town of Nor Nakhijevan. Zhu. By 1928, the government was moved from the old cossack capital novocherkassk to rostov. Rostov also of the city the nearby armenian town of nor nakhijevan. [2.8] Woodsend. By 1928, the regional government was moved from the old Cossack capital Novocherkassk to Rostov. Both also engulfed the nearby Armenian town of Nor Nakhijevan.[3] Wubben. by 1928 , the regional government was moved from the old cossack capital novocherkassk to rostov. the nearby armenian town of nor nakhichevan. [2.7] Narayan. by 1928, the regional government was moved from the old cossack capital novocherkassk to rostov. rostov that engulfed the nearby armenian town of nor nakhichevan. [2.7] UNSUP. The regional government was moved from the old Cossack capital Novocherkassk to Rostov. Rostov also absorbed the nearby town of Nor Nakhijevan.[4.75]    </figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>Example Outputs for Sentence splitting with their average human annotation scores.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://simple.wikipedia.org 2 http://en.wikipedia.org</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">http://svn.ask.it.usyd.edu.au/trac/candc, Version 1.00</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">For more details on the extraction of lexical simplification rules, we refer the reader to<ref type="bibr" target="#b0">Biran et al. (2011)</ref>. For more details on the application of these rules using dynamic programming, we refer the reader to<ref type="bibr" target="#b11">Narayan (2014)</ref>.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10">We upload the outputs from all the systems as supplementary material with this paper. 11 http://www.nltg.brighton.ac.uk/research/lg-eval/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgements</head><p>We are grateful to Zhemin Zhu, Kristian Woodsend and Sander Wubben for sharing their data. We would like to thank our annotators for participating in our human evaluation experiments and to anonymous reviewers for their insightful comments. This research was supported by an EP-SRC grant (EP/L02411X/1) and an EU H2020 grant (688139/H2020-ICT-2015; SUMMA). We also thank the French National Research Agency for funding the research presented in this paper in the context of the WebNLG project.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Putting it simply: a context-aware approach to lexical simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>References</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Biran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="496" to="501" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Syntactic simplification of Text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yvonne</forename><forename type="middle">Margaret</forename><surname>Canning</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
		<respStmt>
			<orgName>University of Sunderland</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Simplifying text for languageimpaired readers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Carroll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 9th Conference of the European Chapter of the Association for Computational Linguistics (EACL)</title>
		<meeting>9th Conference of the European Chapter of the Association for Computational Linguistics (EACL)</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="1999" />
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="269" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Automatic induction of rules for text simplification. Knowledge-Based Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raman</forename><surname>Chandrasekar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bangalore</forename><surname>Srinivas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="183" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Motivations and methods for text simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Chandrasekar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International conference on Computational linguistics (COLING)</title>
		<editor>Coster and Kauchak2011] William Coster and David Kauchak</editor>
		<meeting>the 16th International conference on Computational linguistics (COLING)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
	<note>Proceedings of the Workshop on Monolingual Text-To-Text Generation</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Linguistically motivated largescale NLP with C&amp;C and Boxer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Curran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL) on Interactive Poster and Demonstration Sessions</title>
		<meeting>the 45th Annual Meeting of the Association for Computational Linguistics (ACL) on Interactive Poster and Demonstration Sessions</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="33" to="36" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Tree adjoining grammar and the reluctant paraphrasing of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth International Natural Language Generation Conference (INLG)</title>
		<editor>Filippova and Strube2008] Katja Filippova and Michael Strube</editor>
		<meeting>the Fifth International Natural Language Generation Conference (INLG)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="25" to="32" />
		</imprint>
		<respStmt>
			<orgName>Macquarie University NSW 2109 Australia</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
	<note>Dependency tree based sentence compression</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A theory of truth and semantic representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><surname>Kamp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Formal methods in the study of language, number pt. 1 in Mathematical Centre tracts. Mathematisch Centrum</title>
		<editor>J.A.G. Groenendijk, T.M.V. Janssen, B.J. Stokhof, and M.J.B. Stokhof</editor>
		<imprint>
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Statistics-based summarization-step one: Sentence compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth National Conference on Artificial Intelligence (AAAI) and Twelfth Conference on Innovative Applications of Artificial Intelligence (IAAI)</title>
		<meeting>the Seventeenth National Conference on Artificial Intelligence (AAAI) and Twelfth Conference on Innovative Applications of Artificial Intelligence (IAAI)</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="703" to="710" />
		</imprint>
	</monogr>
	<note>Knight and Marcu2000</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">LG-Eval: A Toolkit for Creating Online Language Evaluation Experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Kow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anja</forename><surname>Belz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC)</title>
		<meeting>the 8th International Conference on Language Resources and Evaluation (LREC)</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="4033" to="4037" />
		</imprint>
	</monogr>
	<note>Kow and Belz2012</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Hybrid simplification using deep semantics and machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gardent2014] Shashi</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gardent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Generating and Simplifying Sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashi</forename><surname>Narayan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
		<respStmt>
			<orgName>Universit√© de Lorraine</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A survey of automated text simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Shardlow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Advanced Computer Science and Applications (IJACSA), Special Issue on Natural Language Processing</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Hybrid text simplification using synchronous dependency grammars with hand-written and automatically harvested rules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Advaith</forename><surname>Siddharthan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angrosh</forename><surname>Mandya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 14th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Gothenburg, Sweden</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014-04" />
			<biblScope unit="page" from="722" to="731" />
		</imprint>
	</monogr>
	<note>Siddharthan and Mandya2014</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An architecture for a text simplification system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Advaith</forename><surname>Siddharthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Language Engineering Conference (LEC)</title>
		<meeting>the Language Engineering Conference (LEC)</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="64" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Complex lexico-syntactic reformulation of sentences using typed dependency representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Advaith</forename><surname>Siddharthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Natural Language Generation Conference (INLG)</title>
		<meeting>the 6th International Natural Language Generation Conference (INLG)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="125" to="133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Text simplification using typed dependencies: a comparison of the robustness of different generation strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Advaith</forename><surname>Siddharthan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th European Workshop on Natural Language Generation (ENLG)</title>
		<meeting>the 13th European Workshop on Natural Language Generation (ENLG)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Quasi-synchronous grammars: Alignment by soft projection of syntactic dependencies</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the HLT-NAACL Workshop on Statistical Machine Translation</title>
		<editor>David A Smith and Jason Eisner</editor>
		<meeting>the HLT-NAACL Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="23" to="30" />
		</imprint>
	</monogr>
	<note>Smith and Eisner2006</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Sentence simplification for semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vickrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daphne</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics (ACL) and the Human Language Technology Conference (HLT)</title>
		<meeting>the 46th Annual Meeting of the Association for Computational Linguistics (ACL) and the Human Language Technology Conference (HLT)</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="344" to="352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Arnaldo Candido Junior, Vin√≠cius Rodriguez Uz√™da, Renata Pontin de Mattos Fortes, Thiago Alexandre Salgueiro Pardo, and Sandra Maria Alu√≠sio</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Watanabe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM international conference on Design of communication</title>
		<meeting>the 27th ACM international conference on Design of communication</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="29" to="36" />
		</imprint>
	</monogr>
	<note>Facilita: reading assistance for low-literacy readers</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning to simplify sentences with quasi-synchronous grammar and integer programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristian</forename><surname>Woodsend</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="409" to="420" />
		</imprint>
	</monogr>
	<note>Woodsend and Lapata2011. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Sentence simplification by monolingual machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Wubben</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL): Long Papers</title>
		<meeting>the 50th Annual Meeting of the Association for Computational Linguistics (ACL): Long Papers</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1015" to="1024" />
		</imprint>
	</monogr>
	<note>Antal van den Bosch, and Emiel Krahmer</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Optimizing statistical machine translation for text simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A syntax-based statistical translation model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Knight2001] Kenji</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th Annual Meeting on Association for Computational Linguistics (ACL)</title>
		<meeting>the 39th Annual Meeting on Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="523" to="530" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A monolingual tree-based translation model for sentence simplification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics (COLING)</title>
		<meeting>the 23rd International Conference on Computational Linguistics (COLING)<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1353" to="1361" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
