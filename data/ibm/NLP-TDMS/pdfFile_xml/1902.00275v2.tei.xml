<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Flow++: Improving Flow-Based Generative Models with Variational Dequantization and Architecture Design</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><surname>Srinivas</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Duan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
						</author>
						<title level="a" type="main">Flow++: Improving Flow-Based Generative Models with Variational Dequantization and Architecture Design</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T17:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Flow-based generative models are powerful exact likelihood models with efficient sampling and inference. Despite their computational efficiency, flow-based models generally have much worse density modeling performance compared to stateof-the-art autoregressive models. In this paper, we investigate and improve upon three limiting design choices employed by flow-based models in prior work: the use of uniform noise for dequantization, the use of inexpressive affine flows, and the use of purely convolutional conditioning networks in coupling layers. Based on our findings, we propose Flow++, a new flow-based model that is now the state-of-the-art non-autoregressive model for unconditional density estimation on standard image benchmarks. Our work has begun to close the significant performance gap that has so far existed between autoregressive models and flow-based models. Our implementation is available at: https://github.com/ aravindsrinivas/flowpp.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Deep generative models -latent variable models in the form of variational autoencoders <ref type="bibr" target="#b18">(Kingma &amp; Welling, 2013)</ref>, implicit generative models in the form of GANs <ref type="bibr" target="#b9">(Goodfellow et al., 2014)</ref>, and exact likelihood models like Pixel-RNN/CNN (van den , Image Transformer <ref type="bibr" target="#b24">(Parmar et al., 2018)</ref>, PixelSNAIL , NICE, RealNVP, and Glow <ref type="bibr" target="#b6">(Dinh et al., 2014;</ref><ref type="bibr" target="#b17">Kingma &amp; Dhariwal, 2018)</ref>  videos, to audio signals and natural language <ref type="bibr" target="#b16">(Karras et al., 2017;</ref><ref type="bibr" target="#b14">Kalchbrenner et al., 2016b;</ref><ref type="bibr" target="#b33">van den Oord et al., 2016a;</ref><ref type="bibr" target="#b13">Kalchbrenner et al., 2016a;</ref><ref type="bibr" target="#b34">Vaswani et al., 2017)</ref>.</p><p>Autoregressive models, a certain subclass of exact likelihood models, achieve state-of-the-art density estimation performance on many challenging real-world datasets, but generally suffer from slow sampling time due to their autoregressive structure <ref type="bibr" target="#b33">(van den Oord et al., 2016b;</ref><ref type="bibr" target="#b30">Salimans et al., 2017;</ref><ref type="bibr" target="#b3">Chen et al., 2017;</ref><ref type="bibr" target="#b24">Parmar et al., 2018)</ref>. Inverse autoregressive models can sample quickly and potentially have strong modeling capacity, but they cannot be trained efficiently by maximum likelihood . Non-autoregressive flow-based models (which we will refer to as "flow models"), such as NICE, RealNVP, and Glow, are efficient for sampling, but have so far lagged behind autoregressive models in density estimation benchmarks <ref type="bibr" target="#b6">(Dinh et al., 2014;</ref><ref type="bibr" target="#b17">Kingma &amp; Dhariwal, 2018)</ref>.</p><p>In the hope of creating an ideal likelihood-based generative model that simultaneously has fast sampling, fast inference, and strong density estimation performance, we seek to close the density estimation performance gap between flow models and autoregressive models. In subsequent sections, we present our new flow model, Flow++, which is powered by an improved training procedure for continuous likelihood models and a number of architectural extensions of the coupling layer defined by <ref type="bibr" target="#b6">Dinh et al. (2014;</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Flow Models</head><p>A flow model f is constructed as an invertible transformation that maps observed data x to a standard Gaussian latent variable z = f (x), as in nonlinear independent component analysis <ref type="bibr" target="#b1">(Bell &amp; Sejnowski, 1995;</ref><ref type="bibr" target="#b12">Hyvärinen et al., 2004;</ref><ref type="bibr" target="#b11">Hyvärinen &amp; Pajunen, 1999)</ref>. The key idea in the design of a flow model is to form f by stacking individual simple invertible transformations <ref type="bibr" target="#b6">(Dinh et al., 2014;</ref><ref type="bibr" target="#b17">Kingma &amp; Dhariwal, 2018;</ref><ref type="bibr" target="#b27">Rezende &amp; Mohamed, 2015;</ref><ref type="bibr" target="#b19">Kingma et al., 2016;</ref><ref type="bibr" target="#b21">Louizos &amp; Welling, 2017)</ref>. Explicitly, f is constructed by composing a series of invertible flows as f (x) = f 1 • · · · • f L (x), with each f i having a tractable inverse and a tractable Jacobian determinant. This way, sampling is efficient, as it can be performed by computing arXiv:1902.00275v2 <ref type="bibr">[cs.</ref>LG] 15 May 2019</p><formula xml:id="formula_0">f −1 (z) = f −1 L • · · · • f −1 1 (z)</formula><p>for z ∼ N (0, I), and so is training by maximum likelihood, since the model density</p><formula xml:id="formula_1">log p(x) = log N (f (x); 0, I) + L i=1 log det ∂f i ∂f i−1 (1)</formula><p>is easy to compute and differentiate with respect to the parameters of the flows f i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Flow++</head><p>In this section, we describe three modeling inefficiencies in prior work on flow models: (1) uniform noise is a suboptimal dequantization choice that hurts both training loss and generalization;</p><p>(2) commonly used affine coupling flows are not expressive enough;</p><p>(3) convolutional layers in the conditioning networks of coupling layers are not powerful enough. Our proposed model, Flow++, consists of a set of improved design choices: (1) variational flow-based dequantization instead of uniform dequantization;</p><p>(2) logistic mixture CDF coupling flows;</p><p>(3) self-attention in the conditioning networks of coupling layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Dequantization via variational inference</head><p>Many real-world datasets, such as CIFAR10 and ImageNet, are recordings of continuous signals quantized into discrete representations. Fitting a continuous density model to discrete data, however, will produce a degenerate solution that places all probability mass on discrete datapoints <ref type="bibr" target="#b32">(Uria et al., 2013)</ref>. A common solution to this problem is to first convert the discrete data distribution into a continuous distribution via a process called "dequantization," and then model the resulting continuous distribution using the continuous density model <ref type="bibr" target="#b32">(Uria et al., 2013;</ref><ref type="bibr" target="#b7">Dinh et al., 2016;</ref><ref type="bibr" target="#b30">Salimans et al., 2017)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1.">UNIFORM DEQUANTIZATION</head><p>Dequantization is usually performed in prior work by adding uniform noise to the discrete data over the width of each discrete bin: if each of the D components of the discrete data x takes on values in {0, 1, 2, . . . , 255}, then the dequantized data is given by y = x+u, where u is drawn uniformly from [0, 1) D . <ref type="bibr" target="#b31">Theis et al. (2015)</ref> note that training a continuous density model p model on uniformly dequantized data y can be interpreted as maximizing a lower bound on the loglikelihood for a certain discrete model P model on the original discrete data x:</p><formula xml:id="formula_2">P model (x) := [0,1) D p model (x + u) du<label>(2)</label></formula><p>The argument of <ref type="bibr" target="#b31">Theis et al. (2015)</ref> proceeds as follows.</p><p>Letting P data denote the original distribution of discrete data and p data denote the distribution of uniformly dequantized data, Jensen's inequality implies that</p><formula xml:id="formula_3">E y∼p data [log p model (y)] (3) = x P data (x) [0,1) D log p model (x + u) du (4) ≤ x P data (x) log [0,1) D p model (x + u) du (5) = E x∼P data [log P model (x)]<label>(6)</label></formula><p>Consequently, maximizing the log-likelihood of the continuous model on uniformly dequantized data cannot lead to the continuous model degenerately collapsing onto the discrete data, because its objective is bounded above by the log-likelihood of a discrete model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">VARIATIONAL DEQUANTIZATION</head><p>While uniform dequantization successfully prevents the continuous density model p model from collapsing to a degenerate mixture of point masses on discrete data, it asks p model to assign uniform density to unit hypercubes x + [0, 1) D around the data x. It is difficult and unnatural for smooth function approximators, such as neural network density models, to excel at such a task. To sidestep this issue, we now introduce a new dequantization technique based on variational inference.</p><p>Again, we are interested in modeling D-dimensional discrete data x ∼ P data using a continuous density model p model , and we will do so by maximizing the loglikelihood of its associated discrete model P model (x) := [0,1) D p model (x + u) du. Now, however, we introduce a dequantization noise distribution q(u|x), with support over u ∈ [0, 1) D . Treating q as an approximate posterior, we have the following variational lower bound, which holds for all q:</p><formula xml:id="formula_4">E x∼P data [log P model (x)] (7) = E x∼P data log [0,1) D q(u|x) p model (x + u) q(u|x) du (8) ≥ E x∼P data [0,1) D q(u|x) log p model (x + u) q(u|x) du (9) = E x∼P data E u∼q(·|x) log p model (x + u) q(u|x)<label>(10)</label></formula><p>We will choose q itself to be a conditional flow-based generative model of the form u = q x ( ), where ∼ p( ) = N ( ; 0, I) is Gaussian noise. In this case, q(u|x) = p(q −1 x (u)) · ∂q −1 x /∂u , and thus we obtain the objective</p><formula xml:id="formula_5">E x∼P data [log P model (x)] (11) ≥ E x∼P data , ∼p log p model (x + q x ( )) p( ) |∂q x /∂ | −1<label>(12)</label></formula><p>which we maximize jointly over p model and q. When p model is also a flow model x = f −1 (z) (as it is throughout this paper), it is straightforward to calculate a stochastic gradient of this objective using the pathwise derivative estimator, as f (x + q x ( )) is differentiable with respect to the parameters of f and q.</p><p>Notice that the lower bound for uniform dequantizationeqs. <ref type="formula">(4)</ref> to <ref type="formula" target="#formula_3">(6)</ref> -is a special case of our variational lower bound -eqs. <ref type="formula">(8)</ref> to <ref type="formula" target="#formula_4">(10)</ref>, when the dequantization distribution q is a uniform distribution that ignores dependence on x. Because the gap between our objective (10) and the true</p><formula xml:id="formula_6">expected log-likelihood E x∼P data [log P model (x)] is exactly E x∼P data [D KL (q(u|x) p model (u|x))]</formula><p>, using a uniform q forces p model to unnaturally place uniform density over each hypercube x+[0, 1) D to compensate for any potential looseness in the variational bound introduced by the inexpressive q. Using an expressive flow-based q, on the other hand, allows p model to place density in each hypercube x + [0, 1) D according to a much more flexible distribution q(u|x). This is a more natural task for p model to perform, improving both training and generalization loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Improved coupling layers</head><p>Recent progress in the design of flow models has involved carefully constructing flows to increase their expressiveness while preserving tractability of the inverse and Jacobian determinant computations. One example is the invertible 1 × 1 convolution flow, whose inverse and Jacobian determinant can be calculated and differentiated with standard automatic differentiation libraries <ref type="bibr" target="#b17">(Kingma &amp; Dhariwal, 2018</ref>). Another example, which we build upon in our work here, is the affine coupling layer <ref type="bibr" target="#b7">(Dinh et al., 2016)</ref>. It is a parameterized flow y = f θ (x) that first splits the components of x into two parts x 1 , x 2 , and then computes y = (y 1 , y 2 ), given by</p><formula xml:id="formula_7">y 1 = x 1 , y 2 = x 2 · exp(a θ (x 1 )) + b θ (x 1 ) (13)</formula><p>Here, a θ and b θ are outputs of a neural network that acts on x 1 in a complex, expressive manner, but the resulting behavior on x 2 always remains an elementwise affine transformation -effectively, a θ and b θ together form a dataparameterized family of invertible affine transformations. This allows the affine coupling layer to express complex dependencies on the data while keeping inversion and loglikelihood computation tractable. Using · and exp to respectively denote elementwise multiplication and exponentia-tion, the affine coupling layer is defined by:</p><formula xml:id="formula_8">x 1 = y 1 , (14) x 2 = (y 2 − b θ (y 1 )) · exp(−a θ (y 1 )),<label>(15)</label></formula><formula xml:id="formula_9">log ∂y ∂x = 1 a θ (x 1 )<label>(16)</label></formula><p>The splitting operation x → (x 1 , x 2 ) and merging operation (y 1 , y 2 ) → y are usually performed over channels or over space in a checkerboard-like pattern <ref type="bibr" target="#b7">(Dinh et al., 2016)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">EXPRESSIVE COUPLING TRANSFORMATIONS WITH CONTINUOUS MIXTURE CDFS</head><p>We found in our experiments that density modeling performance of these coupling layers could be improved by augmenting the data-parameterized elementwise affine transformations by more general nonlinear elementwise transformations. For a given scalar component x of x 2 , we apply the cumulative distribution function (CDF) for a mixture of K logistics -parameterized by mixture probabilities, means, and log scales π, µ, s -followed by an inverse sigmoid and an affine transformation parameterized by a and b:</p><formula xml:id="formula_10">x −→ σ −1 (MixLogCDF(x; π, µ, s)) · exp(a) + b (17) where MixLogCDF(x; π, µ, s) := K i=1 π i σ ((x − µ i ) · exp(−s i ))<label>(18)</label></formula><p>The transformation parameters π, µ, s, a, b for each component of x 2 are produced by a neural network acting on x 1 . This neural network must produce these transformation parameters for each component of x 2 , hence it produces vectors a θ (x 1 ) and b θ (x 1 ) and tensors π θ (x 1 ), µ θ (x 1 ), s θ (x 1 ) (with last axis dimension K). The coupling transformation is then given by:</p><formula xml:id="formula_11">y 1 = x 1 ,<label>(19)</label></formula><formula xml:id="formula_12">y 2 = σ −1 (MixLogCDF(x 2 ; π θ (x 1 ), µ θ (x 1 ), s θ (x 1 ))) · exp(a θ (x 1 )) + b θ (x 1 )<label>(20)</label></formula><p>where the formula for computing y 2 operates elementwise.</p><p>The inverse sigmoid ensures that the inverse of this coupling transformation always exists: the range of the logistic mixture CDF is (0, 1), so the domain of its inverse must stay within this interval. The CDF itself can be inverted efficiently with bisection, because it is a monotonically increasing function. Moreover, the Jacobian determinant of this transformation involves calculating the probability density function of the logistic mixtures, which poses no computational difficulty.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">EXPRESSIVE CONDITIONING ARCHITECTURES WITH SELF-ATTENTION</head><p>In addition to improving the expressiveness of the elementwise transformations on x 2 , we found it crucial to improve the expressiveness of the conditioning on x 1 -that is, the expressiveness of the neural network responsible for producing the elementwise transformation parameters π, µ, s, a, b.</p><p>Our best results were obtained by stacking convolutions and multi-head self attention into a gated residual network <ref type="bibr" target="#b22">(Mishra et al., 2018;</ref><ref type="bibr" target="#b3">Chen et al., 2017)</ref>, in a manner resembling the Transformer <ref type="bibr" target="#b34">(Vaswani et al., 2017)</ref> with pointwise feedforward layers replaced by 3 × 3 convolutional layers. Our architecture is defined as a stack of blocks. Each block consists of the following two layers connected in a residual fashion, with layer normalization <ref type="bibr" target="#b0">(Ba et al., 2016)</ref> after each residual connection:</p><formula xml:id="formula_13">Conv = Input → Nonlinearity → Conv 3×3 → Nonlinearity → Gate Attn = Input → Conv 1×1 → MultiHeadSelfAttention → Gate</formula><p>where Gate refers to a 1 × 1 convolution that doubles the number of channels, followed by a gated linear unit <ref type="bibr" target="#b4">(Dauphin et al., 2016)</ref>. The convolutional layer is identical to the one used by PixelCNN++ <ref type="bibr" target="#b30">(Salimans et al., 2017)</ref>, and the multi-head self attention mechanism we use is identical to the one in the Transformer <ref type="bibr" target="#b34">(Vaswani et al., 2017)</ref>. (We always use 4 heads in our experiments, since we found it to be effective early on in our experimentation process.)</p><p>With these blocks in hand, the network that outputs the elementwise transformation parameters is simply given by stacking blocks on top of each other, and finishing with a final convolution that increases the number of channels to the amount needed to specify the elementwise transformation parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>Here, we show that Flow++ achieves state-of-the-art density modeling performance among non-autoregressive models on CIFAR10 and 32x32 and 64x64 ImageNet. We also present ablation experiments that quantify the improvements proposed in section 3, and we present example generative samples from Flow++ and compare them against samples from autoregressive models.</p><p>Our experiments employed weight normalization and datadependent initialization . We used the checkerboard-splitting, channel-splitting, and downsampling flows of <ref type="bibr" target="#b7">Dinh et al. (2016)</ref>; we also used before every coupling flow an invertible 1x1 convolution flows of <ref type="bibr" target="#b17">Kingma &amp; Dhariwal (2018)</ref>, as well as a variant of their "actnorm" flow that normalizes all activations independently (instead of normalizing per channel). Our CIFAR10 model used 4 coupling layers with checkerboard splits at 32x32 resolution, 2 coupling layers with channel splits at 16x16 resolution, and 3 coupling layers with checkerboard splits at 16x16 resolution; each coupling layer used 10 convolutionattention blocks, all with 96 filters. More details on architectures, as well as details for the other experiments, are in our source code release.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Density modeling results</head><p>In table 1, we show that Flow++ achieves state-of-the-art density modeling results out of all non-autoregressive models, and it is competitive with autoregressive models: its performance is on par with the first generation of PixelCNN models (van den Oord et al., 2016b), and it outperforms Multiscale PixelCNN <ref type="bibr" target="#b26">(Reed et al., 2017)</ref>. Our results are reported using 16384 importance samples in our CIFAR experiment and 1 sample in our ImageNet experiments <ref type="bibr" target="#b2">(Burda et al., 2015)</ref>. With 1 sample only, our CIFAR model attains 3.12 bits/dim. Our listed ImageNet 32x32 and 64x64 results are evaluated on a NVIDIA DGX-1; they are worse by 0.01 bits/dim when evaluated on a NVIDIA Titan X GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Ablations</head><p>We ran the following ablations of our model on unconditional CIFAR10 density estimation: variational dequantization vs. uniform dequantization; logistic mixture coupling vs. affine coupling; and stacked self-attention vs. convolutions only. As each ablation involves removing some component of the network, we increased the number of filters in all convolutional layers (and attention layers, if present) in order to match the total number of parameters with the full Flow++ model.</p><p>In <ref type="figure" target="#fig_0">fig. 1 and table 2</ref>, we compare the performance of these ablations relative to Flow++ at 400 epochs of training, which was not enough for these models to converge, but far enough to see their relative performance differences. Switching from our variational dequantization to the more standard uniform dequantization costs the most: approximately 0.127 bits/dim. The remaining two ablations both cost approximately 0.03 bits/dim: switching from our logistic mixture coupling layers to affine coupling layers, and switching from our hybrid convolution-and-self-attention architecture to a pure convolutional residual architecture. Note that these performance differences are present despite all networks having approximately the same number of parameters: the improved performance of Flow++ comes from improved inductive biases, not simply from increased parameter count.</p><p>The most interesting result is probably the effect of the dequantization scheme on training and generalization loss. At 400 epochs of training, the full Flow++ model with variational dequantization has a train-test gap of approximately Non-autoregressive RealNVP <ref type="bibr" target="#b7">(Dinh et al., 2016)</ref> 3.49 4.28 -Glow <ref type="bibr" target="#b17">(Kingma &amp; Dhariwal, 2018)</ref> 3.35 4.09 3.81 IAF-VAE  3.11 --Flow++ (ours) 3.08 3.86 3.69</p><p>Autoregressive Multiscale PixelCNN <ref type="bibr" target="#b26">(Reed et al., 2017</ref><ref type="bibr">) -3.95 3.70 PixelCNN (van den Oord et al., 2016b</ref> 3.14 --PixelRNN (van den  3.00 3.86 3.63 Gated PixelCNN <ref type="bibr" target="#b33">(van den Oord et al., 2016c)</ref> 3.03 3.83 3.57 PixelCNN++ <ref type="bibr" target="#b30">(Salimans et al., 2017)</ref> 2.92 --Image Transformer <ref type="bibr" target="#b24">(Parmar et al., 2018)</ref> 2.90 3.77 -PixelSNAIL  2.85 3.80 3.52  <ref type="bibr" target="#b25">(Ramachandran et al., 2017)</ref>. More samples are available in the supplementary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Related Work</head><p>Likelihood-based models constitute a large family of deep generative models. One subclass of such methods, based on variational inference, allows for efficient approximate  inference and sampling, but does not admit exact log likelihood computation <ref type="bibr" target="#b18">(Kingma &amp; Welling, 2013;</ref><ref type="bibr" target="#b28">Rezende et al., 2014;</ref><ref type="bibr" target="#b19">Kingma et al., 2016)</ref>. Another subclass, which we called exact likelihood models in this work, does admit exact log likelihood computation. These exact likelihood models are typically specified as invertible transformations that are parameterized by neural networks <ref type="bibr" target="#b5">(Deco &amp; Brauer, 1995;</ref><ref type="bibr" target="#b20">Larochelle &amp; Murray, 2011;</ref><ref type="bibr" target="#b32">Uria et al., 2013;</ref><ref type="bibr" target="#b6">Dinh et al., 2014;</ref><ref type="bibr" target="#b8">Germain et al., 2015;</ref><ref type="bibr" target="#b33">van den Oord et al., 2016b;</ref><ref type="bibr" target="#b30">Salimans et al., 2017;</ref><ref type="bibr" target="#b3">Chen et al., 2017)</ref>.</p><p>There is prior work that aims to improve the sampling speed of deep autoregressive models. The Multiscale PixelCNN <ref type="bibr" target="#b26">(Reed et al., 2017)</ref> modifies the PixelCNN to be non-fullyexpressive by introducing conditional independence assumptions among pixels in a way that permits sampling in a logarithmic number of steps, rather than linear. Such a change in the autoregressive structure allows for faster sampling but  also makes some statistical patterns impossible to capture, and hence reduces the capacity of the model for density estimation. WaveRNN <ref type="bibr" target="#b15">(Kalchbrenner et al., 2018)</ref> improves sampling speed for autoregressive models for audio via sparsity and other engineering considerations, some of which may apply to flow models as well.</p><p>There is also recent work that aims to improve the expressiveness of coupling layers in flow models. <ref type="bibr" target="#b17">Kingma &amp; Dhariwal (2018)</ref> demonstrate improved density estimation using an invertible 1x1 convolution flow, and demonstrate that very large flow models can be trained to produce photorealistic faces. <ref type="bibr" target="#b10">Huang et al. (2018)</ref> show how to design elementwise transformations which themselves are neural networks. <ref type="bibr" target="#b23">Müller et al. (2018)</ref> introduce piecewise polynomial couplings that are similar in spirit to our mixture of logistics couplings and found them to be more expressive than affine couplings, but reported little performance gains in density estimation. We leave a detailed comparison between our coupling layer and these other types of coupling layers for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>We presented Flow++, a new flow-based generative model that begins to close the performance gap between flow models and autoregressive models. Our work considers specific instantiations of design principles for flow models -dequantization, flow design, and conditioning architecture designand we hope these principles will help guide future research in flow models and likelihood-based models in general.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Ablation training (light) and validation (dark) curves on unconditional CIFAR10 density estimation. These runs are not fully converged, but the gap in performance is already visible.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>CIFAR 10 Samples. Left: samples from van den Oord et al. (2016b). Right: samples from Flow++, which captures local dependencies well and generates good samples at the quality level of PixelCNN, but with the advantage of efficient sampling.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>32x32 ImageNet Samples. Left: samples from van den. Right: samples from Flow++. Note that diversity of samples from Flow++ matches the diversity of samples from an autoregressive model on this dataset, which is much larger than CIFAR10.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Samples from Flow++ trained on 5-bit 64x64 CelebA, without low-temperature sampling.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>-have recently begun to successfully model high dimensional raw observations from complex real-world datasets, from natural images and Equal contribution 1 UC Berkeley, Department of Electrical Engineering and Computer Science 2 covariant.ai. Correspondence to: Jonathan Ho &lt;jonathanho@berkeley.edu&gt;, Aravind Srinivas &lt;aravind srinivas@berkeley.edu&gt;. Proceedings of the 36 th International Conference on Machine Learning, Long Beach, California, PMLR 97, 2019. Copyright 2019 by the author(s).</figDesc><table /><note>*</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Unconditional image modeling results in bits/dim</figDesc><table><row><cell>Model family</cell><cell>Model</cell><cell>CIFAR10 ImageNet 32x32 ImageNet 64x64</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>CIFAR10 ablation results after 400 epochs of training. Models not converged for the purposes of ablation study.</figDesc><table><row><cell>Ablation</cell><cell cols="2">bits/dim parameters</cell></row><row><cell>uniform dequantization</cell><cell>3.292</cell><cell>32.3M</cell></row><row><cell>affine coupling</cell><cell>3.200</cell><cell>32.0M</cell></row><row><cell>no self-attention</cell><cell>3.193</cell><cell>31.4M</cell></row><row><cell>Flow++ (not converged for ablation)</cell><cell>3.165</cell><cell>31.4M</cell></row><row><cell cols="3">0.02 bits/dim, but with uniform dequantization, the train-test</cell></row><row><cell cols="3">gap is approximately 0.06 bits/dim. This confirms our claim</cell></row><row><cell cols="3">in Section 3.1.2 that training with variational dequantiza-</cell></row><row><cell cols="3">tion is a more natural task for the model than training with</cell></row><row><cell>uniform dequantization.</cell><cell></cell><cell></cell></row><row><cell>4.3. Samples</cell><cell></cell><cell></cell></row><row><cell cols="3">We present the samples from our trained density models of</cell></row><row><cell cols="3">Flow++ on CIFAR10, 32x32 ImageNet, 64x64 ImageNet,</cell></row><row><cell cols="3">and 5-bit CelebA in figs. 2 to 5. The Flow++ samples match</cell></row><row><cell cols="3">the perceptual quality of PixelCNN samples, showing that</cell></row><row><cell cols="3">Flow++ captures both local and global dependencies as well</cell></row><row><cell cols="3">as PixelCNN and is capable of generating diverse samples</cell></row><row><cell cols="3">on large datasets. Moreover, sampling is fast: our CIFAR10</cell></row><row><cell cols="3">model takes approximately 0.32 seconds to generate a batch</cell></row><row><cell cols="3">of 8 samples in parallel on one NVIDIA 1080 Ti GPU,</cell></row><row><cell cols="3">making it more than an order of magnitude faster than Pixel-</cell></row><row><cell cols="2">CNN++ with sampling speed optimizations</cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank Evan Lohn for discovering that our ImageNet models attain slightly different performance on different GPU hardware. This work was funded in part by ONR PECASE N000141612723, Huawei, Amazon AWS, and Google Cloud.  </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.06450</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">E. Layer normalization. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An informationmaximization approach to blind separation and blind deconvolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Sejnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1129" to="1159" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1509.00519</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">Importance weighted autoencoders. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohaninejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pixelsnail</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.09763</idno>
		<title level="m">An improved autoregressive generative model</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Language modeling with gated convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Grangier</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.08083</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Higher order statistical decorrelation without information loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Deco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Brauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="247" to="254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nice</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.8516</idno>
		<title level="m">Non-linear independent components estimation</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Density estimation using Real NVP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.08803</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Made</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03509</idno>
		<title level="m">Masked autoencoder for distribution estimation</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Neural autoregressive flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lacoste</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2083" to="2092" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Nonlinear independent component analysis: Existence and uniqueness results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hyvärinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pajunen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="429" to="439" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hyvärinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Karhunen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Oja</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>John Wiley &amp; Sons</publisher>
			<biblScope unit="volume">46</biblScope>
		</imprint>
	</monogr>
	<note>Independent component analysis</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Espheholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.00527</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>eural machine translation in linear time</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.00527</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Elsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Noury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Casagrande</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lockhart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Stimberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.08435</idno>
		<title level="m">Efficient neural audio synthesis</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Progressive growing of gans for improved quality, stability, and variation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lehtinen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10196</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Glow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.03039</idno>
		<title level="m">Generative flow with invertible 1x1 convolutions</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Auto-encoding variational Bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd International Conference on Learning Representations</title>
		<meeting>the 2nd International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.04934</idno>
		<title level="m">Improving variational inference with inverse autoregressive flow</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">The Neural Autoregressive Distribution Estimator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Murray</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>AISTATS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Louizos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.01961</idno>
		<title level="m">Multiplicative normalizing flows for variational bayesian neural networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A simple neural attentive meta-learner</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohaninejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mcwilliams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Rousselle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Novák</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.03856</idno>
		<title level="m">Neural importance sampling</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ł</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ku</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1802.05751</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">A. Image transformer. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ramachandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Paine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Khorrami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Babaeizadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Hasegawa-Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.06001</idno>
		<title level="m">Fast generation for convolutional autoregressive models</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Parallel multiscale autoregressive density estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gómez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Belov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 34th International Conference on Machine Learning</title>
		<meeting>The 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Variational inference with normalizing flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 32nd International Conference on Machine Learning</title>
		<meeting>The 32nd International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1530" to="1538" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Stochastic backpropagation and approximate inference in deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Machine Learning (ICML-14)</title>
		<meeting>the 31st International Conference on Machine Learning (ICML-14)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1278" to="1286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Weight normalization: A simple reparameterization to accelerate training of deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.07868</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pixelcnn++</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.05517</idno>
		<title level="m">Improving the pixelcnn with discretized logistic mixture likelihood and other modifications</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">A note on the evaluation of generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bethge</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.01844</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The realvalued neural autoregressive density-estimator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Uria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rnade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2175" to="2183" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wavenet ; Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.03499</idno>
		<idno>arXiv:1606.05328</idno>
		<title level="m">Pixel recurrent neural networks. International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Conditional image generation with pixelcnn decoders</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.03762</idno>
		<title level="m">Attention is all you need</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
