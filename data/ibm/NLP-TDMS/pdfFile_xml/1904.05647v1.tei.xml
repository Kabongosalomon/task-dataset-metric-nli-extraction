<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">C-MIL: Continuation Multiple Instance Learning for Weakly Supervised Object Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wan</forename><forename type="middle">†</forename><surname>Fang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Ke</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Ji</surname></persName>
							<email>xyji@tsinghua.edu.cn</email>
							<affiliation key="aff1">
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbin</forename><surname>Jiao</surname></persName>
							<email>jiaojb@ucas.ac.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixiang</forename><surname>Ye</surname></persName>
							<email>qxye@ucas.ac.cn</email>
							<affiliation key="aff2">
								<orgName type="laboratory">Peng Cheng Laboratory</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">C-MIL: Continuation Multiple Instance Learning for Weakly Supervised Object Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T05:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Weakly supervised object detection (WSOD) is a challenging task when provided with image category supervision but required to simultaneously learn object locations and object detectors. Many WSOD approaches adopt multiple instance learning (MIL) and have non-convex loss functions which are prone to get stuck into local minima (falsely localize object parts) while missing full object extent during training. In this paper, we introduce a continuation optimization method into MIL and thereby creating continuation multiple instance learning (C-MIL), with the intention of alleviating the non-convexity problem in a systematic way. We partition instances into spatially related and class related subsets, and approximate the original loss function with a series of smoothed loss functions defined within the subsets. Optimizing smoothed loss functions prevents the training procedure falling prematurely into local minima and facilitates the discovery of Stable Semantic Extremal Regions (SSERs) which indicate full object extent. On the PASCAL VOC 2007 and 2012 datasets, C-MIL improves the state-of-the-art of weakly supervised object detection and weakly supervised object localization with large margins 1 .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Weakly supervised object detection (WSOD) is rapidly gaining attention in computer vision area. WSOD approaches only require image category annotations indicating the presence or absence of a category of objects in images, significantly reducing human involvement by omitting labor-intensive bounding-box annotations <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref><ref type="bibr" target="#b39">40]</ref>.</p><p>Despite extensive research over the past five years, WSOD remains an open problem, as indicated by the large performance gap (∼ 20%) between WSOD <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b37">38]</ref> and fully supervised detection approaches <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b29">30]</ref> on the PAS-CAL VOC detection benchmark <ref type="bibr" target="#b24">[25]</ref>.</p><p>Combined with deep neural networks, MIL has been the main WSOD method <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b33">34]</ref>. However, it is observed that the model is prone to activate object parts instead of full object extent, particularly during the early learning epochs, <ref type="figure" target="#fig_0">Fig. 1(a)</ref>. This phenomenon arises from non-convexity of the objective/loss functions. Optimizing such functions can get stuck into local minima, i.e., selecting most discriminative regions (instances) for image classification while ignoring full object extent <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b36">37]</ref>.</p><p>Researchers have alleviated this problem by using spatial regularization <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b36">37]</ref>, context information <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b37">38]</ref>, and progressive refinement <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b39">40]</ref>. Despite their advances, the local minimum problem remains unsolved from an optimization perspective.</p><p>In this paper, we introduce the continuation method <ref type="bibr" target="#b1">[2]</ref>, which addresses a complex optimization problem by smoothing the loss function and turning it into multiple easier sub-problems, into multiple instance learning and thereby creating continuation multiple instance learning (C-MIL), with the purpose of alleviating the non-convexity problem in a systematic manner. C-MIL treats images as bags and image regions generated by an object proposal method <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b31">32]</ref> as instances. During training, unlike the conventional MIL that pursues the most discriminative instances, C-MIL learns instance subsets, where the instances are spatially related, i.e., overlapping with each other, and class related, i.e., having similar object class scores. Instance subsets with proper continuation parameters are capable of collecting object parts to fine-tune the network, and activate Stable Semantic Extremal Regions (SSERs) indicating full object extent, <ref type="figure" target="#fig_0">Fig. 1(b)</ref>. Instance subsets are partitioned according to continuation parameters. With the smallest parameter, an image is partitioned into a single subset which contains all instances while the loss function of C-MIL is equal to that of image classification which is convex. With the largest parameter, each instance is defined as a subset, and the loss function degenerates to that of MIL. During training, the continuation parameter gradually dwindles the subset from the maximum set (with all instances) to the minimum sets (with a single instance). In this way, we construct a series of functions which are easier to optimize to approximate the original loss function, <ref type="figure" target="#fig_0">Fig. 1(b)</ref>. With end-to-end training, the most discriminative subset in each image is discovered, and subsets/instances which lack discriminative information are suppressed.</p><p>The contributions of this paper include: (1) A novel C-MIL approach which uses a series of smoothed loss functions to approximate the original loss function, alleviating the non-convexity problem in multiple instance learning.</p><p>(2) A parametric strategy for instance subset partition, which is combined with a deep neural network to activate full object extent.</p><p>(3) New state-of-the-art performance of weakly supervised detection and localization on commonly used object detection benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>For many branches of WSOD methods, <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b39">40]</ref>, we mainly review MIL-based approaches. We also review the continuation optimization and smoothing methods for the non-convex optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Weakly Supervised Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MIL.</head><p>As the major line of WSOD method, MIL treats each training image as a "bag" and iteratively selects highscored instances from each bag when learning detectors. It works in a similar way to the Expectation-Maximization algorithm estimating instances and detectors simultaneously. Nevertheless, such an algorithm is frequently puzzled by local minima caused by non-convex loss functions, particularly, when the solution space is large <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b36">37]</ref>.</p><p>To alleviate the non-convexity problem, clustering was used as a pre-processing step to facilitate instance selection considering that a class of instances often shape a single compact cluster <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b27">28]</ref>. A bag splitting strategy was proposed to reduce the solution space during the optimization procedure of MILinear <ref type="bibr" target="#b38">[39]</ref>. The multi-fold MIL <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref> with training set partition and cross validation was proposed to realize multi-start point optimization.</p><p>MIL Networks. MIL has been updated to MIL networks <ref type="bibr" target="#b7">[8]</ref>, where convolutional filters behave as detectors which activate regions of interest on the feature maps. However, loss functions of MIL networks remain non-convex and thus suffer from local minima. To alleviate this problem, researchers introduced spatial regularization <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b36">37]</ref>, context information <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b37">38]</ref>, and progressive optimization <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b39">40]</ref> into the MIL networks.</p><p>In <ref type="bibr" target="#b13">[14]</ref>, object segmentation was used as the regulariser and optimized with instance selection in two learning stages within cascaded convolutional networks. In <ref type="bibr" target="#b36">[37]</ref>, a cliquebased min-entropy model was proposed as the regularizer to alleviate localization randomness during learning instances. In <ref type="bibr" target="#b15">[16]</ref>, the per-class object count was leveraged to address failure cases about one detected box containing multiple in-stances. In <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b37">38]</ref>, context models were designed to learn instances while being both supported by and standing out from surrounding regions.</p><p>Existing methods often use high-quality regions (instances) as pseudo ground-truth to progressively refine the classifier <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b36">37]</ref>. In <ref type="bibr" target="#b33">[34]</ref>, an online instance classifier refinement algorithm was integrated with the MIL network. In <ref type="bibr" target="#b36">[37]</ref>, a recurrent learning algorithm was proposed to integrate image classification with object detection, and then to progressively optimize the classifiers and detectors.</p><p>Existing strategies using spatial regularization, context information, and progressive refinement are effective at improving WSOD. Nevertheless, there still lacks a principled and systematic way to alleviate the local minimum problem from the perspective of optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Non-convex optimization</head><p>Continuation methods. Continuation methods <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b30">31]</ref> address a complex optimization problem by smoothing the loss function, turning it into multiple sub-problems which are easier to optimize. By tuning continuation parameters, it incorporates a sequence of sub-problems which converge to the optimization problem of interest. These methods have been successful in tackling optimization problems involving non-convex loss functions with multiple local minima. In machine learning, curriculum learning <ref type="bibr" target="#b4">[5]</ref> was inspired by this principle to define a sequence of gradually increasing difficulty training tasks (or training distributions) which converge to the task of interest. Gradient-based optimization over a sequence of mollified loss functions has been shown converging to stronger global minima <ref type="bibr" target="#b9">[10]</ref>.</p><p>Smoothing.</p><p>Smoothing is an important technique in optimization <ref type="bibr" target="#b3">[4]</ref> and has been applied in deep neural networks. In <ref type="bibr" target="#b40">[41]</ref> and <ref type="bibr" target="#b12">[13]</ref>, a method which modified the non-smooth ReLU activation to improve training was proposed. In <ref type="bibr" target="#b19">[20]</ref>, "mollifiers" were introduced to smooth the loss function by gradually increasing the difficulty of the optimization problem. In <ref type="bibr" target="#b8">[9]</ref>, entropy was added to the loss function to promote solutions by reducing randomness.</p><p>In this study, we implement continuation optimization by specifying a series of smoothed loss functions for a MIL network over spatially related and class related instance subsets, and target at alleviating the local minimum problem and learning full object extent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head><p>C-MIL treats images as bags and image regions generated by an object proposal method <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b31">32]</ref> as instances. The goal is to train instance classifiers (detectors) while solely the bag labels are available. In <ref type="figure">Fig. 2</ref>, B i ∈ B denotes the i th bag (image) and B denotes all bags (training images). y i ∈ Y where Y = {1, −1} denotes the label of bag B i indicating the bag contains positive instances (i.e., objects with positive class) or not. y i = 1 indicates a positive bag (image) that contains at least one positive instance, while y i = −1 indicates a negative bag where all instances are negative. Let B i,j and y i,j denote instances and instance labels in bag B i , where j ∈ {1, 2, ..., N } and N the number of instances. w denotes network parameters to be learned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">MIL Revisit</head><p>With above definitions, an MIL method <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b32">33]</ref> can be separated into two alternative steps: instance selection and detector estimation. In the instance selection step, an instance selector f (B i,j , w f ), which computes the object score of each instance, is used to mine a positive instance (object) from B i .</p><formula xml:id="formula_0">B i,j * = arg max j f (B i,j , w f ) ,<label>(1)</label></formula><p>where w f indicates the parameters of the instance selector and j * the index of the selected instance of the highest score. With selected instances, a detector g z (B ij , w g ) with parameter w g is trained, where z ∈ Y. w f and w g respectively denote parameters for the instance selector and detector.</p><p>In MIL networks <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b33">34]</ref>, the two alternative steps are integrated and f (B i,j , w f ) and g z (B i,j , w g ) are jointly optimized with loss functions on training images B, as</p><formula xml:id="formula_1">F(B, w) = i F f (B i , w f ) + F g (B i , B i,j * , w g ), (2)</formula><p>where the first term, loss of instance selection, is defined as</p><formula xml:id="formula_2">F f (B i , w f ) = max(0, 1 − y i max j f (B i,j , w f )), (3)</formula><p>which is the standard hinge loss. The second term, loss of detector estimation, is defined as</p><formula xml:id="formula_3">F g (B i , B i,j * , w g ) = − z j δ z,yi,j log g z (B i,j , w g ),<label>(4)</label></formula><p>where y i,j is defined following the VOC metric <ref type="bibr" target="#b24">[25]</ref> as</p><formula xml:id="formula_4">y i,j = +1, if IoU (B i,j , B i,j * ) ≥ 0.5 −1, if IoU (B i,j , B i,j * ) &lt; 0.5 .<label>(5)</label></formula><p>δ a,b is the Kronecker function which is defined as: δ a,b = 1 if a = b, and 0 otherwise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Convexity Analysis</head><p>Recall that the maximum of a set of convex functions is convex. When y i = −1, Eq. 3 is convex, but when y i = 1, it is non-convex. The loss function (Eq. 2) of the MIL network is therefore non-convex as its first term (Eq. 3) is non-convex, and it may have many local minima when provided with bags of numerous instances. Once false positives are mined by the instance selector, the detector  <ref type="figure">Figure 2</ref>: Comparison of the instance selection strategies of MIL and C-MIL. MIL tends to select the most discriminative instance and activate the object part. In contrast, C-MIL selects the most discriminative instance subset. The instances in the subset are activated equally during back-propagation and thus the object extent is activated. (Best viewed in color) will be misled by them, particularly in the early training epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bag of instances</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bag of instances</head><p>With above analysis, it is concluded that the following two problems remain to be elaborated: 1) How to optimize the non-convex function, and 2) How to perform instance selection in the early training stages when the instance selector is not well trained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Continuation MIL</head><p>We propose a new optimization method, called Continuation Multiple Instance Learning (C-MIL), and target at solving the above two problems. Instead of introducing regularizers into the loss functions, we directly focus on them from an optimization perspective, by partitioning instances in a bag into subsets and manipulating the non-convexity or smoothness of the loss function defined by Eq. 3.</p><p>C-MIL roots in the traditional continuation method <ref type="bibr" target="#b1">[2]</ref>, tracing a series of implicitly defined smoothed loss functions from a start point (w 0 , 0) to a solution point (w * , 1), <ref type="figure" target="#fig_0">Fig. 1(b)</ref>, where w 0 is the solution of F (B, w, λ) when λ = 0, and w * the solution when λ = 1. Accordingly, we define a series of λ, 0 = λ 0 &lt; λ 1 &lt; ... &lt; λ T = 1, and update Eq. 2 to a continuation loss function, as</p><formula xml:id="formula_5">w * = arg min w F (B, w, λ) = arg min w f ,wg i F f Bi, B i,J(λ) , w f + Fg Bi, B i,J(λ) , wg ,<label>(6)</label></formula><p>where B i,J(λ) denotes the instance subset and J(λ) the index of B i,J(λ) , determined by parameter λ. 1) Construct an instance subset using the instance of highest object score while not belonging to any other instance subset. 2) Find the instances whose overlap with the highest scored instance B i,j * are larger than or equal to λ, and then merge them into the subset.</p><p>When λ = 0, bag B i is partitioned into a single subset which include all instances. When λ = 1, a bag B i is partitioned into multiple subsets, each of which contains a single instance. The continuation of instance selection is performed from λ = 0 to λ = 1 with the loss function defined as</p><formula xml:id="formula_6">F f Bi, B i,J(λ) , w f = max(0, 1 − yi max J(λ) f (B i,J(λ) , w f )),<label>(7)</label></formula><p>where f B i,J(λ) , w f , the score of instance subset B i,J(λ) , is defined as</p><formula xml:id="formula_7">f B i,J(λ) , w f = 1 B i,J(λ) j f (B i,j , w f ),<label>(8)</label></formula><p>where |B i,J(λ) | denotes the number of instances in subset B i,J(λ) and B i,j ∈ B i,J(λ) .</p><p>During model learning, C-MIL equally utilizes all instances in subset B i,J(λ) to fine-tune the network parameters. As the instances are spatially overlapped and class related, C-MIL can collect object/parts for object extent activation, <ref type="figure">Fig. 2</ref>. When λ = 0, each bag B i has a single subset that includes all instances. It is equal to change the term max j f (B i,j , w f ) of Eq. 3 to j f (B i,j , w f ) and then Eq. 7 becomes convex. When λ = 1, a bag B i is partitioned into multiple subsets, each of which contains a single in-  <ref type="figure">Figure 3</ref>: The modules of continuation instance selection and continuation detector estimation are implemented atop a deep network for weakly supervised object detection. C is the number of object categories. In the feed-forward procedure, C-MIL selects positive instances from subsets and uses them as pseudo-objects for detector estimation. In back-propagation, the instance selector and object detectors are jointly optimized with an SGD algorithm.</p><p>stance and thus Eq. 7 deteriorates to the original loss function, Eq. 3. For 0 &lt; λ &lt; 1, each bag B i has multiple subsets. According to Eq. 8, the score of an instance subset is equal to the average score of instances within that subset. The loss function Eq. 7 is therefore smoother than Eq. 3, and then the loss function of CMIL defined by Eq. 6, is smoother than that of MIL defined by Eq. 2. In other words, a series of smoothed loss functions are defined to alleviate the non-convexity problem of Eq. 3 and discover better solutions <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b30">31]</ref>, <ref type="figure" target="#fig_0">Fig. 1(b)</ref>. Continuation detector estimation. During model learning, the subset B i,J(λ) of highest average score is selected for detector estimation. Considering that there is no bounding box annotation available, the instance selector is inaccurate and the selected subset might contain object parts or backgrounds. We further propose using a continuation strategy to estimate reliable instances and learn detectors.</p><p>We propose to partition instances into positives and negatives with the continuation parameter λ. Denote the learned instance subset as B i,J(λ) * and the instance of highest score in B i,J(λ) * as B i,j * . Instances in the bag are partitioned into positives or negatives according to their spatial relations, as</p><formula xml:id="formula_8">y i,j = +1, if IoU (B i,j , B i,j * ) ≥ 1 − λ/2 −1, if IoU (B i,j , B i,j * ) &lt; λ/2 ,<label>(9)</label></formula><p>where IoU calculates the Intersection of Union of two instances (bounding boxes). Eq. 9 defines that instances whose IoU with B i,j * greater than the threshold 1 − λ/2 are positives. Instances whose IoU with B i,j * less than λ/2 are negatives. Instances whose IoU with B i,j * falling into [λ/2, 1 − λ/2] are ignored. During the learning procedure, along with the continuation parameter λ changing from 0 to 1, the threshold 1−λ/2 decreases from 1 to 0.5 and the threshold λ/2 increases from 0 to 0.5. According to Eq. 9, more and more instances are estimated as positives or negatives. Based on these instances, the detector g z (B i,j , w g ) is gradually estimated using the loss function defined as</p><formula xml:id="formula_9">F g B i , B i,J(λ) , w g = − z j δ z,yij log g z (B i,j , w g ).<label>(10)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Implementation</head><p>C-MIL is implemented with an end-to-end deep neural network, with the continuation instance selection and continuation object estimation modules added atop of the FC layers, <ref type="figure">Fig. 3</ref>. In the training phrase, multiple instances, corresponding to region proposals, are first generated for each image using Selective Search method <ref type="bibr" target="#b31">[32]</ref>. An ROIpooling layer atop CONV5 and two fully connected layers are used for instance feature extraction. In the feedforward procedure, C-MIL selects positive instances from subsets and uses them as pseudo-objects for detector estimation. In back-propagation, the instance selector and object detectors are jointly optimized with an SGD algorithm. With forward-and back-propagation procedures, network parameters are updated and the instance selector and object detectors are learned.</p><p>The detection procedure involves instance feature extraction and instance classification <ref type="figure">Fig. 3</ref>. The learned detector computes object scores for all instances and Non-Maximum Suppression (NMS) is used to remove the overlapping instances. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>C-MIL was evaluated on the PASCAL VOC 2007 and PASCAL VOC 2012 datasets using mean average precision (mAP) <ref type="bibr" target="#b24">[25]</ref> and correct localization (CorLoc) metrics <ref type="bibr" target="#b35">[36]</ref>, where Cor-Loc is the percentage of images for which the region of highest score has at least 0.5 interaction-over-union (IoU) with the ground-truth object region. In what follows, we first introduced the experimental settings, then analyzed the effect of the functions defined for the continuation parameter. The Stable Semantic Extremal Regions (SSERs) which appeared during the training procedure of C-MIL were also discussed. Finally, we reported the performance of C-MIL on WSOD and compared it with the state-of-theart methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental Settings</head><p>C-MIL was implemented based on the VGGF and VGG16 CNN model <ref type="bibr" target="#b22">[23]</ref> pre-trained on the ILSVRC 2012 dataset <ref type="bibr" target="#b0">[1]</ref>. We used Selective Search <ref type="bibr" target="#b31">[32]</ref> to extract 2000 object proposals as instances for each image, and removed those whose width or height was less than 20 pixels.</p><p>The input images were re-sized into 5 scales {480, 576, 688, 864, 1200} with respect to the larger side (height or width). The scale of a training image was randomly selected and the image was randomly horizontal flipped. In this way, each test image was augmented into a total of 10 images <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b33">34]</ref>. During learning, we employed the SGD algorithm with momentum 0.9, weight decay 5e-4, and batch size 1. The model iterated 20 epochs where the learning rate was 5e-3 for the first 10 epochs and 5e-4 for the last 10 epochs. During testing, the output scores of each instance from the 10 augmented images were averaged.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Continuation Method</head><p>In this section, we investigated how to control the continuation parameter λ and evaluated the effect on instance selection and detector estimation. All experiments are conducted on VOC 2007 benchmark.</p><p>Continuation parameter λ. To control the change   rate of parameter λ during training, five functions were evaluated, <ref type="figure" target="#fig_4">Fig. 4</ref>, and the results are shown in <ref type="table" target="#tab_0">Table 1</ref>.</p><p>With continuation optimization the detection and localization performance respectively improved by 1.1%∼4.7% and 1.4%∼4.5%. <ref type="table" target="#tab_0">Table 1</ref> shows that the "Log" function reported the best performance. With a "Log" function λ increased quickly in the early training epochs while changed slowly in the late epochs, <ref type="figure" target="#fig_4">Fig. 4</ref>. This is consistent with the learning procedure: in the early training epochs, the instance subsets were large, and it required to dwindle them towards the positive instances; in the later epochs, the instance subsets tended to be stable and it required to focus on detector estimation.</p><p>Continuation optimization. <ref type="table" target="#tab_1">Table 2</ref> shows the ablation experimental results of continuation instance selection and continuation detector estimation. Compared with the baseline approach, introducing the continuation instance selection improved the performance by 3.0% (39.0% vs. 36.0%); introducing the continuation of object estimation further improved the performance by 1.4% (37.4% vs. 36.0%). Combining two modules aggregated the performance 4.7% (40.7% vs. 36.0%), which clearly indicated the effectiveness of continuation optimization designed for C-MIL. In <ref type="figure" target="#fig_5">Fig. 5</ref>, we visualized the evolution of the image classification and object localization during training. MIL achieved higher classification performance than C-MIL in the early training epochs. In the later epochs, the classification performance of C-MIL caught up with that of MIL and the localization performance kept higher than that of MIL. The reason lies in that MIL mainly optimized image classification without considering object localization. Therefore, it tended to discover regions which were discriminative for image classification but missed the object location. In contrast, C-MIL optimized both image classification and object localization by learning instance subsets, where object proposals are spatially related and class related.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Stable Semantic Extremal Regions</head><p>To understand the continuation optimization, we visualized the learned subsets/instances in different training epochs in <ref type="figure" target="#fig_6">Fig. 6</ref>. It can be seen that the instance subsets (activated regions) gradually dwindle with the increase of λ from 0 to 1. In the early learning epochs, large subsets were defined to collect object/parts as many as possible. In the later learning epochs, the instance subsets stopped dwindling and tended to form stable activation regions around object boundaries. Such regions, referred to as Stable Semantic Extremal Region (SSERs), often turn out to be full object extent.</p><p>The emergence of SSERs indicated that C-MIL continuously suppressed backgrounds while activating object regions during learning. The procedure is somewhat similar to the process of extracting Maximally Stable Extremal Regions (MSERs) <ref type="bibr" target="#b25">[26]</ref>. The difference lies in that the MSERs are defined for grey-level stable regions and extracted in an unsupervised manner while SSERs are defined for semantic stable regions and learned in a weakly supervised manner. <ref type="table" target="#tab_2">Table 3</ref> shows the performance of C-MIL and a comparison with the state-of-the-art methods on the PASCAL VOC 2007 dataset. It can be seen that C-MIL respectively achieved 40.7% and 50.5% with the VGGF and VGG16 models. With VGGF, C-MIL respectively outperformed the WCCN <ref type="bibr" target="#b13">[14]</ref>, OICR <ref type="bibr" target="#b33">[34]</ref>, and MELM [37] by 3.4% (40.7% vs. 37.3%), 2.8% (40.7% vs. 37.9%) and 2.3% (40.7% vs. 38.4%). With VGG16, it respectively outperformed the WeakRPN <ref type="bibr" target="#b34">[35]</ref>, TS 2 C <ref type="bibr" target="#b37">[38]</ref>, and MELM [37] by 6.2% (50.5% vs. 44.3%), 5.2% (50.5% vs. 45.3%), and 3.2% (50.5% vs. 47.3%), which were large margins in terms of the challenging WSOD task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Performance</head><p>We further re-trained an Fast-RCNN detector using the learned pseudo objects as ground-truth, and achieved 53.1% mAP, as shown in <ref type="table" target="#tab_2">Table 3</ref>, which outperformed the stateof-the-art methods by 2.7%∼6.1%. Specifically, the detection performance for "aeroplane" (+3.2%), "bird" (+5.8%),   "cat" (+3.5%), "train" (+4.5%) significantly improved. <ref type="table" target="#tab_4">Table 4</ref> shows the detection results of the proposed C-MIL and the state-of-the-art methods on the PASCAL VOC 2012 dataset with VGG16. For detection, C-MIL respectively outperformed the WeakRPN <ref type="bibr" target="#b34">[35]</ref>, TS 2 C <ref type="bibr" target="#b37">[38]</ref>, and MELM [37] by 5.9% (46.7% vs. 40.8%), 6.7% (46.7% vs. 40.0%), and 4.3% (46.7% vs. 42.4%).</p><formula xml:id="formula_10">TS 2 C [38] - - - - - - - - - - - - - - - - - - - - 48.</formula><p>We evaluated object localization performance of C-MIL and compared it with the state-of-the-art methods in <ref type="table" target="#tab_4">Table 4</ref> and <ref type="table" target="#tab_5">Table 5</ref>. The used Correct Localization (CorLoc) metric <ref type="bibr" target="#b35">[36]</ref> is the percentage of images for which the region of highest object score has at least 0.5 interaction-over-union (IoU) with the ground-truth. It can be seen that C-MIL respectively outperformed the WeakRPN <ref type="bibr" target="#b34">[35]</ref> and TS 2 C [38] by 1.2% (65.0% vs. 63.8%) and 4.0% (65.0% vs. 61.0%) on VOC 2007, and 3.0% (67.4% vs. 64.4%) and 2.5% (67.4% vs. 64.9%) on VOC 2012.  <ref type="bibr" target="#b13">[14]</ref> 56.7 OICR <ref type="bibr" target="#b33">[34]</ref> 60.6 TS 2 C <ref type="bibr" target="#b37">[38]</ref> 61.0 WeakRPN <ref type="bibr" target="#b34">[35]</ref> 63.8 C-MIL (Ours) 65.0</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We proposed an elegant and effective method, referred to as C-MIL, for weakly supervised object detection. C-MIL targets alleviating the non-convexity problem of multiple instance learning using a series of smoothed loss functions. These functions were defined by introducing a parametric strategy for instance subset partition and evaluating the training loss according to these subsets in a deep learning framework. C-MIL significantly improved performance of weakly supervised object detection and weakly supervised object localization, in striking contrast with state-ofthe-art approaches. The underlying reality is that the continuation optimization combined the deep feature learning first collects object/object parts to activate true object extent and then discovers Stable Semantic Extremal Regions (SSERs) for object localization. This provides a fresh insight for the weakly supervised object detection problem.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Comparison of MIL-based and C-MIL-based WSOD approaches. Due to the non-convex loss function MIL often falls into local minima and falsely localizes an object part. By introducing the continuation optimization with a series of smoothed loss functions, C-MIL alleviates the non-convexity problem and localizes full object extent. (Best viewed in color)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>F f B i , B i,J(λ), w f is the continuation loss function for instance selection, and F g B i , B i,J(λ) , , w g continuation loss function for detector estimation.Continuation instance selection. When learning the instance selector, a bag is partitioned into instance subsets,Fig. 2. In each subset object proposals are spatially related, i.e., overlapping with each other, and class related, i.e., having similar object class scores. The subsets are minimum sufficient cover to a bag (image) B i , i.e., ∪ J B i,J = B i and B i,J ∩B i,J = ∅ for ∀J = J . All instances in a bag are sorted by their object scores f (B i,j , w f ) and the following two steps are iteratively performed:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Five functions defined to control the change of continuation parameter.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Evolution of image classification and object localization performance during training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Stable Semantic Extremal Regions (SSERs). MIL activated the discriminative regions for image classification but missed full object extent. C-MIL discovered SSERs indicating full object extent. The continuation parameter λ of C-MIL increased from 0 to 1 along with the training procedure from epoch 0 to epoch 20. Yellow boxes and green boxes in the last column denote ground-truths and localization results, respectively. (Best viewed in color)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Comparison of five functions controlling the change of continuation parameter λ. Detection and localization performance (%) on the VOC 2007 dataset with VGGF.</figDesc><table><row><cell>Method</cell><cell>Approaches / Continuation Functions</cell><cell>mAP</cell><cell>CorLoc</cell></row><row><cell>MIL</cell><cell>ContextNet [22]</cell><cell>36.0</cell><cell>55.0</cell></row><row><cell></cell><cell>Linear</cell><cell>37.9</cell><cell>58.9</cell></row><row><cell></cell><cell>Piecewise Linear</cell><cell>37.6</cell><cell>57.4</cell></row><row><cell>C-MIL (Ours)</cell><cell>Sigmoid</cell><cell>38.3</cell><cell>58.4</cell></row><row><cell></cell><cell>Exp</cell><cell>37.1</cell><cell>56.4</cell></row><row><cell></cell><cell>Log</cell><cell>40.7</cell><cell>59.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Ablation experimental results of C-MIL. Detection performance (%) on the VOC 2007 dataset with VGGF.</figDesc><table><row><cell>Method</cell><cell>Instance Selector</cell><cell>Object Detector</cell><cell>mAP</cell></row><row><cell>MIL [22]</cell><cell>-</cell><cell>-</cell><cell>36.0</cell></row><row><cell></cell><cell></cell><cell></cell><cell>39.0</cell></row><row><cell>C-MIL (Ours)</cell><cell></cell><cell></cell><cell>37.4</cell></row><row><cell></cell><cell></cell><cell></cell><cell>40.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Detection performance (%) on the VOC 2007 test set. Comparison of C-MIL to the state-of-the-arts. Method aero bike bird boat bottle bus car cat chair cow table dog horse mbike person plant sheep sofa train tv mAP 33.6 30.8 19.9 13.0 40.5 54.3 37.4 14.8 39.8 9.4 28.8 38.1 49.8 14.5 24.0 27.1 12.1 42.3 39.7 31.0 LCL+Context [11] 48.9 42.3 26.1 11.3 11.9 41.3 40.9 34.7 10.8 34.7 18.8 34.4 35.4 52.7 19.1 17.4 35.9 33.3 34.8 46.5 31.6 WSDDN [8] 42.9 56.0 32.0 17.6 10.2 61.8 50.2 29.0 3.8 36.2 18.5 31.1 45.8 54.5 10.2 15.4 36.3 45.2 50.1 43.8 34.5 ContextNet [22] 57.1 52.0 31.5 7.6 11.5 55.0 53.1 34.1 1.7 33.1 49.2 42.0 47.3 56.6 15.3 12.8 24.8 48.9 44.4 47.8 36.3 WCCN [14] 43.9 57.6 34.9 21.3 14.7 64.7 52.8 34.2 6.5 41.2 20.5 33.8 47.6 56.8 12.7 18.8 39.6 46.9 52.</figDesc><table><row><cell>Network</cell><cell></cell></row><row><cell>PDA [15]</cell><cell>49.7</cell></row><row><cell>VGGF/</cell><cell></cell></row><row><cell>AlexNet</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Ens. [35] 63.0 69.7 40.8 11.6 27.7 70.5 74.1 58.5 10.0 66.7 60.6 34.7 75.7 70.3 25.7 26.5 55.4 56.4 55.5 54.9 50.4 C-MIL (Ours) 61.8 60.9 56.2 28.9 18.9 68.2 69.6 71.4 18.5 64.3 57.2 66.9 65.9 65.7 13.8 22.9 54.1 61.9 68.2 66.1 53.1</figDesc><table><row><cell></cell><cell>0</cell></row><row><cell>Re-train</cell><cell>WeakRPN-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Detection and localization performance (%) on the VOC 2012 dataset using VGG16. Comparison of C-MIL to the state-of-the-arts.</figDesc><table><row><cell>Method</cell><cell>mAP</cell><cell>CorLoc</cell></row><row><cell>WCCN [14]</cell><cell>37.9</cell><cell>-</cell></row><row><cell>Self-Taught [21]</cell><cell>38.3</cell><cell>58.8</cell></row><row><cell>OICR [34]</cell><cell>37.9</cell><cell>62.1</cell></row><row><cell>TS 2 C [38]</cell><cell>40.0</cell><cell>64.4</cell></row><row><cell>WeakRPN [35]</cell><cell>40.8</cell><cell>64.9</cell></row><row><cell>MELM [37]</cell><cell>42.4</cell><cell>-</cell></row><row><cell>C-MIL (Ours)</cell><cell>46.7</cell><cell>67.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Localization performance (%) on the VOC 2007 trainval set. Comparison of C-MIL to the state-of-the-arts.</figDesc><table><row><cell>CNN</cell><cell>Method</cell><cell>mAP</cell></row><row><cell></cell><cell>WSDDN [8]</cell><cell>53.5</cell></row><row><cell></cell><cell>WCCN</cell><cell></cell></row><row><cell>VGG16</cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments. The authors are very grateful to the support by NSFC grant 61836012, 61771447, and 61671427, and Beijing Municipal Science and Technology Commission grant Z181100008918014.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krizhevsky</forename><surname>Alex</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sutskever</forename><surname>Ilya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinton</forename><surname>Geoffrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Adv. in Neural Inf. Process. Syst. (NIPS)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Numerical Continuation Methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><forename type="middle">L</forename><surname>Allgower</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Georg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Numerical continuation methods. an introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Eugene L Allgower</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Georg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hettich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Jahresbericht der Deutschen Mathematiker Vereinigung</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="26" to="26" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Smoothing and first order methods: A unified framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Teboulle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Optimization</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="557" to="580" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Ronan Collobert, and Jason Weston. Curriculum learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jérôme</forename><surname>Louradour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 26st Int. Conf. Mach. Learn. (ICML)</title>
		<meeting>26st Int. Conf. Mach. Learn. (ICML)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Weakly supervised object detection with posterior regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hakan</forename><surname>Bilen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Pedersoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinne</forename><surname>Tuytelaars</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Brit. Mach. Vis. Conf. (BMVC)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1997" to="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Weakly supervised object detection with convex clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hakan</forename><surname>Bilen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Pedersoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinne</forename><surname>Tuytelaars</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis. Pattern Recognit. (CVPR)</title>
		<meeting>IEEE Int. Conf. Comput. Vis. Pattern Recognit. (CVPR)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1081" to="1089" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Weakly supervised deep detection networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hakan</forename><surname>Bilen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis. Pattern Recognit. (CVPR)</title>
		<meeting>IEEE Int. Conf. Comput. Vis. Pattern Recognit. (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2846" to="2854" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Entropy-sgd: Biasing gradient descent into wide valleys</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pratik</forename><surname>Chaudhari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Choromanska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlo</forename><surname>Baldassi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Borgs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Chayes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Levent</forename><surname>Sagun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Riccardo</forename><surname>Zecchina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Learn. Repres</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Smoothing methods for nonsmooth, nonconvex minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mathematical programming</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">134</biblScope>
			<biblScope unit="page" from="71" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Large-scale weakly supervised object localization via latent category learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Chong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huang</forename><surname>Kaiqi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ren</forename><surname>Weiqiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhang</forename><surname>Junge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maybank</forename><surname>Steve</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1371" to="1385" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Weakly supervised object localization with latent category learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Chong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ren</forename><surname>Weiqiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huang</forename><surname>Kaiqi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tan</forename><surname>Tieniu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Europ. Conf. Comput. Vis. (ECCV)</title>
		<meeting>Europ. Conf. Comput. Vis. (ECCV)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="431" to="445" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Fast and accurate deep network learning by exponential linear units (elus)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Djork-Arné</forename><surname>Clevert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.07289</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Weakly supervised cascaded convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Diba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vivek</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Pazandeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamed</forename><surname>Pirsiavash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis. Pattern Recognit. (CVPR)</title>
		<meeting>IEEE Int. Conf. Comput. Vis. Pattern Recognit. (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5131" to="5139" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Weakly supervised object localization with progressive domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Bin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Yali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><forename type="middle">Ming</forename><surname>Shengjin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hsuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis. Pattern Recognit. (CVPR)</title>
		<meeting>IEEE Int. Conf. Comput. Vis. Pattern Recognit. (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3512" to="3520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">C-wsl: Count-guided weakly supervised localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingfei</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruichi</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Vlad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry S</forename><surname>Morariu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Davis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Fast r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis. Pattern Recognit. (CVPR)</title>
		<meeting>IEEE Int. Conf. Comput. Vis. Pattern Recognit. (CVPR)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1440" to="1448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multi-fold mil training for weakly supervised object lcalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Verbeek</forename><surname>Cinbis Ramazan Gokberk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Schmid</forename><surname>Jakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cordelia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis. Pattern Recognit. Workshop</title>
		<meeting>IEEE Int. Conf. Comput. Vis. Pattern Recognit. Workshop</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2409" to="2416" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Weakly supervised object localization with multifold multiple instance learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Verbeek</forename><surname>Cinbis Ramazan Gokberk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Schmid</forename><surname>Jakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cordelia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="189" to="203" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Mollifying networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Moczulski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Visin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Learn. Repres</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep self-taught learning for weakly supervised object localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zequn</forename><surname>Jie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojie</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis. Pattern Recognit. (CVPR)</title>
		<meeting>IEEE Int. Conf. Comput. Vis. Pattern Recognit. (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4294" to="4302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Contextlocnet: Context-aware deep network models for weakly supervised localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vadim</forename><surname>Kantorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxime</forename><surname>Oquab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minsu</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Laptev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Europ. Conf. Comput. Vis. (ECCV)</title>
		<meeting>Europ. Conf. Comput. Vis. (ECCV)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="350" to="365" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simonyan</forename><surname>Karen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zisserman</forename><surname>Andrew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Edge boxes: Locating object proposals from edges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dollr</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Piotr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Europ. Conf. Comput. Vis. (ECCV)</title>
		<meeting>Europ. Conf. Comput. Vis. (ECCV)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="391" to="405" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The pascal visual object classes (voc) challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Everingham</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Williams</forename><surname>Van Gool Luc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Winn</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zisserman</forename><surname>Andrew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="303" to="338" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Robust wide-baseline stereo from maximally stable extremal regions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiri</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Chum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Urban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomás</forename><surname>Pajdla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and vision computing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="761" to="767" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Weakly supervised discovery of visual pattern configurations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lee</forename><forename type="middle">Yong</forename><surname>Song Hyun Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jegelka</forename><surname>Jae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darrell</forename><surname>Stefanie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Trevor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Adv. in Neural Inf. Process. Syst. (NIPS)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1637" to="1645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">On learning to localize objects with minimal supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Girshick</forename><surname>Song Hyun Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jegelka</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mairal</forename><surname>Stefanie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harchaoui</forename><surname>Julien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darrell</forename><surname>Zaid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Trevor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 31st Int. Conf. Mach. Learn. (ICML)</title>
		<meeting>31st Int. Conf. Mach. Learn. (ICML)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1611" to="1619" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Weakly supervised object detector learning with model drift detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siva</forename><surname>Parthipan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis. (ICCV)</title>
		<meeting>IEEE Int. Conf. Comput. Vis. (ICCV)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="343" to="350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Adv. in Neural Inf. Process. Syst. (NIPS)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Continuation methods: Theory and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">A</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Decarlo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Sys. Man and Cyber</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="459" to="464" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Selective search for object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uijlings</forename><surname>Jasper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Van De Sande Koen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gevers</forename><surname>Theo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Smeulders</forename><surname>Arnold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="154" to="171" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Support vector machines for multiple-instance learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrews</forename><surname>Stuart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsochantaridis</forename><surname>Ioannis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hofmann</forename><surname>Thomas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Adv. in Neural Inf. Process. Syst. (NIPS)</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="561" to="568" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Multiple instance detection network with online instance classifier refinement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis. Pattern Recognit. (CVPR)</title>
		<meeting>IEEE Int. Conf. Comput. Vis. Pattern Recognit. (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3059" to="3067" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Weakly supervised region proposal network and object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angtian</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongluan</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junzhou</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Europ. Conf. Comput. Vis. (ECCV)</title>
		<meeting>Europ. Conf. Comput. Vis. (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="352" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Weakly supervised localization and learning with generic knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deselaers</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexe</forename><surname>Bogdan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferrari</forename><surname>Vittorio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="275" to="293" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Min-entropy latent model for weakly supervised object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fang</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengxu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbin</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenjun</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixiang</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis. Pattern Recognit. (CVPR)</title>
		<meeting>IEEE Int. Conf. Comput. Vis. Pattern Recognit. (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1297" to="1306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Ts2c:tight box mining with surrounding segmentation context for weakly supervised object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honghui</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Europ. Conf. Comput. Vis. (ECCV)</title>
		<meeting>Europ. Conf. Comput. Vis. (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="434" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Weakly supervised large scale object localization with multiple instance learning and bag splitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ren</forename><surname>Weiqiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huang</forename><surname>Kaiqi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Dacheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tan</forename><surname>Tieniu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="405" to="416" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Self-learning scene-specific pedestrian detectors using a progressive latent model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixiang</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianliang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baochang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillermo</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comput. Vis. Pattern Recognit. (CVPR)</title>
		<meeting>IEEE Int. Conf. Comput. Vis. Pattern Recognit. (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2057" to="2066" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Improving deep neural networks using softplus units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanlei</forename><surname>Hao Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenju</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jizhong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanpeng</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Joint Conf. Neural Networks (IJCNN)</title>
		<meeting>IEEE Int. Joint Conf. Neural Networks (IJCNN)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
