<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multi-Granularity Representations of Dialog</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-08-26">26 Aug 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shikib</forename><surname>Mehri</surname></persName>
							<email>amehri@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Language Technologies Institute</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxine</forename><surname>Eskenazi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Language Technologies Institute</orgName>
								<orgName type="institution" key="instit2">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Multi-Granularity Representations of Dialog</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-08-26">26 Aug 2019</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Neural models of dialog rely on generalized latent representations of language. This paper introduces a novel training procedure which explicitly learns multiple representations of language at several levels of granularity. The multi-granularity training algorithm modifies the mechanism by which negative candidate responses are sampled in order to control the granularity of learned latent representations. Strong performance gains are observed on the next utterance retrieval task using both the MultiWOZ dataset and the Ubuntu dialog corpus. Analysis significantly demonstrates that multiple granularities of representation are being learned, and that multi-granularity training facilitates better transfer to downstream tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Producing generalized representations of language is a well-studied problem in natural language processing (NLP) <ref type="bibr" target="#b12">(Montague, 1973;</ref><ref type="bibr" target="#b3">Davidson and Harman, 2012)</ref>. Neural models typically encode an input into a latent vector, which is then used by upper layers. As such, improving the quality or generality of the learned representations will typically improve performance on the final task due to the increased representative power of the model.</p><p>Constructing meaningful representations of dialog is challenging. To effectively represent the dialog context, a latent dialog representation must contain the information necessary to (1) estimate a belief state over user goals <ref type="bibr" target="#b22">(Williams et al., 2013)</ref>, (2) track entity mentions <ref type="bibr" target="#b26">(Zhao et al., 2017)</ref>, (3) resolve anaphora co-references <ref type="bibr" target="#b11">(Mitkov, 2014)</ref>, (4) model the communicative purpose of an utterance (Core and Allen, 1997) and (5) resolve ambiguity in natural language. A large focus area of dialog research is the development of neural architectures which learn effective represen-tations of the input <ref type="bibr" target="#b28">Zhou et al., 2018)</ref>. With the goal of training a model for next utterance retrieval, <ref type="bibr" target="#b28">Zhou et al. (2018)</ref> use a deep self-attention network to produce a representation of each utterance within a dialog and follow it with an attention between utterances and 3-D convolutional layers.</p><p>Recent work has explored the use of largescale self-supervised pre-training on very large corpora <ref type="bibr" target="#b8">(Kiros et al., 2015;</ref><ref type="bibr" target="#b16">Peters et al., 2018;</ref><ref type="bibr" target="#b4">Devlin et al., 2018;</ref><ref type="bibr" target="#b17">Radford et al., 2018)</ref> as a means of improving natural language representations. These pre-trained models have yielded state-of-the-art results on several downstream NLP tasks <ref type="bibr" target="#b20">(Wang et al., 2018)</ref>: text classification, natural language inference, and question answering. Though such methods have proven useful across several downstream tasks <ref type="bibr" target="#b20">(Wang et al., 2018)</ref>, using them for dialog requires expensive fine-tuning of the complex models <ref type="bibr" target="#b5">(Dinan et al., 2019;</ref><ref type="bibr" target="#b0">Alberti et al., 2019)</ref>. The need for this finetuning is due to the pre-training procedure. First, the domain and style of dialog corpora differ significantly from the majority of the data used during pre-training. This necessitates fine-tuning in order to adapt the representations to more varied input. Second, the pre-trained representations, which are all obtained through various language modelling objectives, do not necessarily capture properties of dialog at several levels of granularity (e.g., belief state, entities, co-references, highlevel user goals).</p><p>Though large-scale pre-training improves the strength and generality of latent representations, this effect is minimized when transferring to dialog tasks or out-of-domain data. To this end, this paper explores an alternate mechanism of learning strong and general representations for the task of next utterance retrieval <ref type="bibr" target="#b9">(Lowe et al., 2015)</ref>. We propose Multi-Granularity Training (MGT), which simultaneously trains multiple levels of representation. It later combines these latent representations to obtain more general models of dialog. Different granularities of representation capture different properties of the input. For example, a high-granularity representation will capture specific words and entities mentioned in the dialog context. A low-granularity representation will instead capture more abstract properties of the dialog, such as the domain of the conversation or the high-level user goal. MGT combines representations at several levels of granularity, resulting in stronger and more general representations of dialog. The strength of representations is a consequence of learning the dedicated representations at each level of granularity. The generality results from learning several diverse representations across multiple granularities, thereby encompassing a wider amount of information. Since the representations are learned on dialog data and for the final task, this method does not suffer from the aforementioned shortcomings of pre-training.</p><p>The specific MGT procedure is motivated by the fact that observing different negative examples during training results in different representations. A model trained to select the correct response out of a set of lexically similar candidates will likely learn fine-grained representations of each word in an effort to identify minute differences between the candidates. On the other hand, a model trained to select a response from a set of topically diverse candidates will likely learn broader and more abstract representations of each utterance. Typically, negative examples are randomly sampled which results in learned representations that fit the average training example. MGT relies on an algorithm for controlled sampling of negative candidate responses, which allows for the construction of multiple training sets in order to learn multiple levels of granularity.</p><p>MGT is agnostic to the underlying model architecture. Though the majority of experiments in this paper are carried out with a dual encoder <ref type="bibr" target="#b9">(Lowe et al., 2015)</ref> as the base model, MGT is also applied on top of Deep Attention Matching networks <ref type="bibr" target="#b28">(Zhou et al., 2018)</ref> and obtains strong performance gains.</p><p>MGT is evaluated using the MultiWOZ dataset <ref type="bibr" target="#b1">(Budzianowski et al., 2018)</ref> and the Ubuntu dialog corpus <ref type="bibr" target="#b9">(Lowe et al., 2015)</ref> to train models for next utterance retrieval. Results show that MGT obtains better performance than ensembling (Perrone and Cooper, 1992) multiple baseline models. At the same time, it also serves as a better downstream representation of dialogs. The contributions of this paper are: (1) a training procedure which learns multiple granularities of latent representations for a task, (2) improved performance on next utterance retrieval across two diverse datasets, (3) an analysis significantly demonstrating that multiple granularities of representation have indeed been learned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>This section discusses two areas of related work: language representations and the next utterance retrieval task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Language Representations</head><p>Recent work has focused on improving latent representations of language through the use of largescale self-supervised pre-training on very large corpora. <ref type="bibr" target="#b8">Kiros et al. (2015)</ref> trains a sequence-tosequence model <ref type="bibr" target="#b18">(Sutskever et al., 2014)</ref> to predict the surrounding sentences, and uses the final encoder hidden state as a generic sentence representation. ELMo (Peters et al., 2018) trained a bidirectional language model on a large corpus in order to obtain strong contextual representations of words. OpenAI's GPT <ref type="bibr" target="#b17">(Radford et al., 2018)</ref> produces latent representations of language by training a large transformer <ref type="bibr" target="#b19">(Vaswani et al., 2017)</ref> with a language modelling objective. <ref type="bibr" target="#b4">Devlin et al. (2018)</ref> further improves on this line of research by introducing the masked language modelling objective and a multi-tasking pre-training loss. Each of these methods has obtained state-of-the-art results on the GLUE benchmark <ref type="bibr" target="#b20">(Wang et al., 2018)</ref>, suggesting that they are strong and general representations of language.</p><p>These pre-trained representations of language have been applied to numerous tasks. Of particular interest are applications of these representations to dialog tasks. As part of the 2nd ConvAI challenge <ref type="bibr" target="#b5">(Dinan et al., 2019)</ref>, the best performing models on both human and automated evaluations <ref type="bibr" target="#b23">(Wolf et al., 2019)</ref> were fine-tuned versions of OpenAI's GPT <ref type="bibr" target="#b17">(Radford et al., 2018)</ref>. Despite strong performance gains, transferring OpenAI's GPT required fine-tuning the full model because the dialog data was in a different domain and required different information to be contained in the representations. Recently, <ref type="bibr" target="#b10">Mehri et al. (2019)</ref> introduce several dialog specific pre-training objectives that obtain strong performance gains across multiple downstream dialog tasks. <ref type="bibr" target="#b9">Lowe et al. (2015)</ref> construct Ubuntu, the largest retrieval corpus for dialog, and present the dual encoder architecture as a baseline architecture. <ref type="bibr" target="#b6">Kadlec et al. (2015)</ref> present several strong baseline architectures for this dataset.  present the Multiview architecture which, with the aim of constructing broader representation, learns both word-level representations and utterance-level representations. Sequential Matching Networks (SMN)  represent each utterance in the dialog context and construct segment-segment matching matrices between the response and each utterance in the context. Deep Attention Matching (DAM) <ref type="bibr" target="#b28">(Zhou et al., 2018)</ref> uses deep transformers <ref type="bibr" target="#b19">(Vaswani et al., 2017)</ref> to construct representations of each utterance in a dialog context, followed by cross-attention and convolutional layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Next Utterance Retrieval</head><p>Previous work on next utterance retrieval has proposed architectural modifications in an effort to improve the representative powers of the models. This paper presents a training algorithm applicable to any neural architecture, which explicitly forces the model to learn different granularities of representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head><p>This section describes three methods used for next utterance retrieval: a strong baseline dual encoder architecture, an ensemble of dual encoders, and an ensemble of dual encoders with multi-granularity training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dual Encoder</head><p>Given a dialog context, next utterance retrieval selects the correct response from a set of k candidates. The retrieval baselines presented by <ref type="bibr" target="#b6">Kadlec et al. (2015)</ref> first encode the dialog context and a candidate response. Then they use the product of the latent representations to output a probability. This baseline architecture consists of two encoders, one to encode the context and one for the response.</p><p>Previous approaches using Ubuntu were trained for binary prediction (i.e., predict the probability of a particular response), and used during testing to select from a candidate set. To mitigate the discrepancy between training and testing, our baseline is trained to select the correct response from a candidate set. Since the Ubuntu training set consists of 0/1 labels, the training set was modified by considering only the positive-labeled examples, and uniformly sampling k − 1 negative candidates.</p><p>Let c 1,...,N denote the words of the dialog context, r i 1,...,M i denote the words of the i-th candidate response and r gt denote the ground-truth response. Given f c , the LSTM encoder of the context, and f r , the LSTM encoder of the candidate responses, the forward propagation of the dual encoder is described by:</p><formula xml:id="formula_0">c = f c (c i ) i ∈ [1, N ]</formula><p>(1)</p><formula xml:id="formula_1">r i = f r (r i j ) j ∈ [1, M i ] (2) r gt = f r (r gt j ) j ∈ [1, M gt ] (3) α gt = c T r gt (4) α i = c T r i (5)</formula><p>The final loss function is:</p><formula xml:id="formula_2">L = − log p(r i 1,...,M i |c 1,...,N ) (6) = − log exp(α gt ) exp(α gt ) + K j=1 exp(α j )</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Ensemble of Dual Encoders</head><p>Ensembling multiple models (Perrone and Cooper, 1992) has been empirically shown to improve performance, since it maintains a low model bias while significantly reducing the model variance. In ensembling, multiple models are trained and their predictions are averaged during inference. Specifically, if α l denotes the output of model l ∈ [1, L], the output probability is defined as:</p><formula xml:id="formula_3">p(r i 1,...,M i |c 1,...,N ) = 1 L L l=1 exp(α l i ) K j=1 exp(α j i )<label>(7)</label></formula><p>Since ensembling reduces the model variance while maintaining low bias, it is most effective when the models are diverse and each model excels at a particular type of input. In typical ensemble training, the different models are either obtained through different random initializations or at different checkpoints from the same training run. In such an approach, there is no mechanism which explicitly enforces diversity between the models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Multi-Granularity Training</head><p>During baseline model training, the negative response candidates were uniformly sampled from R, the set of all responses in the training set. MGT is proposed in an effort to explicitly model different granularities of representation through a controlled method of sampling negative candidates.</p><p>Consider a training corpus consisting of a set of dialog contexts and ground-truth responses, T = (C, R gt ). In the baseline training, k − 1 negative response candidates are uniformly sampled from the set of all responses, R:</p><formula xml:id="formula_4">T i = (C i , R gt i , [N i,1 , N i,2 , . . . , N i,k−1 ]) (8) ∀j ∈ [1, k − 1] N i,j ∼ Uniform(R)</formula><p>MGT is motivated by the idea that observing different types of negative candidate response sets will result in different representations. Negative candidates which are lexically similar to the ground truth response should result in models that carefully consider each word in order to produce fine-grained representations and identify minute differences between candidate responses. On the other hand, very semantically distant candidate responses should result in very broad and abstract representations of language. While there may be many methods of sampling negative responses to influence what the model learns, this paper focuses on using the semantic similarity of the candidate responses as a means of controlling the granularity of learned representations.</p><p>Given the LSTM response encoder, f r , the measure of semantic similarity is defined as:</p><formula xml:id="formula_5">r i = f r (R i,j ) j ∈ [1, M i ]<label>(9)</label></formula><formula xml:id="formula_6">r k = f r (R k,j ) j ∈ [1, M k ] (10) d(R i , R k ) = r i T r k ||r i || · ||r k ||<label>(11)</label></formula><p>This approach relies on a cosine-similarity as a measure of semantic distance between dialog utterances. While not a perfect measure, for the purposes of the MGT algorithm it appears to be a sufficient measure. Since the training algorithm groups together similarly distant negative candidates, it is robust to noise in the measure of semantic distance. Future work may explore whether a better distance measure improves the MGT algorithm.</p><p>A distance matrix D is constructed between all of the responses in R, such that</p><formula xml:id="formula_7">D i,j = d(R i , R j ).</formula><p>The objective of MGT is to train L models at L different levels of granularity. For a particular response R i , rather than sampling negative candidates from the entire set of R, the set of responses R is split into L segments based on distance from R i . Define a function b(D i , l) which considers a list of distances and returns the maximum distance in the l-th segment of a total of L segments. This is equivalent to sorting D i and taking the |R| × l Lth value.</p><p>The distance matrix, D, is used to segment the set of potential negative candidates, R, for each training example (C i , R gt i ), into L buckets: P 1 i , . . . , P L i . Given the definition of segmentation provided above, P 1 i will consist of responses that are strictly closer (as defined by d) to R i than the responses in P 2 i . When training the l-th model at the l-th level of granularity, the negative responses for R i are sampled from P l i rather than R. P l i is constructed using b(D i , l), which was defined to return the maximum value in the l-th segment.</p><p>This method is used to construct L different training corpora, T 1 , . . . , T L . A particular T l is constructed as follows:</p><formula xml:id="formula_8">T l i = (C i , R gt i , [N l i,1 , . . . , N l i,k−1 ])<label>(12)</label></formula><formula xml:id="formula_9">P l i = {r ∈ R | d(R i , r) ∈ (b(D i , l − 1), b(D i , l)} ∀j ∈ [1, k − 1] N l i,j ∼ Uniform(P l i )</formula><p>After the L different training corpora, L different models are trained. Models trained on closer candidate sets should learn more granular representations while models trained on more distant candidate sets should learn more abstract representations of dialog. Upon obtaining L different models, the output probability is produced by the ensembling method described in Equation 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>This section describes the datasets and presents experimental procedures aimed at evaluating the different approaches to next utterance retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>Two retrieval corpora, MultiWOZ <ref type="bibr" target="#b1">(Budzianowski et al., 2018)</ref> and Ubuntu <ref type="bibr" target="#b9">(Lowe et al., 2015)</ref> were used.</p><p>MultiWOZ contains task-oriented conversations between a tourist and a Wizard-of-Oz, while Ubuntu contains both open-domain and technical dialog snippets collected from Internet Relay Chat (IRC). The diversity of these two datasets provides insight into the general applicability of MGT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">MultiWOZ</head><p>The MultiWOZ dataset <ref type="bibr" target="#b1">(Budzianowski et al., 2018)</ref> was converted into a retrieval corpus. MultiWOZ contains 8422 dialogs for training, 1000 for validation and 1000 for testing. There are 20 candidate responses for each dialog context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Ubuntu Dialog Corpus</head><p>The original Ubuntu corpus <ref type="bibr" target="#b9">(Lowe et al., 2015)</ref> has 1,000,000 training examples. Typical interactions include individuals asking for technical assistance in a conversational manner. The subject of conversation is not explicitly bounded and may be any topic. As described in Section 3.1, the training corpus is modified in order to train as a retrieval task rather than as a binary prediction task. Negative training examples (500,127) are filtered out. The size of the new training dataset is 499,873. There are a total of 10 candidate responses for each context. The validation and test sets remain unchanged, with 19,561 validation examples and 18,921 test examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Setup</head><p>Unless otherwise specified, the size of ensembles and the number of models in MGT is L = 5. For MGT, the highest performing checkpoint at each granularity is selected using the validation score. For the ensemble method, the top performing checkpoints are selected from a single run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">MultiWOZ Setup</head><p>Two distinct encoders are trained, one to encode the dialog context and the other for the candidate responses. Each encoder is a single layer, unidirectional LSTM with an embedding dimension of 50 and a hidden size of 150. These hidden sizes match the best performing hyperparameters identified by <ref type="bibr" target="#b1">Budzianowski et al. (2018)</ref>. The Adam optimizer (Kingma and Ba, 2015) with a learning rate of 0.005 is used to train the model for 20 epochs. The vocabulary is 1261 words, the batch size is 32, and gradients are clipped to 5.0. A checkpoint is saved after each epoch, and the best checkpoint is selected using performance on the validation set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Ubuntu Setup</head><p>Each encoder is a single layer, uni-directional LSTM with an embedding dimension of 300 and a hidden size of 150. The Adam optimizer (Kingma and Ba, 2015) with a learning rate of 0.005 is used to train the model for 20 epochs. The vocabulary is 10002 words, the batch size is 128, and gradients are clipped to 5.0. Only the last 160 words of each dialog context are used. The word embeddings are initialized with pre-trained GloVe embeddings <ref type="bibr" target="#b14">(Pennington et al., 2014)</ref>. A checkpoint is saved after each epoch, and the best checkpoint is selected using performance on the validation set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Deep Attention Matching Experiment</head><p>MGT is a training procedure which is agnostic to the underlying model architecture. Though the majority of the experiments presented in this paper use the dual encoder architecture <ref type="bibr" target="#b9">(Lowe et al., 2015)</ref>, MGT is applied on top of the state-of-theart architecture for Ubuntu: the Deep Attention Matching Network (DAM) <ref type="bibr" target="#b28">(Zhou et al., 2018)</ref>. When applying MGT to DAM, the sampling of negative candidates is done using the baseline dual encoder architecture. <ref type="table">Table 1</ref> shows an example dialog context, groundtruth response and the negative candidate responses sampled at several levels of cosine distance, as per Equation 11. These negative candidate responses are retrieved by MGT's sampling algorithm, and are used to train multiple models at different levels of granularity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Multi-Granularity Training Example</head><p>The negative candidates for the higher granularity models are much closer to the ground-truth response than the candidates for the lower granularity models. As such, models trained at higher granularities will learn more granular representations of dialog in order to identify minute differences between responses. Examples for lower granularity models are more distant in meaning, and models may instead learn to represent higherlevel attributes of the dialog. SYS: i need to know when you want to leave and arrival time in order for me to order you a taxi . <ref type="table">Table 1</ref>: An example dialog context from the training set. Along with the ground-truth response, negative candidates sampled at five different levels of semantic distance are shown. The retrieval models are trained to differentiate between the ground-truth response and the different negative candidates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>Multi-granularity training is proposed in order to learn strong and general latent representations of dialog. To evaluate the strength and generality of the learned representations, experiments are conducted to evaluate three different properties of MGT: (1) improved performance on the task of next utterance retrieval, (2) explicit modelling of different granularities, and (3) improved generality and transferability to other dialog tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Next Utterance Retrieval</head><p>Next utterance retrieval is reliant on latent representations of dialog. Several experiments are conducted to evaluate whether MGT improves the representative power of models and results in better performance on the task of next utterance retrieval. MGT is expected to outperform standard ensembling, since MGT explicitly models multiple granularities and trains more diverse models. The performance of MGT is evaluated using both MultiWOZ <ref type="bibr" target="#b1">(Budzianowski et al., 2018)</ref> and Ubuntu <ref type="bibr" target="#b9">(Lowe et al., 2015)</ref>. Experiments are conducted using two different underlying architectures, a dual encoder baseline <ref type="bibr" target="#b9">(Lowe et al., 2015)</ref> and a Deep Attention Matching network <ref type="bibr" target="#b28">(Zhou et al., 2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">MultiWOZ</head><p>Performance on the MultiWOZ retrieval task is evaluated with mean reciprocal rank (MRR), and Hits@1 (H@1). Mean reciprocal rank is defined as follows:</p><formula xml:id="formula_10">M RR = 1 N N i=1 1 rank i<label>(13)</label></formula><p>Hits@1 is equivalent to accuracy. It measures how often the ground-truth response is selected from the K = 20 candidates.</p><p>The results in <ref type="table">Table 2</ref> demonstrate the strong performance gains obtained with MGT. With L = 5 granularities, MGT outperforms a similarly sized ensemble of dual encoders. These results demonstrate that explicitly enforcing the policy that makes models learn multiple granularities of representation improves the representative power and performance on next utterance retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Ubuntu</head><p>Previous research used several variations of the R N @k metric to evaluate retrieval performance on the Ubuntu dialog dataset. R N @k refers to the percentage of the time that the ground truth response was within the top-k predictions for a candidate set size of N utterances. R 10 @1 on Ubuntu is equivalent to Hits@1 and accuracy. In addition Model Name</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MRR Hits@1</head><p>Dual Encoder 79.55 66.13% Ensemble (5) 81.53 69.47% Multi-Granularity (5) 82.74 72.18% <ref type="table">Table 2</ref>: Performance on MultiWOZ. MGT is compared to a baseline dual encoder, and an ensemble of dual encoders with an identical number of parameters. All bold-face results are statistically significant to p &lt; 0.01.</p><p>to MRR, we report R 10 @1 and R 2 @1, top-1 accuracy with a candidate set size of 10 and 2, respectively.</p><p>MGT is applied on top of the dual encoder baseline <ref type="bibr" target="#b9">(Lowe et al., 2015)</ref> and Deep Attention Matching networks <ref type="bibr" target="#b28">(Zhou et al., 2018)</ref>. The results shown in <ref type="table" target="#tab_2">Table 3</ref> show the performance of MGT using two different underlying architectures, as well as previous work. Across both base architectures, MGT outperforms ensembling. The primary difference between these two methods is that MGT explicitly ensures that several granularities of representation are learned. As such, these results reaffirm the hypothesis that learning multiple granularities of representation leads to more diverse models, and more general representations of dialog.</p><p>Even with the dual encoder as the underlying model, MGT outperforms all previous work except for Sequential Matching Networks (SMN)  and Deep Attention Matching networks (DAM) <ref type="bibr" target="#b28">(Zhou et al., 2018)</ref>. The Deep Attention Matching experiment performs MGT using DAM 1 as the underlying architecture. MGT has good performance improvement on top of DAM, roughly double the improvement obtained by ensembling. This suggests that MGT can be used as a general purpose training algorithm which learns multiple-granularities of representation and thereby produces stronger and more general models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Explicit Granularity Modelling</head><p>Multi-granularity training learns multiple granularities of representation. However, strong performance on next utterance retrieval, does not neces-1 It should be noted that the open-source implementation provided by <ref type="bibr" target="#b28">Zhou et al. (2018)</ref> was used, however performance was slightly lower than the results they reported. We speculate that given a DAM implementation that matches their reported results, MGT would obtain a similarly-sized improvement (+0.76 R@1). sarily prove that several granularities are explicitly modelled. To analyze whether the models operate at different levels of granularity, the content of the representations must be considered. The L = 5 trained models, each at a different granularity, have their weights frozen. These frozen models are then used to obtain a latent representation of all the dialog contexts in MultiWOZ. A linear layer is then trained on top of these representations for a downstream task. During this training, only the weights of the linear layer are updated. This evaluates the information contained in these learned representations.</p><p>Two different downstream tasks are considered; bag-of-words prediction and dialog act prediction. Bag-of-words prediction is the task of predicting a binary vector corresponding to the words present in the last utterance of the dialog context. This task requires very granular representations of language, and therefore the models trained to capture high granularity representations should have the highest performance. Dialog act prediction is the task of predicting the set of dialog acts for the next system response. This is a high-level task that requires abstract representations of language, therefore the models with the lowest granularity should do well.</p><p>The results in <ref type="table" target="#tab_3">Table 4</ref> confirm the hypothesis that MGT results in models that learn different granularities of representation. It is clear that higher granularity models better capture the information necessary for the bag-of-words task, while higher abstraction (lower granularity) models better capture information for dialog act prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Generalizability and Task Transfer</head><p>One motivation of MGT is to improve the generality of representation, and facilitate easy transfer to various tasks. Truly general representations of language would require no fine-tuning of the model, and we would only need to learn a linear layer in order to extract the relevant information from the representation. Bag-of-words prediction and dialog act prediction are again used to evaluate the ability of MGT to transfer without any fine-tuning.</p><p>The results shown in <ref type="table" target="#tab_4">Table 5</ref> demonstrate that MGT results in more general representations of language, thereby facilitating better transfer. However, there is room for improvement when comparing to models fine-tuned on the downstream task. This suggests that additional mea-     sures can be taken to improve the representative power of these models. The results in <ref type="table" target="#tab_5">Table 6</ref> demonstrate that MGT learns general representations which effectively transfer to downstream tasks, especially more difficult tasks such as dialog act prediction. Finetuning the latent representations learned by MGT, results in improved performance on dialog act prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions and Future Work</head><p>This paper presents multi-granularity training (MGT), a mechanism for learning strong and general representations for next utterance retrieval. Through the use of a sampling algorithm to select negative candidate responses, multiple gran-ularities of representation are learned during training. Strong performance gains are observed on the task of next utterance retrieval on both MultiWOZ and Ubuntu. Experiments show that MGT is a generally applicable training procedure which can be applied to multiple underlying model architectures. Quantitative analytic experiments demonstrate that multiple granularities of representation are in fact being learned, and that MGT facilitates better transfer to downstream tasks both with and without fine-tuning.</p><p>There are several avenues for future work. First, this method is general and broadly applicable, which suggests that it may improve performance on other tasks and domains. A particularly interesting application would be to generalize this method to language generation tasks. Second, a useful improvement on top of MGT would be a more sophisticated method of combining the multiple granularities of representations. Third, while this paper focuses on capturing multiple representations at different levels of granularity, it would be interesting to generalize MGT to learning multiple representations along several different axes (e.g., domains, styles, intents, etc.).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Dialog Context: USER: i need an expensive place to dine in the center of town . SYS: what type of food are you wanting at this restaurant ? USER: type of food does not matter to me . Ground-Truth Response: SYS: yes there are 33 such restaurant -s . would you like me to book 1 for you ? Closest Neg. Cand. (for Highest Granularity Model): SYS: i have 5 indian restaurant -s in the west . if i may , might i suggest the rice boat . i can reserve a table for you if you would like . 2nd Closest Neg. Cand. (for 2nd Highest Granularity Model): SYS: how about the avalon ? 3rd Closest Neg. Cand. (for 3nd Highest Granularity Model): SYS: i would be happy to book that for you .are you travelling alone ? 2nd Furthest Neg. Cand. (for 2nd Lowest Granularity Model): SYS: i apologize , there s been a misunderstanding . before we can book your taxi , we need to know which college . there are 18 colleges . what area are you looking for ? Furthest Granularity Neg. Cand (for Lowest Granularity Model):</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Results for next utterance retrieval on the Ubuntu dialog corpus. This table shows previous work, and experimental results with two underlying architectures: a dual encoder model and Deep Attention Matching networks. The results shown in the DAM experiments section are performed with the open-sourced implementation of<ref type="bibr" target="#b28">Zhou et al. (2018)</ref>, which obtains slightly worse performance than they report. All bold-face results are statistically significant to p &lt; 0.01.</figDesc><table><row><cell>Model Name</cell><cell cols="2">BoW (F-1) DA (F-1)</cell></row><row><cell>Highest Abstraction</cell><cell>57.00</cell><cell>19.24</cell></row><row><cell>2nd Highest Abs.</cell><cell>57.69</cell><cell>19.14</cell></row><row><cell>Medium</cell><cell>58.49</cell><cell>18.31</cell></row><row><cell>2nd Highest Gran.</cell><cell>58.38</cell><cell>16.88</cell></row><row><cell>Highest Granularity</cell><cell>59.43</cell><cell>15.46</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Results of the granularity analysis experiment. L = 5 models trained to capture different granularities of representation. All bold-face results are statistically significant to p &lt; 0.01.</figDesc><table><row><cell>Model Name</cell><cell cols="2">BoW (F-1) DA (F-1)</cell></row><row><cell>Dual Encoder</cell><cell>60.13</cell><cell>19.09</cell></row><row><cell>Ensemble (5)</cell><cell>64.11</cell><cell>22.39</cell></row><row><cell>Multi-Granularity (5)</cell><cell>67.51</cell><cell>22.85</cell></row><row><cell>Fine-tuned</cell><cell>90.33</cell><cell>28.75</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Experimental results demonstrating performance on two downstream tasks, without any finetuning of the latent representations. All bold-face results are statistically significant to p &lt; 0.01.</figDesc><table><row><cell>Model Name</cell><cell>DA (F-1)</cell></row><row><cell>Random Init</cell><cell>28.75</cell></row><row><cell>Dual Encoder</cell><cell>32.63</cell></row><row><cell>Ensemble (5)</cell><cell>31.71</cell></row><row><cell>Multi-Granularity (5)</cell><cell>33.46</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Experimental results demonstrating performance on the downstream task of dialog act prediction, when the model is fine-tuned on all available data. All bold-face results are statistically significant to p &lt; 0.01.</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.08634</idno>
		<title level="m">A bert baseline for the natural questions</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Multiwoz-a large-scale multi-domain wizard-of-oz dataset for task-oriented dialogue modelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paweł</forename><surname>Budzianowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Hsien</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo-Hsiang</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iñigo</forename><surname>Casanueva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Ultes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Osman Ramadan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gašić</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.00278</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Coding dialogs with the damsl annotation scheme</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Core</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Allen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI fall symposium on communicative action in humans and machines</title>
		<meeting><address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="volume">56</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Semantics of natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gilbert</forename><surname>Harman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Springer Science &amp; Business Media</publisher>
			<biblScope unit="volume">40</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varvara</forename><surname>Logacheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valentin</forename><surname>Malykh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Urbanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iulian</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.00098</idno>
		<title level="m">The second conversational intelligence challenge (convai2)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rudolf</forename><surname>Kadlec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Schmid</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1510.03753</idno>
		<title level="m">Improved deep learning baselines for ubuntu corpus dialogs</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Skip-thought vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ruslan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3294" to="3302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nissan</forename><surname>Pow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iulian</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.08909</idno>
		<title level="m">The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shikib</forename><surname>Mehri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniia</forename><surname>Razumovsakaia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiancheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxine</forename><surname>Eskenazi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.00414</idno>
		<title level="m">Pretraining methods for dialog context representation learning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Anaphora resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Mitkov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Routledge</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The proper treatment of quantification in ordinary english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Montague</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Approaches to natural language</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1973" />
			<biblScope unit="page" from="221" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Text matching as image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanyan</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengxian</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirtieth AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">When networks disagree: Ensemble methods for hybrid neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon N Cooper ; Brown Univ Providence Ri Inst For Brain And Neu-Ral</forename><surname>Perrone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Systems</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.05365</idno>
		<title level="m">Deep contextualized word representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Improving language understanding by generative pre-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<ptr target="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/languageunsupervised/languageunder-standingpaper.pdf" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6000" to="6010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amapreet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel R</forename><surname>Bowman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.07461</idno>
		<title level="m">Glue: A multi-task benchmark and analysis platform for natural language understanding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.07905</idno>
		<title level="m">Machine comprehension using match-lstm and answer pointer</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Deepak Ramachandran, and Alan Black</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Raux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGDIAL 2013 Conference</title>
		<meeting>the SIGDIAL 2013 Conference</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="404" to="413" />
		</imprint>
	</monogr>
	<note>The dialog state tracking challenge</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Transfertransfo: A transfer learning approach for neural network based conversational agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.08149</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Sequential matching network: A new architecture for multi-turn response selection in retrieval-based chatbots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhoujun</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.01627</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning to respond with deep neural networks for retrievalbased human-computer conversation system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiping</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval</title>
		<meeting>the 39th International ACM SIGIR conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="55" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Generative encoderdecoder models for task-oriented spoken dialog systems with chatting capability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiancheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyusong</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxine</forename><surname>Eskenazi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.08476</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Multi-view response selection for human-computer conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daxiang</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiqi</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dianhai</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="372" to="381" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Multi-turn response selection for chatbots with deep attention matching network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daxiang</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wayne</forename><forename type="middle">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dianhai</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Long Papers</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1118" to="1127" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
