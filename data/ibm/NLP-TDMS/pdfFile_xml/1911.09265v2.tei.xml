<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">EnAET: A Self-Trained framework for Semi-Supervised and Supervised Learning with Ensemble Transformations</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="20201">AUGUST 2020 1</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daisuke</forename><surname>Kihara</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Fellow, IEEE</roleName><forename type="first">Jiebo</forename><surname>Luo</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Senior Member, IEEE</roleName><forename type="first">Guo-Jun</forename><surname>Qi</surname></persName>
						</author>
						<title level="a" type="main">EnAET: A Self-Trained framework for Semi-Supervised and Supervised Learning with Ensemble Transformations</title>
					</analytic>
					<monogr>
						<title level="j" type="main">IEEE TRANSACTIONS ON IMAGE PROCESSING</title>
						<imprint>
							<biblScope unit="volume">14</biblScope>
							<biblScope unit="issue">8</biblScope>
							<date type="published" when="20201">AUGUST 2020 1</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T22:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-EnAET</term>
					<term>self-supervised learning</term>
					<term>semi- supervised learning</term>
					<term>Ensemble Transformations</term>
					<term>supervised learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep neural networks have been successfully applied to many real-world applications. However, such successes rely heavily on large amounts of labeled data that is expensive to obtain. Recently, many methods for semi-supervised learning have been proposed and achieved excellent performance. In this study, we propose a new EnAET framework to further improve existing semi-supervised methods with self-supervised information. To our best knowledge, all current semi-supervised methods improve performance with prediction consistency and confidence ideas. We are the first to explore the role of selfsupervised representations in semi-supervised learning under a rich family of transformations. Consequently, our framework can integrate the self-supervised information as a regularization term to further improve all current semi-supervised methods.</p><p>In the experiments, we use MixMatch, which is the current state-of-the-art method on semi-supervised learning, as a baseline to test the proposed EnAET framework. Across different datasets, we adopt the same hyper-parameters, which greatly improves the generalization ability of the EnAET framework. Experiment results on different datasets demonstrate that the proposed EnAET framework greatly improves the performance of current semi-supervised algorithms. Moreover, this framework can also improve supervised learning by a large margin, including the extremely challenging scenarios with only 10 images per class. The code and experiment records are available in https://github.com/maple-research-lab/EnAET.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Deep neural network has shown its sweeping successes in learning from large-scale labeled datasets like ImageNet <ref type="bibr" target="#b0">[1]</ref>. However, such successes hinge on the availability of a large amount of labeled examples <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref> that are expensive to collect. Moreover, deep neural networks usually have a large number of parameters that are prone to over-fitting. Thus, we hope that semi-supervised learning can not only deal with the limited labels but also alleviate the over-fitting problem by exploring unlabeled data. In this paper, we successfully prove The work was done while X. Wang was interning at Futurewei Technologies. X. <ref type="bibr">Wang</ref>  that both goals can be achieved by training a semi-supervised model built upon self-supervised representations.</p><p>Semi-Supervised Learning (SSL) <ref type="bibr" target="#b5">[5]</ref>, <ref type="bibr" target="#b6">[6]</ref>, <ref type="bibr" target="#b7">[7]</ref>, <ref type="bibr" target="#b8">[8]</ref>, <ref type="bibr" target="#b9">[9]</ref>, <ref type="bibr" target="#b10">[10]</ref>, <ref type="bibr" target="#b11">[11]</ref>, <ref type="bibr" target="#b12">[12]</ref> has been extensively studied due to its great potential for addressing the challenge with limited labels. Most stateof-the-art approaches can be divided into two categories. One is confident predictions <ref type="bibr" target="#b6">[6]</ref>, <ref type="bibr" target="#b13">[13]</ref>, <ref type="bibr" target="#b14">[14]</ref>, which improves a model's confidence by encouraging low entropy prediction on unlabeled data. The other category imposes consistency regularization <ref type="bibr" target="#b15">[15]</ref>, <ref type="bibr" target="#b16">[16]</ref>, <ref type="bibr" target="#b17">[17]</ref>, <ref type="bibr" target="#b18">[18]</ref> by minimizing discrepancy among the predictions by different models. The two approaches employ reasonable objectives since good models should make confident predictions that are consistent with each other. Also, apart from image processing, semi-supervised learning ideas have achieved great success in other areas <ref type="bibr" target="#b19">[19]</ref>, <ref type="bibr" target="#b20">[20]</ref>, <ref type="bibr" target="#b21">[21]</ref>, <ref type="bibr" target="#b22">[22]</ref>, <ref type="bibr" target="#b23">[23]</ref>, <ref type="bibr" target="#b24">[24]</ref>.</p><p>In self-supervised learning, researchers have explored several methods <ref type="bibr" target="#b25">[25]</ref>, <ref type="bibr" target="#b26">[26]</ref> to fully utilize the latent information in images. In our previous work <ref type="bibr" target="#b25">[25]</ref>, <ref type="bibr" target="#b27">[27]</ref>, we utilized the image transformations as the supervising signal to train encoders, which have achieved promising performance. Instead of only exploring the information of labels to improve semi-supervised learning performance, we believe that the latent information carried by images can also contribute to the semi-supervised learning. As addressed in the literature <ref type="bibr" target="#b28">[28]</ref>, <ref type="bibr" target="#b29">[29]</ref>, <ref type="bibr" target="#b25">[25]</ref>, a representative encoder should also recognize an object even if it is transformed in different ways. With deep networks, this is usually achieved by training the model with augmented labeled data. However, that will make the trained feature influenced by the label information and thus prevent the features from being more representative. Instead, inspired by those self-supervised methods, we used the transformations as the signal to supervise those transformed images to overcome the information loss introduced by the labels during semisupervised training.</p><p>To this end, we will present an Ensemble of Auto-Encoding Transformations (EnAET) framework to self-train semi-supervised classifiers with various transformations by integrating self-supervised representations <ref type="bibr" target="#b25">[25]</ref> to augment semi-supervised learning performance. Our contributions are summarized as follows:</p><p>• We propose the first method that employs an ensemble of both spatial and non-spatial transformations to train a semi-supervised network in a self-supervised fashion over both labeled and unlabeled data.</p><p>arXiv:1911.09265v2 [cs.CV] 1 Feb 2021</p><p>• We apply an ensemble of AutoEncoding Transformations to learn robust features under various transformations, and improve the prediction consistency on the transformed images by minimizing their KL divergence. The proposed framework is a general framework that can be readily integrated with and improve any semi-supervised learning method. <ref type="bibr">•</ref> We demonstrate that the EnAET can greatly improve both the semi-supervised and supervised baselines by large margins through integrating the self-supervised representations. Moreover, we find out the number of labeling data can be further reduced to achieve desired performances. • We use the same hyper-parameters across different datasets without over-tuning them in the experiments, further demonstrating the model's excellent generalization ability and practical value. The remainder of the paper is organized as follows. We briefly review the related work in semi-supervised learning and self-supervised learning in Section II. We present our algorithm EnAET in Section III. To prove our framework's effectiveness and stability, extensive experiments related to supervised learning and semi-supervised learning are described in Section IV. Finally, we conclude in Section V.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>In this section, we review both semi-supervised and selfsupervised learning approaches in the literature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Semi-Supervised Learning (SSL)</head><p>Semi-Supervised learning (SSL) is an approach in machine learning that performs training under the scenario where a large amount of unlabelled data and a small amount of labelled data are available. Considering the fact that annotated data is expensive to collect and unlabelled data is easy to collect, it is necessary to develop methods that can learn from a small amount of annotated data.</p><p>A wide variety of SSL methods have been developed in literature, which aims to learn from limited number of annotated data. For example, Teach-Student Models <ref type="bibr" target="#b30">[30]</ref>, <ref type="bibr" target="#b16">[16]</ref>, <ref type="bibr" target="#b18">[18]</ref>, <ref type="bibr" target="#b13">[13]</ref> constitute a large category of SSL, which is closely related to the proposed model and is proposed based on the assumption that two online models can learn from each other through their predicted probabilities. Inspired by unsupervised learning <ref type="bibr" target="#b31">[31]</ref>, <ref type="bibr" target="#b32">[32]</ref> performance on feature representation, supervision information is incorporated into the variational auto-encoders to learn various semi-supervised classifiers <ref type="bibr" target="#b33">[33]</ref>, <ref type="bibr" target="#b34">[34]</ref>, <ref type="bibr" target="#b35">[35]</ref>, <ref type="bibr" target="#b36">[36]</ref>. Similarly, GAN-based models <ref type="bibr" target="#b10">[10]</ref>, <ref type="bibr" target="#b37">[37]</ref>, <ref type="bibr" target="#b12">[12]</ref> also show promising results on many semisupervised tasks, whose success is based on the adversarial learning. Below we review two ideas about semi-supervised learning that are closely related to the proposed model. Consistent Predictions One of the most popular and successful ideas in SSL is to encourage consistent predictions when inputs and/or models are perturbed. Inspired by Denoising Source Separation (DSS) <ref type="bibr" target="#b38">[38]</ref>, Γ-model <ref type="bibr" target="#b30">[30]</ref> applies a denoising layer to improve its performance by minimizing the impact of potential perturbations. Π-model <ref type="bibr" target="#b16">[16]</ref> is further improved by adding stochastic augmentations on images and dropout <ref type="bibr" target="#b39">[39]</ref> on network neurons to maximize prediction consistency. Furthermore, Virtual Adversarial Training (VAT) <ref type="bibr" target="#b13">[13]</ref> uses adversarial perturbations to replace the random noises in Π-model, making it more resilient against noises.</p><p>Compared with the previous methods on maximizing the prediction consistency under perturbations, the Mean Teacher model <ref type="bibr" target="#b18">[18]</ref> updates the weights of a teacher model with an exponential moving average (EMA) of the weights from a sequence of student models as follows.</p><formula xml:id="formula_0">Θ τ = αΘ τ −1 + (1 − α)Θ τ<label>(1)</label></formula><p>where Θ (Θ ) is the weights of the Student (Teacher) Model, τ denotes the update step and α is a smoothing coefficient, which is always set to 0.999. This can result in stable and accurate predictions, and will be integrated into the proposed EnAET framework. Confident Predictions The other successful idea in SSL is to encourage a model to make confident predictions on both labeled and unlabeled data. For the feature space of a model, it is ideal that each class has a clear boundary with other classes. In other words, the boundary should be far away from the high density regions of data. "Pseudo-Label" <ref type="bibr" target="#b6">[6]</ref> implements this idea by minimizing the entropy loss of the predictions on unlabeled data. VAT <ref type="bibr" target="#b13">[13]</ref> also combines this entropy minimization term to make confident predictions. Similarly, several other works <ref type="bibr" target="#b14">[14]</ref>, <ref type="bibr" target="#b40">[40]</ref> encourage confident predictions by constructing hard labels for high-confident unlabeled data to "sharpen" the predictions. Recently, MixUp <ref type="bibr" target="#b41">[41]</ref> was proposed to further improve the boundary between classes together with entropy minimization. Instead of only focusing on predicted results on given data, MixUp trains a model with the linear combination of the inputs and corresponding outputs. This has shown extraordinary performances in both supervised <ref type="bibr" target="#b41">[41]</ref> and semi-supervised tasks <ref type="bibr" target="#b40">[40]</ref>, <ref type="bibr" target="#b42">[42]</ref>.</p><p>While current semi-supervised approaches is based on consistent prediction and confident prediction ideas, we find that self-supervised representations can successfully integrate with concurrent semi-supervised ideas by exploring the data variations under a variety of transformations. Unlike data augmentation applied to labeled data, we can self-train a semisupervised model without relying on the labeled data. This can significantly boost the performances in semi-supervised as well as fully-supervised learning tasks. For this reason, we also review the related work on self-supervised methods below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Self-Supervised Learning</head><p>Self-Supervised learning is also referred to as representation learning, which aims to learn representative features without label information. The learned features can then be frozen and used for classification. It can not only reduce the cost and time for collecting annotated data, but also successfully avoid the overfitting problem since it is trained without label information. Moreover, finetuning results <ref type="bibr" target="#b26">[26]</ref> with a pretrained model from self-supervised learning on different datasets also has shown its excellent encoding ability.</p><p>There are a wide variety of unsupervised models that apply different types of self-supervised signals to train deep networks, such as transformation parameters. Mehdi and Favaro <ref type="bibr" target="#b43">[43]</ref> propose to solve Jigsaw puzzles to train a convolutional neural network. Doersch et al. <ref type="bibr" target="#b44">[44]</ref> train the network by predicting the relative positions between sampled patches from an image as self-supervising information. Noroozi et al. <ref type="bibr" target="#b45">[45]</ref> count the features that satisfy equivalence relations between downsampled and tiled images, while Gidaris et al. <ref type="bibr" target="#b29">[29]</ref> classify a discrete set of image rotations to train deep networks. Dosovitskiy et al. <ref type="bibr" target="#b46">[46]</ref> create a set of surrogate classes from individual images. Unsupervised features have also been learned from videos by estimating the self-motion of moving objects between consecutive frames <ref type="bibr" target="#b47">[47]</ref>.</p><p>More recently, Zhang et al. <ref type="bibr" target="#b25">[25]</ref>, <ref type="bibr" target="#b48">[48]</ref> has demonstrated the state-of-the-art performances in many unsupervised tasks with the utilization of transformation information. It aims to learn a good representation of visual structures that can decode the transformations from the learned representations of original and transformed images. Inspired by this self-supervised idea, we develop a self-trained framework for semi-supervised tasks by exploring unlabeled data under a transformation ensemble.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. ENSEMBLE AUTOENCODING TRANSFORMATIONS</head><p>In this section, we introduce the proposed Ensemble Au-toEncoding Transformation (EnAET) framework, a novel idea centered around leveraging an ensemble of spatial and nonspatial transformations to self-train semi-supervised methods for improved performances. Although we choose MixMatch <ref type="bibr" target="#b40">[40]</ref> as the reference model, the EnAET framework is not limited to MixMatch. Even though MixMatch has already achieved competitive performances over several datasets, we will demonstrate EnAET can still significantly further improve its performances as a general self-training mechanism.</p><p>Indeed, the difference between the features extracted from original and transformed images is caused by the applied transformations. Therefore, the transformation decoder can recover the transformations so long as the encoded features capture the necessary details of visual structures. Inspired by unsupervised work in <ref type="bibr" target="#b25">[25]</ref>, EnAET can self-train a good feature representation upon which a competitive semi-supervised classifier can be developed to explore an ensemble of spatial and non-spatial transformations. Since EnAET will not make use of labelled information, the EnAET framework can serve as a regularization part and integrate with all current semisupervised methods and boost its performance. <ref type="figure" target="#fig_0">Fig. 1</ref> illustrates the EnAET framework. We will describe the details in Section III-C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Ensemble Transformations</head><p>Zhang et al. <ref type="bibr" target="#b25">[25]</ref> utilize the parameterized transformations as labels to train encoder to try to predict the most representative features. In the SSL setting, instead of pretraining the encoder as unsupervised learning, we formulate AutoEncoding Transformation (AET) loss as a regularization term along with the SSL loss to train classifiers.  In this study, we mainly focused on two types of transformations to self-train the SSL algorithms. We will briefly introduce it below. Spatial Transformations As introduced in <ref type="bibr" target="#b49">[49]</ref>, for any 2D spatial transformation, we can represent it with a matrix below in Eq. <ref type="formula">(2)</ref>,</p><formula xml:id="formula_1">  a 1 a 2 b 1 a 3 a 4 b 2 c 1 c 2 1     x y 1   =   x y 1   (2)</formula><p>where a1 a2 a3 a4 is a submatrix that controls the rotation, aspect ratio, shearing and scaling factors, b1 b2 is the translation, and c1 c2 is the projection; (x, y) is the coordinate of original image, while (x , y ) denotes the coordinate after the transformation.</p><p>Based on Eq. (2), we incorporate four most representative transformations into the AET loss: 1) Projective transformation, 2) Affine transformation, 3) Similarity transformation, and 4) Euclidean transformation. We illustrate and compare these transformations in <ref type="table" target="#tab_1">Table I</ref> and <ref type="figure" target="#fig_1">Fig. 2</ref>. Although it seems that projective transformation includes the other transformations as its special cases, it is natural to raise the question of whether we still need to include the other transformations explicitly. However, noting the fact that the Euclidean, Similarity and Affine transformations rarely happen under Projective transformation when we use the random parameters to conduct projective transformation, we will explicitly sample these transformations in EnAET. Our ablation study also shows that the ensemble transformations can contribute to the model's performance. Non-spatial transformations A good classifier can also recognize objects in different color, contrast, brightness, and sharpness conditions. Therefore, we also add these nonspatial transformations to EnAET framework. We consider four different non-spatial transformations as shown in <ref type="table" target="#tab_1">Table II</ref>. For simplicity, these four transformations are applied as an </p><formula xml:id="formula_2">L AET k = E x∈U ,t k D [E(x), E(t k (x))] − t k 2</formula><p>Calculate AET loss, which is illustrated in Section III-A. <ref type="bibr" target="#b5">5</ref>:</p><formula xml:id="formula_3">L CL k = E x∈U ,t k y P (y|x) log P (y|x) Pt k (y|x)</formula><p>Consistent Prediction loss, details in Section III-B 6: end for</p><formula xml:id="formula_4">7: L = L SSL + N k=1 λ k L AET k + γ N k=1 L CL k</formula><p>Calculate the overall loss <ref type="bibr">8:</ref> Apply L to update model. 9: Update teacher model:</p><formula xml:id="formula_5">Θ τ = αΘ τ −1 + (1 − α)Θ τ</formula><p>Use EMA <ref type="bibr" target="#b18">[18]</ref> to update the final model's loss (see Eq. <ref type="formula" target="#formula_0">(1)</ref>) Ensure: Student model with weight Θ and teacher model with weight Θ .  <ref type="figure" target="#fig_2">Fig. 3</ref>.</p><p>To apply AutoEncoding Transformation (AET) idea to selftrain the encoder part, we can formulate AET loss in Eq. (3).</p><formula xml:id="formula_6">L AET k = E x,t k D [E(x), E(t k (x))] − t k 2<label>(3)</label></formula><p>where D denotes the transformation decoder, E represents the encoder, and t k is the sampled transformation of type k. The AET loss computes the Mean-Squared Error (MSE) between the predicted transformation and the sampled transformation.</p><p>Then, we can minimize a linear combination of the SSL loss and the AET loss to train a classifier over the network weights Θ where λ k is the weight on the AET loss L AET k for the transformation t k of the kth type.</p><formula xml:id="formula_7">min Θ L SSL + N k=1 λ k L AET k<label>(4)</label></formula><p>Here, the SSL loss L SSL can be any loss used to self-train a semi-supervised classifier in literature. Particularly, we will use the MixMatch loss <ref type="bibr" target="#b40">[40]</ref> that yields the state-of-the-art SSL result. In other words, we use MixMatch as the baseline to demonstrate the proposed framework can further improve an even very competitive model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Making Consistent Predictions</head><p>Inspired by the common SSL algorithms, transformation invariance by making consistent predictions on image labels under transformations <ref type="bibr" target="#b50">[50]</ref>, <ref type="bibr" target="#b13">[13]</ref> are widely used.</p><p>Similarly, apart from the AET loss for our ensemble transformations, we also explore the consistency predictions for our transformations. To achieve this, we propose our consistency loss (CL) by minimizing the KL divergence between the "guessed label" P (y|x) on an original image x and P t (y|x) P (y|t(x)) on a transformed image t(x)</p><formula xml:id="formula_8">L CL = E x,t y P (y|x) log P (y|x) P t (y|x)<label>(5)</label></formula><p>to make consistent predictions under different transformations, where the expectation is taken over the sampled data and transformations. Furthermore, since we used MixMatch as our baseline of the framework, we use sharpened "guessed label" P (y|x) for original image x.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Overall Framework</head><p>We illustrate the framework of the proposed EnAET in <ref type="figure" target="#fig_0">Fig. 1</ref>. For each image x, we apply five different transformations: t 1 (Projective), t 2 (Affine), t 3 (Similarity), t 4 (Euclidean), t 5 (CCBS).</p><p>After that, the network is split into three parts: an representation encoder E, a classifier C, and a set of decoders D k each for a type of transformation t k . The original input x and all its transformed counterparts t k (x) are fed through the network. The original and transformed images have a Siamese encoder E and classifier C with shared weights.</p><p>As in the baseline MixMatch settings, we use Wide ResNet-28-2 network as our architecture. It consists of four blocks, and we use the last block as the classifier C, while the other three blocks constitute the encoder E. Also, all the decoders D k 's share the same network architecture as the classifier C but with different weights.</p><p>The representations of the original and transformed images will be concatenated to predict the parameters of each transformation t k by the corresponding decoder D k .</p><p>The classifier C is built upon the encoded representation to output the label predictions P (y|x) and P (y|t(x)) for both the original and transformed images, respectively. Following our baseline MixMatch, we used the sharpened "guessed label" as P (y|x). The label prediction of original image needs to be "sharpened" <ref type="bibr" target="#b51">[51]</ref> to reach a high degree of prediction confidence by minimizing the prediction entropy.</p><p>After splitting a network into Encoder E and Classifier C, we can then update the network with a linear combination of three losses: semi-supervised loss L SSL k , AET loss L AET k and consistency loss L CL k . Our framework can be illustrated in Algorithm 1. It is clear that our framework is independent of any semi-supervised learning algorithm. That is to say, for lines 1-2 in Algorithm 1, we can easily replace them with any SSL algorithms to apply the framework when new SSL methods are proposed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. SSL Baseline: MixMatch</head><p>MixMatch <ref type="bibr" target="#b40">[40]</ref> is the current state-of-the-art for the semisupervised classification task. It uses many ideas in previous approaches to build a new algorithm. Among them are Mixup <ref type="bibr" target="#b41">[41]</ref> by training a network with a convex combination of examples and their labels, as well as entropy minimization by sharpening the label predictions. In addition, a guessed label with data augmentation also contributes to more consistent label predictions.</p><p>Formally, Algorithm 1 in MixMatch <ref type="bibr" target="#b40">[40]</ref> mixes up a batch of labeled X and unlabeled U to obtain the mixed-up X , U . Then, it minimizes the following SSL loss L SSL to train its model,</p><formula xml:id="formula_9">     L X = E (x,y)∈X H(y, f (x, Θ)) L U = E (u,q)∈U ||f (u, Θ) − q|| 2 L SSL = L X + λ U L U<label>(6)</label></formula><p>where X and U are the labeled and unlabeled data resulting from MixMatch, H is the cross-entropy between two distributions, and q is the sharpened predictions on a unlabeled sample u for each (u, q) ∈ U .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Training Details</head><p>For a fair comparison with other SSL methods, we follow our baseline MixMatch setttings and use "Wide ResNet-28-2" as our backbone network and a "Wide ResNet-28-2" architecture with 135 filters per layer as our larger model, which we will refer to as "Wide ResNet-28-2-Large" in the following. This also follows the evaluation setup for the baseline methods in <ref type="bibr" target="#b59">[59]</ref>.</p><p>For our encoder E and C, We follow our baseline Mix-Match's setting and use the Adam solver <ref type="bibr" target="#b33">[33]</ref> with a learning rate of 0.002 to train. For decoder D k , the SGD optimizer is used with an initial learning rate of 0.1. Then we use a cosine <ref type="bibr" target="#b60">[60]</ref> scheduler for a learning rate decay from 0.1 to 0.0001. We also fix the weight decay rate to 5e-4.</p><p>As settings in <ref type="bibr" target="#b40">[40]</ref>, for all experiments, we use a batch size of 128 images. The model is trained for 1024 epochs. For the sake of fair comparison, the mean error rate of the last 20 models is reported . Also, we report the error variance based on 4 runs with different random seeds.</p><p>We also adopt the same hyper-parameter setup to minimize the MixMatch loss as in <ref type="bibr" target="#b40">[40]</ref>. The weight λ k of the AET loss is initialized to 1.0, 0.75, 0.5, 0.2, 0.05 for the four spatial transformations and the CCBS transformation, respectively, and we fix that for different datasets. The weight γ of the CL loss is also always set to 0.2 as an initial value, and we found it would not influence the overall performance too much, which only needs to be slightly adjusted if you want to transfer to more datasets. Like our baseline MixMatch <ref type="bibr" target="#b40">[40]</ref>, we use a warm-up strategy for the weights of these losses.</p><p>Finally, we also use the exponential moving average (EMA) <ref type="bibr" target="#b18">[18]</ref> in the experiments with a rate of 0.999.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Transformation Details</head><p>For spatial transformations, considering they can all be expressed by a matrix shown in Eq. (2), we use the same operation settings for all of them. For random rotation, we set the rotation degree from [−180°,180°]. For the translation factor, we randomly sample the translation from [-0.2,0.2] for both horizontal and vertical directions. Also, we sample the scaling factor from [0.8,1.2] to make the scaled image fall in a proper range. With the shearing factor, we limit the shearing in [−30°,30°] to make sure the image can still be recognized. For the projective factor, we set the translation factor for the 4 corners of an image in [-0.125,0.125] for both horizontal and vertical directions.</p><p>For non-spatial transformations, we randomly sample the magnitude for color, contrast, brightness and sharpness from [0.2,1.8] to keep the transformed images recognizable by human beings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. EnAET for Semi-Supervised Learning</head><p>To evaluate the proposed method, we perform semisupervised tasks on four datasets: CIFAR-10 and CIFAR-100 <ref type="bibr" target="#b65">[65]</ref>, SVHN <ref type="bibr" target="#b66">[66]</ref>, and STL-10 <ref type="bibr" target="#b67">[67]</ref>.</p><p>1) CIFAR-10 Results: For CIFAR-10, we evaluate the compared methods with different sizes of labeled data. The results are reported in <ref type="table" target="#tab_1">Table III</ref>. Experiments are conducted 4 times with different random seeds to test the stability of our method and we find out that our method's variance is very small when we only use 250 labels. Therefore, we report the variance based on 4 runs for 250 labels and do not further perform more experiments for other conditions.</p><p>The results show that the proposed framework outperforms all the state-of-the-art methods. For example, the proposed model achieves a 7.6% error rate with 250 labels compared with previous best rate of 11.08%, which is our baseline SSL algorithm. Here we reduced around relative 2.5% error rate compared to SSL baseline. Notably, we are the first to conduct experiments with only 50 labels and 100 labels, and achieve 16.45% and 9.35% error rates, respectively. It is worth noting that the proposed framework with 50 labels even outperforms most methods with 1, 000 labels.</p><p>2) CIFAR-100 Results: Different models are compared in <ref type="table" target="#tab_1">Table IV</ref> on CIFAR-100. The proposed EnAET achieves an error rate of 58.73% and 31.83% with only 1, 000 and 5, 000 labels. The performance of EnAET with 5, 000 labels is even better than other models with 10, 000 labels. Here we do not have our baseline experiments' information, but our advantage compared to previous SSL algorithms is very obvious.</p><p>3) SVHN Results: Compared with the previous methods, the proposed model achieves a new performance record on the SVHN dataset as shown in <ref type="table" target="#tab_1">Table VI</ref>. Notably, we are the first to test SVHN under 100 images and achieved 16.92% error rate, which is even better compared to some methods with 1, 000 labels. Compared to our baseline with very low error rate, we can still have around 0.5% accuracy improvement. 4) STL10 Results: STL-10 contains 5, 000 labeled images and 100, 000 unlabeled images and is specifically designed for semi-supervised task. Follow the same setting as baseline MixMatch, we achieve the best performance with 1, 000 and 5, 000 labeled images in <ref type="table" target="#tab_5">Table V</ref>. We reduce the error rate from 10.18% to 8.04% with 1, 000 labeled images, and set a record error rate of 4.52% when using all labeled data. 5) Performance of Wide ResNet-28-2-Large: Following the settings in MixMatch, we also evaluate our framework with larger architecture. The results on 3 different classical settings, we have clearly improved compared to our baseline MixMatch. For instance, we reduced error rate from 25.88% to 22.92% with around 3% improvement under CIFAR-100 with 10000 labels settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Supervised Learning</head><p>We also compare different models in the fully supervised setting on all dataset by using all labeled data. We show that the proposed framewrok can still achieve the best results with the same network architecture.</p><p>1) Wide ResNet-28-2 Backbone: We compare different methods by using Wide ResNet-28-2 as the backbone in Table VIII. It's clear our framwork can achieve best performance and can still have some improvement compared to MixMatch though we used all labels now.</p><p>2) Wide ResNet-28-2-Large Backbone: We also compare the proposed framework with the current state-of-the-art methods to demonstrate its remarkable performance in <ref type="table" target="#tab_1">Table IX</ref> though the architecture is less complex compared to other methods. Compared to baseline, we have improvment with a large margin. It is worth noting EnAET achieves the state of the art on CIFAR-10 with a less complicated architecture. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Ablation Study</head><p>We perform an ablation study of the proposed EnAET on CIFAR-10 and results are shown in <ref type="table">Table X</ref>. Specifically, we focus on the roles of different transformations and the different components in EnAET:</p><p>1) The ensemble of transformations can greatly contribute to the performance compared with any single transformation.</p><p>2) The consistency loss can not contribute much to the performance but can increase the training stability.</p><p>3) The AET loss regularization is the key to boosting the performance on top of the SSL baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>In this paper, we present EnAET, a novel framework that integrates the idea of self-trained representations into semisupervised learning models. Throughout our experiments, the proposed method outperforms the state-of-the-art methods on all the datasets by a significant margin and greatly boost the performance of the semi-supervised baselines. Moreover, with the same architecture, the proposed method can also greatly improve the supervised learning baselines. Furthermore, on many datasets, EnAET even performs better than ProxylessNAS, the auto-augmentation policy search with a less complicated architecture. In the future, we will employ policy search to find the best combination of transformations and their ranges, which we believe can lead to even more competitive results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>The Ensemble Auto Encoding Transformation Pipeline.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Spatial transformations. The images are original, projective transformation, affine transformation, similarity transformation, euclidean transformation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Non-spatial transformations. The images are original, color transformation, contrast transformation, brightness transformation,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>was with Department of Computer Science, Purdue University, West Lafayette, 47906, USA. D. Kihara was with Department of Computer Science and Department of Biological Sciences, Purdue University, West Lafayette, 47906, USA.</figDesc><table /><note>J. Luo was with University of Rochester, Rochester, 14627, USA.G-J. Qi was with was with the Futurewei Seattle Cloud Lab, Seattle, WA, 98006, USA. Email: guojunq@gmail.com. Manuscript received 1 June, 2020; revised 20 Oct, 2020; accepted xx.(Corresponding author: Guo-Jun Qi)</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I SPATIAL</head><label>I</label><figDesc>Algorithms of Ensemble AutoEncoding Transformations (EnAET).Require: a batch of labeled data pair X , unlabeled data U, the number of transformations in EnAET N , the balancing coefficients λ U , λ k , and γ.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">TRANSFORMATIONS.</cell></row><row><cell>Name</cell><cell>DOF</cell><cell></cell><cell></cell><cell>Matrix</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Effect</cell><cell>Property</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3"> a 1 a 2 b 1</cell><cell></cell><cell></cell><cell></cell><cell>Translation+Rotation</cell><cell>Lines map to lines</cell></row><row><cell>Projective</cell><cell>8</cell><cell></cell><cell cols="3"> a 3 a 4 b 2</cell><cell></cell><cell></cell><cell></cell><cell>+Scale+Aspect Ratio</cell><cell>Parallelism may not be maintained</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">c 1 c 2</cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell>+ Shear+Projective</cell><cell>Defined on the complement of line</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3"> a 1 a 2 b 1</cell><cell></cell><cell></cell><cell></cell><cell>Translation+Rotation</cell><cell>Preserves collinearity&amp;parallelism</cell></row><row><cell>Affine</cell><cell>6</cell><cell></cell><cell cols="3"> a 3 a 4 b 2</cell><cell></cell><cell></cell><cell></cell><cell>+Scale+Aspect Ratio</cell><cell>Preserves the ratio of distances</cell></row><row><cell></cell><cell></cell><cell></cell><cell>0</cell><cell>0</cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell>+ Shear</cell><cell>Does not preserve angles or lengths</cell></row><row><cell>Similarity</cell><cell>4</cell><cell cols="2">  a  *  cos(θ) sin(θ) 0</cell><cell cols="4">−sin(θ) a  *  cos(θ) b 2 b 1 0 1</cell><cell> </cell><cell>Translation +Rotation +Scale</cell><cell>Preserves collinearity&amp;parallelism Preserves general shape of objects Preserves angles of objects</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="4">cos(θ) −sin(θ) b 1</cell><cell></cell><cell></cell><cell>Preserves collinearity&amp;parallelism</cell></row><row><cell>Euclidean</cell><cell>3</cell><cell></cell><cell>sin(θ)</cell><cell cols="2">cos(θ)</cell><cell>b 2</cell><cell></cell><cell></cell><cell>Translation+Rotation</cell><cell>Preserves exact shape of objects</cell></row><row><cell></cell><cell></cell><cell></cell><cell>0</cell><cell>0</cell><cell></cell><cell>1</cell><cell></cell><cell></cell><cell>Preserves angles&amp;lengths of objects</cell></row><row><cell>Algorithm 1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>1: X , U = M ixM atch(X , U) Use Algorithm 1 in MixMatch [40]2: L SSL = L X + λ U * LU Calculate SSL loss (see Eq. (6))3: for k=1 to N do4:</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE II</head><label>II</label><figDesc></figDesc><table><row><cell></cell><cell>NON-SPATIAL TRANSFORMATIONS.</cell></row><row><cell>Transform</cell><cell>Description</cell></row><row><cell>Color</cell><cell>Adjusts color balance of image</cell></row><row><cell>Contrast</cell><cell>Adjusts difference of light pixels and dark pixels in image</cell></row><row><cell cols="2">Brightness Adds or subtracts to= image matrix to change brightness</cell></row><row><cell>Sharpness</cell><cell>Adjusts pixels to make image appear sharper</cell></row><row><cell cols="2">entire non-spatial transformation with four strength parameters</cell></row><row><cell cols="2">in EnAET. The effect of such a combined Color Contrast</cell></row><row><cell cols="2">Brightness Sharpness (CCBS) transformation is illustrated in</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE III ERROR</head><label>III</label><figDesc>RATES OF DIFFERENT MODELS ON CIFAR-10. 02±2.05 41.82±1.52 31.53±0.98 23.07±0.66 17.41±0.37 PseudoLabel [14] --49.98±1.17 40.55±1.70 30.91±1.73 21.96±0.42 16.21±0.11 MixUp [41] --47.43±0.92 36.17±2.82 25.72±0.66 18.14±1.06 13.15±0.20 VAT [13] --36.03±2.82 26.11±1.52 18.68±0.40 14.40±0.15 11.05±0.31</figDesc><table><row><cell>Methods/Labels</cell><cell>50</cell><cell>100</cell><cell>250</cell><cell>500</cell><cell>1000</cell><cell>2000</cell><cell>4000</cell></row><row><cell cols="8">Π-Model [16], [17] 53.MeanTeacher [18] ----47.32±4.71 42.01±5.86 17.32±4.00 12.17±0.22 10.36±0.25</cell></row><row><cell>MixMatch [40]</cell><cell>-</cell><cell>-</cell><cell>11.08±0.87</cell><cell>9.65±0.94</cell><cell>7.75±0.32</cell><cell>7.03±0.15</cell><cell>6.24±0.06</cell></row><row><cell>EnAET</cell><cell cols="2">16.45 9.35</cell><cell>7.6±0.34</cell><cell>7.27</cell><cell>6.95</cell><cell>6.00</cell><cell>5.35</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE IV</head><label>IV</label><figDesc></figDesc><table><row><cell cols="4">ERROR RATES OF DIFFERENT MODELS ON CIFAR-100.</cell></row><row><cell>Methods/Labels</cell><cell>1000</cell><cell>5000</cell><cell>10000</cell></row><row><cell>Supervised-only</cell><cell>-</cell><cell>-</cell><cell>51.21±0.33</cell></row><row><cell>Π-Model [17]</cell><cell>-</cell><cell>-</cell><cell>39.19±0.36</cell></row><row><cell>Temporal ensembling [16]</cell><cell>-</cell><cell>-</cell><cell>38.65±0.51</cell></row><row><cell>EnAET</cell><cell cols="3">58.73 31.83 26.93±0.21</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE V ERROR</head><label>V</label><figDesc>RATES OF DIFFERENT MODELS ON STL10.</figDesc><table><row><cell>Methods/Labels</cell><cell>1000</cell><cell>5000</cell></row><row><cell>CutOut [52]</cell><cell>-</cell><cell>12.74</cell></row><row><cell>IIC [53]</cell><cell>-</cell><cell>11.20</cell></row><row><cell>SWWAE [54]</cell><cell>25.70</cell><cell>-</cell></row><row><cell>CC-GAN 2 [55]</cell><cell>22.20</cell><cell>-</cell></row><row><cell>MixMatch [40]</cell><cell>10.18±1.46</cell><cell>5.59</cell></row><row><cell>EnAET</cell><cell>8.04</cell><cell>4.52</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE VI ERROR</head><label>VI</label><figDesc>RATES OF DIFFERENT MODELS ON SVHN. 16±0.88 14.35±0.37 10.19±0.41 7.54±0.27 5.71±0.07 MixUp [41] -39.97±1.89 29.62±1.54 16.79±0.63 10.47±0.48 7.96±0.14</figDesc><table><row><cell cols="2">Methods/Labels</cell><cell></cell><cell>100</cell><cell>250</cell><cell>500</cell><cell>1000</cell><cell>2000</cell><cell>4000</cell></row><row><cell cols="3">Π-Model [16], [17]</cell><cell>-</cell><cell cols="2">17.65±0.27 11.44±0.39</cell><cell>8.6±0.18</cell><cell>6.94±0.27</cell><cell>5.57±0.14</cell></row><row><cell cols="5">PseudoLabel [14] 21.VAT [13] --8.41±1.01</cell><cell>7.44±0.79</cell><cell>5.98±0.21</cell><cell>4.85±0.23</cell><cell>4.20±0.15</cell></row><row><cell cols="3">MeanTeacher [18]</cell><cell>-</cell><cell>6.45±2.43</cell><cell>3.82±0.17</cell><cell>3.75±0.10</cell><cell>3.51±0.09</cell><cell>3.39±0.11</cell></row><row><cell cols="2">MixMatch [40]</cell><cell></cell><cell>-</cell><cell>3.78±0.26</cell><cell>3.64±0.46</cell><cell>3.27±0.31</cell><cell>3.04±0.13</cell><cell>2.89±0.06</cell></row><row><cell cols="2">EnAET</cell><cell cols="2">16.92</cell><cell>3.21±0.21</cell><cell>3.05</cell><cell>2.92</cell><cell>2.84</cell><cell>2.69</cell></row><row><cell></cell><cell cols="2">TABLE VII</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">COMPARISON OF ERROR RATES WITH WIDE RESNET-28-2-LARGE.</cell><cell></cell><cell></cell></row><row><cell>Methods/Labels</cell><cell>CIFAR-10 4000 label</cell><cell cols="2">CIFAR-100 10000 label</cell><cell>SVHN 1000 label</cell><cell></cell><cell></cell></row><row><cell>Mean Teacher [18]</cell><cell>6.28</cell><cell>-</cell><cell></cell><cell>-</cell><cell></cell><cell></cell></row><row><cell>SWA [56]</cell><cell>5.00</cell><cell cols="2">28.80</cell><cell>-</cell><cell></cell><cell></cell></row><row><cell>Fast SWA [56]</cell><cell>5.0</cell><cell cols="2">28.0</cell><cell>-</cell><cell></cell><cell></cell></row><row><cell>MixMatch [40]</cell><cell cols="3">4.95±0.08 25.88±0.30</cell><cell>-</cell><cell></cell><cell></cell></row><row><cell>EnAET</cell><cell>4.18</cell><cell cols="2">22.92</cell><cell>2.42</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">TABLE VIII</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">ERROR RATES OF FULLY SUPERVISED MODELS WITH A WIDE</cell><cell></cell><cell></cell></row><row><cell cols="4">RESNET-28-2 BACKBONE.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Methods/Labels</cell><cell cols="4">CIFAR-10 CIFAR-100 SVHN</cell><cell></cell><cell></cell></row><row><cell>Baseline [57]</cell><cell>5.1</cell><cell cols="2">24.6</cell><cell>3.3</cell><cell></cell><cell></cell></row><row><cell>AutoAugment [58]</cell><cell>4.1</cell><cell cols="2">21.5</cell><cell>1.7</cell><cell></cell><cell></cell></row><row><cell>MixMatch [40]</cell><cell>4.13</cell><cell></cell><cell>-</cell><cell>2.59</cell><cell></cell><cell></cell></row><row><cell>EnAET</cell><cell>3.55</cell><cell cols="2">20.55</cell><cell>2.48</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE IX ERROR</head><label>IX</label><figDesc>RATES OF FULLY SUPERVISED MODELS WITH WIDE RESNET-28-2-LARGE.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>TABLE X</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">ABLATION STUDY OF ENAET ON CIFAR-10.</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Ablation</cell><cell>250labels</cell></row><row><cell></cell><cell></cell><cell></cell><cell>EnAET</cell><cell>7.64</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Only Projective Transformation</cell><cell>9.96</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Only Affine Transformation</cell><cell>8.12</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Only Similarity Transformation</cell><cell>10.25</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Only Euclidean Transformation</cell><cell>10.56</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Only CCBS Transformation</cell><cell>15.34</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Remove CL loss</cell><cell>8.39</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Remove AET loss</cell><cell>13.54</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Baseline: MixMatch</cell><cell>11.08</cell></row><row><cell>Methods/Labels</cell><cell cols="3">CIFAR-10 CIFAR-100 SVHN</cell></row><row><cell>Baseline [57]</cell><cell>3.9</cell><cell>18.8</cell><cell>3.1</cell></row><row><cell>AutoAugment [58]</cell><cell>2.6</cell><cell>17.1</cell><cell>1.9</cell></row><row><cell>PBA [61]</cell><cell>2.6</cell><cell>16.7</cell><cell>-</cell></row><row><cell>Fast AA [62]</cell><cell>2.7</cell><cell>17.3</cell><cell>-</cell></row><row><cell>EnAET</cell><cell>1.99</cell><cell>16.87</cell><cell>2.22</cell></row><row><cell>ProxylessNAS [63]</cell><cell>2.08</cell><cell>-</cell><cell>-</cell></row><row><cell>CutMix [64]</cell><cell>2.88</cell><cell>13.81</cell><cell>-</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Hierarchically gated deep networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-J</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2267" to="2275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Online multi-label active annotation: towards large-scale content-based video search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-S</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-J</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th ACM international conference on Multimedia</title>
		<meeting>the 16th ACM international conference on Multimedia</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="141" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-J</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-S</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Rui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-J</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Correlative multilabel video annotation with temporal kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM)</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Semi-supervised learning (chapelle</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Scholkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<editor>o. et al.</editor>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="542" to="542" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note>book reviews</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Semi-supervised learning by entropy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Grandvalet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="529" to="536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Multimodal curriculum learning for semi-supervised image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Maybank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3249" to="3260" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Semi-supervised deep learning using pseudo labels for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Prasad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1259" to="1270" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Auto-weighted multi-view learning for image clustering and semi-supervised classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1501" to="1511" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Global versus localized generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-J</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Edraki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-S</forename><surname>Hua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1517" to="1525" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Recommending flickr groups with social topic model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information retrieval</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="278" to="295" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An adversarial approach to hard triplet generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-S</forename><surname>Hua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="501" to="517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Virtual adversarial training: a regularization method for supervised and semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ishii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="1979" to="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Challenges in Representation Learning, ICML</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep, big, simple neural nets for handwritten digit recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Cireşan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>Gambardella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3207" to="3220" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Temporal ensembling for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Regularization with stochastic transformations and perturbations for deep semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sajjadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Javanmardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tasdizen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1163" to="1171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Valpola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1195" to="1204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Label information guided graph construction for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on image processing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4182" to="4192" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Improving dataset volumes and model accuracy with semi-supervised iterative selflearning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dupre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fajtl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Argyriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Remagnino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Scalable multi-view semisupervised classification via adaptive regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4283" to="4296" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Word representations: a simple and general method for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Turian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th annual meeting of the association for computational linguistics</title>
		<meeting>the 48th annual meeting of the association for computational linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="384" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Weaklyand semi-supervised learning of a deep convolutional network for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">P</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1742" to="1750" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Not-so-supervised: a survey of semi-supervised, multi-instance, and transfer learning in medical image analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Cheplygina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>De Bruijne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Pluim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical image analysis</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="280" to="296" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Aet vs. aed: Unsupervised representation learning by auto-encoding transformations rather than data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-J</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2547" to="2555" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9729" to="9738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Avt: Unsupervised learning of transformation equivariant representations by autoencoding variational transformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-J</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Transforming autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="44" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Unsupervised representation learning by predicting image rotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=S1v4N2l0-" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Semi-supervised learning with ladder networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rasmus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Berglund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Honkala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Valpola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Raiko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3546" to="3554" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Small data challenges in big data era: A survey of recent progress on unsupervised and semi-supervised methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-J</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.11260</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Joint intermodal and intramodal label transfers for extremely rare or unseen classes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-J</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1360" to="1373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Semisupervised learning with deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3581" to="3589" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning disentangled representations with semi-supervised deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Narayanaswamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">B</forename><surname>Paige</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-W</forename><surname>Van De Meent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5925" to="5935" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Auxiliary deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Maaløe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Winther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd International Conference on International Conference on Machine Learning</title>
		<meeting>the 33rd International Conference on International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="1445" to="1454" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Ladder variational autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Raiko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Maaløe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Winther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3738" to="3746" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Improved techniques for training gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2234" to="2242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Denoising source separation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Särelä</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Valpola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="233" to="272" />
			<date type="published" when="2005-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Mixmatch: A holistic approach to semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5050" to="5060" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">mixup: Beyond empirical risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Interpolation consistency training for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kannala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 28th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3635" to="3641" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Unsupervised learning of visual representations by solving jigsaw puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Noroozi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Favaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="69" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Unsupervised visual representation learning by context prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1422" to="1430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Representation learning by learning to count</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Noroozi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pirsiavash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Favaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5898" to="5906" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Discriminative unsupervised feature learning with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="766" to="774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Learning to see by moving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="37" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Learning generalized transformation equivariant representations via autoencoding transformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-J</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Theory and practice of projective rectification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">I</forename><surname>Hartley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="115" to="127" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Contractive auto-encoders: Explicit invariance during feature extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rifai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on International Conference on Machine Learning</title>
		<meeting>the 28th International Conference on International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>Omnipress</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="833" to="840" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Improved regularization of convolutional neural networks with cutout</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.04552</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Invariant information clustering for unsupervised image classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9865" to="9874" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Stacked what-where auto-encoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Goroshin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Semi-supervised learning with context-conditional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Denton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.06430</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">There are many consistent explanations of unlabeled data: Why you should average</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Athiwaratkun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Finzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Izmailov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Wilson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Wide residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Autoaugment: Learning augmentation strategies from data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="113" to="123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Realistic evaluation of deep semi-supervised learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3235" to="3246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Sgdr: Stochastic gradient descent with warm restarts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Population based augmentation: Efficient learning of augmentation policy schedules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Stoica</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2731" to="2741" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Fast autoaugment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6662" to="6672" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Proxylessnas: Direct neural architecture search on target task and hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Cutmix: Regularization strategy to train strong classifiers with localizable features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6023" to="6032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Citeseer, Tech. Rep</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Reading digits in natural images with unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">An analysis of single-layer networks in unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourteenth international conference on artificial intelligence and statistics</title>
		<meeting>the fourteenth international conference on artificial intelligence and statistics</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="215" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">He is currently pursuing his Ph.D. degree in the Department of</title>
	</analytic>
	<monogr>
		<title level="m">His research interests include deep learning, computer vision, bioinformatics and intelligent systems</title>
		<meeting><address><addrLine>Xi&apos;an, China; West Lafayette, IN, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
		<respStmt>
			<orgName>Xiao Wang Xiao Wang received his B.S. degree from Department of Computer Science in Xi&apos;an Jiaotong University ; Computer Science at Purdue University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">degree from Kyoto University, Japan in 1996 and 1999, respectively. His research area is protein bioinformatics, which include protein structure, docking, and function prediction</title>
		<editor>1994, M.S. and Ph.D.</editor>
		<imprint>
			<date type="published" when="2013" />
			<pubPlace>West Lafayette, Indiana, USA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Daisuke Kihara Daisuke Kihara is professor of Department of Biological Sciences and Department of Computer Science at Purdue University ; He is named Showalter University Faculty Scholar from Purdue University</orgName>
		</respStmt>
	</monogr>
	<note>He has received B.S. degree from University of Tokyo</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">His research interests include computer vision, NLP, machine learning, data mining, computational social science, and digital health</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiebo Luo Jiebo</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE CVPR 2012, ACM ICMR 2016, and IEEE ICIP 2017, as well as a general co-chair of ACM Multimedia 2018. He has served on the editorial boards of the IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), IEEE Transactions on Multimedia (TMM), IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), IEEE Transactions on Big Data (TBD), ACM Transactions on Intelligent Systems and Technology (TIST), Pattern Recognition, Knowledge and Information Systems (KAIS), Machine Vision and Applications, and Journal of Electronic Imaging. He is the current Editor-in-Chief of the IEEE Transactions on Multimedia</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note>S93, M96, SM99, F09) is a Professor of Computer Science at the University of Rochester which he joined in 2011 after a prolific career of fifteen years at Kodak Research Laboratories. He has authored nearly 500 technical papers and holds over 90 U.S. patents. Professor Luo is also a Fellow of ACM, AAAI, SPIE, and IAPR</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">His research interests include machine learning and knowledge discovery from multi-modal data sources to build smart and reliable information and decision-making systems. Dr. Qi has published more than 100 papers in a broad range of venues in pattern recognition, machine learning and computer vision. He also has served or will serve as a general co-chair for ICME 2021, technical program co-chair for ACM Multimedia 2020, ICIMCS 2018 and MMM 2016, as well as an area chair (senior program committee member) for multiple academic conferences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guo-Jun Qi Guo-Jun</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Dr. Qi is an associate editor for IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), IEEE Transactions on Multimedia (T-MM), IEEE Transactions on Image Processing</title>
		<editor>T.J. Watson Research Center</editor>
		<meeting><address><addrLine>Yorktown Heights, NY</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-08" />
		</imprint>
	</monogr>
	<note>Pattern Recognition (PR), and ACM Transactions on Knowledge Discovery from Data (T-KDD)</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
