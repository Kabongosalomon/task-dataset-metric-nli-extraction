<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SGAS: Sequential Greedy Architecture Search https://www.deepgcns.org/auto/sgas</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guohao</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">King Abdullah University of Science and Technology (KAUST)</orgName>
								<address>
									<country key="SA">Saudi Arabia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guocheng</forename><surname>Qian</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">King Abdullah University of Science and Technology (KAUST)</orgName>
								<address>
									<country key="SA">Saudi Arabia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Itzel</forename><forename type="middle">C</forename><surname>Delgadillo</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">King Abdullah University of Science and Technology (KAUST)</orgName>
								<address>
									<country key="SA">Saudi Arabia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>MÃ¼ller</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Intelligent Systems Lab</orgName>
								<orgName type="institution">Intel Labs</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Thabet</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">King Abdullah University of Science and Technology (KAUST)</orgName>
								<address>
									<country key="SA">Saudi Arabia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Ghanem</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">King Abdullah University of Science and Technology (KAUST)</orgName>
								<address>
									<country key="SA">Saudi Arabia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SGAS: Sequential Greedy Architecture Search https://www.deepgcns.org/auto/sgas</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T21:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Architecture design has become a crucial component of successful deep learning. Recent progress in automatic neural architecture search (NAS) shows a lot of promise. However, discovered architectures often fail to generalize in the final evaluation. Architectures with a higher validation accuracy during the search phase may perform worse in the evaluation (see <ref type="figure">Figure 1</ref>). Aiming to alleviate this common issue, we introduce sequential greedy architecture search (SGAS), an efficient method for neural architecture search. By dividing the search procedure into subproblems, SGAS chooses and prunes candidate operations in a greedy fashion. We apply SGAS to search architectures for Convolutional Neural Networks (CNN) and Graph Convolutional Networks (GCN). Extensive experiments show that SGAS is able to find state-of-the-art architectures for tasks such as image classification, point cloud classification and node classification in protein-protein interaction graphs with minimal computational cost. arXiv:1912.00195v2 [cs.</p><p>LG] 2 Apr 2020 chitecture search. However, despite their success, current approaches still have a lot of limitations. During the search phase, network architectures are usually constructed from basic building blocks and evaluated on a validation set. Due to computational cost, the size of considered architectures is limited. In the evaluation phase, the best building blocks are used to construct larger architectures and they are evaluated on the test set. As a result there is a large discrepancy between the validation accuracy during search and the test accuracy during evaluation. In this work, we propose a novel greedy architecture search algorithm, SGAS, which addresses this discrepancy and searches very efficiently.</p><p>Contributions. Our contributions can be summarized as the following: (1) We propose SGAS, a greedy approach for neural architecture search with high correlation between the validation accuracy during the search phase and the final evaluation accuracy.</p><p>(2) Our method discovers topperforming architectures with much less search cost than previous state-of-the-art methods such as DARTS.</p><p>(3) Our proposed method is able to search architectures for both CNNs and GCNs across various datasets and tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Deep learning has revolutionized computer vision by learning features directly from data. As a result deep neural networks have achieved state-of-the-art results on many difficult tasks such as image classification <ref type="bibr" target="#b12">[13]</ref>, object detection <ref type="bibr" target="#b31">[32]</ref>, object tracking <ref type="bibr" target="#b38">[39]</ref>, semantic segmentation <ref type="bibr" target="#b10">[11]</ref>, depth estimation <ref type="bibr" target="#b15">[16]</ref> and activity understanding <ref type="bibr" target="#b6">[7]</ref>, to name just a few examples. While there was a big emphasis on feature engineering before deep learning, the focus has now shifted to architecture engineering. In particular many novel architectures have been proposed, such as LeCun <ref type="bibr" target="#b27">[28]</ref>, AlexNet <ref type="bibr" target="#b26">[27]</ref>, VGG <ref type="bibr" target="#b46">[47]</ref>, GoogLeNet <ref type="bibr" target="#b48">[49]</ref>, ResNet <ref type="bibr" target="#b18">[19]</ref>, DenseNet <ref type="bibr" target="#b21">[22]</ref>, ResNeXt <ref type="bibr" target="#b56">[57]</ref> and SENet <ref type="bibr" target="#b20">[21]</ref>. Results on each of the above mentioned tasks keep improving every year by innovations in architecture design. In essence, the community has shifted from feature engineering to architecture engineering. * equal contribution In recent years, many efforts have been made to reduce the manual intervention required to obtain better models for a particular task. As a matter of fact, a new area of research, commonly referred to as meta-learning, has emerged in order to tackle such problems. The idea of metalearning is to leverage prior experience in order to quickly find good algorithm configurations, network architectures and any required parameters for a new learning task. Examples of recent meta-learning approaches include automatic hyper-parameter search <ref type="bibr" target="#b14">[15]</ref>, data-augmentation <ref type="bibr" target="#b11">[12]</ref>, finding novel optimizers <ref type="bibr" target="#b1">[2]</ref> and architecture search <ref type="bibr" target="#b64">[65]</ref>. In particular, architecture search has sparked a lot of interest in the community. In this task, the search space is huge and manual search is prohibitive.</p><p>Early work by Zoph et al. <ref type="bibr" target="#b64">[65]</ref>, based on Reinforcement Learning, has shown very promising results. However, its high computational cost has prevented widespread adoption. Recently, differentiable architecture search (DARTS) <ref type="bibr" target="#b34">[35]</ref> has been proposed as an alternative which makes architecture search differentiable and much more efficient. This has opened up a path towards computationally feasible ar-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>In the past, considerable success was achieved with hand-crafted architectures. One of the earliest successful architectures was LeNet <ref type="bibr" target="#b27">[28]</ref>, a very simple convolutional neural network for optical character recognition. Other prominent networks include AlexNet <ref type="bibr" target="#b26">[27]</ref>, VGG <ref type="bibr" target="#b46">[47]</ref> and GoogLeNet <ref type="bibr" target="#b48">[49]</ref> which revolutionized computer vision by outperforming all previous approaches in the ImageNet <ref type="bibr" target="#b12">[13]</ref> challenge by a large margin. ResNet <ref type="bibr" target="#b18">[19]</ref> and DenseNet <ref type="bibr" target="#b21">[22]</ref> were further milestones in architecture design. They showed the importance of residual and dense connections for designing very deep networks, an insight that influences modern architecture design to this day. Until recently, architecture innovations were a result of human insight and experimentation. The first successful attempts for architecture search were using reinforcement learning <ref type="bibr" target="#b64">[65]</ref> and evolutionary algorithms <ref type="bibr" target="#b42">[43]</ref>. These works were extended with NASNet <ref type="bibr" target="#b65">[66]</ref> where a new cell-based search space and regularization technique were proposed. Another extension, ENAS <ref type="bibr" target="#b39">[40]</ref>, represents the entire search space as a single directed acyclic graph. A controller discovers architectures by searching for subgraphs that maximize the expected reward on the validation set. This setup allows for parameter sharing between child models making search very efficient. Further, PNAS <ref type="bibr" target="#b32">[33]</ref> introduced a sequential modelbased optimization (SMBO) strategy in order to search for structures of increasing complexity. PNAS needs to evaluate 5 times less models and reduces the computational cost by a factor of 8 compared to NASNet. Yet, PNAS still requires thousands of GPU hours. One shot approaches <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b7">8]</ref> further reduce the search time by training a single over-parameterized network with inherited/shared weights. In order to search in a continuous domain <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b52">53]</ref>, DARTS <ref type="bibr" target="#b34">[35]</ref> proposes a continuous relaxation of the architecture representation, making architecture search differentiable and hence much more efficient. As a result, DARTS is able to find good convolutional architectures at a fraction of the computational cost making NAS broadly accessible. Owed to the large success of DARTS, several extensions have been proposed recently. SNAS <ref type="bibr" target="#b57">[58]</ref> optimizes parameters of a joint distribution for the search space in a cell. The authors propose a search gradient which optimizes the same objective as RL-based NAS, but leads to more efficient structural decisions. P-DARTS <ref type="bibr" target="#b8">[9]</ref> attempts to overcome the depth gap issue between search and evaluation. This is accomplished by increasing the depth of searched architectures gradually during the training procedure. PC-DARTS <ref type="bibr" target="#b60">[61]</ref> leverages the redundancy in network space and only samples a subset of channels in super-net during search to reduce computation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Preliminary -DARTS</head><p>By reducing the search problem to searching for the best cell structure, cell-based NAS methods <ref type="bibr" target="#b65">[66,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b42">43]</ref> are able to learn scalable and transferable architectures. The networks are composed of layers with identical cell structure but different weights. A cell is usually represented as a directed acyclic graph (DAG) with N nodes including two input nodes, several intermediate nodes and a single output node. Each node is a latent representation denoted as x (i) , where i is its topological order in the DAG. Each directed edge (i, j) in the DAG is associated with an operation o (i,j) that transfers the information from node x (i) to node x (j) . In Differentiable Architecture Search (DARTS) <ref type="bibr" target="#b34">[35]</ref> and its variants <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b17">18]</ref>, the optimal architecture is derived from a discrete search space by relaxing the selection of operations to a continuous optimization problem. During the search phase, the operation of each edge is parameterized by architectural parameters Î± (i,j) as a softmax mixture over all the possible operations within the operation space</p><formula xml:id="formula_0">O, i.e. o (i,j) (x (i) ) = oâO exp(Î± (i,j) o ) o âO exp(Î± (i,j) o )</formula><p>o(x (i) ). The input nodes are represented by the outputs from the previous two cells. Each intermediate node aggregates information flows from all of its predecessors, x (j) = i&lt;jÅ (i,j) (x (i) ). The output node is defined as a concatenation of a fixed number of its predecessors. The learning procedure of architectural parameters involves a bi-level optimization problem: </p><formula xml:id="formula_1">min A L val (W * (A), A)<label>(1)</label></formula><formula xml:id="formula_2">s.t. W * (A) = argmin W L train (W, A)<label>(2)</label></formula><formula xml:id="formula_3">i â  , j â  ) by replacingÅ (i â  ,j â  ) with o (i â  ,j â  ) = argmax oâO Î± (i â  ,j â  ) o .</formula><p>The corresponding architectural parameter Î± (i â  ,j â  ) will be removed from the bi-level optimization. Operations which were not chosen in a mixture operation will be pruned. At the end of the search phase, a stand-alone architecture without weight sharing will be obtained.</p><p>L train and L val denote the training and validation loss respectively. Owing to the continuous relaxation, the search is realized by optimizing a supernet. W is the set of weights of the supernet and A is the set of the architectural parameters. DARTS <ref type="bibr" target="#b34">[35]</ref> proposed to solve this bi-level problem by a first/second order approximation. At the end of the search, the final architecture is derived by selecting the operation with highest weight for every mixture operation,</p><formula xml:id="formula_4">o (i,j) = argmax oâO Î± (i,j) o .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Search-Evaluation Correlation</head><p>A popular pipeline of existing NAS algorithms <ref type="bibr" target="#b65">[66,</ref><ref type="bibr" target="#b34">35]</ref> includes two stages: a search phase and an evaluation phase. In order to reduce computational overhead, previous works <ref type="bibr" target="#b65">[66,</ref><ref type="bibr" target="#b34">35]</ref> first search over a pre-defined search space with a lightweight proxy model on a small proxy dataset. After the best architecture cell/encoding is obtained, the final architecture is built and trained from scratch on the target dataset. This requires that the true performance during evaluation can be inferred during the search phase. However, this assumption usually does not hold due to the discrepancy in dataset, hyper-parameters and network architectures between the search and evaluation phases. The best ranking derived from the search phase does not imply the actual ranking in the final evaluation. In practice, the correlation between the performances of derived architectures during the search and evaluation phases is usually low. In this paper, we refer to this issue as degenerate search-evaluation correlation. Recent work by Sciuto et al. <ref type="bibr" target="#b44">[45]</ref> also analyzes this issue and suggests that the Kendall Ï metric <ref type="bibr" target="#b23">[24]</ref> could be used to evaluate the search phase. They show that the widely used weight sharing technique actually decreases the correlation. The Kendall Ï metric <ref type="bibr" target="#b23">[24]</ref> is a common measurement of the correlation between two rankings. The Kendall Ï coefficient can be computed as Ï = NcâN d 1 2 n(nâ1) , where N c and N d are the number of concordant pairs and the number of discordant pairs respectively. It is a number in the range from â1 to 1 where â1 corresponds to a perfect negative correlation and 1 to a perfect positive correlation. If the Kendall Ï coefficient is 0, the rankings are completely independent. An ideal NAS method should have a high search-evaluation Kendall Ï coefficient. We take DARTS <ref type="bibr" target="#b34">[35]</ref> as an example and show its Kendall Ï in <ref type="figure" target="#fig_0">Figure 1</ref>. It is calculated between the rankings during search phase and evaluation phase. The rankings are determined according to the validation accuracy and the final evaluation accuracy after 10 different runs on the CIFAR-10 dataset. The Kendall Ï coefficients for DARTS are only 0.16 and â0.29 for the 1st-order and 2nd-order versions respectively. Therefore, it is impossible to make reliable predictions regarding the final test accuracy based on the search phase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Sequential Greedy Architecture Search</head><p>In order to alleviate the degenerate search-evaluation correlation problem, the core aspects are to reduce (1) the discrepancy between the search and evaluation phases and (2) the negative effect of weight sharing. We propose to solve the bi-level optimization (Equation 1, 2) in a sequential greedy fashion to reduce the model discrepancy and the weight sharing progressively. As mentioned in Section 3.1, DARTS-based methods <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b60">61]</ref> solve the relaxed problem fully and obtain all the selected operations at the end. Instead of solving the complete problem directly, we divide it into sub-problems and solve them sequentially with a greedy algorithm. The sub-problems are defined based on the directed edges in the DAG. We pick the operation </p><formula xml:id="formula_5">(i â  ,j â  ) with o (i â  ,j â  ) = argmax oâO Î± (i â  ,j â  ) o</formula><p>Prune unchosen weights from W, Remove Î± (i â  ,j â  ) from A Derive the final architecture based on chosen operations for edges greedily in a sequential manner and solve the remaining sub-problem iteratively. The iterative procedure is shown in Algorithm 1. At each decision epoch, we choose one edge (i â  , j â  ) according to a pre-defined selection criterion. A greedy optimal choice is made for the selected edge by replacing the corresponding mixture operationÅ</p><formula xml:id="formula_6">(i â  ,j â  ) with o (i â  ,j â  ) = argmax oâO Î± (i â  ,j â  ) o</formula><p>. The architectural parameters Î± (i â  ,j â  ) and the weights of the remaining paths within the mixture operations are no longer needed; we prune and exclude them from the latter optimization. As a side benefit, the efficiency improves as parameters in A and W are pruned gradually in the optimization loop. The search procedure of the remaining A and W forms a new sub-problem which will be solved iteratively. At the end of the search phase, a stand-alone network without weight sharing is obtained, as illustrated in <ref type="figure" target="#fig_1">Figure 2</ref>. Therefore, the model discrepancy is minimized and the validation accuracy during the search phase reflects the final evaluation accuracy much better. To maintain the optimality, the design of the selection criterion is crucial. We consider three aspects of edges which are the edge importance, the selection certainty and the selection stability.</p><p>Edge Importance. Similar to DARTS <ref type="bibr" target="#b34">[35]</ref>, a zero operation is included in the search space to indicate a lack of connection. Edges that are important should have a low weight in the zero operation. Thus, the edge importance is defined as the summation of weights over non-zero operations:</p><formula xml:id="formula_7">S (i,j) EI = oâO,o =zero exp(Î± (i,j) o ) o âO exp(Î± (i,j) o ) (3)</formula><p>Selection Certainty. Entropy is a common measurement of uncertainty of a distribution. The normalized softmax weights of non-zero operations can be regarded as a distribution, p</p><formula xml:id="formula_8">(i,j) o = exp(Î± (i,j) o ) S (i,j) EI o âO exp(Î± (i,j) o ) , o â O, o = zero.</formula><p>We define the selection certainty as the complement of the normalized entropy of the operation distribution:</p><formula xml:id="formula_9">S (i,j) SC = 1 â â oâO,o =zero p (i,j) o log(p (i,j) o ) log(|O| â 1)<label>(4)</label></formula><p>Selection Stability. In order to incorporate the history information, we measure the movement of the operation distribution. KullbackLeibler divergence and histogram intersection <ref type="bibr" target="#b47">[48]</ref> are two popular methods to detect changes in distribution. For simplicity, we choose the latter one. The average selection stability at step T with a history window size K is computed as follows:</p><formula xml:id="formula_10">S (i,j) SS = 1 K T â1 t=T âK otâOot, =zero min(p (i,j) ot , p (i,j) o T ) (5)</formula><p>In our experiments, we consider the following two criteria:</p><formula xml:id="formula_11">Criterion 1. An edge (i â  , j â  ) with a high edge importance S (i,j)</formula><p>EI and a high selection certainty S (i,j) SC will be selected. We normalize S (i,j) EI and S (i,j) SC , compute the final score and pick the edge with the highest score:</p><formula xml:id="formula_12">S (i,j) 1 = normalize(S (i,j) EI ) * normalize(S (i,j) SC ) (6)</formula><p>Criterion 2. In addition to Criterion 1, we also consider that the selected edge (i â  , j â  ) should have a high selection stability. The final score is defined as follows:</p><formula xml:id="formula_13">S (i,j) 2 = S (i,j) 1 * normalize(S (i,j) SS )<label>(7)</label></formula><p>where normalize(Â·) denotes a standard Min-Max scaling normalization. For a fair comparison with existing works <ref type="bibr" target="#b64">[65,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b34">35]</ref>, two incoming edges are preserved for every intermediate node in the DAG. Once a node has two determined incoming edges, its other incoming edges will be pruned. We refer to our method as Sequential Greedy Architecture Search (SGAS). <ref type="figure" target="#fig_0">Figure 1</ref> shows that SGAS with Criterion 1 and 2 improves the Kendall Ï correlation coefficients to 0.56 and 0.42 respectively. As expected from the much higher search-evaluation correlation SGAS outperform DARTS in terms of average accuracy significantly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>We use our SGAS to automatically find architectures for both CNNs and GCNs. The CNN architectures discovered by SGAS outperform the state-of-the-art (SOTA) in image classification on CIFAR-10 <ref type="bibr" target="#b25">[26]</ref> and ImageNet <ref type="bibr" target="#b12">[13]</ref>. Similarly, the discovered GCN architectures outperform the state-of-the-art methods for point cloud classification on ModelNet <ref type="bibr" target="#b55">[56]</ref> and node classification in biological graphs using the PPI <ref type="bibr" target="#b63">[64]</ref> dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Searching CNN architectures with SGAS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Architecture Search on CIFAR-10</head><p>As is common practice, we first search for normal cells and reduction cells with a small network for image classification on CIFAR-10. CIFAR-10 is a small popular dataset containing 50K training images and 10K testing images. Then, a larger network is constructed by making necessary changes in channel size and stacking the searched cells multiple times. The larger network is retrained on CIFAR-10 to compare its performance with other state-of-the-art methods. Finally, we show the transferability of our SGAS by stacking even more cells and evaluating on ImageNet. We show that SGAS consistently achieves the top performance.</p><p>Search Space. We keep our search space the same as DARTS, which has 8 candidate operations: skip-connect, max-pool-3Ã3, avg-pool-3Ã3, sep-conv-3Ã3, sep-conv-5Ã5, dil-conv-3Ã3, dil-conv-5Ã5, zero. During the search phase, we stack 6 normal cells and 2 reduction cells to form a network. Two reduction cells are inserted at a network depth of 1/3 and 2/3 respectively. The stride of each convolution in normal cells is 1, so the spatial size of an input feature map does not change. In reduction cells, convolutions with stride 2 are used to reduce the spatial resolution of feature maps. There are 7 nodes with 4 intermediate nodes and 14 edges in each cell during search. The first and second input nodes of the cell are set equal to the outputs of the two previous cells respectively. The output node of a cell is the depth-wise concatenation of all the intermediate nodes.</p><p>Training Settings. We keep the training setting the same as in DARTS <ref type="bibr" target="#b34">[35]</ref>. A small network consisting of 6 normal cells and 2 reduction cells with an initial channel size 16 is trained on CIFAR-10. We perform architecture search for 50 epochs with a batch size of 64. SGD is used to optimize the model weights W with an initial learning rate 0.025, momentum 0.9 and weight decay 3 Ã 10 â4 . For architecture parameters A, the Adam optimizer with an initial learning rate 3 Ã 10 â4 , momentum (0.5, 0.999) and weight decay 10 â3 is used. Instead of training the entire supernet throughout the search phase, SGAS makes decisions sequentially in a greedy fashion. After warming up for 9 epochs, SGAS begins to select one operation for one se-lected edge every 5 epochs using Criterion 1 or Criterion 2 as the selection criterion. For Criterion 2, we set the history window size K to 4. The batch size is increased by 8 after each greedy decision, which further boosts the searching efficiency of SGAS. We provide a thorough discussion and ablation study on the choices of hyper-parameters in the supplement material. The search takes only 0.25 day (6 hours) on a single NVIDIA GTX 1080Ti.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Architecture Evaluation on CIFAR-10</head><p>We run 10 independent searches to get 10 architectures with Criterion 1 or Criterion 2, as shown in <ref type="figure" target="#fig_0">Figure 1</ref>. To highlight the stability of the search method, we evaluate the discovered architectures on CIFAR-10 and report the mean and standard deviation of the test accuracy across those 10 models and the performance of the best model in <ref type="table" target="#tab_0">Table 1</ref>. It is important to mention that other related works in <ref type="table" target="#tab_0">Table 1</ref> only report the mean and standard deviation for their best architecture with different runs on evaluation. Training Settings. We train a large network of 20 cells with a initial channel size 36. The SGD optimizer is used during 600 epochs with a batch size of 96. The other hyperparameters remain the same as the search phase. Cutout with length 16, auxiliary towers with weight 0.4 and path dropout with probability 0.3 are used as in DARTS <ref type="bibr" target="#b34">[35]</ref>. Evaluation Results and Analysis. We compare our results with other methods in <ref type="table" target="#tab_0">Table 1</ref> and report the average and best performance for both Criterion 1 and Criterion 2. We outperform our baseline DARTS by a significant margin with test errors of 2.39% and 2.44% respectively while only using 0.25 day (6 hours) on a single NVIDIA GTX 1080Ti.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Architecture Evaluation on ImageNet</head><p>The architecture evaluation on ImageNet uses the cell architectures that we obtained after searching on CIFAR-10. Training Settings. We choose the 3 best performing cell architectures on CIFAR-10 for each Criterion and train them on ImageNet. For this evaluation, we build a large network with 14 cells and 48 initial channels and train for 250 epochs with a batch size of 1024. The SGD optimizer with an initial learning rate of 0.5, a momentum of 0.9 and a weight decay of 3 Ã 10 â5 is used. We run these experiments on 8 Nvidia Tesla V100 GPUs for three days. Evaluation Results and Analysis. In <ref type="table">Table 2</ref> we compare our models with SOTA hand-crafted architectures (manual) and models obtained through other search methods. We apply the mobile setting for ImageNet, which has an image size of 224 Ã 224 and restricts the number of multi-add operations to 600M . Our best performing models SGAS (Cri.1 best) and SGAS (Cri.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Searching GCN architectures with SGAS</head><p>Recently, GCNs have achieved impressive performance on point cloud segmentation <ref type="bibr" target="#b29">[30]</ref>, biological graph node classification <ref type="bibr" target="#b28">[29]</ref> and video recognition <ref type="bibr" target="#b59">[60]</ref> by training DeepGCNs <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b28">29]</ref>. However, this hand-crafted architecture design requires adequate effort by an human expert. The main component of DeepGCNs is the GCN backbone. We explore an automatic way to design the GCN backbone using SGAS. Our backbone network is formed by stacking the graph convolutional cell discovered by SGAS. Our GCN cell consists of 6 nodes. We use fixed 1 Ã 1 convolutions in the first two nodes, and set the input to them equal to the output from the previous two layers. Our experiments on GCNs have two stages. First, we apply SGAS to search for the graph convolutional cell using a small dataset and obtain 10 architectures from 10 runs. Then, 10 larger networks are constructed by stacking each discovered cell multiple times. The larger networks are trained on the same dataset or a larger one to evaluate their performance. We report the best and average performance of these 10 architectures. We show the effectiveness of SGAS in GCN architecture search by comparisons with SOTA hand-crafted methods and Random Search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Architecture Search on ModelNet10</head><p>ModelNet <ref type="bibr" target="#b55">[56]</ref> is a dataset for 3D object classification with two variants, ModelNet10 and ModelNet40 containing objects from 10 and 40 classes respectively. We conduct GCN architecture search on ModelNet10 and then evaluate the final performance on ModelNet40. Search Space. Our graph convolutional cell has 10 candidate operations: conv-1Ã1, MRConv <ref type="bibr" target="#b29">[30]</ref>, EdgeConv <ref type="bibr" target="#b54">[55]</ref>, GAT <ref type="bibr" target="#b51">[52]</ref>, SemiGCN <ref type="bibr" target="#b24">[25]</ref>, GIN <ref type="bibr" target="#b58">[59]</ref>, SAGE <ref type="bibr" target="#b16">[17]</ref>, RelSAGE, skip-connect, and zero operation. Please refer to our supplement material for more details of these GCN operators. We use k nearest neighbor in the first operation of each cell to construct edges (we use k = 9 by default unless it is specified). These edges are then shared in the following operations inside the cell. Dilated graph convolutions with the same linearly increasing dilation rate schedule as proposed in DeepGCNs <ref type="bibr" target="#b29">[30]</ref> are applied to the cells. Training Settings. We sample 1024 points from the 3D models in ModelNet10. We use 2 cells with 32 initial channels and search the architectures for 50 epochs with batch size 28. SGD is used to optimize the model weights with initial learning rate 0.005, momentum 0.9 and weight decay 3Ã10 â4 . The Adam optimizer with the same parameters as in the search for CNNs is used to optimize architecture parameters. After warming up for 9 epochs, SGAS begins to select one operation for a selected edge every 7 epochs. We experimented with both selection criteria, Criterion 1 and Criterion 2. We use a history window of 4 for Cri. <ref type="bibr" target="#b1">2</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Architecture Evaluation on ModelNet40</head><p>After searching for 10 architectures on ModelNet10, we form a large backbone network for each and train them on ModelNet40. The performance of 3D point cloud classification is evaluated with the overall accuracy (OA). We also apply Random Search to the same search space to obtain 10 architectures as our random search baseline.</p><p>Training Settings. We stack the searched cell 9 times with channel size 128. We also form small networks by stacking the cell 3 times with the same channel size. We use k = 20 for all the large networks and k = 9 for the small ones.</p><p>Adam is used to optimize the weights with initial learning rate 0.001 and weight decay 1 Ã 10 â4 . We sample 1024 points as input. Our architectures are all trained for 400 epochs with batch size of 32. We report the mean and standard deviation of the accuracy on the test dataset of the 10 discovered architectures; we also report the accuracy of the best performing model of the big and the small networks.</p><p>Evaluation Results and Analysis. We compare the performance of our discovered architectures with SOTA handcrafted methods and architectures obtained by Random Search for 3D point clouds classification on ModelNet40. <ref type="table">Table 3</ref> shows that SGAS (Cri.2 best), the best architecture discovered by our SGAS with Criterion 2, outperforms all the other models. The smaller network SGAS (Cri.2 small best) discovered by SGAS with Criterion 2 also outperforms all the hand-crafted architectures. Owing to a welldesigned search space, Random Search is a strong baseline. The performance of SGAS surpasses the hand-crafted architectures and Random Search, demonstrating the effectiveness of SGAS for GCN architecture search. The best architecture for this task can be found in <ref type="figure">Figure 4 (a)</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Architecture Search on PPI</head><p>PPI is a popular biological graph dataset in the data mining domain. We search for GCN architectures on the PPI dataset for the task of node classification.</p><p>Training Settings. We use 1 cell with 32 channels. We train and search the architectures for 50 epochs with a batch size of 6 on PPI. We do not increase the batch size after making decisions since PPI is small and only contains 20 batches. The other parameters are the same as when searching on ModelNet10. The search takes around 0.003 day (4 minutes) on a Nvidia Tesla V100 GPU (16GB).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4">Architecture Evaluation on PPI</head><p>We evaluate architectures on the PPI test set. We report the mean, standard derivation and the best accuracy and compare them with the SOTA methods and Random Search. We also conduct an ablation study on number of cells and channel size which we include in the supplement material.</p><p>Training Settings. We stack the discovered cell 5 times with channel size 512. Adam is used to optimize the model weights with initial learning rate 0.002. We use a cosine annealing to schedule the learning rate. Our architectures are trained for 2000 epochs with batch size of 1 as suggested in DeepGCNs <ref type="bibr" target="#b28">[29]</ref>. We find the best model on the validation dataset and obtain the micro-F1 score on the test dataset.</p><p>Evaluation Results and Analysis. We compare the average and best performance of SGAS to other state-of-thearts methods and Random Search on node classification on the PPI dataset. that Criterion 2 provides more stable results. We visualize the architecture with the best performance in <ref type="figure">Figure 4</ref> (b).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this work, we propose the Sequential Greedy Architectural Search (SGAS) algorithm to design architectures automatically for CNNs and GCNs. The bi-level optimization problem in NAS is solved in a greedy fashion using heuristic criteria which take the edge importance, the selection certainty and the selection stability into consideration. Such an approach alleviates the effect of the degenerate search-evaluation correlation problem and reflects the true ranking of architectures. As a result, architectures discovered by SGAS achieve state-of-the-art performance on CIFAR-10, ImageNet, ModelNet and PPI datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SGAS: Sequential Greedy Architecture Search -Supplementary Material -</head><p>A. Discussion</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1. Greedy Methods in NAS</head><p>The idea of incorporating greedy algorithms into NAS has been explored in several works. PNAS <ref type="bibr" target="#b32">[33]</ref> proposes a sequential model-based optimization (SMBO) approach to accelerate the search for CNN architectures. They start from a simple search space and a learn a predictor function. Then they greedily grow the search space by predicting scores of candidates cells using the learned predictor function. GNAS <ref type="bibr" target="#b22">[23]</ref> learns a global tree-like architecture for multi-attribute learning by iteratively updating layer-wise local architectures in a greedy manner. P-DARTS <ref type="bibr" target="#b8">[9]</ref> can also be regarded as a greedy approach, in which they bridge the depth gap between search and evaluation by gradually increasing the depth of the search networks while shrinking the number of candidate operations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Selection Criteria and Hyper-parameters</head><p>Edge Importance and Selection Certainty. Edge importance and selection certainty are combined into a single criterion, since the algorithm will be agnostic to the selection distribution of an edge, if we only consider edge importance. In this case, an edge may be selected with a suboptimal operation at early epochs. On the other hand, we need to select 8 out of 14 edges in a DAG with 4 intermediate nodes for a fair comparison with DARTS. Only considering selection certainty may fail to select the optimal 8 edges, since an edge with a high selection certainty may have a high weight on Zero operation (low edge importance).</p><p>Choices of Hyper-parameters. Three extra parameters are introduced in SGAS: (1) length of warm-up phase (2) interval of greedy decisions (3) history window size for Cri.2. We provide a discussion on the default choices of them:</p><p>(1) Since the softmax weights of operations are initialized under a uniform distribution, choosing an operation for an edge after a short period of warming up leads to stable results. We simply set the length of the warm-up phase to 9 epochs so that the first greedy decision will be made at the 10th epoch. <ref type="bibr" target="#b1">(2)</ref> For CNN experiments, the interval between greedy decisions is chosen to be 5. Since designing a normal cell with 4 intermediate nodes needs to select 8 out of 14 edges (8 decisions to be made). For a fair comparison to our baseline DARTS, we want the search phase to last up to 50 epochs, which is the length of search epochs in DARTS. For GCN architectures, in order to learn a compact network, we search a normal cell with 3 intermediate nodes.</p><p>Thus, we have 6 decisions to make (6 out of 9 edges). Similarly, to keep the length of the search phase less than 50 epochs, we set the interval between greedy decisions to be 7.</p><p>(3) The history window size for Cri.2 is always set as 4, which is simply chosen to be slightly smaller than the interval between greedy decisions.</p><p>Ablation Study on Hyper-parameters. In order to better understand the effects of the choices of hyper-parameters, we conduct ablation studies on interval of greedy decisions T and history window size K for Cri.2 on CIFAR-10 in <ref type="table" target="#tab_4">Table 5</ref>. The default values of T and K are 5 and 4 respectively. We find that larger T and K stabilize the search and produce standard deviations in the test error. The test error only has a standard deviation as 0.08 when T = 7. When T = 3, the average test error increases significantly from 2.67% to 2.86%. We also find K is less sensitive than T .  <ref type="bibr" target="#b16">[17]</ref> which combines the ideas from MR-Conv <ref type="bibr" target="#b29">[30]</ref> and GraphSAGE <ref type="bibr" target="#b16">[17]</ref>. Instead of aggregating the node features with its neighbor features directly, we aggregate the node features with the difference between the node features and its neighbor features:</p><formula xml:id="formula_14">h (k) v = Ï W (k) Â· f k h (kâ1) v , h (kâ1) u â h (kâ1) v , âu â N (v) where h (k) v</formula><p>is the feature of the center node v in k-th layer. N (v) denotes the neighbors of node v. f k is a max aggregation function and Ï is a ReLU activation function as GraphSAGE <ref type="bibr" target="#b16">[17]</ref>. The GCNs operators are implemented using Pytorch Geometric <ref type="bibr" target="#b13">[14]</ref>. We also add skip-connect (similar as residual graph connections <ref type="bibr" target="#b29">[30]</ref>) and zero operation in our search space. Ablation Study on GCN Cells. We conduct an ablation study on the parameter size of the best cell searched on PPI by SGAS (Cri.1 best). <ref type="table">Table 6</ref> shows the trade-off between the parameter size and the final performance. To derive a compact model, we can use a smaller number of cells or less channels in the architecture searched by SGAS.  <ref type="table">Table 6</ref>. Ablation study on channel size and number of cells on node classification on PPI. We use SGAS (Cri.1 best), the best architecture we discovered by using Criterion 1 to conduct experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2. More Details</head><p>Cell Visualizations. We visualize the best cells discovered by SGAS with different criteria (Criterion 1 and Criterion 2) mentioned in the experiment section. <ref type="figure" target="#fig_4">Figure 5</ref> shows the best cells for CNNs on CIFAR-10 and ImageNet. <ref type="figure">Figure 6</ref> shows the best cells for GCNs on ModelNet-40 and PPI.</p><p>Detailed results. Here we provide the detailed results mentioned in the experimental section of the paper. In the CNN experiments, we compare SGAS with DARTS on CIFAR-10 and ImageNet. We execute the search phase 10 times for both SGAS (Cri.1 and Cri.2) and DARTS (1st and 2nd order) to obtain 10 different architectures per method. For each resulting architecture, we run the evaluation phase and assign a ranking based on the evaluation accuracy. To measure the discrepancy between the search and evaluation, we calculate the Kendall Ï correlation between the ranking of the search phase and the evaluation phase. We show these results in <ref type="table">Table 7</ref> and <ref type="table">Table 8</ref> for SGAS, and <ref type="table">Table 9</ref> and <ref type="table" target="#tab_0">Table 10</ref> for DARTS. For ImageNet, we evaluate the top three architectures found on CIFAR-10. We show the results in <ref type="table" target="#tab_0">Table 11</ref> and <ref type="table" target="#tab_0">Table 12</ref> for both Criterion 1 and Criterion 2.</p><p>In the GCN experiments, we compare SGAS (Cri.1 and Cri.2) with a random search baseline on ModelNet and PPI. Similar as in experiments for CNNs, we conduct the search phase 10 times for each method. For experiments on Mod-elNet, we search cells on ModelNet10 and then evaluate the searched cells on ModelNet40. The results are shown for Criterion 1, Criterion 2 and random search in <ref type="table" target="#tab_0">Table 13</ref>, <ref type="table" target="#tab_0">Table 14</ref> and <ref type="table" target="#tab_0">Table 15</ref> respectively. The results on PPI are presented in <ref type="table" target="#tab_0">Table 16</ref> and <ref type="table" target="#tab_0">Table 17</ref> for each Criterion and in <ref type="table" target="#tab_0">Table 18</ref> for random search.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Comparison of search-evaluation Kendall Ï coefficients. We show Kendall Ï correlations for architecture rankings between the search and the evaluation phase of DARTS and SGAS. Architectures are obtained from 10 independent search runs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Illustration of Sequential Greedy Architecture Search. At each greedy decision epoch, an edge (i â  , j â  ) is selected based on the selection criterion. A greedy decision will be made for the edge (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>while using only a search cost of 0.25 GPU day on one NVIDIA GTX 1080Ti. SGAS (Cri.2) outperforms SGAS (Cri.1) showing the effectiveness of integrating selection stability into the selection criterion. The best performing cells of SGAS (Cri.2 best) are illustrated inFigure 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 . 4 .</head><label>34</label><figDesc>Best cell architecture on Imagenet with SGAS Crit. 2 (a) Normal cell of the best model with SGAS Crit. 2 on ModelNet40 (b) Normal cell of the best model with SGAS Crit. 1 on PPI Figure Best cell architectures on ModelNet40 and PPI</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>5 .</head><label>5</label><figDesc>Normal cell of the best model with SGAS Cri. 1 (b) Reduction cell of the best model with SGAS Cri. 1 on CIFAR-10 and ImageNet on CIFAR-10 and ImageNet Normal cell of the best model with SGAS Cri. 2 on CIFAR-10 (d) Reduction cell of the best model with SGAS Cri. 2 on CIFAR-10 Normal cell of the best model with SGAS Cri. 2 on ImageNet (f) Reduction cell of the best model with SGAS Cri. 2 on ImageNet Figure Best cell architecture for image classification tasks Normal cell of the best model with SGAS Cri. 1 on ModelNet40 (b) Normal cell of the best model with SGAS Cri. 2 on ModelNet40 (c) Normal cell of the best model with SGAS Cri. 1 on PPI (d) Normal cell of the best model with SGAS Cri. 2 on PPI Figure 6. Best cell architectures on ModelNet40 and PPI with each Criterion</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Algorithm 1 :</head><label>1</label><figDesc>SGAS -Sequential Greedy Architecture Search Create architectural parameters A = {Î± (i,j) } and supernet weights W Create a mixed operationÅ (i,j) parameterized by Î± (i,j) for each edge (i, j) while not terminated do 1. Update undetermined architecture parameters A by descending â A L val (W, A) 2. Update weights W by descending â W L train (W, A) (since the weights of unchosen operations are pruned, only the remaining weights need to be updated) 3. If a decision epoch, select an edge (i â  , j â  ) based on the greedy Selection Criterion Determine the operation by replacingÅ</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1</head><label>1</label><figDesc>2 best) outperform all the other methods with top-1 errors 24.2% and 24.1% respectively</figDesc><table><row><cell>Architecture</cell><cell>Test Err.</cell><cell cols="2">Params Search Cost</cell><cell>Search</cell></row><row><cell></cell><cell>(%)</cell><cell>(M)</cell><cell cols="2">(GPU-days) Method</cell></row><row><cell>DenseNet-BC [22]</cell><cell>3.46</cell><cell>25.6</cell><cell>-</cell><cell>manual</cell></row><row><cell>NASNet-A [66]</cell><cell>2.65</cell><cell>3.3</cell><cell>1800</cell><cell>RL</cell></row><row><cell>AmoebaNet-A [43]</cell><cell>3.34Â±0.06</cell><cell>3.2</cell><cell>3150</cell><cell>evolution</cell></row><row><cell>AmoebaNet-B [43]</cell><cell>2.55Â±0.05</cell><cell>2.8</cell><cell>3150</cell><cell>evolution</cell></row><row><cell>Hier-Evolution [34]</cell><cell>3.75Â±0.12</cell><cell>15.7</cell><cell>300</cell><cell>evolution</cell></row><row><cell>PNAS [33]</cell><cell>3.41Â±0.09</cell><cell>3.2</cell><cell>225</cell><cell>SMBO</cell></row><row><cell>ENAS [40]</cell><cell>2.89</cell><cell>4.6</cell><cell>0.5</cell><cell>RL</cell></row><row><cell>NAONet-WS [37]</cell><cell>3.53</cell><cell>3.1</cell><cell>0.4</cell><cell>NAO</cell></row><row><cell>DARTS (1 st order) [35]</cell><cell>3.00Â±0.14</cell><cell>3.3</cell><cell>0.4</cell><cell>gradient</cell></row><row><cell cols="2">DARTS (2 nd order) [35] 2.76Â±0.09</cell><cell>3.3</cell><cell>1</cell><cell>gradient</cell></row><row><cell>SNAS (mild) [58]</cell><cell>2.98</cell><cell>2.9</cell><cell>1.5</cell><cell>gradient</cell></row><row><cell>ProxylessNAS [8]</cell><cell>2.08</cell><cell>-</cell><cell>4</cell><cell>gradient</cell></row><row><cell>P-DARTS [9]</cell><cell>2.5</cell><cell>3.4</cell><cell>0.3</cell><cell>gradient</cell></row><row><cell>BayesNAS [63]</cell><cell>2.81Â±0.04</cell><cell>3.4</cell><cell>0.2</cell><cell>gradient</cell></row><row><cell>PC-DARTS [61]</cell><cell>2.57Â±0.07</cell><cell>3.6</cell><cell>0.1</cell><cell>gradient</cell></row><row><cell>SGAS (Cri.1 avg.)</cell><cell>2.66Â±0.24  *</cell><cell>3.7</cell><cell>0.25</cell><cell>gradient</cell></row><row><cell>SGAS (Cri.1 best)</cell><cell>2.39</cell><cell>3.8</cell><cell>0.25</cell><cell>gradient</cell></row><row><cell>SGAS (Cri.2 avg.)</cell><cell>2.67Â±0.21  *</cell><cell>3.9</cell><cell>0.25</cell><cell>gradient</cell></row><row><cell>SGAS (Cri.2 best)</cell><cell>2.44</cell><cell>4.1</cell><cell>0.25</cell><cell>gradient</cell></row></table><note>. Performance comparison with state-of-the-art image classifiers on CIFAR-10. We report the average and best performance of SGAS (Cri.1) and SGAS (Cri.2). Criterion 1 and Criterion 2 are used in the search respectively. *Note that mean and standard derivation are computed across 10 independently searched architectures.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>.Table 2 Table 3 .</head><label>23</label><figDesc>The Comparison with state-of-the-art architectures for 3D object classification on ModelNet40. 10 architectures are derived for both SGAS and Random Search within the same search space. batch size increases by 4 after each decision. The search takes around 0.19 GPU day on one NVIDIA GTX 1080Ti.</figDesc><table><row><cell cols="2">Architecture</cell><cell></cell><cell cols="2">Test Err. (%)</cell><cell cols="3">Params Ã+ Search Cost</cell><cell>Search</cell></row><row><cell></cell><cell></cell><cell></cell><cell>top-1</cell><cell>top-5</cell><cell>(M)</cell><cell cols="2">(M) (GPU-days) Method</cell></row><row><cell cols="2">Inception-v1 [49]</cell><cell></cell><cell>30.2</cell><cell>10.1</cell><cell>6.6</cell><cell>1448</cell><cell>-</cell><cell>manual</cell></row><row><cell cols="2">MobileNet [20]</cell><cell></cell><cell>29.4</cell><cell>10.5</cell><cell>4.2</cell><cell>569</cell><cell>-</cell><cell>manual</cell></row><row><cell cols="3">ShuffleNet 2x (v1) [62]</cell><cell>26.4</cell><cell>10.2</cell><cell>â¼5</cell><cell>524</cell><cell>-</cell><cell>manual</cell></row><row><cell cols="3">ShuffleNet 2x (v2) [38]</cell><cell>25.1</cell><cell>-</cell><cell>â¼5</cell><cell>591</cell><cell>-</cell><cell>manual</cell></row><row><cell cols="2">NASNet-A [66]</cell><cell></cell><cell>26</cell><cell>8.4</cell><cell>5.3</cell><cell>564</cell><cell>1800</cell><cell>RL</cell></row><row><cell cols="2">NASNet-B [66]</cell><cell></cell><cell>27.2</cell><cell>8.7</cell><cell>5.3</cell><cell>488</cell><cell>1800</cell><cell>RL</cell></row><row><cell cols="2">NASNet-C [66]</cell><cell></cell><cell>27.5</cell><cell>9</cell><cell>4.9</cell><cell>558</cell><cell>1800</cell><cell>RL</cell></row><row><cell cols="2">AmoebaNet-A [43]</cell><cell></cell><cell>25.5</cell><cell>8</cell><cell>5.1</cell><cell>555</cell><cell>3150</cell><cell>evolution</cell></row><row><cell cols="2">AmoebaNet-B [43]</cell><cell></cell><cell>26</cell><cell>8.5</cell><cell>5.3</cell><cell>555</cell><cell>3150</cell><cell>evolution</cell></row><row><cell cols="2">AmoebaNet-C [43]</cell><cell></cell><cell>24.3</cell><cell>7.6</cell><cell>6.4</cell><cell>570</cell><cell>3150</cell><cell>evolution</cell></row><row><cell cols="2">FairNAS-A [10]</cell><cell></cell><cell>24.7</cell><cell>7.6</cell><cell>4.6</cell><cell>388</cell><cell>12</cell><cell>evolution</cell></row><row><cell cols="2">PNAS [33]</cell><cell></cell><cell>25.8</cell><cell>8.1</cell><cell>5.1</cell><cell>588</cell><cell>225</cell><cell>SMBO</cell></row><row><cell cols="2">MnasNet-92 [50]</cell><cell></cell><cell>25.2</cell><cell>8</cell><cell>4.4</cell><cell>388</cell><cell>-</cell><cell>RL</cell></row><row><cell cols="3">DARTS (2 nd order) [35]</cell><cell>26.7</cell><cell>8.7</cell><cell>4.7</cell><cell>574</cell><cell>4.0</cell><cell>gradient</cell></row><row><cell cols="2">SNAS (mild) [58]</cell><cell></cell><cell>27.3</cell><cell>9.2</cell><cell>4.3</cell><cell>522</cell><cell>1.5</cell><cell>gradient</cell></row><row><cell cols="2">ProxylessNAS [8]</cell><cell></cell><cell>24.9</cell><cell>7.5</cell><cell>7.1</cell><cell>465</cell><cell>8.3</cell><cell>gradient</cell></row><row><cell cols="2">P-DARTS [9]</cell><cell></cell><cell>24.4</cell><cell>7.4</cell><cell>4.9</cell><cell>557</cell><cell>0.3</cell><cell>gradient</cell></row><row><cell cols="2">BayesNAS [63]</cell><cell></cell><cell>26.5</cell><cell>8.9</cell><cell>3.9</cell><cell>-</cell><cell>0.2</cell><cell>gradient</cell></row><row><cell cols="2">PC-DARTS [61]</cell><cell></cell><cell>25.1</cell><cell>7.8</cell><cell>5.3</cell><cell>586</cell><cell>0.1</cell><cell>gradient</cell></row><row><cell cols="2">SGAS (Cri.1 avg.)</cell><cell cols="3">24.41Â±0.16 7.29Â±0.09</cell><cell>5.3</cell><cell>579</cell><cell>0.25</cell><cell>gradient</cell></row><row><cell cols="2">SGAS (Cri.1 best)</cell><cell></cell><cell>24.2</cell><cell>7.2</cell><cell>5.3</cell><cell>585</cell><cell>0.25</cell><cell>gradient</cell></row><row><cell cols="2">SGAS (Cri.2 avg.)</cell><cell cols="3">24.38Â±0.22 7.39Â±0.07</cell><cell>5.4</cell><cell>597</cell><cell>0.25</cell><cell>gradient</cell></row><row><cell cols="2">SGAS (Cri.2 best)</cell><cell></cell><cell>24.1</cell><cell>7.3</cell><cell>5.4</cell><cell>598</cell><cell>0.25</cell><cell>gradient</cell></row><row><cell>Architecture</cell><cell>OA</cell><cell cols="3">Params Search Cost</cell><cell></cell><cell></cell></row><row><cell></cell><cell>(%)</cell><cell>(M)</cell><cell cols="2">(GPU-days)</cell><cell></cell><cell></cell></row><row><cell>3DmFV-Net [4]</cell><cell>91.6</cell><cell>45.77</cell><cell>manual</cell><cell></cell><cell></cell><cell></cell></row><row><cell>SpecGCN [54]</cell><cell>91.5</cell><cell>2.05</cell><cell>manual</cell><cell></cell><cell></cell><cell></cell></row><row><cell>PointNet++ [42]</cell><cell>90.7</cell><cell>1.48</cell><cell>manual</cell><cell></cell><cell></cell><cell></cell></row><row><cell>PCNN [3]</cell><cell>92.3</cell><cell>8.2</cell><cell>manual</cell><cell></cell><cell></cell><cell></cell></row><row><cell>PointCNN [31]</cell><cell>92.2</cell><cell>0.6</cell><cell>manual</cell><cell></cell><cell></cell><cell></cell></row><row><cell>DGCNN [55]</cell><cell>92.2</cell><cell>1.84</cell><cell>manual</cell><cell></cell><cell></cell><cell></cell></row><row><cell>KPConv [51]</cell><cell>92.9</cell><cell>14.3</cell><cell>manual</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Random Search</cell><cell>92.65Â±0.33</cell><cell>8.77</cell><cell>random</cell><cell></cell><cell></cell><cell></cell></row><row><cell>SGAS (Cri.1 avg.)</cell><cell>92.69Â±0.20</cell><cell>8.78</cell><cell>0.19</cell><cell></cell><cell></cell><cell></cell></row><row><cell>SGAS (Cri.1 best)</cell><cell>92.87</cell><cell>8.63</cell><cell>0.19</cell><cell></cell><cell></cell><cell></cell></row><row><cell>SGAS (Cri.2 avg.)</cell><cell>92.93Â±0.19</cell><cell>8.87</cell><cell>0.19</cell><cell></cell><cell></cell><cell></cell></row><row><cell>SGAS (Cri.2 best)</cell><cell>93.23</cell><cell>8.49</cell><cell>0.19</cell><cell></cell><cell></cell><cell></cell></row><row><cell>SGAS (Cri.2 small best)</cell><cell>93.07</cell><cell>3.86</cell><cell>0.19</cell><cell></cell><cell></cell><cell></cell></row></table><note>. Comparison with state-of-the-art classifiers on ImageNet. We transfer the top 3 performing architectures on CIFAR-10 to ImageNet in the mobile setting. Ã+ denote multiply-add operations. The average and best performance of SGAS are reported.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 Table 4 .</head><label>44</label><figDesc>shows the best architecture discovered by our SGAS outperforms the state-of-the-art DenseMRGCN-14<ref type="bibr" target="#b28">[29]</ref> by â¼0.03% with â¼30.24 M less Comparison with state-of-the-art architectures for node classification on PPI. SGAS (small) is the small network stacking the cell searched by SGAS (Cri.1).</figDesc><table><row><cell>Architecture</cell><cell>micro-F1</cell><cell cols="2">Params Search Cost</cell></row><row><cell></cell><cell>(%)</cell><cell>(M)</cell><cell>(GPU-days)</cell></row><row><cell>GraphSAGE (LSTM) [17]</cell><cell>61.2</cell><cell>0.26</cell><cell>manual</cell></row><row><cell>GeniePath [36]</cell><cell>97.9</cell><cell>1.81</cell><cell>manual</cell></row><row><cell>GAT [52]</cell><cell>97.3Â±0.2</cell><cell>3.64</cell><cell>manual</cell></row><row><cell>DenseMRGCN-14 [29]</cell><cell>99.43</cell><cell>53.42</cell><cell>manual</cell></row><row><cell>ResMRGCN-28 [29]</cell><cell>99.41</cell><cell>14.76</cell><cell>manual</cell></row><row><cell>Random Search</cell><cell>99.36Â±0.04</cell><cell>23.70</cell><cell>random</cell></row><row><cell>SGAS (Cri.1 avg.)</cell><cell>99.38Â±0.17</cell><cell>25.01</cell><cell>0.003</cell></row><row><cell>SGAS (Cri.1 best)</cell><cell>99.46</cell><cell>23.18</cell><cell>0.003</cell></row><row><cell>SGAS (Cri.2 avg.)</cell><cell>99.40Â±0.09</cell><cell>25.93</cell><cell>0.003</cell></row><row><cell>SGAS (Cri.2 best)</cell><cell>99.46</cell><cell>29.73</cell><cell>0.003</cell></row><row><cell>SGAS (small)</cell><cell>98.89</cell><cell>0.40</cell><cell>0.003</cell></row></table><note>parameters. The average performance of SGAS also sur- passes the Random Search baseline consistently. In addi- tion, SGAS (Cri.2 avg.) outperforms SGAS (Cri.1 avg.) in terms of both mean and standard deviation. This indicates</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>Ablation study on interval of greedy decisions T and history window size K for Cri.2 on CIFAR-10. We use SGAS (Cri.2) as our search method. We report the average and best performance of searched architectures.</figDesc><table><row><cell cols="2">Avg.</cell><cell>Best</cell><cell></cell></row><row><cell cols="4">T K Params (M) Test Err.(%) Params (M) Test Err.(%)</cell></row><row><cell>5 4 3.91Â±0.22</cell><cell>2.67Â±0.21</cell><cell>4.09</cell><cell>2.44</cell></row><row><cell>3 4 4.09Â±0.24</cell><cell>2.86Â±0.12</cell><cell>4.39</cell><cell>2.69</cell></row><row><cell>7 4 3.66Â±0.16</cell><cell>2.65Â±0.08</cell><cell>3.68</cell><cell>2.54</cell></row><row><cell>5 2 3.87Â±0.20</cell><cell>2.73Â±0.16</cell><cell>3.94</cell><cell>2.51</cell></row><row><cell>5 6 3.93Â±0.26</cell><cell>2.67Â±0.17</cell><cell>3.70</cell><cell>2.47</cell></row><row><cell cols="2">B. Experimental Details</cell><cell></cell><cell></cell></row><row><cell cols="2">B.1. GCN Experiments</cell><cell></cell><cell></cell></row><row><cell cols="4">GCN operators. Similar as the search for CNN, SGAS</cell></row><row><cell cols="4">selects one operation from a candidate operation search</cell></row><row><cell cols="4">space for each edge in the DAG. We choose the follow-</cell></row><row><cell cols="4">ing 10 operations as our candidate operations: conv-1Ã1,</cell></row><row><cell cols="4">MRConv [30], EdgeConv [55], GAT [52], SemiGCN [25],</cell></row><row><cell cols="4">GIN [59], SAGE [17], RelSAGE, skip-connect, and zero op-</cell></row><row><cell cols="4">eration. conv-1Ã1 is a basic convolution operation without</cell></row><row><cell cols="4">aggregating information from neighbors, which is similar</cell></row><row><cell cols="4">to PointNet [41]. MRConv [30], EdgeConv [55], GAT [52],</cell></row><row><cell cols="4">SemiGCN [25], GIN [59] and SAGE [17] are widely used</cell></row><row><cell cols="4">GCN operators in the graph learning domain and the 3D</cell></row><row><cell cols="4">computer vision domain. RelSAGE is a modified Graph-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 8 .Table 9 .Table 10 .Table 11 .Table 12 .Table 13 .Table 14 .Table 15 .</head><label>89101112131415</label><figDesc>Results of SGAS Criterion 2 on CIFAR-10 Results of DARTS 1st order on CIFAR-10 Experiment Validation error (%) Params (M) Test error (%) Evaluation ranking Results of DARTS 2nd order on CIFAR-10 Results of SGAS with Criterion 1 on ImageNet. Note that the chosen architectures are the three best ones from the results obtained on CIFAR-10. Results of SGAS with Criterion 2 on ImageNet. Note that the chosen the architectures are the three best ones from the results obtained on CIFAR-10. Results of SGAS with Criterion 1 on ModelNet40. Architectures are formed by stacking 9 cells with 128 channel size. Results of SGAS with Criterion 2 on ModelNet40. Architectures are formed by stacking 9 cells with 128 channel size. Results of random search on ModelNet40. Architectures are formed by stacking 9 cells with 128 channel size.</figDesc><table><row><cell cols="8">Experiment Cri.1 CIFAR 1 DARTS 2nd CIFAR 1 Cri.1 CIFAR 2 DARTS 2nd CIFAR 2 Cri.1 CIFAR 3 DARTS 2nd CIFAR 3 Cri.1 CIFAR 4 DARTS 2nd CIFAR 4 Cri.1 CIFAR 5 DARTS 2nd CIFAR 5 Cri.1 CIFAR 6 DARTS 2nd CIFAR 6 Cri.1 CIFAR 7 DARTS 2nd CIFAR 7 Cri.1 CIFAR 8 DARTS 2nd CIFAR 8 Cri.1 CIFAR 9 DARTS 2nd CIFAR 9 Cri.1 CIFAR 10 DARTS 2nd CIFAR 10 Validation error (%) Params (M) Test error (%) Evaluation ranking 16.94 3.75 2.44 11.35 2.91 2.96 Experiment Params (M) Test OA (%) 8 2 17.33 3.73 2.50 11.51 2.93 2.73 Cri.2 ModelNet 1 8.78 92.91 5 3 17.90 3.80 2.39 11.68 2.20 3.01 Cri.2 ModelNet 2 8.78 92.67 9 1 17.90 3.32 2.63 11.76 2.66 2.75 Cri.2 ModelNet 3 9.08 92.79 6 6 17.99 3.45 2.78 11.80 3.09 2.72 Cri.2 ModelNet 4 8.49 93.23 4 8 18.43 3.47 2.68 11.82 3.40 2.62 Cri.2 ModelNet 5 9.08 93.03 3 7 18.72 3.83 2.51 11.83 2.91 2.82 Cri.2 ModelNet 6 9.08 93.07 7 4 19.82 3.66 2.61 11.93 3.20 2.51 Cri.2 ModelNet 7 8.78 93.11 1 5 19.93 3.98 3.18 11.95 2.14 3.48 Cri.2 ModelNet 8 8.63 92.67 10 10 21.53 3.61 2.87 12.03 2.55 2.62 Cri.2 ModelNet 9 8.78 92.83 2 9 Average 18.65Â±1.4 3.66Â±0.2 2.66Â±0.24 Kendall Ï Best Model 17.90 3.80 2.39 0.56 Average 11.77Â±0.21 2.8Â±0.41 Kendall Ï Cri.2 ModelNet 10 9.23 92.95 2.82Â±0.28 Best Model 11.93 3.20 2.51 Average 8.87Â±0.23 92.93Â±0.19 -0.29 Best Model 8.49 93.23</cell></row><row><cell></cell><cell cols="4">Table 7. Results of SGAS Criterion 1 on CIFAR-10</cell><cell></cell><cell></cell></row><row><cell>Experiment</cell><cell cols="7">Test error top-1 (%) Test error top-5 (%) Params (M) Ã+</cell></row><row><cell cols="8">Experiment Cri.1 ImageNet 1 Validation error (%) Params (M) Test error (%) Evaluation ranking 24.47 7.23 5.25 578 Cri.1 ImageNet 2 24.53 7.40 5.23 574 Experiment Params (M) Test OA (%)</cell></row><row><cell cols="2">Cri.2 CIFAR 1 Cri.1 ImageNet 3 Random ModelNet 1 16.48 24.22</cell><cell>4.14 9.22</cell><cell>7.25</cell><cell>2.57 92.79</cell><cell></cell><cell>5.29</cell><cell>4</cell><cell>585</cell></row><row><cell>Cri.2 CIFAR 2 Cri.2 CIFAR 3 Cri.2 CIFAR 4 Average Best Model</cell><cell>17.26 17.31 17.47 24.41Â±0.16 Random ModelNet 2 24.22 Random ModelNet 3 Random ModelNet 4</cell><cell cols="3">3.88 4.09 3.91 8.93 7.29Â±0.09 2.60 2.44 2.49 92.67 7.25 9.08 92.71 8.78 92.46</cell><cell cols="3">5.25Â±0.03 5.29</cell><cell>6 1 2</cell><cell>579 585</cell></row><row><cell>Cri.2 CIFAR 5</cell><cell>17.53 Random ModelNet 5</cell><cell>3.69 8.19</cell><cell></cell><cell>2.52 92.79</cell><cell></cell><cell></cell><cell>3</cell></row><row><cell>Cri.2 CIFAR 6</cell><cell>17.98 Random ModelNet 6</cell><cell>3.95 8.63</cell><cell></cell><cell>3.12 92.54</cell><cell></cell><cell></cell><cell>10</cell></row><row><cell>Cri.2 CIFAR 7</cell><cell>18.28 Random ModelNet 7</cell><cell>3.69 8.93</cell><cell></cell><cell>2.58 91.94</cell><cell></cell><cell></cell><cell>5</cell></row><row><cell>Cri.2 CIFAR 8 Experiment</cell><cell cols="7">18.28 Test error top-1 (%) Test error top-5 (%) Params (M) Ã+ 4.33 2.85 8 Random ModelNet 8 8.63 92.99</cell></row><row><cell cols="2">Cri.2 CIFAR 9 Cri.2 CIFAR 10 Cri.2 ImageNet 1 Random ModelNet 9 19.48 19.98 24.44 Cri.2 ImageNet 2 24.13 Random ModelNet 10</cell><cell>3.73 3.68 8.79 8.49</cell><cell>7.41 7.31</cell><cell>2.85 2.66 93.15 92.46</cell><cell></cell><cell>5.70 5.44</cell><cell>9 7</cell><cell>621 598</cell></row><row><cell cols="2">Average Cri.2 ImageNet 3 Average 18.00Â±1.06 24.55</cell><cell cols="4">3.91Â±0.22 8.77Â±0.30 7.44 2.67Â±0.21 92.65Â±0.33</cell><cell>5.20</cell><cell>Kendall Ï 571</cell></row><row><cell>Best Model Average</cell><cell>17.31 24.38Â±0.22 Best Model</cell><cell cols="3">4.09 8.79 7.39Â±0.07 2.44 93.15</cell><cell cols="3">5.44Â±0.25</cell><cell>0.42 597</cell></row><row><cell>Best Model</cell><cell>24.13</cell><cell></cell><cell>7.31</cell><cell></cell><cell></cell><cell>5.44</cell><cell>598</cell></row><row><cell>Experiment DARTS 1st CIFAR 1 DARTS 1st CIFAR 2 DARTS 1st CIFAR 3 DARTS 1st CIFAR 4 DARTS 1st CIFAR 5 DARTS 1st CIFAR 6 DARTS 1st CIFAR 7 DARTS 1st CIFAR 8 DARTS 1st CIFAR 9 DARTS 1st CIFAR 10 Average Best Model</cell><cell cols="7">Validation error (%) Params (M) Test error (%) Evaluation ranking 11.37 3.27 2.83 Experiment Experiment Params (M) Test micro-F1 (%) Params (M) Test OA (%) 4 11.45 3.65 2.57 2 11.47 2.29 2.94 7 11.48 2.65 2.96 8 11.65 3.09 2.50 1 11.75 2.86 2.84 5 11.77 2.09 3.06 10 11.81 2.52 3.01 9 11.82 2.65 2.94 6 11.94 3.27 2.82 3 11.65Â±0.19 2.84Â±0.49 2.85Â±0.18 Cri.1 ModelNet 1 8.79 Cri.1 PPI 1 27.11 99.45 92.71 Cri.1 ModelNet 2 9.23 Cri.1 PPI 2 23.18 99.42 92.83 Cri.1 ModelNet 3 8.79 Cri.1 PPI 3 25.80 98.91 92.79 Cri.1 ModelNet 4 8.78 Cri.1 PPI 4 25.80 99.38 92.34 Cri.1 ModelNet 5 8.93 Cri.1 PPI 5 24.49 99.44 92.79 Cri.1 ModelNet 6 8.19 Cri.1 PPI 6 29.73 99.44 92.30 Cri.1 ModelNet 7 8.63 Cri.1 PPI 7 24.50 99.44 92.83 Cri.1 ModelNet 8 8.63 Cri.1 PPI 8 21.87 99.43 92.71 Cri.1 ModelNet 9 8.63 Cri.1 PPI 9 24.49 99.44 92.87 Cri.1 ModelNet 10 9.23 Cri.1 PPI 10 23.18 99.46 92.79 Kendall Ï 11.65 3.09 2.50 0.16 Average 8.78Â±0.30 Average 25.01Â±2.24 99.38Â±0.17 92.69Â±0.20 Best Model 8.63 92.87 Best Model 23.18 99.46</cell></row></table><note>Table 16. Results of SGAS with Criterion 1 on PPI.</note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karim</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Torresani</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.09582</idno>
		<title level="m">Connectivity learning in multi-branch networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning to learn by gradient descent by gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Andrychowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Misha</forename><surname>Denil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Pfau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendan</forename><surname>Schaul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nando De</forename><surname>Shillingford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3981" to="3989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Point convolutional neural networks by extension operators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matan</forename><surname>Atzmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haggai</forename><surname>Maron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaron</forename><surname>Lipman</surname></persName>
		</author>
		<idno>71:1-71:12</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Three-dimensional point cloud classification in real-time using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhak</forename><surname>Ben-Shabat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Lindenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anath</forename><surname>Fischer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robotics and Automation Letters</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="3145" to="3152" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Understanding and simplifying one-shot architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter-Jan</forename><surname>Kindermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="549" to="558" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Smash: one-shot model architecture search through hypernetworks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theodore</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Ritchie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weston</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.05344</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Activitynet: A large-scale video benchmark for human activity understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Fabian Caba Heilbron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Escorcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan</forename><forename type="middle">Carlos</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Niebles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="961" to="970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ligeng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.00332</idno>
		<title level="m">Proxylessnas: Direct neural architecture search on target task and hardware</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Progressive differentiable architecture search: Bridging the depth gap between search and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.12760</idno>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Fairnas: Rethinking evaluation fairness of weight sharing neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangxiang</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruijun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jixiang</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uwe</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3213" to="3223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dandelion</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Mane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Autoaugment</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.09501</idno>
		<title level="m">Learning augmentation policies from data</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">ImageNet: A Large-Scale Hierarchical Image Database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR09</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Fast graph representation learning with pytorch geometric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">Eric</forename><surname>Lenssen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.02428</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Bilevel programming for hyperparameter optimization and meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Franceschi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Frasconi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saverio</forename><surname>Salzo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Riccardo</forename><surname>Grazzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimilano</forename><surname>Pontil</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.04910</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Vision meets robotics: The kitti dataset. The International</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Stiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Robotics Research</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1231" to="1237" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Milenas: Efficient neural architecture search via mixed-level reformulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaoyang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haishan</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijun</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Weyand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Andreetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.04861</idno>
		<title level="m">Mobilenets: Efficient convolutional neural networks for mobile vision applications</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Squeeze-and-excitation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7132" to="7141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="4700" to="4708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Gnas: A greedy neural architecture search method for multi-attribute learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Qi</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongfei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Hauptmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 ACM Multimedia Conference on Multimedia Conference</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A new measure of rank correlation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Maurice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kendall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1/2</biblScope>
			<biblScope unit="page" from="81" to="93" />
			<date type="published" when="1938" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<idno>abs/1609.02907</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">LÃ©on</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deepgcns: Making gcns go as deep as cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guohao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>MÃ¼ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guocheng</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Itzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdulellah</forename><surname>Delgadillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><forename type="middle">K</forename><surname>Abualshour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Thabet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ghanem</surname></persName>
		</author>
		<idno>abs/1910.06849</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deepgcns: Can gcns go as deep as cnns?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guohao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Mller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Thabet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Ghanem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Pointcnn: Convolution on x-transformed points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangyan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingchao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinhan</forename><surname>Di</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoquan</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In NeurIPS</title>
		<imprint>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>DollÃ¡r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Progressive neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Hierarchical representations for efficient architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chrisantha</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.09055</idno>
		<title level="m">Darts: Differentiable architecture search</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Geniepath: Graph neural networks with adaptive receptive paths</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziqi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaochao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Longfei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="4424" to="4431" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Neural architecture optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renqian</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7816" to="7827" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Shufflenet v2: Practical guidelines for efficient cnn architecture design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ningning</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai-Tao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="116" to="131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Trackingnet: A large-scale dataset and benchmark for object tracking in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adel</forename><surname>Bibi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Giancola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salman</forename><surname>Alsubaihi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Ghanem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="300" to="317" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Efficient neural architecture search via parameter sharing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Melody</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.03268</idno>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Pointnet: Deep learning on point sets for 3d classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Charles Ruizhongtai Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaichun</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Pointnet++: Deep hierarchical feature learning on point sets in a metric space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Charles Ruizhongtai Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5099" to="5108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Regularized evolution for image classifier architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esteban</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alok</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanping</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Convolutional neural fabrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shreyas</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Verbeek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4053" to="4061" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Evaluating the search phase of neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Sciuto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaicheng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Jaggi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudiu</forename><surname>Musat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Salzmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.08142</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Differentiable neural network architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Packer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Color indexing. International journal of computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Swain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Dana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ballard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="11" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Mnasnet: Platform-aware neural architecture search for mobile</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruoming</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2820" to="2828" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Kpconv: Flexible and deformable convolution for point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugues</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Emmanuel</forename><surname>Deschaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatriz</forename><surname>Marcotegui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">FranÃ§ois</forename><surname>Goulette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petar</forename><surname>VeliÄkoviÄ</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Lio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10903</idno>
		<title level="m">Graph attention networks</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Learning time/memoryefficient deep architectures with budgeted super networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Veniat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludovic</forename><surname>Denoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3492" to="3500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Local spectral graph convolution for point set feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Babak</forename><surname>Samari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaleem</forename><surname>Siddiqi</surname></persName>
		</author>
		<idno>Septem- ber 2018. 7</idno>
	</analytic>
	<monogr>
		<title level="m">The European Conference on Computer Vision (ECCV)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Dynamic graph cnn for learning on point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongbin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjay</forename><forename type="middle">E</forename><surname>Sarma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><forename type="middle">M</forename><surname>Solomon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">3d shapenets: A deep representation for volumetric shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhirong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuran</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linguang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxiong</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Aggregated residual transformations for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>DollÃ¡r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1492" to="1500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sirui</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hehui</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.09926</idno>
		<title level="m">Snas: stochastic neural architecture search</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">How powerful are graph neural networks? ArXiv</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keyulu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<idno>abs/1810.00826</idno>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">G-tad: Sub-graph localization for temporal action detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengmeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">S</forename><surname>Rojas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Thabet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Ghanem</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Pc-darts: Partial channel connections for memory-efficient differentiable architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhui</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaopeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guo-Jun</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongkai</forename><surname>Xiong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.05737</idno>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Shufflenet: An extremely efficient convolutional neural network for mobile devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengxiao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="6848" to="6856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Bayesnas: A bayesian approach for neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongpeng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Pan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Predicting multicellular function through multi-layer tissue networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marinka</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Bioinformatics</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01578</idno>
		<title level="m">Neural architecture search with reinforcement learning</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Learning transferable architectures for scalable image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="8697" to="8710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Experiment Params (M) Test micro-F1 (%)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
				<title level="m">Table 17. Results of SGAS with Criterion 2 on PPI. Experiment Params (M) Test micro-F1 (%)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Table 18. Results of random search on PPI</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
