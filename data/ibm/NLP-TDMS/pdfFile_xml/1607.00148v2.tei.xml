<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">LSTM-based Encoder-Decoder for Multi-sensor Anomaly Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pankaj</forename><surname>Malhotra</surname></persName>
							<email>malhotra.pankaj@tcs.com</email>
							<affiliation key="aff0">
								<orgName type="institution">TCS Research</orgName>
								<address>
									<settlement>New Delhi</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anusha</forename><surname>Ramakrishnan</surname></persName>
							<email>anusha.ramakrishnan@tcs.com</email>
							<affiliation key="aff0">
								<orgName type="institution">TCS Research</orgName>
								<address>
									<settlement>New Delhi</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaurangi</forename><surname>Anand</surname></persName>
							<email>gaurangi.anand@tcs.com</email>
							<affiliation key="aff0">
								<orgName type="institution">TCS Research</orgName>
								<address>
									<settlement>New Delhi</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lovekesh</forename><surname>Vig</surname></persName>
							<email>lovekesh.vig@tcs.com</email>
							<affiliation key="aff0">
								<orgName type="institution">TCS Research</orgName>
								<address>
									<settlement>New Delhi</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Puneet</forename><surname>Agarwal</surname></persName>
							<email>puneet.a@tcs.com</email>
							<affiliation key="aff0">
								<orgName type="institution">TCS Research</orgName>
								<address>
									<settlement>New Delhi</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gautam</forename><surname>Shroff</surname></persName>
							<email>gau-tam.shroff@tcs.com</email>
							<affiliation key="aff0">
								<orgName type="institution">TCS Research</orgName>
								<address>
									<settlement>New Delhi</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">LSTM-based Encoder-Decoder for Multi-sensor Anomaly Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T11:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Mechanical devices such as engines, vehicles, aircrafts, etc., are typically instrumented with numerous sensors to capture the behavior and health of the machine. However, there are often external factors or variables which are not captured by sensors leading to time-series which are inherently unpredictable. For instance, manual controls and/or unmonitored environmental conditions or load may lead to inherently unpredictable time-series. Detecting anomalies in such scenarios becomes challenging using standard approaches based on mathematical models that rely on stationarity, or prediction models that utilize prediction errors to detect anomalies. We propose a Long Short Term Memory Networks based Encoder-Decoder scheme for Anomaly Detection (EncDec-AD) that learns to reconstruct 'normal' time-series behavior, and thereafter uses reconstruction error to detect anomalies. We experiment with three publicly available quasi predictable time-series datasets: power demand, space shuttle, and ECG, and two realworld engine datasets with both predictive and unpredictable behavior. We show that EncDec-AD is robust and can detect anomalies from predictable, unpredictable, periodic, aperiodic, and quasi-periodic time-series. Further, we show that EncDec-AD is able to detect anomalies from short time-series (length as small as 30) as well as long time-series (length as large as 500).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In real-world sensor data from machines, there are scenarios when the behavior of a machine changes based on usage and external factors which are difficult to capture. For  example, a laden machine behaves differently from an unladen machine. Further, the relevant information pertaining to whether a machine is laden or unladen may not be available. The amount of load on a machine at a time may be unknown or change very frequently/abruptly, for example, in an earth digger. A machine may have multiple manual controls some of which may not be captured in the sensor data. Under such settings, it becomes difficult to predict the time-series, even for very near future (see <ref type="figure" target="#fig_1">Figure 1</ref>), rendering ineffective prediction-based time-series anomaly detection models, such as ones based on exponentially weighted moving average (EWMA) <ref type="bibr" target="#b0">(Basseville &amp; Nikiforov, 1993)</ref>, SVR <ref type="bibr" target="#b10">(Ma &amp; Perkins, 2003)</ref>, or Long Short-Term Memory (LSTM) Networks .</p><p>LSTM networks <ref type="bibr" target="#b5">(Hochreiter &amp; Schmidhuber, 1997)</ref> are recurrent models that have been used for many sequence learning tasks like handwriting recognition, speech recognition, and sentiment analysis. LSTM Encoder-Decoder models have been recently proposed for sequence-tosequence learning tasks like machine translation <ref type="bibr" target="#b3">(Cho et al., 2014;</ref><ref type="bibr" target="#b13">Sutskever et al., 2014)</ref>. An LSTM-based encoder is used to map an input sequence to a vector representation of fixed dimensionality. The decoder is another LSTM network which uses this vector representation to produce the target sequence. Other variants have been proposed for natural language generation and reconstruction <ref type="bibr" target="#b9">(Li et al., 2015)</ref>, parsing , image captioning <ref type="bibr" target="#b1">(Bengio et al., 2015)</ref>.</p><p>We propose an LSTM-based Encoder-Decoder scheme for Anomaly Detection in multi-sensor time-series (EncDec-AD). An encoder learns a vector representation of the input time-series and the decoder uses this representation to reconstruct the time-series. The LSTM-based encoderdecoder is trained to reconstruct instances of 'normal' time-arXiv:1607.00148v2 [cs.AI] 11 Jul 2016 series with the target time-series being the input time-series itself. Then, the reconstruction error at any future timeinstance is used to compute the likelihood of anomaly at that point. We show that such an encoder-decoder model learnt using only the normal sequences can be used for detecting anomalies in multi-sensor time-series: The intuition here is that the encoder-decoder pair would only have seen normal instances during training and learnt to reconstruct them. When given an anomalous sequence, it may not be able to reconstruct it well, and hence would lead to higher reconstruction errors compared to the reconstruction errors for the normal sequences.</p><p>EncDec-AD uses only the normal sequences for training. This is particularly useful in scenarios when anomalous data is not available or is sparse, making it difficult to learn a classification model over the normal and anomalous sequences. This is especially true of machines that undergo periodic maintainance and therefore get serviced before anomalies show up in the sensor readings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">EncDec-AD</head><p>Consider a time-series</p><formula xml:id="formula_0">X = {x (1) , x (2) , ..., x (L) } of length L, where each point x (i) ∈ R m is an m-dimensional vec-</formula><p>tor of readings for m variables at time-instance t i . We consider the scenario where multiple such time-series are available or can be obtained by taking a window of length L over a larger time-series. We first train the LSTM Encoder-Decoder model to reconstruct the normal time-series. The reconstruction errors are then used to obtain the likelihood of a point in a test time-series being anomalous s.t. for each point x (i) , an anomaly score a (i) of the point being anomalous is obtained. A higher anomaly score indicates a higher likelihood of the point being anomalous.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">LSTM Encoder-Decoder as reconstruction model</head><p>We train an LSTM encoder-decoder to reconstruct instances of normal time-series. The LSTM encoder learns a fixed length vector representation of the input time-series and the LSTM decoder uses this representation to reconstruct the time-series using the current hidden state and the value predicted at the previous time-step. Given X, h</p><formula xml:id="formula_1">(i) E is the hidden state of encoder at time t i for each i ∈ {1, 2, ..., L}, where h (i) E ∈ R c ,</formula><p>c is the number of LSTM units in the hidden layer of the encoder. The encoder and decoder are jointly trained to reconstruct the timeseries in reverse order (similar to <ref type="bibr" target="#b13">(Sutskever et al., 2014)</ref></p><formula xml:id="formula_2">), i.e. the target time-series is {x (L) , x (L−1) , ..., x (1) }. The final state h (L)</formula><p>E of the encoder is used as the initial state for the decoder. A linear layer on top of the LSTM decoder layer is used to predict the target. During training, the decoder uses x (i) as input to obtain the state h (i−1) D , and then  </p><formula xml:id="formula_3">{x (1) , x (2) , x (3) } to predict {x (1) , x (2) , x (3) } predict x (i−1) corresponding to target x (i−1) . During in- ference, the predicted value x (i) is input to the decoder to obtain h (i−1) D and predict x (i−1) . The model is trained to minimize the objective X∈s N L i=1 x (i) − x (i) 2 , where s N is set of normal training sequences.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Computing likelihood of anomaly</head><p>Similar to , we divide the normal time-series into four sets of time-series: s N , v N 1 , v N 2 , and t N , and the anomalous time-series into two sets v A and t A . The set of sequences s N is used to learn the LSTM encoder-decoder reconstruction model. The set v N 1 is used for early stopping while training the encoder-decoder model. The reconstruction error vector for t i is given by</p><formula xml:id="formula_4">e (i) = |x (i) − x (i) |.</formula><p>The error vectors for the points in the sequences in set v N 1 are used to estimate the parameters µ and Σ of a Normal distribution N (µ, Σ) using Maximum Likelihood Estimation. Then, for any point x (i) , the anomaly score a (i) = (e (i) − µ) T Σ −1 (e (i) − µ).</p><p>In a supervised setting, if a (i) &gt; τ , a point in a sequence can be predicted to be "anomalous", otherwise "normal". When enough anomalous sequences are available, a threshold τ over the likelihood values is learnt to maximize F β = (1 + β 2 ) × P × R/(β 2 P + R), where P is precision, R is recall, "anomalous" is the positive class and "normal" is the negative class. If a window contains an anomalous pattern, the entire window is labeled as "anomalous". This is helpful in many real-world applications where the exact position of anomaly is not known. For example, for the engine dataset (refer Section 3), the only information available is that the machine was repaired on a particular date. The last few operational runs prior to repair are assumed to be anomalous and the first few operational runs after the repair are assumed to be normal. We assume β &lt; 1 since the fraction of actual anomalous points in a sequence labeled as anomalous may not be high, and hence lower recall is expected. The parameters τ and c are chosen with maximum F β score on the validation sequences in v N 2 and v A .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiments</head><p>We consider four real-world datasets: power demand, space shuttle valve, ECG, and engine (see <ref type="table" target="#tab_0">Table 1</ref>). The first three are taken from <ref type="bibr" target="#b7">(Keogh et al., 2005)</ref> whereas the engine dataset is a proprietary one encountered in a real-life project. The engine dataset contains data for two different applications: Engine-P where the time-series is quasi-predictable, Engine-NP where the time-series is unpredictable, for reasons such as mentioned earlier.</p><p>In our experiments, we consider architectures where both the encoder and decoder have single hidden layer with c LSTM units each. Mini-batch stochastic optimization based on Adam Optimizer <ref type="bibr" target="#b8">(Kingma &amp; Ba, 2014)</ref> is used for training the LSTM Encoder-Decoder. <ref type="table">Table 2</ref> shows the performance of EncDec-AD on all the datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Datasets</head><p>Power demand dataset contains one univariate time-series with 35, 040 readings for power demand recorded over a period of one year. The demand is normally high during the weekdays and low over the weekend. Within a day, the demand is high during working hours and low otherwise (see <ref type="figure" target="#fig_4">Figure 3(a)</ref>, top-most subplot). A week when any of the first 5 days has low power demands (similar to the demand over the weekend) is considered anomalous (see  <ref type="figure" target="#fig_4">Figure 3(b)</ref> where first day has low power demand). We downsample the original time-series by 8 to obtain nonoverlapping sequences with L = 84 such that each window corresponds to one week. Space shuttle dataset contains periodic sequences with 1000 points per cycle, and 15 such cycles. We delibrately choose L = 1500 such that a subsequence covers more than one cycle (1.5 cycles per subsequence) and consider sliding windows with step size of 500. We downsample the original time-series by 3. The normal and anomalous sequences in <ref type="figure" target="#fig_4">Figure 3</ref>(c)-3(d) belong to TEK17 and TEK14 time-series, respectively. Engine dataset contains readings for 12 sensors such as coolant temperature, torque, accelerator (control variable), etc. We consider two differents applications of the engine: Engine-P and Engine-NP. Engine-P has a discrete external control with two states: 'high' and 'low'. The resulting time-series are predictable except at the time-instances when the control variable changes. On the other hand, the external control for Engine-NP can assume any value within a certain range and changes very frequently, and hence the resulting time-series are unpredictable. Sample sequences for the control variables from Engine-P and Engine-NP are shown in <ref type="figure" target="#fig_1">Figure 1(a) and 1(b)</ref>, respectively. We randomly choose L = 30 for both Engine-P and Engine-NP. We reduce the multivariate time-series to univariate by considering only the first principal component after applying principal component analysis <ref type="bibr" target="#b6">(Jolliffe, 2002)</ref>. The first component captures 72% of the variance for Engine-P and 61% for Engine-NP. ECG dataset contains quasi-periodic time-series (duration of a cycle varies from one instance to another). For our experiment, we use the first channel from qtdb/sel102 dataset where the time-series contains one anomaly corresponding to a pre-ventricular contraction (see <ref type="figure" target="#fig_4">Figure 3</ref>(j)). We consider non-overlapping subsequences with L = 208 (each subsequence corresponds to approximately 800ms). Since only one anomaly is present in the dataset, sets v N 2 and v A are not created. The best model, i.e. c, is chosen based on the minimum reconstruction error on set v N 1 . We choose τ = µ a + σ a , where µ a and σ a are the mean and standard deviation of the anomaly scores of the points from v N 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Observations</head><p>The key observations from our experiments are as follows:</p><p>1) The positive likelihood ratio is significantly higher than 1.0 for all the datasets (see <ref type="table">Table 2</ref>). High positive likelihood ratio values suggest that EncDec-AD gives significantly higher anomaly scores for anomalous points as compared to normal points.</p><p>2) For periodic time-series, we experiment with varying window lengths: window length same as the length of one cycle (power demand dataset) and window length greater than the length of one cycle (space shuttle dataset). We also consider a quasi-periodic time-series (ECG). EncDec-AD is able to detect anomalies in all these scenarios.</p><p>3) A time-series prediction based anomaly detection model LSTM-AD  gives better results for the predictable datasets: Space Shuttle, Power and Engine-P (corresponding to Engine dataset in ) with F 0.1 scores of 0.84, 0.90 and 0.89, respectively. On the other hand, EncDec-AD gives better results for Engine-NP where the sequences are not predictable. The best LSTM-AD model gives P, R, F 0.05 and TPR/FPR of 0.03, 0.07, 0.03, 1.9, respectively (for a two hidden layer architecture with 30 LSTM units in each layer and prediction length of 1) owing to the fact that the time-series is not predictable and hence a good prediction model could not be learnt, whereas EncDec-AD gives P, R, F 0.1 score and TPR/FPR of 0.96, 0.18, 0.93 and 7.6, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Related Work</head><p>Time-series prediction models have been shown to be effective for anomaly detection by using the prediction error or a function of prediction error as a measure of the severity of anomaly <ref type="bibr" target="#b4">(Hayton et al., 2007;</ref><ref type="bibr" target="#b10">Ma &amp; Perkins, 2003;</ref><ref type="bibr" target="#b17">Ye et al., 2000)</ref>. Recently, deep LSTMs have been used as prediction models in LSTM-AD <ref type="bibr" target="#b2">Chauhan &amp; Vig, 2015;</ref><ref type="bibr" target="#b16">Yadav et al.)</ref> where a prediction model learnt over the normal time-series using LSTM networks is used to predict future points, and likelihood of prediction error is used as a measure of anomaly. EncDec-AD learns a representation from the entire sequence which is then used to reconstruct the sequence, and is therefore different from prediction based anomaly detection models. Non-temporal reconstruction models such as denoising autoencoders for anomaly detection <ref type="bibr" target="#b12">(Sakurada &amp; Yairi, 2014)</ref> and Deep Belief Nets <ref type="bibr" target="#b15">(Wulsin et al., 2010)</ref> have been proposed. For time-series data, LSTM based encoder-decoder is a natural extension to such models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Discussion</head><p>We show that LSTM Encoder-Decoder based reconstruction model learnt over normal time-series can be a viable approach to detect anomalies in time-series. Our approach works well for detecting anomalies from predictable as well as unpredictable time-series. Whereas many existing models for anomaly detection rely on the fact that the timeseries should be predictable, EncDec-AD is shown to detect anomalies even from unpredictable time-series, and hence may be more robust compared to such models. The fact that EncDec-AD is able to detect anomalies from time-series with length as large as 500 suggests the LSTM encoderdecoders are learning a robust model of normal behavior.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Presented at ICML 2016 Anomaly Detection Workshop, New York, NY, USA, 2016. Copyright c 2016 Tata Consultancy Services Ltd.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 .</head><label>1</label><figDesc>Readings for a manual control sensor.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>LSTM Encoder-Decoder inference steps for input</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2</head><label>2</label><figDesc>depicts the inference steps in an LSTM Encoder-Decoder reconstruction model for a sequence with L = 3.The value x (i) at time instance t i and the hidden state h(i−1) E of the encoder at time t i − 1 are used to obtain the hidden state h (i) E of the encoder at time t i . The hidden state h (3) E of the encoder at the end of the input sequence is used as the initial state h (3) D of the decoder s.t. h linear layer with weight matrix w of size c × m and bias vector b ∈ R m on top of the decoder is used to compute x (3) = w T h (3) D + b. The decoder uses h (i) D and prediction x (i) to obtain the next hidden state h (i−1) D .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 .</head><label>3</label><figDesc>Sample original normal (first column) and anomalous (second column) sequences (first row, blue color) with corresponding reconstructed sequences (second row, green color) and anomaly scores (third row, red color). The red regions in the original time-series for anomalous sequences correspond to the exact location of the anomaly in the sequence (whenever available). Plots in same row have same y-axis scale. The anomaly scores are on log-scale.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Nature of datasets. N , Nn and Na is no. of original sequences, normal subsequences and anomalous subsequences, respectively.</figDesc><table><row><cell>Datasets</cell><cell cols="4">Predictable Dimensions</cell><cell cols="2">Periodicity</cell><cell>N Nn Na</cell></row><row><cell>Power Demand</cell><cell>Yes</cell><cell></cell><cell>1</cell><cell></cell><cell cols="2">Periodic</cell><cell>1</cell><cell>45</cell><cell>6</cell></row><row><cell>Space Shuttle</cell><cell>Yes</cell><cell></cell><cell>1</cell><cell></cell><cell cols="2">Periodic</cell><cell>3</cell><cell>20</cell><cell>8</cell></row><row><cell>Engine-P</cell><cell>Yes</cell><cell></cell><cell>12</cell><cell></cell><cell cols="2">Aperiodic</cell><cell>30 240 152</cell></row><row><cell>Engine-NP</cell><cell>No</cell><cell></cell><cell>12</cell><cell></cell><cell cols="2">Aperiodic</cell><cell>6 200 456</cell></row><row><cell>ECG</cell><cell>Yes</cell><cell></cell><cell>1</cell><cell></cell><cell cols="3">Quasi-periodic 1 215</cell><cell>1</cell></row><row><cell>Datasets</cell><cell>L</cell><cell>c</cell><cell>β</cell><cell>P</cell><cell>R</cell><cell cols="2">F β -score TPR/FPR</cell></row><row><cell cols="6">Power Demand 84 40 0.1 0.92 0.04</cell><cell>0.77</cell><cell>33.0</cell></row><row><cell>Space Shuttle</cell><cell cols="5">500 50 0.05 0.83 0.08</cell><cell>0.81</cell><cell>4.9</cell></row><row><cell>Engine-P</cell><cell cols="5">30 40 0.05 0.94 0.02</cell><cell>0.82</cell><cell>13.8</cell></row><row><cell>Engine-NP</cell><cell cols="4">30 90 0.05 1.0</cell><cell>0.01</cell><cell>0.83</cell><cell>∞</cell></row><row><cell>ECG</cell><cell cols="5">208 45 0.05 1.0 0.005</cell><cell>0.65</cell><cell>∞</cell></row><row><cell>Table 2. F</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>β -scores and positive likelihood ratios (TPR/FPR).</note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Detection of Abrupt Changes: Theory and Application</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michèle</forename><surname>Basseville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><forename type="middle">V</forename><surname>Nikiforov</surname></persName>
		</author>
		<idno>0-13-126780-9</idno>
		<imprint>
			<date type="published" when="1993" />
			<publisher>Prentice-Hall, Inc</publisher>
			<pubPlace>Upper Saddle River, NJ, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Scheduled sampling for sequence prediction with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Samy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Oriol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1171" to="1179" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Anomaly detection in ecg time signals via deep long short-term memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sucheta</forename><surname>Chauhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lovekesh</forename><surname>Vig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Science and Advanced Analytics (DSAA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
	<note>IEEE International Conference on</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Van</forename><surname>Merriënboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Caglar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dzmitry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fethi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.1078</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Static and dynamic novelty detection methods for jet engine health monitoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Hayton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Utete</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Simukai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dennis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Steve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Anuzis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lionel</forename><surname>Tarassenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society of London A: Mathematical, Physical and Engineering Sciences</title>
		<imprint>
			<biblScope unit="volume">365</biblScope>
			<biblScope unit="page" from="493" to="514" />
			<date type="published" when="1851" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Long shortterm memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Principal component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Jolliffe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>Wiley Online Library</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Hot sax: Efficiently finding the most unusual time series subsequence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eamonn</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessica</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ada</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data mining, Fifth IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization. CoRR, abs/1412</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1412.6980" />
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">6980</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">A hierarchical neural autoencoder for paragraphs and documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Minh-Thang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.01057</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Online novelty detection on temporal sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junshui</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Perkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the ninth ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="613" to="618" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Long short term memory networks for anomaly detection in time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pankaj</forename><surname>Malhotra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lovekesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gautam</forename><surname>Shroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Puneet</forename><surname>Agarwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ESANN, 23rd European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Anomaly detection using autoencoders with nonlinear dimensionality reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mayu</forename><surname>Sakurada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takehisa</forename><surname>Yairi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the MLSDA 2014 2Nd Workshop on Machine Learning for Sensory Data Analysis, MLSDA&apos;14</title>
		<meeting>the MLSDA 2014 2Nd Workshop on Machine Learning for Sensory Data Analysis, MLSDA&apos;14<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="4" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ilya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V ; Z</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weinberger</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>K. Q.</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
	<note>Ghahramani,</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Grammar as a foreign language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Oriol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Łukasz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Koo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Terry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Slav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2755" to="2763" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Semi-supervised anomaly detection for eeg waveforms using deep belief nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Drausin</forename><surname>Wulsin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Blanco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ram</forename><surname>Mani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Litt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning and Applications (ICMLA), 2010 Ninth International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="436" to="441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Ode-augmented training improves anomaly detection in sensor data from machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Yadav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Malhotra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pankaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lovekesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sriram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gautam</forename><surname>Shroff</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1605.01534" />
	</analytic>
	<monogr>
		<title level="m">NIPS Time Series Workshop</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A markov chain model of temporal behavior for anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nong</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2000 IEEE Systems, Man, and Cybernetics Information Assurance and Security Workshop</title>
		<meeting>the 2000 IEEE Systems, Man, and Cybernetics Information Assurance and Security Workshop<address><addrLine>NY</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">166</biblScope>
			<biblScope unit="page">169</biblScope>
		</imprint>
		<respStmt>
			<orgName>West Point</orgName>
		</respStmt>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
