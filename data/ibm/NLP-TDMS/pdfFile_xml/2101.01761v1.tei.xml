<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">AutoDropout: Learning Dropout Patterns to Regularize Deep Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Google Research</orgName>
								<orgName type="institution" key="instit2">Brain Team</orgName>
								<address>
									<postCode>94043</postCode>
									<settlement>Mountain View</settlement>
									<region>CA</region>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Google Research</orgName>
								<orgName type="institution" key="instit2">Brain Team</orgName>
								<address>
									<postCode>94043</postCode>
									<settlement>Mountain View</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">AutoDropout: Learning Dropout Patterns to Regularize Deep Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T08:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Neural networks are often over-parameterized and hence benefit from aggressive regularization. Conventional regularization methods, such as Dropout <ref type="bibr" target="#b49">(Srivastava et al. 2014)</ref> or weight decay, do not leverage the structures of the network's inputs and hidden states. As a result, these methods are less effective than recent methods that leverage the structures, such as SpatialDropout (Tompson et al. 2020) and DropBlock (Ghiasi, Lin, and Le 2018), which randomly drop the values at certain contiguous areas in the hidden states and setting them to zero. Although the locations of dropout areas are random, the patterns of SpatialDropout and DropBlock are manually designed and fixed. Here we propose AutoDropout, which automates the process of designing dropout patterns. In our method, a controller learns to generate a dropout pattern at every channel and layer of a target network, such as a Con-vNet or a Transformer. The target network is then trained with the dropout pattern, and its resulting validation performance is used as a signal for the controller to learn from. We show that this method works well for both image recognition on CIFAR-10 and ImageNet, as well as language modeling on Penn Treebank and WikiText-2. The learned dropout patterns also transfers to different tasks and datasets, such as from language model on Penn Treebank to Engligh-French translation on WMT 2014. Our code will be available. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Modern neural networks are often over-parameterized <ref type="bibr" target="#b39">(Nakkiran et al. 2020</ref>) and thus require proper regularization to avoid overfitting. A common regularization method is Dropout <ref type="bibr" target="#b49">(Srivastava et al. 2014)</ref>, which randomly selects neurons from some intermediate layers of a network and replaces the values of these neurons with zero. In other words, we drop these neurons out of the current step of training. More recent studies show that imposing certain structures to the dropped neurons can lead to significant improvements over dropout neurons uniformly at random <ref type="bibr" target="#b21">(Huang et al. 2016;</ref><ref type="bibr">Tompson et al. 2020;</ref><ref type="bibr" target="#b16">Ghiasi, Lin, and Le 2018;</ref><ref type="bibr" target="#b15">Gal and Ghahramani 2016b;</ref><ref type="bibr" target="#b64">Zoph et al. 2018;</ref><ref type="bibr" target="#b59">Zaremba, Sutskever, and Vinyals 2014;</ref><ref type="bibr">Vaswani et al. 2017)</ref>. In practice, however, the dropout patterns are adapted to become different for different applications.</p><p>Copyright Â© 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. 1 Code repository: https://github.com/google-research/googleresearch/tree/master/auto_dropout. For example, in the text domain, <ref type="bibr" target="#b59">Zaremba, Sutskever, and Vinyals (2014)</ref> suggest that, for a multi-layered LSTM <ref type="bibr" target="#b19">(Hochreiter and Schmidhuber 1997)</ref>, it is better to only drop the neurons in the vertical connections than to drop the neurons everywhere. <ref type="bibr" target="#b15">Gal and Ghahramani (2016b)</ref> later propose Variational Dropout, where they drop neurons everywhere in the network but share a dropout pattern along the temporal dimension. Both methods, however, are not used in the recent Transformer architecture, which only uses vanilla Dropout. The differences in how LSTM and Transformer implement Dropout suggest that dropout patterns need to be tailored to different model architectures in NLP.</p><p>In the image domain, vanilla Dropout is often only applied to the fully-connected layers within a ConvNet <ref type="bibr" target="#b18">(He et al. 2016;</ref><ref type="bibr" target="#b58">Zagoruyko and Komodakis 2016;</ref><ref type="bibr" target="#b17">Han, Jiwhan, and Kim 2017;</ref><ref type="bibr" target="#b20">Hu et al. 2018;</ref><ref type="bibr" target="#b50">Szegedy et al. 2016</ref>). Other convolutional layers often require the dropout neurons to have particular structures. For example, stochastic depth <ref type="bibr" target="#b21">(Huang et al. 2016</ref>) drops the whole residual branch in residual networks, and DropPath <ref type="bibr" target="#b64">(Zoph et al. 2018</ref>) drops a whole branch in multi-branched convolutional cells. <ref type="bibr" target="#b16">Ghiasi, Lin, and Le (2018)</ref> propose DropBlock which drop contiguous squares of neurons in the convolutional layers. While DropBlock works well on ResNet-50 and AmoebaNet <ref type="bibr" target="#b43">(Real et al. 2018)</ref>, it is not proven to be successful in more recent architectures such as EfficientNet <ref type="bibr">(Tan, Pang, and Le 2020)</ref> and EfficientDet <ref type="bibr">(Tan, Pang, and Le 2020;</ref><ref type="bibr" target="#b62">Zoph et al. 2019)</ref>. Again, the differences in the way ConvNet architectures use dropout patterns suggest that they also need to be specialized to architectures.</p><p>By studying the dropout patterns from previous works, we observe that these patterns are difficult to design and need to be specialized for each model architecture, task, and domain. In this work, we address this difficulty by learning a specialized pattern for each model architecture, task, and domain. To this end, we propose AutoDropout which automates the process of designing specialized dropout patterns. The main contribution of AutoDropout is a novel search space of structured dropout patterns. In the search space we design, one can find a suitable for each model architecture and task. Our search space generalizes many existing dropout patterns <ref type="bibr" target="#b49">(Srivastava et al. 2014;</ref><ref type="bibr">Gal and Ghahramani 2016a,b;</ref><ref type="bibr" target="#b21">Huang et al. 2016;</ref><ref type="bibr" target="#b16">Ghiasi, Lin, and Le 2018)</ref>. For example, <ref type="figure">Figure 1</ref> shows a dropout pattern from our search space. The pattern is generated by tiling a contiguous area and then transforming it geometrically. The resulting pattern is applied to a convolutional output channel, which is a common building block of image recognition models.</p><p>Our implementation of AutoDropout has a controller that is trained by reinforcement learning (RL). The reward for the RL is the validation performance of the dropout pattern on a target network on a dataset of interest. We design a distributed RL-based search algorithm, which allows us to maximally leverage all machines available on an arbitrary cluster of computational nodes. <ref type="bibr">2</ref> Our experiments show that AutoDropout can find dropout patterns that significantly improve commonly-used ConvNet and Transformer architectures. On ImageNet, AutoDropout improves the top-1 accuracy of ResNet-50 from 76.5% to 78.7%, and EfficientNet-B7 from 84.1% to 84.7%. In the semi-supervised setting with CIFAR-10-4000, AutoDropout also improves the accuracy of Wide-ResNet-28-2 from 94.9% to 95.8%. For language modeling, AutoDropout reduces the perplexity of Transformer-XL <ref type="bibr" target="#b10">(Dai et al. 2019)</ref> on Penn Treebank from 56.0 to 54.9.</p><p>Additionally, when transferred to German-to-English translation on the IWSLT 14 dataset, the dropout pattern found by AutoDropout improves Transformer's BLEU score from 34.4 to 35.8, which is a new state-of-the-art on this dataset. On English-to-French translation with WMT 2014, the transferred dropout pattern also yields an improvement of 1.9 BLEU scores over the Transformer model with vanilla Dropout.</p><p>Although the search cost of AutoDropout can be high, a simple use case of AutoDropout is to drop our found patterns into existing pipelines in the same way that AutoAugment policies <ref type="bibr" target="#b8">(Cubuk et al. 2019a</ref>) were used to improve state-ofthe-art models.</p><p>Related works. Our work has the same philosophy with existing neural architecture search and AutoAugment lines of research <ref type="bibr" target="#b42">(Pham et al. 2018;</ref><ref type="bibr" target="#b32">Liu, Simonyan, and Yang 2019;</ref><ref type="bibr" target="#b63">Zoph and Le 2017;</ref><ref type="bibr" target="#b64">Zoph et al. 2018;</ref><ref type="bibr" target="#b2">Bello et al. 2017b;</ref><ref type="bibr" target="#b8">Cubuk et al. 2019a;</ref><ref type="bibr" target="#b40">Park et al. 2019;</ref><ref type="bibr" target="#b30">Lim et al. 2019;</ref><ref type="bibr" target="#b51">Tan and Le 2019;</ref><ref type="bibr" target="#b43">Real et al. 2018;</ref><ref type="bibr" target="#b37">Mirhoseini et al. 2017;</ref><ref type="bibr" target="#b1">Bello et al. 2017a;</ref><ref type="bibr" target="#b9">Cubuk et al. 2019b;</ref><ref type="bibr" target="#b44">Real et al. 2017;</ref>. We create a search space comprising the possible decisions and then use RL to search for the best decision.</p><p>More specifically, AutoDropout can also be viewed as data augmentation in the networks' hidden states. We generalize the successful approaches of searching for data augmentation <ref type="bibr" target="#b40">(Park et al. 2019;</ref><ref type="bibr">Cubuk et al. 2019a,b;</ref><ref type="bibr" target="#b30">Lim et al. 2019)</ref> and apply them to the hidden states of ConvNets and Transformer networks. Unlike data augmentations, which are domainspecific, our dropout patterns for the hidden states have the same design philosophy on ConvNets for image recognition models and Transformer for text understanding models. CutMix <ref type="bibr" target="#b57">(Yun et al. 2019)</ref> and <ref type="bibr">ManifoldMixup (Verma et al. 2019a</ref>) also apply successful data augmentation techniques such as CutOut (DeVries and Taylor 2017) and Mixup <ref type="bibr" target="#b60">(Zhang et al. 2018)</ref> into the hidden states. Implicit Semantic Data Augmentation (ISDA; <ref type="bibr" target="#b52">Wang et al. (2019)</ref>) approximate a Gaussian distribution of ConvNets' hidden states using the moving averages of their mean and standard deviations to generate more training examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>Representing dropout patterns. We represent the dropout patterns in our search space using elementwise multiplicative masks as adopted by many previous works <ref type="bibr" target="#b49">(Srivastava et al. 2014;</ref><ref type="bibr">Gal and Ghahramani 2016a,b;</ref><ref type="bibr" target="#b21">Huang et al. 2016;</ref><ref type="bibr" target="#b64">Zoph et al. 2018;</ref><ref type="bibr" target="#b16">Ghiasi, Lin, and Le 2018;</ref><ref type="bibr">Vaswani et al. 2017)</ref>. To bridge the gap between training, when the mask is used, and inference, when the mask is not used, we scale the values of the non-drop neurons properly during training. Specifically, to apply a dropout pattern to a layer h of a neural network, we randomly generate a binary mask m of the same shape with h. We then scale the values in the mask m, and replace h with:</p><formula xml:id="formula_0">Drop(h, m) = h â Size(m) Sum(m) Â· m<label>(1)</label></formula><p>Dimensional notations. In modern deep learning frameworks <ref type="bibr" target="#b0">(Abadi et al. 2016;</ref><ref type="bibr" target="#b41">Paszke et al. 2019)</ref>, intermediate layers are represented as high dimensional tensors. We denote the general shape of a tensor as (N, d 1 , d 2 , ..., d k , C), where N is the batch dimension, C is the feature dimension, and d 1 , d 2 , ..., d k are the spatiotemporal dimensions. For instance, a layer in a typical ConvNet has a shape of (N, H, W, C) where H and W are the layer's height and width; while a Transformer layer has the output of shape (N, T, C) where T is the temporal dimension which represents the number of tokens. Our method is general and works well for both ConvNets and Transformers where the spatiotemporal dimensions are different from each other. In the following, we will first discuss the search space for ConvNets, and then discuss how we generalize it to Transformers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Search Space for Dropout Patterns in ConvNets</head><p>Basic patterns. The basic pattern in our search space is a contiguous rectangle. The rectangle is then tiled to produce a dropout pattern. For ConvNets, the hyper-parameters that define the basic rectangle are two sizes height and width. The hyper-parameters that define the tiling are the stride and the number of repeats. <ref type="figure">Figure 2</ref> shows an example. For C channels, we can either sample C independent dropout patterns, or we can sample only one dropout pattern and then share it along the feature dimension.</p><p>Geometric transformations. In addition to tiling the rectangles, we introduce two geometric transformations into our search space: rotating about the spatial center, and shearing along each spatial dimension. When the transformations result in fractional coordinates, we round them to the nearest integers. Where to apply the dropout pattern. Once we have a dropout pattern, there is a decision about where we should apply it to. Here, we apply the dropout pattern to the output of batch normalization layers because we empirically observe that applying the pattern elsewhere in the network often leads to unstable training during our search process. If there is a residual connection in the ConvNet to regularize, then there is a choice of whether we should apply the dropout pattern to the residual branch as well. We leave this decision to the controller. Appendix Details on the Search Spaces for ConvNets visualizes where the noise masks are applied in some network architectures in our experiments in <ref type="figure" target="#fig_3">Figure 7</ref>, and specifies more details about our ConvNet search space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Controller Model and Search Algorithms</head><p>Model Architecture and Search Algorithm. We parameterize our controller with a Transformer network, as illustrated in <ref type="figure">Figure 3</ref>. We train the parameters Î¸ of our controller using the REINFORCE algorithm with a standard moving average baseline <ref type="bibr" target="#b53">(Williams 1992)</ref>. That is, we optimize Î¸ to minimize the objective via Monte Carlo gradient estimation:</p><formula xml:id="formula_1">J(Î¸) = E râ¼P (r;Î¸) [Perf(r)] â Î¸ J = 1 M M i=1 (Perf(r i ) â b) Â· â Î¸ log P (r i ; Î¸)<label>(2)</label></formula><p>Here, b is the moving average baseline, M is the empirical batch size which we set to 16, and Perf(r) is measured by training a target network with a dropout pattern r on a designated proxy task's validation set. We find it important to tailor the proxy task according to the actual downstream task. We discuss our proxy tasks in detailed in Experiments.</p><p>Improving Parallelism. Previous works in architecture search and data augmentation search <ref type="bibr" target="#b63">(Zoph and Le 2017;</ref><ref type="bibr" target="#b64">Zoph et al. 2018;</ref><ref type="bibr" target="#b2">Bello et al. 2017b;</ref><ref type="bibr" target="#b8">Cubuk et al. 2019a;</ref><ref type="bibr" target="#b40">Park et al. 2019;</ref><ref type="bibr" target="#b51">Tan and Le 2019)</ref> typically wait for minibatches of M dropout patterns to finish training before making every update on Î¸. Since each child model can take significantly long to train, and is subjected to multiple failures, such as jobs being descheduled on a shared cluster, waiting for M dropout patterns to finish can cause an unnecessary bottleneck.</p><p>To alleviate this bottleneck, we propose a modification. Specifically, in a shared environment, the number of available machines will vary over time. Sometimes, the number of machines will be lower than M . In this case, we will have to use this low number of machines to slowly compute the rewards for M configurations. However, sometimes the number of machines will be much higher than M . In such case, we want to generate many more than M jobs to take advantage of the available resources. But even in such case, for training stability, we only use a minibatch of M configurations, causing the other trained configurations to have stale gradient. To adjust for the staleness of their gradients, we need to reweigh the gradient properly as explained later.</p><p>Our implementation maintains two queues: a queue q unfinished of unfinished jobs and a queue q finished of finished jobs. Whenever the q unfinished contains less than its capacity C, the controller generates n = C â |q unfinished | new dropout patterns r 1 , r 2 , ..., r n and fills up q unfinished with the pairs (r i , P (r i ; Î¸ i )), where Î¸ i is the value of the controller's parameters at the time r i is sampled.</p><p>On the other hand, whenever a dropout pattern r finishes training, the controller dequeues (r, Perf(r)) from q unfinished and moves it into q finished . Whenever the capacity |q finished | reaches M , M configurations along with their accuracy are dequeued from q finished to perform an update on Î¸. The caveat of this approach is that due to many dropout patterns being executed in parallel, the controller parameter Î¸ when we update the controller with a configuration r i can be different from the Î¸ i when r i was generated. To account for this difference, we resort to importance sampling, which allows us to  <ref type="figure">Figure 3</ref>: Our controller is a Transformer network. The network generates the tokens to describe the configurations of the dropout pattern. The tokens are generated like words in a language model. For every layer in a ConvNet, a group of 8 tokens need to be made to create a dropout pattern. These 8 tokens are generated sequentially. In the figure above, size, stride, and repeat indicate the size and the tiling of the pattern; rotate, shear_x, and shear_y specify the geometric transformations of the pattern; share_c is a binary deciding whether a pattern is applied to all C channels; and residual is a binary deciding whether the pattern is applied to the residual branch as well. If we need L dropout patterns, the controller will generate 8L decisions.</p><p>write the training objective J(Î¸) as follows:</p><formula xml:id="formula_2">â Î¸ J(Î¸) = â Î¸ E râ¼P (r;Î¸) [Perf(r)] â 1 M M i=1 Perf(r i ) Â· P (r i ; Î¸) P (r i ; Î¸ i ) Â· â Î¸ log P (r i ; Î¸)<label>(3)</label></formula><p>Implementing this update rule simply requires scaling the gradient â Î¸ log P (r i ; Î¸) by the ratio of the two probabilities as shown in Equation 3. In our design, the only training bottleneck is the number of workers that can be run in parallel. In practice, distributed search procedures like ours typically run on a shared cluster, where the number of available workers varies instantly. Our design obviates the need to reserve all C workers throughout the search procedure and allows us to use a large value of C to achieve better parallelism when more workers are available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Search Space for Dropout Patterns in Transformers</head><p>Basic patterns. Intermediate layers in Transformer models typically have three dimensions (N, T, C), where N and C are the batch dimension and the channel dimension, similar to those of ConvNets, and T is the number of tokens, such as words or sub-word units. The dropout pattern for this dimension T is realized by generating four hyper-parameters: size, stride, share_t, and share_c. size indicates how many tokens does a pattern affects; stride indicates the number of tokens to be skipped by the pattern; share_t is a binary deciding whether all the tokens covered by size are set to zero using the same noise mask or independent noise masks; and share_c is a binary deciding whether a the dropout pattern shared along the channel dimension C. Once the values of size, stride, share_t, and share_c are decided, at each training step, we sample the starting position to apply the resulting dropout pattern. We repeat the pattern until the end of the sequence, following size and stride. <ref type="figure">Figure 4</ref> provides an illustration of a dropout pattern that our controller samples from our search space, and how the pattern is applied to a sequence of words. Many successful regularization patterns for text processing models are included in our basic patterns. For instance, WordDropout <ref type="bibr" target="#b47">(Sennrich, Haddow, and Birch 2016)</ref> can be realized from our patterns by setting share_c=True, while Variational Dropout <ref type="bibr" target="#b15">(Gal and Ghahramani 2016b)</ref> can be realized by setting share_t=True and setting size to the T , number of tokens in the sequence.</p><p>Where to apply the dropout pattern. Unlike the case for image recognition models, we find that the dropout patterns in our search space can be flexibly applied at multiple sublayers within a Transformer layer (e.g., on the query, key, value, softmax, output projection, and residual). As a result, we apply one independent dropout pattern to each of them. <ref type="figure" target="#fig_4">Figure 8</ref> in our Appendix Details on the Search Spaces for Transformer specifies all the possible places to apply the dropout patterns in our Transformer model. We will use this pattern at all Transformer layers in the Transformer network. In our implementation, size is overloaded, and if it has the value of zero, the dropout pattern is not applied at the corresponding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments</head><p>In the following sections, we will apply AutoDropout to both ConvNets and Transformers. For ConvNets, we first consider Supervised Image Classification and then we consider Semi-supervised Image Classification. For Transformer, we consider Language Model and Machine Translation applications. Finally, we compare our search method against random search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supervised Image Classification with ConvNets</head><p>We first evaluate AutoDropout on two standard benchmarks for image classification: CIFAR-10 (Krizhevsky 2009) and ImageNet <ref type="bibr" target="#b46">(Russakovsky et al. 2015)</ref>. For CIFAR-10, we use Wide ResNet 28-10 (WRN-28-10; Zagoruyko and Komodakis (2016)) because it is a common baseline on this dataset. For ImageNet, we consider ResNet-50 <ref type="bibr" target="#b18">(He et al. 2016)</ref> because it is a common architecture for ImageNet. We also consider EfficientNet (Tan and Le 2019) since it is closer to the state-of-the-art than ResNet. For each benchmark and model, we first use AutoDropout to search for a good dropout pattern on a proxy task, and then scale up the best found pattern to apply to the final task. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Search</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Transformer Layers</head><p>Controller Token Embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sample Self Attention Outputs</head><p>Word Embeddings <ref type="figure">Figure 4</ref>: An example of our controller generating ad dropout pattern for a self-attention operation. Top: the controller's outputs. The tokens have the following meanings: size=2 and stride1 means that the dropout pattern affects two consecutive tokens, then skips two token, then affects the next two consecutive tokens, and so on; share_t=True means that every block of two consecutive tokens that the dropout pattern affects shares the same dropout mask; share_c=False means that each of the C feature dimensions of the (N, T, C) tensor has its own independent mask. Bottom: The dropout pattern that the controller's outputs realize on the self-attention operation. The values in the red cells are set to zero, while the values in the green are kept intact. detailed training information of our controller. Here, we focus on the proxy tasks that we design to reduce the Auto-Dropout's search time. We scale down the final architecture and reduce the amount of data for the final task as follows.</p><p>For CIFAR-10, we search with a WRN-28-2 on the entire dataset, reserving 10% of the original training set for validation. For ImageNet, we scale down ResNet-50 and EfficientNet-B0 so that each of their layers has half the number of channels as the original models. We use 80,000 examples for training and 5,000 examples for validation. The controller's reward is the accuracy of the dropout pattern on the validation set. We train each dropout pattern on CIFAR-10 for 32,000 steps, and train each pattern on ImageNet for 16,000 steps. Under these settings, each dropout pattern trains in approximately 40 minutes on both datasets. Our search explores 16,384 patterns for each task.</p><p>Baselines. For WRN-28-10 and ResNet-50, we compare AutoDropout against DropBlock <ref type="bibr" target="#b16">(Ghiasi, Lin, and Le 2018)</ref>, since DropBlock has been well-tuned for these models. For EfficientNet, we compare AutoDropout with Stochastic Depth <ref type="bibr" target="#b21">(Huang et al. 2016</ref>) since it is the default noise-based regularization scheme of this architecture. We implement these baselines in our environment for fair comparison. Note that large EfficientNet models, such as B3, B5, B7 in our experiments, enlarge the spatial dimensions of the input images. For these models, we proportionally scale up the sizes and strides of the masks found by AutoDropout on these models. Training details of all models are in our Appendix Hyperparameters of Experiments.</p><p>Results. <ref type="figure">Figure 1</ref> reports the results of our control experiments on ResNets and EfficientNet. From <ref type="table" target="#tab_2">Table 1</ref>, it can be seen that AutoDropout outperforms DropBlock by 0.6% accuracy on CIFAR-10 with WRN-28-10, which corresponds to a 16% error reduction. Notably, on CIFAR-10 with WRN-28-10, DropBlock does not yield significant improvements compared to not using regularization at all, suggesting that the intuition on blocking contiguous regions is not sufficient. On ImageNet, AutoDropout improves the top-1 accuracy of ResNet-50 on ImageNet by 0.4% compared to DropBlock. AutoDropout improves the accuracy of all EfficientNet models by a margin of 0.7% on average. This is larger than the improvement of 0.5% that DropBlock delivers on AmoebaNet <ref type="bibr" target="#b16">(Ghiasi, Lin, and Le 2018;</ref><ref type="bibr" target="#b43">Real et al. 2018)</ref>, even though Ef-ficientNet baselines have higher accuracy than AmoebaNet.</p><p>Pushing the limits of ResNets. In the above experiments, we wanted to perform fair comparisons against other baselines, and did not combine AutoDropout with any data augmentation methods. Here, we aim to push the limits of WRN-28-10 and ResNet-50 by combining AutoDropout and other data augmentation methods. As such, we apply the pattern found by AutoDropout on CIFAR-10 with RandAugment <ref type="bibr" target="#b9">(Cubuk et al. 2019b</ref>) to WRN-28-10 and achieve 97.9% accuracy. We also apply the pattern found by AutoDropout on ImageNet with RandAugment and achieve 80.3% top-1 accuracy with ResNet-50 on ImageNet. These results outperform existing state-of-the-art results on these datasets with the same model architectures, as presented in <ref type="table" target="#tab_3">Table 2</ref>. <ref type="table" target="#tab_3">Table 2</ref> also shows that AutoDropout is the only method that improves the performance on both CIFAR-10 with WRN-28-10 and ImageNet with ResNet-50. Among other baselines, Manifold Mixup (Verma et al. 2019a) improves the CIFAR-10 accuracy but has a weak accuracy on ImageNet. Meanwhile, CutMix <ref type="bibr" target="#b57">(Yun et al. 2019</ref>) achieves good accuracy on ImageNet but worsens CIFAR-10 accuracy. These observations suggest that regularization methods that are validated for a certain architecture and dataset might not deliver as strong performance for another architecture and dataset, necessitating automated designing procedures like AutoDropout.  LGA+VAT <ref type="formula" target="#formula_0">(2019)</ref>   Qualitative analysis of good dropout patterns. Auto-Dropout finds several patterns that are unexpected. For example, the best noise pattern found for ResNet-50 on ImageNet, which is visualized in <ref type="figure">Figure 10</ref> in our Appendix Visualization of Good Dropout Patterns, only injects noise into the first and the last bottleneck convolutional blocks. These two blocks also have different noise patterns. This behavior is different from DropBlock <ref type="bibr" target="#b16">(Ghiasi, Lin, and Le 2018)</ref>, where a fixed and predefined mask of size 7x7 is applied at every layer. Additionally, rotation is applied in the first block, but not in the last block, suggesting that AutoDropout finds that rotational invariance should be enforced at the first block, where most low-level feature extracting happens, rather than in the last block, where most features have become more abstract. To validate the decisions of AutoDropout, we vary the locations where the dropout patterns are applied and observe about 1% drop in top-1 accuracy, which is significant for ResNet-50 on ImageNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Semi-supervised Image Classification with ConvNets</head><p>Experiment Settings. We now consider two typical benchmarks for semi-supervised image classification: CIFAR-10 with 4,000 labeled examples and ImageNet with 10% labeled examples. Since our search procedure of AutoDropout on Im-ageNet, as described in the previous section, uses a subset of images in ImageNet-10%, we simply take the same dropout patterns found in that setting. We make sure that ImageNet-10% contain the 80,000 images that we perform the search on. On CIFAR-10, we repeat our AutoDropout search with 3,600 training examples and 400 validation examples.</p><p>Baselines and Results. We apply AutoDropout into Unsupervised Data Augmentation (UDA; <ref type="bibr" target="#b54">Xie et al. (2019a)</ref>), since UDA has a simple implementation. As shown in <ref type="table" target="#tab_5">Table 3</ref>, the dropout patterns found by AutoDropout improves UDA by 0.9% on CIFAR-10 and 4.1% Top-1 accuracy on ImageNet.</p><p>Here we compare against recent representative strong baselines and skip earlier works such as <ref type="bibr">(Tarvainen and Valpola 2017;</ref><ref type="bibr" target="#b38">Miyato et al. 2018;</ref><ref type="bibr" target="#b27">Lee 2013)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Language Model and Machine Translation</head><p>In this section, we first apply AutoDropout to regularize Transformer-XL <ref type="bibr" target="#b10">(Dai et al. 2019)</ref> the task of language model on the Penn Treebank dataset (PTB; <ref type="bibr" target="#b34">Marcus et al. (1994)</ref>). PTB is a small dataset, with about 929K training tokens, 73K validation tokens, and 82K test tokens, on a vocabulary size of 10K. The small size of PTB makes it a suitable testbed for AutoDropout.</p><p>Search Configuration. We use the search space for Transformer models as described in the Section Search Space for Dropout Patterns inTransformers. Every dropout pattern that our controller sampled is employed to regularize a training process of Transformer-XL <ref type="bibr" target="#b10">(Dai et al. 2019)</ref>. We use the same model size as specified by <ref type="bibr" target="#b10">Dai et al. (2019)</ref>. We train every configuration from scratch for 160,000 steps, using a batch size of 16 and a segment length of 70. We use the cosine learning rate schedule so that each trial converges to a reasonable perplexity. On 4 TPU v2 chips, each of our runs takes about 40 minutes. The performance of a configuration r is computed by Perf(r) = 80/ValidPPL(r).  For PTB and WikiText-2, we report the model's perplexity (lower is better â). For IWSLT-14-DeEn and WMT-14-EnFr, we report BLEU scores (higher is better â).</p><p>Results. Our results for Transformer models are reported in <ref type="table" target="#tab_7">Table 4</ref>. Once again, hyper-parameters for each experiment are reported in our Appendix Hyper-parameters of Experiments. First, we take the dropout pattern that achieves the lowest perplexity on PTB and train for 300,000 steps. We compare our results with Variational Dropout, which is originally used by Transformer-XL <ref type="bibr" target="#b10">(Dai et al. 2019)</ref>. Under this setting, AutoDropout outperforms Variational Dropout by 1.1 perplexity, which is a significant improvement on this dataset.</p><p>Transfer learning results. To test the transferability of the found pattern, we also transfer it to three other tasks: 1) language modeling on WikiText-2 , 2) German-English translation on the IWSLT-14 dataset, and 3) English-French translation on the WMT-14 dataset. On Wiki-Text-2, we compare AutoDropout's dropout pattern against Variational Dropout because we find that it works better than vanilla Dropout on this task. On translation tasks, we compare AutoDropout's dropout pattern against the vanilla Dropout configurations that are typically applied in Transformer models <ref type="bibr">(Vaswani et al. 2017)</ref>.</p><p>Qualitative analysis of the AutoDropout's dropout pattern. For Transformer models, AutoDropout assigns different sizes and strides at different sub-layers in a Transformer layer. For instance, in our best dropout pattern, visualized in <ref type="figure">Figure 11</ref> in our Appendix, AutoDropout learns that the pattern for the multi-head attention layer is similar to Variational Dropout (Gal and Ghahramani 2016b), but the pattern for the positional feed-forward layer follows word dropout <ref type="bibr" target="#b47">(Sennrich, Haddow, and Birch 2016)</ref>. To validate that such decision is beneficial, we try to apply Variational Dropout in all layers of Transformer-XL and got the resulting validation perplexity of 59.8, which is 1.7 point higher than the configuration found by AutoDropout.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison with Random Search</head><p>Recent works on neural architecture search <ref type="bibr" target="#b29">(Li and Talwalkar 2019)</ref> show that random search is a strong search baseline.</p><p>Here we perform a controlled experiment to verify the advantage of AutoDropout's search process over random search.</p><p>To this end, we sample 512 uniformly random patterns from the search space for WRN-28-2 on CIFAR-10 and another 512 uniformly random patterns from the search space for Transformer-XL on PTB. We train each of these patterns to convergence, and compare the results against training the first 512 patterns suggested by AutoDropout under the same settings. In <ref type="figure" target="#fig_1">Figure 5</ref>, we plot the best-so-far performances of both methods, and observe substantial differences between AutoDropout and random search. Specifically, on CIFAR-10, the best patterns found by AutoDropout is more than 0.2% accuracy above that of Random Search. Recall that from <ref type="table" target="#tab_2">Table 1</ref>, we know that the standard deviation of CIFAR-10 accuracy in our code base is less than 0.1%. This means that AutoDropout is more than 2x standard deviations away from random search and makes the difference significant. On PTB, the difference between AutoDropout and Random Search is more than 3 validation perplexity points, which is also significant for the dataset. We thus conclude that when searching for structured noise to regularize deep networks, RL search exhibits significant advantage compared to Random Search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion and Future Directions</head><p>We proposed AutoDropout, an algorithm to automatically design dropout patterns to regularize neural networks. Our algorithm successfully found dropout patterns that improve the performance of various ConvNets for image classification, as well as Transformer models for language modeling and machine translation. Currently, a weakness of Au-toDropout is that the method is computationally expensive. Therefore, a potential future direction is to develop more efficient search approaches, similar to the developments on architecture search <ref type="bibr" target="#b42">(Pham et al. 2018;</ref><ref type="bibr" target="#b32">Liu, Simonyan, and Yang 2019;</ref><ref type="bibr" target="#b31">Liu et al. 2017</ref>) and data augmentation search <ref type="bibr" target="#b30">(Lim et al. 2019;</ref><ref type="bibr" target="#b52">Wang et al. 2019;</ref><ref type="bibr" target="#b9">Cubuk et al. 2019b)</ref>.</p><p>Although the search cost of AutoDropout can be high, a simple use case of AutoDropout is to reuse our found patterns in the same way that AutoAugment policies <ref type="bibr" target="#b8">(Cubuk et al. 2019a</ref>) were used to improve state-of-the-art models. To date, the method of reusing the found AutoAugment <ref type="bibr" target="#b8">(Cubuk et al. 2019a)</ref> and RandAugment <ref type="bibr" target="#b9">(Cubuk et al. 2019b</ref>) policies has benefitied many state-of-the-art models on CIFAR-10 and ImageNet (e.g., <ref type="bibr" target="#b51">Tan and Le (2019)</ref>; <ref type="bibr" target="#b55">Xie et al. (2019b)</ref>; <ref type="bibr" target="#b45">Ridnik et al. (2020);</ref><ref type="bibr" target="#b13">Foret et al. (2020)</ref>  We use the same dropout pattern for layers with same spatial size. For instance, in a ResNet-50, there are 4 bottleneck convolutions groups: having has 3 blocks, 4 blocks, 6 blocks, and 3 blocks respectively. The spatial dimensions of these blocks are 56x56, 28x28, 14x14, and 7x7, decreasing by a factor of 2 after each block due to strided convolutions or spatial reduction pooling. To reduce the number of decisions that our controller has to make, within each of these 4 groups, the dropout patterns are kept the same (but the actual samples of the dropout masks are still random at training time). <ref type="figure">Figure 10</ref> in Appendix shows this sharing scheme in a pattern found by AutoDropout. Example geometric transformations. The geometric transformations, namely rotating and shearing along each dimensions, are implemented using projective transformations. <ref type="figure" target="#fig_2">Figure 6</ref> shows the effects of these transformations on some example dropout patterns. In this figure, we consider 3 RGB channels and visualize the patterns as they apply to the image. In our search space, the masks are applied to intermediate layers with many more channels.</p><p>Where to apply the dropout patterns. <ref type="figure" target="#fig_3">Figure 7</ref> specifies where we apply the dropout patterns for ConvNets. In general, we apply the dropout pattern after each batch normalization layer. If a convolutional block has a residual branch, which sometimes has a 1x1 convolution followed by batch normalization, then we also apply a dropout pattern after the normalization as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Details on the Search Spaces for Transformer</head><p>Details on generating dropout patterns. In our search space for Transformer, each dropout pattern is generated by its hyperparameters: size, stride, share_t, and share_c, in that order. The available values for the operations are summarized in <ref type="table" target="#tab_10">Table 6</ref>. We allow our controller to generate different patterns at different steps in a Transformer layer. Specifically, <ref type="figure" target="#fig_4">Figure 8</ref> shows where the dropout patterns could be applied, in a self-attention operation and in a positional feed-forward operation. If a self-attention operation uses multi-head attention, then we use the same dropout pattern across all heads. However, within each head, the position to apply the dropout pattern is randomly sampled at training time. Similarly, in a typical Transformer network, </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parameters Semantics Available Values</head><p>size How many consecutive tokens to affect 0, 10, 20, 30, 40, 50, 60, 70 stride How many consecutive tokens to skip 0, 5, 10, 15, 20 share_t Share a mask across the tokens to affect True, False share_c Share a pattern across channels True, False where multiple Transformer layers are stacked above each other, we use the same dropout pattern to all layers, but the actual dropout mask are generated randomly and independently at each layer. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Illustration for the Controller Parallel Training Algorithm</head><p>We provide an illustrative working example of the distributed reinforcement learning search algorithm for controller, as described in Section Controller Model and Search Algorithms. <ref type="figure">Figure 9</ref> visualizes the example. Our search process runs on a shared cluster. The controller has a queue q unfinished which stores the generated dropout patterns waiting to be executed, as the workers become available. In our example, suppose that thw cluster has only two available workers. The controller sequentially dequeues (r i , P (r i , Î¸ i )) and (r j , P (r j , Î¸ j )) and sends them to the two workers to train. When one of these dropout patterns finishes, say the i th on Worker 1 finishes, the controller sends (r i , Perf(r i )) into q finished and sends (r k , P (r k , Î¸ k )) into the now-available Worker 1 to train. Later, after the j th dropout pattern and the k th dropout pattern both finish, and the controller has finished sending their results to q finished , then q finished has M = 3 finished configurations, where M is the minibatch size for the controller updates. The controller now computes the gradients corresponding to the i th , j th , and k th dropout patterns, scales them according to the probability ratios as specified in Equation 3, and averages the resulting gradients to update its parameters.</p><p>If during the controller's training, more workers become available, then more dropout configurations from q unfinished can be sent to the available workers to train to enhance the model's better parallelism. This is a significant advantage compared to previous AutoML search algorithms, which always requires M workers to be available, or the search process has to stay idle waiting for the minibatches to finish. (1) <ref type="bibr">(2)</ref> (3) <ref type="figure">Figure 9</ref>: Illustration of our controller. From left tor right order with M = 3 and C 3.</p><p>(1) The controller generates up to C regularization rules and stores these rules in qspawn, along with their sample probabilities. <ref type="formula" target="#formula_1">(2)</ref> A fixed pool of workers dequeue the rules from qspawn and train a model with these rules. In this case, 2 workers dequeue and train 3 rules ri, rj, r k to produce Perf(ri), Perf(rj), Perf(r k ).</p><p>(3) When M rules have their Perf's measured, their corresponding gradients are computed using importance sampling as in Equation 3, and then are averaged to update the controller at its instantaneous parameter Î¸update. If we select C sufficiently large, the only bottleneck of this procedure is the number of available workers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hyper-parameters of Experiments</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :Figure 2 :</head><label>12</label><figDesc>An example dropout pattern from our search space applied to an convolutional output channel. Left: the input image. Middle: DropBlock sets contiguous square blocks in the channel to zero. Right: a dropout pattern in the search space of AutoDropout. More patterns in our noise space are described in Section Methods. Example of the basic patterns in our search space. A dropout pattern, represented in black and gray, is applied to a grid of while cells representing the tensors. The neuron corresponding to the gray cells are retained.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 5 :</head><label>5</label><figDesc>Best-so-far performances of the first 512 dropout patterns sampled by AutoDropout and by random search. Top: Accuracy on CIFAR-10 (higher is better); Bottom: ValidPPL on PennTreebank (lower is better).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 6 :</head><label>6</label><figDesc>Example noise patterns from our search space for image understanding models. Here, we visualize the noise applied on the RGB channels of an image for illustration purposes.(a): The original image. (b-c): Three different patterns, one for each of the RGB channels of an image, and the resulting image after applying the patterns. (d-e): Three channels RGB share the same pattern (which leads to the color black), and the resulting image by applying this shared pattern. Image best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 7 :</head><label>7</label><figDesc>For ConvNets, we apply the dropout patterns immediate after the batch normalization layers. Shown are the examples ConvNet blocks in our experiments: (a) post-activation ResNet; (b) pre-activation ResNet; (c) Mobile Inverse Convolutional cell (MBConv; (Tan and Le 2019)).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 8 :</head><label>8</label><figDesc>We apply the noise at various nodes inside a multi-head self-attention operation. Left: Noise in a two-headed attention operation. Right: Noise in a positional feed-forward operation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Configurations and Proxy Tasks. We refer readers to Appendix Hyper-parameters of Experiments for</figDesc><table><row><cell></cell><cell>size</cell><cell></cell><cell>stride</cell><cell cols="2">share_t</cell><cell>share_c</cell><cell></cell></row><row><cell></cell><cell>(2)</cell><cell></cell><cell>(1)</cell><cell cols="2">(True)</cell><cell>(False)</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>...</cell></row><row><cell></cell><cell>&lt;GO&gt;</cell><cell></cell><cell>size (2)</cell><cell cols="2">stride (1)</cell><cell>share_t (True)</cell><cell></cell><cell>share_c (False)</cell></row><row><cell cols="2">shared_mask</cell><cell>no_drop</cell><cell cols="2">shared_mask</cell><cell>no_drop</cell><cell cols="2">shared_mask</cell><cell>no_drop</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">self attention</cell><cell></cell><cell></cell><cell></cell></row><row><cell>four</cell><cell>of</cell><cell>the</cell><cell>five</cell><cell cols="2">surviving workers</cell><cell>have</cell><cell>&lt;unk&gt;</cell><cell>diseases</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Performance of AutoDropout and the baselines on supervised image classification (higher is better). This is a control experiment and all models are implemented by us.</figDesc><table><row><cell>Regularization</cell><cell></cell><cell cols="2">CIFAR-10</cell><cell></cell><cell>ImageNet</cell></row><row><cell>Methods</cell><cell></cell><cell cols="5">WRN-28-10 ResNet-50 EfficientNet-B0 EfficientNet-B3 EfficientNet-B5 EfficientNet-B7</cell></row><row><cell>None</cell><cell></cell><cell cols="2">96.1 Â± 0.12 76.5 / 93.4</cell><cell>76.2 / 92.9</cell><cell>â</cell><cell>â</cell><cell>â</cell></row><row><cell cols="4">DropBlock (Ghiasi, Lin, and Le 2018) 96.2 Â± 0.07 78.3 / 94.3</cell><cell>76.3 / 92.8</cell><cell>â</cell><cell>â</cell><cell>â</cell></row><row><cell cols="2">Stochastic Depth (Huang et al. 2016)</cell><cell cols="2">96.2 Â± 0.07 77.5 / 93.7</cell><cell>76.8 / 93.1</cell><cell>80.2 / 95.0</cell><cell>82.5 / 96.2</cell><cell>84.1 / 96.9</cell></row><row><cell>AutoDropout</cell><cell></cell><cell cols="2">96.8 Â± 0.09 78.7 / 94.3</cell><cell>77.5 / 93.8</cell><cell>80.9 / 95.6</cell><cell>83.1 / 96.5</cell><cell>84.7 / 97.1</cell></row><row><cell>Methods</cell><cell cols="3">CIFAR-10 (WRN-28-10) (ResNet-50) ImageNet</cell><cell></cell><cell></cell></row><row><cell>Stochastic Depth (2016)</cell><cell cols="2">96.2 Â± 0.07  â </cell><cell>77.5 / 93.7</cell><cell></cell><cell></cell></row><row><cell>DropPath (2017)</cell><cell>95.4</cell><cell></cell><cell>77.1 / 93.5</cell><cell></cell><cell></cell></row><row><cell>Manifold Mixup (2019a)</cell><cell cols="2">97.5 Â± 0.02</cell><cell>77.5 / 93.8</cell><cell></cell><cell></cell></row><row><cell>Mixup (2018)</cell><cell cols="2">97.1 Â± 0.08  â </cell><cell>77.9 / 93.9</cell><cell></cell><cell></cell></row><row><cell>CutMix (2019)</cell><cell cols="2">96.7 Â± 0.05  â </cell><cell>78.6 / 94.1</cell><cell></cell><cell></cell></row><row><cell>MoEx (2020)</cell><cell cols="2">96.7 Â± 0.03</cell><cell>79.1 / 94.3</cell><cell></cell><cell></cell></row><row><cell cols="3">CutMix+RandAugment (2019b) 97.0 Â± 0.06  â </cell><cell>78.3 / 94.2  â </cell><cell></cell><cell></cell></row><row><cell>CutMix+FixRes (2019)</cell><cell>n/a</cell><cell></cell><cell>79.8 / 94.9</cell><cell></cell><cell></cell></row><row><cell>AutoDropout+RandAugment</cell><cell cols="2">97.9 Â± 0.06</cell><cell>80.3 / 95.1</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table><row><cell>Methods</cell><cell>CIFAR-10-4K ImageNet-10% (WRN-28-2) (ResNet-50)</cell></row></table><note>Performance of AutoDropout and representative baselines on supervised image classification (higher is better). ( â ) denotes our implementation. CutMix+FixRes is not applicable for CIFAR-10 since we keep the image resolution at 32x32 for CIFAR-10.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Performance of AutoDropout and representative baselines on semi-supervised image classification (higher is better).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>Performance of Transformer and Transformer-XL models trained with default regularization techniques vs. trained with AutoDropout.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5 :</head><label>5</label><figDesc>Semantics of the hyper-parameters that specify a ConvNet dropout pattern and their available values in our search space.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 6 :</head><label>6</label><figDesc>Semantics of the hyper-parameters that specify a Transformer dropout pattern and their available values in our search space.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">We will release the datasets consisting of the dropout patterns that our search algorithm has sampled and run. Like the similar datasets collected from benchmarking various model architectures<ref type="bibr" target="#b56">(Ying et al. 2019;</ref><ref type="bibr" target="#b12">Dong and Yang 2019)</ref>.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Controller. We use a small Transformer model to parameterize our controller. Specifically, our Transformer architecture has 4 layers, with the hidden size of 128. Each multi-head attention operation uses 4 heads, and each head has the hidden dimension size of 32. The positional feed-forward has the inner dimension of 32. The controller's parameters are initialized at a normal distribution with zero mean and a standard deviation of 0.02. We update the controller's parameters using Adam <ref type="bibr" target="#b23">(Kingma and Ba 2015)</ref> with a constant learning rate of 0.00035 and the default values Î² 1 = 0.9, and Î² 2 = 0.999. We also use a moving average baseline with momentum 0.95 to stabilize the update, and an entropy regularization of 10 â5 to encourage the controller's explorations. For each search, our controller explores 16,384 dropout patterns in total, and updates its parameters using a batch size of 16, leading to 1,024 updates.</p><p>Image Recognition Models. In order to avoid tuning the dropout rate at each layer of a ConvNet, we specify a single dropout rate for the final convolutional layer. Previously layers have their dropout rate linearly increased from 0 to the specified value. During search time, we set the final value to 0.2. Once the search finishes, we tune the final value among the list of 0.1, 0.2, ..., 0.7. We find the with out dropout pattern, the ideal final dropout rate for WRN-28-10, ResNet-50, and EfficientNet are 0.6, 0.3, and 0.5. Apart from the layer-wise dropout rate, we use the same values with <ref type="bibr" target="#b51">Tan and Le (2019)</ref> for EfficientNet, the same values with Ghiasi, Lin, and Le (2018) for ResNet-50 on ImageNet, the same values with <ref type="bibr" target="#b54">Xie et al. (2019a)</ref> for WRN-28-{2,10} on CIFAR-10. Note that this means that we train ResNet-50 for 240 epochs, which is 1.5 times longer than normally done for this architecture, but we train EfficientNet for 350 epochs, which is the same with <ref type="bibr" target="#b51">Tan and Le (2019)</ref>.</p><p>Language Model. For both Penn Treebank and WikiText-2, we use the Transformer-XL architecture <ref type="bibr" target="#b10">(Dai et al. 2019</ref>), which has 16 layers, hidden size of 380, 10 heads each of dimension 38, and positional feed-forward inner size of 900. For Penn Treebank, this results in a model with 24 million parameters, while for WikiText-2, this results in a model with 35 million parameters. We use a dropout rate of 0.5 for the embedding layer, a dropout rate of 0.6 for the softmax layer. We find these dropout rates from the Penn Treebank code released by <ref type="bibr" target="#b10">Dai et al. (2019)</ref>. We use the dropout rate of 0.2 elsewhere in our Transformer-XL model. We also use the state-value and state-difference regularizations <ref type="bibr" target="#b35">(Merity, Keskar, and Socher 2017)</ref>, even though we do not observe significant raise in perplexities without using them. We train with Adam for 160K steps during AutoDropoutsearch, and 320K steps for the best architecture that AutoDropout finds. We using a cosine-decayed learning rate schedule <ref type="bibr" target="#b33">(Loshchilov and Hutter 2017)</ref>, starting at 3 Ã 10 â4 and decaying to 10 â4 throughout 80% of the training process. After the learning rate decays to 10 â4 , we continue the remaining 20$ of the training process with a constant learning rate of 5 Ã 10 â5 .</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head><p>AutoDropout: Learning Dropout Patterns to Regularize Deep Networks Details on the Search Spaces for ConvNets Details on generating dropout pattern. In our search space for ConvNets, each dropout pattern is generated by its hyperparameters: size, stride, repeat, share_c, residual, rotate, shear_x, and shear_y, in that order. The available values for the operations are summarized in <ref type="table">Table 5</ref>.</p><p>During the last 20% of the training procedure, we start collecting a moving average trail of the model's parameters. We perform one validation evaluation every 1,000 training steps and store the best model checkpoint. In the end, we obtain the test perplexity from the checkpoint with the lowest validation perplexity.</p><p>Machine Translation. We use the Transformer-Base architecture from <ref type="bibr">Vaswani et al. (2017)</ref>. We tokenize the training, validation, and test data by SentencePiece <ref type="bibr" target="#b25">(Kudo and Richardson 2018)</ref>, with a vocabulary size of 10,000 for the IWSLT 14 De-En dataset, and a vocabulary size of 32,000 for the WMT 14 En-Fr dataset. After tokenizing the data, we filter the training datasets, keeping only sentences that have no more than 360 tokens for IWSLT 14 De-En, and keeping only sentences that have mo nore than 200 tokens for WMT 14 En-Fr. We share the embeddings for both the encoder and the decoder Transformer, and use the same embedding matrix for softmax in the decoder. We train our models using Adam, with a learning rate linearly warming up for 4,000 steps to 1.6 Ã 10 â3 , and then decreasing to 0 using the cosine schedule. We train for 15,000 steps on IWSLT 14 De-En, and 35,000 steps on WMT 14 En-Fr. We do not use checkpoint averaging for decoding, which could potentially improve our results.</p><p>When we transfer the dropout pattern found on Penn Treebank to our machine translation experiments, we keep the same hyper-parameters: size, stride, share_t, and share_c. Unlike the language model tasks, we do not use embedding dropout or softmax dropout. We also set the dropout rate at all steps to 0.1.  <ref type="figure">Figure 11</ref>: The best dropout pattern that AutoDropout finds for Transformer-XL on Penn Treebank. Left: the dropout pattern in the self-attention operation. Right: the dropout pattern in the positional feed-forward operation. Meanings of the dropout pattern's hyper-parameters: At each step where the controller can apply a dropout pattern, we specify a tuple of (size, stride, share_t, share_c). size and stride specify how many consecutive tokens are affected by the dropout pattern, and then how many consecutive tokens are not affected by the pattern. share_t means whether the dropout pattern uses the same mask at all size temporal steps that it affects, and share_c) decides whether the pattern uses the same mask across the channel dimension. A tuple of None means that the controller decides to not apply any dropout pattern at the corresponding step. In this case, the controller does not apply any noise pattern on the residual branches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Visualization of Good Dropout Patterns</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">TensorFlow: A system for large-scale machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kudlur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Levenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Warden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wicke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
		<idno>1605.08695</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Neural Combinatorial Optimization with Reinforcement Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Bello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations Workshop</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Neural optimizer search with reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Bello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">ReMixMatch: Semi-Supervised Learning with Distribution Alignment and Augmentation Anchoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">MixMatch: A Holistic Approach to Semi-Supervised Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">AutoML for Architecting Efficient and Specialized Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ligeng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Micro</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A Simple Framework for Contrastive Learning of Visual Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">AutoAugment: Learning Augmentation Policies from Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">RandAugment: Practical data augmentation with no separate search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note>Arxiv 1909.13719 . 2, 5, 6</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Meeting of the Association for Computational Linguistics. 2, 6</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Improved Regularization of Convolutional Neural Networks with Cutout</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<idno>1708.04552 . 2</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">NAS-Bench-201: Extending the Scope of Reproducible Neural Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Sharpness-Aware Minimization for Efficiently Improving Generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Foret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kleiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mobahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Neyshabur</surname></persName>
		</author>
		<idno>Arxiv, 2010.01412 . 7</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A Theoretically Grounded Application of Dropout in Recurrent Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems. 1, 2, 4</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">DropBlock: A regularization method for convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ghiasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems. 1, 2, 5</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep Pyramidal Residual Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Jiwhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Long Short-term Memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Computations</title>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Squeeze-and-Excitation Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Albanie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deep Networks with Stochastic Depth</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sedra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision. 1</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Semi-Supervised Learning by Label Gradient Alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jackson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<idno>1902.02336 . 6</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Learning Multiple Layers of Features from Tiny Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<idno>. 4</idno>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods for Natural Language Processing</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Frac-talNet: Ultra-Deep Neural Networks without Residuals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Larsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Shakhnarovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Pseudo-Label: The Simple and Efficient Semi-Supervised Learning Method for Deep Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning Workshop</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-N</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<title level="m">On Feature Normalization and Data Augmentation. Arxiv</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Random Search and Reproducibility for Neural Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Talwalkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Uncertainty in Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Fast AutoAugment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<idno>1712.00559 . 7</idno>
	</analytic>
	<monogr>
		<title level="j">Progressive Neural Architecture Search. Arxiv</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">DARTS: Differentiable Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">SGDR: Stochastic Gradient Descent with Warm Restarts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The Penn Treebank: Annotating Predicate Argument Structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Marcinkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Macintyre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ferguson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schasberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Human Language Technology</title>
		<meeting>the Workshop on Human Language Technology</meeting>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Regularizing and Optimizing LSTM Language Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Merity</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">S</forename><surname>Keskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<idno>1708.02182 . 13</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Pointer Sentinel Mixture Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Merity</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Device Placement Optimization with Reinforcement Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mirhoseini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Larsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Virtual adversarial training: a regularization method for supervised and semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ishii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Koyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Deep Double Descent: Where Bigger Models and More Data Hurt</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Nakkiran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kaplun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Barak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-C</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">PyTorch: An Imperative Style, High-Performance Deep Learning Library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Efficient Neural Architecture Search via Parameter Sharing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Y</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Barret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Regularized Evolution for Image Classifier Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<idno>1802.01548 . 1</idno>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Large-Scale Evolution of Image Classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Selle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">S</forename><surname>Leon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">TResNet: High Performance GPU-Dedicated Architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ridnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lawen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Noy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Baruch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sharir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Arxiv</title>
		<imprint>
			<biblScope unit="volume">13630</biblScope>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">ImageNet Large Scale Visual Recognition Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Com</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>puter Vision . 4</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Edinburgh neural machine translation systems for wmt 16</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Birch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Machine Translation</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Liang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Dropout: A Simple Way to Prevent Neural Networks from Overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Rethinking the Inception Architecture for Computer Vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. 2, 3, 4</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Implicit Semantic Data Augmentation for Deep Networks Authors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Simple statistical gradient-following algorithms for connectionist reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Unsupervised Data Augmentation For Consistency Training. Arxiv, 1904.12848</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Selftraining with Noisy Student improves ImageNet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno>Arxiv 1911.04252 . 7</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">NAS-Bench-101: Towards Reproducible Neural Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Christiansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Wide Residual Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<idno>1409.2329 . 1</idno>
		<title level="m">Recurrent Neural Network Regularization. Arxiv</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">mixup: Beyond Empirical Risk Minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Local Label Propagation for Large-Scale Semi-Supervised Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Murli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yamins</surname></persName>
		</author>
		<idno>1905.11581 . 6</idno>
	</analytic>
	<monogr>
		<title level="j">Arxiv</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Learning Data Augmentation Strategies for Object Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ghiasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno>1906.11172 . 1</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Neural Architecture Search with Reinforcement Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Learning Transferable Architectures for Scalable Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
