<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Optimized Skeleton-based Action Recognition via Sparsified Graph Regression</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Gao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Science and Technology</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Science and Technology</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxiang</forename><surname>Tang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Science and Technology</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaying</forename><surname>Liu</surname></persName>
							<email>liujiaying@pku.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Science and Technology</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongming</forename><surname>Guo</surname></persName>
							<email>guozongming@pku.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computer Science and Technology</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Optimized Skeleton-based Action Recognition via Sparsified Graph Regression</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T11:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Graph regression</term>
					<term>graph convolutional net- works</term>
					<term>spatio-temporal graph modeling</term>
					<term>skeleton-based action recognition</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>With the prevalence of accessible depth sensors, dynamic human body skeletons have attracted much attention as a robust modality for action recognition. Previous methods model skeletons based on RNN or CNN, which has limited expressive power for irregular skeleton joints. While graph convolutional networks (GCN) have been proposed to address irregular graphstructured data, the fundamental graph construction remains challenging. In this paper, we represent skeletons naturally on graphs, and propose a graph regression based GCN (GR-GCN) for skeleton-based action recognition, aiming to capture the spatio-temporal variation in the data. As the graph representation is crucial to graph convolution, we first propose graph regression to statistically learn the underlying graph from multiple observations. In particular, we provide spatio-temporal modeling of skeletons and pose an optimization problem on the graph structure over consecutive frames, which enforces the sparsity of the underlying graph for efficient representation. The optimized graph not only connects each joint to its neighboring joints in the same frame strongly or weakly, but also links with relevant joints in the previous and subsequent frames. We then feed the optimized graph into the GCN along with the coordinates of the skeleton sequence for feature learning, where we deploy high-order and fast Chebyshev approximation of spectral graph convolution. Further, we provide analysis of the variation characterization by the Chebyshev approximation. Experimental results validate the effectiveness of the proposed graph regression and show that the proposed GR-GCN achieves the state-of-the-art performance on the widely used NTU RGB+D, UT-Kinect and SYSU 3D datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="figure">Fig. 1</ref><p>. The pipeline of the proposed GR-GCN for skeleton-based action recognition. Given a sequence of human body joints, we first learn a common sparsified spatio-temporal graph over each frame, its previous frame and the subsequent one via graph regression. This leads to a spatio-temporal graph with strong and physical edges (black solid lines), strong and non-physical edges (red dashed lines) and weak edges (green dashed ones) for variation modeling. We then feed the sparsified spatio-temporal graph into a graph convolutional network (GCN) along with the 3D coordinates of joints for variation learning, which leads to the output classification scores.</p><p>features and temporal dependencies. Recent methods learn these features via deep models like recurrent neural networks (RNN) <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b16">[17]</ref>- <ref type="bibr" target="#b22">[23]</ref> and convolutional neural networks (CNN) <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b23">[24]</ref>- <ref type="bibr" target="#b26">[27]</ref>. Nevertheless, the topology in skeletons is not fully exploited in the grid-shaped representation of RNN and CNN.</p><p>A natural way to represent skeletons is graph, where each joint is treated as a vertex in the graph, and the relationship among the joints is interpreted by edges with weights. As unordered graphs cannot be fed into RNN or CNN directly, graph convolutional networks (GCN) have been proposed to deal with data defined on irregular graphs for a variety of applications <ref type="bibr" target="#b27">[28]</ref>- <ref type="bibr" target="#b30">[31]</ref>. Yan et al. <ref type="bibr" target="#b31">[32]</ref> and Li et al. <ref type="bibr" target="#b32">[33]</ref> are the first to propose graph-based skeleton representation, which is then fed into the GCN to automatically learn the spatial and temporal patterns from data. Tang et al. <ref type="bibr" target="#b33">[34]</ref> propose a deep progressive reinforcement learning (DPRL) method to select the most informative frames of the input sequences and leverage GCN to learn the dependency among joints. Bin et al. <ref type="bibr" target="#b34">[35]</ref> propose a spatio-temporal graph routing (STGR) scheme for skeleton-based action recognition, which learns both the spatial connectivity and temporal connectivity. However, the graph constructions in these methods have certain limitations: graphs in <ref type="bibr" target="#b31">[32]</ref> are restricted by small partitions; graphs in <ref type="bibr" target="#b32">[33]</ref> only model joints bridged by a bone; there is no explicit temporal graph in <ref type="bibr" target="#b33">[34]</ref>; the computation complexity of graph learning in <ref type="bibr" target="#b34">[35]</ref> is high, and the spatial graph is built over clusters, each of which is assigned a weight and thus may not capture delicate pairwise spatial relationship among joints.</p><p>Since the graph construction is crucial to graph convolution in GCNs, we propose a graph regression based GCN (GR-GCN) model to further improve the graph construction of skeleton data for stronger expressive power, providing an alternate view of the action sequence. The problem of learning the underlying graph structure from data (a.k.a., graph regression) is fundamental and helps discover the relation among graph signals. In the context of dynamic skeletons, we provide spatio-temporal modeling of skeletons and pose an optimization problem on the underlying graph Laplacian matrix 1 over consecutive frames. The optimization not only enforces the graph Laplacian to capture the structure of each spatio-temporal frame (i.e., every three consecutive frames), but also impose the sparsity constraint on the graph for compact representation. We then obtain the common structure of the graph Laplacian optimized from multiple observations of spatio-temporal frames by statistical analysis. The resulting graph not only connects each joint to its neighboring joints in the same frame strongly or weakly, but also links with relevant joints in the previous and subsequent frames.</p><p>After learning the common optimal graph for spatiotemporal frames in a dynamic skeleton sequence, we feed the optimized graph into the GCN along with the coordinates of the skeleton sequence for feature learning. We deploy highorder and fast Chebyshev approximation of spectral graph convolution <ref type="bibr" target="#b30">[31]</ref>, which leads to final classification scores. Further, we provide analysis of the variation characterization by the Chebyshev approximation. We analyze that the Chebyshev approximation essentially extracts the variation of the coordinates of joints, which is suitable to learn action features for final classification. As strong edges in the graph reflect strong relationship among physical/non-physical connections and weak edges represent potential relationship among nonphysical connections, the proposed network strengthens learning actions which are accomplished by joints that are not bridged by bones (i.e., non-physical connections), such as "drink water" with the interaction between one hand and the head.</p><p>In summary, our contributions include the following aspects:</p><p>• We propose efficient graph regression to learn the underlying common graph of spatio-temporal frames in a dynamic skeleton sequence, by posing an optimization problem on the graph Laplacian from the constraints of data structure and sparsity.</p><p>• We integrate our graph regression with the GCN, and analyze the variation characterization by the Chebyshev approximation of spectral graph convolution, which leads to effective action feature learning.</p><p>• We achieve the state-of-the-art performance on the widely used NTU RGB+D, UT-Kinect and SYSU 3D datasets, and validate the effectiveness of the proposed graph regression. The rest of the paper is organized as follows. Section II reviews previous works on skeleton-based action recognition and GCNs. Next, we introduce some basic concepts in spectral graph theory in Section III. Then, we present the proposed spatio-temporal graph regression and sparsified graph construction in Section IV, and elaborate on the proposed GR-GCN in Section V. Finally, experimental results and conclusions are presented in Section VI and Section VII, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Skeleton-based Action Recognition</head><p>Previous skeleton-based action recognition methods can be divided into 2 classes <ref type="bibr" target="#b31">[32]</ref>: hand-crafted feature based methods and deep learning methods.</p><p>Hand-crafted feature based methods. Hand-crafted features include covariance matrix for skeleton joint locations over time as a discriminative descriptor <ref type="bibr" target="#b36">[37]</ref>, modeling human actions as curves in the Lie group <ref type="bibr" target="#b13">[14]</ref>, and Spatio-Temporal Naive-Bayes Nearest-Neighbor <ref type="bibr" target="#b15">[16]</ref>, etc. However, these methods either lose information of interactions between specific sets of body parts or depend on complicated handcrafted features.</p><p>Deep learning methods. Recent methods learn features via deep learning due to the notable performance, including RNN <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b16">[17]</ref>- <ref type="bibr" target="#b22">[23]</ref> and CNN <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b23">[24]</ref>- <ref type="bibr" target="#b26">[27]</ref>. However, these methods typically lose structural information when converting the raw skeleton data into the grid-shaped input of the neural networks. A natural way to address this issue is to represent skeleton data on graphs. Yan et al. <ref type="bibr" target="#b31">[32]</ref> and Li et al. <ref type="bibr" target="#b32">[33]</ref> are the first to employ GCNs to automatically learn both the spatial and temporal patterns from data. Specifically, Yan et al. <ref type="bibr" target="#b31">[32]</ref> construct graph convolution operations on partitions, which however may not capture the relationship among joints in different partitions due to the small receptive field. Li et al. <ref type="bibr" target="#b32">[33]</ref> design multi-scale convolutional filters, and simultaneously perform local convolutional filtering on temporal motions and spatial structures. For each frame, an undirected graph is constructed, where only joints bridged by a bone are connected, whereas there is no explicit temporal connectivity. Tang et al. <ref type="bibr" target="#b33">[34]</ref> propose a deep progressive reinforcement learning (DPRL) method to select the most informative frames of the input sequences and apply GCN to learn the spatial</p><formula xml:id="formula_0">Input Sequence × Spatio-Temporal Graph × × × 3</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Concatenated Sequence Graph Convolution</head><p>Classification Score</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Graph Regression</head><p>Multi-Convolution Layer</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Average Pooling Layer</head><p>Fully Connected Layer <ref type="figure">Fig. 2</ref>. The architecture of the proposed GR-GCN for skeleton-based action recognition. Our proposed network takes a skeleton sequence as the input, which goes through sequence concatenation and sparsified spatio-temporal graph construction before feeding into the network. We then employ graph convolution and standard 2D convolution to the concatenated sequence, followed by feature aggregation via average pooling. Thereafter, a fully-connected layer is utilized to generate the output classification scores for C classes.</p><p>dependency between the joints. Edges in the constructed graph reflect both intrinsic dependencies (i.e., physical connection) and extrinsic dependencies (i.e., physical disconnection) by different weights. Nevertheless, there is no explicit graph construction in the temporal domain. Bin et al. <ref type="bibr" target="#b34">[35]</ref> propose a spatio-temporal graph routing (STGR) scheme for skeletonbased action recognition, which learns both spatial connectivity and temporal connectivity. Nevertheless, the computation complexity of the spatial and temporal graph learning is high.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Graph Convolutional Neural Networks</head><p>GCN extends CNN by consuming data defined on irregular grids. The key challenge is to define convolution over graphs, which is difficult due to the unordered data. According to the definitions of graph convolution, most of these methods can be divided into two main categories: spectral-domain methods and nodal-domain methods.</p><p>Spectral-domain methods. The convolution over graphs is elegantly defined in the spectral domain, which is the multiplication of the spectral-domain representation of signals. Specifically, the spectral representation is in the graph Fourier transform (GFT) <ref type="bibr" target="#b37">[38]</ref> domain, where each signal is projected onto the eigenvectors of the graph Laplacian matrix <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b38">[39]</ref>. The computation complexity, however, is high due to the eigen-decomposition of the graph Laplacian matrix in order to get the eigenvector matrix. Hence, it is improved by <ref type="bibr" target="#b30">[31]</ref> through fast localized convolutions, where the Chebyshev expansion is deployed to approximate GFT. Besides, Susnjara et al. introduce the Lancoz method for approximation <ref type="bibr" target="#b39">[40]</ref>. Spectral GCN has shown its efficiency in various tasks such as segmentation and classification <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b40">[41]</ref>.</p><p>Nodal-domain methods. Many techniques are introduced to implement graph convolution directly on each node and its neighbors, i.e., in the nodal domain. Gori et al. introduce recurrent neural networks that operate on graphs in <ref type="bibr" target="#b41">[42]</ref>. Duvenaud et al. propose a convolution-like propagation to accumulate local features <ref type="bibr" target="#b28">[29]</ref>. Bruna et al. deploy the multiscale clustering of graphs in convolution to implement multiscale representation <ref type="bibr" target="#b27">[28]</ref>. Furthermore, Niepert et al. define convolution on a sequence of nodes and perform normalization afterwards <ref type="bibr" target="#b42">[43]</ref>. Wang et al. propose edge convolution on graphs by incorporating local neighborhood information, which is applied to point cloud segmentation and classification <ref type="bibr" target="#b43">[44]</ref>. Nodal-domain methods provide strong localized filters, but it also means it might be difficult to learn the global structure.</p><p>The above methods apply convolutional aggregators in the propagation step. Besides, there are other related works based on different aggregators, including attention aggregators <ref type="bibr" target="#b44">[45]</ref>, which incorporate the attention mechanism <ref type="bibr" target="#b45">[46]</ref> into the propagation step, aiming to compute the hidden states of each node by attending over its neighbors; and gate aggregators <ref type="bibr" target="#b46">[47]</ref>- <ref type="bibr" target="#b51">[52]</ref>, which use the gate mechanism like GRU <ref type="bibr" target="#b52">[53]</ref> or LSTM <ref type="bibr" target="#b53">[54]</ref> in the propagation step to improve the long-term propagation of information across the graph structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PRELIMINARIES</head><p>We consider an undirected graph G = {V, E, A} composed of a vertex set V of cardinality |V| = n, an edge set E connecting vertices, and a weighted adjacency matrix A. A is a real symmetric n × n matrix, where a i,j is the weight assigned to the edge (i, j) connecting vertices i and j. We assume non-negative weights, i.e., a i,j ≥ 0.</p><p>The Laplacian matrix, defined from the adjacency matrix, can be used to uncover many useful properties of a graph. Among different variants of Laplacian matrices, the combinatorial graph Laplacian used in <ref type="bibr" target="#b54">[55]</ref>, <ref type="bibr" target="#b55">[56]</ref> is defined as</p><formula xml:id="formula_1">L = D − A,<label>(1)</label></formula><p>where D is the degree matrix-a diagonal matrix where d i,i = n j=1 a i,j . We will optimize L in the proposed graph regression method in Sec. IV. Further, the symmetric normalized Laplacian is defined as L = D − 1 2 LD − 1 2 , which will be deployed in the GCN so as to avoid numerical instabilities.</p><p>Graph signal refers to data that resides on the vertices of a graph, such as social, transportation, sensor, and neuronal networks. In our context, we treat each joint in a skeleton sequence as a vertex in a graph, and define the corresponding graph signal as the coordinates of each joint.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. DYNAMIC SKELETON MODELING</head><p>The fundamental of skeleton-based action recognition is to capture the variation of joints both in the spatial and temporal domain, so as to learn motion features for classification.</p><p>We propose spatio-temporal graph regression modeling for dynamic skeletons, and come up with the optimization of the underlying graph so as to characterize the variation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Spatio-temporal Graph Regression Modeling of Skeletons</head><p>Let x t ∈ R n×3 be the coordinate signal in one frame at time t, where n is the number of joints in each skeleton. We define a spatio-temporal frame as x = [x t−1 , x t , x t+1 ] ∈ R 3n×3 , i.e., three consecutive frames are concatenated. We then represent x on a spatio-temporal graph described by L, which models the correlation among joints.</p><p>We formulate the graph regression problem as the optimization of the graph Laplacian L:</p><formula xml:id="formula_2">min L tr(x Lx) + β L 2 F , s.t. tr(L) = 3n, L i,j = L j,i ≤ 0, i = j, L · 1 = 0,<label>(2)</label></formula><p>where β is a weighting parameter, and 1 and 0 denote the constant one and zero vectors. In addition, tr(·) and · F denote the trace and Frobenius norm of a matrix, respectively. The first term in the objective function aims to fit the graph structure to the data by minimizing the total variation of the input signal (discussed soon), while the second term enforces the sparsity of the underlying graph for compact representation. The constraints ensure that the learned L satisfies the properties of the desired graph Laplacian: normalized, symmetry, non-negativity of edge weights, and the zero row sum. Next, we discuss the variation characterization by L.</p><p>The quadratic term x Lx in Eq. (2) describes the total variation. This is because x Lx can be written as <ref type="bibr" target="#b56">[57]</ref>:</p><formula xml:id="formula_3">x Lx = i∼j a i,j (x i − x j ) 2 ,<label>(3)</label></formula><p>where i ∼ j denotes two vertices i and j are one-hop neighbors in the graph. Hence, x Lx computes the total variation among connected vertices in x. By minimizing this term in Eq. <ref type="formula" target="#formula_2">(2)</ref>, we enforce the edge weight between a pair of vertices with different features to be small, while allowing for a large edge weight between a pair of similar vertices. Thus, the optimized graph is able to characterize the variation in the skeleton data. The optimization problem in Eq. <ref type="formula" target="#formula_2">(2)</ref> is convex and thus can be solved optimally, which leads to the learned graph for one given observation of x. In order to acquire a spatiotemporal graph that captures the common structure of skeleton sequences, we propose to solve Eq. (2) over multiple observations of x, and then statistically compute the common structure. For the purpose of succinct representation, we further restrict the connectivities of the common graph spatially and temporally, as discussed in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Sparsified Graph Construction</head><p>The graph construction includes spatial connectivity and temporal connectivity. <ref type="figure">Fig. 3</ref>. Illustration of the learned graph construction. We learn a common structure of the spatio-temporal graph for spatio-temporal frames (i.e., every three adjacent frames). The yellow, blue, and red groups include three adjacent frames respectively, containing intra-frame connectivities (gray dotted lines) and inter-frame connectivities (red dotted lines). Note that the connectivities are simplified for clear visualization.</p><p>Spatial connectivity. Within each frame, we model the human body via a connected graph, based on two types of connectivities in particular: strong connections E s and weak connections E w for describing different correlations. Strong connections aim to capture strong correlations with large weights to emphasize the variation, including physical connectivity and some physical disconnection among joints, while weak connections are used to represent potential correlations among joints that are not physically connected. As shown in <ref type="figure">Fig. 1</ref>, whereas the "head" joint and "hand" joint are not bridged by a bone, a weak connectivity could be built between them because of the latent relationship during some actions (e.g., "drink water"). In particular, different weights are assigned to strong and weak edges, i.e., edge weights within a frame are set as</p><formula xml:id="formula_4">a i,j =    w 1 , (i, j) ∈ E s w 2 , (i, j) ∈ E w 0, otherwise,<label>(4)</label></formula><p>where w 1 &gt; w 2 .</p><p>Temporal connectivity. Unlike previous works where each joint is disconnected in the temporal domain or only connected to its corresponding joints in the adjacent frames in general, we allow connecting each joint in frame x t to the neighborhood of its correspondence in the previous frame x t−1 and subsequent frame x t+1 , which are referred to as potential edges, as shown in <ref type="figure">Fig. 3</ref>. This is to capture the latent variation between one joint in frame x t and its neighboring joints in the adjacent frames. The receptive field in the temporal domain is thus enlarged by exploiting more neighboring joints, which contributes to learning the temporal variation. Taking the action "typing on a keyboard" as an example, the left thumb may have little motion in a short period. However, the left index finger moves relative to the left thumb both spatially and over time, which can be captured by the proposed potential edges. Hence, the final spatio-temporal adjacency matrix of consecutive frames {x t−1 , x t , x t+1 } is defined as</p><formula xml:id="formula_5">A g =   A t−1,t−1 A t−1,t O A t,t−1 A t,t A t,t+1 O A t+1,t A t+1,t+1   ,<label>(5)</label></formula><p>where O ∈ R n×n is a zero matrix, A i,i ∈ R n×n is the weighted adjacency matrix of frame i for representing the intra-frame connectivity, while A i,j ∈ R n×n (i = j) is the adjacency matrix between frame i and j for description of the inter-frame connectivity. Similar with the edge weights for the spatial connectivity, we define two types of temporal connectivities: the connectivity for corresponding joints, denoted as E c , and the connectivity between each joint and the neighborhood of its correspondence in the adjacent frames, denoted as E n . We assign w 1 to edges in E c , and assign w 2 to edges in E n , i.e.,</p><formula xml:id="formula_6">a i,j =    w 1 , (i, j) ∈ E c w 2 , (i, j) ∈ E n 0, otherwise,<label>(6)</label></formula><p>where i and j denote vertices in two different frames.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Final Graph Modeling</head><p>Based on the above restriction of spatial and temporal connectivities, we extract the common structure of the optimized graph Laplacian learned from multiple observations of spatio-temporal frames. Specifically, we first randomly take m spatio-temporal frames from different classes of skeleton sequences, each of which serves as x in Eq. (2). Then we obtain the optimal spatio-temporal graph Laplacian for each spatio-temporal frame Eq. (2), leading to m optimized graph Laplacian {L l opt } m l=1 . Next, we derive a common graph Laplacian L from the statistics of {L l opt } m l=1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. THE PROPOSED GR-GCN</head><p>Having elaborated on the proposed graph regression that provides the underlying common structure of spatio-temporal frames, we now overview the architecture of the proposed GR-GCN. Then we discuss the corresponding graph convolution and feature learning in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. GR-GCN architecture</head><p>As illustrated in <ref type="figure">Fig. 2</ref>, the input is a skeleton-based action sequence organized as a P ×T 0 ×N 0 ×3 tensor, where P is the number of actors in each sequence, T 0 is the number of frames, N 0 is the number of joints in each frame, and 3 means the dimension of x, y, z coordinates. In order to exploit the spatiotemporal dependencies, we firstly concatenate the input sequence in the unit of 3 consecutive frames, e.g., the {1, 2, 3} th frames are concatenated into the first spatio-temporal frame, and the {2, 3, 4} th frames into the second one, etc. Thus, the sequence length is changed to T 1 , and the number of joints in each frame is N 1 after frame concatenation, where T 1 = T 0 − 2 and N 1 = N 0 × 3. We then perform the proposed graph regression, which leads to the learned graph Laplacian of a common spatio-temporal graph. Secondly, we feed a feature matrix containing the coordinates of skeleton joints in the concatenated sequence and the graph Laplacian into the designed graph convolution layer and standard 2D convolution layers for feature extraction. Average pooling is then employed for feature aggregation. Finally, the global feature matrix will go through a fully connected layer followed by a Softmax activation function to output the classification score for C classes. Also, batch normalization is used for all layers before the ReLU activation function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Spatio-Temporal Graph Convolution</head><p>Following the definition of graph convolution in <ref type="bibr" target="#b30">[31]</ref>, we adopt the approximation of spectral convolution by Chebyshev polynomials for efficient implementation:</p><formula xml:id="formula_7">g θ * x ≈ K−1 k=0 θ k T k (L)x,<label>(7)</label></formula><p>where L = D − 1 2 LD − 1 2 is the symmetric normalized graph Laplacian as defined in Sec. III, which is employed because the domain of Chebyshev polynomials lies in [−1, 1]. θ k denotes the k-th Chebyshev coefficient and g θ denotes a convolution kernel. T k (L) is the Chebyshev polynomial of order k. It is recurrently calculated by T k (L) = 2LT k−1 (L) − T k−2 (L), where T 0 (L) = 1, T 1 (L) = L. When k &gt; 1, L k essentially describes k-hop connectivities, thus incorporating more neighbors and leading to convolution over a larger receptive field.</p><p>We provide analysis of the variation characterization by the above Chebyshev approximation. As discussed in <ref type="bibr" target="#b57">[58]</ref>, the graph Laplacian matrix L is essentially a high-pass operator which captures the variation in the underlying signal. For any signal x, it satisfies</p><formula xml:id="formula_8">(Lx)(i) = j∈Ni a i,j (x i − x j ),<label>(8)</label></formula><p>where (Lx)(i) denotes the i-th component of Lx. N i is the set of vertices connected to i. This presents that when operating L on x, for each vertex, it computes the signal difference among the vertex and its one-hop neighbors. In other words, Lx captures the variation in x. Similarly, L k x captures the variation between each vertex and its k-hop neighbors. Thus, the approximated graph convolution seamlessly enables learning the variation in a skeleton sequence. This also sheds light on why graph convolution works for action recognition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Feature Learning</head><p>Having designed the spatio-temporal graph convolution, we define the transfer function as follows:</p><formula xml:id="formula_9">y = ReLU( K−1 k=0 T k (L)xW k + b),<label>(9)</label></formula><p>where W k ∈ R F1×F2 is a matrix of weight parameters θ k as in Eq. 7, which will be learnt from the network, and F 1 , F 2 are the dimensions of generated features in two connected layers respectively. b ∈ R n×F2 is the bias, while ReLU is an activation function. After the graph convolution layer, we employ standard 2D convolution to the output y, followed by feature aggregation via average pooling. Thereafter, a fully-connected layer and a Softmax activation function are adopted to generate the output classification scores. We adopt the categorical cross-entropy loss to train the network. The implementation details of our model will be discussed in Sec. VI-B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. EXPERIMENTS</head><p>We evaluate our proposed GR-GCN on four widely used datasets and compare with state-of-the-art skeleton-based action recognition methods. Experimental details and results are discussed below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Datasets and Evaluation Metrics</head><p>NTU RGB+D Dataset <ref type="bibr" target="#b16">[17]</ref>: This dataset was captured from 40 human subjects by 3 Microsoft Kinect v2 cameras. It consists of 56880 action sequences with 60 classes. Actions 1-49 were performed by one actor, and actions 50-60 were performed by the other two actors. Each body skeleton was recorded with 25 joints. The benchmark evaluations include Cross-Subject (CS) and Cross-View (CV). In the CS evaluation, 40320 samples from 20 subjects were used for training, and the other samples for testing. In the CV evaluation, samples captured from camera 2 and 3 were used for training, while samples from camera 1 were employed for testing.</p><p>Florence 3D Dataset <ref type="bibr" target="#b58">[59]</ref>: This dataset contains 215 action sequences of 10 actors with 9 classes. Each body skeleton was collected from Kinect, and recorded with 15 joints. We follow the standard experimental settings to perform leaveone-actor-out validation protocol: we use all the sequences from 9 out of 10 actors for training and the remaining one for testing, and repeat this procedure for all the actors. The resulting 10 classification accuracy values are averaged to get the final accuracy.</p><p>UT-Kinect Dataset <ref type="bibr" target="#b9">[10]</ref>: This dataset was captured using a single stationary Kinect. It consists of 200 sequences with 10 classes, and each skeleton includes 20 joints. The dataset was recorded by three channels: RGB, depth, and skeleton joint locations, whereas we only use the 3D skeleton joint coordinates. We also adopt the leave-one-actor-out validation protocol to evaluate our model on this dataset. SYSU 3D Dataset <ref type="bibr" target="#b59">[60]</ref>: On this dataset, 40 actors were asked to perform 12 different activities. Therefore, there are totally 480 action videos on this dataset. For each video, the corresponding RGB, depth, and skeleton information were captured by a Kinect. We use the skeleton sequences performed by 20 actors for training, and the remaining 20 actors for testing. We employ the 30-fold cross-subject validation and report the mean accuracy on the dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Implementation Details</head><p>Our proposed model was implemented with the PyTorch 2 framework. The number of actors P is set to be 2, 1, 1, 1 for NTU RGB+D, Florence 3D, UT-Kinect, and SYSU 3D dataset respectively. We learn the edge weight ratio r = 5 for the four datasets, i.e., w 1 = 5, w 2 = 1.</p><p>Basic Model: Prior to the graph convolution layer, we set a Batch Normalization layer for the batched input data in order to be less careful about data initialization and speed up the training process <ref type="bibr" target="#b60">[61]</ref>. In the graph convolution layer, we set the Chebyshev order K to be 4, and the dimension of the weight matrix W k in Eq. 9 to be 3n×3n (i.e., the same as the spatio-temporal Laplacian matrix L). The Multi-Convolution Layer consists of 2 standard CNN layers. Each convolution layer follows a Batch Normalization layer. We choose ReLU as the activation function after each convolution layer, and assign the dropout rate 0.5.</p><p>Deep Stacking: The above convolutional model can be easily extended into a deep architecture. Taking the above model as one basic layer, we stack it into a multi-layer network architecture, in which the output at the previous layer is used as the input of the next layer. Here, we stack it into a 10layer architecture. In this architecture, we appropriately adjust the kernel size so as to acquire the final output feature of dimension M 2 = 256 for each point. With the increase of layers, the receptive field of convolutional kernels become larger, thus enabling abstracting more global information.</p><p>Next, we employ three average pooling layers to pool the P , N , and T dimension respectively, followed by a fully connected layer and a Softmax activation function to output the final classification score. The number of neurons depends on the output channel of the last convolution layer of the network. We apply Adam <ref type="bibr" target="#b61">[62]</ref> optimizer to train the whole model with the initial learning rate 0.1, and decrease it on the 10 th epoch. Note that we did not perform any normalization on the skeleton coordinates during data preprocessing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Data Preprocessing</head><p>NTU RGB+D Dataset: Due to some missing skeletons in this dataset, we only use the cleaned data 3 for action recognition <ref type="bibr" target="#b62">[63]</ref>. In order to enhance the robustness of model training, we split the sequences into several segments of equal size in a way similar to <ref type="bibr" target="#b32">[33]</ref>. Specifically, we split the whole sequence into 32 segments, and pick the {1, 2, 3, 4} th frame respectively from each segment to generate a large amount of training data.</p><p>Florence 3D Dataset: Since the sequences in this dataset contain few frames, we design two ways to generate the training set: sampling and interpolation. For longer sequences (i.e., the length of the sequence is greater than 32), we randomly choose 32 frames; for the other sequences, we calculate the mean of two adjacent frames and insert it into the sequence as a new frame, eventually forming a sequence of 32 frames. For all the sequences, we repeat this operation 3 times to generate the training set.</p><p>UT-Kinect Dataset: We also adopt sampling and interpolation methods to generate the training set. Here, we set the length of each training sequence to be 64, and repeat the process twice.</p><p>SYSU 3D Dataset: Similar to the NTU RGB+D dataset, we split each sequence into 32 segments, and pick the {1, 2, 3, 4, 5} th frame from each segment to generate the training set. However, this dataset does not provide vertex labels, hence we only adopt the adjacency matrix of physical connections provided by the author as the graph within each frame.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Results on NTU RGB+D Dataset</head><p>As reported in Tab. I, our model achieves accuracy of 87.5% in CS and 94.3% in CV respectively. Also, as will be discussed in the ablation study, the proposed intra-connections improve the performance by 0.7% in CS and 1.4% in CV over the baseline method (GR-GCN+Bone), while the proposed temporal connectivities lead to 3.2% gain in CS and 3.1% gain in CV, thus validating the effectiveness of our method.</p><p>Comparison with the State-of-the-arts: We present the comparison with the state-of-the-art methods in Tab. I. We see that our method outperforms all the other state-of-the-art methods. Specifically, compared with the latest state-of-theart method STGR-GCN <ref type="bibr" target="#b34">[35]</ref>, our model leads to 0.6% gain in CS and 2.0% gain in CV respectively, which demonstrates the superiority of our method.</p><p>Ablation Study: In order to validate the advantages of the proposed spatio-temporal graph construction in our method, we evaluate various graph construction methods progressively and design the following incomplete models. Model 1 is GR-GCN (Bone only), in which only joints connected with a bone are linked with graph edges. This kind of graph construction is commonly used in existing graph-based skeleton recognition <ref type="bibr" target="#b31">[32]</ref>- <ref type="bibr" target="#b33">[34]</ref>, and thus is the baseline. Model 2 is GR-GCN (Bone + Intra-connection) (non-physical), where connectivities are further added to joints that are not physically connected within each frame, including strong and weak edges for capturing latent dependencies. This kind of connectivities are previously exploited in <ref type="bibr" target="#b33">[34]</ref>. Model 3 is our complete model with extra temporal connections included. We observe that Model 1 already achieves competitive performance with the state-of-the-art methods, which shows the effectiveness of the proposed GR-GCN. With additional intra-connectivities, Model 2 improves the accuracy by 0.7% in CS and 1.4% in CV over Model 1, validating the benefits of non-physical connections. Further, when the temporal connections are exploited, the complete model achieves 2.5% gain in CS and 1.7% gain in CV over Model 2. We thus conclude that both the proposed non-physical intra-connectivities and the explicit temporal connections make contributions to skeleton-based action recognition, in which the temporal connectivities are more crucial. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Results on SYSU 3D Dataset</head><p>We compare our method with the state-of-the-art skeletonbased action recognition methods on SYSU 3D Dataset, which are presented in Tab. II. Our proposed method outperforms all the other state-of-the-art methods on this dataset, achieving accuracy improvement of 1.0% over the previous best method DPRL <ref type="bibr" target="#b33">[34]</ref>.</p><p>Note that, as vertex labels are not provided by this dataset, we can only build strong physical connections from the given adjacency matrix within each frame while abandoning weak edges. Hence, we provide ablation study with Model 1 in Tab. II. We see that our complete model achieves 2.7% improvement over the baseline method. This validates the benefits of incorporating explicit temporal connectivities across consecutive frames again. Also, the confusion matrix of our result is demonstrated in <ref type="figure">Fig. 4</ref>. We see that the matrix is diagonally dominant on all the 12 classes, which validates that our method achieves excellent classification results on this dataset. Besides, we note that our model sometimes confuses the activity of "mopping" with "sweeping", which is mainly due to the highly similar motions in the two actions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods Accuracy</head><p>Year Dynamic Skeletons <ref type="bibr" target="#b59">[60]</ref> 75.5 2015 LAFF (SKL) <ref type="bibr" target="#b64">[65]</ref> 54.2 2016 ST-LSTM (Tree) <ref type="bibr" target="#b22">[23]</ref> 73.4 2018 ST-LSTM (Tree) + Trust Gate <ref type="bibr" target="#b22">[23]</ref> 76.5 2018 DPRL <ref type="bibr" target="#b33">[34]</ref> 76.9 2018 GR-GCN (Bone only) 75.2 Complete GR-GCN model 77.9 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods Accuracy Year</head><p>Lie Group <ref type="bibr" target="#b13">[14]</ref> 97.1 2014 LARP+mfPCA <ref type="bibr" target="#b65">[66]</ref> 94.9 2015 SPGK <ref type="bibr" target="#b12">[13]</ref> 97.4 2016 ST-NBNN <ref type="bibr" target="#b15">[16]</ref> 98.0 2017 Bi-LSTM <ref type="bibr" target="#b21">[22]</ref> 96.9 2018 ST-LSTM(Tree) + Trust Gate <ref type="bibr" target="#b22">[23]</ref> 97.0 2018 DPRL <ref type="bibr" target="#b33">[34]</ref> 98.5 2018 GR-GCN (Bone only) 96.9 GR-GCN (Bone + Intra-connection) 97.4 Complete GR-GCN model 98.5</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Results on UT-Kinect Dataset</head><p>As listed in Tab. III, our method achieves comparable accuracy of 98.5% to <ref type="bibr" target="#b33">[34]</ref>, and outperforms all the other methods. Note that the performance difference among all the methods is rather small in general. The reason is that this dataset includes several very similar actions, which are difficult to distinguish without RGB or depth data.</p><p>Also, we perform the same ablation study as in Sec. VI-D, as reported in Tab. III. We observe that Model 2 improves the accuracy by 0.5% over Model 1 with additional intraconnectivities. Further, when the temporal connectivities are built, the complete model achieves 1.1% improvement over Model 2, which demonstrates the advantages of the proposed spatio-temporal graph construction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Results on Florence 3D Dataset</head><p>We present the performance comparison with the state-ofthe-art methods on the Florence 3D dataset in Tab. IV. Our method achieves classification accuracy of 98.5%, outperforming all the other state-of-the-art methods significantly except Deep STGC K <ref type="bibr" target="#b32">[33]</ref>. The reason is that Deep STGC K benefits from the design philosophy of autoregressive moving average model, which is tailored for time sequences. Due to the few joints in each frame and few frames in the sequence, our model is difficult to capture subtle variation from few joints. Thus we misclassify "drink from a bottle" and "answer phone", "read watch" and "clap", which is difficult to distinguish even with human vision.</p><p>Moreover, Tab. IV reports the results of ablation study. We achieve 0.1% improvement from non-physical intraconnections compared with GR-GCN (Bone only), and another 2.8% improvement from temporal connections compared with GR-GCN (Bone + Intra-connection). This validates the </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods Accuracy Year</head><p>Lie Group <ref type="bibr" target="#b13">[14]</ref> 90.9 2014 LARP+mfPCA <ref type="bibr" target="#b65">[66]</ref> 89.7 2015 Rolling Rotations <ref type="bibr" target="#b66">[67]</ref> 91.4 2016 SPGK <ref type="bibr" target="#b12">[13]</ref> 91.6 2016 Transion Forests <ref type="bibr" target="#b67">[68]</ref> 94.2 2017 MIMTL <ref type="bibr" target="#b68">[69]</ref> 95.3 2017 Bi-LSTM <ref type="bibr" target="#b21">[22]</ref> 93.0 2018 Deep STGC K <ref type="bibr" target="#b32">[33]</ref> 99.1 2018 GR-GCN (Bone only) 95.5 GR-GCN (Bone + Intra-connection) 95.6 Complete GR-GCN model 98.4 effectiveness of the proposed graph construction, in which the temporal connectivities are vital. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H. Analysis on Chebyshev Orders</head><p>We explore the effects of different Chebyshev polynomial orders on our complete GR-GCN model, as demonstrated in <ref type="figure" target="#fig_0">Fig. 5</ref>. When K = 1, graph convolution defaults to a fully connected layer according to Eq. (7), thus becoming the baseline with only traditional CNNs. The performance is inferior to those with larger K (corresponding to graph convolution with (K − 1)-hop neighborhood) in general, thus validating the effectiveness of graph convolution. Further, our model achieves the best performance when K = 4 for all the datasets, thus validating the choice of K in the experimental setting. In contrast, the performance with K = 5 drops, because a wide range of neighbors will be incorporated, which is unable to capture the local variation well and may lead to overfitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSION</head><p>We propose a graph regression based GCN (GR-GCN) for skeleton-based action recognition, aiming to fully exploit both spatial and temporal dependencies among human joints. As the graph representation is crucial to graph convolution, we propose graph regression to optimize the underlying graph over multiple observations of spatio-temporal frames, and then statistically learn the common sparsified graph representation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 5 .</head><label>5</label><figDesc>Classification accuracy on different Chebyshev orders.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I COMPARISONS</head><label>I</label><figDesc>ON THE NTU RGB+D DATASET (%).</figDesc><table><row><cell>Methods</cell><cell>CS</cell><cell>CV</cell><cell>Year</cell></row><row><cell cols="4">Dynamic Skeletons [60] 60.2 65.2 2015</cell></row><row><cell cols="4">Part-aware LSTM [17] 62.9 70.3 2016</cell></row><row><cell cols="4">Geometric Features [20] 70.3 82.4 2017</cell></row><row><cell cols="4">LSTM-CNN [21] 82.9 91.0 2017</cell></row><row><cell cols="4">Two-Stream CNN [24] 83.2 89.3 2017</cell></row><row><cell cols="4">ST-LSTM (Tree)+Trust Gate [23] 69.2 77.7 2018</cell></row><row><cell cols="4">Deep STGC K [33] 74.9 86.3 2018</cell></row><row><cell cols="4">ST-GCN [32] 81.5 88.3 2018</cell></row><row><cell cols="4">DPRL [34] 83.5 89.8 2018</cell></row><row><cell cols="4">SR-TSL [64] 84.8 92.4 2018</cell></row><row><cell cols="4">STGR-GCN [35] 86.9 92.3 2019</cell></row><row><cell cols="3">GR-GCN (Bone only) 84.3 91.2</cell><cell></cell></row><row><cell cols="3">GR-GCN (Bone + Intra-connection) 85.0 92.6</cell><cell></cell></row><row><cell cols="3">Complete GR-GCN model 87.5 94.3</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE II COMPARISONS</head><label>II</label><figDesc>ON THE SYSU 3D DATASET (%).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE III COMPARISONS</head><label>III</label><figDesc>ON THE UT-KINECT DATASET (%).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE IV COMPARISONS</head><label>IV</label><figDesc>ON THE FLORENCE 3D DATASET (%).</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">In spectral graph theory<ref type="bibr" target="#b35">[36]</ref>, a graph Laplacian matrix is an algebraic representation of the connectivities and node degrees of the corresponding graph, which will be introduced in Section III.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://pytorch.org 3 https://github.com/InwoongLee/TS-LSTM</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The learned graph not only captures intrinsic physical connections, but also models non-physical spatial connectivities as well as temporal connectivities over consecutive frames so as to represent the latent correlations for better action recognition. We then feed the learned spatio-temporal graph into the GCN with spectral graph convolution approximated by highorder Chebyshev polynomials for feature extraction. Extensive experiments demonstrate the superiority of our method.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Two-stream convolutional networks for action recognition in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="568" to="576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning spatiotemporal features with 3d convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Du</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lubomir</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Torresani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manohar</forename><surname>Paluri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4489" to="4497" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Action recognition with trajectory-pooled deep-convolutional descriptors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4305" to="4314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Temporal segment networks: Towards good practices for deep action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="20" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Temporal action detection with structured segment networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhirong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Hierarchical recurrent neural network for skeleton based action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1110" to="1118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Spatio-temporal lstm with trust gates for 3d human action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Shahroudy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="816" to="833" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Realtime human pose recognition in parts from single depth images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Fitzgibbon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mat</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toby</forename><surname>Sharp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Finocchio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kipman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Blake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1297" to="1304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Space-time representation of people based on 3d skeletal data: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Reily</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Hoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding (CVIU)</title>
		<imprint>
			<biblScope unit="volume">158</biblScope>
			<biblScope unit="page" from="85" to="105" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">View invariant human action recognition using histograms of 3d joints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chia-Chih</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><forename type="middle">K</forename><surname>Aggarwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer vision and pattern recognition workshops</title>
		<imprint>
			<publisher>CVPRW</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="20" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Mining actionlet ensemble for action recognition with depth cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zicheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsong</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1290" to="1297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Histogram of oriented displacements (hod): Describing trajectories of human joints for action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marwan</forename><surname>Mohammad Abdelaziz Gowayyed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Torki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Motaz</forename><surname>Hussein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>El-Saban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1351" to="1357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Graph based skeleton motion representation and similarity measurement for action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunfeng</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiming</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanning</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="370" to="385" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Human action recognition by representing 3d skeletons as points in a lie group</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raviteja</forename><surname>Vemulapalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felipe</forename><surname>Arrate</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rama</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="588" to="595" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Mining 3d key-posemotifs for action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2639" to="2647" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Spatio-temporal naive-bayes nearest-neighbor (st-nbnn) for skeleton-based action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junwu</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaoqun</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsong</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4171" to="4180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Ntu rgb+d: A large scale dataset for 3d human activity analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Shahroudy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tian-Tsong</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1010" to="1019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Co-occurrence feature learning for skeleton based action recognition using regularized deep lstm networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wentao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cuiling</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junliang</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjun</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanghao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohui</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An end-to-end spatio-temporal attention model for human action recognition from skeleton data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sijie</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cuiling</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junliang</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjun</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaying</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence (AAAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4263" to="4270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">On geometric features for skeleton-based action recognition using multilayer lstm networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songyang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Winter Conference on Applications of Computer Vision (WACV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="148" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Skeleton-based action recognition using lstm and cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuankun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pichao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghong</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanqing</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Multimedia &amp; Expo Workshops (ICMEW)</title>
		<imprint>
			<date type="published" when="2017-07" />
			<biblScope unit="page" from="585" to="590" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Coding kendall&apos;s shape trajectories for 3d action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amor</forename><surname>Ben Tanfous</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hassen</forename><surname>Drira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boulbaba</forename><surname>Ben Amor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2840" to="2849" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Skeleton-based action recognition using spatio-temporal lstm network with trust gates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Shahroudy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">C</forename><surname>Kot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="3007" to="3021" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Skeletonbased action recognition with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaoyong</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiliang</forename><surname>Pu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Multimedia &amp; Expo Workshops</title>
		<imprint>
			<publisher>ICMEW</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="597" to="600" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A new representation of skeleton sequences for 3d action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiuhong</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammed</forename><surname>Bennamoun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Senjian</forename><surname>An</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4570" to="4579" />
		</imprint>
	</monogr>
	<note>Ferdous Sohel, and Farid Boussaid</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Interpretable 3d human action analysis with temporal convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soo</forename><surname>Tae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Austin</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Reiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<imprint>
			<publisher>CVPRW</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1623" to="1631" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Enhanced skeleton visualization for view invariant human action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition (PR)</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="346" to="362" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Spectral networks and locally connected networks on graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Science</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Convolutional networks on graphs for learning molecular fingerprints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dougal</forename><surname>David K Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorge</forename><surname>Maclaurin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafael</forename><surname>Iparraguirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Bombarell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alán</forename><surname>Hirzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan P</forename><surname>Aspuru-Guzik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2224" to="2232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Convolutional neural networks on graphs with fast localized spectral filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michaël</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3844" to="3852" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Spatial temporal graph convolutional networks for skeleton-based action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sijie</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Spatio-temporal graph convolution for skeleton based action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaolong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenming</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Deep progressive reinforcement learning for skeleton-based action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yansong</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peiyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5323" to="5332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Spatio-temporal graph routing for skeleton-based action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongfei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Spectral graph theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference Board of the Mathematical Sciences</title>
		<imprint>
			<publisher>American Mathematical Society</publisher>
			<date type="published" when="1997" />
			<biblScope unit="volume">92</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Human action recognition using a temporal hierarchy of covariance descriptors on 3d joint locations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marwan</forename><surname>Mohamed E Hussein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">Abdelaziz</forename><surname>Torki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Motaz</forename><surname>Gowayyed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>El-Saban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="2466" to="2472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Wavelets on graphs via spectral graph theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Hammond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rémi</forename><surname>Vandergheynst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gribonval</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Applied and Computational Harmonic Analysis (ACHA)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="129" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikael</forename><surname>Henaff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.05163</idno>
		<title level="m">Deep convolutional networks on graph-structured data</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Accelerated filtering on graphs using lanczos method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ana</forename><surname>Susnjara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Perraudin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Kressner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Vandergheynst</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1509.04537</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Rgcnn: Regularized graph cnn for point cloud segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gusi</forename><surname>Te</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongming</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amin</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Multimedia Conference (MM)</title>
		<imprint>
			<date type="published" when="2018-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A new model for learning in graph domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriele</forename><surname>Monfardini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franco</forename><surname>Scarselli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Joint Conference on Neural Networks (IJCNN)</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="729" to="734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Learning convolutional neural networks for graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathias</forename><surname>Niepert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Kutzkov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2014" to="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Dynamic graph cnn for learning on point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongbin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sanjay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sarma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><forename type="middle">M</forename><surname>Michael M Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Solomon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.07829</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Graph attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petar</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Lio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Gated graph sequence neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Tarlow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Brockschmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Improved semantic representations from tree-structured long short-term memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai Sheng</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Natural Language Processing (IJCNLP)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Conversation modeling on reddit using a graph-structured lstm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victoria</forename><surname>Zayats</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mari</forename><surname>Ostendorf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association of Computational Linguistics (TACL)</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="121" to="132" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Cross-sentence n-ary relation extraction with graph lstms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoifung</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Quirk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wentau</forename><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics (TACL)</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="101" to="115" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Sentence-state lstm for text representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linfeng</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Semantic object parsing with graph lstm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohui</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="125" to="143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Edge-adaptive transforms for efficient depth map coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Godwin</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W-S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sunil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaejoon</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hocheon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Picture Coding Symposium (PCS)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="566" to="569" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Multiresolution graph fourier transform for compression of piecewise smooth images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gene</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><forename type="middle">C</forename><surname>Au</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing (TIP)</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="419" to="433" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Lecture 2 of spectral graph theory and its applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Spielman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">The emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunil</forename><forename type="middle">K</forename><surname>David I Shuman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Frossard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="83" to="98" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Recognizing actions from depth cameras as weakly aligned multi-part bag-of-poses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Seidenari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincenzo</forename><surname>Varano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Berretti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Bimbo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Pala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<imprint>
			<publisher>CVPRW</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="479" to="485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Jointly learning heterogeneous features for rgb-d activity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Fang</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Shi</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianhuang</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianguo</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="5344" to="5352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2015-07" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Science</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Ensemble deep learning for skeleton-based action recognition using temporal sliding lstm networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inwoong</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doyoung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seoungyoon</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanghoon</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1012" to="1020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Skeleton-based action recognition with spatial reasoning and temporal stack learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenyang</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ya</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tieniu</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="106" to="121" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Real-time rgb-d activity prediction by soft regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Fang</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Shi</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lianyang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianhuang</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="280" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Elastic functional coding of human actions: From vector-fields to latent variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rushil</forename><surname>Anirudh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavan</forename><surname>Turaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingyong</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anuj</forename><surname>Srivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3147" to="3155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Rolling rotations for recognizing human actions from 3d skeletal data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raviteja</forename><surname>Vemulapalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rama</forename><surname>Chellapa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4471" to="4479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Transition forests: Learning discriminative temporal transitions for action recognition and detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillermo</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Hernando</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tae-Kyun</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="432" to="440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Discriminative multi-instance multitask learning for 3d action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanhua</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shangqian</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dapeng</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinbo</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia (TMM)</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="519" to="529" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
