<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Tri-graph Information Propagation for Polypharmacy Side Effect Prediction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Sheffield</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengqi</forename><surname>Sang</surname></persName>
							<email>s4sang@uwaterloo.ca</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Physics and Astronomy</orgName>
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Perimeter Institute for Theoretical Physics</orgName>
								<address>
									<settlement>Waterloo</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiping</forename><surname>Lu</surname></persName>
							<email>h.lu@sheffield.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Sheffield</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Tri-graph Information Propagation for Polypharmacy Side Effect Prediction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T22:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The use of drug combinations often leads to polypharmacy side effects (POSE). A recent method formulates POSE prediction as a link prediction problem on a graph of drugs and proteins, and solves it with Graph Convolutional Networks (GCNs). However, due to the complex relationships in POSE, this method has high computational cost and memory demand. This paper proposes a flexible Tri-graph Information Propagation (TIP) model that operates on three subgraphs to learn representations progressively by propagation from protein-protein graph to drug-drug graph via protein-drug graph. Experiments show that TIP improves accuracy by 7%+, time efficiency by 83×, and space efficiency by 3×.</p><p>Inspired by the Decagon model and motivated by its limitations, we propose a Tri-graph Information Propagation (TIP) model for improving prediction accuracy, and time and space efficiency, as shown 33rd</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>When treating complex or simultaneous diseases, patients often have to take more than one drugs concurrently, called polypharmacy. This often causes additional side effects, i.e., polypharmacy side effects (POSE) due to interactions between drugs. Graph convolutional network (GCN) is an emerging approach for graph representation learning <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7]</ref>. GCN-based drug representation learning has shown improved performance in POSE prediction <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b15">16]</ref>. POSE prediction can be viewed as a link prediction problem. As shown in <ref type="figure" target="#fig_0">Fig. 1</ref>, a multi-modal graph can be constructed using 1) drug-drug interactions (D-D) with side effects as edge labels, e.g., from POSE clinical records, 2) protein-drug interactions (P-D) with edges labeled as t, and 3) proteinprotein interactions (P-P)) with edges labeled as b, e.g., from pharmacological information. On such a graph, Zitnik et al. <ref type="bibr" target="#b15">[16]</ref> proposed a GCN-based Decagon model to learn drug/protein representation via weighted aggregation of local neighbourhood information, with different weights assigned to different edge labels. It predicts all relationships between all nodes (drug/protein). This formulation enables the prediction of side effects that have strong molecular origins. However, due to the large number of nodes and possible edge labels, the aggregation operation has both high computational cost and high memory demand.   <ref type="figure" target="#fig_1">Fig. 2</ref>. We start from the same multi-modal biomedical graph as in <ref type="bibr" target="#b15">[16]</ref>, constructed from three open BioSNAP-Decagon datasets <ref type="bibr" target="#b9">[10]</ref>, as detailed in <ref type="table" target="#tab_0">Table 1</ref>. Instead of viewing the graph as a whole, we propose to view it as three subgraphs: the P-P graph, P-D graph and D-D graph, as in Figs.1 and 2. TIP focuses on predicting relationships (side effects) in the D-D graph only rather than all relationships in the whole graph in Decagon. Thus, we treat drug nodes and protein nodes differently. Specifically, TIP has four steps: 1) learn protein embedding on the P-P graph; 2) propagate such embedding to the D-D graph via the P-D graph; 3) learn the final drug embedding; 4) predict the side effects on the D-D graph.</p><p>TIP embeds proteins and drugs into different spaces of possibly different dimensions, rather than the same space and dimensions as in Decagon. This enables the propagation of flexible protein embedding to drug embedding as supplementary information. This brings three key benefits: 1) Flexibility. We design three information propagation GCN modules corresponding to the first three TIP steps and two ways to combine protein and drug information in the P-D graph (step 2). Thus, we have the flexibility to set the number of GCN layers to control the order of neighborhood considered in each module. 2) Efficiency. Separate embedding of proteins and drugs can greatly improve the time (83×) and space (3×) efficiency of GCN-based representation learning and information propagation for them, 3) Accuracy. More focused learning of drug representation makes better use of available data sources and can lead to improved POSE prediction, e.g., by 7.2% in our experiments.</p><p>2 Tri-graph Information Propagation (TIP) TIP follows the popular encoder-decoder framework <ref type="bibr" target="#b3">[4]</ref>. <ref type="figure" target="#fig_1">Figure 2</ref> shows the structure of the TIP encoder, within which Pharmacological information is propagated from P-P to D-D graph via P-D graph. The drug representation is produced by combining protein embedding and other available drug information. Further, drug embedding is used as input to the decoder to compute a set of side-effect-specified scores. Given a side effect and a drug pair, a higher score means the side effect is more likely to exist.</p><p>TIP Encoder: We follow the same Message Passing Neural Networks (MPNN) framework <ref type="bibr" target="#b2">[3]</ref> as GCN <ref type="bibr" target="#b6">[7]</ref>, Decagon <ref type="bibr" target="#b15">[16]</ref> and R-GCNs <ref type="bibr" target="#b12">[13]</ref>. Our Encoder can be considered as a sequence of different MPNN cases. The protein and drug input features are V p ∈ R N p ×N p and V d ∈ R N d ×N d , where N p/d is the total number of proteins/drugs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) P-P Graph Embedding Module (PPM):</head><p>PPM is a GCN module <ref type="bibr" target="#b6">[7]</ref> used to learn protein embedding. The input of PPM module is the protein features h 0 = V p . The relation between two hidden layers is given by</p><formula xml:id="formula_0">h k+1 (pi) = ReLU( 1 c i j∈Ni W k p h k (pj ) + h k (pi) ),<label>(1)</label></formula><p>where c i = |N i | and i is associated with a protein node p i ∈ P .</p><p>2) Graph-to-Graph Information Propagation Module (GGM): This module takes V d and the protein embedding generated by PPM to learn the embedding of pharmacological information associated with each drugs. It contains two units:</p><formula xml:id="formula_1">2a) Graph-to-Graph unit: a one-layer MPNN with h H (di) = ReLU( 1 c i j∈Ni W h h (pj ) ),<label>(2)</label></formula><p>where h H (di) can be regraded as a higher level representation of a subset of proteins, inspired by the subgraph embedding algorithm <ref type="bibr" target="#b0">[1]</ref> which simply sums over the feature vectors of the involved nodes. 2b) Drug feature dimension reduction unit: A linear transformation followed by an activation function:</p><formula xml:id="formula_2">h D (di) = ReLU(W d v (di) ).<label>(3)</label></formula><p>The output of GGM h k+1 (di) is the concatenation (TIP-cat) or the sum (TIP-sum) of h H (di) and h D (di) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) D-D Graph Embedding Module (DDM):</head><p>This module is a R-GCN encoder with a basisdecomposition regularization <ref type="bibr" target="#b12">[13]</ref>. The update rule between layers is:</p><formula xml:id="formula_3">h k+1 (di) = ReLU   r∈R j∈N i r 1 c i,r W k r h k (dj ) + W k o h k di   W k r = b∈[B] a k rb V k b ,<label>(4)</label></formula><p>where</p><formula xml:id="formula_4">c i,r = |N di r | and h 0 = [h H , h D ] or h H + h D .</formula><p>The weight W k r was regularized by basisdecomposition <ref type="bibr" target="#b12">[13]</ref>, which decomposes the matrix into the linear combination of a small number of basis matrices V k b ∈ R d l+1 ×d l with side-effect-specified coefficients a k rb . TIP Decoder: TIP takes the final drug representation Z d learned from TIP encoder, and computes the probability p i,j r of side effect r ∈ R given a pair of drugs embedding (z i , z j ). For the POSE task we only care about predicting edges and edge labels on the D-D graph. We consider using the DistMult factorization <ref type="bibr" target="#b14">[15]</ref> or a 2-layer neural network multi-label classifier as the decoder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) DistMult Factorization decoder (DF):</head><p>For the DF decoder <ref type="bibr" target="#b14">[15]</ref>, we first compute a N d ×N d ×N r score tensor G = {g i,j r }, and then get the probability by acting the sigmoid function on it:</p><formula xml:id="formula_5">p ij r = σ(g ij r ) = σ(z T i M r z j ),<label>(5)</label></formula><p>where M r is a trainable diagonal matrix associated with the side effect r.</p><p>2) Neural Network Decoder (NN): NN-decoder is a multi-classifier with each side effects corresponded to a classifier. It takes the concatenation of drug pair's representations as input and embeds it into a lower-dimensional space in the first layer. For second layer it predicts the probability of all the possible side effects with the sigmoid function.</p><p>We will compare the performance of two decoders in the following chapter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Results and Discussions</head><p>We implement TIP in PyTorch <ref type="bibr" target="#b10">[11]</ref> with PyTorch-Geometric package <ref type="bibr" target="#b1">[2]</ref>. The code is available at https://github.com/NYXFLOWER/TIP. Hyper-parameter setting, model training, optimization and performance measurement details are in the supplementary material.</p><p>Models and Baselines As shown in <ref type="table" target="#tab_1">Table 2</ref>, we study two TIP model implementations TIP-cat and TIP-sum with concatenation or sum in GGM, and two degenerated TIP (dTIP) models dTIP D and dTIP P focusing on modelling drug or protein, respectively. We compare them with two recent POSE prediction models reporting state-of-the-art performance on the same dataset: Decagon <ref type="bibr" target="#b15">[16]</ref> and DistMult <ref type="bibr" target="#b14">[15]</ref> (reported by <ref type="bibr" target="#b8">[9]</ref>). We also study R-GCN <ref type="bibr" target="#b12">[13]</ref>, which shows good performance on standard datasets. These models are described in detail in the supplementary materials. Performance comparison TIP-cat and TIP-sum are the top two performers, outperforming Decagon by 7.2+% in AUPRC and much more in AUROC and AP@50. Compared to Decagon, TIP-cat and TIP-sum reduce Decagon's computational time by at least 98.9% and the peak GPU usage by at least 66.1%. TIP models achieve good performance because of the efficient information propagation between graphs. Learning the embedding of proteins in the P-P graph is efficient as all the propagation operations share the same trainable parameter at each layer. The most time and memory consuming part is the drug embedding learning on D-D graph, which takes ∼ 74% of the total training time and hits the peak GPU memory usage of 9.47G.</p><p>Learning drug embedding with pharmacological information Pharmacological information does contain drug-drug interaction information. By using it directly in dTIP P , we can get decent result with the shortest time. However, compared with R-GCN, additional pharmacological information in TIP-sum only improves the performance slightly. In addition, the comparable performance of TIP-cat and TIP-sum has an interesting implication: information propagation from PPM to GGM can be considered as learning a higher-level representation of a subset of proteins, which captures the relationship between proteins, and between proteins and drugs.</p><p>Drug representation learning on D-D graph Compared with DistMult that uses the dimensionreduced drug features directly (DF), the additional use of DDM in R-GCN (i.e., DDM-DF) improves over DF only by 5.6% (in AUPRC), and the further additional use of PPM and GGM in TIP-sum (i.e., PPM-GGM-DDM-DF) improves over DF only by 6.6%. This is because when using DDM, the drug can learn from its local neighborhoods and capture the relationship information. While protein-protein interaction and protein-drug interaction are extracted as additional drug features when using PPM-GGM. When decoding the drug embedding, The DF decoder outperforms the NN decoder by 11.5% in accuracy and 43.9% in time cost. However, the DF decoder requires more memory than the NN one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prediction of molecular-original side effects</head><p>We list side effects with 20 best and worst performance in TIP-cat in AUPRC score in <ref type="figure">Figs. 4 and 5</ref> of the supplementary materials, which show consistent conclusion that TIP is particularly good at modeling side effects with inter-molecular origins. However, by comparing these side effects, we find that even if the model does not have access to pharmacological information, it can predict the side effects with molecular origins very well. As shown in <ref type="table" target="#tab_1">Table 2</ref>, the R-GCN model with architecture DDM-DF achieves performance that is competitive with TIP-cat or TIP-sum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this work, we proposed a new Tri-graph Information Propagation (TIP) model for predicting more than one thousand side effects between hundreds of drugs, using pharmacological information and drug-drug interaction clinical records. TIP has achieved state-of-the-art performance on POSE prediction task with much less training time and memory consumption. It can be further improved by using general optimization strategies. It can also be applied to other problems such as cancer risk or drug response prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Materials</head><p>This is the supplementary material, including detailed problem formulation, notation, information propagation between nodes and graphs in TIP, model variants definitions, experimental setup and results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Problem Formulation and Notation</head><p>As shown in <ref type="figure">Figure.</ref> In the graph G, edges are directed and labeled: E = {(vi, q, vi)}, vi, vj ∈ V and l is a label of edges (q will be defined below). There are three edge types: protein-protein (P-P) edges , drug-protein (P-D) edges and drug-drug (D-D) edges, the labels of edges are associated with different edge types. Corresponding to the edge types, there are three subgraphs:</p><p>1. Undirected P-P graph: Gp = {Vp, Ep}. The edges Ep = (pi, b, p) are labeled with b, pi, pj ∈ Vp.</p><p>2. Undirected D-D graph:</p><formula xml:id="formula_6">G d = {V d , E d }, where E d = {(di, r k , dj)</formula><p>} means that a pair of drugs (di, dj) can cause multi-pharmacy side effect r k .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Directed D-P graph:</head><formula xml:id="formula_7">G h = {V, E h }, E h = pi, t,</formula><p>di is a set of edges directed from a protein to a drug with edge label t.</p><p>As shown above, the Gp/G h have the same label b / t, but the label of G d is chosen from R, where each ri ∈ R represents a side effect. Note that between a pair of drugs there might be more than one links with different labels (a pair of drug might cause more than one side effects). Use Q = {q|q ∈ {b, t} ∪ R} represents all kinds of labels.</p><p>We here consider POSE prediction task as a graph completion problem which aims to find the undiscovered edges and labels on the graph. Specifically, we extract the representation of the drugs from the defined graph G i.e. H d = {h d i |di ∈ D}, and predict the probability of all possible side effects of a queried drug pair (di, dj), i.e. {Pr k (di, dj)|r k ∈ R}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">TIP Encoder Design -An MPNN Framework Perspective</head><p>In our TIP encoder, each module corresponding to a special case of the Message Passing Neural Networks (MPNN) framework <ref type="bibr" target="#b2">[3]</ref> on a graph. A simple differentiable MPNN framework on a graph G = {V , E } is:</p><formula xml:id="formula_8">h (l+1) i = σ( m∈M i gm(h (l) i , Ni)),<label>(6)</label></formula><p>where i is associated with a node vi ∈ V . The input of the framework h (0) is a node feature vector, and h (l)</p><formula xml:id="formula_9">i ∈ R d (l)</formula><p>is the hidden state of this node in the l th layer of the neural network. Mi is the set of type-specified message passed in the form of gm(·, ·) related to node vi, and gm(·, ·) is typically a neural network-like function of the node state vi and its neighborhood Ni.</p><p>Inspired by this architecture, we define the tri-graph interaction propagation (TIP) encoder for calculating the update in each graphs forwardly. <ref type="figure" target="#fig_4">Figure.3</ref> shows an example for information propagation between nodes and graphs in a TIP-cat implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Detail of Models</head><p>The number of layers for PPM, GGM and DDM are set to <ref type="bibr" target="#b1">(2,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b1">2)</ref> in all the experiments.</p><p>TIP-cat and TIP-sum They both use a two-layer PPM with d 1 p = 32 and d 2 p = 16, a one-layer GGM and a two-layer DDM with  dTIP P This variant uses the protein information and relationship information between drugs and proteins only to predict drug side effects. It uses a two-layer PPM with d 1 p = 32 and d 2 p = 16, a one-layer GGM d p g = 16, d d g = 48 with concatenation, and the same two layer NN decoder as DDM-NN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Experimental Setup</head><p>Loss Function and Negative Sampling We use cross-entropy loss to optimize model, aiming to assign higher probabilities to observed edges and lower probabilities to undiscovered ones. Given a set of positive samples E p = {(di, r, dj)|r ∈ R} , the negative samples E n are sampled randomly from R until E n∩E p = ∅ <ref type="bibr" target="#b6">[7]</ref>.</p><p>Training and Testing data We pre-processed the whole dataset (See 1) by removing the side effects with less than 500 occurrence in the dataset. <ref type="bibr" target="#b0">1</ref> For each side effect, we use 80% of the total edges in D-D graph for model training and the remaining 20% for testing.</p><p>Optimization We use the Adam optimizer <ref type="bibr" target="#b4">[5]</ref> with learning rate of 0.01 and train for 100 epochs for all the experiments. The TIP model is optimized end-to-end which means all trainable parameters in both encoder and decoder are trained together. Due to the Graph-to-Graph information propagation architecture of TIP model, the memory cost is much less than Decagon model <ref type="bibr" target="#b15">[16]</ref>. TIP model therefore is optimized by full-batch, which means the whole dataset is fed into the model in each epoch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Implementation</head><p>We implement our TIP model in PyTorch <ref type="bibr" target="#b10">[11]</ref> with the PyTorch-Geometric package <ref type="bibr" target="#b1">[2]</ref>. The evaluation of peak GPU memory usage uses the tools provided by pytorch_memlab package 2 .</p><p>Performance Measurement We measure the performance using: 1) AUPRC: area under precision-recall curve, 2) AUROC: area under the receiver-operating characteristic, and 3) AP@k: average precision for the top k predictions for each side effect. 4) The computing cost (i.e. training time and peak GPU memory usage) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Prediction of Molecular-original Side Effects</head><p>We visualize the top 20 best and worst performance side effects in the DDM-DF model as shown in 4 and 5. Via comparing these figures, we find that even if model does not have pharmacological information, they can predict the side effects which have molecular origins very well. See more discussion in the main body. <ref type="figure">Figure 4</ref>: Side effects with the top 20 best and worst performance in TIP-cat on AUPRC scores. The side effects marked with red rectangular is in the side effect rank of the top 10 best/worst performance in <ref type="bibr" target="#b15">[16]</ref> Figure 5: Side effects with the top 20 best and worst performance in DDM-DF model on AUPRC scores. The side effects marked with red rectangular is in the side effect rank of the top 10 best/worst performance in <ref type="bibr" target="#b15">[16]</ref> </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>A multi-modal biomedical graph with two types of nodes: Drug (D) and Protein (P), and three types of edges: Protein-Protein (P-P) edges labeled with b (fixed), Protein-Drug (P-D) edges labeled with t (fixed), and Drug-Drug (D-D) edges labeled by a side effect r ∈ R.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Information propagation in TIP encoder.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>1 ,</head><label>1</label><figDesc>we construct a large multi-modal biomedical graph with Drug (D) nodes and Protein (P) nodes for polypharmacy side effect modeling. Given a set of drugs V d = {di} i∈[N d ] , a set of proteins Vp = {pi} i∈[N p ] and a set of side effects R = {ri} i∈[N r ] , where N d/p/r is the total number of drugs/proteins/side effects, the graph can be denoted as G = {V, E}, where V = {vi|vi ∈ V d ∪ Vp}.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>d 1 d</head><label>1</label><figDesc>= 32, d 2 d = 16 and base number d b d = 16. Their difference lies in the choice of aggregation function in GGM: TIP-cat uses concatenation with d p g = 16, d d g = 48, while TIP-sum uses summation with d p g = d d g = 64.R-GCN It's composed of a two-layer DDM with d 1 d = 32, d 2 d = 16 and a DistMult Factorization (DF) decoder. It models the D-D graph directly and is a special case of generic R-GCN for multi-relational link prediction<ref type="bibr" target="#b12">[13]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>An example of information propagation between nodes and graphs in a TIP-cat implementation with a 2-layer PPM, a GGM with concatenation operation and a 2-layer DDM. dTIP D It uses the same DDM as DR-DF, and does not use any protein information. Drug embeddings are learned from DR module, and a 2-layer neural network multi-classifier with d 1 n = 16, d 2 n = 964 is used as a decoder.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>BioSNAP-Decagon<ref type="bibr" target="#b9">[10]</ref> datasets. (P) denotes protein node, and (D) denotes drug node.</figDesc><table><row><cell>Dataset</cell><cell>Nodes</cell><cell cols="3">Edges Unique Labels Graph Name</cell></row><row><cell>PP-Decagon</cell><cell>19081(P)</cell><cell>715612</cell><cell>1</cell><cell>P-P graph</cell></row><row><cell cols="2">GhG-TargetDecagon 3648(P), 284(D)</cell><cell>18690</cell><cell>1</cell><cell>P-D graph</cell></row><row><cell>ChChSe-Decagon</cell><cell>645(D)</cell><cell>63473</cell><cell>1317</cell><cell>D-D graph</cell></row><row><cell>in</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Performance comparison on the SNAP-Decagon dataset. The best result is in bold for each evaluation metric. For Decagon, we quote the accuracy score in<ref type="bibr" target="#b15">[16]</ref> (marked with * ) and estimate the space and time cost from sub-set implementation (indicated by + ). Acronyms are described Secs. 2 and 3. ARCT: architecture; Mem: peak memory usage; TpE: computational time per epoch (including training and testing score computation).</figDesc><table><row><cell>Model</cell><cell>ARCT</cell><cell cols="4">AUPRC AUROC AP@50 Mem(G)</cell><cell>TpE(s)</cell></row><row><cell>Decagon</cell><cell></cell><cell>*  0.832</cell><cell>*  0.872</cell><cell>*  0.803</cell><cell cols="2">&gt; + 28 &gt; + 9600</cell></row><row><cell>DistMult</cell><cell>DF</cell><cell>0.835</cell><cell>0.859</cell><cell>0.834</cell><cell>9.25</cell><cell>41</cell></row><row><cell>R-GCN</cell><cell>DDM-DF</cell><cell>0.882</cell><cell>0.908</cell><cell>0.883</cell><cell>10.49</cell><cell>82</cell></row><row><cell>dTIP D</cell><cell>DDM-NN</cell><cell>0.791</cell><cell>0.847</cell><cell>0.792</cell><cell>9.49</cell><cell>118</cell></row><row><cell>dTIP P</cell><cell>PPM-GGM-NN</cell><cell>0.746</cell><cell>0.743</cell><cell>0.733</cell><cell>6.38</cell><cell>29</cell></row><row><cell>TIP-cat</cell><cell>PPM-GGM-DDM-DF</cell><cell>0.889</cell><cell>0.913</cell><cell>0.890</cell><cell>9.47</cell><cell>116</cell></row><row><cell cols="2">TIP-sum PPM-GGM-DDM-DF</cell><cell>0.890</cell><cell>0.914</cell><cell>0.890</cell><cell>9.47</cell><cell>115</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">It's the same pre-processing as in Zitnik et al. [16] 2 https://github.com/Stonesjtu/pytorch_memlab</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Convolutional networks on graphs for learning molecular fingerprints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dougal</forename><surname>David K Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorge</forename><surname>Maclaurin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafael</forename><surname>Iparraguirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Bombarell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alán</forename><surname>Hirzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan P</forename><surname>Aspuru-Guzik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2224" to="2232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Fast graph representation learning with PyTorch Geometric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">E</forename><surname>Lenssen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR Workshop on Representation Learning on Graphs and Manifolds</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Neural message passing for quantum chemistry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schoenholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Patrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">E</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1263" to="1272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rex</forename><surname>William L Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Leskovec</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.05584</idno>
		<title level="m">Representation learning on graphs: Methods and applications</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.07308</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">Variational graph auto-encoders. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Drug similarity integration through attentive multi-view graph auto-encoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengfei</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cao</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 27th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3477" to="3483" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Knowledge graph completion to predict polypharmacy side effects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brandon</forename><surname>Malone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>García-Durán</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathias</forename><surname>Niepert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Data Integration in the Life Sciences</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="144" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sagar Maheshwari Marinka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rok</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Sosic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Leskovec</surname></persName>
		</author>
		<ptr target="http://snap.stanford.edu/biodata" />
		<title level="m">BioSNAP Datasets: Stanford biomedical network dataset collection</title>
		<imprint>
			<date type="published" when="2018-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Automatic differentiation in PyTorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Autodiff Workshop</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep learning improves prediction of drug-drug and drug-food interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jae</forename><surname>Yong Ryu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyun</forename><forename type="middle">Uk</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sang</forename><forename type="middle">Yup</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">18</biblScope>
			<biblScope unit="page" from="4304" to="4311" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Modeling relational data with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rianne</forename><surname>Bloem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Semantic Web Conference</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="593" to="607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Gamenet: Graph augmented memory networks for recommending medication combination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyuan</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cao</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengfei</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimeng</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1126" to="1133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Embedding entities and relations for learning and inference in knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bishan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6575</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Modeling polypharmacy side effects with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marinka</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Monica</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="457" to="466" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
