<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Careful Selection of Knowledge to solve Open Book Question Answering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pratyay</forename><surname>Banerjee</surname></persName>
							<email>pbanerj6@asu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Arizona State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuntal</forename><forename type="middle">Kumar</forename><surname>Pal</surname></persName>
							<email>kkpal@asu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Arizona State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arindam</forename><surname>Mitra</surname></persName>
							<email>amitra7@asu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Arizona State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chitta</forename><surname>Baral</surname></persName>
							<email>chitta@asu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Arizona State University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Careful Selection of Knowledge to solve Open Book Question Answering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T18:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Open book question answering is a type of natural language based QA (NLQA) where questions are expected to be answered with respect to a given set of open book facts, and common knowledge about a topic. Recently a challenge involving such QA, OpenBookQA, has been proposed. Unlike most other NLQA tasks that focus on linguistic understanding, Open-BookQA requires deeper reasoning involving linguistic understanding as well as reasoning with common knowledge. In this paper we address QA with respect to the OpenBookQA dataset and combine state of the art language models with abductive information retrieval (IR), information gain based re-ranking, passage selection and weighted scoring to achieve 72.0% accuracy, an 11.6% improvement over the current state of the art. * These authors contributed equally to this work. Github.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Natural language based question answering (NLQA) not only involves linguistic understanding, but often involves reasoning with various kinds of knowledge. In recent years, many NLQA datasets and challenges have been proposed, for example, SQuAD <ref type="bibr" target="#b22">(Rajpurkar et al., 2016)</ref>, Trivi-aQA <ref type="bibr" target="#b11">(Joshi et al., 2017)</ref> and MultiRC <ref type="bibr" target="#b12">(Khashabi et al., 2018)</ref>, and each of them have their own focus, sometimes by design and other times by virtue of their development methodology. Many of these datasets and challenges try to mimic human question answering settings. One such setting is open book question answering where humans are asked to answer questions in a setup where they can refer to books and other materials related to their questions. In such a setting, the focus is not on memorization but, as mentioned in <ref type="bibr" target="#b16">Mihaylov et al. (2018)</ref>, on "deeper understanding of the materials and its application to new situations <ref type="bibr" target="#b10">(Jenkins, 1995;</ref><ref type="bibr" target="#b15">Landsberger, 1996)</ref>." In <ref type="bibr" target="#b16">Mihaylov et al. (2018)</ref>, they propose the OpenBookQA dataset mimicking this setting.</p><p>Question: A tool used to identify the percent chance of a trait being passed down has how many squares ? (A) Two squares (B) Four squares (C) Six squares (D) Eight squares Extracted from OpenBook: a punnett square is used to identify the percent chance of a trait being passed down from a parent to its offspring. Retrieved Missing Knowledge: Two squares is four. The Punnett square is made up of 4 squares and 2 of them are blue and 2 of them are brown, this means you have a 50% chance of having blue or brown eyes. The OpenBookQA dataset has a collection of questions and four answer choices for each question. The dataset comes with 1326 facts representing an open book. It is expected that answering each question requires at least one of these facts. In addition it requires common knowledge. To obtain relevant common knowledge we use an IR system <ref type="bibr" target="#b3">(Clark et al., 2016)</ref> front end to a set of knowledge rich sentences. Compared to reading comprehension based QA (RCQA) setup where the answers to a question is usually found in the given small paragraph, in the OpenBookQA setup the open book part is much larger (than a small paragraph) and is not complete as additional common knowledge may be required. This leads to multiple challenges. First, finding the relevant facts in an open book (which is much bigger than the small paragraphs in the RCQA setting) is a challenge. Then, finding the relevant common knowledge using the IR front end is an even bigger challenge, especially since standard IR approaches can be misled by distractions. For example, <ref type="table" target="#tab_0">Table 1</ref> shows a sample question from the Open-BookQA dataset. We can see the retrieved missing knowledge contains words which overlap with both answer options A and B. Introduction of such knowledge sentences increases confusion for the question answering model. Finally, reasoning involving both facts from open book, and common knowledge leads to multi-hop reasoning with respect to natural language text, which is also a challenge.</p><p>We address the first two challenges and make the following contributions in this paper: (a) We improve on knowledge extraction from the Open-Book present in the dataset. We use semantic textual similarity models that are trained with different datasets for this task; (b) We propose natural language abduction to generate queries for retrieving missing knowledge; (c) We show how to use Information Gain based Re-ranking to reduce distractions and remove redundant information; (d) We provide an analysis of the dataset and the limitations of BERT Large model for such a question answering task.</p><p>The current best model on the leaderboard of OpenBookQA is the BERT Large model <ref type="bibr" target="#b5">(Devlin et al., 2018)</ref>. It has an accuracy of 60.4% and does not use external knowledge. Our knowledge selection and retrieval techniques achieves an accuracy of 72%, with a margin of 11.6% on the current state of the art. We study how the accuracy of the BERT Large model varies with varying number of knowledge facts extracted from the OpenBook and through IR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>In recent years, several datasets have been proposed for natural language question answering <ref type="bibr" target="#b22">(Rajpurkar et al., 2016;</ref><ref type="bibr" target="#b11">Joshi et al., 2017;</ref><ref type="bibr" target="#b12">Khashabi et al., 2018;</ref><ref type="bibr" target="#b24">Richardson et al., 2013;</ref><ref type="bibr" target="#b14">Lai et al., 2017;</ref><ref type="bibr" target="#b23">Reddy et al., 2018;</ref><ref type="bibr" target="#b27">Tafjord et al., 2018;</ref><ref type="bibr" target="#b17">Mitra et al., 2019</ref>) and many attempts have been made to solve these challenges <ref type="bibr" target="#b5">(Devlin et al., 2018;</ref><ref type="bibr" target="#b28">Vaswani et al., 2017;</ref><ref type="bibr" target="#b25">Seo et al., 2016)</ref>.</p><p>Among these, the closest to our work is the work in <ref type="bibr" target="#b5">(Devlin et al., 2018)</ref> which perform QA using fine tuned language model and the works of <ref type="bibr" target="#b26">(Sun et al., 2018;</ref><ref type="bibr" target="#b33">Zhang et al., 2018)</ref> which performs QA using external knowledge.</p><p>Related to our work for extracting missing knowledge are the works of <ref type="bibr" target="#b19">(Ni et al., 2018;</ref><ref type="bibr" target="#b18">Musa et al., 2018;</ref><ref type="bibr" target="#b13">Khashabi et al., 2017)</ref> which respectively generate a query either by extracting key terms from a question and an answer option or by classifying key terms or by Seq2Seq models to generate key terms. In comparison, we generate queries using the question, an answer option and an extracted fact using natural language abduction.</p><p>The task of natural language abduction for natural language understanding has been studied for a long time <ref type="bibr" target="#b20">(Norvig, 1983</ref><ref type="bibr" target="#b21">(Norvig, , 1987</ref><ref type="bibr" target="#b7">Hobbs, 2004;</ref><ref type="bibr" target="#b8">Hobbs et al., 1993;</ref><ref type="bibr" target="#b30">Wilensky, 1983;</ref><ref type="bibr" target="#b31">Wilensky et al., 2000;</ref><ref type="bibr">Goldman, 1988, 1989)</ref>. However, such works transform the natural language text to a logical form and then use formal reasoning to perform the abduction. On the contrary, our system performs abduction over natural language text without translating the texts to a logical form.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Approach</head><p>Our approach involves six main modules: Hypothesis Generation, OpenBook Knowledge Extraction, Abductive Information Retrieval, Information Gain based Re-ranking, Passage Selection and Question Answering. A key aspect of our approach is to accurately hunt the needed knowledge facts from the OpenBook knowledge corpus and hunt missing common knowledge using IR. We explain our approach in the example given in Table 2.</p><p>Question: A red-tailed hawk is searching for prey. It is most likely to swoop down on what? (A) a gecko Generated Hypothesis : H : A red-tailed hawk is searching for prey. It is most likely to swoop down on a gecko. Retrieved Fact from OpenBook: F : hawks eat lizards Abduced Query to find missing knowledge: K : gecko is lizard Retrieved Missing Knowledge using IR: K : Every gecko is a lizard.  In Hypothesis Generation, our system generates a hypothesis H ij for the ith question and jth answer option, where j ∈ {1, 2, 3, 4}. In Open-Book Knowledge Extraction, our system retrieves appropriate knowledge F ij for a given hypothesis H ij using semantic textual similarity, from the OpenBook knowledge corpus F. In Abductive Information Retrieval, our system abduces missing knowledge from H ij and F ij . The system formulates queries to perform IR to retrieve missing knowledge K ij . With the retrieved K ij , F ij , Information Gain based Re-ranking and Passage Selection our system creates a knowledge passage P ij . In Question Answering, our system uses P ij to answer the questions using a BERT Large based MCQ model, similar to its use in solving SWAG <ref type="bibr" target="#b32">(Zellers et al., 2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Hypothesis Generation</head><p>Our system creates a hypothesis for each of the questions and candidate answer options as part of the data preparation phase as shown in the example in <ref type="table" target="#tab_1">Table 2</ref>. The questions in the OpenBookQA dataset are either with wh word or are incomplete statements. To create hypothesis statements for questions with wh words, we use the rule-based model of <ref type="bibr" target="#b4">Demszky et al. (2018)</ref>. For the rest of the questions, we concatenate the questions with each of the answers to produce the four hypotheses. This has been done for all the training, test and validation sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">OpenBook Knowledge Extraction</head><p>To retrieve a small set of relevant knowledge facts from the knowledge corpus F, a textual similarity model is trained in a supervised fashion on two different datasets and the results are compared. We use the large-cased BERT <ref type="bibr" target="#b5">(Devlin et al., 2018)</ref> (BERT Large) as the textual similarity model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">BERT Model Trained on STS-B</head><p>We train it on the semantic textual similarity (STS-B) data from the GLUE dataset . The trained model is then used to retrieve the top ten knowledge facts from corpus F based on the STS-B scores. The STS-B scores range from 0 to 5.0, with 0 being least similar.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">BERT Model Trained on OpenBookQA</head><p>We generate the dataset using the gold Open-BookQA facts from F for the train and validation set provided. To prepare the train set, we first find the similarity of the OpenBook F facts with respect to each other using the BERT model trained on STS-B dataset. We assign a score 5.0 for the goldF i fact for a hypothesis. We then sample different facts from the OpenBook and assign the STS-B similarity scores between the sampled fact and the gold factF i as the target score for that fact F ij and H ij . For example:</p><p>Hypothesis : Frilled sharks and angler fish live far beneath the surface of the ocean, which is why they are known as Deep sea animals. Gold Fact : deep sea animals live deep in the ocean : Score : 5.0 Sampled Facts : coral lives in the ocean : Score : 3.4 a fish lives in water : Score : 2.8</p><p>We do this to ensure a balanced target score is present for each hypothesis and fact. We use this trained model to retrieve top ten relevant facts for each H ij from the knowledge corpus F.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Natural Language Abduction and IR</head><p>To search for the missing knowledge, we need to know what we are missing. We use "abduction" to figure that out. Abduction is a long studied task in AI, where normally, both the observation (hypothesis) and the domain knowledge (known fact) is represented in a formal language from which a logical solver abduces possible explanations (missing knowledge). However, in our case, both the observation and the domain knowledge are given as natural language sentences from which we want to find out a possible missing knowledge, which we will then hunt using IR. For example, one of the hypothesis H ij is "A redtailed hawk is searching for prey. It is most likely to swoop down on a gecko.", and for which the known fact F ij is "hawks eats lizards". From this we expect the output of the natural language abduction system to be K ij or "gecko is a lizard". We will refer to this as "natural language abduction".</p><p>For natural language abduction, we propose three models, compare them against a baseline model and evaluate each on a downstream question answering task. All the models ignore stop words except the Seq2Seq model. We describe the three models and a baseline model in the subsequent subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Word Symmetric Difference Model</head><p>We design a simple heuristic based model defined as below:</p><formula xml:id="formula_0">K ij = (H ij ∪F ij )\(H ij ∩F ij ) ∀j ∈ {1, 2, 3, 4}</formula><p>where i is the ith question, j is the jth option, H ij , F ij , K ij represents set of unique words of each instance of hypothesis, facts retrieved from knowledge corpus F and abduced missing knowledge of validation and test data respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Supervised Bag of Words Model</head><p>In the Supervised Bag of Words model, we select words which satisfy the following condition:</p><formula xml:id="formula_1">P (w n ∈ K ij ) &gt; θ where w n ∈ {H ij ∪ F ij }.</formula><p>To elaborate, we learn the probability of a given word w n from the set of words in H ij ∪ F ij belonging to the abduced missing knowledge K ij . We select those words which are above the threshold θ.</p><p>To learn this probability, we create a training and validation dataset where the words similar (cosine similarity using spaCy) <ref type="bibr">(Honnibal and Montani, 2017)</ref> to the words in the gold missing knowledgeK i (provided in the dataset) are labelled as positive class and all the other words not present inK i but in H ij ∪ F ij are labelled as negative class. Both classes are ensured to be balanced. Finally, we train a binary classifier using BERT Large with one additional feed forward network for classification. We define value for the threshold θ using the accuracy of the classifier on validation set. 0.4 was selected as the threshold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Copynet Seq2Seq Model</head><p>In the final approach, we used the copynet sequence to sequence model <ref type="bibr" target="#b6">(Gu et al., 2016)</ref> to generate, instead of predict, the missing knowledge given, the hypothesis H and knowledge fact from the corpus F. The intuition behind using copynet model is to make use of the copy mechanism to generate essential yet precise (minimizing distractors) information which can help in answering the question. We generate the training and validation dataset using the goldK i as the target sentence, but we replace out-of-vocabulary words from the target with words similar (cosine similarity using spaCy) <ref type="bibr">(Honnibal and Montani, 2017)</ref> to the words present in H ij ∪ F ij . Here, however, we did not remove the stopwords. We choose one, out of multiple generated knowledge based on our model which provided maximum overlap score, given by</p><formula xml:id="formula_2">overlap score = i count((Ĥ i ∪ F i ) ∩ K i ) i count(K i )</formula><p>where i is the ith question,Ĥ i being the set of unique words of correct hypothesis, F i being the set of unique words from retrieved facts from knowledge corpus F, K i being the set of unique words of predicted missing knowledge andK i being the set of unique words of the gold missing knowledge .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.4">Word Union Model</head><p>To see if abduction helps, we compare the above models with a Word Union Model. To extract the candidate words for missing knowledge, we used the set of unique words from both the hypothesis and OpenBook knowledge as candidate keywords. The model can be formally represented with the following:</p><formula xml:id="formula_3">K ij = (H ij ∪ F ij ) ∀j ∈ {1, 2, 3, 4}</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Information Gain based Re-ranking</head><p>In our experiments we observe that, BERT QA model gives a higher score if similar sentences are repeated, leading to wrong classification. Thus, we introduce Information Gain based Re-ranking to remove redundant information. We use the same BERT Knowledge Extraction model Trained on OpenBookQA data (section 3.2.2), which is used for extraction of knowledge facts from corpus F to do an initial ranking of the retrieved missing knowledge K. The scores of this knowledge extraction model is used as relevancy score, rel. To extract the top ten missing knowledge K, we define a redundancy score, red ij , as the maximum cosine similarity, sim, between the previously selected missing knowledge, in the previous iterations till i, and the candidate missing knowledge K j . If the last selected missing knowledge is K i , then</p><formula xml:id="formula_4">red ij (K j ) = max(red i−1,j (K j ), sim(K i , K j )) rank score = (1 − red i,j (K j )) * rel(K j )</formula><p>For missing knowledge selection, we first take the missing knowledge with the highest rel score. From the subsequent iteration, we compute the redundancy score with the last selected missing knowledge for each of the candidates and then rank them using the updated rank score. We select the top ten missing knowledge for each H ij .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Question Answering</head><p>Once the OpenBook knowledge facts F and missing knowledge K have been extracted, we move onto the task of answering the questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.1">Question-Answering Model</head><p>We use BERT Large model for the question answering task. For each question, we create a passage using the extracted facts and missing knowledge and fine-tune the BERT Large model for the QA task with one additional feed-forward layer for classification. The passages for the train dataset were prepared using the knowledge corpus facts, F. We create a passage using the top N facts, similar to the actual gold factF i , for the train set. The similarities were scored using the STS-B trained model (section 3.2.1). The passages for the training dataset do not use the gold missing knowledgê K i provided in the dataset. For each of our experiments, we use the same trained model, with passages from different IR models. The BERT Large model limits passage length to be lesser than equal to 512. This restricts the size of the passage. To be within the restrictions we create a passage for each of the answer options, and score for all answer options against each passage. We refer to this scoring as sum score, defined as follows:</p><p>For each answer options, A j , we create a passage P j and score against each of the answer options A i . To compute the final score for the answer, we sum up each individual scores. If Q is the question, the score for the answer is defined as</p><formula xml:id="formula_5">P r(Q, A i ) = 4 j=1 score(P j , Q, A i )</formula><p>where score is the classification score given by the BERT Large model. The final answer is chosen based on,</p><formula xml:id="formula_6">A = arg max A P r(Q, A i )</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.2">Passage Selection and Weighted Scoring</head><p>In the first round, we score each of the answer options using a passage created from the selected knowledge facts from corpus F. For each question, we ignore the passages of the answer options which are in the bottom two. We refer to this as Passage Selection. In the second round, we score for only those passages which are selected after adding the missing knowledge K.</p><p>We assume that the correct answer has the highest score in each round. Therefore we multiply the scores obtained after both rounds. We refer to this as Weighted Scoring. We define the combined passage selected scores and weighted scores as follows :</p><formula xml:id="formula_7">P r(F, Q, A i ) = 4 j=1 score(P j , Q, A i )</formula><p>where P j is the passage created from extracted OpenBook knowledge, F. The top two passages were selected based on the scores of P r(F, Q, A i ). where δ = 1 for the top two scores and δ = 0 for the rest. P k is the passage created using both the facts and missing knowledge. The final weighted score is :</p><formula xml:id="formula_8">wP r(Q, A i ) = P r(F, Q, A i ) * P r(F ∪ K, Q, A i )</formula><p>The answer is chosen based on the top weighted scores as below:</p><formula xml:id="formula_9">A = arg max A wP r(Q, A i )</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset and Experimental Setup</head><p>The dataset of OpenBookQA contains 4957 questions in the train set and 500 multiple choice questions in validation and test respectively. We train a BERT Large based QA model using the top ten  knowledge facts from the corpus F, as a passage for both training and validation set. We select the model which gives the best score for the validation set. The same model is used to score the validation and test set with different passages derived from different methods of Abductive IR. The best Abductive IR model, the number of facts from F and K are selected from the best validation scores for the QA task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">OpenBook Knowledge Extraction</head><p>Question: .. they decide the best way to save money is ? (A) to quit eating lunch out (B) to make more phone calls (C) to buy less with monopoly money (D) to have lunch with friends Knowledge extraction trained with STS-B: using less resources usually causes money to be saved a disperser disperses each season occurs once per year Knowledge extraction trained with Open-BookQA: using less resources usually causes money to be saved decreasing something negative has a positive impact on a thing conserving resources has a positive impact on the environment <ref type="table" target="#tab_3">Table 3</ref> shows a comparative study of our three approaches for OpenBook knowledge extraction. We show, the number of correct OpenBook knowledge extracted for all of the four answer options using the three approaches TF-IDF, BERT model trained on STS-B data and BERT model Trained on OpenBook data. Apart from that, we also show the count of the number of facts present precisely across the correct answer options. It can be seen that the Precision@N for the BERT model trained on OpenBook data is better than the other models as N increases.</p><p>The above example presents the facts retrieved from BERT model trained on OpenBook which are more relevant than the facts retrieved from BERT model trained on STS-B. Both the models were able to find the most relevant fact, but the other facts for STS-B model introduce more distractors and have lesser relevance. The impact of this is visible from the accuracy scores for the QA task in <ref type="table" target="#tab_3">Table 3</ref> . The best performance of the BERT QA model can be seen to be 66.2% using only OpenBook facts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Abductive Information Retrieval</head><p>We evaluate the abductive IR techniques at different values for number of facts from F and number of missing knowledge K extracted using IR. <ref type="figure">Figure 2</ref> shows the accuracy against different combinations of F and K , for all four techniques of IR prior to Information gain based Re-ranking. In general, we noticed that the trained models performed poorly compared to the baselines. The Word Symmetric Difference model performs better, indicating abductive IR helps. The poor performance of the trained models can be attributed to the challenge of learning abductive inference.</p><p>For the above example it can be seen, the pre-reranking facts are relevant to the question but contribute very less considering the knowledge facts retrieved from the corpus F and the correct answer. <ref type="figure">Figure 3</ref> shows the impact of Information gain based Re-ranking. Removal of redundant data allows the scope of more relevant information being present in the Top N retrieved missing knowledge K.</p><p>Question: A red-tailed hawk is searching for prey. It is most likely to swoop down on what? (A) an eagle (B) a cow (C) a gecko (D) a deer Fact from F : hawks eats lizards Pre-Reranking K : red-tail hawk in their search for prey Red-tailed hawks soar over the prairie and woodlands in search of prey. Post-Reranking K: Geckos -only vocal lizards. Every gecko is a lizard.   For the example shown above, the wrong answer leopards had very low score with only the facts extracted from knowledge corpus F. But introduction of missing knowledge from the wrong fact from F boosts its scores, leading to wrong prediction. Passage selection helps in removal of such options and Weighted Scoring gives preference to those answer options whose scores are relatively high before and after inclusion of missing knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Question Answering</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Analysis &amp; Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Model Analysis</head><p>BERT Question Answering model: BERT performs well on this task, but is prone to distractions. Repetition of information leads to boosted prediction scores. BERT performs well for lookup based QA, as in RCQA tasks like SQuAD. But this poses a challenge for Open Domain QA, as the extracted knowledge enables lookup for all answer options, leading to an adversarial setting for lookup based QA. This model is able to find the correct answer, even under the adversarial setting, which is shown by the performance of the sum score to select the answer after passage selection.</p><p>Symmetric Difference Model This model improves on the baseline Word Union model by 1-2%. The improvement is dwarfed because of inappropriate domain knowledge from F being used for abduction. The intersection between the inappropriate domain knowledge and the answer hypothesis is ∅, which leads to queries which are exactly same as the Word Union model.</p><p>Supervised learned models The supervised learned models for abduction under-perform. The Bag of Words and the Seq2Seq models fail to extract keywords for many F − H pairs, sometimes missing the keywords from the answers. The Seq2Seq model sometimes extracts the exact missing knowledge, for example it generates "some birds is robin" or "lizard is gecko". This shows there is promise in this approach and the poor performance can be attributed to insufficient train data size, which was 4957 only. A fact verification model might improve the accuracy of the supervised learned models. But, for many questions, it fails to extract proper keywords, copying just a part of the question or the knowledge fact.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Error Analysis</head><p>Other than errors due to distractions and failed IR, which were around 85% of the total errors, the errors seen are of four broad categories.</p><p>Temporal Reasoning: In the example 2 shown below, even though both the options can be considered as night, the fact that 2:00 AM is more suitable for the bats than 6:00 PM makes it difficult to reason. Such issues accounted for 5% of the errors. Question: Owls are likely to hunt at? (A) 3:00 PM (B) 2:00 AM (C) 6:00 PM (D) 7:00 AM Negation: In the example shown below, a model is needed which handles negations specifically to reject incorrect options. Such issues accounted for 1% of the errors.</p><p>Question: Which of the following is not an input in photosynthesis? (A) sunlight (B) oxygen (C) water (D) carbon dioxide Conjunctive Reasoning: In the example as shown below, each answer options are partially correct as the word " bear" is present. Thus a model has to learn whether all parts of the answer are true or not, i.e Conjunctive Reasoning. Logically, all answers are correct, as we can see an "or", but option (A) makes more sense. Such issues accounted for 1% of the errors.</p><p>Question: Some berries may be eaten by (A) a bear or person (B) a bear or shark (C) a bear or lion (D) a bear or wolf Qualitative Reasoning: In the example shown below, each answer options would stop a car but option (D) is more suitable since it will stop the car quicker. A deeper qualitative reasoning is needed to reject incorrect options. Such issues accounted for 8% of the errors.</p><p>Question: Which of these would stop a car quicker? (A) a wheel with wet brake pads (B) a wheel without brake pads (C) a wheel with worn brake pads (D) a wheel with dry brake pads</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this work, we have pushed the current state of the art for the OpenBookQA task using simple techniques and careful selection of knowledge. We have provided two new ways of performing knowledge extraction over a knowledge base for QA and evaluated three ways to perform abductive inference over natural language. All techniques are shown to improve on the performance of the final task of QA, but there is still a long way to reach human performance.</p><p>We analyzed the performance of various components of our QA system. For the natural language abduction, the heuristic technique performs better than the supervised techniques. Our analysis also shows the limitations of BERT based MCQ models, the challenge of learning natural language abductive inference and the multiple types of reasoning required for an OpenBookQA task. Nevertheless, our overall system improves on the state of the art by 11.6%.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Our approach</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>P r(F ∪ K, Q, A i ) = 4 k=1 δ * score(P k , Q, A i )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 : 1 Figure 3 :</head><label>213</label><figDesc>Accuracy v/s Number of facts from F -number of facts from K, without Information Gain based Re-ranking for 3 abductive IR models and Word Union model. Accuracy v/s Number of facts from F -number of facts from K, with Information Gain based Reranking for 3 abductive IR models and Word Union model. 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>2</head><label></label><figDesc>Predictions are in italics, Correct answers are in Bold.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>An example of distracting retrieved knowledge</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Our approach with an example for the correct option</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Compares (a) The number of correct facts that appears across any four passages (b) The number of correct facts that appears in the passage of the correct hypothesis (c) The accuracy for TF-IDF, BERT model trained on STS-B dataset and BERT model trained on OpenBook dataset. N is the number of facts considered.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell>shows the incremental improvement on</cell></row><row><cell>the baselines after inclusion of carefully selected</cell></row><row><cell>knowledge.</cell></row><row><cell>Passage Selection and Weighted Scoring are</cell></row><row><cell>used to overcome the challenge of boosted pre-</cell></row><row><cell>diction scores due to cascading effect of errors in</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell>: Test Set Comparison of Different Compo-</cell></row><row><cell>nents. Current state of the art (SOTA) is the Only Ques-</cell></row><row><cell>tion model. K is retrieved from Symmetric Difference</cell></row><row><cell>Model. KE refers to Knowledge Extraction.</cell></row><row><cell>each stage.</cell></row><row><cell>Question: What eat plants? (A) leopards (B)</cell></row><row><cell>eagles (C) owls (D) robin</cell></row><row><cell>Appropriate extracted Fact from F :</cell></row><row><cell>some birds eat plants</cell></row><row><cell>Wrong Extracted Fact from F :</cell></row><row><cell>a salamander eats insects</cell></row><row><cell>Wrong Retrieved Missing Knowledge:</cell></row><row><cell>Leopard geckos eat mostly insects</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">No Passage Selection and Weighted Scoring.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Acknowledgement</head><p>We thank NSF for the grant 1816039 and DARPA for partially supporting this research.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A logic for semantic interpretation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Goldman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th annual meeting on Association for Computational Linguistics</title>
		<meeting>the 26th annual meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1988" />
			<biblScope unit="page" from="87" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A semantics for probabilistic quantifier-free first-order languages, with particular application to story understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Robert P Goldman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="1989" />
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page" from="1074" to="1079" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Yatskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wentau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.07036</idno>
		<title level="m">Quac: Question answering in context</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Combining retrieval, statistics, and inference to answer elementary science questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Turney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirtieth AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Transforming question answering datasets into natural language inference datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dorottya</forename><surname>Demszky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.02922</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Incorporating copying mechanism in sequence-to-sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiatao</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">K</forename><surname>Victor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P16-1154</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1631" to="1640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Abduction in natural language understanding. Handbook of pragmatics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jerry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hobbs</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="724" to="741" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Interpretation as abduction. Artificial intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jerry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><forename type="middle">E</forename><surname>Hobbs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><forename type="middle">E</forename><surname>Stickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Appelt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Martin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="69" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">2017. spacy 2: Natural language understanding with bloom embeddings, convolutional neural networks and incremental parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Honnibal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ines</forename><surname>Montani</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Open Book Assessment in Computing Degree Programmes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tony</forename><surname>Jenkins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<publisher>Citeseer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1147</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1601" to="1611" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Looking beyond the surface: A challenge set for reading comprehension over multiple sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Snigdha</forename><surname>Chaturvedi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shyam</forename><surname>Upadhyay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="252" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning what is essential in questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st Conference on Computational Natural Language Learning</title>
		<meeting>the 21st Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="80" to="89" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Race: Large-scale reading comprehension dataset from examinations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guokun</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-1082</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="785" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Landsberger</surname></persName>
		</author>
		<title level="m">Study guides and strategies</title>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Can a suit of armor conduct electricity? a new dataset for open book question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todor</forename><surname>Mihaylov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Declarative question answering over knowledge bases containing natural language text with answer set programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arindam</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chitta</forename><surname>Baral</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Answering science exam questions using query rewriting with background knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Musa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Achille</forename><surname>Fokoue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Mattei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavan</forename><surname>Kapanipathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bassem</forename><surname>Makni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kartik</forename><surname>Talamadupula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Witbrock</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.05726</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Learning to attend on essential terms: An enhanced retriever-reader model for scientific question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmo</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenguang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.09492</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Frame activated inferences in a story understanding program</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Norvig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="1983" />
			<biblScope unit="page" from="624" to="626" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Inference in text understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Norvig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="1987" />
			<biblScope unit="page" from="561" to="565" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Squad: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D16-1264</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2383" to="2392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.07042</idno>
		<title level="m">Coqa: A conversational question answering challenge</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Mctest: A challenge dataset for the open-domain machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erin</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Renshaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="193" to="203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Bidirectional attention flow for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aniruddha</forename><surname>Kembhavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01603</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Improving machine reading comprehension with general reading strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<idno>abs/1810.13441</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.08048</idno>
		<title level="m">Quarel: A dataset and models for answering questions about qualitative relationships</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amapreet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel R</forename><surname>Bowman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.07461</idno>
		<title level="m">Glue: A multi-task benchmark and analysis platform for natural language understanding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Planning and understanding: A computational approach to human reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Wilensky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The berkeley unix consultant project</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Wilensky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Luria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dekai</forename><surname>Mayfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Help Systems for UNIX</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="49" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rowan</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.05326</idno>
		<title level="m">Swag: A large-scale adversarial dataset for grounded commonsense inference</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Kgˆ2: Learning to reason science exam questions with contextual knowledge graph embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanjun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kamil</forename><surname>Toraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Song</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.12393</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
