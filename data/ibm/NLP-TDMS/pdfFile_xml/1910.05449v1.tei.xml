<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MultiPath: Multiple Probabilistic Anchor Trajectory Hypotheses for Behavior Prediction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuning</forename><surname>Chai</surname></persName>
							<email>chaiy@waymo.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Waymo LLC</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Sapp</surname></persName>
							<email>bensapp@waymo.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Waymo LLC</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mayank</forename><surname>Bansal</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Waymo LLC</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Waymo LLC</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">MultiPath: Multiple Probabilistic Anchor Trajectory Hypotheses for Behavior Prediction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T19:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Predicting human behavior is a difficult and crucial task required for motion planning. It is challenging in large part due to the highly uncertain and multimodal set of possible outcomes in real-world domains such as autonomous driving. Beyond single MAP trajectory prediction <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>, obtaining an accurate probability distribution of the future is an area of active interest <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>. We present MultiPath, which leverages a fixed set of future state-sequence anchors that correspond to modes of the trajectory distribution. At inference, our model predicts a discrete distribution over the anchors and, for each anchor, regresses offsets from anchor waypoints along with uncertainties, yielding a Gaussian mixture at each time step. Our model is efficient, requiring only one forward inference pass to obtain multi-modal future distributions, and the output is parametric, allowing compact communication and analytical probabilistic queries. We show on several datasets that our model achieves more accurate predictions, and compared to sampling baselines, does so with an order of magnitude fewer trajectories.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>We focus on the problem of predicting future agent states, which is a crucial task for robot planning in real-world environments. We are particularly interested in addressing this problem for self-driving vehicles, an application with a potentially enormous societal impact. Importantly, predicting the future of other agents in this domain is vital for safe, comfortable and efficient operation. For example, it is important to know whether to yield to a vehicle if they are going to cut in front of our robot or when would be the best time to merge into traffic. Such future prediction requires an understanding of the static and dynamic world context: road semantics (e.g., lane connectivity, stop lines), traffic light information, and past observations of other agents, as depicted in <ref type="figure" target="#fig_0">Fig. 1</ref>.</p><p>A fundamental aspect of future state prediction is that it is inherently stochastic, as agents cannot know each other's motivations. When driving, we can never really be sure what other drivers will do next, and it is important to consider multiple outcomes and their likelihoods. We seek a model of the future that can provide both (1) a weighted, parsimonious set of discrete trajectories that covers the space of likely outcomes and (2) a closed-form evaluation of the likelihood of any trajectory. These two attributes enable efficient reasoning in crucial planning use-cases, for example, human-like reactions to discrete trajectory hypotheses (e.g., yielding, following), and probabilistic queries such as the expected risk of collision in a space-time region.</p><p>Both of these attributes present modeling challenges. Models which try to achieve diversity and coverage often suffer from mode collapse during training <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6]</ref>, while tractable probabilistic inference is difficult due to the space of possible trajectories growing exponentially over time.</p><p>Our MultiPath model addresses these issues with a key insight: it employs a fixed set of trajectory anchors as the basis of our modeling. This lets us factor stochastic uncertainty hierarchically: First, intent uncertainty captures the uncertainty of what an agent intends to do and is encoded as a distribution over the set of anchor trajectories. Second, given an intent, control uncertainty represents our uncertainty over how they might achieve it. We assume control uncertainty is normally distributed at each future time step <ref type="bibr" target="#b6">[7]</ref>, parameterized such that the mean corresponds to a context-specific offset from the anchor state, with the associated covariance capturing the unimodal aleatoric uncertainty <ref type="bibr" target="#b7">[8]</ref>. <ref type="figure" target="#fig_0">Fig. 1</ref> illustrates a typical scenario where there are 3 likely intents given the scene context, with control mean offset refinements respecting the road geometry, and control uncertainty intuitively growing over time.</p><p>Our trajectory anchors are modes found in our training data in state-sequence space via unsupervised learning. These anchors provide templates for coarse-granularity futures for an agent and might correspond to semantic concepts like "change lanes", or "slow down" (although to be clear, we don't use any semantic concepts in our modeling).</p><p>Our complete model predicts a Gaussian mixture model (GMM) at each time step, with the mixture weights (intent distribution) fixed over time. Given such a parametric distribution model, we can directly evaluate the likelihood of any future trajectory and also have a simple way to obtain a compact, diverse weighted set of trajectory samples: the MAP sample from each anchor-intent.</p><p>Our model contrasts with popular past approaches which either provide only a single MAP trajectory <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b10">11]</ref> or an unweighted set of samples via a generative model <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15]</ref>.</p><p>There are a number of downsides to sample-based methods when it comes to real-world applications such as self-driving vehicles: (1) non-determinism in a safety critical system, (2) a poor handle on approximation error (e.g,. "how many samples must I draw to know the chance the pedestrian will jaywalk?"), (3) no easy way to perform probabilistic inference for relevant queries, such as computing expectations over a spacetime region.</p><p>We demonstrate empirically that our model emits distributions which predict the observed outcomes better on synthetic and real-world prediction datasets: we achieve higher likelihood than a model which emits unimodal parametric distributions, showing the importance of multiple anchors in real-world data. We also compare to sampling-based methods by using our weighted set of MAP trajectories per anchor, which describe the future better with far fewer samples on sample-set metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>We broadly categorize previous approaches to predicting future trajectory distributions into two classes of models: deterministic and stochastic. Deterministic models predict a single most-likely trajectory per agent, usually via supervised regression <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b15">16]</ref>.</p><p>Stochastic models incorporate random sampling during training and inference to capture future non-determinism. The seminal motion forecasting work of Kitani et al. <ref type="bibr" target="#b13">[14]</ref> cast this as a Markov decision process and learns a 1-step policy, as does follow on work focusing on egocentric video and pedestrians <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b16">17]</ref>. To encourage sample diversity and coverage, R2P2 <ref type="bibr" target="#b3">[4]</ref> proposes a symmetric KL loss between the predicted and data distributions. Several works explore the use of conditional variational autoencoders (CVAEs) and GANs to generate samples <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19]</ref>. One drawback of such non-deterministic approaches is that they can make reproducing and analyzing results in a larger system difficult.</p><p>Like us, a few previous works directly model probability distributions, either parametric <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b19">20]</ref> or in the form of probabilistic state-space occupancy grids (POGs) <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b10">11]</ref>. While extremely flexible, POGs require state-space-dense storage to describe the distribution rather than just a few parameters, and it's not obvious how best to extract trajectory samples from POG space-time volumes.</p><p>Our method is influenced heavily by the concept of predefined anchors, which have a rich history in machine learning applications to handle multi-modal problems, starting with classic semi-parametric methods such as locally-weighted logistic regression, radial basis SVM and Gaussian Mixture Models <ref type="bibr" target="#b4">[5]</ref>. In the computer vision literature, they have been used effectively for detection <ref type="bibr" target="#b20">[21]</ref> and human-pose estimation <ref type="bibr" target="#b21">[22]</ref>. Like ours, these effective approaches predict the likelihood of anchors and also predict continuous refinements of state conditioned on these anchors (e.g. box corners, joint locations or vehicle positions).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>Given observations x in the form of past trajectories of all agents in a scene and possibly additional contextual information (e.g., lane semantics, traffic light states) , MultiPath seeks to provide (1) a parametric distribution over future trajectories s: p(s|x), and (2) a compact weighted set of explicit trajectories which summarizes this distribution well.</p><p>Let t denote a discrete time step, and let s t denote the state of an agent at time t, the future trajectory s = [s 1 , . . . , s T ] is a sequence of states from t = 1 to a fixed time horizon T . We also refer to a state in a trajectory as a waypoint.</p><p>We factorize the notion of uncertainty into independent quantities. Intent uncertainty models uncertainty about the agents' latent coarse-scale intent or desired goal. For example, in a driving context, uncertainty about which lane the agent is attempting to reach. Conditioned on intent, there is still control uncertainty, which describes the uncertainty over the sequence of states the agent will follow to satisfy its intent. Both intent and control uncertainty depend on the past observations of static and dynamic world context x.</p><p>We model a discrete set of intents as a set of K anchor trajectories A = {a k } K k=1 , where each anchor trajectory is a sequence of states: a k = [a k 1 , . . . , a k T ], assumed given for now. We model uncertainty over this discrete set of intents with a softmax distribution: π(a k |x)</p><formula xml:id="formula_0">= exp f k (x) i exp fi(x)) , where f k (x) : R d(x) → R is the output of a deep neural network.</formula><p>We make the simplifying assumption that uncertainty is unimodal given intent, and model control uncertainty as a Gaussian distribution dependent on each waypoint state of an anchor trajectory:</p><formula xml:id="formula_1">φ(s k</formula><p>To obtain a distribution over the entire state space, we marginalize over agent intent:</p><formula xml:id="formula_2">p(s|x) = K k=1 π(a k |x) T t=1 φ(s t |a k , x)<label>(2)</label></formula><p>Note that this yields a Gaussian Mixture Model distribution, with mixture weights fixed over all time steps. This is a natural choice to model both types of uncertainty: it has rich representational power, a closed-form partition function, and is also compact. It is easy to evaluate this distribution on a discretely sampled grid to obtain a probabilistic occupancy grid, more cheaply and with fewer parameters than a native occupancy grid formulation <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b10">11]</ref>.</p><p>Obtaining anchor trajectories. Our distribution is parameterized by anchor trajectories A. As noted by <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b4">5]</ref>, directly learning a mixture suffers from issues of mode collapse. As is common practice in other domains such as object detection <ref type="bibr" target="#b22">[23]</ref> and human pose estimation <ref type="bibr" target="#b21">[22]</ref>, we estimate our anchors a-priori before fixing them to learn the rest of our parameters. In practice, we used the k-means algorithm as a simple approximation to obtain A with the following squared distance between trajectories:</p><formula xml:id="formula_3">d(u, v) = T t ||M u u t − M v v t || 2 2 , where M u ,</formula><p>M v are affine transformation matrices which put trajectories into a canonical rotation-and translation-invariant agent-centric coordinate frame. In Sec. 4, on some datasets, k-means leads to highly redundant clusters due to prior distributions that are heavily skewed to a few common modes. To address this, we employ a simpler approach to obtain A by uniformly sampling trajectory space.</p><p>Learning. We train our model via imitation learning by fitting our parameters to maximize the log-likelihood of recorded driving trajectories. Let our data be of the form {(x m ,ŝ m )} M m=1 . We learn to predict distribution parameters π(a k |x), µ(x) k t and Σ(x) k t as outputs of a deep neural network parameterized by weights θ with the following negative log-likelihood loss built upon Equation 2:</p><formula xml:id="formula_4">(θ) = − M m=1 K k=1 1(k =k m ) log π(a k |x m ; θ) + T t=1 log N (s k t |a k t + µ k t , Σ k t ; x m ; θ) . (3)</formula><p>This is a time-sequence extension of standard GMM likelihood fitting <ref type="bibr" target="#b4">[5]</ref>. The notation 1(·) is the indicator function, andk m is the index of the anchor most closely matching the groundtruth trajectoryŝ m , measured as 2 -norm distance in state-sequence space. This hard-assignment of groundtruth anchors sidesteps the intractability of direct GMM likelihood fitting, avoids resorting to an expectation-maximization procedure, and gives practitioners control over the design of the anchors as they wish (see our choice below). One could also employ a soft-assignment to anchors (e.g., proportional to the distance of the anchor to the groundtruth trajectory), just as easily.</p><p>Inferring a diverse weighted set of test-time trajectories. Our model allows us to eschew standard sampling techniques at test time, and obtain a weighted set of K trajectories without any additional computation: we take the MAP trajectory estimates from each of our K anchor modes, and consider the distribution over anchors π(a k |x) the sample weights (i.e., importance sampling). When metrics and applications call for a set of top κ &lt; K trajectories for evaluation, we return the top κ according to these sample weights.</p><p>Input representation. We follow other recent approaches <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b10">11]</ref> and represent a history of dynamic and static scene context as a 3-dimensional array of data rendered from a top-down orthographic perspective. The first two dimensions represent spatial locations in the top-down image. The channels in the depth dimension hold static and time-varying (dynamic) content of a fixed number of previous time steps. Agent observations are rendered as orientated bounding box binary images, one channel for each time step. Other dynamic context such as traffic light state and static context of the road (lane connectivity and type, stop lines, speed limit, etc.) form additional channels. See Sec. 4 for further details, as the input content differs from dataset to dataset. An important benefit of using such a top-down representation is the simplicity of representing contextual information like the agents' spatial relationships to each other and semantic road information. In Sec. B.4, we empirically highlight its benefit towards behavior prediction.</p><p>Neural network details. As shown in <ref type="figure" target="#fig_0">Fig. 1</ref>, we designed a jointly-trained, two-stage architecture that first extracts a feature representation for the whole scene and then attends to each agent in the scene to make agent-specific trajectory predictions.</p><p>The first stage is fully convolutional to preserve spatial structure; it takes the 3D input representation described above and outputs a 3D feature map of the entire top-down scene. We opt to use ResNetbased architectures <ref type="bibr" target="#b23">[24]</ref> for this scene-level feature extractor. We employ depth-wise thinned-out networks for all experiments, and a different number of residual layers depending on the dataset. See Sec. B.2 for a speed-accuracy analysis of different ResNet setups.</p><p>The second phase extracts patches of size 11 × 11 centered on agents locations in this feature map. To be orientation invariant, the extracted features are also rotated to an agent-centric coordinate system via a differentiable bilinear warping. The efficacy of this type of heading-normalization is shown in Sec. B.3. The second agent-centric network then operates on a per-agent basis. It contains 4 convolutional layers with kernel size 3 and 8 or 16 depth channels. It produces K×T ×5 parameters describing bivariate Gaussian's per time step per anchor (parameterized by µ x , µ y , log σ x , log σ y and ρ; the last 3 parameters define the 2 × 2 covariance matrix Σ xy in the agent-centric x, y-coordinate space), as well as K softmax logits to represent π(a|x).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>This section presents empirical results on a number of prediction tasks. We consider the following methods in order to contrast to different aspects of MultiPath.</p><p>MultiPath µ [, Σ]. Our proposed method with multiple anchors, modeling offsets µ and control uncertainty covariances Σ. For some experiments, we keep Σ frozen, which reduces the maximumlikelihood loss to simple 2 -loss. However, we can no longer estimate likelihood p(s|x) without Σ and only report distance-based metrics.</p><formula xml:id="formula_5">Regression µ [, Σ].</formula><p>To verify our hypothesis that modeling multiple intents is important, we modified the MultiPath architecture to regress a single output trajectory. This is similar to <ref type="bibr" target="#b0">[1]</ref>'s output (but extended to include uncertainty).</p><p>Min-of-K <ref type="bibr" target="#b19">[20]</ref>. This method predicts K trajectories directly, without pre-defined anchors. The authors define an 2 -loss on the single trajectory (out of K) with minimum distance to the groundtruth trajectory. This is similar to our method, but with implicit anchors and evolving hard-assignment of anchors to groundtruth as training progresses. This representation has inherent ambiguity problems and can suffer from mode collapse. In our experiments below, we extend this method to also predict µ, Σ values at each waypoint to evaluate likelihood.</p><p>CVAE. The Conditional Variational Auto-Encoder is a standard implicit generative sampling model and has been successfully adapted to predict trajectory for autonomous driving in <ref type="bibr" target="#b2">[3]</ref>. We are interested in comparing its ability to generate a diverse set of samples compared to MultiPath's MAP trajectory per anchor-we hypothesize that MultiPath will have better coverage with the same number of trajectories due to its choice of anchors. For this baseline, we add a CVAE at the end of the second stage agent-centric feature extractor. The decoder and encoder have the same architecture: 4 fully-connected layers of 32 units each.</p><p>Linear. Following <ref type="bibr" target="#b24">[25]</ref>, we use a linear model on past states to establish how well a simple constant velocity model can perform. We fit past observed positions as a linear function of time:</p><p>x t = [αt + β, γt + δ] for t ≤ 0, and use these models to evaluate future positions x 1 , . . . , x T . We investigated using higher-order polynomials with worse results.</p><p>We implemented the single-trajectory regression, Min-of-K, and CVAE using the same input representation and a comparable model architecture in order to achieve a fair comparison. For benchmark datasets, we also report numbers taken from recent publications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Metrics</head><p>Different approaches use a variety of output representations; primary examples are single trajectory prediction <ref type="bibr" target="#b0">[1]</ref>, an unweighted set of trajectory samples <ref type="bibr" target="#b2">[3]</ref>, a distribution over trajectories (ours), or probabilistic occupancy grids <ref type="bibr" target="#b10">[11]</ref>. Each representation comes with its own salient metrics, making it difficult to compare across all methods. Letŝ =ŝ t=1...T be a groundtruth trajectory. We consider the following metrics:  <ref type="bibr" target="#b4">[5]</ref>. (e) Min-of K = 5 trajectories. This model is very sensitive to initial weights, and on 5 trials with 4 learning rates, collapsed to only 1 or 2 active modes only (2 are shown here). We initialized starting regression weights to be uniform random in a small region surrounding the t = 0 position, for a better chance of learning multiple unique modes.</p><p>Log-likelihood (LL). We report log p(ŝ|x) if the model admits evaluation of likelihood, as does MultiPath when all parameters are learned (see Eq. <ref type="formula" target="#formula_2">(2)</ref>). The metric is scaled down by a factor of 2 × T , where T is the number of time steps and 2 for the two spatial dimensions.</p><p>Distance-based. In this category are the commonly-used average displacement error (ADE) measures the displacement error against the closest trajectory in the set of size M , so that reasonable predictions that simply do not happen to be the logged groundtruth are not penalized. Note that there is also the minMSD M <ref type="bibr" target="#b3">[4]</ref>, which is similar but the average is calculated on squared distances instead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Toy experiment: 3-way intersection</head><p>We first explore a simple proof-of-concept dataset generated based on our modeling assumptions. We generate synthetic 3-way intersections, with the probability of choosing the left, the middle or the right path set a priori to be the intent uncertainty distribution {0.3, 0.5, 0.2}. To emphasize the flexibility of our single-trajectory control uncertainty modeling, each path is generated by sampling parameterized sine waves: y = sin(ωt + φ), where the frequency ω ∼ U(0, 2) and phase shift φ ∼ U(−π, π). As shown in <ref type="figure" target="#fig_2">Figure 2</ref>, MultiPath is able to fit the underlying distribution correctly, recovering the intent uncertainty, and reaching approximately Bayes-optimal likelihood, while other methods fare worse.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Behavior prediction for autonomous driving.</head><p>To verify the performance of the proposed system, we collected a large dataset of real-world driving scenes from several cities in North America. Data is captured by a vehicle equipped with cameras, lidar and radar. As in <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b5">6]</ref>, we assume that an industry-grade perception system provides sufficiently accurate poses and tracks for all nearby agents, including vehicles, pedestrians, and cyclists. In our experiments, we treat the sensing vehicle as an additional agent, indistinguishable from any other agent in the scene. Most of the collected vehicle trajectories are either stationary or moving straight at a constant speed. Neither case is particularly interesting from a behavior prediction point of view. To address this and other dataset skew, we partitioned the space of future trajectories via a uniform, 2D grid over constant curvatures and distances, and performed stratified sampling such that the number of examples in each partition was capped to be at most 5% of the resulting dataset. The balanced dataset totals 3.85 million examples, contains 5.75 million agent trajectories and constitutes approximately 200 hours of driving.</p><p>The top-down rendered input tensor for this data has a resolution of 400 px × 400 px and corresponds to 80 m × 80 m in real-world coordinates. We sample time steps every 0.2 s (5 Hz). The following features are stacked in the depth dimension: 3 channels of color-coded road semantics, 1 channel  of distance-to-road-edge map, 1 channel encoding the speed limit, 5 channels encoding the traffic light states over the past 5 time steps (=1 second), and 5 channels each showing vehicles' top-down orthographic projection for each of the past 5 time steps. This results in 15 input channels in total. We predict trajectories up to 30 frames / 6 seconds into the future. The number of anchors K is set to 16 for MultiPath µ, Σ and 64 for MultiPath µ. The scene-level network is a ResNet50 <ref type="bibr" target="#b23">[24]</ref> with a depth multiplier of 25%, followed by a depth-to-space operation that restores some of the lost spatial resolution in the ResNet back to 200 × 200. Finally, we train the model end-to-end for 500k steps at a batch size of 32, with a learning rate warm-up phase and a cosine learning rate decay Experimental results are shown in Tab. 1. MultiPath outperforms the baselines in all metrics. With respect to the log-likelihood, we have observed the most log-likelihood measurements for this task to fall between 3 to 4.2 nats, so the gain of roughly 0.2 nat by MultiPath compared to the regression baseline is quite significant. See Sec. A for in-depth analyses of these results. 16 anchors are used for MultiPath µ, Σ, while 64 was the best K for MultiPath µ. An analysis of the effect of the number of anchors K is in Sec. B.1, while the figures in Sec. C visualize the anchors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Stanford Drone</head><p>The Stanford Drone Dataset <ref type="bibr" target="#b27">[28]</ref> consists of top-down, near-orthographic videos of college campus scenes, collected by drones, containing interacting pedestrians, cyclists and vehicles. The RGB camera frames provide context similar to a rendered road semantics in the driving vehicle environment, and  1.14 R2P2-MA <ref type="bibr" target="#b3">[4]</ref> 0.77 ESP <ref type="bibr" target="#b17">[18]</ref> 0.68 MultiPath µ, Σ 0.69 we treat it as such. We use the most common settings in the literature: sampling at 2.5 Hz, and predicting 4.8 seconds (12 frames) into the future, using 2 seconds of history (5 frames). Additional experimental details are in Sec. D.</p><p>As shown in Tab. 2, we perform at or better than state-of-the-art in best single-trajectory distance metrics. Notably, CAR-Net <ref type="bibr" target="#b8">[9]</ref> outperforms our comparable single-trajectory model; their method focuses on a sophisticated attention and sequential architecture tuned to get the best single-trajectory distance metric performance. Interestingly, our single-trajectory model performs better when trained to predict uncertainty as well, a potential benefit of modeling uncertainty discussed in <ref type="bibr" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">CARLA</head><p>We evaluate MultiPath on the publicly available multi-agent trajectory forecasting and planning dataset generated using the CARLA <ref type="bibr" target="#b28">[29]</ref> simulator by <ref type="bibr" target="#b17">[18]</ref>. Experimental details are in Sec. E. Tab. 3 reproduces results reported by <ref type="bibr" target="#b17">[18]</ref> for the DESIRE <ref type="bibr" target="#b2">[3]</ref>, SocialGAN <ref type="bibr" target="#b18">[19]</ref>, R2P2-MA <ref type="bibr" target="#b3">[4]</ref>, and the PRECOG-ESP <ref type="bibr" target="#b17">[18]</ref> methods and compares the performance of MultiPath against them. We report the minMSD metric with the top K = 12 predictions as defined in <ref type="bibr" target="#b17">[18]</ref> to report our evaluation results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We have introduced MultiPath, a model which predicts parametric distributions of future trajectories for agents in real-world settings. Through synthetic and real-world datasets, we have shown the benefits of MultiPath over previous single-trajectory and stochastic models in achieving likelihood and trajectory-set metrics and needing only 1 feed-forward inference pass.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A In-depth analysis</head><p>We provide a more detailed analysis of Tab. 1. The results are strictly different representations of the same experiments, all evaluated on the autonomous driving dataset, as described in Sec. 4.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Group by groundtruth final waypoint</head><p>Statistically, most vehicles we observe are parked (stationary) or going straight. Neither case is particularly interesting since a trivial solution such as the linear fitting is probably good enough to solve them. In this exercise, we split the evaluation samples into seven disjoint categories according to the location of the final waypoint at 6 seconds: 1) Stationary, agents that have moved less than 4 meters; 2) Slow, agents that moved farther than 4 meters but less than 8 meters; 3) Straight, agents that moved farther than 8 meters and the final waypoint is within ±5 • with respect of the initial heading; 4) Slight left (SLeft), farther than 8 meters and between −5 • and −30 • ; 5) Left, farther than 8 meters and larger than −30 • ; 6) Slight right (SRight), same as SLeft, but in the other direction; 7) Right, same as Left, but in the other direction.</p><p>Results are shown in <ref type="figure" target="#fig_4">Fig. 4</ref>. In <ref type="figure" target="#fig_4">Fig. 4a</ref>, we compare MultiPath µ, Σ against the regression baseline µ, Σ on the log-likelihood metric. As expected, the baseline performs reasonably well in the Stationary and Slow categories but is unable to model faster trajectories, where MultiPath outperforms the baseline decisively. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Group by time step</head><p>We look at the distance-based errors as the function of the predicted time step up to 6 seconds in <ref type="figure" target="#fig_5">Fig. 5</ref>. This error is usually expected to grow linearly in time. However, our curves are slightly super-linear, most likely caused by the natural distribution of heading-normalized trajectories, where the acceleration in both heading and speed is smooth. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Hyperparameters</head><p>There are numerous moving parts of the proposed model. In this section, we conducted extensive experiments on the choice of key hyperparameters, discuss the sensitivity of the model with respect to these parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Number of anchors K</head><p>One of the key hyperparameters of MultiPath is the choice of the number of anchors K, as it is always the case with methods that rely on unsupervised clustering. To this end, we trained several MultiPath µ, Σ and MultiPath µ models with different Ks, the results are shown in <ref type="figure" target="#fig_6">Fig. 6</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Backbone network sensitivity</head><p>We run the MultiPath µ, Σ model using 4 ResNet <ref type="bibr" target="#b23">[24]</ref> backbones of various complexity: ResNet8_thin, ResNet18_thin, ResNet50_thin, ResNet50. The backbones denoted with em thin are using a depth multiplier of 25%. The results are shown in <ref type="figure">Fig. 7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 Importance of heading normalization</head><p>The heading of a vehicle is a valuable signal, especially since cars cannot move in arbitrary directions. In Sec. 4.3, we assumed that the heading of the agents is given, alongside the positions and sizes of them over the past 1 second. We then crop the agent-specific feature map while compensating for the heading, so that the heading of the agent points to the same direction after the crop. In <ref type="figure">Fig. 8</ref>, we show the importance of this heading normalization.  <ref type="figure">Figure 8</ref>: Impact of heading normalization on three metrics. Having the heading compensated during agent-centric feature crop is beneficial throughout.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4 Road semantic information and traffic lights</head><p>One main benefit of using a rasterized top-down input representation is the simplicity to encode spatial information such as semantic road information and traffic lights, which are crucial for human driving. To validate that MultiPath also considers this contextual information, we trained ablation models by stripping the road information and traffic lights from the input. Results are shown in Tab. 4. The gain of including the contextual information is significant in all distance-based metrics. Interestingly, the gain is less apparent in the log-likelihood. We believe this is due to the fact that the context is mostly useful to prevent false positive trajectories, which has a smaller impact on the log-likelihood. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Visualization of all anchors</head><p>The anchors for the autonomous driving dataset for the various number of anchors K are shown in <ref type="figure" target="#fig_7">Fig. 9</ref>. Since the data is captured in North America, left turns are expected to have a larger curvature than right turns, and u-turns mostly are on the left side. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Stanford Drone Dataset experimental details</head><p>Unlike much of the past literature, we do not encode the raw location information directly. In keeping with our top-down rendered representation as detailed in Sec. 3, we render a history of oriented boxes as input channels concatenated with the current RGB video frame. Oriented boxes are estimated via past positions plus fixed-size extents. For consistent processing, we resize and pad videos to have a resolution of 800 px × 800 px, maintaining the original aspect ratio, but report results at the original resolution.</p><p>Due to the small size of the dataset and lack of heading information, we created our anchor set for this dataset by enumeration rather than K-means: we chose 64 straight-trajectory anchors via 16 evenly-spaced orientations at 4 different final-waypoint distances (roughly 5%, 10%, 15% and 20% of the max image dimension), and 1 stationary anchor. Due to the complexity of natural image (RGB) input, we chose a higher-capacity feature processing backbone than other datasets: 28-layer ResNet, each layer of depth 32. This proved beneficial over our default choice in Sec. 4.3, and we did no other architecture search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E CARLA experimental details</head><p>This dataset contains 60, 701 training, 7, 586 validation and 7, 567 test scenes from Town01 and 16, 960 test scenes from Town02. Each scene contains the autopilot's LIDAR observation together with 2 seconds of past and 4 seconds of future position information for the autopilot and 4 other agents at 5Hz. To allow comparison to the numbers reported in <ref type="bibr" target="#b17">[18]</ref>, we follow their training data setup: we use a 100 × 100 pixel crop of the top-down images, and only use the two LIDAR channels that represent a 2-bin histogram of points above and at ground-level in 0.5 m × 0.5 m cells.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>MultiPath estimates the distribution over future trajectories per agent in a scene, as follows: 1) Based on a top-down scene representation, the Scene CNN extracts mid-level features that encode the state of individual agents and their interactions. 2) For each agent in the scene, we crop an agent-centric view of the mid-level feature representation and predict the probabilities over the fixed set of K predefined anchor trajectories. 3) For each anchor, the model regresses offsets from the anchor states and uncertainty distributions for each future time step.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>8 ! 2 Figure 2 :</head><label>822</label><figDesc>p (a 1 | x) = 0.29 ! p (a 2 | x) = 0.51 ! p (a 3 | x) = 0.Results on the 3-way intersection toy example. Due to large dynamic range, uncertainties shown with jet colormap are scaled per-plot per-timestep, and not directly comparable. (a) Samples drawn from the data generation procedure, with groundtruth paths shown as blue lines. (b) MultiPath with K = 3 anchors correctly learns the intent and uncertainty distributions, achieving high likelihood. The anchors (light gray) were estimated by averaging 10 5 samples. (c) Single-trajectory modeling predicts a mean over all paths with corresponding location uncertainty which grows as paths diverge. (d) CVAE samples with a Kernel Density Estimate distribution fit</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>ŝ t − s * t 2</head><label>2</label><figDesc>and final displacement error (FDE) ŝ T − s * T 2 , where s * is the most-likely within a weighted set. For evaluating a set of trajectories, minADE M min sm 1 T T t=1 ŝ t − s m,t 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>MultiPath example results. We show in one column the result for one agent (focused agent) in a scene. Top: Logged trajectories of all agents are displayed in cyan. The focused agent is highlighted by a red circle. Bottom: MultiPath showing up to 5 trajectories with uncertainty ellipses. Trajectory probabilities (softmax outputs) are encoded in a color map shown to the right. MultiPath can predict uncertain future trajectories for various speed (1st column), different intent at intersections (2nd and 3rd columns) and lane changes (4th and 5th columns), where the regression baseline only predicts a single intent.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Detailed results grouped by the groundtruth final waypoint. (a): Detailed comparison between MultiPath µ, Σ and the regression µ, Σ baseline on the log-likelihood. (b): Detailed comparison between MultiPath µ and the regression µ baseline on the ADE. Detailed comparison between MultiPath µ and the CVAE baseline on the meanADE. The top 5 trajectories are kept for MultiPath, and 100000 trajectories are sampled from the CVAE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Detailed results from MultiPath µ grouped by time step on the ADE and minADE 5 metrics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Results as function of the number of clusters K. (a): MultiPath µ, Σ on the log-likelihood metric with K ranging from 1 to 64. (b): MultiPath µ on the ADE and minADE 5 metrics, with K ranging from 1 to 128.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 :</head><label>9</label><figDesc>Visualization of trajectories and their clusters. (a): 20k randomly sampled trajectories. (b) -(g): Anchors for a variety of K values.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Comparison of MultiPath on a large autonomous driving dataset. Brackets appear for cells where a metric expects a set of future trajectories but the method only produces one. All experiments (except for linear) were repeated 5 times with random initialization to produce the mean and standard deviation values. LL is the log-likelihood. ADE is the average distance error. minADEM is the top-M average distance error given M trajectory predictions. One out of five CVAE runs degenerated. CVAE includes all 5 runs, while CVAE select excludes the degenerated run. A more detailed analysis is in Sec. A.</figDesc><table><row><cell>Method</cell><cell>LL ↑</cell><cell>ADE ↓</cell><cell cols="3">minADE 5 ↓ minADE 10 ↓ minADE 15 ↓</cell></row><row><cell>Linear</cell><cell>-</cell><cell>3.26</cell><cell>(3.26)</cell><cell>(3.26)</cell><cell>(3.26)</cell></row><row><cell>Regression µ</cell><cell>-</cell><cell>1.17±0.01</cell><cell>(1.17±0.01 )</cell><cell>(1.17±0.01 )</cell><cell>(1.17±0.01 )</cell></row><row><cell>Regression µ, Σ</cell><cell cols="2">3.64±0.01 1.41± 0.02</cell><cell>(1.41± 0.02)</cell><cell>(1.41± 0.02 )</cell><cell>(1.41± 0.02 )</cell></row><row><cell>CVAE</cell><cell>-</cell><cell>2.16±2.15</cell><cell>1.82±2.35</cell><cell>1.74±2.39</cell><cell>1.71±2.41</cell></row><row><cell>CVAE select</cell><cell>-</cell><cell>1.20±0.03</cell><cell>0.77±0.03</cell><cell>0.67±0.03</cell><cell>0.63±0.03</cell></row><row><cell>Min-Of-K µ [20]</cell><cell>-</cell><cell>1.37±0.02</cell><cell>0.87±0.02</cell><cell>0.86±0.02</cell><cell>0.86±0.02</cell></row><row><cell>Min-Of-K µ, Σ [20]</cell><cell cols="2">4.26±0.04 1.23± 0.02</cell><cell>0.70± 0.01</cell><cell>0.70± 0.01</cell><cell>0.70± 0.01</cell></row><row><cell>MultiPath µ (ours)</cell><cell>-</cell><cell>1.17±0.00</cell><cell>0.58±0.00</cell><cell>0.48±0.00</cell><cell>0.46±0.00</cell></row><row><cell cols="3">MultiPath µ, Σ (ours) 4.37±0.00 1.25±0.01</cell><cell>0.63±0.00</cell><cell>0.61±0.00</cell><cell>0.61±0.00</cell></row><row><cell>GT</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Multi-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Path</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>(ours)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Comparison of MultiPath and baselines on the Stanford Drone Dataset (SDD). Distance measures are in terms of pixels in the original video resolution.MethodLL ↑ ADE ↓ FDE ↓ minADE 5 ↓</figDesc><table><row><cell>Linear</cell><cell>-</cell><cell>26.14</cell><cell>53.24</cell><cell>-</cell></row><row><cell>CVAE</cell><cell>-</cell><cell>30.91</cell><cell>61.40</cell><cell>26.29</cell></row><row><cell>Regression µ</cell><cell>-</cell><cell>27.44</cell><cell>56.44</cell><cell>-</cell></row><row><cell>Regression µ, Σ</cell><cell>3.06</cell><cell>26.67</cell><cell>54.34</cell><cell>-</cell></row><row><cell>MultiPath µ, Σ</cell><cell>3.52</cell><cell>28.32</cell><cell>58.38</cell><cell>17.51</cell></row><row><cell>DESIRE-SI-IT0 [3]</cell><cell>-</cell><cell>36.48</cell><cell>61.35</cell><cell>30.78</cell></row><row><cell>CAR-Net [9]</cell><cell>-</cell><cell>25.72</cell><cell>51.80</cell><cell>-</cell></row><row><cell>Social Forces [26]</cell><cell>-</cell><cell>36.48</cell><cell>58.14</cell><cell>-</cell></row><row><cell>Social LSTM [27]</cell><cell>-</cell><cell>31.19</cell><cell>56.97</cell><cell>-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Comparison of MultiPath and baselines on the CARLA Dataset. minMSD12 is the minimum mean-squared-distance computed on the top 12 predicted trajectories.</figDesc><table><row><cell cols="2">Town01 (5 agents) minMSD 12 ↓</cell><cell cols="2">Town02 (5 agents) minMSD 12 ↓</cell></row><row><cell>DESIRE [3]</cell><cell>2.60</cell><cell>DESIRE [3]</cell><cell>2.42</cell></row><row><cell>SocialGAN [19]</cell><cell>1.46</cell><cell>SocialGAN [19]</cell><cell></cell></row><row><cell>R2P2-MA [4]</cell><cell>0.84</cell><cell></cell><cell></cell></row><row><cell>ESP [18]</cell><cell>0.72</cell><cell></cell><cell></cell></row><row><cell>MultiPath µ, Σ</cell><cell>0.68</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Impact of including the semantic road information and traffic light context. MethodLog-likelihood ↑ ADE ↓ FDE ↓ minADE 5 ↓</figDesc><table><row><cell>With context µ, Σ</cell><cell>4.37</cell><cell>1.25</cell><cell>3.17</cell><cell>0.63</cell></row><row><cell>No context µ, Σ</cell><cell>4.32</cell><cell>1.45</cell><cell>3.83</cell><cell>0.68</cell></row><row><cell>With context µ</cell><cell>-</cell><cell>1.18</cell><cell>2.93</cell><cell>0.58</cell></row><row><cell>No context µ</cell><cell>-</cell><cell>1.44</cell><cell>3.71</cell><cell>0.73</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">t |a k , x) = N (s k t |a k t + µ k t (x), Σ k t (x))(1)The Gaussian parameters µ k t and Σ k t are directly predicted by our model as a function of x for each time-step of each anchor trajectory a k t . Note in the Gaussian distribution mean, a k t + µ k t , the µ k t represents a scene-specific offset from the anchor state a k t ; it can be thought of as modeling a scene-specific residual or error term on top of the prior anchor distribution. This allows the model to refine the static anchor trajectories to the current context, with variations coming from, e.g. specific road geometry, traffic light state, or interactions with other agents.The time-step distributions are assumed to be conditionally independent given an anchor, i.e., we write φ(s t |·) instead of φ(s t |·, s 1:t−1 ). This modeling assumption allows us to predict for all time steps jointly with a single inference pass, making our model simple to train and efficient to evaluate. If desired, it is straightforward to add a conditional next-time-step dependency to our model, using a recurrent structure (RNN).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We like to thank Anca Dragan, Stephane Ross and Wei Chai for their helpful comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Fast and Furious: Real time end-to-end 3D detection, tracking and motion forecasting with a single convolutional net</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">IntentNet: Learning to predict intention from raw sensor data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<editor>CoRL</editor>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">DESIRE: Distant future prediction in dynamic scenes with interacting agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vernaza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">B</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H S</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">R2P2: A reparameterized pushforward policy for diverse, precise generative path forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rhinehart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Kitani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vernaza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Pattern recognition and machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Rules of the Road: Predicting driving behavior with a convolutional model of semantic interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sapp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Philbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Probabilistic Robotics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Burgard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fox</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">What uncertainties do we need in Bayesian deep learning for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Car-net: Clairvoyant attentive recurrent network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Legros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Voisin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vesel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">You&apos;ll never walk alone: Modeling social behavior for multi-target tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pellegrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">ChauffeurNet: Learning to drive by imitating the best and synthesizing the worst</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ogale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">RSS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Generative modeling of multimodal multi-human behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ivanovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schmerling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pavone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In IROS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Accurate and diverse sampling of sequences based on a &quot;best of many&quot; sample objective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Activity forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Kitani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">D</forename><surname>Ziebart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Bagnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Forecasting interactive dynamics of pedestrians with fictitious play</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-A</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Kitani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Social force model for pedestrian dynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Helbing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Molnar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical review E</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">4282</biblScope>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">First-person activity forecasting with online inverse reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rhinehart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Kitani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">PRECOG: Prediction conditioned on goals in visual multi-agent settings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rhinehart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mcallister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kitani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.01296</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Social GAN: Socially acceptable trajectories with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Multimodal trajectory predictions for autonomous driving using deep convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Radosavljevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F.-C</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Djuric</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICRA</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Scalable object detection using deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Articulated human detection with flexible mixtures of parts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>PAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">SSD: Single shot MultiBbox detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">RED: A simple but effective baseline predictor for the TrajNet benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hug</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hubner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Who are you with and where are you going?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yamaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">E</forename><surname>Ortiz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR 2011</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">SocialLSTM: Human trajectory prediction in crowded spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Robicquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Forecasting social navigation in crowded complex scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Robicquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Anenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Doherty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1601.00998</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Codevilla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Carla</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.03938</idno>
		<title level="m">An open urban driving simulator</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
