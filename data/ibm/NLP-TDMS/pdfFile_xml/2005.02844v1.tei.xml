<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">TAGNN: Target Attentive Graph Neural Networks for Session-based Recommendation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Center for Research on Intelligent Perception and Computing</orgName>
								<orgName type="department" key="dep2">Institute of Automation</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Artificial Intelligence</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqiao</forename><surname>Zhu</surname></persName>
							<email>yanqiao.zhu@cripac.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Center for Research on Intelligent Perception and Computing</orgName>
								<orgName type="department" key="dep2">Institute of Automation</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Artificial Intelligence</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Liu</surname></persName>
							<email>qiang.liu@realai.ai</email>
							<affiliation key="aff2">
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Center for Research on Intelligent Perception and Computing</orgName>
								<orgName type="department" key="dep2">Institute of Automation</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Artificial Intelligence</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Center for Research on Intelligent Perception and Computing</orgName>
								<orgName type="department" key="dep2">Institute of Automation</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Artificial Intelligence</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tieniu</forename><surname>Tan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Center for Research on Intelligent Perception and Computing</orgName>
								<orgName type="department" key="dep2">Institute of Automation</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Artificial Intelligence</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Yu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqiao</forename><surname>Zhu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Wu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="laboratory">ACM Reference Format</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">TAGNN: Target Attentive Graph Neural Networks for Session-based Recommendation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/nnnnnnn.nnnnnnn</idno>
					<note>Tieniu Tan. 2020. TAGNN: Target Attentive Graph Neural Networks for Session-based Rec-ommendation. In Proceedings of International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR&apos;20). ACM, New York, NY, USA, 5 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T09:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Session-based recommendation</term>
					<term>graph neural networks</term>
					<term>target at- tention</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Session-based recommendation nowadays plays a vital role in many websites, which aims to predict users' actions based on anonymous sessions. There have emerged many studies that model a session as a sequence or a graph via investigating temporal transitions of items in a session. However, these methods compress a session into one fixed representation vector without considering the target items to be predicted. The fixed vector will restrict the representation ability of the recommender model, considering the diversity of target items and users' interests. In this paper, we propose a novel target attentive graph neural network (TAGNN) model for session-based recommendation. In TAGNN, target-aware attention adaptively activates different user interests with respect to varied target items. The learned interest representation vector varies with different target items, greatly improving the expressiveness of the model. Moreover, TAGNN harnesses the power of graph neural networks to capture rich item transitions in sessions. Comprehensive experiments conducted on real-world datasets demonstrate its superiority over state-of-the-art methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>previous work studies approaches that personalize the recommendation according to constantly recorded user profiles. In many real-world applications, however, such long-term profiles, even the users' identities may not exist. As an emerging method aiming to solve this problem, session-based recommendation predicts the next action (e.g., which item to click) of a user, given her previous behaviors within the ongoing session.</p><p>Considering the high practical values of session-based recommendation, many approaches have been proposed so far. Traditionally, Markov-chain-based methods <ref type="bibr" target="#b6">[7]</ref> predict the user's next action solely based on the previous action. Such a strong independence assumption suffers from noisy data and thus restricts its use in session-based recommendation scenarios. Recent trends in recommender systems have led to a proliferation of studies using deep neural network techniques. Models based on recurrent neural networks (RNNs) have achieved promising performance. For example, Hidasi et al. propose a RNN-based method GRU4Rec <ref type="bibr" target="#b0">[1]</ref> to model short-term preferences with gated recurrent units <ref type="bibr">(GRUs)</ref>. Recently, NARM <ref type="bibr" target="#b2">[3]</ref> proposes two RNN-based subsystems to capture users' local and global preference respectively. Similar to NARM, STAMP <ref type="bibr" target="#b4">[5]</ref> extracts users' potential interests using a simple multilayer perception model and an attentive network.</p><p>Despite their effectiveness, we would argue that those methods are still in their infancy. Previous work highlights that complex user behavioral patterns are of great significance for session-based recommendation <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b4">5]</ref>. However, these sequence-based methods only model sequential transitions between consecutive items, with complex transitions neglected. Take repeated purchases as an example, which is one of the most prominent behaviors in e-shopping scenarios. Suppose a session for a user is</p><formula xml:id="formula_0">s = v 1 → v 2 → v 1 → v 3 .</formula><p>Then, it is hard for these sequence-based methods to capture such a to-and-fro relationship between items. Specifically, they will be confused about the relationship between item v 1 and items (v 2 , v 3 ). In this paper, we propose to discover the complex transitional patterns underneath sessions through session graphs <ref type="bibr" target="#b9">[10]</ref>. By modeling items in sessions as session graphs, this natural means of encoding the abundant temporal patterns within sessions produces more accurate representation for each item.</p><p>Moreover, candidate items are usually abundant and users' interests are usually diverse. Previous work <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b9">10]</ref> represents one session using one embedding vector. That fixed-size vector represents all interests of a single user, which cannot express diverse user interests, and thereby limits the expressiveness of the recommender model. As a brute-force solution, we may consider enlarging the dimension of that fixed-length vector, which will in turn expose the arXiv:2005.02844v1 [cs.IR] 6 May 2020 risk of overfitting and deteriorate the model performance. However, we observe that it is not necessary to embed all user interests into one vector when making prediction for a specific candidate item. For example, suppose that a customer has a historical session of (swimming suits, purse, milk, frying pan). If we want to recommend a handbag for her, we focus on her interests in the purse rather than the frying pan. That is to say, the interests of a user with rich behaviors can be specifically activated given a target item <ref type="bibr" target="#b10">[11]</ref>. In this paper, we refine the proposed graph-based model through a novel target attention module. We term the resulting model as Target Attentive Graph Neural Networks for session-based recommendation, TAGNN 1 for brevity. The proposed target attention module aims to adaptively activate user interests by considering the relevance of historical behaviors given a target item. By introducing a local target attentive unit, specific user interests related to a target item in the current session are activated, which will benefit downstream session representations as a result. <ref type="figure">Figure 1</ref> gives an overview of the TAGNN method. We first construct session graphs using items in historical sessions. After that, we obtain corresponding embeddings using graph neural networks to capture complex item transitions based on session graphs. Given the item embeddings, we employ a target-aware attentive network to activate specific user interests with respect to a target item. Following that, we construct session embeddings. At last, for each session, we can infer the user's next action based on item embeddings and the session embedding.</p><p>The main contribution of this work is threefold. Firstly, we model items in sessions as session graphs to capture complex item transitions within sessions. Then, we employ graph neural networks to obtain item embeddings. Secondly, to adaptively activate users' diverse interests in sessions, we propose a novel target attentive network. The proposed target attentive module can reveal the relevance of historical actions given a certain target item, which further improves session representations. Finally, we conduct extensive experiments on real-world datasets. The empirical studies show that our method achieves state-of-the-art performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">THE PROPOSED METHOD: TAGNN 2.1 Problem Statement and Constructing Session Graphs</head><p>In session-based recommendation, an anonymous session can be represented by a list s = [v s,i ] s n i=1 ordered by timestamps and we de-</p><formula xml:id="formula_1">note V = {v i } m i=1</formula><p>as the set consisting of all unique items (e.g., user clicks) involved in sessions. Session-based recommendation aims to predict the next action v s,s n +1 given session s. Our model produces a ranking list of probabilities for all candidate items and items with top-k probability values will be selected for recommendation.</p><p>In our model, we represent each session s as a directed session  <ref type="figure">Figure 1</ref>: An overview of the proposed TAGNN method. Session graphs are constructed based on sessions at first. Then, graph neural networks capture rich item transitions in sessions. Last, from one session embedding vector, target-aware attention adaptively activates different user interests concerning varied target items to be predicted.</p><formula xml:id="formula_2">graph G s = (V s , E s , A s ), where V s , E s ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sessions Session Graph</head><formula xml:id="formula_3">sessions, where A (out) s and A (in)</formula><p>s represents weighted connections of outgoing and incoming edges respectively. Here we use the same strategy of constructing session graphs as SR-GNN <ref type="bibr" target="#b9">[10]</ref>. However, it is flexible to adopt different mechanisms of constructing the session graph for different session-based recommendation scenarios. For clarity, we omit subscript s for referring item embeddings hereafter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Learning Item Embeddings</head><p>After constructed session graphs, we transform every node v i ∈ V into a unified embedding space. The resulting vector v i ∈ R d is a ddimensional representation of item v i obtained using graph neural networks. Then, we can represent each session s using item embeddings. The graph neural network (GNN) <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b8">9]</ref> is a class of widely used deep learning models. GNNs generate node representations on top of graph topology, which models complex item connections. Therefore, they are particularly suitable for session-based recommendation. In this paper, we employ gated graph neural networks (GGNNs) <ref type="bibr" target="#b3">[4]</ref>, a variant of GNN, to learn the node vectors. Formally, for node v s,i of graph G s , its update rules are:</p><formula xml:id="formula_4">a (t ) s,i = A s,i: v (t −1) 1 , . . . , v (t −1) s n ⊤ H + b,<label>(1)</label></formula><formula xml:id="formula_5">z (t ) s,i = σ W z a (t ) s,i + U z v (t −1) i ,<label>(2)</label></formula><formula xml:id="formula_6">r (t ) s,i = σ W r a (t ) s,i + U r v (t −1) i ,<label>(3)</label></formula><formula xml:id="formula_7">v (t ) i = tanh W o a (t ) s,i + U o r (t ) s,i ⊙ v (t −1) i ,<label>(4)</label></formula><formula xml:id="formula_8">v (t ) i = 1 − z (t ) s,i ⊙ v (t −1) i + z (t ) s,i ⊙ v (t ) i ,<label>(5)</label></formula><p>where t is the training step, A s,i: ∈ R 1×2n is the i-th row in matrix </p><formula xml:id="formula_9">A s corresponding to node v s,i , H ∈ R d</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Constructing Target-Aware Embeddings</head><p>Previous work captures users' interests only using intra-session item representations. In our model, once we obtained the node vector for each item, we proceed to construct target embeddings, to adaptively consider the relevance of historical behaviors concerning target items. Here we define the target items as all candidate items to predict. Usually, a user's action given a recommended item only matches a part of her interests. To model this process, we design a novel target attention mechanism to calculate soft attention scores over all items in the session with respect to each target item.</p><p>In this section, we introduce a local target attentive module to calculate attention scores between all items v i in session s and each target item v t ∈ V . Firstly, a shared non-linear transformation parameterized by a weight matrix W ∈ R d ×d is applied to every node-target pair. Then, we normalize the self-attention scores using the softmax function:</p><formula xml:id="formula_10">β i,t = softmax(e i,t ) = exp v ⊤ t W v i m j=1 exp v ⊤ t W v j .<label>(6)</label></formula><p>Finally, for each session s, the users' interests towards a target item v t is represented by s t target ∈ R d , as given below:</p><formula xml:id="formula_11">s t target = s n i=1 β i,t v i .<label>(7)</label></formula><p>The obtained target embedding for representing users' interests varies with different target items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Generating Session Embeddings</head><p>In this section, we further exploit users' short-and long-term preference exhibited in the current session s using node representations involved in session s. The resulting two representations along with the user's target embedding will be further concatenated to generate better session embeddings.</p><p>Local embedding. As the user's final action is usually determined by her last action, we simply represent the user's short-term preference as a local embedding s local ∈ R d as the representation of the last-visited item v s,s n .</p><p>Global embedding. Then, we represent the user's long-term preference as a global embedding s global ∈ R d by aggregating all involved node vectors. We adopt another soft-attention mechanism to draw dependencies between the last-visited item and each item involved in the session:</p><formula xml:id="formula_12">α i = q ⊤ σ (W 1 v s n + W 2 v i + c),<label>(8)</label></formula><formula xml:id="formula_13">s global = s n i=1 α i v i ,<label>(9)</label></formula><p>where q, c ∈ R d and W 1 ,W 2 ∈ R d ×d are weight parameters.</p><p>Session embedding. Finally, we generate the session embedding s of session s by taking linear transformation over the concatenation of the local and global embeddings and the target embedding:</p><formula xml:id="formula_14">s t = W 3 [s t target ; s local ; s global ],<label>(10)</label></formula><p>where W 3 ∈ R d ×3d projects the three vectors into one embedding space R d . Please kindly note that we generate different session embeddings for each target item.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Making Recommendation</head><p>After obtaining all item embeddings and session embeddings, we compute the recommendation scoreẑ t for each target item v t ∈ V by taking inner-product of item embedding v t and session representation s. Following that, we use the softmax function over all unnormalized scores z for all target items and get the final output vector:ẑ</p><formula xml:id="formula_15">y = softmax (ẑ) .<label>(12)</label></formula><p>Hereŷ ∈ R m denotes the probabilities of nodes being the next action in s. The items with the top-k probabilities inŷ will be selected as recommended items. For training the model, we define the loss function as the crossentropy of the prediction and the ground truth:</p><formula xml:id="formula_16">L(ŷ) = − m i=1 y i log (ŷ i ) + (1 − y i ) log (1 −ŷ i ),<label>(13)</label></formula><p>where y denotes the one-hot encoding vector of the ground truth items. We use the back-propagation through time (BPTT) algorithm to train the proposed model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EXPERIMENTS</head><p>In this section, we aim to answer the following two questions:</p><p>RQ1. Does the proposed TAGNN achieve state-of-the-art performance compared with existing representative baseline algorithms?</p><p>RQ2. How do different schemes for representing user interests affect the model performance?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental Configurations</head><p>Datasets. We evaluate the proposed method using two widelyused real-world datasets Yoochoose 2 and Diginetica 3 , obtained from two contests in data mining conference RecSys 2015 and CIKM 2016 respectively. For fair comparison, we closely follow the same data preprocessing scheme as Li et al. <ref type="bibr" target="#b2">[3]</ref>, Liu et al. <ref type="bibr" target="#b4">[5]</ref>, Wu et al. <ref type="bibr" target="#b9">[10]</ref>. Specifically, we drop items appearing less than 5 times and sessions consisting of less than 2 items. For generating training and test sets, sessions of last days are used as the test set for Yoochoose, and sessions of last weeks as the test set for Diginetica. For an existing session s = [v s,1 , v s,2 , . . . , v s,s n ], we generate a series of input session sequences and corresponding labels as</p><formula xml:id="formula_17">([v s,1 ], v s,2 ), ([v s,1 , v s,2 ], v s,3 ), . . . , ([v s,1 , v s,2 , . . . , v s,s n−1 ]</formula><p>, v s,s n ). Since the Yoochoose dataset is too large, we only use its the most recent 1/64 fractions of the training sessions, denoted as Yoochoose 1/64. Baselines. To evaluate the performance of the proposed method, we comprehensively compare TAGNN with representative baselines. The traditional baselines include (a) frequency-based methods POP and S-POP, (b) similarity-based method Item-KNN <ref type="bibr" target="#b7">[8]</ref>, and (c) factorization-based methods Bayesian personalized ranking (BPR-MF) <ref type="bibr" target="#b5">[6]</ref> and factorizing personalized Markov chain model (FPMC) <ref type="bibr" target="#b6">[7]</ref>. We also consider deep learning baselines, including RNN-based recommender model GRU4REC <ref type="bibr" target="#b0">[1]</ref>, neural attentive recommender model (NARM) <ref type="bibr" target="#b3">[4]</ref>, short-term attention/memory priority model (STAMP) <ref type="bibr" target="#b4">[5]</ref>, and GNN-based recommender model SR-GNN <ref type="bibr" target="#b9">[10]</ref>.</p><p>Evaluation Metrics. We adopt two commonly-used metrics for evaluation, including Precision@20 and MRR@20. The former one evaluates the proportion of correct recommendation in an unranked list, while the latter one further considers the position of correct recommended items in a ranked list.</p><p>Hyperparameter Setup. Following previous methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b9">10]</ref>, we set d = 100 for hidden dimensionality in all experiments. We tune other hyperparameters based on a random 10% validation set. The initial learning rate for Adam is set to 0.001 and will decay by 0.1 after every 3 training epochs. The batch size is set to 100 for both datasets and the ℓ 2 penalty is set to 10 −5 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Comparison with Baseline Methods (RQ1)</head><p>To evaluate the performance of the proposed method, we firstly compare it with existing representative baselines (RQ1). The overall performance in terms of Precision@20 and MRR@20 is summarized in <ref type="table" target="#tab_2">Table 1</ref>, with the highest performance highlighted in boldface.</p><p>In all, TAGNN aggregates session items into session graphs and further considers modeling user preference through target-aware attention. It is apparent from the table that the proposed TAGNN model achieves state-of-the-art performance on all datasets in terms of Precision@20 and MRR@20, which confirms the effectiveness of the proposed method.</p><p>This table is quite revealing in several ways. Firstly, traditional methods including POP and S-POP achieve poor performance. They mainly emphasize items with high co-occurrence, which is oversimplified in session-based recommendation. Interestingly, the simple method Item-KNN still shows favorable performance, compared with POP, BPR-MF, and FPMC. Without knowing the sequential information, Item-KNN only recommends items with high similarity. This may be explained by the fact that latent factors representing user preference play a key role in generating accurate recommendation. It can also be seen that Item-KNN surpasses most Markov-chain-based methods, such as BPR-MF and FPMC, which demonstrates that modeling limited dependencies in session sequence is not realistic in session-based recommendation scenarios. Secondly, there is a clear trend that deep learning methods greatly outperform conventional models. These methods have a stronger capability to capture complex user behavior, leading to superior performance over traditional ones. Sequential models such as GRU4REC and NARM only considers single-way transitions between successive item. Compared with SR-GNN, which further models session as graphs and is able to capture more implicit connections between user clicks, these methods neglect complex item transitional patterns. However, the performance of these models is still inferior to that of the proposed method. TAGNN elaborates graph-based models by further considering user interests with target-aware attentions. This mechanism specifically activates diverse user interests given different target items, which improves the expressiveness of the recommender model. In summary, these results demonstrate the efficacy of the proposed TAGNN method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Ablation Studies (RQ2)</head><p>We conduct ablation studies on session embedding strategies in this section. We design 4 model variants to analyze how different representations for user preference affect the model performance (RQ2): (a) local embedding only (TAGNN-L), (b) global embedding using average pooling only (TAGNN-Avg), (c) attentive global embedding (TAGNN-Att), and (d) local embedding plus attentive global embedding (TAGNN-L+Att). <ref type="figure" target="#fig_0">Figure 2</ref> presents experimental results using different session representations.</p><p>It is apparent from this figure that the hybrid embedding strategy used by TAGNN achieves the best performance on all datasets, which verifies the necessity of explicitly incorporating target-aware attention for better representing user interests. Also, it is clear that the mixed use of attentive global embedding with local embedding outperforms other opponents, demonstrating the necessity to capture both long-and short-term preference exhibited within sessions. Please note that the performance of TAGNN-L, which merely uses the last item as the session representation stands out in this figure. It indicates that the last item has a great impact on a user's final action. Moreover, we can observe that using average pooling over items in session achieves bad performance. This phenomenon may be explained by the diversity of user behavior in the session, which further highlights the importance of using the proposed target-aware attention to capture diverse user interests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CONCLUSIONS</head><p>In this paper, we have developed a novel target attentive graph neural network model for session-based recommendation. By incorporating graph modeling and a target-aware attention module, the proposed TAGNN jointly considers user interests given a certain target item as well as complex item transitions in sessions. We have conducted thorough empirical evaluation to investigate TAGNN. Extensive experiments on real-world benchmark datasets demonstrate the effectiveness of our model.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>The performance of different session representations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>A s are the node set, the edge set, and the adjacency matrix, respectively. In this graph G s , each node represents an item v s,i ∈ V and each edge (v s,i−1 , v s,i ) ∈ E</figDesc><table><row><cell></cell><cell></cell><cell>Target</cell><cell>0.61</cell><cell>0.04</cell><cell>0.20</cell><cell>0.13</cell></row><row><cell></cell><cell>Attention Networks</cell><cell>Items</cell><cell></cell><cell></cell><cell>…</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Prediction Layer</cell></row><row><cell></cell><cell>Graph Neural Networks</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Linear Transformation</cell></row><row><cell>and A (in)</cell><cell>(out) s</cell><cell></cell><cell></cell><cell></cell></row></table><note>s represents a user visits item v s,i−1 and v s,i consecutively. Here we define A s as the concatenation of two adjacency matrices As to reflect the bidirectional relationship between items in1 Code available at https://github.com/CRIPAC-DIG/TAGNN</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>denotes element-wise multiplication. For each session graph G s , the GGNN model propagates information between neighboring nodes. The update and reset gate decides what information to be preserved and discarded respectively.</figDesc><table /><note>×2d and b ∈ R d are weight and bias parameter respectively, v(t −1) 1 , . . . , v(t −1) sn is the list of node vectors in session s, z s,i ∈ R d ×d and r s,i ∈ R d ×d are the reset and update gates respectively, σ (·) is the sigmoid function, and ⊙</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>The performance of TAGNN compared with other baseline methods using two datasets.</figDesc><table><row><cell>Method</cell><cell cols="4">Diginetica Precision@20 MRR@20 Precision@20 MRR@20 Yoochoose 1/64</cell></row><row><cell>POP S-POP Item-KNN BPR-MF FPMC GRU4REC NARM STAMP SR-GNN</cell><cell>0.89 21.06 35.75 5.24 26.53 29.45 49.70 45.64 50.73</cell><cell>0.20 13.68 11.57 1.98 6.95 8.33 16.17 14.32 17.59</cell><cell>6.71 30.44 51.60 31.31 45.62 60.64 68.32 68.74 70.57</cell><cell>1.65 18.35 21.81 12.08 15.01 22.89 28.63 29.67 30.94</cell></row><row><cell>TAGNN Improv.(%)</cell><cell>51.31 1.14</cell><cell>18.03 2.50</cell><cell>71.02 0.64</cell><cell>31.12 0.58</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">t = s ⊤ t v t ,(11)</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">http://2015.recsyschallenge.com/challenge.html 3 http://cikm2016.cs.iupui.edu/cikm-cup</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work is jointly supported by National Key Research and Development Program (2018YFB1402600, 2016YFB1001000) and National Natural Science Foundation of China (U19B2038, 61772528).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Session-based Recommendations with Recurrent Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balázs</forename><surname>Hidasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandros</forename><surname>Karatzoglou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Linas Baltrunas, and Domonkos Tikk</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Semi-Supervised Classification with Graph Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Neural Attentive Session-based Recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengjie</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhumin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaochun</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Lian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2017-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Gated Graph Sequence Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Tarlow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Brockschmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">STAMP: Short-Term Attention/Memory Priority Model for Session-based Recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifu</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Refuoe</forename><surname>Mokhosi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibin</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">BPR: Bayesian Personalized Ranking from Implicit Feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeno</forename><surname>Gantner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UAI</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Factorizing Personalized Markov Chains for Next-basket Recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Item-based Collaborative Filtering Recommendation Algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Badrul Munir Sarwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">A</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The Graph Neural Network Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franco</forename><surname>Scarselli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ah</forename><surname>Chung Tsoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Hagenbuchner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriele</forename><surname>Monfardini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE T-NN</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Session-based Recommendation with Graph Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuyuan</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqiao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tieniu</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep Interest Network for Click-Through Rate Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guorui</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqiang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengru</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanghui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junqi</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Gai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
