<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SUBMITTED TO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING 1 BASS Net: Band-Adaptive Spectral-Spatial Feature Learning Neural Network for Hyperspectral Image Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirban</forename><surname>Santara</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaustubh</forename><surname>Mani</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranoot</forename><surname>Hatwar</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankit</forename><surname>Singh</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Garg</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kirti</forename><surname>Padia</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pabitra</forename><surname>Mitra</surname></persName>
						</author>
						<title level="a" type="main">SUBMITTED TO IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING 1 BASS Net: Band-Adaptive Spectral-Spatial Feature Learning Neural Network for Hyperspectral Image Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T21:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Convolutional Neural Network (CNN)</term>
					<term>deep learning</term>
					<term>feature extraction</term>
					<term>hyperspectral imagery</term>
					<term>landcover classification</term>
					<term>pattern classification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep learning based landcover classification algorithms have recently been proposed in literature. In hyperspectral images (HSI) they face the challenges of large dimensionality, spatial variability of spectral signatures and scarcity of labeled data. In this article we propose an end-to-end deep learning architecture that extracts band specific spectral-spatial features and performs landcover classification. The architecture has fewer independent connection weights and thus requires lesser number of training data. The method is found to outperform the highest reported accuracies on popular hyperspectral image data sets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Hyperspectral imaging <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref> collects rich spectral information from a large number of densely-spaced contiguous frequency bands. It produces three dimensional (x, y, λ) data volumes, where x, y represent spatial dimensions and λ represents spectral dimension.</p><p>Hyperspectral image classification <ref type="bibr" target="#b2">[3]</ref> is the task of assigning a class label to every pixel. This paper studies landcover classification in hyperspectral images where the task is to predict the type of land-cover present in the location of each pixel. There are several challenges associated with hyperspectral data the most critical of which are as follows <ref type="bibr" target="#b3">[4]</ref>. <ref type="bibr" target="#b0">1</ref> Eucledian distance in the input space or a transformed space is used to find the k nearest training examples and a class is assigned on the basis of them. In <ref type="bibr" target="#b4">[5]</ref> and <ref type="bibr" target="#b5">[6]</ref> some modified versions of the k-NN algorithm have been proposed for HSI classification. Support Vector Machine (SVM) classifier is a maximum margin linear classifier <ref type="bibr" target="#b6">[7]</ref>. Melghani et al. <ref type="bibr" target="#b7">[8]</ref> introduced SVM Classifier for HSI classification. SVM based methods, in general, follow a two step approach. 1) Dimensionality reduction in order to address the problems of high spectral dimensionality and scarcity of labeled training examples. Some of the methods followed for dimensionality reduction are subspace projection <ref type="bibr" target="#b8">[9]</ref>, random feature selection <ref type="bibr" target="#b9">[10]</ref> and Kernel Local Fisher Discriminant Analysis <ref type="bibr" target="#b10">[11]</ref>. 2) Classification in the reduced dimensional space using SVM <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b11">[12]</ref>.</p><p>Li et al. <ref type="bibr" target="#b11">[12]</ref> propose local Fisher's Discriminant Analysis for dimensionality reduction and Gaussian Mixture Model (GMM) for classification. Mianji et al. <ref type="bibr" target="#b12">[13]</ref> propose Gaussian Non-linear Discriminant Analysis for dimensionality reduction and Relevance Vector Machine for classification. Samat et al. <ref type="bibr" target="#b13">[14]</ref> introduced Extreme Learning Machine (ELM) for HSI classification. ELM <ref type="bibr" target="#b14">[15]</ref> is a two layer artificial neural network in which the input to hidden weights are randomly chosen and the hidden to output weights are learned by minimizing a least squares objective function. In <ref type="bibr" target="#b5">[6]</ref> LBP is used to extract texture based local descriptors which are combined with global descriptors like Gabor and spectral features and fed into an ELM for classification. Lu et al. <ref type="bibr" target="#b15">[16]</ref> proposed a set-to-set distance based method for HSI classification.</p><p>Recently deep neural networks <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref> have been employed for landcover classification in HSI. Deep learning methods for HSI classification <ref type="bibr" target="#b18">[19]</ref> focus on spectral-spatial context modeling in order to address the problem of spatial variability of spectral signatures. They fall into two broad categories. The first category <ref type="bibr" target="#b19">[20]</ref>- <ref type="bibr" target="#b23">[24]</ref> follows a two-step procedure.</p><p>1) Dimensionality reduction and spectral-spatial feature learning using Autoencoder. Autoencoder <ref type="bibr" target="#b24">[25]</ref> is an artificial neural network architecture that learns to reconstruct the input vector at the output with minimum distortion after passing through a bottleneck. representation of the input vector that often encodes useful semantic information. 2) Classification using multi-class logistic regression. The second category of methods use Convolutional Neural Networks (CNN) <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b25">[26]</ref> for feature learning and classification in an end-to-end fashion. CNN uses extensive parameter-sharing to tackle the curse of dimensionality. Hu et al. <ref type="bibr" target="#b26">[27]</ref> introduced CNN for HSI classification. The proposed architecture is designed to learn abstract spectral signatures in a hierarchical fashion but does not take into account spatial context. In <ref type="bibr" target="#b27">[28]</ref> compressed spectral features from a local discriminant embedding method are concatenated with spatial features from a CNN and fed into a multi-class classifier. Yu et al. <ref type="bibr" target="#b28">[29]</ref> and Chen et al. <ref type="bibr" target="#b29">[30]</ref> propose end-to-end CNN architectures for spectral-spatial feature learning and classification. In <ref type="bibr" target="#b30">[31]</ref> the idea of classifying pixel-pair features using CNN is introduced to compensate for data scarcity. Also a voting strategy is proposed for test time to provide robustness in heterogeneous regions.</p><p>In this paper we present a deep neural network architecture that learns band-specific spectral-spatial features and gives state-of-the-art performance without any kind of data-set augmentation or input pre-processing. The architecture consists of three cascaded blocks. Block 1 takes a p × p × N c input volume (N c = number of spectral channels) and performs a preliminary feature transformation on the spectral axis. It splits the spectral channels into bands and feeds to Block 2 where parallel neural networks are used to extract low and mid-level spectral-spatial features. The outputs of the parallel networks are fused by concatenation and fed into Block 3 which summarizes them to form a high-level representation of the input. This is eventually classified by logistic regression. Extensive use of convolutional layers and weight sharing among the parallel networks of Block 2 keeps the parameter budget and computational complexity low. Band-specific representation learning and fusion via concatenation in Block 2 makes the network discriminative towards spectral locality of low and mid level features. Experiments on benchmark hyperspectral image classification data sets show that the proposed network converges faster and gives superior classification performance than other deep learning based methods in literature. Our source code is publicly available on the Web 1 .</p><p>The contributions of this paper can be summarized as follows:</p><p>1) A novel end-to-end neural network architecture has been proposed that shows state-of-the-art performance on benchmark hyperspectral image classification data sets. The design is aimed at efficient band-specific feature learning keeping the number of parameters low. Section II gives a detailed description of the proposed architecture along with the design methodology followed. Experimental results are presented in Section III. Comparison with existing methods is also reported. Section IV concludes the paper with a summary of the proposed method and scope of future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. PROPOSED FRAMEWORK</head><p>The BASS Net architecture, shown in <ref type="figure" target="#fig_1">Figure 1</ref>, combines spectral and spatial information processing in a systematic way with a focus on efficient use of parameters. The input to the network is a pixel X i from the image with its p × p neigbourhood (for spatial context) in the form of a p × p × N c volume, where N c is the number of channels in the input image. The output is the predicted class labelŷ i for X i . The entire network is differentiable end-to-end and can be trained by backpropagation <ref type="bibr" target="#b31">[32]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Overview of architecture</head><p>The architecture is organized as three cascaded blocks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Block 1: Spectral feature selection and band partitioning:</head><p>Block 1 takes the input p × p × N c volume X i and performs the following operation.</p><formula xml:id="formula_0">{B 1 , B 2 , . . . , B n b } = Ψ(Φ(X i ), n b )<label>(1)</label></formula><p>Ψ(·, ·) is a function that takes as input a hyperspectral image volume X with N spectral channels and an integer n b . It splits X into n b non-overlapping adjacent bands</p><formula xml:id="formula_1">{B i } n b i=1 of equal bandwidth b, where b = N n b . {B 1 , B 2 , . . . , B n b } = Ψ(X, n b )<label>(2)</label></formula><p>Φ(·) is a function that applies a feature selection alogrithm along the spectral dimension of a p × p × N in hyperspectral image volume X and produces another p × p × N out output volume Y. Out of the many different possibilities for this function we have explored the identity function I(·) and 1 × 1 spatial convolution in this paper.</p><formula xml:id="formula_2">Let X = [X (i) ] Nin i=1</formula><p>and Y = [Y (j) ] Nout j=1 , i.e. let X i and Y j be the input and output channels along the spectral dimension. If Φ(·) be the identity function, then Y = Φ(X) = I(X) = X. If Φ(·) is implemented using 1 × 1 spatial convolution then it effectively performs the following operation.</p><formula xml:id="formula_3">Y j = Nin i=1 w ji X i<label>(3)</label></formula><p>∀j = 1, 2, . . . , N out . n b is a hyperparameter that can be tuned to improve performance on the validation set. The set of bands {B 1 , B 2 , . . . , B n b } are passed as input to Block 2. 2) Block 2: Band-specific spectral-spatial feature learning:</p><p>Block 2 applies n b parallel networks, one on each band. <ref type="table" target="#tab_2">Table I</ref> explores a variety of choices for these networks. Each convolutional and fully connected layer is followed by a ReLU (Rectified Linear Unit) layer <ref type="bibr" target="#b32">[33]</ref> which applies the following operation element-wise on the input volume.</p><formula xml:id="formula_4">y = ReLU (x) (4) = max(0, x)</formula><p>The outputs of the parallel networks are concatenated and fed into Block 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) Block 3: Summarization and classification:</head><p>Block 3 summarizes the concatenated outputs of the bandspecific networks of Block 2 by using a set of fully connected layers, each of which is followed by a ReLU layer. A Cway softmax layer does the final classification by calculating the conditional probabilities of the C output classes, p = [p 1 , p 2 , . . . , p C ] as:</p><formula xml:id="formula_5">p i = e zi C i=1 e zi<label>(5)</label></formula><p>where z = [z 1 , z 2 , . . . , z C ] is the input to the softmax layer. <ref type="table" target="#tab_2">Table I</ref> shows four different network configurations (1-4) and their validation accuracies on the Indian Pines data set (see Section III-A) in an attempt to demonstrate the effect of different architectural design choices on the performance of the network. Only weight layers have been shown to avoid clutter. In all the four configurations the parallel networks in Block 2 have identical architecture. The Block 2 row shows the architecture of one of the parallel networks. Each conv and f c layer (except the last one in Block 3) is followed by a ReLU layer. Cells with an asterisk (*) in the beginning mark the salient points of difference of the corresponding configuration from the one to the left of it. P S = ON/OF F indicates whether parameter-sharing is on/off among the networks of Block 2. conv xy − p, n represents a spatial convolutional layer with receptive field size of p × p and n output spectral-channels. conv λ − p, n represents a spectral convolutional layer with a spectral receptive field of size p and n output spatial-channels. Each convolutional layer, spatial or spectral, consists of a set of 3-dimensional filters, one corresponding to each output channel. Each filter in a conv xy − p, n layer has a spatial extent of p × p and extends throughout the entire spectral axis of the input volume ( <ref type="figure" target="#fig_0">Figure 2</ref>). On the other hand, a filter in a conv λ − p, n layer has a spectral extent of p and extends throughout the spatial extent of the input volume ( <ref type="figure" target="#fig_3">Figure 3</ref>). All convolutions used in our networks are "valid" which means there is no zero-padding of the input volume during convolution. As shown in <ref type="figure" target="#fig_0">Figures 2 and 3</ref>, if we have a A × B × C input volume then the output volumes of a conv xy − p, n layer and a conv λ − p, n layer with valid convolutions will respectively be (A − p + 1) × (B − p + 1) × n and n × 1 × (C − p + 1). f c − n denotes a fully-connected layer with n nodes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Architectures explored</head><p>Significance of different design choices are as follows.</p><p>1) Tying the parameters of the parallel networks in Block 2 yields an improvement of validation accuracy by at least 1% in all the four configurations. This confirms that reducing the number of free parameters through parameter sharing leads to better generalization by reducing chances of overfitting. 2) Configuration 2 is constructed by replacing the first fully connected layer in Block 2 of Configuration 1 with a couple of spectral convolution layers. Higher validation accuracy of Configuration 2 can be attributed to fewer parameters in Block 2 than Configuration 1.</p><p>3) Configuration 1 and 2 have Φ(·) = I(·). Configuration 3 is constructed by replacing I(·) in Block 1 of Configuration 2 with a 1 × 1 spatial convolution followed by ReLU . An improvement in validation accuracy is observed. This demonstrates the importance of a non-trivial spectral feature selection function. Such a function increases the discriminative power of the network by adding more parameters and non-linearity.</p><p>4) Configuration 4 is constructed by replacing the last fully connected layer in Block 2 of Configuration 3 with two spectral convolution layers and removing the first fully connected layer of Block 3. This construction improves the validation accuracy further by 1% with parameter sharing in Block 2 and 0.5% without. This shows that in the presence of a non-trivial spectral feature selection function in Block 1, reducing the number of parameters in Block 2 and 3 can help achieve better generalization by reducing overfitting. This also shows that adding more spectral convolution layers in Block 2 and reducing the number of fully connected layers in Block 3 leads to better performance.</p><p>We use Configuration 4 with input patch-size 3 × 3 and P S = ON in all the experiments of our comparative study in Sections III-D and III-E with some minor modifications for Salinas and U. Pavia data sets as listed below.</p><p>1) The 1 × 1 spatial covolution layer of Block 1 has 224 and 100 output channels for Salinas and U. Pavia respectively.</p><p>2) The number of parallel networks in Block 2, n b , is 14 and 5 for Salinas and U. Pavia respectively. 3) In case of Salinas data set, the last layer of Block 3 is f c − 16 as the number of output classes is 16.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Learning algorithm</head><p>The networks are trained by minimizing the cross-entropy loss function <ref type="bibr" target="#b17">[18]</ref>. If C be the total number of output classes, {X i , y i } N i=1 be the training set, P data (class = c|X) and P model (class = c|X), ∀c = 1, 2, . . . , C be the observed and model conditional distributions respectively then the cross entropy loss function, L ×−entropy is given by:</p><formula xml:id="formula_6">L ×−entropy = − N i=1 C c=1 P data (c|X i )log(P model (c|X i )) (6)</formula><p>In our data sets, the observed conditional distribution P data is a one-hot distribution i.e.</p><formula xml:id="formula_7">P data (class = i|X) = 1, if y = i 0, otherwise<label>(7)</label></formula><p>Hence the expression of cross-entropy loss function becomes:</p><formula xml:id="formula_8">L ×−entropy = − N i=1 log(P model (y i |X i ))<label>(8)</label></formula><p>Thus minimizing this expression is equivalent to maximizing the log-likelihood of the target labels given the inputs.</p><p>The Adam optimizer <ref type="bibr" target="#b33">[34]</ref> is used for making the parameter updates. It computes adaptive learning rates for each parameter. The base learning rate is set to 0.0005 and batch-size to 100. Dropout, with probability 0.5 is applied to the fully connected layers of Block 3. Dropout is an effective method of regularizing neural networks by preventing co-adaptation of features <ref type="bibr" target="#b34">[35]</ref>. Batchnorm <ref type="bibr" target="#b35">[36]</ref> is observed to degrade the performance of our network and hence is not used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. EXPERIMENTAL RESULTS</head><p>We first present the details of the data set used; followed by the classification performances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. data sets</head><p>The experiments are performed on three popular hyperspectral image classification data sets 2 viz. Indian Pines, Salinas, and Pavia University scene (U. Pavia). Some classes in the Indian Pines data set have very few samples. We reject those classes and select the top 9 classes by population for experimentation. The problem of insufficient samples is less severe for Salinas and U. Pavia and all the classes are taken into account. 200 labeled pixels from each class are randomly picked to construct a training set. The rest of the labelled samples constitute the test set. A validation set is extracted from the available training set for tuning the hyperparameters of the model. As different frequency channels have different   dynamic ranges, their values are normalized to the range [0, 1] using the following formula.</p><formula xml:id="formula_9">f c − 500 f c − 500 f c − 500 f c − 100 f c − 100 f c − 100 f c − 100 f c − 9 f c − 9 f c − 9 f c −</formula><formula xml:id="formula_10">y = x − min(x) max(x)<label>(9)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Evaluation metrics</head><p>We evaluate the proposed architecture in terms of the following metrics.</p><p>1) Class-specific accuracy: Class specific accuracy for class C i is calculated as the fraction of samples from class C i which were correctly classified.</p><p>2) Overall accuracy: Overall accuracy is the ratio of the total number of correctly classified samples to the total number of samples of all classes.</p><p>3) Macro and micro-averaged precision, recall and Fscore: Let T P , T N , F N and F P denote respectively, the number of true positive, true negative, false negative and false positive samples. Then, P recision = T P T P + F P</p><formula xml:id="formula_11">Recall = T P T P + F N<label>(10)</label></formula><formula xml:id="formula_12">F − score = 2T P 2T P + F P + F N<label>(11)</label></formula><p>Let M (T P, F P, T N, F N ) be an evaluation metric, e.g. Precision, Recall, F-score. The macro and micro averaged values of the metric can be calculated as:</p><formula xml:id="formula_14">M micro = M ( N c=1 T P c , N c=1 F P c , N c=1 T N c , N c=1 F N c ) (13) M macro = 1 N N c=1 M (T P c , F P c , T N c , F N c )<label>(14)</label></formula><p>where N is the total number of output classes. A significantly lower value of the micro-average of a metric than the macro-average indicates that the less populated labels are correctly classified while the most populated labels have been grossly misclassified and vice versa <ref type="bibr" target="#b36">[37]</ref>. 4) κ score: The κ-score or κ-coefficient is a statistical measure of the degree of agreement among different evaluators <ref type="bibr" target="#b37">[38]</ref>. Suppose there are two evaluators that classify N items into C mutually exclusive classes. Then the κ-score is given by the following equation.</p><formula xml:id="formula_15">κ = p 0 − p e 1 − p e<label>(15)</label></formula><p>where p 0 is the relative observed probability of agreement and p e is the hypothetical probability of chance agreement. κ = 1 indicates complete agreement between the evaluators while κ ≤ 0 means there is no agreement at all.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Implementation platform</head><p>The networks are implemented in Torch 3 , a popular deep learning library written in Lua. The models are trained on a NVIDIA Tesla K20c GPU.   <ref type="figure">Figure 4</ref> shows test accuracies on Indian Pines for different choices of input patch-size. Increasing the patch-size gives more spatial context which results in marginally better accuracy of classification. However due to an increased number of parameters the model might tend to learn the data set-bias and fail to generalize to samples outside the image region from which the training and testing samples were extracted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Comparison of different hyperparameter settings</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Comparison with other methods</head><p>The test accuracies of the BASS Net architecture (BASS) on Indian Pines, Salinas and U. Pavia data sets are compared with other traditional and deep learning based classifiers  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Results and discussion</head><p>Tables III, IV and V show the results of the comparison of the proposed framework with traditional and deep learning based methods. The proposed framework outperforms all the other methods on all the three data sets in terms of Overall Accuracy (OA) of classification. For example, on Indian Pines, the test-accuracy of our network exceeds SVM, CNN and PPF by 6.94%, 10.33% and 2.43% respectively. <ref type="figure" target="#fig_8">Figure 7</ref> compares the variation of validation accuracy over epochs of training on Indian Pines. Our network converges faster than MLP and CNN. <ref type="table" target="#tab_2">Table VI</ref> gives micro and macro-averaged precision, recall and F-score and κ− scores for our models trained on the three data sets. High values of both macro and micro-averaged classification metrics viz. precision, recall and F-score suggest that the classifier is effective for both scarce and abundant classes. High values of κ-score for all the data sets show that the proposed classifier has high degree of agreeability with the ground truth generating mechanism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. CONCLUSION</head><p>In this paper an end-to-end deep learning neural network architecture has been proposed that performs band-specific spectral-spatial feature learning for superior modeling of spectral signatures. Curse of dimensionality and scarcity of labeled training examples are tackled by extensive parameter sharing in the network. Predictions are made on the basis of a p × p neighborhood around the target pixel in order to take care of large spatial variability of spectral signature in hyperspectral images. Experiments on benchmark hyperspectral image classification data sets show superior classification performance    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. ACKNOWLEDGEMENT</head><p>This study was performed as a part of the project titled "Deep Learning for Automated Feature Discovery in Hyperspectral Images (LDH)" sponsored by Space Applications Centre (SAC), Indian Space Research Organization (ISRO). Anirban Santara's work in this project was supported by Google India under the Google India PhD Fellowship Award.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>2 )</head><label>2</label><figDesc>Considerble improvement in training time is observed when compared to other popular deep learning 1 https://github.com/kaustubh0mani/BASS-Net architectures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Block diagram of the BASS Net architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Diagrammatic representation of convxy − p, n on a A × B × C input volume.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Diagrammatic representation of conv λ − p, n on a A × B × C input volume.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Block 2 f c − 150 n b = 10 *</head><label>215010</label><figDesc>conv λ − 3, 20 n b = 10 conv λ − 3, 20 n b = 10 conv λ − 3, 20 n b = 10 f c − 100 *conv λ − 3, 20 conv λ − 3, 20 *conv λ − 3, 20 f c − 100 f c − 100 *conv λ − 3, 10 conv λ − 5, 5 Concatenate the outputs of the parallel networks Block 3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figures 5 Fig. 4 .</head><label>54</label><figDesc>and 6 show the effect of changing the number of output channels of 1 × 1 spatial convolution in Block 1 and the number of networks in Block 2 of Configuration Variation of test accuracy on the Indian Pines data-set with input patch-size in Configuration 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 .</head><label>5</label><figDesc>Variation of validation accuracy on the Indian Pines data-set with the number of output channels in Block 1 in Configuration 4. 4 on validation accuracy on Indian Pines.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 6 .</head><label>6</label><figDesc>Variation of validation accuracy on the Indian Pines data-set with the number of parallel networks in Block 2 in Configuration 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 7 .</head><label>7</label><figDesc>Variation of validation error over epochs of training on Indian Pines data set for the proposed architecture and other popular deep neural networks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 8 .</head><label>8</label><figDesc>Thematic maps resulting from classification for the Indian Pines data set with 9 classes. (a) ground-truth map (b) decoded output from our model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 9 .</head><label>9</label><figDesc>Thematic maps resulting from classification for the Salinas data set with 16 classes. (a) ground-truth map (b) decoded output from our model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 10 .</head><label>10</label><figDesc>Thematic maps resulting from classification for the Pavia University Scene data set with 9 classes. (a) ground-truth map (b) decoded output from our model. and faster convergence than other popular deep learning based methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>) Curse of dimensionality resulting from large number of spectral dimensions. 2) Scarcity of labelled training examples. 3) Large spatial variability of spectral signature. Several approaches have been followed in literature for HSI classification. The simplest of them are based on k-nearest neighbors (k-NN). In these methods, given a test sample, * Denotes equal contribution. A. Santara and P. Mitra are with the Department of Computer Science and Engineering, Indian Institute of Technology, Kharagpur, WB, 721302 India (e-mail: anirban santara@iitkgp.ac.in, pabitra@cse.iitkgp.ernet.in) P. Hatwar and A. Singh are with the Department of Electrical Engineering, Indian Institute of Technology, Kharagpur, WB, 721302 India (e-mail: pphatwar1995@gmail.com, ankit.vngr@gmail.com) K. Mani is with the Department of Geology and Geophysics, Indian Institute of Technology, Kharagpur, WB, 721302 India (e-mail: kaus-tubh3095@gmail.com) A. Garg and K. Padia are with Space Applications Centre, Indian Space Research Organization (ISRO) Ahmedabad, GJ, 380015 India (e-mail: agarg@sac.isro.gov.in, kirtipadia@sac.isro.gov.in)</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE I COMPARISON</head><label>I</label><figDesc>OF DIFFERENT ARCHITECTURAL DESIGN CHOICES IN TERMS OF ACCURACY ON THE VALIDATION SPLIT OF THE INDIAN PINES DATA SET Split into n b bands along the λ-axis</figDesc><table><row><cell></cell><cell>Configuration 1</cell><cell>Configuration 2</cell><cell>Configuration 3</cell><cell>Configuration 4</cell></row><row><cell></cell><cell></cell><cell>Input volume: 3 × 3 × 220</cell><cell></cell><cell></cell></row><row><cell>Block 1</cell><cell>-</cell><cell>-</cell><cell>*convxy − 1, 220</cell><cell>convxy − 1, 220</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE III CLASS</head><label>III</label><figDesc>-SPECIFIC ACCURACY (%) AND OVERALL ACCURACY (OA) OF DIFFERENT TECHNIQUES FOR THE INDIAN PINES DATA SET</figDesc><table><row><cell>Class</cell><cell>k-NN</cell><cell>SVM</cell><cell>ELM</cell><cell>MLP</cell><cell>CNN</cell><cell>PPF</cell><cell>BASS</cell></row><row><cell>1</cell><cell>61.83</cell><cell>88.73</cell><cell>86.06</cell><cell>77.77</cell><cell>78.58</cell><cell>92.99</cell><cell>96.09</cell></row><row><cell>2</cell><cell>72.65</cell><cell>91.20</cell><cell>88.19</cell><cell>79.05</cell><cell>85.23</cell><cell>96.66</cell><cell>98.25</cell></row><row><cell>3</cell><cell>95.65</cell><cell>97.52</cell><cell>96.07</cell><cell>94.70</cell><cell>95.75</cell><cell>98.58</cell><cell>100</cell></row><row><cell>4</cell><cell>98.90</cell><cell>99.86</cell><cell>99.73</cell><cell>98.11</cell><cell>99.81</cell><cell>100</cell><cell>99.24</cell></row><row><cell>5</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>99.64</cell><cell>99.64</cell><cell>100</cell><cell>100</cell></row><row><cell>6</cell><cell>80.76</cell><cell>91.67</cell><cell>90.02</cell><cell>83.68</cell><cell>89.63</cell><cell>96.24</cell><cell>94.82</cell></row><row><cell>7</cell><cell>59.39</cell><cell>78.79</cell><cell>71.00</cell><cell>79.60</cell><cell>81.55</cell><cell>87.80</cell><cell>94.41</cell></row><row><cell>8</cell><cell>75.72</cell><cell>93.76</cell><cell>95.62</cell><cell>89.31</cell><cell>95.42</cell><cell>98.98</cell><cell>97.46</cell></row><row><cell>9</cell><cell>94.86</cell><cell>98.74</cell><cell>98.66</cell><cell>98.12</cell><cell>98.59</cell><cell>99.81</cell><cell>99.90</cell></row><row><cell>OA</cell><cell>76.24</cell><cell>89.83</cell><cell>87.33</cell><cell>85.48</cell><cell>86.44</cell><cell>94.34</cell><cell>96.77</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">TABLE IV</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="8">CLASS-SPECIFIC ACCURACY (%) AND OVERALL ACCURACY (OA) OF</cell></row><row><cell></cell><cell cols="6">DIFFERENT TECHNIQUES FOR THE SALINAS DATA SET</cell><cell></cell></row><row><cell>Class</cell><cell>k-NN</cell><cell>SVM</cell><cell>ELM</cell><cell>MLP</cell><cell>CNN</cell><cell>PPF</cell><cell>BASS</cell></row><row><cell>1</cell><cell>98.71</cell><cell>99.55</cell><cell>99.75</cell><cell>99.67</cell><cell>97.34</cell><cell>100</cell><cell>100</cell></row><row><cell>2</cell><cell>99.65</cell><cell>99.92</cell><cell>99.87</cell><cell>99.77</cell><cell>99.29</cell><cell>99.88</cell><cell>99.97</cell></row><row><cell>3</cell><cell>99.09</cell><cell>99.44</cell><cell>99.60</cell><cell>98.37</cell><cell>96.51</cell><cell>99.60</cell><cell>100</cell></row><row><cell>4</cell><cell>99.78</cell><cell>99.86</cell><cell>99.64</cell><cell>99.75</cell><cell>99.66</cell><cell>99.49</cell><cell>99.66</cell></row><row><cell>5</cell><cell>95.28</cell><cell>98.02</cell><cell>98.81</cell><cell>98.83</cell><cell>96.97</cell><cell>98.34</cell><cell>99.59</cell></row><row><cell>6</cell><cell>99.49</cell><cell>99.70</cell><cell>99.67</cell><cell>99.68</cell><cell>99.60</cell><cell>99.97</cell><cell>100</cell></row><row><cell>7</cell><cell>99.55</cell><cell>99.69</cell><cell>99.66</cell><cell>99.29</cell><cell>99.49</cell><cell>100</cell><cell>99.91</cell></row><row><cell>8</cell><cell>63.53</cell><cell>84.85</cell><cell>84.04</cell><cell>75.96</cell><cell>72.25</cell><cell>88.68</cell><cell>90.11</cell></row><row><cell>9</cell><cell>95.94</cell><cell>99.58</cell><cell>99.89</cell><cell>99.27</cell><cell>97.53</cell><cell>98.33</cell><cell>99.73</cell></row><row><cell>10</cell><cell>91.98</cell><cell>96.49</cell><cell>95.03</cell><cell>96.07</cell><cell>91.29</cell><cell>98.60</cell><cell>97.46</cell></row><row><cell>11</cell><cell>98.41</cell><cell>98.78</cell><cell>96.82</cell><cell>97.93</cell><cell>97.58</cell><cell>99.54</cell><cell>99.08</cell></row><row><cell>12</cell><cell>99.84</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>100</cell></row><row><cell>13</cell><cell>98.69</cell><cell>99.13</cell><cell>98.25</cell><cell>99.58</cell><cell>99.02</cell><cell>99.44</cell><cell>99.44</cell></row><row><cell>14</cell><cell>97.38</cell><cell>98.97</cell><cell>97.94</cell><cell>98.96</cell><cell>95.05</cell><cell>98.96</cell><cell>100</cell></row><row><cell>15</cell><cell>65.66</cell><cell>76.38</cell><cell>72.96</cell><cell>75.93</cell><cell>76.83</cell><cell>83.53</cell><cell>83.94</cell></row><row><cell>16</cell><cell>99.00</cell><cell>99.56</cell><cell>99.06</cell><cell>98.51</cell><cell>98.94</cell><cell>99.31</cell><cell>99.38</cell></row><row><cell>OA</cell><cell>86.29</cell><cell>93.15</cell><cell>92.42</cell><cell>90.78</cell><cell>89.28</cell><cell>94.80</cell><cell>95.36</cell></row><row><cell cols="8">in Tables III, IV and V. Among traditional classifiers k-</cell></row><row><cell cols="8">Nearest Neighbor (k-NN), Support Vector Machine (SVM)</cell></row><row><cell cols="8">with Random Feature Selection [10] and Extreme Learning</cell></row><row><cell cols="8">Machine (ELM) [6], [14] are compared. k-NN is implemented</cell></row><row><cell cols="8">in scikit learn 4 while SVM is implemented using libsvm 5 . An</cell></row><row><cell cols="8">implementation of ELM is downloaded from the Web Page 6 .</cell></row><row><cell cols="8">Among deep learning based classifiers, a N c -150-100-50-C</cell></row><row><cell cols="8">Multi-Layer Perceptron (MLP), the Convolutional Neural</cell></row><row><cell cols="8">Network (CNN) architecture of Hu et al. [27] and the</cell></row><row><cell cols="8">Convolutional Neural Network with Pixel-Pair Features (PPF)</cell></row><row><cell cols="8">of Li et al. [31] are implemented in Torch for comparison.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE V</head><label>V</label><figDesc>CLASS-SPECIFIC ACCURACY (%) AND OVERALL ACCURACY (OA) OF DIFFERENT TECHNIQUES FOR THE PAVIA UNIVERSITY SCENE DATA SET</figDesc><table><row><cell>Class</cell><cell>k-NN</cell><cell>SVM</cell><cell>ELM</cell><cell>MLP</cell><cell>CNN</cell><cell>PPF</cell><cell></cell><cell>BASS</cell></row><row><cell>1</cell><cell>77.70</cell><cell>87.95</cell><cell>81.32</cell><cell>91.73</cell><cell>88.38</cell><cell cols="2">97.42</cell><cell>97.71</cell></row><row><cell>2</cell><cell>75.30</cell><cell>91.17</cell><cell>90.91</cell><cell>94.79</cell><cell>91.27</cell><cell cols="2">95.76</cell><cell>97.93</cell></row><row><cell>3</cell><cell>77.27</cell><cell>86.99</cell><cell>85.09</cell><cell>85.41</cell><cell>85.88</cell><cell cols="2">94.05</cell><cell>94.95</cell></row><row><cell>4</cell><cell>92.46</cell><cell>95.50</cell><cell>96.61</cell><cell>94.13</cell><cell>97.24</cell><cell cols="2">97.52</cell><cell>97.80</cell></row><row><cell>5</cell><cell>99.63</cell><cell>99.85</cell><cell>99.63</cell><cell>99.65</cell><cell>99.91</cell><cell>100</cell><cell></cell><cell>100</cell></row><row><cell>6</cell><cell>79.50</cell><cell>94.31</cell><cell>94.33</cell><cell>90.87</cell><cell>96.41</cell><cell cols="2">99.13</cell><cell>96.60</cell></row><row><cell>7</cell><cell>92.86</cell><cell>94.74</cell><cell>95.94</cell><cell>92.56</cell><cell>93.62</cell><cell cols="2">96.19</cell><cell>98.14</cell></row><row><cell>8</cell><cell>76.45</cell><cell>85.89</cell><cell>82.65</cell><cell>83.19</cell><cell>87.45</cell><cell cols="2">93.62</cell><cell>95.46</cell></row><row><cell>9</cell><cell>99.62</cell><cell>99.89</cell><cell>99.79</cell><cell>99.73</cell><cell>99.57</cell><cell cols="2">99.60</cell><cell>100</cell></row><row><cell>OA</cell><cell>79.45</cell><cell>91.10</cell><cell>89.86</cell><cell>92.54</cell><cell>92.27</cell><cell cols="2">96.48</cell><cell>97.48</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">TABLE VI</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="6">CLASSIFICATION PERFORMANCE STATISTICS</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Indian Pines</cell><cell cols="2">Salinas</cell><cell cols="2">U. Pavia</cell></row><row><cell></cell><cell></cell><cell cols="2">precision</cell><cell>0.9677</cell><cell cols="2">0.9536</cell><cell></cell><cell>0.9748</cell></row><row><cell cols="2">micro-averaged</cell><cell cols="2">recall</cell><cell>0.9677</cell><cell cols="2">0.9536</cell><cell></cell><cell>0.9748</cell></row><row><cell></cell><cell></cell><cell cols="2">F-score</cell><cell>0.9677</cell><cell cols="2">0.9536</cell><cell></cell><cell>0.9748</cell></row><row><cell></cell><cell></cell><cell cols="2">precision</cell><cell>0.9713</cell><cell cols="2">0.9730</cell><cell></cell><cell>0.9680</cell></row><row><cell cols="2">macro-averaged</cell><cell cols="2">recall</cell><cell>0.9779</cell><cell cols="2">0.9802</cell><cell></cell><cell>0.9762</cell></row><row><cell></cell><cell></cell><cell cols="2">F-score</cell><cell>0.9745</cell><cell cols="2">0.9764</cell><cell></cell><cell>0.9719</cell></row><row><cell></cell><cell cols="2">κ-score</cell><cell></cell><cell>0.9612</cell><cell cols="2">0.9480</cell><cell></cell><cell>0.9662</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">http://www.ehu.eus/ccwintco/index.php?title=Hyperspectral Remote Sensing Scenes</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">http://torch.ch</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">http://scikit-learn.org 5 http://www.csie.ntu.edu.tw/ cjlin/libsvm/ 6 http://www.ntu.edu.sg/home/egbhuang/elm˙codes.html</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Hyperspectral image data analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Landgrebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Mag</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="17" to="28" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Remote Sensing Digital Image Analysis: An Introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Richards</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Springer</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Advances in hyperspectral image classification: Earth monitoring with statistical learning methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Camps-Valls</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tuia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bruzzone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1310.5107</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>cs.CV</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Kernel-based methods for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Camps-Valls</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bruzzone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1351" to="1362" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Nearest neighbor classification of remote sensing images with the maximal margin principle</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Blanzieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Melgani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1804" to="1811" />
			<date type="published" when="2008-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Collaborative-representation-based nearest neighbor classifier for hyperspectral imagery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geosci. Remote Sens. Lett</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="389" to="393" />
			<date type="published" when="2015-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A tutorial on support vector machines for pattern recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Burges</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="121" to="167" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Classification of hyperspectral remote sensing images with support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Melgani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lorenzo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1778" to="1790" />
			<date type="published" when="2004-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Subspace-based support vector machines for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geosci. Remote Sens. Lett</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="349" to="353" />
			<date type="published" when="2015-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Sensitivity of support vector machines to random feature selection in classification of hyperspectral data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Waske</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Van Der Linden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hostert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2880" to="2889" />
			<date type="published" when="2010-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Locality-preserving discriminant analysis in kernel-induced feature spaces for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Fowler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>Bruce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geosci. Remote Sens. Lett</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="894" to="898" />
			<date type="published" when="2011-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Locality-preserving dimensionality reduction and classification for hyperspectral image analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Fowler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>Bruce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1185" to="1198" />
			<date type="published" when="2012-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Robust hyperspectral classification using relevance vector machine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">A</forename><surname>Mianji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2100" to="2112" />
			<date type="published" when="2011-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">E 2 LMs: Ensemble extreme learning machines for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Samat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1060" to="1069" />
			<date type="published" when="2014-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Extreme learning machine: Theory and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q.-Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-K</forename><surname>Siew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="489" to="501" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Set-to-set distance-based spectral-spatial classification of hyperspectral images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bruzzone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="7122" to="7134" />
			<date type="published" when="2016-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="436" to="444" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Book in preparation for</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
	<note>Deep learning</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep learning for remote sensing data: A technical tutorial on the state of the art</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geosci. Remote Sens. Mag</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="22" to="40" />
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deep learning-based classification of hyperspectral data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2094" to="2107" />
			<date type="published" when="2014-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Hyperspectral image classification via contextual deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EURASIP J. Image Video Process</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Spectral-spatial classification of hyperspectral data based on deep belief network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2381" to="2392" />
			<date type="published" when="2015-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Saliency-guided unsupervised feature learning for scene classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2175" to="2184" />
			<date type="published" when="2015-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Spectral-spatial classification of hyperspectral image based on deep auto-encoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Geng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4073" to="4085" />
			<date type="published" when="2016-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Reducing the dimensionality of data with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="issue">5786</biblScope>
			<biblScope unit="page" from="504" to="507" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deep convolutional neural networks for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Sensors</title>
		<imprint>
			<biblScope unit="volume">2015</biblScope>
			<biblScope unit="page">258619</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Spectral-spatial feature extraction for hyperspectral image classification: A dimension reduction and deep learning approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="4544" to="4554" />
			<date type="published" when="2016-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deep feature extraction and classification of hyperspectral images based on convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ghamisi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="6232" to="6251" />
			<date type="published" when="2016-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Hyperspectral image classification using deep pixel-pair features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Geosci. Remote Sens</title>
		<imprint>
			<biblScope unit="issue">99</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2016-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Learning representations by back-propagating errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="page" from="533" to="536" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Deep sparse rectifier neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Conference on Artificial Intelligence and Statistics (AISTATS)</title>
		<meeting>the 14th International Conference on Artificial Intelligence and Statistics (AISTATS)</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Diederik Kingma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1310.5107</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>cs.CV</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Sergey Ioffe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03167</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>cs.LG</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A systematic analysis of performance measures for classification tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sokolova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lapalme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="427" to="437" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A coefficient of agreement for nominal scales</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Educational and Psychological Measurement</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="37" to="46" />
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
