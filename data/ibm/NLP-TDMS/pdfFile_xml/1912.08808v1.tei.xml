<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Bridging the Gap between Community and Node Representations: Graph Embedding via Community Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Artem</forename><surname>Lutov</surname></persName>
							<email>artem.lutov@unifr.ch</email>
							<affiliation key="aff0">
								<orgName type="institution">eXascale Infolab University of Fribourg</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dingqi</forename><surname>Yang</surname></persName>
							<email>dingqi.yang@unifr.ch</email>
							<affiliation key="aff1">
								<orgName type="institution">eXascale Infolab University of Fribourg</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Cudré-Mauroux</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">eXascale Infolab University of Fribourg</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Bridging the Gap between Community and Node Representations: Graph Embedding via Community Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T08:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Graph embedding has become a key component of many data mining and analysis systems. Current graph embedding approaches either sample a large number of node pairs from a graph to learn node embeddings via stochastic optimization or factorize a high-order node proximity/adjacency matrix via computationally intensive matrix factorization techniques. These approaches typically require significant resources for the learning process and rely on multiple parameters, which limits their applicability in practice. Moreover, most of the existing graph embedding techniques operate effectively in one specific metric space only (e.g., the one produced with cosine similarity), do not preserve higher-order structural features of the input graph and cannot automatically determine a meaningful number of dimensions for the embedding space. Typically, the produced embeddings are not easily interpretable, which complicates further analyses and limits their applicability. To address these issues, we propose DAOR, a highly efficient and parameter-free graph embedding technique producing metric space-robust, compact and interpretable embeddings without any manual tuning. Compared to a dozen state-of-the-art graph embedding algorithms, DAOR yields competitive results on both node classification (which benefits form high-order proximity) and link prediction (which relies on low-order proximity mostly). Unlike existing techniques, however, DAOR does not require any parameter tuning and improves the embeddings generation speed by several orders of magnitude. Our approach has hence the ambition to greatly simplify and speed up data analysis tasks involving graph representation learning.</p><p>Index Terms-parameter-free graph embedding, unsupervised learning of network representation, automatic feature extraction, interpretable embeddings, scalable graph embedding.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Representation learning has become a key paradigm to learn low-dimensional node representations from graphs. These automatically generated representations can be used as features to facilitate downstream graph analysis tasks such as node classification and link prediction. The main idea behind graph embedding techniques is to project graph nodes onto a lowdimensional vector space such that the key structural properties of the graph are preserved. The most commonly preserved property in this context is the proximity between nodes in the graph <ref type="bibr" target="#b0">[1]</ref>. For example, DeepWalk <ref type="bibr" target="#b1">[2]</ref> and Node2vec <ref type="bibr" target="#b2">[3]</ref> This project has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation program (grant agreement 683253/GraphInt).</p><p>preserve up-to-k-order node proximity by sampling random walk sequences from an input graph using a context window of a certain size; HOPE <ref type="bibr" target="#b3">[4]</ref> and NetMF <ref type="bibr" target="#b4">[5]</ref> capture high (up-toinfinite)-order node proximity by factorizing high-order node proximity matrices, measured by the Katz index <ref type="bibr" target="#b5">[6]</ref>, for example. The resulting embedding vectors from those techniques, capturing node proximity in graphs, are known to achieve good results on many downstream graph analysis tasks, such as node classification, node clustering (a.k.a. community detection) and link prediction.</p><p>Among various graph analysis applications, community detection is one of the most popular tasks. Network communities (i.e., node clusters or granules <ref type="bibr" target="#b6">[7]</ref>) represent groups of nodes that are densely connected inside each group and loosely connected between different groups <ref type="bibr" target="#b7">[8]</ref>. In essence, community detection techniques intrinsically capture node proximity in the graph to generate such node clusters. In the context of graph embeddings, community detection naturally implies that nodes in a cluster should be projected closer to each other than to the nodes from other clusters in the vector space. For example, DeepWalk <ref type="bibr" target="#b1">[2]</ref> performs node sampling using random walks, such that nodes from the same cluster (intra-cluster nodes) are linked tighter together than nodes from different clusters (inter-cluster nodes) and have a higher probability to be closer in random walk sequences. In the case of HOPE <ref type="bibr" target="#b3">[4]</ref>, the node proximity is defined by the Katz index <ref type="bibr" target="#b5">[6]</ref> that computes the weighted sum of all paths between two nodes. There, intracluster nodes also have a higher proximity measure than intercluster nodes, since there are more paths linking nodes in the same cluster than paths linking nodes between different clusters.</p><p>In this paper, by revisiting existing graph embedding techniques, we raise the following question: "Can we generate node embeddings from clusters produced via community detection? More precisely, we explore how to generate node embeddings in a graph leveraging the latest advances in community detection techniques, analyzing and addressing emerging issues in the embedding learning process.</p><p>In the current literature, the graph embedding problem has also been investigated to specifically preserve community structures in a graph by applying hybrid approaches <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>arXiv:1912.08808v1 [cs.SI] 17 Dec 2019</head><p>These approaches consist in specific graph embedding models jointly learning node embeddings and performing community detection, where the two steps are performed iteratively until convergence. However, such hybrid methods preserving community structures lose other inherent advantages from modern community detection techniques:</p><p>• Parameter-free community detection does not require any manual tuning, while current embedding techniques (hybrid or not) impose significant human efforts. Parameter-free processing could significantly simplify the application of graph embeddings in practice compared to current graph embedding techniques, which require manual tuning of multiple parameters (including the number of embedding dimensions).</p><p>• Metric-Robustness: community detection typically does not rely on any specific metric space (e.g., cosine, Jaccard, or Hamming spaces), which provides an opportunity to obtain metric-robust node embeddings. More precisely, as existing graph embedding techniques are designed to learn node embeddings in a specific metric space (e.g., cosine <ref type="bibr" target="#b1">[2]</ref> or Hamming <ref type="bibr" target="#b10">[11]</ref>), they are often limited to the specified metric space. To ensure the applicability of learned embeddings in a wide variety of settings, it might hence be beneficial to learn embeddings that are robust to different metric spaces.</p><p>• Efficient community detection techniques usually have linear or near-linear runtime complexity and are able to handle large graphs consisting of billions of nodes <ref type="bibr" target="#b11">[12]</ref>, which may significantly speedup the embedding learning process. Specifically, existing graph embedding techniques usually either sample a large number of node pairs from a graph to learn node embeddings via stochastic optimization, or factorize a highorder proximity/adjacency matrix, which requires significant computational resources. Therefore, it might be desirable to let graph embedding techniques benefit from the high-efficiency of state-of-the-art community detection techniques.</p><p>In this paper, we bridge the gap between community detection and node embeddings. More specifically, our main contributions can be formulated as follows: a) we propose a mechanism to generate node embeddings from given community structures (i.e., a set of clusters) and b) we identify the key features of community detection algorithms required to efficiently produce effective graph embeddings. Both of these contributions are applied on top of the Louvain [12]-based DAOC 1 <ref type="bibr" target="#b12">[13]</ref> clustering algorithm and constitute our novel graph embedding framework called DAOR 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK A. Graph embedding</head><p>Graph embedding techniques project graph nodes onto a low-dimensional vector space such that the key structural properties of the graph are preserved <ref type="bibr" target="#b0">[1]</ref>. Existing techniques can be classified into four categories. First, graph-sampling based techniques design specific embedding models to learn node embeddings from sampled node pairs from an input graph. The node pairs are often sampled by scanning random walk sequences from an input graph using a context window of size k to capture up-to-k-order node proximity <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, or directly sampled to capture 1st-and 2nd-order node proximities <ref type="bibr" target="#b15">[16]</ref>. Second, factorization-based techniques decompose specific node proximity matrices, such as highorder transitional matrices <ref type="bibr" target="#b16">[17]</ref>, high-order proximity matrices measured by the Katz index, personalized PageRank or Adamic-Adar <ref type="bibr" target="#b3">[4]</ref>, to output node embeddings. Third, hashingbased techniques resort to similarity-preserving hashing techniques <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref> to create node embeddings, capturing highorder common neighbors between nodes in a graph. Due to the high efficiency of the hashing process, these techniques show significant speedup in the embedding learning process compared to the techniques of the two previous categories <ref type="bibr" target="#b18">[19]</ref>. Fourth, a few meta techniques are designed to preserve higherorder structural features by hierarchical coarsening of the input graph prior to the embedding process <ref type="bibr" target="#b19">[20]</ref>. As they capture higher-order node proximity in the graph, modern graph embedding techniques have shown good performance on various graph analysis tasks, including node classification, node clustering and link prediction.</p><p>In the current literature, the graph embedding problem has also been investigated to specifically preserve community structures in a graph <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>. These hybrid techniques combine the objectives of both node embedding learning and community detection. More precisely, community detection and node embedding learning are tightly coupled and are performed alternatively to enhance each other in the learning process. The resulting node embeddings preserve the community structures of the input graph. However, such hybrid approaches are not able to directly reuse results of existing community detection techniques, loosing their advantages as outlined in the introduction, i.e., they typically are not parameter-free, metric-robust, or particularly efficient (as we show in Section VI).</p><p>In this paper, instead of jointly learning node embedding and detecting communities in a graph, we take an alternative solution to bridge the gap from detected communities to node embeddings. Specifically, we a) design a new mechanism to generate node embeddings directly from given community structures (i.e., clusters) and b) analyze the various aspects of community detection techniques required for effective node embeddings generation from the clusters. We implement these contributions in a novel graph embedding framework called DAOR 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Community detection for graph embedding</head><p>To the best our knowledge, only matrix factorization-based (MF) community detection methods have been used to directly generate graph embeddings. Spectral clustering is a matrix factorization approach <ref type="bibr" target="#b2">[3]</ref>, which was the first community detection method used for graph embedding. It can be applied in two variations: a) conventional spectral clustering <ref type="bibr" target="#b20">[21]</ref> (introduced in <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref> and operating on a Laplacian matrix) and b) spectral optimization of modularity <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b23">[24]</ref> (introduced in <ref type="bibr" target="#b24">[25]</ref> and operating on a modularity matrix). Node embeddings in this context are represented as the top-d eigenvectors (i.e., latent dimensions) of the respective matrix. Conventional spectral clustering is equivalent to nonnegative matrix factorization (NMF) <ref type="bibr" target="#b25">[26]</ref>. The latter is another community detection method <ref type="bibr" target="#b26">[27]</ref>, which is applied jointly with spectral optimization of modularity to learn node embeddings <ref type="bibr" target="#b9">[10]</ref>. The Gausian mixture model (GMM) is a statistical inference-based community detection method <ref type="bibr" target="#b27">[28]</ref>, which can be used jointly with a conventional node representation learning (e.g., Deepwalk <ref type="bibr" target="#b1">[2]</ref> and SDNE <ref type="bibr" target="#b28">[29]</ref>) to perform graph embedding <ref type="bibr" target="#b8">[9]</ref>. It is worth noting that GMM by itself explicitly learns the "random mixtures over latent communities variables" <ref type="bibr" target="#b27">[28]</ref> (i.e., node embeddings) but suffers from a large number of parameters and does not take into account the low-order proximity of the nodes when generating the graph embeddings.</p><p>In essence, community detection by modularity maximization <ref type="bibr" target="#b29">[30]</ref>, statistical inference <ref type="bibr" target="#b30">[31]</ref>, normalized-cut graph partitioning <ref type="bibr" target="#b31">[32]</ref> and spectral clustering are equivalent under certain conditions <ref type="bibr" target="#b32">[33]</ref>. According to <ref type="bibr" target="#b33">[34]</ref>, community detection through generalized modularity maximization is equivalent to the provably correct but computationally expensive maximum likelihood method applied to the degree-corrected stochastic block model <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b35">[36]</ref>. The latter inspired us to develop a novel graph embedding framework, which is able to generate node embeddings directly form the detected communities, and to extend an efficient community detection method based on parameter-free optimization of generalized modularity to produce effective embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PRELIMINARIES</head><p>Network communities represent groups of tightly-coupled graph nodes with loosely inter-group connections <ref type="bibr" target="#b7">[8]</ref>, where the group structure is determined by a clustering optimization function. The resulting clusters can be overlapping, which happens in case they share some common nodes called the overlap. Also, the clusters can be nested, forming a hierarchical structure inherent to many complex real-world systems <ref type="bibr" target="#b36">[37]</ref>. Each cluster represents a coarse-grained view on (i.e., an approximation of) its member nodes or subclusters being called a granule <ref type="bibr" target="#b37">[38]</ref>. The main notations used in this paper are listed in <ref type="table" target="#tab_0">Table I</ref>. Node &lt;i&gt; of the graph (network) G ci</p><p>Cluster &lt;i&gt; of the graph G n</p><p>The number of nodes in the graph G m</p><p>The number of links in the graph G k</p><p>The number of clusters (communities) in the graph G w</p><p>Weight of the graph G wi</p><p>Weight of #i wi</p><p>Weight of ci:ẇi = wc i Q Modularity ∆Qi,j Modularity Gain between #i and #j γ</p><p>Resolution parameter s</p><p>The number of salient clusters (features), s ≤ k d</p><p>The number of embedding dimensions: d = |D|, d ≤ s</p><p>Modularity (Q) <ref type="bibr" target="#b38">[39]</ref> is a standard measure of clustering quality that is equal to the difference between the density of the links in the clusters and their expected density:</p><formula xml:id="formula_0">Q = 1 2w i,j w i,j − w i w j 2w δ(C i , C j ),<label>(1)</label></formula><p>where w i,j is the accumulated weight of the links between nodes #i and #j; w i is the accumulated weight of all links of #i; w is the total weight of the graph; C i is the cluster to which #i is assigned; and the Kronecker delta δ(C i , C j ) equals to 1 when #i and #j belong to the same cluster (i.e., C i = C j ), and 0 otherwise. Modularity gain (∆Q) <ref type="bibr" target="#b11">[12]</ref> captures the difference in modularity when merging two nodes #i and #j into the same cluster, providing a computationally efficient way to optimize Modularity:</p><formula xml:id="formula_1">∆Q i,j = 1 2w w i,j − w i w j w .<label>(2)</label></formula><p>Modularity is commonly used as a global optimization criterion but suffers from the resolution limit problem <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b40">[41]</ref>, which corresponds to its inability to detect clusters smaller than a certain size. To address this problem, generalized modularity was proposed with a resolution parameter γ <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref>:</p><formula xml:id="formula_2">Q = 1 2w i,j w i,j − γ w i w j 2w δ(C i , C j ).<label>(3)</label></formula><p>The optimal value of the resolution parameter isγ <ref type="bibr" target="#b33">[34]</ref>:</p><formula xml:id="formula_3">γ =p −p logp − logp , p = 2w cẇ 2 c /(2w) ,p = 2w − 2w 2w − cẇ 2 c /(2w) ,<label>(4)</label></formula><p>wherew is the total internal weight of all clusters (i.e., accumulated weight of all intra-cluster links). The generalized modularity is equivalent to the standard modularity when γ = 1; it tends to find larger (macro-scale) clusters if γ ∈ [0, 1) and smaller clusters otherwise. We use the generalized modularity gain (∆Q) as an underlying optimization function for the meta-optimization strategy MMG of the DAOC <ref type="bibr" target="#b12">[13]</ref> clustering algorithm on top of which our framework, DAOR, is built.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. TRANSFORMING CLUSTERS INTO NODE EMBEDDINGS</head><p>Community detection algorithms only generate clusters as groups of nodes, which hence requires some post-processing to produce node embeddings, namely to: a) form latent embedding dimensions from the clusters (i.e., extract features) and b) quantify node membership in each dimension (i.e., generate the embedding vector for a node). In addition, it is often desirable to manually control the number of embedding dimensions d. These aspects are described in the following and are illustrated in <ref type="figure">Fig. 1</ref>. <ref type="figure">Fig. 1</ref>. Transformation of the hierarchy of overlapping clusters consisting of n nodes and k = 5 + 2 clusters (2 nodes-outliers, which are grouped as OL together with the outlier cluster C3) into d = 4 dimensional node embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Feature Extraction from Clusters</head><p>Intuitively, a straightforward approach for feature extraction from clusters is to consider each cluster as a dedicated feature representing one embedding dimension <ref type="bibr" target="#b23">[24]</ref>. This approach can be used to discriminate between the nodes (given a finegrained structure of clusters), but on the other hand, may not correlate with the graph embedding objective of providing a low-dimensional representation of the nodes. Fixing the number of clusters to the required number of dimensions d is possible when considering flat clustering <ref type="bibr" target="#b23">[24]</ref> but not for hierarchical cases. For hierarchical clustering, producing d dimensions can be expressed with an inequality in the general case, i.e. producing at most d clusters at the top level. Therefore, some technique to identify a small number s ≥ d of salient clusters, which are then regarded as features, is required. This number s can either be parameterized or, ideally, inferred as the optimal tradeoff between the number of clusters and their quality. In addition, there exists a fundamental constraint on the structure of the clusters used to create the embedding space. Namely, each graph node should be connected to at least one feature to be present in the embeddings.</p><p>The exact way salient clusters (features) are identified depends on the structure of the clusters (e.g., hierarchical, multi-resolution, overlapping, non-overlapping) and on the ability to control the number of formed clusters k ≥ s by the community detection algorithm. In the following, we discuss salient clusters identification for the most general case, i.e., for clustering techniques that are multi-resolution, hierarchical and overlapping. Features extraction is presented in Algorithm 1. We traverse all clusters on each level of the formed hierarchy of clusters starting from the top level, and fetch as salient clusters: a) the top-level clusters of the hierarchy (line 6) (to cover all nodes) and b) all the nested clusters satisfying the following requirements (line 17): -having a higher weight density than each of their direct super-clusters (ancestors), since the nested salient clusters are expected to represent the mutual core structure <ref type="bibr" target="#b43">[44]</ref> of their ancestors, and -weighting less than the most lightweight ancestor (discounted by a factor). The weight discounting factor r w (line 29) is required to prevent fetching too many similar clusters that are nested into each other. The factor r w ∈ [0.5, 1) retains an approximation of the nested cluster to its ancestor, while r w → r wmin = 0.5 reduces the number of salient clusters. However, considering the availability of overlapping clusters and known weight of the overlap w Covp &lt; w C for the cluster C, we refine r w as r w = 0.5 +</p><formula xml:id="formula_4">(b−1)×wc ovp 2 b×wc</formula><p>, where b ≥ 2 is the overlap factor equal to the number of clusters sharing the overlapping nodes in C. Also, the number of overlapping clusters can be estimated according to the Pareto principle <ref type="bibr" target="#b44">[45]</ref>, <ref type="bibr" target="#b45">[46]</ref>, which makes reasonable to take r w = 0.5×1.2 = 0.6 when the exact value cannot be evaluated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Dimension Formation from Features</head><p>Embedding dimensions are formed from the salient clusters extracted above, which implicitly yields the recommended for all lev ∈ hier do <ref type="bibr">5:</ref> for all cl ∈ lev do <ref type="bibr">6:</ref> res ← count(cl.ances) = 0 Salient flag <ref type="bibr">7:</ref> dens ← cl.weight/count(cl.nodes) Density <ref type="bibr">8:</ref> savdens ← 0; savwgh ← 0 Statistics to be stored <ref type="bibr">9:</ref> if not res then <ref type="bibr">10:</ref> hits ← 0 Saliency hits <ref type="bibr">11:</ref> for all ac ∈ cl.ances do Traverse ancestors <ref type="bibr">12:</ref> ast ← clsts[ac] Ancestor statistics <ref type="bibr">13:</ref> if savdens &lt; ast.dens and (not savwgh or savwgh &gt; ast.wgh) then <ref type="bibr">14:</ref> savdens ← ast.dens <ref type="bibr">15:</ref> savwgh ← ast.wgh <ref type="bibr">16:</ref> end if <ref type="bibr">17:</ref> if not res and dens ≥ ast.dens and cl.weight ≤ ast.wgh then <ref type="bibr">18:</ref> hits ← hits + 1 <ref type="bibr">19:</ref> end if <ref type="bibr">20:</ref> ast.reqs ← ast.reqs + 1 <ref type="bibr">21:</ref> if ast.reqs = count(ac.des) then <ref type="bibr">22:</ref> clsts.erase(cl)</p><p>Remove outdated <ref type="bibr">23:</ref> end if <ref type="bibr">24:</ref> end for <ref type="bibr">25:</ref> end if <ref type="bibr">26:</ref> if not res and hits = count(cl.ances) then <ref type="bibr">27:</ref> res ← true <ref type="bibr">28:</ref> end if <ref type="bibr">29:</ref> savwgh ← cl.weight * wrstep <ref type="bibr">30:</ref> clsts[cl] ← (savdens, savwgh) dens,wgh,reqs=0 <ref type="bibr">31:</ref> if res then <ref type="bibr">32:</ref> scls.add(cl) <ref type="bibr">33:</ref> end if <ref type="bibr">34:</ref> end for <ref type="bibr">35:</ref> end for <ref type="bibr">36:</ref> return scls The resulting salient clusters 37: end function number of dimensions for the input graph based on its statistical properties. The embedding vector v i ∈ V of size d = |D| for each graph node #i is then produced by quantifying the degree of belonging of the node to each dimension D j as the node weight w i,Dj belonging to this dimension. This weight corresponds to the aggregated weight of the node links to other nodes being members of all salient clusters composing the dimension:</p><formula xml:id="formula_5">V = { w i,Dj w i | i = 1..n, j = 1..d}, w i,Dj = k∈nodes(Dj ) w i,k .<label>(5)</label></formula><p>We perform this embedding vectors generation efficiently by resorting to a single scan over the members of each salient cluster. The node weights are then aggregated to form the dimension values. The embedding vectors are obtained by transposing the resulting matrix: V = D T . a) Constraining the Number of Dimensions: In the case of a connected graph without clusters-outliers, the most salient clusters d are fetched from the t ≤ d ≤ s top level clusters of the hierarchy and from the d − t densest of the remaining s − t salient clusters. When the clustering algorithm does not allow to control the number of top level clusters or when the graph is disconnected and the number of components is larger than d resulting in t &gt; d, then the dimensions are formed as follows. According to the so-called "Rag Bag" formal constraint of clustering quality <ref type="bibr" target="#b46">[47]</ref>, <ref type="bibr" target="#b47">[48]</ref>, the t − (d − 1) most lightweight clusters should be grouped together to the last dimension and the d − 1 heaviest clusters fill the remaining dimensions. However, the presence of outliers on the top levels prevents to effectively generate dimensions from the salient clusters. To solve this issue, the outliers can be separated from the valid clusters based on their weights, which are either evaluated from the statistical distributions or approximately estimated as follows. In case there is no prior information about the data, a rule of thumb is to take the estimated minimal size of clusters as the square root of the number of nodes <ref type="bibr" target="#b48">[49]</ref>. Generalizing the rule of thumb to the weighted graphs, the number of z &lt; t root clusters, each having a weight less that the square root of the graph weight w can be moved to the "outliers" dimension. The resulting dimensions are composed of the t − z top level clusters of the hierarchy, the d − 1 − (t − z) densest remaining salient clusters, each having a weight w i ≥ √ w, and a single dimension of outliers to cover all remaining graph nodes (see <ref type="figure">Fig. 1</ref> for an illustration).</p><p>b) Dimension Interpretability: The resulting embedding space is inherently easier to interpret than spaces derived from other techniques, as its dimensions are taken from (salient) clusters representing ground-truth semantic categories, with accuracy being evaluated using extrinsic quality metrics <ref type="bibr" target="#b46">[47]</ref>. This opens the door to new features and applications in the fields of granular and privacy-preserving computations. For example, only a subset of the dimensions having some required semantics can be fetched for evaluation, which has the advantage of reducing the amount of processing data while avoiding to leak or share information beyond the required features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. COMMUNITY DETECTION</head><p>In this section, we first discuss the properties of a community detection algorithm that are required to perform an effective and efficient graph embedding. Then, we select one of the most suitable state-of-the-art community detection algorithms for our task and propose its extension to satisfy the required properties.</p><p>As an effective graph embedding technique should preserve both low-and high-order node proximities, the community detection algorithm used for the graph embedding should be able to produce clusters with various resolutions (i.e., at different granularities). Moreover, the more resolutions are covered, the wider the range of node proximity orders that can be captured, since each embedding dimension consists of at least one cluster as described in Section IV-B. A lowdimensional representation of graph nodes implies a small number t of coarse-grained (macro-scale) clusters, since the number of generated dimensions d ≥ t (see Section IV). This number t should be a parameter of the technique when a specific number d of embedding dimensions is required, with a default value defined according to the statistical properties of the input graph.</p><p>In addition, the following properties of community detection algorithms are also required to generate high-quality embeddings, to simplify and speedup the generation process:</p><p>• Each graph node should potentially belong to multiple features (i.e., should be represented in multiple dimensions), which requires the clustering to be soft (i.e., fuzzy or overlapping). • It is desirable to have graph embedding techniques applicable to any input graph without any manual tuning; hence, the clustering should be parameter-free and efficient (to be applicable to large graphs).</p><p>-An unsupervised parameter-free processing is sensitive to the quality of the input data, so a robust clustering algorithm is required. Robustness is typically reached by applying a consensus (also called ensemble) clustering method <ref type="bibr" target="#b49">[50]</ref>- <ref type="bibr" target="#b51">[52]</ref>.</p><p>-From a practical perspective, it is desirable to have consistent embeddings for the same input graph irrespective of the order in which the nodes are processed or whether their IDs are modified. The clustering algorithm should hence be deterministic and input-order invariant.</p><p>-Considering the hierarchical nature of complex networks modeling real-world systems <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b52">[53]</ref>, the effective clustering algorithm should be hierarchical. In particular, an agglomerative hierarchical clustering addresses also the efficiency criterion by reducing the number of processed items at each iteration, since each hierarchy level is built using clusters from the previous level directly. Following the above requirements, DAOC 1 <ref type="bibr" target="#b12">[13]</ref> is, to the best of our knowledge, the only parameter-free clustering algorithm that is simultaneously deterministic, input order invariant, robust (as it uses a consensus approach) and applicable to large weighted networks yielding a fine-grained hierarchy of overlapping clusters <ref type="bibr" target="#b53">[54]</ref>. Moreover, it is based on a MMG meta-optimization function, where generalized modularity gain can be used as the target optimization function to perform clustering at the required resolution. However, DAOC a) yields a hierarchy of clusters only for a single value of the resolution parameter (γ = 1 operating with the non-generalized modularity), treating the hierarchy levels as scales (i.e., resolutions in terms of nested clusters rather than distinct values of γ) similar to <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b54">[55]</ref>, and b) does not bound the size of the top (root) level of the forming hierarchy to produce the required number t ≤ d of clusters as described in Section IV-A. Therefore, we propose two extensions addressing these issues in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Hierarchical multi-resolution clustering</head><p>Even though a multi-resolution structure of non-overlapping clusters is not necessary hierarchical <ref type="bibr" target="#b55">[56]</ref>, <ref type="bibr" target="#b56">[57]</ref> (i.e., a node might be a member of several clusters that are not nested into each other), it can be represented as a hierarchy of overlapping clusters <ref type="bibr" target="#b57">[58]</ref> (where the overlap addresses the case of a node shared by non-nested clusters). However, a hierarchical overlapping structure created with a single resolution may substantially differ from the respective multi-resolution structure (i.e., the produced clusters may differ vastly) as illustrated in <ref type="figure" target="#fig_0">Fig. 2</ref>, where the strength on nodes interaction is represented with the width of the links and the number of interactions with the size of the nodes (i.e., their weight). A large value of the resolution parameter can penalize heavily-weighted nodes according to Eq. (3), resulting in grouping together linked lightweight nodes. Such a behavior makes sense in many realworld cases, for example when employees working on the same project interact more frequently with their supervisor than between each other but the supervisor may not be a core of the group, participating also in other projects. Therefore, it is essential to incorporate the resolution parameter when generating the hierarchy levels, similar to <ref type="bibr" target="#b55">[56]</ref>, <ref type="bibr" target="#b58">[59]</ref>, <ref type="bibr" target="#b59">[60]</ref>. In <ref type="bibr" target="#b55">[56]</ref>, <ref type="bibr" target="#b59">[60]</ref>, the authors operate with the analog of the resolution parameter called resistance parameter, which can not be transformed to the resolution parameter γ according to <ref type="bibr" target="#b41">[42]</ref> and, hence, cannot be used with the generalized modularity defined in Eq. (3). In <ref type="bibr" target="#b58">[59]</ref>, the scale factor α is proposed, which can be directly transformed to the resolution parameter: γ = (1 − α)/α. However, the computational complexity of the proposed method is O(n √ n)×O 0 in average and O(n 2 ) × O 0 in the worst case, where n is the number of nodes in the graph and O 0 is the complexity of the original clustering algorithm without the multi-scaling technique. This boosting of the computational complexity makes this technique inappropriate for large graphs. Hence, we propose our own approach to produce a hierarchy of multi-resolution clusters for large graphs based on DAOC.</p><p>The main idea behind our efficient multi-resolution hierarchical clustering is the dynamic variation of the resolution parameter γ during the hierarchy construction process. More precisely, DAOC is an agglomerative clustering algorithm, which builds the hierarchy bottom-up with micro-scale clusters on the bottom levels. These clusters should be constructed on a high value of the resolution parameter (γ 1) according to Eq. (3). The resolution should then gradually decrease to the lowest value γ &gt; 0 yielding macro-scale clusters located on the top (root) level of the hierarchy. The bounds for γ can be estimated based on the resolution limit analysis conducted in <ref type="bibr" target="#b39">[40]</ref>, where the equation is defined for the marginal case when all clusters have a perfect balance between the internal and external degrees being on the limit of detectability. That equation takes the following shape when adapted to the generalized modularity:</p><formula xml:id="formula_6">m &lt;m max = m 4γ ,<label>(6)</label></formula><p>wherem is the number of internal links in a cluster and m is the total number of links in the graph. To estimate the upper bound of γ, we need to bindm and m, which could be done relying on the two following heuristics. First, in case there is no prior information about the data, a rule of thumb is to take the estimated maximal number of clusters as the square root of the number of nodes <ref type="bibr" target="#b48">[49]</ref>:k max = √ n. Then, considering that the number of internal links constitutes half of all the links of a cluster in the marginal case described by Eq. <ref type="formula" target="#formula_6">(6)</ref>:</p><formula xml:id="formula_7">2 m = 2m × k, k k max =⇒ m m √ n.<label>(7)</label></formula><p>Second, most real-world systems are modeled by sparse graphs <ref type="bibr" target="#b52">[53]</ref>. The number of links in a sparse graph does not exceed n 3/2 . Thereby, Eq. (6) extended with Eq. (7) takes the following shape:</p><formula xml:id="formula_8">m &lt;m √ n 4γ =⇒ γ &lt; √ n 4 3 √ m 4 ≤ 3 w/w min 4 = γ max .</formula><p>(8) wherew min is the minimal weight of a link. Eq. (8) provides a definition for the upper bound of γ in a weighted graph. The lower bound of gamma is evaluated dynamically based on the optimal value of the resolution parameter given in Eq. (4) for each level of the hierarchy: γ min =γ. Typically,γ ≥ 1 for large real-world networks <ref type="bibr" target="#b33">[34]</ref>, so γ min = 0.5 .. 1 is taken for the first iteration beforeγ is evaluated.</p><p>In summary, γ is decreased from γ max to γ min with a fixed ratio r γ and represents a trade-off between the number of captured resolutions when r γ → 1 versus a lower number of iterations (i.e., higher efficiency) and higher quality on coarse resolutions when r γ → 0. The quality of the forming macro-clusters is affected by the amount and size of the finegrained clusters since the former are constructed iteratively from the latter, and the actual multi-resolution structure is not necessary hierarchical <ref type="bibr" target="#b55">[56]</ref>, <ref type="bibr" target="#b56">[57]</ref>. In theory, r γ should allow the growth of the cluster weight by a factor less than two to still retain the cluster semantics (super/sub-cluster ordering). Otherwise, the super/sub-cluster association is transformed into an overlapping clusters relation, losing the hierarchical structure. The limitation of the cluster weight growth to a factor 2 corresponds to r γ &gt; 2 −2 = 0.25 according to Eq. (3), which is a hard theoretical bound. In practice, a larger value of r γ is required considering the possibility of multiple mutually overlapping clusters as discussed in Section IV-A: r γ r 2 wmin = 0.36. The upper bound of r γ corresponds to the lower bound of the cluster weight growth factor, which can be taken as 10 − 20% according to the Pareto principle <ref type="bibr" target="#b44">[45]</ref>, <ref type="bibr" target="#b45">[46]</ref> or 10/90 gap <ref type="bibr" target="#b60">[61]</ref>: r γ ≤ 1.1 −2 = 0.826. Thus, the operational range of the gamma ratio is as follows: r γ ∈ [0.36, 0.826], and we pick r γ = 0.6. This selected value is not supposed to be tuned by the users. Higher values of r γ yield a larger number of salient clusters, which is not desirable, and lower values may cause the loss of some important salient clusters. The exact theoretical r γ depends on the number of overlapping clusters on the next iteration, which is generally speaking unknown.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Bounding the number of clusters</head><p>DAOC generates a hierarchy of clusters as long as the value of the optimization function is improving (i.e., ∆Q ≥ 0), which might result in any number of clusters at the top level of the hierarchy. If a specific number of clusters is required (e.g., for a fair comparison of various graph embedding techniques on the same number of dimensions), we propose the following extensions of the hierarchy generation process:</p><p>• The hierarchy generation is interrupted early if the number of clusters at level i, |h i | reaches the required number d. • The hierarchy generation is forced to continue until the number of clusters reaches the required number d even if the value of the optimization function ∆Q becomes negative. In that case, the clustering objective becomes the minimal loss of the optimization function value: max ∆Q &lt; 0. The proposed extensions of the clustering algorithm are summarized in Algorithm 2. The early termination of the hierarchy construction process happens on lines 11, 19. The forced continuation of the hierarchy construction corresponds to a boolean parameter d = 0 for the original DAOC clustering on line 7. This parameter prevents the completion of the clustering process when the optimization function ∆Q cannot be further improved. hier ← [] List of the hierarchy levels <ref type="bibr">6:</ref> while nodes do Stop if the nodes list is empty <ref type="bibr">7:</ref> cls ← daocHierLev(nodes, gamma, d) <ref type="bibr">8:</ref> if gamma * (rg + 1)/2 ≥ gmin and (not cls or count(cls) ≤ count(nodes)) then Decrease gamma <ref type="bibr">9:</ref> gamma ← gamma * rg 10:</p><p>else <ref type="bibr">11:</ref> nodes ← cls Consider early termination <ref type="bibr">12:</ref> end if <ref type="bibr">13:</ref> if cls then Initialize the next-level nodes <ref type="bibr">14:</ref> hier.append(cls) Extend the hierarchy <ref type="bibr">15:</ref> gmin ← gammaOptim(cls) Update min gamma <ref type="bibr">16:</ref> if not d or count(cls) &gt; d then <ref type="bibr">17:</ref> nodes ← cls Update the processing nodes <ref type="bibr" target="#b17">18</ref> return hier The resulting hierarchy of clusters 24: end function VI. EXPERIMENTAL EVALUATION In this section, we conduct an extensive set of experiments to evaluate our proposed method on two typical graph analysis tasks, i.e., node classification and link prediction. We start by introducing our experimental setup including the datasets and baselines we use before presenting our experimental results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Experimental Setup 1) Datasets:</head><p>We conduct experiments on the following five graphs, which are widely used in the current literature for evaluating graph embedding techniques. <ref type="table" target="#tab_0">Table II summarizes</ref> the key characteristics of the graphs.</p><p>• BlogCatalog (Blog) <ref type="bibr" target="#b23">[24]</ref> is a social network of bloggers. Each node represents a user, while the labels of a node represent the topics the corresponding user is interested in.</p><p>• Protein-Protein Interactions (PPI) <ref type="bibr" target="#b2">[3]</ref> is a graph of the PPI network for Homo Sapiens. The labels of a node refer to its gene sets and represent the corresponding biological states.</p><p>• Wikipedia (Wiki) <ref type="bibr" target="#b2">[3]</ref> is a co-occurrence network of words appearing in a sampled set of the Wikipedia dump. The labels represent part-of-speech tags.</p><p>• DBLP [62] is a collaboration network capturing the coauthorship of writers. Each node represents an author, and the labels of a node refer to the publication venues of the corresponding author.</p><p>• YouTube <ref type="bibr" target="#b62">[63]</ref> is a social network of users on YouTube. Each node represents a user, and the labels of a node refer to the groups (e.g., "anime") that the corresponding user is interested in. This graph is used only to evaluate the efficiency of the embedding techniques, since the ground-truth categories include only 3% of the graph (as opposed to a 100% coverage for the other graphs). 2) Baselines: We compare our proposed technique against ten state-of-the-art graph embedding techniques from three categories. a) Graph-sampling based techniques: DeepWalk [2], Node2Vec <ref type="bibr" target="#b2">[3]</ref>, LINE <ref type="bibr" target="#b15">[16]</ref> and VERSE <ref type="bibr" target="#b63">[64]</ref>. For DeepWalk and Node2Vec, we set the walk length to 40, the number of walks per node to 80, and the context window size to 10. For Node2Vec, we also tune the return parameter p and the in-out parameter q with a grid search over p, q ∈ {0.25, 0.05, 1, 2, 4}. For LINE, we set the total number of samples to 1 billion for Blog, PPI, Wiki and DBLP and to 10 billions for YouTube. For VERSE, we tune the damping factor α of personalized PageRank using the method suggested by the authors. b) Factorization-based techniques: GraRep <ref type="bibr" target="#b16">[17]</ref>, HOPE <ref type="bibr" target="#b3">[4]</ref> and NetMF <ref type="bibr" target="#b4">[5]</ref>. For GraRep, we search the optimal k over {1, 2, 3, 4, 5, 6}. When d/k is not an integer, we learn the first k − 1 sets of d/k -dimension embeddings, and the last set of embeddings of dimension d − (k − 1) d/k . For HOPE, we search the optimal decay parameter β from 0.1 to 0.9 with a step of 0.2. For NetMF, we tune the implicit window size T within {1, 10}.</p><p>c) Similarity-preserving hashing based techniques: INH-MF <ref type="bibr" target="#b64">[65]</ref>, NetHash <ref type="bibr" target="#b17">[18]</ref> and NodeSketch <ref type="bibr" target="#b18">[19]</ref>. For INH-MF, we set the ratio for subspace learning to 100%, to let it achieve optimal performance w.r.t. the quality of the learnt node embeddings. For NetHash, as suggested by the authors, · the algorithm meta parameters are tuned once for all datasets to maximize accuracy : the algorithm parameters are tuned for each dataset to maximize accuracy we search the optimal tree depth in {1, 2, 3}. For NodeSketch, we search the optimal order of proximity k up to 6 and the optimal decay parameter α from 0.0001 to 1 on a log scale. d) Meta techniques: HARP <ref type="bibr" target="#b19">[20]</ref>. We configure HARP to learn from the embeddings of DeepWalk (HARP-DWalk) and LINE (HARP-LINE) using the following parameter settings. For HARP-DWalk, we set the walk length to 10, the number of walks per node to 40, the context window size to 10 and the sampling ratio to 0.1. For HARP-LINE, we set the context window size to 1, the number of iterations to 50 and the sampling ratio to 0.001.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Node Classification Task</head><p>Node classification tries to predict the most probable label(s) for some nodes based on other labeled nodes. In this experiment, we consider a multi-label setting, where a node is assigned one or multiple labels. Our evaluation was performed using an open-source graph embeddings evaluation framework, GraphEmbEval 3 , which uses the same evaluation scheme as in <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b16">[17]</ref>. More precisely, we randomly pick a set of nodes as labeled nodes for training, and use the rest for testing. To fairly compare node embeddings with different similarity measures, we train a one-vs-rest kernel SVM classifier with a pre-computed kernel (cosine, Jaccard or Hamming kernel according to the embedding techniques) to return the most probable labels for each node. We report the average Macro-F1 and Micro-F1 scores from 5 repeated trials. A higher value of these metrics implies better performance.</p><p>Our method, DAOR, shows competitive results without requiring any tuning (unlike conventional embedding techniques, which require extensive tuning, as described above). We also evaluated embeddings generated using DAOC without our proposed extension for multi-resolution clustering. The improvement of DAOR over DAOC verifies the effectiveness of our proposed extensions for graph embedding. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Link Prediction Task</head><p>Link prediction is a typical graph analysis task that predicts potential (or missing) links between nodes in a graph. For this task, we use the same setting as in <ref type="bibr" target="#b3">[4]</ref>. Specifically, we randomly sample 20% of the links out of the graph as test data, and use the rest of the graph for training. After learning the node embeddings based on the training graph, we predict the missing links by generating a ranked list of potential links. For each pair of nodes, we use the cosine, Jaccard or Hamming similarity (according to the embedding techniques) between their embedding vectors to generate the ranked list. As the number of possible pairs of nodes is too large, we randomly sample 0.1% pairs of nodes for evaluation. We report the average precision@N and recall@N from 10 repeated trials. <ref type="table" target="#tab_0">Table IV</ref> shows the results of the link prediction task. Our proposed method, DAOR, is among the top-3 best-performing techniques being unsupervised and parameter-free. The impact of our proposed multi-resolution clustering is especially visible on this task, were DAOR significantly outperforms DAOC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Robustness to the Metric Space</head><p>Node embedding robustness to different metric spaces is shown in Table V on the node classification task for our method DAOR versus the two other best-performing methods from <ref type="table" target="#tab_0">Table III</ref> that technically can be evaluated with another metric space (NodeSketch is omitted because it uses a nonlinear Hamming metric space, where cosine distance cannot be formally evaluated). For all input graphs, DAOR shows the best worst-case performance, i.e., DAOR yields much more accurate results in its least accurate non-primary metric space than the other methods do. Moreover, Hamming distance is directly applicable to DAOR without any preliminary binarization, unlike the algorithms operating in the cosine metric space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Runtime Performance</head><p>In this experiment, we investigate the efficiency of the graph embedding learning process. Our evaluation was performed  · the algorithm meta parameters are tuned once for all datasets to maximize accuracy : the algorithm parameters are tuned for each dataset to maximize accuracy x the algorithm is crashed on coarsening small disconnected components using an open-source graph embeddings evaluation framework, GraphEmbEval 3 . on a Linux Ubuntu 16.04.3 LTS server with an Intel Xeon CPU E5-2620 v4 @ 2.10GHz CPU (16 physical cores) and 132 GB RAM. The training and execution termination constraints for each algorithm were set to 64 GB of RAM and 240 hours CPU time (we terminate the process when either of those thresholds are met). <ref type="table" target="#tab_0">Table VI</ref> shows the end-to-end embedding learning time. To discount the impact of the multi-threaded implementation of some of the methods, we dedicate a single logical CPU per each method implementation and report the total CPU time. Our method, DAOR, is faster than existing state-ofthe-art techniques by several orders of magnitude; it exhibits near-linear scaling when increasing the number of links in the graph. DAOR is also much more scalable than DAOC (on which DAOR is built) due to its specific multi-scaling approach that boosts the number of nodes reaching consensus of the optimization function early on lower levels of the hierarchy. Moreover, unlike other graph embedding techniques, DAOR execution time decreases when increasing </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>A possible overlapping hierarchical clustering with the fixed resolution parameter of the weighed subgraph consisting of three nodes is shown on the left-hand side of the figure. A possible multi-resolution clustering for the same subgraph is shown on the right-hand side. The size of the nodes and the width of the links correspond to their weights.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Algorithm 2</head><label>2</label><figDesc>Hierarchical multi-resolution clustering with optionally bounded number of clusters. 1: function CLUSTER(nodes, d)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>3 https://github.com/eXascaleInfolab/GraphEmbEval</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>0.0159 0.0090 0.0423 0.0301 0.2227 0.0493 0.6749 :Node2Vec 0.0927 0.0137 0.0267 0.0321 0.1378 0.1958 0.1514 0.5174 ·LINE 0.0070 0.0073 0.0031 0.0392 0.0103 0.0923 0.0167 0.6186 ·VERSE 0.0404 0.0206 0.0212 0.0436 0.0602 0.2723 0.1118 00.0175 0.0164 0.0032 0.1438 0.2345 0.0892 0.0548</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I NOTATIONS</head><label>I</label><figDesc></figDesc><table><row><cell>#i</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE II CHARACTERISTICS</head><label>II</label><figDesc>OF THE EXPERIMENTAL GRAPHS</figDesc><table><row><cell>Dataset</cell><cell>Blog</cell><cell>PPI</cell><cell cols="2">Wiki DBLP</cell><cell>YouTube</cell></row><row><cell>Nodes</cell><cell>10,312</cell><cell>3,890</cell><cell cols="3">4,777 13,326 1,138,499</cell></row><row><cell>Links</cell><cell cols="5">333,983 76,584 184,812 34,281 2,990,443</cell></row><row><cell>Labels</cell><cell>39</cell><cell>50</cell><cell>40</cell><cell>2</cell><cell>47</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE III NODE</head><label>III</label><figDesc>CLASSIFICATION PERFORMANCE USING KERNEL SVM, WHERE THE TOP-3 RESULTS FOR EACH DATASET ARE HIGHLIGHTED WITH BOLD NUMBERS</figDesc><table><row><cell>Method</cell><cell>Blog</cell><cell cols="2">Micro-F1 (%) PPI Wiki DBLP</cell><cell>Blog</cell><cell cols="3">Macro-F1 (%) PPI Wiki DBLP</cell></row><row><cell>·DeepWalk</cell><cell cols="2">39.60 17.24 46.05</cell><cell cols="3">83.46 21.93 10.28</cell><cell>6.62</cell><cell>83.16</cell></row><row><cell>:Node2Vec</cell><cell cols="2">37.95 16.04 50.32</cell><cell cols="2">93.25 20.22</cell><cell>9.57</cell><cell>9.86</cell><cell>93.12</cell></row><row><cell>·LINE</cell><cell cols="2">35.49 15.01 48.22</cell><cell cols="2">86.83 16.60</cell><cell>8.70</cell><cell>8.47</cell><cell>86.54</cell></row><row><cell>·VERSE</cell><cell cols="2">39.61 15.90 41.39</cell><cell cols="2">92.79 22.85</cell><cell>9.76</cell><cell>4.14</cell><cell>92.66</cell></row><row><cell>:GraRep</cell><cell>36.21</cell><cell>5.83 56.22</cell><cell cols="2">91.41 16.91</cell><cell cols="2">1.52 12.14</cell><cell>91.25</cell></row><row><cell>:HOPE</cell><cell cols="2">31.37 14.69 56.68</cell><cell cols="2">91.47 11.74</cell><cell cols="2">8.13 13.30</cell><cell>91.30</cell></row><row><cell>:NetMF</cell><cell cols="2">40.04 15.03 57.62</cell><cell cols="2">93.59 23.43</cell><cell cols="2">8.74 14.35</cell><cell>93.46</cell></row><row><cell>·INH-MF</cell><cell cols="2">36.13 15.50 45.03</cell><cell cols="2">93.27 18.88</cell><cell>9.55</cell><cell>6.90</cell><cell>93.16</cell></row><row><cell>:NetHash</cell><cell cols="2">35.80 18.85 47.57</cell><cell cols="3">97.61 18.72 12.91</cell><cell>8.05</cell><cell>97.57</cell></row><row><cell>:NodeSketch</cell><cell cols="2">38.16 21.04 59.07</cell><cell cols="4">98.83 21.84 15.55 16.31</cell><cell>98.81</cell></row><row><cell cols="3">·HARP-DWalk 36.52 15.46 43.06</cell><cell cols="2">92.66 19.56</cell><cell>9.04</cell><cell>5.59</cell><cell>92.53</cell></row><row><cell>·HARP-LINE</cell><cell cols="2">30.27 12.67 42.79</cell><cell cols="2">88.07 13.06</cell><cell>6.25</cell><cell>5.38</cell><cell>87.84</cell></row><row><cell>DAOC</cell><cell cols="2">21.3 12.56 42.43</cell><cell>89.24</cell><cell>6.47</cell><cell>7.25</cell><cell>5.66</cell><cell>89.03</cell></row><row><cell>DAOR</cell><cell cols="2">33.05 19.07 53.24</cell><cell cols="4">87.86 17.25 13.94 15.97</cell><cell>87.64</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE IV LINK</head><label>IV</label><figDesc>PREDICTION PERFORMANCE, WHERE THE TOP-3 RESULTS FOR EACH DATASET ARE HIGHLIGHTED WITH BOLD NUMBERS</figDesc><table><row><cell>Method</cell><cell>Blog</cell><cell>Precision@100 PPI Wiki DBLP</cell><cell>Blog</cell><cell>Recall@100 PPI Wiki DBLP</cell></row><row><cell>·DeepWalk</cell><cell>0.0200</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE V NODE</head><label>V</label><figDesc>EMBEDDING ROBUSTNESS TO THE METRIC SPACE, WHERE THE NATIVE METRIC SPACE FOR EACH ALGORITHM IS HIGHLIGHTED IN BOLD DAOR jaccard 33.05 19.07 53.24 87.86 cosine 30.41 13.62 47.20 87.42 hamming 23.87 14.13 45.52 86.98 binham 23.89 10.25 41.36 87.17</figDesc><table><row><cell cols="2">Method Metric</cell><cell>Blog</cell><cell cols="2">Micro-F1 (%) PPI Wiki</cell><cell>DBLP</cell></row><row><cell></cell><cell>cosine</cell><cell cols="3">40.04 15.03 57.62 93.59</cell></row><row><cell>NetMF</cell><cell cols="3">hamming 17.54 6.55</cell><cell>40.93 70.32</cell></row><row><cell></cell><cell>binham</cell><cell cols="2">19.82 7.05</cell><cell>42.85 74.91</cell></row><row><cell></cell><cell>cosine</cell><cell cols="3">31.37 14.69 56.68 91.47</cell></row><row><cell>HOPE</cell><cell cols="3">hamming 17.02 5.95</cell><cell>40.89 59.94</cell></row><row><cell></cell><cell>binham</cell><cell cols="2">18.23 6.21</cell><cell>40.89 74.36</cell></row><row><cell cols="5">binham -Hamming metric applied after a binarization of each dimension</cell></row><row><cell cols="2">using its median value</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE VI NODE</head><label>VI</label><figDesc>EMBEDDING LEARNING TIME (IN SECONDS), WHERE THE TOP 3</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/eXascaleInfolab/daoc 2 https://github.com/eXascaleInfolab/daor</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RESULTS FOR EACH DATASET ARE HIGHLIGHTED IN BOLD</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Blog PPI Wiki DBLP <ref type="table">YouTube  DeepWalk  3375 1273 1369  4665  747060  Node2Vec  1073  383 1265  504  -LINE  2233 2153 1879  2508  29403  VERSE  1095  203  276  1096  245334  GraRep  3364  323</ref>  -the algorithm was terminated by timeout the number of embedding dimensions, which is due to the early termination of the clustering as described in Section V-B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSIONS</head><p>In this paper, we presented a novel highly efficient and parameter-free graph embedding technique, DAOR 2 , which produces metric-robust and interpretable embeddings without requiring any manual tuning. Compared to a dozen state-ofthe-art graph embedding algorithms, DAOR yields competitive results on diverse graph analysis tasks (node classification and link prediction), while being several orders of magnitude more efficient.</p><p>In future work, we plan to recommend the minimal, maximal and optimal number of embedding dimensions, and conduct a comprehensive study on their quality and interpretability. Also, we plan to integrate further state-of-the-art community detection algorithms in addition to DAOC.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A comprehensive survey of graph embedding: problems, techniques and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">W</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TKDE</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deepwalk: Online learning of social representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;14</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="701" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">node2vec: Scalable feature learning for networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;16</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="855" to="864" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Asymmetric transitivity preserving graph embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;16</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1105" to="1114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Network embedding as matrix factorization: Unifying deepwalk, line, pte, and node2vec</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM&apos;18</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="459" to="467" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A new status index derived from sociometric analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Katz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="43" />
			<date type="published" when="1953" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Granular computing: basic issues and possible solutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th Joint Conference on Information Sciences</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="186" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The structure and function of complex networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E J</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Rev</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning community embedding with community detection and node embedding on graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cavallari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">W</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">C C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="377" to="386" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Community preserving network embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Histosketch: Fast similarity-preserving sketching of streaming histograms with concept drift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Rettig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cudré-Mauroux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM&apos;17</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="545" to="554" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Fast unfolding of communities in large networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">D</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-L</forename><surname>Guillaume</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lambiotte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lefebvre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Stat Mech</title>
		<imprint>
			<biblScope unit="issue">10</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Daoc: Stable clustering of large networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lutov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Khayati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cudré-Mauroux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE BigData</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Revisiting user mobility and social relationships in lbsns: a hypergraph embedding approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cudre-Mauroux</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>WWW. ACM</publisher>
			<biblScope unit="page" from="2147" to="2157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Are meta-paths necessary?: Revisiting heterogeneous graph embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hussein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cudré-Mauroux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="437" to="446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Line: Largescale information network embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Mei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>WWW</publisher>
			<biblScope unit="page" from="1067" to="1077" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Grarep: Learning graph representations with global structural information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM&apos;15</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="891" to="900" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Efficient attributed network embedding via recursive randomized hashing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Nodesketch: Highlyefficient graph embeddings via recursive sketching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cudre-Mauroux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KDD</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Harp: Hierarchical representation learning for networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in AAAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Leveraging social media networks for classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Min. Knowl. Discov</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="447" to="478" />
			<date type="published" when="2011-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Algebraic connectivity of graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fiedler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Czechoslovak Mathematical Journal</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="298" to="305" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Partitioning sparse matrices with eigenvectors of graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pothen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Liou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIMAX</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="430" to="452" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Relational learning via latent social dimensions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGKDD</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="817" to="826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Finding community structure in networks using the eigenvectors of matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E J</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. E</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page">36104</biblScope>
			<date type="published" when="2006-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">On the equivalence of nonnegative matrix factorization and spectral clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">D</forename><surname>Simon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SDM</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="606" to="610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Overlapping community detection at scale: A nonnegative matrix factorization approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ser. WSDM</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Probabilistic community discovery using hierarchical latent gaussian mixture model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">C</forename><surname>Foley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ser. AAAI</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="663" to="668" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Structural deep network embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ser. ACM SIGKDD</title>
		<imprint>
			<biblScope unit="page" from="1225" to="1234" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Fast algorithm for detecting community structure in networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E J</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. E</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page">66133</biblScope>
			<date type="published" when="2004-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Estimation and prediction for stochastic blockmodels for graphs with latent block structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">A</forename><surname>Snijders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nowicki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Classification</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="75" to="100" />
			<date type="published" when="1997-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Network community discovery: Solving modularity clustering via normalized cut</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ser. MLG &apos;10. ACM</title>
		<imprint>
			<biblScope unit="page" from="34" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Spectral methods for network community detection and graph partitioning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E J</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. E</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">42822</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Equivalence between modularity optimization and maximum likelihood methods for community detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E J</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. E</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="page">52315</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Stochastic blockmodels and community structure in networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Karrer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E J</forename><surname>Newman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. E</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<date type="published" when="2011-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Efficient monte carlo and greedy heuristic for the inference of stochastic block models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">P</forename><surname>Peixoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. E</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<date type="published" when="2014-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The architecture of complexity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Simon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Am. Phil. Soc</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="467" to="482" />
			<date type="published" when="1962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Information granulation and rough set approximation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int J Intell Syst</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="87" to="104" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Finding and evaluating community structure in networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E J</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Girvan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. E</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">26113</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Resolution limit in community detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fortunato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Barthélemy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PNAS</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="36" to="41" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Performance of modularity maximization in practical contexts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">H</forename><surname>Good</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-A</forename><surname>De Montjoye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Clauset</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. E</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">46106</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Analysis of the structure of complex networks at different resolution levels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Arenas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gomez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New Journal of Physics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">53039</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Limited resolution in complex network community detection with potts model approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Kumpula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Saramäki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kaski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kertész</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eur. Phys. J. B</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="41" to="45" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Models of core/periphery structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Borgatti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Everett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social Networks</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="375" to="395" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Manual of political economy (manuale di economia politica)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pareto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1906" />
			<publisher>Kelley</publisher>
			<biblScope unit="page">1971</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">An analysis for unreplicated fractional factorials</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Box</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Meyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technometrics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="11" to="18" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Accuracy evaluation of overlapping and multi-resolution clustering algorithms on large datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lutov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Khayati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cudré-Mauroux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BigComp</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A comparison of extrinsic clustering evaluation metrics based on formal constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Amigó</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Artiles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Verdejo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Retr</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2009-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">V</forename><surname>Mardia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Kent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Bibby</surname></persName>
		</author>
		<title level="m">Multivariate analysis</title>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Robust data clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L N</forename><surname>Fred</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="128" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A survey of clustering ensemble algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vega-Pons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ruiz-Shulcloper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Pattern Recogn</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">03</biblScope>
			<biblScope unit="page" from="337" to="372" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Consensus clustering in complex networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lancichinetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fortunato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Network science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A.-L</forename><surname>Barabási</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pósfai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Cambridge Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Clubmark: a parallel isolation framework for benchmarking and profiling clustering algorithms on numa architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lutov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Khayati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cudré-Mauroux</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICDMW</publisher>
			<biblScope unit="page" from="1481" to="1486" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Extracting the hierarchical organization of complex systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sales-Pardo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Guimerà</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Moreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A N</forename><surname>Amaral</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc Natl Acad Sci</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">39</biblScope>
			<biblScope unit="page" from="15" to="224" />
			<date type="published" when="2007-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Multiple resolution of the modular structure of complex networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Arenas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fernández</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gómez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New J. Phys</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Multi-scale modularity in complex networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lambiotte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WiOpt</title>
		<imprint>
			<date type="published" when="2010-05" />
			<biblScope unit="page" from="546" to="553" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Detecting the overlapping and hierarchical community structure in complex networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lancichinetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fortunato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kertész</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New Journal of Physics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">33015</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Post-processing hierarchical community structures: Quality improvements and multi-scale view</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Latapy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theor. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">412</biblScope>
			<biblScope unit="issue">8-10</biblScope>
			<biblScope unit="page" from="892" to="900" />
			<date type="published" when="2011-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Hierarchical multiresolution method to overcome the resolution limit in complex networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Granell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gómez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Arenas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Bifurc. Chaos</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">07</biblScope>
			<biblScope unit="page">1250171</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Global Forum for Health Research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Currat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Francisco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Al-Tuwaijri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ghaffar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jupp</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Defining and evaluating network communities based on ground-truth</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KIS</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="181" to="213" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Scalable learning of collective behavior based on sparse social dimensions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM&apos;09</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1107" to="1116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Verse: Versatile graph embeddings from similarity measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tsitsulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mottin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW&apos;18</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="539" to="548" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">High-order proximity preserving information network hashing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">W</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD&apos;18</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1744" to="1753" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
