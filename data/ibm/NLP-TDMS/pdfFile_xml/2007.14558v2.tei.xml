<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">BiTraP: Bi-directional Pedestrian Trajectory Prediction with Multi-modal Goal Estimation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Yao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ella</forename><surname>Atkins</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Johnson-Roberson</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ram</forename><surname>Vasudevan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Du</surname></persName>
						</author>
						<title level="a" type="main">BiTraP: Bi-directional Pedestrian Trajectory Prediction with Multi-modal Goal Estimation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T09:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Pedestrian trajectory prediction is an essential task in robotic applications such as autonomous driving and robot navigation. State-of-the-art trajectory predictors use a conditional variational autoencoder (CVAE) with recurrent neural networks (RNNs) to encode observed trajectories and decode multi-modal future trajectories. This process can suffer from accumulated errors over long prediction horizons (≥ 2 seconds). This paper presents BiTraP, a goal-conditioned bidirectional multi-modal trajectory prediction method based on the CVAE. BiTraP estimates the goal (end-point) of trajectories and introduces a novel bi-directional decoder to improve longer-term trajectory prediction accuracy. Extensive experiments show that BiTraP generalizes to both first-person view (FPV) and bird's-eye view (BEV) scenarios and outperforms state-of-the-art results by ∼ 10 − 50%. We also show that different choices of non-parametric versus parametric target models in the CVAE directly influence the predicted multi-modal trajectory distributions. These results provide guidance on trajectory predictor design for robotic applications such as collision avoidance and navigation systems. Our code is available at: https://github.com/umautobots/ bidireaction-trajectory-prediction</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Understanding and predicting pedestrian movement behaviors is crucial for autonomous systems to safely navigate interactive environments. By correctly forecasting pedestrian trajectories, a robot can plan safe and socially-aware paths in traffic <ref type="bibr">[1]</ref>, <ref type="bibr">[2]</ref>, <ref type="bibr">[3]</ref>, <ref type="bibr">[4]</ref> and produce alarms about anomalous motions (e.g., crashes or near collisions) <ref type="bibr">[5]</ref>, <ref type="bibr">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>. Early work often assumed a deterministic future, where only one trajectory is predicted for each person given past observations <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>. However, pedestrians move with a high degree of stochasticity so multiple plausible and distinct future behaviors can exist <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>. Recent studies <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref> have shown predicting a distribution of multiple potential future trajectories (i.e., multi-modal prediction) rather than a single best trajectory can more accurately model future motions of pedestrians.</p><p>Recurrent neural networks (RNNs), notably long shortterm memory networks (LSTMs) and gated recurrent units (GRUs), have demonstrated success in trajectory prediction <ref type="bibr">[2]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>. However, existing models recurrently predict future trajectories based on previous output thus their performance tends to deteriorate rapidly over time (&gt; 560 ms) <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b23">[24]</ref>. We propose to address this problem with a novel goal-conditioned bi-directional trajectory predictor, named BiTraP. BiTraP first estimates future goals (end-points of the future trajectories) of pedestrians and then predicts trajectories by combining forward passing from current position and backward passing from estimated goals. We believe that predicting goals can improve longterm trajectory predictions, as pedestrians in real world often have desired goals and plan paths to reach these goals <ref type="bibr" target="#b24">[25]</ref>. Compared to existing goal-conditioned methods <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref> where goals were used as an input to a forward decoder, BiTraP takes goals as the starting position of a backward decoder and predicts future trajectories from two directions, thus mitigating the accumulated error over longer prediction horizons.</p><p>Recently, generative models such as the generative adversarial network (GAN) <ref type="bibr" target="#b12">[13]</ref> and conditional variational autoencoder (CVAE) <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b15">[16]</ref>, were developed to predict multi-modal distributions of future trajectories. Our BiTraP model predicts multi-modal trajectories based on CVAE which learns target future trajectory distributions conditioned on the observed past trajectories through a stochastic latent variable. The two most common forms of the latent variable follow either a Gaussian distribution or a categorical distribution, resulting in either a non-parametric target distribution <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b24">[25]</ref> or a parametric target distribution model such as a Gaussian Mixture Model (GMM) <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>. There has been limited research on how latent variable distributions impact predicted multi-modal trajectories. To fill this gap, we conducted extensive comparison studies using two variations of our BiTraP method: a non-parametric model using Gaussian latent variables (BiTraP-NP) and a GMM model using categorical latent variables (BiTraP-GMM). We implemented two types of loss functions, best-of-many (BoM) L2 loss <ref type="bibr" target="#b28">[29]</ref> and negative log-likelihood (NLL) loss <ref type="bibr" target="#b19">[20]</ref> to evaluate different predicted trajectory behaviors (e.g., spread and diversity). We show that latent variable distribution choices are closely related to the diversity of predicted distributions, which provides guidance for selecting trajectory predictors for robot navigation and collision avoidance systems.</p><p>The contributions of this work are summarized as follows. First, we developed a novel bi-directional trajectory predictor, BiTraP, based on multi-modal goal estimation and show it offers significant improvements on trajectory prediction performance especially for longer (≥ 2 seconds) prediction horizons. Second, we studied parametric versus non-parametric target modeling methods by presenting two variations of our model, BiTraP-NP and BiTraP-GMM, and compare their influence on the diversity of predicted distribution. Extensive experiments with both first person and bird's eye view datasets show the effectiveness of BiTraP models in different domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>Our BiTraP model consists of two parts: a multi-modal goal estimator and a goal-conditioned bi-directional trajectory predictor. This section describes related work in multimodal trajectory prediction and goal-conditioned prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CVAE-based Approaches for Multi-modal Trajectory</head><p>Prediction. Probabilistic approaches, particularly conditional variational autoencoder (CVAE) based models, have been developed for multi-modal trajectory prediction. Different from GANs <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b29">[30]</ref>, CVAEs can explicitly learn the form of a target distribution conditioned on past observations by learning the latent distribution from which it samples. Some CVAE methods assume the target trajectory follows a non-parametric (NP) distribution and produces multi-modal predictions by sampling from a Gaussian latent space. Lee et al. <ref type="bibr" target="#b15">[16]</ref> first used CVAE for multi-modal trajectory prediction by incorporating Gaussian latent space sampling to an long short-term memory encoder-decoder (LSTM-ED) model. CVAE with LSTM components has since been used in many applications <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b32">[33]</ref>. Other CVAEbased methods assume parametric trajectory distributions. Ivanovic et al. <ref type="bibr" target="#b18">[19]</ref> assumed the target trajectory follows a Gaussian Mixture Model (GMM) and designed a Trajectron network to predict GMM parameters using a spatio-temporal graph. Trajectron++ <ref type="bibr" target="#b19">[20]</ref> extended Trajectron to account for dynamics and heterogeneous input data. Our work extends existing CVAE models to include goal estimation and shows improved multi-modal prediction results. Our work also provides novel insights in comparisons between CVAE target distributions (NP and GMM).</p><p>Trajectory Conditioned on Goals. Incorporating goals has been shown to improve trajectory prediction. Rehder et al. <ref type="bibr" target="#b25">[26]</ref> proposed a particle-filter based method to estimate goal distribution as a prior for trajectory prediction. We drew inspiration from <ref type="bibr" target="#b33">[34]</ref>, which computed forward and backward rewards based on current position and goal; the path is planned using Inverse Reinforcement Learning (IRL). Our work is distinct due to its bi-directional temporal propagation and integration combined with a CVAE to achieve multi-modal prediction. Rhinehart et al. <ref type="bibr" target="#b26">[27]</ref> estimated multimodal semantic action as goals and planned conditioned trajectories using imitative models. Deo et al. <ref type="bibr" target="#b34">[35]</ref> used IRL to estimate goal states and fused results with past trajectory encodings to generate predictions. Most recently, Mangalam et al. <ref type="bibr" target="#b24">[25]</ref> designed a PECNet which showed state-of-the-art results on BEV trajectory prediction datasets. However, PECNet only concatenated past trajectory encod-ings and end-point encodings, which we believe did not fully take advantage of goal information. We have designed a bi-directional trajectory decoder in which current trajectory information is passed forward to the end-points (goals) and goals are recurrently propagated back to the current position. Experiment results show that our goal estimation can help generate more accurate trajectories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. BITRAP: BI-DIRECTIONAL TRAJECTORY PREDICTION WITH GOAL ESTIMATION</head><p>Our BiTraP model performs goal-conditioned multimodal bi-directional trajectory prediction in either firstperson view (FPV) or bird's eye view (BEV). Let X t = [X t−τ +1 , X t−τ +2 , ..., X t ] denote observed past trajectory at time t, where X t is bounding box location and size (x, y, w, h) in pixels for FPV <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref> and (x, y) position in meters for BEV <ref type="bibr" target="#b19">[20]</ref>. Given X t , we first estimate goal G t of the person then predict future trajectory</p><formula xml:id="formula_0">Y t = [Y t+1 , Y t+2 , ..., Y t+δ ],</formula><p>where τ and δ are observation and prediction horizons, respectively. Define goal G t = Y t+δ as the future trajectory endpoint, which is given in training and unknown in testing. We adopt a CVAE model to realize multi-modal goal and trajectory prediction. BiTraP contains four sub-modules: conditional prior network p θ (Z|X t ) to model latent variable Z from observations, recognition network q φ (Z|X t , Y t ) to capture dependencies between Z and Y t , goal generation network p ω (G t |X t , Z), and trajectory generation network p ψ (Y t |X t , G t , Z) where φ, θ, ω and ψ represent network parameters. Either parametric or nonparametric models can be used to design networks p ψ and p ω for CVAE. Non-parametric models do not assume the distribution format of target Y t but learn it implicitly by learning the distribution of Z. Parametric models assume a known distribution format for Y t and predict distribution parameters. We design non-parametric and parametric models in Sections III-A and III-B, and explain different loss functions to train these models in Sections III-C and III-D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. BiTraP with Non-parametric (NP) Distribution</head><p>BiTraP-NP is built on a standard recurrent neural network encoder-decoder (RNN-ED) based CVAE trajectory predictor as in <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b31">[32]</ref>, except it predicts goal first and then predict trajectories leveraging goals. Following previous work, we assume Gaussian latent variable Z ∼ N (µ Z , σ Z ) and a non-parametric target distribution format. <ref type="figure" target="#fig_0">Fig. 1</ref> shows the network architecture of BiTraP-NP.</p><p>Encoder and goal estimation. First, observed trajectory X t is processed by a gated-recurrent unit (GRU) encoder network to obtain encoded feature vector h t . In training, ground truth target Y t is encoded by another GRU yielding h Yt . Recognition network q φ (Z|X t , Y t ) takes h t and h Yt to predict distribution mean µ Zq and covariance Σ Zq which capture dependencies between observation and ground truth target. Prior network p θ (Z|X t ) assumes no knowledge about target and predicts µ Zp and Σ Zp using h t only. Kullback-Leibler divergence (KLD) loss between N (µ Zp , Σ Zp ) and N (µ Zq , Σ Zq ) is optimized so that dependency between Y t and X t is implicitly learned by the prior network. Latent variable Z is sampled from N (µ Zq , Σ Zq ) and concatenated with h t to predict multi-modal goalsĜ t with goal generation network p ω (G t |X t , Z). In testing, we directly draw multiple samples from N (µ Zp , Σ Zp ) and concatenate h t to predict estimated goalsĜ t . We use 3-layer multi-layer perceptrons (MLPs) for prior, recognition and goal generation networks.</p><p>Trajectory Decoder. Predicted goalsĜ t are used as inputs to a bi-directional trajectory generation network p ψ (Y t |X t ,Ĝ t , Z), the trajectory decoder, to predict multimodal trajectories. BiTraP's decoder contains forward and backward RNNs. The forward RNN is similar to a regular RNN decoder (Eq. (1)) except its output is not transformed to trajectory space. The backward RNN is initialized from encoder hidden state h t . It takes estimated goalŶ t+δ =Ĝ t as the initial input (Eq. (2)) and propagates from time t + δ to t + 1 so backward hidden state is updated from the goal to the current location. Forward and backward hidden states for the same time step are concatenated to predict the final trajectory way-point at that time (Eq. (3)). These steps can be formulated as</p><formula xml:id="formula_1">h f t+1 = GRU f (h f t , W i f h f t + b i f ),<label>(1)</label></formula><formula xml:id="formula_2">h b t+δ−1 = GRU b (h b t+δ , W i bŶt+δ + b i b ),<label>(2)</label></formula><formula xml:id="formula_3">Y t+δ−1 = W o f h f t+δ−1 + W o b h b t+δ−1 + b o ,<label>(3)</label></formula><p>where, f , b, i and o indicate "forward", "backward", "input" and "output" respectively, and h f t and h b t+δ are initialized by passing h t through two different fully-connected networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. BiTraP with GMM Distribution</head><p>Parametric models predict trajectory distribution parameters instead of trajectory coordinates. BiTraP-GMM is our parametric variation of BiTraP assuming a GMM for the trajectory goal and at each way-point <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref></p><formula xml:id="formula_4">. Let p(Y t+δ ) denote a K-component GMM at time step t + δ. We assume p(Y t+δ ) = K i=1 π i N (Y t+δ |µ i t+δ , Σ i t+δ ),</formula><p>where each Gaussian component can be considered the distribution of one trajectory modality. Mixture component weights π i sum to one, thus forming a categorical distribution. Each π i indicates the probability (confidence) that a person's motion belongs to that modality. We design latent vector Z as a categorical (Cat) variable Z ∼ Cat(K, π 1:K ) parameterized by GMM component weights π 1:K rather than separatelycomputed parameters. Similar to BiTraP-NP, we use three 3-layer MLPs for the prior, recognition and goal generation networks, and a bi-directional RNN decoder for the trajectory generation network. Instead of directly predicting trajectory coordinates, generation networks of BiTraP-GMM estimate the µ i t+δ and Σ i t+δ of the ith Gaussian components at time t + δ. In training, we sample one Z from each category to ensure all trajectory modalities are trained. In testing, we sample Z from Cat(K, π 1:K ) so it is more probable to sample from high-confidence trajectory modalities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Residual Prediction and BoM Loss for BiTraP-NP</head><p>Instead of directly predicting future location <ref type="bibr" target="#b22">[23]</ref> or integrating from predicted future velocity <ref type="bibr" target="#b19">[20]</ref>, BiTraP-NP predicts change with respect to the current location based on residualsŶ t+δ = Y t+δ − X t . There are two advantages of residual prediction. First, it assures the model will predict the trajectory starting from the current location, providing smaller initial loss than predicting location from scratch. Second, the residual target can be less noisy than the velocity target due to the fact that trajectory annotation is not always accurate. Standard CVAE loss includes NLL loss of the predicted distribution which is not applicable to NP methods due to their unknown distribution format. L2 loss between predictions and targets can be used as a substitution <ref type="bibr" target="#b15">[16]</ref>. To further encourage diversity in multi-modal prediction, we use best-of-many (BoM) L2 loss as in <ref type="bibr" target="#b28">[29]</ref>. The final loss function for BiTraP-NP is a combination of the goal L2 loss, the trajectory L2 loss and the KL-divergence loss between prior and recognition networks, written as</p><formula xml:id="formula_5">L N P = min i∈N G t − X t −Ĝ i t + min i∈N t+δ τ =t+1 Y τ − X t −Ŷ i τ + KLD,<label>(4)</label></formula><p>whereĜ t andŶ τ are the predicted goal and trajectory waypoints with respect to current position X t .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Bi-directional NLL Loss for BiTraP-GMM</head><p>Similar to <ref type="bibr" target="#b19">[20]</ref>, our BiTraP-GMM models the pedestrian velocity distribution as a GMM at each time step. The velocity GMM is then integrated forward to obtain the GMM distribution of trajectory waypoints Y t+δ as shown by blue blocks in <ref type="figure" target="#fig_1">Fig. 2</ref>. We assume linear dynamics for pedestrian and use a single integrator as in Eq. <ref type="bibr">(5)</ref>. The loss function is then the summation of negative log-likelihood (NLL) of the ground truth future waypoints over the prediction horizon, formulated as</p><formula xml:id="formula_6">GM M Y t+δ (π 1:K t+δ ,μ 1:K t+δ ,Σ 1:K t+δ ) = X t + t+δ t GM M vτ (π 1:K τ , µ 1:K τ , Σ 1:K τ )dτ,<label>(5)</label></formula><formula xml:id="formula_7">N LL f wd = t+δ τ =t − log p(Y τ |π 1:K τ ,μ 1:K τ ,Σ 1:K τ ),<label>(6)</label></formula><p>where</p><formula xml:id="formula_8">π 1:K τ , µ 1:K τ , Σ 1:K τ are velocity GMM parameters at time τ ∈ [t + 1, t + δ]</formula><p>, and the· symbol indicates location GMM parameters obtained from integration. p(·) is the GM M probability density function. Such an N LL emphasizes earlier waypoints along the prediction horizon because a waypoint at time t + 1 is used in integration results over t+2, t+3, ..., while these later waypoints are not used when computing t + 1. This goes against our proposed idea which is to leverage a bi-directional temporal model. Therefore, we compute bi-directional NLL loss with reverse integration from the goal, formulated as</p><formula xml:id="formula_9">GM M Yt (π 1:K t ,μ 1:K t ,Σ 1:K t ) = G t − t t+δ GM M vτ (π 1:K τ , µ 1:K τ , Σ 1:K τ )dτ,<label>(7)</label></formula><formula xml:id="formula_10">N LL bwd = t τ =t+δ − log p (Y τ |π 1:K τ ,μ 1:K τ ,Σ 1:K τ ).<label>(8)</label></formula><p>where p(·) is the backward GM M probability density function, the· symbol indicates backward location GMM parameters. The final loss function for BiTraP-GMM can be written as</p><formula xml:id="formula_11">L GM M = − log p G (G t |π 1:K G ,μ 1:K G ,Σ 1:K G ) + N LL f wd + N LL bwd + KLD,<label>(9)</label></formula><p>where the first term is N LL loss of the goal estimation, N LL f wd and N LL bwd are computed from forward and backward integration, the KLD term is the KL-divergence similar to Eq. (4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS AND RESULTS</head><p>In this section, we empirically evaluate BiTraP-NP and BiTraP-GMM models on both first-person view (FPV) and bird's eye view (BEV) trajectory prediction datasets. We also provide a comparative study and discussion on the effects of model and loss selection.</p><p>Datasets. Two FPV datasets, Joint Attention for Autonomous Driving (JAAD) <ref type="bibr" target="#b35">[36]</ref> and Pedestrian Intention Estimation (PIE) <ref type="bibr" target="#b22">[23]</ref>, and two benchmark BEV datasets, ETH <ref type="bibr" target="#b36">[37]</ref> and UCY <ref type="bibr" target="#b37">[38]</ref>, were used in our experiments. JAAD contains 2,800 pedestrian trajectories captured from dash cameras annotated at 30Hz. PIE contains 1,800 pedestrian trajectories also annotated at 30Hz, with longer trajectories and more comprehensive annotations such as semantic intention, ego-motion and neighbor objects. ETH-UCY datasets contain five sub-datasets captured from downfacing surveillance cameras in four different scenes with 1,536 pedestrian trajectories annotated at 2.5Hz. Implementation Details. We used the standard training/testing splits of JAAD and PIE as in <ref type="bibr" target="#b22">[23]</ref>. A 0.5-second (15 frame) observation length and 1.5-second (45 frame) prediction horizon were used for evaluation. For ETH-UCY, a standard leave-one-out approach based on scene was used per <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b19">[20]</ref>. We observed trajectories for 3.2 seconds (8 frames) and predicted the paths for the next 4.8 seconds (12 frames). We used hidden size 256 for all encoders and decoders in BiTraP across all datasets. All models were trained with batch size 128, learning rate 0.001, and an exponential LR scheduler <ref type="bibr" target="#b19">[20]</ref> on a single NVIDIA TITAN XP GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Experiments on JAAD and PIE Datasets</head><p>Baselines. We compare our results against the following baseline models: 1) Linear Kalman filter, 2) Vanilla LSTM model, 3) Bayesian-LSTM model (B-LSTM) <ref type="bibr" target="#b38">[39]</ref>, 4) PIE traj , an attentive RNN encoder-decoder model, 5) PIE f ull , a multi-stream attentive RNN model, by injecting ego-motion and semantic intention stream to PIE traj , and 6) FOL-X <ref type="bibr" target="#b21">[22]</ref>, a multi-stream RNN encoder-decoder model using residual prediction. We also conducted an ablation study for a deterministic variation of our model (BiTraP-D), where the multi-modal CVAE module was removed.</p><p>Evaluation Metrics. Following <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b38">[39]</ref>, our BiTraP model was evaluated using: 1) bounding box Average Displacement Error (ADE), 2) box center ADE (C ADE ) and 3) box center Final Displacement Error (C F DE ) in squared pixels. For our multi-modal BiTraP-NP and BiTraP-GMM, we compute the best-of-20 results (the minimum ADE and FDE from 20 randomly-sampled trajectories), following <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b39">[40]</ref>. We also report the Kernel Density Estimation-based Negative Log Likelihood (KDE-NLL) metric for BiTraP-NP and BiTraP-GMM, which evaluates the NLL of the ground truth under a distribution fitted by a KDE on 2000 trajectory samples from each prediction model <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b40">[41]</ref>. For all metrics, lower values are better.</p><p>Results. <ref type="table" target="#tab_0">Table I presents</ref>    based only on past trajectory information, also outperforms the state-of-the-art PIE f ull , which requires additional egomotion and semantic intention annotations. <ref type="table" target="#tab_0">Table I also</ref> shows that non-parametric multi-modal method BiTraP-NP performs better on displacement metrics while parametric method BiTraP-GMM performs better on the N LL metric. This difference illustrates the objectives of these methods: BiTraP-NP generates diverse trajectories, and one trajectory was optimized to have minimum displacement error, while BiTraP-GMM generates trajectory distributions with more similarity to the ground truth trajectory. <ref type="figure" target="#fig_2">Fig. 3</ref> shows trajectory prediction results on sample frames from the PIE dataset. We observed that when a pedestrian intends to cross the street or change directions, the multimodal BiTraP methods yield higher accuracy and more reasonable predictions than the deterministic variation. For example, as shown in <ref type="figure" target="#fig_2">Fig. 3(b)</ref>, the deterministic BiTraP-D model (top row) can fail to predict the trajectory and the   end-goal, where a pedestrian intends to cross the street in the future; the multi-modal BiTraP-NP model (bottom row) can successfully predict multiple possible future trajectories, including one where the pedestrian is crossing the street matching ground truth intention. Similar observations can be made in other frames. This result indicates multi-modal BiTraP-NP can predict multiple possible futures, which could help a mobile robot or a self-driving car safely yield to pedestrians. Although BiTraP-NP samples diverse trajectories, it still predicts distribution with high likelihood around ground truth targets and low likelihood in other locations as shown in <ref type="figure" target="#fig_2">Fig. 3(b)-3(d)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Experiments on ETH-UCY Datasets</head><p>Baselines. We compare our methods with five multimodal baseline methods: S-GAN <ref type="bibr" target="#b12">[13]</ref>, SoPhie <ref type="bibr" target="#b39">[40]</ref>, S-BiGAT <ref type="bibr" target="#b29">[30]</ref>, PECNet <ref type="bibr" target="#b24">[25]</ref> and Trajectron++ <ref type="bibr" target="#b19">[20]</ref>. PEC-Net and Trajectron++ are most recent. PCENet is a goalconditioned method using non-parametric distribution (thus directly comparable to our BiTraP-NP) while Trajectron++ uses a GMM trajectory distribution directly comparable to our BiTraP-GMM. Note that the baselines incorporated social information while our method focuses on investigating goal-based trajectory modeling and do not require extra input such as social or scene information.</p><p>Evaluation Metrics. Following <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b39">[40]</ref>, we used best-of-20 trajectory ADE and FDE in meters as evaluation metrics. We also report Average and Final KDE-NLL (ANLL and FNLL) metrics on 2000 sampled trajectories <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b19">[20]</ref> to evaluate the predicted trajectory and goal distribution.</p><p>Results. <ref type="table" target="#tab_0">Table II</ref> shows the best-of-20 ADE/FDE results across all methods. We observed that BiTraP-NP outperforms the state-of-the-art goal based method (PECNet) by a large margin (∼ 12% − 51%), demonstrating the effectiveness of our bi-directional decoder module. BiTraP-NP also obtains lower ADE/FDE on most scenes (∼ 12%-24% improvement) compared with Trajectron++. Our BiTraP-GMM model was trained using NLL loss, so it shows higher ADE/FDE results compared with BiTraP-NP. This is consistent with our FPV dataset observations in Section IV-A. Nevertheless, BiTraP-GMM still achieves similar or better results than PECNet and Trajectron++.</p><p>To further evaluate predicted trajectory distributions, we report KDE-NLL results in <ref type="table" target="#tab_0">Table III</ref>. As shown, BiTraP-GMM outperforms Trajectron++ with lower ANLL and FNLL on ETH, Univ, Zara1 and Zara2 datasets. On Hotel, Trajectron++ achieves lower NLL values which may be due to the possible higher levels of inter-personal interactions  than in other scenes. We observed improved ANLL/FNLL on Hotel (-1.88/0.27) when combining the BiTraP-GMM decoder with the interaction encoder in <ref type="bibr" target="#b19">[20]</ref>, consistent with our hypothesis. <ref type="figure" target="#fig_3">Fig. 4</ref> shows qualitative examples of our predicted trajectories using the BiTraP-NP and BiTraP-GMM models. As shown, BiTraP-NP (top row) generates future possible trajectories with a wider spread (more diverse), while BiTraP-GMM generates more compact distributions. This is consistent with our quantitative evaluations as reported in <ref type="table" target="#tab_0">Table III</ref>, where the lower NLL results of BiTraP-GMM correspond to more compact trajectory distributions. We also computed KDE-NLL results for both Trajec-tron++ and BiTraP-GMM methods at each time step to ana-lyze how BiTraP affects both short-term and longer-term (up to 4.8 seconds) prediction results. Per <ref type="figure" target="#fig_4">Fig. 5</ref>, BiTraP-GMM outperforms Trajectron++ with longer prediction horizons (after 1.2 seconds on ETH, Univ, Zara1, and Zara2). This shows the backward passing from the goal helps reduce error with longer prediction horizon.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Additional Experiments</head><p>Ablation study. We conducted two ablation experiments. Computational time. We provide model inference time of Social GAN <ref type="bibr" target="#b12">[13]</ref>, Trajectron++ <ref type="bibr" target="#b19">[20]</ref> and our BiTraP-NP and BiTraP-GMM models in <ref type="table" target="#tab_4">Table V</ref>. Trajectron++ generates scene graphs before running the model so computation time is summed over scene graph generation and model inference. For Social GAN and our method, total time consists of model inference time only. We show computational times for number of samples 20 and 2000. Time differences of BiTraP models between the two numbers are ∼ 3ms, while the difference of S-GAN is extremely large as it generates samples one-by-one. BiTraP-GMM is ∼ 3ms slower than Trajectron++, not significant since both methods run at ∼ 70ms per frame (∼ 14 FPS) on average. BiTraP-NP is about 8x faster than Trajectron++ and BiTraP-GMM since it does not fit a GMM model or perform dynamic integration. Adding the bi-directional decoder slows inference by ∼ 3ms (TraP-NP vs BiTraP-NP). All experiments are conducted on the same machine used for training.</p><p>Robot Navigation Simulation Experiment. To intuitively present model performance in robot navigation, we conducted a robot navigation simulation experiment on the ETH-UCY dataset. We observed that a robot equipped with the BiTraP-NP predictor is more sensitive to potential collisions as it predicts diverse distributions of surrounding pedestrians.</p><p>On the other hand, a robot equipped with BiTraP-GMM predictor reports less false alarm when navigating among pedestrians and, thus, being more efficient. Experimental details can be found in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>We presented BiTraP, a bi-directional multi-modal trajectory prediction method conditioned on goal estimation. We demonstrated that our proposed model can achieve state-ofthe-art results for pedestrian trajectory prediction on both first-person view and bird's eye view datasets. The current BiTraP models, with only observed trajectories as inputs, already surpass previous methods which required additional ego-motion, semantic intention, and/or social information. By conducting a comparative study between non-parametric (BiTraP-NP) and parametric (BiTraP-GMM) models, we observed that the different latent variable choice affects the diversity of target distributions of future trajectories. We hypothesized that such difference in predicted distribution directly influences the collision rate in robot path planning and showed that collision metrics can be used to guide predictor selection in real world applications. For future work, we plan to incorporate scene semantics and social components to further boost the performance of each module. We are also interested in using predicted goals and trajectories to infer and interpret pedestrian intention and actions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. CVAE PRELIMINARIES</head><p>A Conditional Variation Autoencoder (CVAE) is a conditional generative model designed to output target data Y based on latent variable Z and observation X <ref type="bibr">[1]</ref>. A CVAE consists of three modules: a conditional prior network p θ (Z|X) to model latent variable Z conditioned on observation X, a recognition network q φ (Z|X, Y ) to capture dependencies between Z and target Y , and a generation network p ψ (Y |X, Z) to generate the target Y , where φ, θ, and ψ represent network parameters. Stochastic latent variable Z ∈ R d is sampled from a pre-defined distribution format such as a Gaussian distribution. The CVAE samples Z and generates target Y conditioned on observation X. The objective of a typical CVAE model is to maximize its variational lower bound</p><formula xml:id="formula_12">max θ,φ,ψ E q φ (Z|X,Y ) log p ψ (Y |X, Z) − KL q φ (Z|X, Y )||p θ (Z|X) ,<label>(1)</label></formula><p>where the first term maximizes the expectation of the loglikelihood of the target in the predicted distribution; the K-L (Kullback-Leibler) divergence term minimizes the difference between the recognition network and the conditional prior network. In this paper, we designed a modified CVAE with two generation networks and optimize both networks endto-end.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. ROBOT NAVIGATION SIMULATION EXPERIMENT USING BITRAP</head><p>To quantitatively analyze application of the BiTraP-GMM and BiTraP-NP models to robot navigation tasks, we designed a simulated robot navigation experiment based on the ETH-UCY bird's-eye view dataset. In this experiment, given predicted pedestrian trajectory distributions in a scene using our BiTraP models and pre-planned paths for a robot, we show that we are able to compute the collision likelihood for each path, and thus are able to predict collision rate and select the safest path for the robot. Assuming a mobile robot navigates among pedestrians, we present results on two tasks: 1) Select the safest path for the robot and 2) Predict whether a path will collide with any other pedestrians in the scene. In this section, we first introduce our experiment setup. Then, we present evaluation results of our BiTraP models on path selection and collision prediction tasks.</p><p>Experimental Setup. We selected all samples with more than one pedestrian in the test split <ref type="bibr">[2]</ref> from ETH-UCY.  Each sample has a node pedestrian (the pedestrian used for testing in previous work) and several neighbor pedestrians (the pedestrians used for social modeling in previous work) as in <ref type="bibr">[2]</ref>, <ref type="bibr">[3]</ref>. We regard the node pedestrian as a "robot" navigating among other neighbor pedestrians. The starting and goal points of the "robot" are the same as the current position and goal point of the node pedestrian. A sample scene with one "robot" navigating among four other pedestrians is shown in <ref type="figure" target="#fig_0">Fig. 1</ref>. For the robot, 100 Monte Carlo (MC) paths were generated from start state to end point following quadratic and cubic Bezier curves <ref type="bibr">[4]</ref>. Other more complex path planners could be used to generate additional experimental datasets. We assume the robot must reach the designated goal in 12 time steps, matching the prediction horizon for the pedestrian node in each scene. We uniformly generate waypoints along the path and randomly shift each by up to ±50% of the step length, resulting in a trajectory sequence containing 12 random waypoints. Other pedestrians follow their original (ground truth) trajectories in the scene. For each neighbor pedestrian, we run BiTraP-NP and BiTraP-GMM separately. Each method samples 2000 future trajectories to fit one Gaussian Kernel Density Estimation (KDE) model for each pedestrian as the predicted future distribution. Then, we compute the maximum KDE log-likelihood of all the waypoints on all robot MC paths and treat this log-likelihood value as a collision score. The higher the collision score, the more likely a collision will happen along this path. Given these collision scores, we compute the safest path collision rate (SPCR) as reported in Task 1 below. Receiver operating characteristic (ROC) and precision-recall (P-R) curve results are reported in Task 2.</p><p>Task 1: Predict the Safest Path. We mark the robot MC path in each scene with minimum collision score as the "safest" (lowest collision likelihood) path. Then, we compute Euclidean distances between each safest path waypoint and other pedestrians' ground truth future trajectories. A collision is tallied if the minimum distance between a path and any pedestrians in the scene is less than 0.2 meters. Collision rate is computed as the number of paths with collision divided by the total number of safest paths. Due to the randomness in MC path generation, we conducted the simulation experiment five times with BiTraP-NP and BiTraP-GMM predictors separately and report collision rate mean (µ) and standard deviation (σ) values in <ref type="table" target="#tab_0">Table I</ref>. As a comparison, we also present the collision rate of a randomly selected path among the 100 MC paths. The randomly selected paths do not have very high collision rates since the paths are planned based on pedestrian ground truth start and goal positions which are less likely to be involved in a collision. Compare to randomly selected paths, paths selected by our methods reduce the SPCR by a large margin. This shows that our predictors are effective for safest path selection. Both of our BiTraP methods achieve collision rate lower than 1% on ETH, Hotel and Zara1 datasets. The Univ dataset is more difficult due to its high pedestrian density, and Zara2 is most difficult because many pedestrian trajectories are quite close to each other. BiTraP-GMM shows lower SPCRs than BiTraP-NP on four datasets, indicating that it predicted more accurate (compared to ground truth) distributions. On Zara1, BiTraP-NP outperforms BiTraP-GMM by a small margin. BiTraP-NP ANLL and FNLL metric values as reported in the main paper are still higher than BiTraP-GMM values. A possible explanation is that BiTraP-NP predicts more diverse distributions thus detects some collisions not identified by BiTraP-GMM. Task 2: Predict Collision for Any Path. The collision rate metric above only evaluates the safest path as selected by a trajectory predictor thus neglects all other paths. In the realworld, a trajectory predictor must be sufficiently accurate for the robot to accurately predict future collisions with high precision with a low missing rate (high true positive rate, TPR) and a low false alarm rate (low false positive rate, FPR). To show the performance of BiTraP-NP and BiTraP-GMM predictors in terms of these metrics, we plotted the collision prediction ROC curve and P-R curve as follows. First, we collected all MC paths for the robot and tallied their collision scores. By setting a threshold γ, we can classify a path as collided (positive) or not collided (negative) and</p><p>Method KDE NLL FDE ML @1s @2s @3s @4s @1s @2s @3s @4s  compute the TPR (i.e., recall), FPR and precision values. The ground truth label of each path is computed in the same way as before. By decreasing γ from a maximum value to minimum value (6 and -10 in this work), we plot the ROC and P-R curves shown in <ref type="figure" target="#fig_1">Fig. 2</ref>. The corresponding area under curve (AUC) and average precision (AP) are presented in <ref type="table" target="#tab_0">Table I</ref>. In this work, AP is computed by equally spaced recall levels {1/40, 2/40,...,1} following <ref type="bibr">[5]</ref>. As shown in <ref type="figure" target="#fig_1">Fig. 2</ref> and <ref type="table" target="#tab_0">Table I</ref>, both BiTraP-NP and BiTraP-GMM methods achieve high AUCs (e.g., &gt; 90 on ETH). Generally, BiTraP-GMM outperforms BiTraP-NP by a small margin in terms of both AUC and AP (e.g., 95.5 vs 92.3 AUC, and 26.0 vs 24.2 AP on ETH). Note that in realworld mobile robot applications missed collision detection (false negative) is unacceptable due to safety. That is to say, a high TPR (recall) is required. As can be observed in the higher TPR regions (x-axis) of the P-R curves, BiTraP-GMM outperforms BiTraP-NP on ETH <ref type="figure" target="#fig_1">(Fig. 2(a)</ref>) and Hotel <ref type="figure" target="#fig_1">(Fig. 2(b)</ref>), and both methods perform similarly on Zara1 <ref type="figure" target="#fig_1">(Fig. 2(d)</ref>). On Univ <ref type="figure" target="#fig_1">(Fig. 2(c)</ref>) and Zara2 <ref type="figure" target="#fig_1">(Fig. 2(e)</ref>), when the TPR is greater than a relatively high value (say 0.8), the FPR are higher (&gt; 0.2) than in the other datasets, indicating increased chance of false alarms on these two datasets.</p><p>Compared to the ROC curve, the P-R curve is more suitable for imbalanced datasets due to the fact that it evaluates the fraction of true positives among positive predictions. This fits our case where the ratio of with-collision to no-collision paths is around 1:140, a large imbalance. On Univ and Zara2 <ref type="figure" target="#fig_1">(Fig. 2</ref>(c) and 2(e)), BiTraP-GMM has higher precision than BiTraP-NP across almost all recall values. On the other hand, on ETH, Hotel and Zara1 <ref type="figure" target="#fig_1">(Fig. 2</ref>(a) 2(b) and 2(d)), the two methods achieve similar precision at higher recall regions (e.g., when recall&gt; 0.6). This is because when the threshold γ is too low, many paths are predicted as collided by both methods.</p><p>The ROC and P-R curves also verified our observation regarding the diversity of the predicted trajectory distribution as described in the main paper. At a fixed TPR on the ROC curves, we observe that BiTraP-NP always has a greater FPR than BiTraP-GMM, consistent with our hypothesis that BiTraP-NP predicts more diverse distributions, thus predicts more false alarms. Similarly, with fixed recall in P-R curves, BiTraP-NP has lower precision due the greater number of false alarms.</p><p>In summary, this simulated robot collision experiment demonstrated our proposed BiTraP trajectory predictor can be used in future robotic applications, such as predicting collisions and selecting safest paths in robot navigation tasks.</p><p>Results from this supplementary experiment are consistent with our main paper's observations and further verify our hypothesis regarding the diversity/compactness of predicted trajectory distributions, i.e., BiTraP-NP predicts more diverse distributions while BiTraP-GMM predicts more compact distributions. The SPCR, ROC (AUC) and P-R (AP) metrics used in this experiment act as a supplement to the currently reported and widely used ADE/FDE and KDE-NLL metrics in the main paper. We believe these additional metrics and experiments offer an intuitive and complementary performance evaluation of the two proposed BiTraP models (NP and GMM) and their applications for tasks such as collision prediction and path selection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. EXPERIMENT AND RESULT ON NUSCENES DATASET</head><p>Among the datasets we have evaluated on, JAAD and PIE are first-person view only while ETH and UCY are focusing on campus or sidewalks only. To further present the performance of BiTraP in bird's eye view autonomous driving scenarios, we evaluate on the nuScenes dataset <ref type="bibr">[6]</ref>. The nuScenes dataset contains trajectories collected from 850 scenes, 700 for training and 150 for testing <ref type="bibr">[6]</ref>. We followed <ref type="bibr">[3]</ref> to extract training and testing trajectories and trained our model using the same configurations as in ETH-UCY experiment. Note that we treat the pedestrian position at 4 seconds in the future as the target of our goal or endpoint during training.</p><p>Evaluation metrics. To be comparable with <ref type="bibr">[3]</ref>, the mostlikely (ML) prediction is used to compute the final displacement error (FDE). We also use the kernel density estimation negative log-likelihood (KDE NLL) as in our other experiments. <ref type="bibr">Method</ref> FDE ML @1s @2s @3s @4s  Results. As can be seen in <ref type="table" target="#tab_0">Table II</ref>, adding dynamic integration and map encoding to the base Trajectron++ improved the distribution accuracy by a large margin but does not affect the FDE ML, indicating similar modes but smaller variances of the predicted distributions. Trajectron++ based methods used interactions and/or encoded map as inputs while our BiTraP-GMM only takes target pedestrians past trajectory. As in <ref type="table" target="#tab_0">Table II</ref>, BiTraP-GMM improves the KDE-NLL at all evaluated time steps and also improves FDE after 2 seconds, showing how does the bi-directional strategy improves prediction accuracy. Note that the Trajectron++ benchmark lacks a ablation with integration but not map encoding (e.g. Trajectron++ ) to show the necessity of map. However, our experiment shows that map may not be a very important information when predicting pedestrian trajectories on nuScenes dataset since BiTraP-GMM outperforms "Trajectron++ , map".</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Overview of our BiTraP-NP network. Red, blue and black arrows show processes that appear in training only, inference only, and both training and inference, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>trajectory prediction results with JAAD and PIE datasets. Our deterministic BiTraP-D model shows consistently lower displacement errors across various prediction horizons than baseline methods such as PIE traj and FOL-X indicating our goal estimation and bi-directional prediction modules are effective. Our BiTraP-D model, Latent space sampling and decoder modules of BiTraP-GMM. The ellipse shows one of K GMM components at each timestep. The rest of the network is the same as BiTraP-NP inFig. 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 :</head><label>3</label><figDesc>Qualitative results of deterministic (top row) vs multi-modal (bottom row) bi-directional prediction. Past (dark blue), ground truth future (red) and predicted future (green) trajectories and final bounding box locations are plotted. In the bottom row, each BiTraP-NP likelihood heatmap fits a KDE over samples. The orange color indicates higher probability.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 :</head><label>4</label><figDesc>Visualizations of BiTraP-NP (first row) and BiTraP-GMM (second row). Twenty sampled future trajectories are plotted. For BiTraP-GMM, we also plot end-point GMM distributions as colored ellipses. Size indicates component Σ k and transparency indicates component weight π k .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 :</head><label>5</label><figDesc>KDE-NLL results on the ETH-UCY dataset per timestep up to 4.8 seconds.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>To show bi-directional decoder effectiveness, we removed the backward decoder from BiTraP-NP and compared its performance with the original BiTraP-NP model (w/o backward (TraP-NP) vs w/ backward). To show bi-directional loss effectiveness in BiTraP-GMM, we compared two BiTraP-GMM models trained with forward loss and bi-directional loss (w/o bi-loss vs w/ bi-loss). A comparison of ADE/FDE and ANLL/FNLL results is presented in Table IV. Using a bi-directional decoder (BiTraP-NP) improves ADE/FDE by 10%-28% (ANLL/FNLL by ∼0.4) from the model without backward decoder. By using bi-directional loss (bi-loss), the ADE/FDE of BiTraP-GMM model improves by 5-18% on ETH, and ANLL/FNLL improves by ∼0.25.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>*</head><label></label><figDesc>{brianyao, ematkins, mattjr, ramv, xiaodu}@umich.edu</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 1 :</head><label>1</label><figDesc>Generation of Monte Carlo (MC) robot trajectories for collision detection experiments using Bezier curves. We illustrate five MC trajectory samples including start (robot icon) and end (red star) waypoints. Predicted trajectory distributions of neighbor pedestrians are plotted as a heat map; their walking directions are indicated by black arrows.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 2 :</head><label>2</label><figDesc>ROC (left) and P-R (right) curves of BiTraP-NP and BiTraP-GMM on ETH dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I :</head><label>I</label><figDesc>Results on JAAD and PIE datasets. The center row shows deterministic baselines including our ablation model BiTraP-D; the bottom row shows our proposed multi-modal methods. NLL is not available for deterministic methods since they predict single trajectories. Lower values are better.</figDesc><table><row><cell>Methods</cell><cell>ADE (0.5/1.0/1.5s)</cell><cell>JAAD C ADE (1.5s)</cell><cell>C F DE (1.5s)</cell><cell>N LL</cell><cell>ADE (0.5/1.0/1.5s)</cell><cell>PIE C ADE (1.5s)</cell><cell>C F DE (1.5s)</cell><cell>N LL</cell></row><row><cell>Linear [23] LSTM [23] B-LSTM [39] FOL-X [22] PIEtraj [23] PIE f ull [23]</cell><cell>233/857/2303 289/569/1558 159/539/1535 147/484/1374 110/399/1280 -</cell><cell>1565 1473 1447 1290 1183 -</cell><cell>6111 5766 5615 4924 4780 -</cell><cell>------</cell><cell>123/477/1365 172/330/911 101/296/855 47/183/584 58/200/636 -/-/556</cell><cell>950 837 811 546 596 520</cell><cell>3983 3352 3259 2303 2477 2162</cell><cell>------</cell></row><row><cell>BiTraP-D BiTraP-NP (20) BiTraP-GMM (20)</cell><cell>93/378/1206 38/94/222 153/250/585</cell><cell>1105 177 501</cell><cell>4565 565 998</cell><cell>-18.9 16.0</cell><cell>41/161/511 23/48/102 38/90/209</cell><cell>481 81 171</cell><cell>1949 261 368</cell><cell>-16.5 13.8</cell></row><row><cell>(a)</cell><cell></cell><cell>(b)</cell><cell></cell><cell></cell><cell>(c)</cell><cell></cell><cell></cell><cell>(d)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II :</head><label>II</label><figDesc>Trajectory prediction results (ADE/FDE) on BEV ETH-UCY datasets. Lower is better.</figDesc><table><row><cell>Datasets</cell><cell>S-GAN [13]</cell><cell>SoPhie [40]</cell><cell>S-BiGAT [30]</cell><cell>PECNet [25]</cell><cell>Trajectron++ [20]</cell><cell cols="2">BiTraP-NP BiTraP-GMM</cell></row><row><cell>ETH Hotel Univ Zara1 Zara2</cell><cell>0.81/1.52 0.72/1.61 0.60/1.26 0.34/0.69 0.42/0.84</cell><cell>0.70/1.43 0.76/1.67 0.54/1.24 0.30/0.63 0.38/0.78</cell><cell>0.69/1.29 0.49/1.01 0.55/1.32 0.30/0.62 0.36/0.75</cell><cell>0.54/0.87 0.18/0.24 0.35/0.60 0.22/0.39 0.17/0.30</cell><cell>0.43/0.86 0.12/0.19 0.22/0.43 0.17/0.32 0.12/0.25</cell><cell>0.37/0.69 0.12/0.21 0.17/0.37 0.13/0.29 0.10/0.21</cell><cell>0.40/0.74 0.13/0.22 0.19/0.40 0.14/0.28 0.11/0.22</cell></row><row><cell>Average</cell><cell>0.58/1.18</cell><cell>0.54/1.15</cell><cell>0.48/1.00</cell><cell>0.29/0.48</cell><cell>0.21/0.39</cell><cell>0.18/0.35</cell><cell>0.19/0.37</cell></row><row><cell cols="2">(a) Hotel</cell><cell></cell><cell>(b) Univ</cell><cell></cell><cell>(c) Zara2</cell><cell></cell><cell>(d) ETH</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE III</head><label>III</label><figDesc></figDesc><table><row><cell>Datasets</cell><cell cols="2">S-GAN [13] Trajectron++ [19]</cell><cell cols="2">BiTraP-NP BiTraP-GMM</cell></row><row><cell>ETH Hotel Univ Zara1 Zara2</cell><cell>15.70/-8.10/-2.88/-1.36/-0.96/-</cell><cell>1.31/4.28 -1.94/0.25 -1.13/2.13 -1.41/1.83 -2.53/0.50</cell><cell>3.80/3.79 -0.41/1.26 -0.84/2.15 -0.81/1.85 -1.89/1.31</cell><cell>0.96/3.55 -1.60/0.51 -1.19/2.03 -1.51/1.56 -2.54/0.38</cell></row></table><note>: Average-NLL/Final-NLL (ANLL/FNLL) results on ETH-UCY datasets. Lower is better.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE IV :</head><label>IV</label><figDesc>Ablation study results (ADE/FDE and ANLL/FNLL). Lower is better.</figDesc><table><row><cell>Method</cell><cell>BiTraP-NP w/o backward (TraP-NP)</cell><cell cols="2">w/ backward</cell><cell cols="2">w/o bi-loss</cell><cell>BiTraP-GMM</cell><cell>w/ bi-loss</cell></row><row><cell>ETH Hotel Univ Zara1 Zara2</cell><cell cols="2">ADE/FDE ANLL/FNLL ADE/FDE 0.44/0.96 4.20/4.45 0.37/0.69 0.13/0.23 -0.17/1.64 0.12/0.21 0.21/0.43 -0.21/2.78 0.17/0.37 0.15/0.31 -0.37/2.27 0.13/0.29 0.12/0.23 -1.70/1.54 0.10/0.21</cell><cell>ANLL/FNLL 3.80/3.79 -0.41/1.26 -0.84/2.15 -0.81/1.85 -1.89/1.31</cell><cell>ADE/FDE 0.43/0.80 0.16/0.25 0.20/0.41 0.19/0.35 0.13/0.25</cell><cell cols="2">ANLL/FNLL ADE/FDE 1.11/3.81 0.40/0.74 -1.32/0.80 0.13/0.22 -1.16/2.06 0.19/0.40 -0.90/2.12 0.14/0.28 -2.38/0.64 0.11/0.22</cell><cell>ANLL/FNLL 0.96/3.55 -1.60/0.51 -1.19/2.03 -1.51/1.56 -2.54/0.38</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE V :</head><label>V</label><figDesc>Computational times with 20/2000 samples.</figDesc><table><row><cell>Method</cell><cell>Scene Graph</cell><cell>Model inference</cell><cell>Total</cell></row><row><cell>S-GAN[13] Trajectron++[20]</cell><cell>N/A 11ms</cell><cell>103/10445 ms 55/58 ms</cell><cell>103/10300 ms 66/69 ms</cell></row><row><cell>TraP-NP BiTraP-NP BiTraP-GMM</cell><cell>N/A N/A N/A</cell><cell>5.3/5.9 ms 8.3/9.1 ms 69/72ms</cell><cell>5.3/5.9 ms 8.3/9.1 ms 69/72ms</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE I :</head><label>I</label><figDesc>SPCR(µ±σ), AUC and AP results of our methods on ETH-UCY data group.</figDesc><table><row><cell></cell><cell>Random from 100 (SPCR)</cell><cell>BiTraP-NP (SPCR/AUC/AP)</cell><cell>BiTraP-GMM (SPCR/AUC/AP)</cell></row><row><cell>ETH HOTEL Univ Zara1 Zara2</cell><cell>0.6 ± 0.4% 0.4 ± 0.3% 8.5 ± 1.4% 2.4 ± 0.5% 6.1 ± 0.6%</cell><cell>0.3 ± 0.1%/ 92.3/ 24.2 0.1 ± 0.1%/ 86.4/ 22.4 5.8 ± 0.5%/ 81.0/ 33.4 0.6 ± 0.2%/ 88.9/ 38.6 3.2 ± 0.1%/ 81.0/ 44.0</cell><cell>0.1 ± 0.1%/ 95.5/ 26.0 0.0 ± 0.0%/ 91.6/ 29.1 3.6 ± 0.2%/ 87.6/ 43.4 0.8 ± 0.3%/ 90.4/ 41.6 2.5 ± 0.3%/ 87.5/ 52.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE II :</head><label>II</label><figDesc>Pedestrian-only trajectory prediction results on nuScenes dataset.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>TABLE III :</head><label>III</label><figDesc>Vehicle-only trajectory prediction results on nuScenes dataset.</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Social lstm: Human trajectory prediction in crowded spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Robicquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Peeking into the future: Predicting future person activities and locations in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Niebles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Hauptmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Dynamic probabilistic drivability maps for lane change and merge driver assistance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sivaraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Intell. Transp. Syst</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2063" to="2073" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Gametheoretic modeling of multi-vehicle interactions at uncontrolled intersections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kolmanovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Atkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Girard</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.05423</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning regularity in skeleton trajectories for anomaly detection in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Morais</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mansour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Venkatesh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Unsupervised traffic accident detection in first-person videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Crandall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Atkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IROS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Atkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Crandall</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.03044</idno>
		<title level="m">When, where, and what? a new dataset for anomaly detection in driving videos</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The smart black box: A value-driven automotive event data recorder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Atkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in ITSC</title>
		<imprint>
			<biblScope unit="page" from="973" to="978" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The smart black box: A value-driven high-bandwidth automotive event data recorder</title>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Intell. Transp. Syst</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A new approach to linear filtering and prediction problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Kalman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. basic Engineering</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="35" to="45" />
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Social force model for pedestrian dynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Helbing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Molnar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical review E</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">4282</biblScope>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Gaussian processes for machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Rasmussen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>MIT press</publisher>
			<biblScope unit="volume">2</biblScope>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Social GAN: Socially acceptable trajectories with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Recurrent network models for human dynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fragkiadaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Felsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Real-time certified probabilistic pedestrian forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">O</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">K</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Johnson-Roberson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vasudevan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robot. Autom. Lett</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2064" to="2071" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Desire: Distant future prediction in dynamic scenes with interacting agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vernaza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">B</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Stochastic sampling simulation for pedestrian trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Johnson-Roberson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IROS</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4236" to="4243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Multipath: Multiple probabilistic anchor trajectory hypotheses for behavior prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sapp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.05449</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The trajectron: Probabilistic multi-agent trajectory modeling with dynamic spatiotemporal graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ivanovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pavone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Trajec-tron++: Multi-agent generative trajectory forecasting with heterogeneous data for control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ivanovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chakravarty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pavone</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.03093</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Bio-LSTM: a biomechanically inspired recurrent neural network for 3-D pedestrian pose and gait prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Johnson-Roberson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robot. Autom. Lett</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1501" to="1508" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Egocentric vision-based future vehicle localization for intelligent driving assistance systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Crandall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Atkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dariush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICRA</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9711" to="9717" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Pie: A large-scale dataset and models for pedestrian intention estimation and trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rasouli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kotseruba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kunic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Tsotsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Anticipating many futures: Online human motion prediction and generation for human-robot interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bütepage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kjellström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kragic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in ICRA</title>
		<imprint>
			<biblScope unit="page" from="4563" to="4570" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mangalam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Girase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Adeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gaidon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.02025</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>It is not the journey but the destination: Endpoint conditioned trajectory prediction</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Goal-directed pedestrian prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rehder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kloeden</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICCVW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Precog: Prediction conditioned on goals in visual multi-agent settings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rhinehart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mcallister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kitani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning structured output representation using deep conditional generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Accurate and diverse sampling of sequences based on a &quot;best of many&quot; sample objective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Social-bigat: Multimodal trajectory forecasting using bicycle-gan and graph attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Martín-Martín</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Multi-modal trajectory prediction of surrounding vehicles with maneuver based lstms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Deo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Trivedi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<pubPlace>IV</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Generative modeling of multimodal multi-human behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ivanovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schmerling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pavone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in IROS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Drogon: A causal reasoning framework for future trajectory forecast</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Malla</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.00024</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Pedestrian prediction by planning using deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rehder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wirth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Stiller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in ICRA</title>
		<imprint>
			<biblScope unit="page" from="5903" to="5908" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Trajectory forecasts in unknown environments conditioned on grid-based plans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Deo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Trivedi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.00735</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kotseruba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rasouli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Tsotsos</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.04741</idno>
		<title level="m">Joint attention in autonomous driving (JAAD)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">You&apos;ll never walk alone: Modeling social behavior for multi-target tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pellegrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning an image-based motion context for multiple people tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Leal-Taixé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fenzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kuznetsova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Rosenhahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Long-term on-board prediction of people in traffic scenes under uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Sophie: An attentive gan for predicting paths compliant to social and physical constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Hirose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Analyzing the variety loss in the context of probabilistic trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Thiede</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">P</forename><surname>Brahma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Learning structured output representation using deep conditional generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Social GAN: Socially acceptable trajectories with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Trajec-tron++: Multi-agent generative trajectory forecasting with heterogeneous data for control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ivanovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chakravarty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pavone</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.03093</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Curves and surfaces in geometric modeling: theory and algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gallier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Gallier</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>Morgan Kaufmann</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Disentangling monocular 3d object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Simonelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bulo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Porzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>López-Antequera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kontschieder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Caesar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Bankiti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">H</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">E</forename><surname>Liong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Baldan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Beijbom</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.11027</idno>
		<title level="m">nuscenes: A multimodal dataset for autonomous driving</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
