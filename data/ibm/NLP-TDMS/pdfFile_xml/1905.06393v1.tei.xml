<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">IPC: A Benchmark Data Set for Learning with Graph-Structured Data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Ferber</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengfei</forename><surname>Ma</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyu</forename><surname>Huo</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Katz</surname></persName>
						</author>
						<title level="a" type="main">IPC: A Benchmark Data Set for Learning with Graph-Structured Data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T18:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Benchmark data sets are an indispensable ingredient of the evaluation of graph-based machine learning methods. We release a new data set, compiled from International Planning Competitions (IPC), for benchmarking graph classification, regression, and related tasks. Apart from the graph construction (based on AI planning problems) that is interesting in its own right, the data set possesses distinctly different characteristics from popularly used benchmarks. The data set, named IPC, consists of two self-contained versions, grounded and lifted, both including graphs of large and skewedly distributed sizes, posing substantial challenges for the computation of graph models such as graph kernels and graph neural networks. The graphs in this data set are directed and the lifted version is acyclic, offering the opportunity of benchmarking specialized models for directed (acyclic) structures. Moreover, the graph generator and the labeling are computer programmed; thus, the data set may be extended easily if a larger scale is desired. The data set is accessible from https: //github.com/IBM/IPC-graph-data.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Benchmark data sets are indispensable in the evaluation of machine learning models for graph-structured data. With the surging interest in graph representation learning, a rich collection of data sets constructed from real-life applications becomes important for the validation of effectiveness of any existing or newly proposed method, and for demonstrating its widespread applicability. We introduce a new labeled data set, IPC, compiled from AI plannig tasks described in the Planning Domain Definition Language (PDDL) <ref type="bibr" target="#b8">(McDermott, 2000)</ref>.</p><p>In this data set, each planning task is represented as a directed graph, which has target values and whose nodes are equipped with features. Planning tasks described in PDDL admit a concise representation in transition graphs, however too big to fit in any conceivable size memory. Recent advances in planning allow to encode some structural information of a task in graphs of manageable size. Two examples are the problem description graph <ref type="bibr" target="#b9">(Pochter et al., 2011)</ref>, for a grounded task representation, and the abstract structure graph <ref type="bibr" target="#b12">(Sievers et al., 2019b)</ref>, for a lifted representation. Hence, our data set consists of two versions of graphs (IPC-grounded and IPC-lifted) for the same set of tasks; each version may be used independently. There are 2439 planning tasks in total, pre-split for training, validation, and testing. Moreover, the lifted version is acyclic.</p><p>Accompanied with the tasks are performance results for 17 cost-optimal domain-independent planners, each of which attempts to solve a task under a timeout limit T = 1800 seconds. Hence, the target values for each graph are the CPU times of these planners, gathered on the same hardware. For practical reasons, if a planner cannot solve the task before timeout, the target value is artificially set as 10000.</p><p>The background on AI Planning and graph construction, including example problem domains, node feature definition, and how the data set can be extended, are presented in Section 2. The characteristics of this data set are different in several aspects from those of the commonly used benchmark data sets for graph kernels and graph neural networks: The sizes of our graphs not only are substantially larger but also vary significantly. The imposed challenges and implications are elaborated in Section 3. We present an example use of the data set in Section 4 and conclude in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Data Set Construction</head><p>PDDL tasks are defined over a first-order language L that consists of predicates, functions, a set of natural numbers, variables, and constants. Given L, a normalized <ref type="bibr" target="#b1">(Helmert, 2009</ref>) PDDL task is a tuple Π = O, A, I, G of schematic operators, schematic axioms, initial state specification, and goal specification, in so-called lifted representation.</p><p>Most tools for solving the planning problems (a.k.a. planners) perform grounding as a first step, followed by trans- lation into a SAS + language <ref type="bibr" target="#b0">(Bäckström &amp; Nebel, 1995)</ref>.</p><p>In SAS + , a task Π = V, O, A, s 0 , s consists of finitedomain variables, ground operators, ground axioms, initial state, and the goal.</p><p>Our data set consists of two graphical representations per planning task. These representations losslessly encode the information in the planning task and are often used for the computation of structural symmetries <ref type="bibr" target="#b10">(Shleyfman et al., 2015)</ref>. The graph obtained from the grounded representation SAS + is called the problem description graph (PDG) <ref type="bibr" target="#b9">(Pochter et al., 2011)</ref>. We present here the definition extended to support conditional effects and axioms and refer the reader to <ref type="bibr" target="#b11">Sievers et al. (2019a)</ref> for further details.</p><p>Definition 1 Let Π = V, V d , O, A, s d , s 0 , s be a SAS + task. The problem description graph of Π is the digraph N, E with nodes</p><formula xml:id="formula_0">N = {n 0 , n } ∪ {n v | v ∈ V} ∪ N f ∪ N O ∪ {n a | a ∈ A}, where N f = {n d v | v ∈ V, d ∈ dom(v)} and N O = {n o | o ∈ O} ∪ {n e o | o ∈ O, e ∈ effs(o)}, and edges E = E 0 ∪ E ∪ E v ∪ E a ∪ E o , where E 0 = { n 0 , n d v | s 0 [v] = d} E = { n g , n d v | v ∈ vars(s ), s [v] = d} E v = { n v , n d v | d ∈ dom(v)} E a = { n a , n d v | a ∈ A, v ∈ vars(pre(a)), pre(a)[v] = d} ∪ { n a , n d v | a ∈ A, var(a) = v, val(a) = d} E o = { n o , n d v | o ∈ O, v ∈ vars(pre(o)), pre(o)[v] = d} ∪ { n o , n e o | e ∈ effs(o)} ∪ { n d v , n e o | c, ·, · ∈ effs(o), v ∈ vars(c), c[v] = d} ∪ { n e o , n d v | ·, v, d ∈ effs(o)}.</formula><p>The graph obtained from the lifted PDDL representations is called the abstract structure graph (ASG) <ref type="bibr" target="#b12">(Sievers et al., 2019b)</ref>. Planning tasks in PDDL can be naturally modeled as abstract structures, which, in turn, can be represented as graphs. In what follows we present the definitions of abstract structures and abstract structure graphs, referring the reader to <ref type="bibr" target="#b12">Sievers et al. (2019b)</ref> for further details.</p><p>Definition 2 <ref type="bibr" target="#b12">(Sievers et al., 2019b)</ref> Let S be a set of symbols, where each s ∈ S is associated with a type t(s). The set of abstract structures over S is inductively defined as follows:</p><p>• each symbol s ∈ S is an abstract structure, and</p><p>• for abstract structures A 1 , . . . , A n , the set {A 1 , . . . , A n } and the tuple A 1 , . . . , A n are abstract structures.</p><p>Using the language L of a PDDL task Π, each part of Π can inductively be defined as an abstract structure, with the symbols of L forming the basic abstract structures. Finally, abstract structures can be naturally turned into a graph.</p><p>Definition 3 <ref type="bibr" target="#b12">(Sievers et al., 2019b)</ref> Let A be an abstract structure over S. The abstract structure graph ASG A is a digraph N, E , defined as follows.</p><p>• N contains a node A for the abstract structure A. If N contains a node for A = {A 1 , . . . , A n } or A = A 1 , . . . , A n , it also contains the nodes for A 1 , . . . , A n .</p><p>• For every set (sub-)structure A = {A 1 , . . . , A n } there are edges A → A i for i ∈ {1, . . . , n}.</p><p>• For every tuple (sub-)structure A = A 1 , . . . , A n , the graph contains auxiliary nodes n A 1 , . . . , n A n , an edge A → n A 1 , and edges</p><formula xml:id="formula_1">n A i−1 → n A i for 1 &lt; i ≤ n. For each component A i , there is an edge n A i → A i .</formula><p>Note that the edges in ASGs are from the abstract structures to their sub-structures, which results in acyclic graphs.</p><p>In both PDG and ASG, the node features are one-hot according to the self-explanatory node type indicated in the above definitions.</p><p>The aim in classical planning is to find a sequence of ground operators that, if applied to the initial state, will necessarily transform it into a goal state. Such a sequence is called a plan. Assigning a quantitative cost to each ground operator, the cost of a plan is defined as the sum over the costs of its operators. The goal of cost-optimal classical planning is to find a provably cheapest plan. There exist dozens if not hundreds of highly parameterized methods for heuristic guidance computation, giving rise to an enormous possible number of planners. As even the classical planning is PSPACE-hard, there cannot be one planner that will work well on all possible planning problems. Thus, finding a planner that works well on a given planning problem is a challenging task.</p><p>While planners are often domain-independent, in the sense that they depend only on the information encoded in PDDL, the planning tasks encode computational problems from various domains. These domains range from puzzles or one-person games (e.g., towers of Hanoi, 15-puzzle, freecell, and sokoban), to real-life domains (e.g., task planning and automated control of autonomous systems: greenhouse logistics, rovers, elevators, satellites), as well as emerging domains (e.g., genome editing distance computation).</p><p>Many of the existing domains were introduced through International Planning Competitions, which were held regularly since 1998. Each such competition, intended for comparing the performance of domain-independent planners, introduced new, previously unseen domains on which submitted planners were tested. In many cases, the authors of the domains supplied not only the planning tasks, but also the generator that allowed for creating additional tasks. Some of these generators can be found at, e.g., https://bitbucket.org/ planning-researchers/pddl-generators. Hence, these generators may be used to extend the current data set with little effort, although for benchmarking purpose we did not include any such task in the data set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Statistics</head><p>A number of graph statistics, compared with those of commonly used datasets <ref type="bibr" target="#b3">(Kersting et al., 2016)</ref> for benchmarking graph kernels and graph neural networks, are reported in <ref type="table" target="#tab_0">Table 1</ref> and <ref type="figure">Figures 2 and 3</ref> in the supplementary material. Observations follow.</p><p>1. The IPC graphs are significantly larger. The graphs in other data sets under comparison generally have tens to hundreds of nodes, but 39% of the graphs in IPCgrounded and 63% in IPC-lifted have over 1,000 nodes. The largest graph in IPC-grounded has 87,140 nodes, and the number for IPC-lifted is 238,909.</p><p>2. Note that the size of the largest graph is often the memory bottleneck indicator for graph neural networks, because the batch size is at least this number in stochastic training. Hence, our data set poses substantial challenges for the computation of many neural graph models.</p><p>3. The sizes of the IPC graphs are highly skewed, compared to those of other data sets. For many machine learning tasks, especially in the unsupervised setting, the notion of similarity is key to clustering and categorization. When the sizes of two graphs significantly differ, the intuition of similarity is challenged. After all, what does it mean by saying "a graph with 10 nodes is similar to another graph with 100,000 nodes?" 4. The lifted graphs are the most sparse, compared to the grounded ones and graphs in other data sets.</p><p>5. Similar to many other data sets, the IPC graphs are not necessarily connected. However, the main connected component generally dominates. Hence, graph neural networks still suffer the memory bottleneck caused by the exceedingly large graphs.</p><p>6. Despite the difference in size and density, the IPC graphs have a moderate diameter, similar to other data sets. The number of layers in a graph neural network of neighborhood-aggregation style is often questioned beyond hyperparameter tuning; and speculation attributes to the diameter of the graphs. Meanwhile, it has been widely acknowledged that neighborhood aggregation is a type of Laplacian smoothing and too many layers lead to oversmoothing <ref type="bibr" target="#b13">Xu et al., 2018;</ref><ref type="bibr" target="#b5">Klicpera et al., 2019)</ref>. The diameter statistics may be useful for the analysis of the role of small-world structures handled by graph neural networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Example Use</head><p>For an illustration of the use of the data set, we focus on the problem of cost-optimal planning, whose goal is to solve as many tasks by using cost-optimal planners as possible, each given a time limit T . Hence, for each of the 17 target values, we convert it to 0 if the value ≤ T and 1 otherwise. For each target, the problem becomes a binary classification and thus a probability value between 0 and 1 is output. We select the planner corresponding to the smallest probability and confirm success if its actual planning time is smaller than the timeout limit T . Test accuracy (percentage of successfully solved tasks) is reported.</p><p>Three methods for comparison are (a) an image-based CNN whereby the gray-scale image is converted from the adjacency matrix of the graph; (b) a graph convolutional network (GCN) <ref type="bibr" target="#b4">(Kipf &amp; Welling, 2017)</ref> with attention readout; and (c) a gated graph neural network (GG-NN) <ref type="bibr" target="#b7">(Li et al., 2016)</ref>. For details of the CNN architecture, see <ref type="bibr" target="#b2">Katz et al. (2018)</ref>. 1.9 (0.3) 13.3 (5.1) 19.9 (7.7) 11.6 (7.9) 10.9 (4.8) 8.2 (1.8)</p><p>The data set has been pre-split for training, validation, and testing. <ref type="table" target="#tab_1">Table 2</ref> reports the test accuracy. Additionally, we re-split the training/validation combination as a form of cross validation, whereby we fix the test set because it comes from the most recent International Planning Competition. Two forms of random re-splits are possible. One is to preserve the domains of the planning tasks (i.e., tasks from the same domain cannot appear in both training and validation), and the other is free from this restriction. We call the former domain split and the latter random split. For each type of re-split, we perform ten randomizations. <ref type="table" target="#tab_2">Table 3</ref> reports the test accuracy together with standard deviation. From both tables, one sees that the lifted graphs yield much higher accuracy and GCN outperforms the other two methods.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>We have described a new data set, IPC, for benchmarking graph-based learning models (e.g., graph kernels and graph neural networks) in classification, regression, and related uses. The graphs are constructed from AI planning tasks appearing in International Planning Competitions, without requiring human efforts for labeling, and may be extended with random instances of planning problems. The data set has distinctively different statistics from other popularly used benchmarks: the graphs are much larger and their sizes vary substantially. Moreover, the lifted version of the data set is comprised of directed acyclic graphs, enabling the development of specialized graph models. We anticipate that the data set is a valuable inclusion to the current collection of commonly used benchmarks for validating the effectiveness of existing and forthcoming graph methods. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>An example planning task (described by using PDDL) and the constructed graphs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .Figure 3 .</head><label>23</label><figDesc>Box plot of the graph size distribution. The orange bar marks the median; the red cross the mean. Box plot of the diameter distribution. The orange bar marks the median; the red cross the mean.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Statistics of IPC, compared with that of the other commonly used benchmark data sets. Ave Degree" is the average node degree (of the undirected version of the graph). 2 "CC" means connected components (of the undirected version of the graph). 3 "Diam" means diameter. Because a graph may consist of multiple connected components, we define the diameter as the maximum of the diameters of each connected component. 4 For large graphs, the diameter is too costly to compute. Hence, for IPC, only the diameters of 94.3% of the graphs are computed. For other data sets, diameters of all graphs are computed.</figDesc><table><row><cell></cell><cell>IPC-grounded</cell><cell cols="2">IPC-lifted</cell><cell cols="4">REDDIT-MULTI-12k REDDIT-BINARY</cell></row><row><cell>Type</cell><cell>directed</cell><cell cols="2">DAG</cell><cell></cell><cell>undirected</cell><cell cols="2">undirected</cell></row><row><cell>#Graphs</cell><cell>2,439</cell><cell cols="2">2,439</cell><cell></cell><cell>11,929</cell><cell cols="2">2,000</cell></row><row><cell>Total #Nodes</cell><cell>6,233,856</cell><cell cols="2">9,816,948</cell><cell></cell><cell>4,669,116</cell><cell cols="2">859,254</cell></row><row><cell>Max #Nodes</cell><cell>87,140</cell><cell cols="2">238,909</cell><cell></cell><cell>3,782</cell><cell cols="2">3,782</cell></row><row><cell>Mean (Std) #Nodes</cell><cell cols="3">2,555.9 (6,099.0) 4,025.0 (14,507.6)</cell><cell></cell><cell>391.4 (428.7)</cell><cell cols="2">429.6 (554.1)</cell></row><row><cell>Mean (Std) Ave Degree 1</cell><cell>12.3 (131.0)</cell><cell cols="2">2.9 (35.1)</cell><cell></cell><cell>4.7 (27.6)</cell><cell cols="2">4.6 (41.3)</cell></row><row><cell>Mean (Std) #CC 2</cell><cell>1.09 (0.61)</cell><cell cols="2">1.14 (0.49)</cell><cell></cell><cell>2.81 (2.65)</cell><cell cols="2">2.48 (2.47)</cell></row><row><cell>Mean (Std) Diam 3,4</cell><cell>8.2 (2.3)</cell><cell cols="2">17.1 (1.5)</cell><cell></cell><cell>10.9 (3.1)</cell><cell cols="2">9.7 (3.1)</cell></row><row><cell cols="2">1 "COLLAB</cell><cell>NCI1</cell><cell>DD</cell><cell></cell><cell cols="2">PROTEINS ENZYMES</cell><cell>MUTAG</cell></row><row><cell>Type</cell><cell>undirected</cell><cell>undirected</cell><cell cols="2">undirected</cell><cell>undirected</cell><cell cols="2">undirected undirected</cell></row><row><cell>#Graphs</cell><cell>5,000</cell><cell>4,110</cell><cell>1,178</cell><cell></cell><cell>1,113</cell><cell>600</cell><cell>188</cell></row><row><cell>Total #Nodes</cell><cell>372,474</cell><cell>122,747</cell><cell>334,925</cell><cell></cell><cell>43,471</cell><cell>19,580</cell><cell>3,371</cell></row><row><cell>Max #Nodes</cell><cell>492</cell><cell>111</cell><cell>5,748</cell><cell></cell><cell>620</cell><cell>126</cell><cell>28</cell></row><row><cell>Mean (Std) #Nodes</cell><cell>74.5 (62.3)</cell><cell cols="5">29.9 (13.6) 106.5 (284.3) 39.1 (45.8) 32.6 (15.3)</cell><cell>18.0 (4.6)</cell></row><row><cell cols="2">Mean (Std) Ave Degree 1 132.0 (158.5)</cell><cell>4.3 (1.6)</cell><cell cols="2">10.1 (3.4)</cell><cell>7.5 (2.3)</cell><cell>7.6 (2.3)</cell><cell>4.4 (1.5)</cell></row><row><cell>Mean (Std) #CC 2</cell><cell>1 (0)</cell><cell>1.19 (0.57)</cell><cell cols="2">1.02 (0.18)</cell><cell cols="2">1.08 (0.52) 1.24 (3.61)</cell><cell>1 (0)</cell></row><row><cell>Mean (Std) Diam 3,4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Percentage of solved tasks in the test set.</figDesc><table><row><cell cols="3">Method Grounded Lifted</cell></row><row><cell>CNN</cell><cell>73.1%</cell><cell>86.9%</cell></row><row><cell>GCN</cell><cell>80.7%</cell><cell>87.6%</cell></row><row><cell>GG-NN</cell><cell>77.9%</cell><cell>81.4%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Percentage of solved tasks in the test set (lifted graphs).</figDesc><table><row><cell cols="2">Multiple training/validation splits.</cell></row><row><cell cols="2">Method Domain Splits Random Splits</cell></row><row><cell>CNN</cell><cell>82.1% (6.6%) 86.1% (5.5%)</cell></row><row><cell>GCN</cell><cell>85.6% (5.5%) 87.2% (3.5%)</cell></row><row><cell cols="2">GG-NN 76.6% (5.8%) 74.4% (2.7%)</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Additional Information of Graph Statistics</head><p>See <ref type="figure">Figures 2 and 3.</ref> </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Complexity results for SAS + planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bäckström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Nebel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="625" to="655" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Concise finite-domain representations for PDDL planning tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Helmert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AIJ</title>
		<imprint>
			<biblScope unit="volume">173</biblScope>
			<biblScope unit="page" from="503" to="535" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Online planner selection for cost-optimal planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sohrabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Samulowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sievers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Delfi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IPC-9 planner abstracts</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Benchmark data sets for graph kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kersting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M</forename><surname>Kriege</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mutzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<ptr target="http://graphkernels.cs.tu-dortmund.de" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Predict then propagate: Graph neural networks meet personalized pagerank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Klicpera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bojchevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gnnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deeper insights into graph convolutional networks for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-M</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In AAAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Gated graph sequence neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tarlow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brockschmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">The 1998 AI Planning Systems competition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcdermott</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="35" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Exploiting problem symmetries in state-based planners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Pochter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zohar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Rosenschein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Heuristics and symmetries in classical planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shleyfman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Helmert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sievers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wehrle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep learning for cost-optimal planning: Taskdependent planner selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sievers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sohrabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Samulowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ferber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI 2019</title>
		<meeting>AAAI 2019</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Theoretical foundations for structural symmetries of lifted pddl tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sievers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Rger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wehrle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Katz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICAPS 2019</title>
		<meeting>ICAPS 2019</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Representation learning on graphs with jumping knowledge networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sonobe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ichi Kawarabayashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
