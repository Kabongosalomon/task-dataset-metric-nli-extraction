<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PaDiM: a Patch Distribution Modeling Framework for Anomaly Detection and Localization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Defard</surname></persName>
							<email>thomas.defard@imt-atlantique.net</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Paris-Saclay</orgName>
								<orgName type="institution" key="instit2">CEA</orgName>
								<address>
									<postCode>F-91120</postCode>
									<settlement>Palaiseau</settlement>
									<region>List</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandr</forename><surname>Setkov</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Paris-Saclay</orgName>
								<orgName type="institution" key="instit2">CEA</orgName>
								<address>
									<postCode>F-91120</postCode>
									<settlement>Palaiseau</settlement>
									<region>List</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angelique</forename><surname>Loesch</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Paris-Saclay</orgName>
								<orgName type="institution" key="instit2">CEA</orgName>
								<address>
									<postCode>F-91120</postCode>
									<settlement>Palaiseau</settlement>
									<region>List</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romaric</forename><surname>Audigier</surname></persName>
							<email>romaric.audigier@cea.fr</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université Paris-Saclay</orgName>
								<orgName type="institution" key="instit2">CEA</orgName>
								<address>
									<postCode>F-91120</postCode>
									<settlement>Palaiseau</settlement>
									<region>List</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">PaDiM: a Patch Distribution Modeling Framework for Anomaly Detection and Localization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T18:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a new framework for Patch Distribution Modeling, PaDiM, to concurrently detect and localize anomalies in images in a one-class learning setting. PaDiM makes use of a pretrained convolutional neural network (CNN) for patch embedding, and of multivariate Gaussian distributions to get a probabilistic representation of the normal class. It also exploits correlations between the different semantic levels of CNN to better localize anomalies. PaDiM outperforms current state-ofthe-art approaches for both anomaly detection and localization on the MVTec AD and STC datasets. To match real-world visual industrial inspection, we extend the evaluation protocol to assess performance of anomaly localization algorithms on non-aligned dataset. The state-of-the-art performance and low complexity of PaDiM make it a good candidate for many industrial applications.</p><p>• Each patch position is described by a multivariate Gaussian distribution; • PaDiM takes into account the correlations between dif-arXiv:2011.08785v1 [cs.CV]  </p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Humans are able to detect heterogeneous or unexpected patterns in a set of homogeneous natural images. This task is known as anomaly or novelty detection and has a large number of applications, among which visual industrial inspections. However, anomalies are very rare events on manufacturing lines and cumbersome to detect manually. Therefore, anomaly detection automation would enable a constant quality control by avoiding reduced attention span and facilitating human operator work. In this paper, we focus on anomaly detection and, in particular, on anomaly localization, mainly in an industrial inspection context. In computer vision, anomaly detection consists in giving an anomaly score to images. Anomaly localization is a more complex task which assigns each pixel, or each patch of pixels, an anomaly score to output an anomaly map. Thus, anomaly localization yields more precise and interpretable results. Examples of anomaly maps produced by our method to localize anomalies in images from the MVTec Anomaly Detection (MVTec AD) dataset <ref type="bibr" target="#b0">[1]</ref> are displayed in <ref type="figure" target="#fig_0">Figure 1</ref>.</p><p>Anomaly detection is a binary classification between the normal and the anomalous classes. However, it is not possible to train a model with full supervision for this task because we frequently lack anomalous examples, and, what is more, anomalies can have unexpected patterns. Hence, anomaly detection models are often estimated in a one-class learning setting, i.e., when the training dataset contains only images from the normal class and anomalous examples are not available during the training. At test time, examples that differ from the normal training dataset are classified as anomalous. Recently, several methods have been proposed to combine anomaly localization and detection tasks in a one-class learning setting <ref type="bibr" target="#b1">[2]</ref>- <ref type="bibr" target="#b4">[5]</ref>. However, either they require deep neural network training <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b5">[6]</ref> which might be cumbersome, or they use a K-nearest-neighbor (K-NN) algorithm <ref type="bibr" target="#b6">[7]</ref> on the entire training dataset at test time <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>. The linear complexity of the KNN algorithm increases the time and space complexity as the size of the training dataset grows. These two scalability issues may hinder the deployment of anomaly localization algorithms in industrial context.</p><p>To mitigate the aforementioned issues, we propose a new anomaly detection and localization approach, named PaDiM for Patch Distribution Modeling. It makes use of a pretrained convolutional neural network (CNN) for embedding extraction and has the two following properties: ferent semantic levels of a pretrained CNN. With this new and efficient approach, PaDiM outperforms the existing state-of-the-art methods for anomaly localization and detection on the MVTec AD <ref type="bibr" target="#b0">[1]</ref> and the ShanghaiTech Campus (STC) <ref type="bibr" target="#b7">[8]</ref> datasets. Besides, at test time, it has a low time and space complexity, independent of the dataset training size which is an asset for industrial applications. We also extend the evaluation protocol to assess model performance in more realistic conditions, i.e., on a non-aligned dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>Anomaly detection and localization methods can be categorized as either reconstruction-based or embedding similaritybased methods.</p><p>Reconstruction-based methods are widely-used for anomaly detection and localization. Neural network architectures like autoencoders (AE) <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b8">[9]</ref>- <ref type="bibr" target="#b10">[11]</ref>, variational autoencoders (VAE) <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b11">[12]</ref>- <ref type="bibr" target="#b13">[14]</ref> or generative adversarial networks (GAN) <ref type="bibr" target="#b14">[15]</ref>- <ref type="bibr" target="#b16">[17]</ref> are trained to reconstruct normal training images only. Therefore, anomalous images can be spotted as they are not well reconstructed. At the image level, the simplest approach is to take the reconstructed error as an anomaly score <ref type="bibr" target="#b9">[10]</ref> but additional information from the latent space <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b17">[18]</ref>, intermediate activations <ref type="bibr" target="#b18">[19]</ref> or a discriminator <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b19">[20]</ref> can help to better recognize anomalous images. Yet to localize anomalies, reconstruction-based methods can take the pixel-wise reconstruction error as the anomaly score <ref type="bibr" target="#b0">[1]</ref> or the structural similarity <ref type="bibr" target="#b8">[9]</ref>. Alternatively, the anomaly map can be a visual attention map generated from the latent space <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b13">[14]</ref>. Although reconstruction-based methods are very intuitive and interpretable, their performance is limited by the fact that AE can sometimes yield good reconstruction results for anomalous images too <ref type="bibr" target="#b20">[21]</ref>.</p><p>Embedding similarity-based methods use deep neural networks to extract meaningful vectors describing an entire image for anomaly detection <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b21">[22]</ref>- <ref type="bibr" target="#b23">[24]</ref> or an image patch for anomaly localization <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b24">[25]</ref>. Still, embedding similarity-based methods that only perform anomaly detection give promising results but often lack interpretability as it is not possible to know which part of an anomalous images is responsible for a high anomaly score. The anomaly score is in this case the distance between embedding vectors of a test image and reference vectors representing normality from the training dataset. The normal reference can be the center of a nsphere containing embeddings from normal images <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b21">[22]</ref>, parameters of Gaussian distributions <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b25">[26]</ref> or the entire set of normal embedding vectors <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b23">[24]</ref>. The last option is used by SPADE <ref type="bibr" target="#b4">[5]</ref> which has the best reported results for anomaly localization. However, it runs a K-NN algorithm on a set of normal embedding vectors at test time, so the inference complexity scales linearly to the dataset training size. This may hinder industrial deployment of the method.</p><p>Our method, PaDiM, generates patch embeddings for anomaly localization, similar to the aforementioned approaches. However, the normal class in PaDiM is described through a set of Gaussian distributions that also model correlations between semantic levels of the used pretrained CNN model. Inspired by <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b22">[23]</ref>, we choose as pretrained networks a ResNet <ref type="bibr" target="#b26">[27]</ref>, a Wide-ResNet <ref type="bibr" target="#b27">[28]</ref> or an EfficientNet <ref type="bibr" target="#b28">[29]</ref>. Thanks to this modelisation, PaDiM outperforms the current state-of-the-art methods. Moreover, its time complexity is low and independent of the training dataset size at the prediction stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PATCH DISTRIBUTION MODELING A. Embedding extraction</head><p>Pretrained CNNs are able to output relevant features for anomaly detection <ref type="bibr" target="#b23">[24]</ref>. Therefore, we choose to avoid ponderous neural network optimization by only using a pretrained CNN to generate patch embedding vectors. The patch embedding process in PaDiM is similar to one from SPADE <ref type="bibr" target="#b4">[5]</ref> and illustrated in <ref type="figure" target="#fig_1">Figure 2</ref>. During the training phase, each patch of the normal images is associated to its spatially corresponding activation vectors in the pretrained CNN activation maps. Activation vectors from different layers are then concatenated to get embedding vectors carrying information from different semantic levels and resolutions, in order to encode finegrained and global contexts. As activation maps have a lower resolution than the input image, many pixels have the same embeddings and then form pixel patches with no overlap in the original image resolution. Hence, an input image can be divided in a grid of (i, j) ∈ [1, W ] × [1, H] positions where W xH is the resolution of the largest activation map used to generate embeddings. Finally, each patch position (i, j) in this grid is associated to an embedding vector x ij computed as described above.</p><p>The generated patch embedding vectors may carry redundant information, therefore we experimentally study the possibility to reduce their size (Section V-A). We noticed that randomly selecting few dimensions is more efficient that a classic Principal Component Analysis (PCA) algorithm <ref type="bibr" target="#b29">[30]</ref>. This simple random dimensionality reduction significantly decreases the complexity of our model for both training and testing time while maintaining the state-of-the-art performance. Finally, patch embedding vectors from test images are used to output an anomaly map with the help of the learned parametric representation of the normal class described in the next subsection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Learning of the normality</head><p>To learn the normal image characteristics at position (i, j), we first compute the set of patch embedding vectors at (i, j),</p><formula xml:id="formula_0">X ij = {x k ij , k ∈ [[1,</formula><p>N ]]} from the N normal training images as shown on <ref type="figure" target="#fig_1">Figure 2</ref>. To sum up the information carried by this set we make the assumption that X ij is generated by a multivariate Gaussian distribution N (µ ij , Σ ij ) where µ ij is the sample mean of X ij and the sample covariance Σ ij is estimated as follows :</p><formula xml:id="formula_1">Σ ij = 1 N − 1 N k=1 (x k ij − µ ij )(x k ij − µ ij ) T + I<label>(1)</label></formula><p>where the regularisation term I makes the sample covariance matrix Σ ij full rank and invertible. Finally, each possible patch position is associated with a multivariate Gaussian distribution as shown in <ref type="figure" target="#fig_1">Figure 2</ref> by the matrix of Gaussian parameters.</p><p>Our patch embedding vectors carry information from different semantic levels. Hence, each estimated multivariate Gaussian distribution N (µ ij , Σ ij ) captures information from different levels too and Σ ij contains the inter-level correlations. We experimentally show (Section V-A) that modeling these relationships between the different semantic levels of the pretrained CNN helps to increase anomaly localization performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Inference : computation of the anomaly map</head><p>Inspired by <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b25">[26]</ref>, we use the Mahalanobis distance <ref type="bibr" target="#b30">[31]</ref> M (x ij ) to give an anomaly score to the patch in position (i, j) of a test image. M (x ij ) can be interpreted as the distance between the test patch embedding x ij and learned distribution</p><formula xml:id="formula_2">N (µ ij , Σ ij ), where M (x ij )</formula><p>is computed as follows:</p><formula xml:id="formula_3">M (x ij ) = (x ij − µ ij ) T Σ −1 ij (x ij − µ ij )<label>(2)</label></formula><p>Hence, the matrix of Mahalanobis distances M = (M (x ij )) 1&lt;i&lt;W,1&lt;j&lt;H that forms an anomaly map can be computed. High scores in this map indicate the anomalous areas. The final anomaly score of the entire image is the maximum of anomaly map M . Finally, at test time, our method does not have the scalability issue of the K-NN based methods <ref type="bibr" target="#b3">[4]</ref>- <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b24">[25]</ref> as we do not have to compute and sort a large amount of distance values to get the anomaly score of a patch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Datasets and metrics</head><p>Metrics. To assess the localization performance we compute two threshold independent metrics. We use the Area Under the Receiver Operating Characteristic curve (AUROC) where the true positive rate is the percentage of pixels correctly classified as anomalous. Since the AUROC is biased in favor of large anomalies we also employ the per-region-overlap score (PRO-score) <ref type="bibr" target="#b1">[2]</ref>. It consists in plotting, for each connected component, a curve of the mean values of the correctly classified pixel rates as a function of the false positive rate between 0 and 0.3. The PRO-score is the normalized integral of this curve. A high PRO-score means that both large and small anomalies are well-localized.</p><p>Datasets. We first evaluate our models on the MVTec AD <ref type="bibr" target="#b0">[1]</ref> designed to test anomaly localization algorithms for industrial quality control and in a one-class learning setting. It contains 15 classes of approximately 240 images. The original image resolution is between 700x700 and 1024x1024. There are 10 object and 5 texture classes. Objects are always wellcentered and aligned in the same way across the dataset as we can see in <ref type="figure" target="#fig_0">Figure 1</ref> for classes Transistor and Capsule. In addition to the original dataset, to assess performance of anomaly localization models in a more realistic context, we create a modified version of the MVTec AD, referred as Rd-MVTec AD, where we apply random rotation (-10, +10) and random crop (from 256x256 to 224x224) to both the train and test sets. This modified version of the MVTec AD may better describe real use cases of anomaly localization for quality control where objects of interest are not always centered and aligned in the image.</p><p>For further evaluation, we also test PaDiM on the Shanghai Tech Campus (STC) Dataset <ref type="bibr" target="#b7">[8]</ref> that simulates video surveillance from a static camera. It contains 274 515 training and 42 883 testing frames divided in 13 scenes. The original image resolution is 856x480. The training videos are composed of normal sequences and test videos have anomalies like the presence of vehicles in pedestrian areas or people fighting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Experimental setups</head><p>We train PaDiM with different backbones, a ResNet18 (R18) <ref type="bibr" target="#b26">[27]</ref>, a Wide ResNet-50-2 (WR50) <ref type="bibr" target="#b27">[28]</ref> and an EfficientNet-B5 <ref type="bibr" target="#b28">[29]</ref>, all pretrained on ImageNet <ref type="bibr" target="#b31">[32]</ref>. Like in <ref type="bibr" target="#b4">[5]</ref>, patch embedding vectors are extracted from the first three layers when the backbone is a ResNet, in order to combine information from different semantic levels, while keeping a high enough resolution for the localization task. Following this idea, we extract patch embedding vectors from layers 7 (level 2), 20 (level 4), and 26 (level 5), if an EfficientNet-B5 is used. We also apply a random dimensionality reduction (Rd) (see Sections III-A and V-A). Our model names indicate the backbone and the dimensionality reduction method used, if any. For example, PaDiM-R18-Rd100 is a PaDiM model with a ResNet18 backbone using 100 randomly selected dimensions for the patch embedding vectors. By default we use = 0.01 for the from <ref type="figure" target="#fig_0">Equation 1</ref>.</p><p>We reproduce the model SPADE <ref type="bibr" target="#b4">[5]</ref> as described in the original publication with a Wide ResNet-50-2 (WR50) <ref type="bibr" target="#b27">[28]</ref> as backbone. For SPADE and PaDiM we apply the same prepocessing as in <ref type="bibr" target="#b4">[5]</ref>. We resize the images from the MVTec AD to 256x256 and center crop them to 224x224. For the images from the STC we use a 256x256 resize only. We resize the images and the localization maps using bicubic interpolation and we use a Gaussian filter on the anomaly maps with parameter σ = 4 like in <ref type="bibr" target="#b4">[5]</ref>.</p><p>We also implement our own VAE as a reconstructionbased baseline implemented with a ResNet18 as encoder and a 8x8 convolutional latent variable. It is trained on each MVTec AD class with 10 000 images using the following data augmentations operations: random rotation (−2 • , +2 • ), 292x292 resize, random crop to 282x282, and finally center crop to 256x256. The training is performed during 100 epochs with the Adam optimizer <ref type="bibr" target="#b11">[12]</ref> with an initial learning rate of 10 −4 and a batch size of 32 images. The anomaly map for the localization corresponds to the pixel-wise L2 error for reconstruction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Ablative studies</head><p>First, we evaluate the impact of modeling correlations between semantic levels in PaDiM and explore the possibility to simplify our method through dimensionality reduction.</p><p>Inter-layer correlation. The combination of Gaussian modeling and the Mahalanobis distance has already been employed in previous works to detect adversarial attacks <ref type="bibr" target="#b25">[26]</ref> and for anomaly detection <ref type="bibr" target="#b22">[23]</ref> at the image level. However those methods do not model correlations between different CNN's semantic levels as we do in PaDiM. In <ref type="table" target="#tab_0">Table I</ref> we show the anomaly localization performance on the MVTec AD of PaDiM with a ResNet18 backbone when using only one of the first three layers (Layer 1, Layer 2, or Layer 3) and when summing the outputs of these 3 models to form an ensemble method that takes into account the first three layers but not the correlations between them (Layers 1+2+3). The last row of Table I (PaDiM-R18) is our proposed version of PaDiM where each patch location is described by one Gaussian distribution taking into account the first three ResNet18 layers and correlations between them. It can be observed that using Layer 3 produces the best results in terms of AUROC among the three layers. It is due to the fact that Layer 3 carries higher semantic level information which helps to better describe normality. However, Layer 3 has a slightly worse PRO-score than Layer 2 that can be explained by the lower resolution of Layer 2 which affects the accuracy of anomaly localization. As we see in the two last rows of  Dimensionality reduction. PaDiM-R18 estimates multivariate Gaussian distributions from sets of patch embeddings vectors of 448 dimensions each. Decreasing the embedding vector size would reduce the computational and memory complexity of our model. We study two different dimensionality reduction methods. The first one consists in applying a Principal Component Analysis (PCA) algorithm to reduce the vector size to 100 or 200 dimensions. The second method is a random feature selection where we randomly select features before the training. In this case, we train 10 different models and take the average scores. Still the randomness does not change the results between different seeds as the standard error mean (SEM) for the average AUROC is always between 10 −4 and 10 −7 .</p><p>From <ref type="table" target="#tab_0">Table II</ref> we can notice that for the same number of dimensions, the random dimensionality reduction (Rd) outperforms the PCA on all the MVTec AD classes by at least 1.3p.p in the AUROC and 1.2p.p in the PRO-score. It can be explained by the fact that PCA selects the dimensions with the highest variance which may not be the ones that help to discriminate the normal class from the anomalous one <ref type="bibr" target="#b22">[23]</ref>. It can also be noted from <ref type="table" target="#tab_0">Table II</ref> that randomly reducing the embedding vector size to only 100 dimensions has a very little impact on the anomaly localization performance. The results drop only by 0.4p.p in the AUROC and 0.3p.p in the PRO-score. This simple yet effective dimensionality reduction method significantly reduces PaDiM time and space complexity as it will be shown in Section V-D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Comparison with the state-of-the-art</head><p>Localization. In <ref type="table" target="#tab_0">Table III</ref>, we show the AUROC and the PRO-score results for anomaly localization on the MVTec AD. For a fair comparison, we used a Wide ResNet-50-2 (WR50) as this backbone is used in SPADE <ref type="bibr" target="#b4">[5]</ref>. Since the other baselines have smaller backbones, we also try a ResNet18 (R18). We randomly reduce the embedding size to 550 and 100 for PaDiM with WR50 and R18 respectively.</p><p>We first notice that PaDiM-WR50-Rd550 outperforms all the other methods in both the PRO-score and the AUROC on average for all the classes. PaDiM-R18-Rd100 which is a very light model also outperforms all models in the average AUROC on the MVTec AD classes by at least 0.2p.p. When we further analyze the PaDiM performances, we see that the gap for the object classes is small as PaDiM-WR50-Rd550 is the best only in the AUROC (+0.2p.p) but SPADE <ref type="bibr" target="#b4">[5]</ref> is the best in the PRO-score (+1.8p.p). However, our models are particularly accurate on texture classes. PaDiM-WR50-Rd550 outperforms the second best model SPADE <ref type="bibr" target="#b4">[5]</ref> by 4.8p.p and 4.0p.p in the PRO-score and the AUROC respectively on average on texture classes. Indeed, PaDiM learns an explicit probabilistic model of the normal classes contrary to SPADE <ref type="bibr" target="#b4">[5]</ref> or Patch-SVDD <ref type="bibr" target="#b3">[4]</ref>. It is particularly efficient on texture images because even if they are not aligned and centered like object images, PaDiM effectively captures their statistical similarity accross the normal train dataset.</p><p>Additionally, we evaluate our model on the STC dataset. We compare our method to the two best reported models performing anomaly localization without temporal information, CAVGA-RU <ref type="bibr" target="#b2">[3]</ref> and SPADE <ref type="bibr" target="#b4">[5]</ref>. As shown in <ref type="table" target="#tab_0">Table IV</ref>, the best result (AUROC) on the STC dataset is achieved with our simplest model PaDiM-R18-Rd100 by a 2.1p.p. margin. In fact, pedestrian positions in images are highly variable in this dataset and, as shown in Section V-C, our method performs well on non-aligned datasets.</p><p>Detection. By taking the maximum score of the anomaly maps issued by our models (see Section III-C) we give anomaly scores to entire images to perform anomaly detection at the image level. We test PaDiM for anomaly detection with a Wide ResNet-50-2 (WR50) <ref type="bibr" target="#b27">[28]</ref> used in SPADE and an EfficientNet-B5 <ref type="bibr" target="#b28">[29]</ref>. The <ref type="table" target="#tab_5">Table V</ref> shows that our model PaDiM-WR50-Rd550 outperforms every method except MahalanobisAD <ref type="bibr" target="#b22">[23]</ref> with their best reported backbone, an EfficientNet-B4. Still our PaDiM-EfficientNet-B5 outperforms every model by at least 2.6p.p on average on all the classes in the AUROC. Besides, contrary to the second best method for anomaly detection, MahalanobisAD <ref type="bibr" target="#b22">[23]</ref>, our model also performs anomaly segmentation which characterizes more precisely the anomalous areas in the images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Anomaly localization on a non-aligned dataset</head><p>To estimate the robustness of anomaly localization methods, we train and evaluate the performance of PaDiM and several  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>GANomaly <ref type="bibr" target="#b19">[20]</ref> ITAE <ref type="bibr" target="#b10">[11]</ref> Patch SVDD <ref type="bibr" target="#b3">[4]</ref> SPADE <ref type="bibr" target="#b4">[5]</ref> (WR50)</p><p>MahalanobisAD <ref type="bibr" target="#b22">[23]</ref> (EfficientNet-B4)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PaDiM-WR50-Rd550</head><p>PaDiM state-of-the-art methods (SPADE <ref type="bibr" target="#b4">[5]</ref>, VAE) on a modified version of the MVTec AD, Rd-MVTec AD, described in Section IV-A. Results of this experiment are displayed in <ref type="table" target="#tab_0">Table VI</ref>. For each test configuration we run 5 times data preprocessing on the MVTec AD with random seeds to obtain 5 different versions of the dataset, denoted as Rd-MVTec AD. Then, we average the obtained results and report them in <ref type="table" target="#tab_0">Table VI</ref>. According to the presented results, PaDiM-WR50-Rd550 outperforms the other models on both texture and object classes in the PRO-score and the AUROC. Besides, the SPADE <ref type="bibr" target="#b4">[5]</ref> and VAE performances on the Rd-MVTec AD decrease more than the performance of PaDiM-WR50-Rd550 when comparing to the results obtained on the normal MVTec AD (refer to <ref type="table" target="#tab_0">Table III</ref>). The AUROC results decrease by 5.3p.p for PaDiM-WR50-Rd550 against 12.2p.p and 8.8p.p decline for VAE and SPADE respectively. Thus, we can conclude that our method seems to be more robust to non-aligned images than the other existing and tested works. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Scalability gain</head><p>Time complexity. In PaDiM, the training time complexity scales linearly with the dataset size because the Gaussian parameters are estimated using the entire training dataset. However, contrary to the methods that require to train deep neural networks, PaDiM uses a pretrained CNN, and, thus, no deep learning training is required which is often a complex procedure. Hence, it is very fast and easy to train it on small datasets like MVTec AD. For our most complex model PaDiM-WR50-Rd550, the training on a CPU (Intel CPU 6154 3GHz 72th) with a serial implementation takes on average 150 seconds on the MVTec AD classes and 1500 seconds on average on the STC video scenes. These training procedures could be further accelerated using GPU hardware for the forward pass and the covariance estimation. In contrast, training the VAE with 10 000 images per class on the MVTec AD following the procedure described in Section IV-B takes 2h40 per class using one GPU NVIDIA P5000. Conversely, SPADE <ref type="bibr" target="#b4">[5]</ref> requires no training as there are no parameters to learn. Still, it computes and stores in the memory before testing all the embedding vectors of the normal training images. Those vectors are the inputs of a K-NN algorithm which makes SPADE's inference very slow as shown in <ref type="table" target="#tab_0">Table VII</ref>.</p><p>In <ref type="table" target="#tab_0">Table VII</ref>, we measure the model inference time using a mainstream CPU (Intel i7-4710HQ CPU @ 2.50GHz) with a serial implementation. On the MVTec AD, the inference time of SPADE is around seven times slower than our PaDiM model with equivalent backbone because of the computationally expensive NN search. Our VAE implementation, which is similar to most reconstruction-based models, is the fastest model but our simple model PaDiM-R18-Rd100 has the same order of magnitude for the inference time. While having similar complexity, PaDiM largely outperfoms the VAE methods (see Section V-B).</p><p>Memory complexity. Unlike SPADE <ref type="bibr" target="#b4">[5]</ref> and Patch SVDD <ref type="bibr" target="#b3">[4]</ref>, the space complexity of our model is independent of the dataset training size and depends only on the image resolution. PaDiM keeps in the memory only the pretrained CNN and the Gaussian parameters associated with each patch. In <ref type="table" target="#tab_0">Table  VIII</ref> we show the memory requirement of SPADE, our VAE implementation, and PaDiM, assuming that parameters are encoded in float32. Using equivalent backbone, SPADE has a lower memory consumption than PaDiM on the MVTec AD. However, when using SPADE on a larger dataset like the STC, its memory consumption becomes intractable, whereas PaDiM-WR50-Rd550 requires seven times less memory. The PaDiM space complexity increases from the MVTec AD to the STC only because the input image resolution is higher in the latter dataset as described in Section IV-B. Finally, one of the advantages of our framework PaDiM is that the user can easily adapt the method by choosing the backbone and the embedding size to fit its inference time requirements, resource limits, or expected performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>We have presented a framework called PaDiM for anomaly detection and localization in one-class learning setting which is based on distribution modeling. It achieves state-of-the-art performance on MVTec AD and STC datasets. Moreover, we extend the evaluation protocol to non-aligned data and the first results show that PaDiM can be robust on these more realistic data. PaDiM low memory and time consumption and its ease of use make it suitable for various applications, such as visual industrial control.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Image samples from the MVTec AD [1]. Left column: normal images of Transistor, Capsule and Wood classes. Middle column: images of the same classes with the ground truth anomalies highlighted in yellow. Right column: anomaly heatmaps obtained by our PaDiM model. Yellow areas correspond to the detected anomalies, whereas the blue areas indicate the normality zones. Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>For each image patch corresponding to position (i, j) in the largest CNN feature map, PaDiM learns the Gaussian parameters (µ ij , Σ ij ) from the set of N training embedding vectors X ij = {x k ij , k ∈ [[1, N ]]}, computed from N different training images and three different pretrained CNN layers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I STUDY</head><label>I</label><figDesc>OF THE ANOMALY LOCALIZATION PERFORMANCE USING DIFFERENT SEMANTIC-LEVEL CNN LAYERS. RESULTS ARE DISPLAYED AS TUPLES (AUROC%, PRO-SCORE%) ON THE MVTEC AD.</figDesc><table><row><cell>Layer used</cell><cell cols="2">all texture classes all object classes</cell><cell>all classes</cell></row><row><cell>Layer 1</cell><cell>(93.1, 87.1)</cell><cell>(95.6, 86.5)</cell><cell>(94.8, 86.8)</cell></row><row><cell>Layer 2</cell><cell>(95.0, 89.7)</cell><cell>(96.1, 87.9)</cell><cell>(95.7, 88.5)</cell></row><row><cell>Layer 3</cell><cell>(94.8, 89.6)</cell><cell>(97.1, 87.7)</cell><cell>(95.7, 88.3)</cell></row><row><cell>Layer 1+2+3</cell><cell>(95.4, 90.7)</cell><cell>(96.3, 88.1)</cell><cell>(96.0, 89.0)</cell></row><row><cell>PaDiM-R18</cell><cell>(96.3, 92.3)</cell><cell>(97.5, 90.1)</cell><cell>(97.1, 90.8)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table I</head><label>I</label><figDesc></figDesc><table><row><cell>, aggregating information</cell></row><row><cell>from different layers can solve the trade-off issue between</cell></row><row><cell>high semantic information and high resolution. Unlike model</cell></row><row><cell>Layer 1+2+3 that simply sums the outputs, our model PaDiM-</cell></row><row><cell>R18 takes into account correlations between semantic levels.</cell></row></table><note>As a result, it outperforms Layer 1+2+3 by 1.1p.p (percent point) for AUROC and 1.8p.p for PRO-score. It confirms the relevance of modeling correlation between semantic levels.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE II STUDY</head><label>II</label><figDesc>OF THE ANOMALY LOCALIZATION PERFORMANCE WITH A DIMENSIONALITY REDUCTION FROM 448 TO 100 AND 200 USING PCA OR RANDOM FEATURE SELECTION (RD). RESULTS ARE DISPLAYED AS TUPLES (AUROC%, PRO-SCORE%) ON THE MVTEC AD.</figDesc><table><row><cell></cell><cell cols="2">all texture classes all object classes</cell><cell>all classes</cell></row><row><cell>Rd 100</cell><cell>(95.7, 91.3)</cell><cell>(97.2, 89.4)</cell><cell>(96.7, 90.5)</cell></row><row><cell>PCA 100</cell><cell>(93.7, 88.9)</cell><cell>(93.5, 84.1)</cell><cell>(93.5, 85.7)</cell></row><row><cell>Rd 200</cell><cell>(96.1, 92.0)</cell><cell>(97.5, 89.8)</cell><cell>(97.0, 90.5)</cell></row><row><cell>PCA 200</cell><cell>(95.1, 91.8)</cell><cell>(96.0, 88.1)</cell><cell>(95.7, 89.3)</cell></row><row><cell>all (448)</cell><cell>(96.3, 92.3)</cell><cell>(97.5, 90.1)</cell><cell>(97.1, 90.8)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE III COMPARISON</head><label>III</label><figDesc>OF OUR PADIM MODELS WITH THE STATE-OF-THE-ART FOR THE ANOMALY LOCALIZATION ON THE MVTEC AD. RESULTS ARE DISPLAYED AS TUPLES (AUROC%, PRO-SCORE%)</figDesc><table><row><cell>Type</cell><cell cols="4">Reconstruction-based methods</cell><cell cols="3">Embedding similarity based methods</cell><cell cols="2">Our methods</cell></row><row><cell>Model</cell><cell>AE simm</cell><cell>AE</cell><cell>L2</cell><cell>VAE</cell><cell>Student</cell><cell>Patch</cell><cell>SPADE [5]</cell><cell>PaDiM-</cell><cell>PaDiM-</cell></row><row><cell></cell><cell>[1], [2], [9]</cell><cell>[1], [2]</cell><cell></cell><cell></cell><cell>[2]</cell><cell>SVDD [4]</cell><cell></cell><cell>R18-Rd100</cell><cell>WR50-Rd550</cell></row><row><cell>Carpet</cell><cell>(87, 64.7)</cell><cell cols="2">(59, 45.6)</cell><cell>(59.7, 61.9)</cell><cell>(-, 69.5)</cell><cell>(92.6, -)</cell><cell>(97.5, 94.7)</cell><cell>(98.9, 96.0)</cell><cell>(99.1, 96.2)</cell></row><row><cell>Grid</cell><cell>(94, 84.9)</cell><cell cols="2">(90, 58.2)</cell><cell>(61.2, 40.8)</cell><cell>(-, 81.9)</cell><cell>(96.2, -)</cell><cell>(93.7, 86.7)</cell><cell>(94.9, 90.9)</cell><cell>(97.3, 94.6)</cell></row><row><cell>Leather</cell><cell>(78, 56.1)</cell><cell cols="2">(75, 81.9)</cell><cell>(67.1, 64.9)</cell><cell>(-, 81.9)</cell><cell>(97.4, -)</cell><cell>(97.6, 97.2)</cell><cell>(99.1, 97.9)</cell><cell>(99.2, 97.8)</cell></row><row><cell>Tile</cell><cell>(59, 17.5)</cell><cell cols="2">(51, 89.7)</cell><cell>(51.3, 24.2)</cell><cell>(-, 91.2)</cell><cell>(91.4, -)</cell><cell>(87.4, 75.9)</cell><cell>(91.2, 81.6)</cell><cell>(94.1, 86.0)</cell></row><row><cell>Wood</cell><cell>(73, 60.5)</cell><cell cols="2">(73, 72.7)</cell><cell>(66.6, 57.8)</cell><cell>(-, 72.5)</cell><cell>(90.8, -)</cell><cell>(88.5, 87.4)</cell><cell>(93.6, 90.3)</cell><cell>(94.9, 91.1)</cell></row><row><cell>All texture classes</cell><cell>(78, 56.7)</cell><cell cols="2">(70, 69.6)</cell><cell>(61.2, 49.9)</cell><cell>(-, 79.4)</cell><cell>(93.7, -)</cell><cell>(92.9, 88.4)</cell><cell>(95.6, 91.3)</cell><cell>(96.9, 93.2)</cell></row><row><cell>Bottle</cell><cell>(93, 83.4)</cell><cell cols="2">(86, 91.0)</cell><cell>(83.1, 70.5)</cell><cell>(-, 91.8)</cell><cell>(98.1, -)</cell><cell>(98.4, 95.5)</cell><cell>(98.1, 93.9)</cell><cell>(98.3, 94.8)</cell></row><row><cell>Cable</cell><cell>(82, 47.8)</cell><cell cols="2">(86, 82.5)</cell><cell>(83.1, 77.9)</cell><cell>(-, 86.5)</cell><cell>(96.8, -)</cell><cell>(97.2, 90.9)</cell><cell>(95.8, 86.2)</cell><cell>(96.7, 88.8)</cell></row><row><cell>Capsule</cell><cell>(94, 86.0)</cell><cell cols="2">(88, 86.2)</cell><cell>(81.7, 77.9)</cell><cell>(-, 91.6)</cell><cell>(95.8, -)</cell><cell>(99.0 ,93.7)</cell><cell>(98.3, 91.9)</cell><cell>(98.5, 93.5)</cell></row><row><cell>Hazelnut</cell><cell>(97, 91.6)</cell><cell cols="2">(95, 91.7)</cell><cell>(87.7, 77.0)</cell><cell>(-, 93.7)</cell><cell>(97.5, -)</cell><cell>(99.1, 95.4)</cell><cell>(97.7, 91.4)</cell><cell>(98.2, 92.6)</cell></row><row><cell>Metal Nut</cell><cell>(89, 60.3)</cell><cell cols="2">(86, 83.0)</cell><cell>(78.7, 57.6)</cell><cell>(-, 89.5)</cell><cell>(98.0, -)</cell><cell>(98.1, 94.4)</cell><cell>(96.7, 81.9)</cell><cell>(97.2, 85.6)</cell></row><row><cell>Pill</cell><cell>(91, 83.0)</cell><cell cols="2">(85, 89.3)</cell><cell>(81.3, 79.3)</cell><cell>(-, 93.5)</cell><cell>(95.1, -)</cell><cell>(96.5, 94.6)</cell><cell>(94.7, 90.6)</cell><cell>(95.7, 92.7)</cell></row><row><cell>Screw</cell><cell>(96, 88.7)</cell><cell cols="2">(96, 75.4)</cell><cell>(75.3, 66.4)</cell><cell>(-, 92.8)</cell><cell>(95.7, -)</cell><cell>(98.9, 96.0)</cell><cell>(97.4, 91.3)</cell><cell>(98.5, 94.4)</cell></row><row><cell>Toothbrush</cell><cell>(92, 78.4)</cell><cell cols="2">(93, 82.2)</cell><cell>(91.9, 85.4)</cell><cell>(-, 86.3)</cell><cell>(98.1, -)</cell><cell>(97.9, 93.5)</cell><cell>(98.7, 92.3)</cell><cell>(98.8, 93.1)</cell></row><row><cell>Transistor</cell><cell>(90, 72.5)</cell><cell cols="2">(86, 72.8)</cell><cell>(75.4, 61.0)</cell><cell>(-, 70.1)</cell><cell>(97.0, -)</cell><cell>(94.1, 87.4)</cell><cell>(97.2, 80.2)</cell><cell>(97.5, 84.5)</cell></row><row><cell>Zipper</cell><cell>(88, 66.5)</cell><cell cols="2">(77, 83.9)</cell><cell>(71.6, 60.8)</cell><cell>(-, 93.3)</cell><cell>(95.1, -)</cell><cell>(96.5, 92.6)</cell><cell>(98.2, 94.7)</cell><cell>(98.5, 95.9)</cell></row><row><cell>All object classes</cell><cell>(91, 75.8)</cell><cell cols="2">(88, 83.8)</cell><cell>(81.0, 71.4)</cell><cell>(-, 88.9)</cell><cell>(96.7, -)</cell><cell>(97.6, 93.4)</cell><cell>(97.3, 89.4)</cell><cell>(97.8, 91.6)</cell></row><row><cell>All classes</cell><cell>(87, 69.4)</cell><cell cols="2">(82, 79.0)</cell><cell>(74.4, 64.2)</cell><cell>(-, 85.7)</cell><cell>(95.7, -)</cell><cell>(96.5, 91.7)</cell><cell>(96.7, 90.1)</cell><cell>(97.5, 92.1)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE IV COMPARISON</head><label>IV</label><figDesc>OF OUR PADIM MODEL WITH THE STATE-OF-THE-ART FOR THE ANOMALY LOCALIZATION ON THE STC IN THE AUROC%.</figDesc><table><row><cell>Model</cell><cell>CAVGA-RU [3]</cell><cell>SPADE [5]</cell><cell>PaDiM-R18-Rd100</cell></row><row><cell>AUROC score%</cell><cell>85</cell><cell>89.9</cell><cell>91.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE V ANOMALY</head><label>V</label><figDesc>DETECTION RESULTS (AT THE IMAGE LEVEL) ON THE MVTEC AD USING AUROC%.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE VI ANOMALY</head><label>VI</label><figDesc>LOCALIZATION RESULTS ON THE NON-ALIGNED RD-MVTEC AD. RESULTS ARE DISPLAYED AS TUPLES (AUROC%, PRO-SCORE%)</figDesc><table><row><cell>Model</cell><cell>VAE (R18)</cell><cell>SPADE</cell><cell>PaDiM-WR50-</cell></row><row><cell></cell><cell></cell><cell>(WR50)</cell><cell>Rd550</cell></row><row><cell>all texture classes</cell><cell>(54.7, 23.1)</cell><cell>(84.6, 75.6)</cell><cell>(92.4, 77.9)</cell></row><row><cell>all object classes</cell><cell>(65.8, 30.2)</cell><cell>(88.2, 65.8)</cell><cell>(92.1, 70.8)</cell></row><row><cell>all classes</cell><cell>(62.1, 27.8)</cell><cell>(87.2, 69.0)</cell><cell>(92.2, 73.1)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE VII AVERAGE</head><label>VII</label><figDesc>INFERENCE TIME OF ANOMALY LOCALIZATION IN SECONDS ON THE MVTEC AD WITH A CPU INTEL I7-4710HQ @ 2.50GHZ.</figDesc><table><row><cell>Model</cell><cell>SPADE</cell><cell>VAE</cell><cell>PaDiM</cell><cell>PaDiM-</cell></row><row><cell></cell><cell>(WR50)</cell><cell>(R18)</cell><cell>R18-Rd100</cell><cell>WR50-Rd550</cell></row><row><cell cols="2">Inference time (sec.) 7.10</cell><cell>0.21</cell><cell>0.23</cell><cell>0.95</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>TABLE VIII MEMORY</head><label>VIII</label><figDesc>REQUIREMENT IN GB OF THE ANOMALY LOCALIZATION METHODS TRAINED ON THE MVTEC AD AND THE STC DATASET.</figDesc><table><row><cell>model</cell><cell>SPADE</cell><cell>VAE</cell><cell>PaDiM</cell><cell>PaDiM-</cell></row><row><cell></cell><cell>(WR50)</cell><cell>(R18)</cell><cell>R18-Rd100</cell><cell>WR50-Rd550</cell></row><row><cell cols="2">MVTec AD 1.4</cell><cell>0.09</cell><cell>0.17</cell><cell>3.8</cell></row><row><cell>STC</cell><cell>37.0</cell><cell>-</cell><cell>0.21</cell><cell>5.2</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Mvtec ad-a comprehensive real-world dataset for unsupervised anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sattlegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Steger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Uninformed students: Student-teacher anomaly detection with discriminative latent embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sattlegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Steger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Attention guided anomaly localization in images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Venkataramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-C</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">V</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mahalanobis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1911" />
		</imprint>
	</monogr>
	<note>in arXiv</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Patch svdd: Patch-level svdd for anomaly detection and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yoon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note>in arXiv</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Sub-image anomaly detection with deep pyramid correspondences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hoshen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>in arXiv</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Classification-based anomaly detection for general data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bergman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hoshen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Nearest neighbor pattern classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="27" />
			<date type="published" when="1967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Future frame prediction for anomaly detection -a new baseline</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L W</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Improving unsupervised defect segmentation by applying structural similarity to autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Löwe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sattlegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Steger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>VISIGRAPP</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Memorizing normality to detect anomaly: Memoryaugmented deep autoencoder for unsupervised anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Mansour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hengel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Attribute restoration framework for anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1911" />
		</imprint>
	</monogr>
	<note>in arXiv</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Predictable uncertainty-aware unsupervised deep anomaly segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Matsubara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Uehara</surname></persName>
		</author>
		<editor>IJCNN</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Towards visually explaining variational autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Karanam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bhanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J R</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Camps</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Adversarially learned one-class classifier for novelty detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sabokrou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Khalooei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Adeli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Generative probabilistic novelty detection with adversarial autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pidhorskyi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Almohsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Adjeroh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Doretto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Ganomaly: Semisupervised anomaly detection via adversarial training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Akcay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Atapour-Abarghouei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">P</forename><surname>Breckon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ACCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Latent space autoregression for novelty detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Abati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Porrello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Calderara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cucchiara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Rapp: Novelty detection with reconstruction along projection pathway</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jeon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Yoon</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Skip-ganomaly: Skip connected and adversarially trained encoder-decoder anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Akçay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Atapour-Abarghouei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">P</forename><surname>Breckon</surname></persName>
		</author>
		<editor>IJCNN</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">OCGAN: one-class novelty detection using gans with constrained latent representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deep one-class classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ruff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vandermeulen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goernitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deecke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Siddiqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kloft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLM</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Modeling the distribution of normal data in pre-trained deep features for anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Rippel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mertens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Merhof</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>in arXiv</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Deep nearest neighbor anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bergman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hoshen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
	<note>in arXiv</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Anomaly detection in nanofibrous materials by cnn-based self-similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Napoletano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Piccoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">209</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A simple unified framework for detecting out-of-distribution samples and adversarial attacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Wide residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Efficientnet: Rethinking model scaling for convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">On lines and planes of closest fit to systems of points in space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Pearson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="559" to="572" />
			<date type="published" when="1901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">On the generalized distance in statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mahalanobis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1936" />
		</imprint>
		<respStmt>
			<orgName>National Institute of Science of India</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">ImageNet: A Large-Scale Hierarchical Image Database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
