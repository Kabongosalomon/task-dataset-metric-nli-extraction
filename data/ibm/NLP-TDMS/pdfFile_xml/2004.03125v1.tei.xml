<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">RYANSQL: Recursively Applying Sketch-based Slot Fillings for Complex Text-to-SQL in Cross-Domain Databases</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghyun</forename><surname>Choi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Kakao Enterprise</orgName>
								<address>
									<settlement>Pangyo</settlement>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Sungkyunkwan University</orgName>
								<address>
									<settlement>Suwon</settlement>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myeong</forename><forename type="middle">Cheol</forename><surname>Shin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Kakao Enterprise</orgName>
								<address>
									<settlement>Pangyo</settlement>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunggyun</forename><surname>Kim</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Kakao Enterprise</orgName>
								<address>
									<settlement>Pangyo</settlement>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><forename type="middle">Ryeol</forename><surname>Shin</surname></persName>
							<email>drshin@skku.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">Sungkyunkwan University</orgName>
								<address>
									<settlement>Suwon</settlement>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">RYANSQL: Recursively Applying Sketch-based Slot Fillings for Complex Text-to-SQL in Cross-Domain Databases</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T21:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Text-to-SQL is the problem of converting a user question into an SQL query, when the question and database are given. In this paper, we present a neural network approach called RYANSQL (Recursively Yielding Annotation Network for SQL) to solve complex Text-to-SQL tasks for cross-domain databases. Statement Position Code (SPC) is defined to transform a nested SQL query into a set of nonnested SELECT statements; a sketch-based slot filling approach is proposed to synthesize each SELECT statement for its corresponding SPC. Additionally, two input manipulation methods are presented to improve generation performance further. RYANSQL achieved 58.2% accuracy on the challenging Spider benchmark, which is a 3.2%p improvement over previous state-of-the-art approaches. At the time of writing, RYANSQL achieves the first position on the Spider leaderboard.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Text-to-SQL is the task of generating SQL queries when database and natural language user questions are given. Recently proposed neural net architectures achieved more than 80% exact matching accuracy on the well-known Text-to-SQL benchmarks such as ATIS, GeoQuery and WikiSQL <ref type="bibr" target="#b20">(Xu et al., 2017;</ref><ref type="bibr" target="#b23">Yu et al., 2018a;</ref><ref type="bibr" target="#b14">Shi et al., 2018;</ref><ref type="bibr" target="#b5">Dong and Lapata, 2018;</ref><ref type="bibr" target="#b9">Hwang et al., 2019;</ref><ref type="bibr" target="#b7">He et al., 2019)</ref>. However, those benchmarks have shortcomings of either assuming the same database across the training and test dataset(ATIS, GeoQuery) or assuming the database of a single table and restricting the complexity of SQL query to have a unitary SELECT statement with a single SELECT and WHERE clause (WikiSQL).</p><p>Different from those benchmarks, the Spider benchmark proposed by <ref type="bibr" target="#b24">Yu et al. (2018b)</ref> contains complex SQL queries with cross-domain databases.</p><p>Cross-domain means that the databases for the training dataset and test dataset are different; the system should predict with an unseen database as its input during testing. Also, different from another cross-domain benchmark WikiSQL, the SQL queries in Spider benchmark contain nested queries with multiple JOINed tables, and clauses like ORDERBY, GROUPBY, and HAVING. <ref type="bibr" target="#b24">Yu et al. (2018b)</ref> showed that the state-of-the-art systems for the previous benchmarks do not perform well on the Spider dataset.</p><p>In this paper, we propose a novel network architecture called RYANSQL (Recursively Yielding Annotation Network for SQL) to handle such complex, cross-domain Text-to-SQL problem. The proposed approach generates nested queries by recursively yielding its component SELECT statements. A sketch-based slot filling approach is proposed to predict each SELECT statement. In addition, two simple but effective input manipulation methods are proposed to improve the overall system performance. The proposed system improves the previous state-of-the-art system by 3.2%p in terms of the test set exact matching accuracy, using BERT <ref type="bibr" target="#b3">(Devlin et al., 2019)</ref>. Our contributions are summarized as follows.</p><p>• We propose a detailed sketch for the complex SELECT statements, along with a network architecture to fill the slots.</p><p>• Statement Position Code (SPC) is introduced to recursively predict nested queries with sketch-based slot filling algorithm.</p><p>• We suggest two simple input manipulation methods to improve performance further. Those methods are easy to apply, and they improve the overall system performance significantly. Most recent works on Text-to-SQL task used encoder-decoder model. Those works could be classified into three main categories, based on their decoder outputs. Direct Sequence-to-Sequence approaches <ref type="bibr" target="#b4">(Dong and Lapata, 2016;</ref><ref type="bibr" target="#b25">Zhong et al., 2017)</ref> generate SQL query tokens as their decoder outputs; due to the risk of generating grammatically incorrect SQL queries, the Direct Sequenceto-Sequence approaches are rarely used in recent works.</p><p>Grammar-based approaches generate a sequence of grammar rules and apply the generated rules sequentially to get the resultant SQL query. <ref type="bibr" target="#b14">Shi et al. (2018)</ref> defines a structural representation of an SQL query and a set of parse actions to handle the WikiSQL dataset. <ref type="bibr" target="#b6">Guo et al. (2019)</ref> defines SemQL queries, which is an abstraction of SQL query in tree form, along with a set of grammar rules to synthesize SemQL queries; Synthesizing SQL query from a SemQL tree structure is straightforward.  focused on the DB constraints selection problem during the grammar decoding process; they applied global reasoning between question words and database columns/tables. Sketch-based slot-filling approaches, firstly proposed by <ref type="bibr" target="#b20">Xu et al. (2017)</ref> to handle the WikiSQL dataset, define a sketch with slots for SQL queries, and the decoder classifies values for those slots. Sketch-based approaches <ref type="bibr" target="#b9">Hwang et al. (2019)</ref> and <ref type="bibr" target="#b7">He et al. (2019)</ref> achieved state-of-the-art performances on the WikiSQL dataset, with the aid of BERT <ref type="bibr" target="#b3">(Devlin et al., 2019)</ref>. However, sketch-based approach on more complex Spider benchmark <ref type="bibr" target="#b10">(Lee, 2019)</ref> showed relatively low performance compared to the grammar-based approaches. There are two major reasons: (1) It is hard to define a sketch for Spider queries since the allowed syntax of the Spider SQL queries is far more complicated than that of the WikiSQL queries. (2) Since the sketchbased approaches fill values for the predefined slots, the approaches have difficulties in predicting the nested queries.</p><p>In this paper, a sketch-based slot filling approach is proposed to solve the complex Text-to-SQL problem. A detailed sketch for complex SELECT statements is newly proposed, along with Statement Position Code (SPC) to effectively predict for the nested queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Q</head><p>Find the name of airports which do not have any flight in and out. </p><formula xml:id="formula_0">S SELECT AirportName FROM Airports WHERE AirportCode NOT IN (SELECT SourceAirport FROM Flights UNION SELECT DestAirport FROM Flights) N(S) P 1 [ NONE ] S 1 SELECT AirportName FROM Airports WHERE AirportCode NOT IN S 2 P 2 [ WHERE ] S 2 SELECT SourceAirport FROM Flights UNION S 3 P 3 [ WHERE, UNION ] S 3 SELECT DestAirport FROM Flights</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Task Definition</head><p>The Text-to-SQL task considered in this paper is defined as follows: Given a question with n tokens Q = {w Q 1 , ..., w Q n } and a DB schema with t tables and f foreign key relations D = {T 1 , ..., T t , F 1 , ..., F f }, find S, the SQL translation of Q. Each table T i consists of a table name with t i words {w T i 1 , ..., w T i t i }, and a set of columns {C j , ..., C k }. Each column C j consists of a column name {w C j 1 , ..., w C j c j }, and a marker to check if the column is a primary key.</p><p>For an SQL query S we define a non-nested form of S, N (S) = {(P 1 , S 1 ), ..., (P l , S l )}. In the definition, P i is the i-th SPC, and S i is its corresponding SELECT statement. <ref type="table" target="#tab_1">Table 1</ref> shows an example of natural language query Q, SQL translation S and its non-nested form N (S).</p><p>Each SPC P could be considered as a sequence of p position code elements, P = [c P 1 , ..., c P p ]. The possible set of position code elements is {NONE, UNION, INTERSECT, EXCEPT, WHERE, HAVING, PARALLEL}. NONE represents the outermost statement, while PARALLEL means the parallel elements inside a single clause like the second element of the WHERE clause. Other position code elements represent corresponding SQL clauses.</p><p>Since it is straightforward to construct S from N (S), the goal of the proposed system is to construct N (S) for the given Q and D. To achieve the goal, the proposed system first sets the initial SPC P 1 = [NONE], and predicts its corresponding  -.</p><p>, . Conv + Max-Pooling</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NAME</head><formula xml:id="formula_1">⧺ ⧺ ⧺ ⧺ ⧺ ⧺ ⧺ ⧺ ⧺ ⧺ ⧺ M M M M M M " + ) + ℎ " , ℎ 7 , ℎ 8 , ℎ 9 , ⧺ ⧺ ⧺ ⧺ Question- Column Alignment " , 7 , 8 , 9 ,</formula><p>Transformer <ref type="table" target="#tab_3">Table  Encoder</ref> Question- <ref type="table" target="#tab_3">Table  Alignment</ref> OUTPUTS SELECT statement and nested SPCs. The system recursively finds out the corresponding SELECT statements for remaining SPCs, until every SPC has its corresponding SELECT statement.</p><formula xml:id="formula_2">… … … … … … … … … … … … … … … … … … … … … … … … … … … … … S ℎ " + ℎ ) + … " # $ # % # " + ) + … " ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Generating a SELECT Statement</head><p>In this section, the method to create the SELECT statement for the given question Q, database D, and SPC P is described. Section 4.1 describes the input encoder; the sketch-based slot-filling decoder is described in section 4.2. <ref type="figure" target="#fig_1">Figure 1</ref> shows the overall network architecture. The input encoder consists of five layers: Embedding layer, Embedding Encoder layer, Question-Column Alignment layer, Embedding. To get the embedding vector for a word w in question, table names or column names, its word embedding and character embedding are concatenated. The word embedding is initialized with d 1 = 300-dimensional pre-trained GloVe <ref type="bibr" target="#b13">(Pennington et al., 2014)</ref> word vectors, and is fixed during training. For character embedding, each character is represented as a trainable vector of dimension d 2 = 50, and we take maximum value of each dimension of component characters to get the fixed-length vector. The two vectors are then concatenated to get the embedding vector e w ∈ R d 1 +d 2 . One layer highway network <ref type="bibr" target="#b16">(Srivastava et al., 2015)</ref> is applied on top of this representation. For SPC P , each code element c is represented as a trainable vector of dimension d p = 100.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Input Encoder</head><p>Embedding Encoder. One dimensional convolution layer with kernel size 3 is applied on SPC element embedding vectors {e P 1 , ..., e P p }. Maxpooling is applied on the output to get the SPC vector v P ∈ R p×dp . v P is then concatenated to each question and column word embedding vector.</p><p>CNN with Dense Connection proposed in <ref type="bibr" target="#b22">Yoon et al. (2018)</ref> is applied to encode each word of question and columns to capture local information. Parameters are shared across the question and columns. For each column, a max-pooling layer is followed; outputs are concatenated with their table name representations and projected to dimension d. Layer outputs are encoded question</p><formula xml:id="formula_3">words V Q = {v Q 1 , v Q 2 , ..., v Q n } ∈ R n×d , and hid- den column vectors H C = {h C 1 , ..., h C m } ∈ R m×d .</formula><p>Question-Column Alignment. In this layer, the column vectors are modeled with contextual information of the question by attending question tokens with their corresponding columns. Scaled dot-product attention <ref type="bibr">(Vaswani et al., 2017)</ref> is used to align question tokens with column vectors:</p><formula xml:id="formula_4">A QtoC = softmax( H C · (V Q ) √ d ) · V Q<label>(1)</label></formula><p>Where each i-th row of A QtoC ∈ R m×d is an attended question vector of the i-th column.</p><p>The heuristic fusion function f usion(x, y), proposed in <ref type="bibr" target="#b8">Hu et al. (2018)</ref>, is applied to merge A QtoC with H C :</p><formula xml:id="formula_5">x = relu(W r [x; y; x • y; x − y]) g = σ(W g [x; y; x • y; x − y]) f usion(x, y) = g •x + (1 − g) • x F C = f usion(A QtoC , H C )<label>(2)</label></formula><p>Where W r and W g are trainable variables, σ denotes the sigmoid function, • denotes element-wise multiplication and F C ∈ R m×d is fused column matrix. A transformer layer <ref type="bibr">(Vaswani et al., 2017)</ref> is applied on top of F C to capture contextual column information. Layer outputs are the encoded column vectors </p><formula xml:id="formula_6">V C = {v C 1 , ..., v C m } ∈ R m×d .</formula><formula xml:id="formula_7">f s (M ) = softmax(W 2 tanh(W 1 M ))M<label>(3)</label></formula><p>Where W 1 ∈ R d×d , W 2 ∈ R 1×d are trainable parameters. Then, for table t with columns {C j , ..., C k }, the hidden table vector h T t is calculated as follows: </p><formula xml:id="formula_8">h T t = f s ([v C j ; ...; v C k ])<label>(4)</label></formula><formula xml:id="formula_9">T = {v T 1 , v T 2 , ..., v T t } ∈ R t×d .</formula><p>Output. Final outputs of the input encoder are:</p><formula xml:id="formula_10">(1) Encoded question words V Q = {v Q 1 , ..., v Q n } ∈ R n×d , (2) Encoded columns V C = {v C 1 , ..., v C m } ∈ R m×d , (3) Encoded tables V T = {v T 1 , ..., v T t } ∈ R t×d , and (4) Encoded SPC v P ∈ R dp . Addition- ally, (5) Encoded question v Q = f s (V Q ) and (6) Encoded DB schema v D = f s (V C ) ∈ R d are cal- culated for later use.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">BERT-based Input Encoder</head><p>Inspired by the work of <ref type="bibr" target="#b9">Hwang et al. (2019)</ref> and <ref type="bibr" target="#b6">Guo et al. (2019)</ref>, BERT <ref type="bibr" target="#b3">(Devlin et al., 2019)</ref> is considered as another version of input encoder. The input to BERT is constructed by concatenating question words, SPC elements and column words as follows:</p><formula xml:id="formula_11">[CLS], w Q i , [SEP], c P j , [SEP], w C 1 k , [SEP], ..., w Cm l , [SEP]</formula><p>. Hidden states of the last layer are retrieved to form V Q and V C ; for V C , the state of each column's last word is taken to represent encoded column vector. Each table vector v T j is calculated as a self-attended vector of its containing columns; v Q , v D , and v P are calculated as the same. <ref type="table" target="#tab_3">Table 2</ref> shows the proposed sketch for a SELECT statement. The sketch-based slot-filling decoder predicts values for slots of the proposed sketch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Sketch-based Slot-Filling Decoder</head><p>Classifying Base Structure. By the term base structure of a SELECT statement, we refer to the existence of its component clauses and the number of conditions for each clause. We first combine the encoded vectors v Q , v D and v P to get the statement encoding vector v S , as follows:</p><formula xml:id="formula_12">hc(x, y) = concat(x, y, |x − y|, x • y) (5) v S = W · concat(hc(v Q , v D ), v P ) (6)</formula><p>Where W ∈ R d×(4d+dp) is a trainable parameter, and function hc(x, y) is the concatenation function for heuristic matching method proposed in <ref type="bibr" target="#b12">Mou et al. (2016)</ref>.</p><p>Eleven values b g , b o , b l , b w , b h , n g , n o , n s , n w , n h and c IUEN are classified by applying two fully-connected layers on v S . Binary values b g , b o , b l , b w , b h represent the existence of GROUPBY, ORDERBY, LIMIT, WHERE and HAVING, respectively. Note that FROM and SELECT clauses must exist to form a valid SELECT statement. n g , n o , n s , n w , n h represent $AGG is one of {none, max, min, count, sum, avg}, $ARI is one of the arithmetic operators {none, -, +, *, / }, and $COND is one of the conditional operators {between, =, &gt;, &lt;, &gt;=, &lt;=, !=, in, like, is, exists}. $DIST and $NOT are boolean variables representing the existence of keywords DISTINCT and NOT, respectively. $ORD is a binary value for keywords ASC/DESC, and $CONJ is one of conjunctions {AND, OR}. $VAL is the value for WHERE/HAVING condition; $SEL represents the slot for another SELECT statement. the number of conditions in GROUPBY, ORDERBY, SELECT, WHERE and HAVING clause, respectively. The maximal number of conditions N g = 3, N o = 3, N s = 6, N w = 4, and N h = 2 are defined for GROUPBY, ORDERBY, SELECT, WHERE and HAVING clauses, to solve the problem as n-way classification problem. The values of maximal condition numbers are chosen to cover all the training cases.</p><formula xml:id="formula_13">CLAUSE SKETCH FROM ($TBL) + SELECT $DIST ( $AGG ( $DIST 1 $AGG 1 $COL 1 $ARI $DIST 2 $AGG 2 $COL 2 ) ) + ORDERBY ( ( $DIST 1 $AGG 1 $COL 1 $ARI $DIST 2 $AGG 2 $COL 2 ) $ORD ) * GROUPBY ( $COL ) * LIMIT $NUM WHERE ( $CONJ ( $DIST 1 $AGG 1 $COL 1 $ARI $DIST 2 $AGG 2 $COL 2 ) HAVING $NOT $COND $VAL 1 |$SEL 1 $VAL 2 |$SEL 2 ) * INTERSECT UNION $SEL EXCEPT</formula><p>Finally, c IUEN represents the existence of one of INTERSECT, UNION or EXCEPT, or NONE if no such clause exists. If the value of c IUEN is one of INTERSECT, UNION or EXCEPT, the corresponding SPC is created, and the SELECT statement for that SPC is generated recursively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FROM clause.</head><p>A list of $TBLs should be decided to predict the FROM clause. For each table i, P fromtbl (i|Q, D, P ), the probability that table i is included in the FROM clause, is calculated:</p><formula xml:id="formula_14">c i = concat(v T i , v Q , v D , v P ) s i = W 2 tanh(W 1 · c i ) (7) P fromtbl (i|Q, D, P ) = σ(s) i</formula><p>Where W 1 , W 2 are trainable variables, s = [s 1 , ..., s t ] ∈ R t and σ denotes the sigmoid function. From now on, we omit the notations Q, D and P for the sake of simplicity.</p><p>Top n t tables with the highest P fromtbl (i) values are chosen. We set an upper bound N t = 6 on possible number of tables. The formula to get P #tbl (n t ) for each possible n t is:</p><formula xml:id="formula_15">v T = softmax(s) · V T P #tbl (n t ) = softmax(f ull 2 (v T ))<label>(8)</label></formula><p>In the equation, f ull 2 means the application of two fully-connected layers, and table score vector s is from equation 7.</p><p>SELECT clause. The decoder first generates N s conditions to predict the SELECT. Since each condition depends on different parts of Q, we calculate attended question vector for each condition:</p><formula xml:id="formula_16">A Q sel = W 3 tanh(V Q · W 1 + v P · W 2 ) V Q sel = softmax(A Q sel ) · V Q<label>(9)</label></formula><p>While W 1 , W 2 ∈ R d×d , W 3 ∈ R Ns×d are trainable parameters, and V Q sel ∈ R Ns×d is the matrix of attended question vectors for N s conditions. v P is tiled to match the row of V Q .</p><p>For m columns and N s conditions, P sel col1 ∈ R Ns×m , the probability matrix for each column to fill the slot $COL 1 of each condition, is calculated as follows:</p><formula xml:id="formula_17">A C sel [i] = W 6 tanh(V Q sel [i] · W 4 + V C · W 5 ) P sel col1 [i] = softmax(A C sel [i])<label>(10)</label></formula><p>Where W 4 , W 5 ∈ R d×d and W 6 ∈ R 1×d are trainable parameters. The notation M [i] is used to represent the i-th row of matrix M .</p><p>The attended question vectors are then updated with selected column information to get the updated question vector U Q sel col1 ∈ R Ns×d :</p><formula xml:id="formula_18">U C sel col1 [i] = P sel col1 [i] · V C U Q sel col1 [i] = W 7 · hc(V Q sel [i], U C sel col1 [i])<label>(11)</label></formula><p>Where W 7 is a trainable variable, and hc(x, y) is defined in equation 5. The probabilities for $DIST 1 , $AGG 1 , $ARI and $AGG are calculated by applying a fully connected layer on</p><formula xml:id="formula_19">U Q sel col1 [i]. Equation 10 is reused to calculate P sel col2 , with V Q sel [i] replaced by U Q sel col1 [i]; then U Q sel col2</formula><p>is retrieved in the same way as equation 11, and the probabilities of $DIST 2 and $AGG 2 are calculated in the same way as $DIST 1 and $AGG 1 . Finally, the $DIST slot, DISTINCT marker for overall SELECT clause, is calculated by applying a fullyconnected layer on v S .</p><p>Once all the slots are filled for N s conditions, the decoder retrieves the first n s conditions to predict the SELECT clause. That is possible since the CNN with Dense Connection used for question encoding <ref type="bibr" target="#b22">(Yoon et al., 2018)</ref> captures relative position information. In combine with the SQL consistency protocol of the Spider benchmark <ref type="bibr" target="#b24">(Yu et al., 2018b)</ref>, we expect the conditions are ordered in the same way as they are presented in Q. For the datasets without such consistency protocol, the proposed slot filling method could easily be changed to an LSTM-based model, as shown in <ref type="bibr" target="#b20">Xu et al. (2017)</ref>.</p><p>ORDERBY clause. The same network structure as a SELECT clause is applied. The only difference is the prediction for $ORD slot; this could be done by applying a fully connected layer on U Q ob col1 , which is the correspondence of U Q sel col1 . GROUPBY clause. The same network structure as a SELECT clause is applied. For the GROUPBY case, retrieving only the values of P gb col1 is enough to fill the necessary slots.</p><p>LIMIT clause. Questions do not contain the $NUM slot value for LIMIT clauses explicitly in many cases, if the questions are for the top-1 result (Example: "Show the name and the release year of the song by the youngest singer"). Thus, the LIMIT decoder first determines if the given Q requests for the top-1 result. If so, the decoder sets the $NUM value to 1; otherwise, it tries to find the specific token for $NUM among the tokens of Q using pointer network <ref type="bibr" target="#b19">(Vinyals et al., 2015)</ref>. LIMIT Q: What are the papers of Liwen Xiong in 2015? SQL: SELECT DISTINCT t3.paperid FROM writes AS t2 JOIN author AS t1 ON t2.authorid = t1.authorid JOIN paper AS t3 ON t2.paperid = t3.paperid WHERE t1.authorname = "Liwen Xiong" AND t3.year = 2015; <ref type="table" target="#tab_3">Table 3: SQL statement with link table. Table writes</ref> is not explicitly mentioned in Q, but it is used in the JOIN statement to link between tables author and paper. top-1 probability P limit top1 is retrieved by applying a fully-connected layer on v S . P Q limit num [i], the probability of i-th question token for $NUM slot value, is calculated as:</p><formula xml:id="formula_20">A Q limit num = W 3 tanh(V Q · W 1 + v P · W 2 ) P Q limit num [i] = softmax(A Q limit num ) i (12) W 1 , W 2 ∈ R d×d , W 3 ∈ R 1×d are trainable parameters.</formula><p>WHERE clause. The same network structure as a SELECT clause is applied to get the attended question vectors V Q wh ∈ R Nw×d , and probabilities for $COL 1 , $COL 2 , $DIST 1 , $DIST 2 , $AGG 1 , $AGG 2 and $ARI. Besides, a fully-connected layer is applied on U Q wh col1 to get the probabilities for $CONJ, $NOT and $COND.</p><p>A fully-connected layer is applied on U Q wh col1</p><p>and U Q wh col2 to determine if the condition value for each column is another nested SELECT statement or not. If the value is determined as a nested SELECT statement, the corresponding SPC is generated, and the SELECT statement for the SPC is predicted recursively. If not, the pointer network is used to get the start and end position of the value span from question tokens.</p><p>HAVING clause. The same network structure as a WHERE clause is applied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Two Input Manipulation Methods</head><p>In this section, we introduce two input manipulation methods to improve the performance of our proposed system further.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">JOIN Table Filtering</head><p>In a FROM clause, some tables may be used only to make "link" between other tables; <ref type="table" target="#tab_3">Table 3</ref> shows  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Supplemented Column Names</head><p>We supplement the column names with its table names to distinguish between columns with the same name but belonging to different tables and representing different entities.  <ref type="bibr" target="#b24">(Yu et al., 2018b</ref>) is used to evaluate our proposed system. We use the same data split as <ref type="bibr" target="#b24">Yu et al. (2018b)</ref>; 206 databases are split into 146 train, 20 dev, and 40 test. All questions for the same database are in the same split; there are 8659 questions for train, 1034 for dev, and 2147 for test. The test set of Spider is not publicly available, so for testing our models are submitted to the data owner. For evaluation, we used exact matching accuracy, with the same definition as defined in <ref type="bibr" target="#b24">Yu et al. (2018b)</ref>.</p><p>Implementation. The proposed system is implemented with Tensorflow <ref type="bibr" target="#b0">(Abadi et al., 2015)</ref>. Layernorm <ref type="bibr" target="#b1">(Ba et al., 2016)</ref> and dropout <ref type="bibr" target="#b15">(Srivastava et al., 2014)</ref> are applied between layers, with a dropout rate of 0.  <ref type="table" target="#tab_3">Table 5</ref>: Comparison results with other state-of-the-art systems the validation dataset, and the training stops when the exact match score for the validation dataset is not improved for 20 consequent training epochs. Minibatch size is set to 16; learning rate is set to 4e −4 . Loss is defined as the sum of all classification losses from the slot-filling decoder.</p><p>For BERT-based input encoding, we downloaded the publicly available pre-trained model of BERT, BERT-Large, Uncased (Whole Word Masking), and fine-tuned the model during training. The learning rate is set to 1e −5 , and minibatch size is set to 4. <ref type="table" target="#tab_3">Table 5</ref> shows the comparisons of our system with several state-of-the-art systems; Evaluation scores for dev and test datasets are retrieved from the Spider leaderboard 1 . The performance of the proposed system is compared with grammar-based systems GrammarSQL <ref type="bibr" target="#b11">(Lin et al., 2019)</ref>, <ref type="bibr">Global-GNN (Bogin et al., 2019)</ref> and IRNet <ref type="bibr" target="#b6">(Guo et al., 2019)</ref>. Also, we compared the system performance with RCSQL <ref type="bibr" target="#b10">(Lee, 2019)</ref>, which so far showed the best performance on the Spider dataset using a sketch-based slot-filling approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Experimental Results</head><p>As can be observed from the table, the proposed system RYANSQL improves the previous slot filling based system RCSQL by a large margin of 15%p on the development dataset. With the use of BERT, our system outperforms the current stateof-the-art by 3.2%p on the hidden test dataset, in terms of exact matching accuracy.</p><p>Ablation studies are conducted to further figure out the effect of SPC and the two input manipulation methods. Since the test dataset is not publicly available, we use the development dataset to run the tests. The results are presented in <ref type="table" target="#tab_3">Table  Approach</ref>    6. In addition, the ablation study results of RYAN-SQL(BERT) for each hardness level is presented in <ref type="table" target="#tab_3">Table 7</ref>. The definitions of hardness levels are the same as the definitions in <ref type="bibr" target="#b24">Yu et al. (2018b)</ref>. In the tables, Proposed means our proposed system, while -SPC means the one without Statement Position Code, -JTF means the one without JOIN <ref type="table" target="#tab_3">Table Filtering</ref>, and -SCN means the one without Supplemented Column Names. As can be observed from the tables, the use of SPC significantly improves the system performance, especially for Hard and Extra Hard queries. The result suggests that by introducing the SPC the proposed system could effectively handle the nested queries. The JTF feature showed some improvements over Medium and Hard queries, meaning that the JTF feature is effective for handling the statements with multiple tables and clauses.</p><p>Finally, the SCN feature showed the most significant performance improvement among the three proposed features. When the SCN feature is used, the system performances of all hardness levels are improved significantly. The evaluation result suggests that our proposed input encoder network architectures do not integrate the table names efficiently during the encoding process. But the evaluation result also shows that the proposed system could successfully integrate the table names into encoding vectors by simply applying the proposed SCN feature, instead of modifying the network architectures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Error Analysis</head><p>We analyzed 345 failed examples of the RYAN-SQL(BERT) system on the development set. 195 of those examples are analyzed to figure out the main reasons for failure.</p><p>The most common cause of failure is column selection failure; 68 out of 195 cases (34.9%) suffered from the error. In many of those cases, the correct column name is not mentioned in a question; for example, for the question "What is the airport name for airport 'AKO'?", the decoder chooses column AirportName instead of AirportCode as its WHERE clause condition column. As mentioned in <ref type="bibr" target="#b21">Yavuz et al. (2018)</ref>, cell value examples for each column will be helpful to solve this problem.</p><p>The second frequent error is table number classification error; 49 out of 195 cases (25.2%) belong to the category. The decoder occasionally chooses too many tables for the FROM clause, resulting unnecessary table JOINs. Similarly, 22 out of 195 cases (11.3%) were due to condition number classification error. Those errors could be resolved by observing and updating the extracted slot values as a whole; our future work will focus on this problem.</p><p>The remaining 150 errors were either hard to be classified into one category, and some of them were due to different representations of the same meaning, for example: "SELECT max(age) FROM Dogs" vs. "SELECT age FROM Dogs ORDER BY age DESC LIMIT 1".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper, we proposed a sketch-based slot filling algorithm for complex, cross-domain Textto-SQL problem. A detailed sketch for complex SELECT statement prediction is proposed, along with the Statement Position Code to handle nested queries. Also, two input manipulation methods are proposed to enhance the overall system performance further. Our proposed system achieved the state-of-the-art performance on the challenging Spider benchmark dataset.</p><p>The error analysis suggests that we should update slot values based on other slots' prediction results. Our future work will focus on this slot value updating problem.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Network architecture of the proposed input encoder. ⧺ represents vector concatenation, M represents max-pooling and S represents self-attention.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Example of a user question Q, SQL translation S, and its non-nested form N (S).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE t</head><label>t</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell cols="2">CNN with</cell><cell>CNN with</cell><cell></cell><cell></cell><cell></cell><cell cols="2">CNN with</cell><cell cols="2">CNN with</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Dense</cell><cell></cell><cell>Dense</cell><cell></cell><cell></cell><cell></cell><cell>Dense</cell><cell></cell><cell>Dense</cell><cell></cell><cell></cell><cell></cell></row><row><cell>" + *</cell><cell>) * + *</cell><cell>" , *</cell><cell>-* , *</cell><cell>" , .</cell><cell>-. , .</cell><cell>" + /</cell><cell>) / + /</cell><cell>" , 0</cell><cell>-0 , 0</cell><cell>" , 1</cell><cell>-1 , 1</cell><cell>" 3</cell><cell>4 3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>" + /</cell><cell>) / + /</cell><cell>" , 0</cell><cell>-0 , 0</cell><cell>" , 1</cell><cell>-1 , 1</cell><cell>" 3</cell><cell>4 3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">COLUMN k</cell><cell cols="2">COLUMN m</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table</head><label></label><figDesc></figDesc><table /><note>Encoder layer, and Question-Table Alignment layer.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table Encoder .</head><label>Encoder</label><figDesc>Column vectors belonging to each table are integrated to get the encoded table vector. For a matrix M ∈ R n×d , self-attention function f s (M ) ∈ R 1×d is defined as follows:</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Layer outputs are the hidden table vectors H T = {h T 1 , h T 2 , ..., h T t } ∈ R t×d . Question-Table Alignment. In this layer, the same network architecture as the Question-Column alignment layer is used to model the table vectors with contextual information of the question. Layer outputs are the encoded table vectors V</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 2 :</head><label>2</label><figDesc>Proposed sketch for a SELECT statement. $TBL and $COL represent a table and a column, respectively.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table Column</head><label>Column</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell>SCN</cell></row><row><cell>tv channel</cell><cell cols="2">id series name tv channel series name tv channel id</cell></row><row><cell>tv series</cell><cell>id</cell><cell>tv series id</cell></row><row><cell>cartoon</cell><cell>id</cell><cell>cartoon id</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 4 :</head><label>4</label><figDesc>Examples of supplemented column names. SCN represents Supplemented Column Name.</figDesc><table><row><cell>such an example. Those "link" tables are necessary</cell></row><row><cell>to create the proper SELECT statement, but they</cell></row><row><cell>work as noise for Question-Table alignment since</cell></row><row><cell>they do not have the corresponding tokens in Q.</cell></row><row><cell>Thus, we discard those tables from FROM clauses</cell></row><row><cell>during training; while inferencing, the link tables</cell></row><row><cell>are easily recovered using foreign key relations.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table names</head><label>names</label><figDesc></figDesc><table><row><cell>are con-</cell></row><row><cell>catenated in front of their belonging column names</cell></row><row><cell>to form SCNs, but if the stemmed form of a table</cell></row><row><cell>name is wholly included in a stemmed form of the</cell></row><row><cell>column name, the table name is not concatenated.</cell></row><row><cell>Table 4 shows SCN examples; the three columns</cell></row><row><cell>with the same name id are distinguished using their</cell></row><row><cell>SCNs.</cell></row><row><cell>6 Experiment</cell></row><row><cell>6.1 Experiment Setup</cell></row><row><cell>Dataset. Spider dataset</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 6 :</head><label>6</label><figDesc>Ablation study results of RYANSQL and RYANSQL(BERT).</figDesc><table><row><cell cols="2">Approach Easy</cell><cell>Med-Hard ium</cell><cell>Extra Hard</cell></row><row><cell cols="4">Proposed 86.0% 70.5% 54.6% 40.6%</cell></row><row><cell>-SPC</cell><cell cols="3">85.6% 66.6% 27.0% 22.4%</cell></row><row><cell>-JTF</cell><cell cols="3">86.8% 66.1% 46.6% 42.4%</cell></row><row><cell>-SCN</cell><cell cols="3">76.4% 58.2% 46.6% 30.6%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 7 :</head><label>7</label><figDesc>Ablation study results of RYANSQL(BERT) for each hardness level.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://yale-lily.github.io/spider</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">TensorFlow: Large-scale machine learning on heterogeneous systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martín</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Craig</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Harp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafal</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manjunath</forename><surname>Kudlur ; Martin Wicke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqiang</forename><surname>Zheng</surname></persName>
		</author>
		<editor>Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viégas, Oriol Vinyals, Pete Warden</editor>
		<imprint>
			<date type="published" when="2015" />
			<pubPlace>Josh Levenberg, Dandelion Mané, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner</pubPlace>
		</imprint>
	</monogr>
	<note>Software available from tensorflow.org</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Hinton</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><forename type="middle">Lei</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><forename type="middle">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1607.06450</idno>
	</analytic>
	<monogr>
		<title level="m">Layer normalization. Computing Research Repository</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Global reasoning over database structures for textto-sql parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Bogin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3650" to="3655" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Language to logical form with neural attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="33" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Coarse-to-fine decoding for neural semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="731" to="742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Towards complex text-to-sql in cross-domain database with intermediate representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaqi</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zecheng</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Guang</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongmei</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.082057</idno>
	</analytic>
	<monogr>
		<title level="m">Computing Research Repository</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">X-sql: reinforce schema representation with context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengcheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaushik</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.08113</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">Computing Research Repository</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Reinforced mnemonic reader for machine reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghao</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxing</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 27th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4099" to="4106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wonseok</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinyeong</forename><surname>Yim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seunghyun</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.01069</idno>
		<title level="m">A comprehensive exploration on wikisql with table-aware word contextualization. Computing Research Repository</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Clause-wise and recursive decoding for complex and cross-domain text-to-sql generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongjun</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6047" to="6053" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Grammar-based neural text-to-sql generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Bogin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.13326</idno>
	</analytic>
	<monogr>
		<title level="j">Computing Research Repository</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>Jonathan Berant, and Matt Gardner</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Natural language inference by tree-based convolution and heuristic matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lili</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Men</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ge</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="130" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Incsql: Training incremental text-to-sql parsers with non-deterministic oracles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianze</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kedar</forename><surname>Tatwawadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaushik</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Polozov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.05054</idno>
	</analytic>
	<monogr>
		<title level="j">Computing Research Repository</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Training very deep networks. Advances in neural information processing systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rupesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jrgen</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schmidhuber</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2377" to="2385" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<imprint>
			<pubPlace>Llion Jones, Aidan N. Gomez, ukasz</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Attention is all you need. Advances in neural information processing systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Polosukhin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Pointer networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meire</forename><surname>Fortunato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2692" to="2700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.04436</idno>
		<title level="m">Sqlnet: Generating structured queries from natural language without reinforcement learning. Computing Research Repository</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">What it takes to achieve 100% condition accuracy on wikisql</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Semih</forename><surname>Yavuz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Izzeddin</forename><surname>Gur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xifeng</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1702" to="1711" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Dynamic self-attention : Computing attention over words dynamically for sentence embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deunsol</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongbok</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangkeun</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.073837</idno>
	</analytic>
	<monogr>
		<title level="m">Computing Research Repository</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Typesql: Knowledgebased type-aware neural text-to-sql generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zifan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zilin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="588" to="594" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Spider: A largescale human-labeled dataset for complex and crossdomain semantic parsing and text-to-sql task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michihiro</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongxu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zifan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irene</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingning</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanelle</forename><surname>Roman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zilin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3911" to="3921" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.00103</idno>
		<title level="m">Seq2sql: Generating structured queries from natural language using reinforcement learning. Computing Research Repository</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
