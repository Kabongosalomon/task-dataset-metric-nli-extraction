<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Published as a conference paper at ICLR 2020 ATOMNAS: FINE-GRAINED END-TO-END NEURAL ARCHITECTURE SEARCH</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jieru</forename><surname>Mei</surname></persName>
							<email>meijieru@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Johns Hopkins University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingwei</forename><surname>Li</surname></persName>
							<email>yingwei.li@jhu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Johns Hopkins University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaochen</forename><surname>Lian</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">ByteDance AI Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojie</forename><surname>Jin</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">ByteDance AI Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linjie</forename><surname>Yang</surname></persName>
							<email>linjie.yang@bytedance.com</email>
							<affiliation key="aff1">
								<orgName type="department">ByteDance AI Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
							<email>alan.l.yuille@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Johns Hopkins University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianchao</forename><surname>Yang</surname></persName>
							<email>yangjianchao@bytedance.com</email>
							<affiliation key="aff1">
								<orgName type="department">ByteDance AI Lab</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Published as a conference paper at ICLR 2020 ATOMNAS: FINE-GRAINED END-TO-END NEURAL ARCHITECTURE SEARCH</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Search space design is very critical to neural architecture search (NAS) algorithms. We propose a fine-grained search space comprised of atomic blocks, a minimal search unit that is much smaller than the ones used in recent NAS algorithms. This search space allows a mix of operations by composing different types of atomic blocks, while the search space in previous methods only allows homogeneous operations. Based on this search space, we propose a resource-aware architecture search framework which automatically assigns the computational resources (e.g., output channel numbers) for each operation by jointly considering the performance and the computational cost. In addition, to accelerate the search process, we propose a dynamic network shrinkage technique which prunes the atomic blocks with negligible influence on outputs on the fly. Instead of a searchand-retrain two-stage paradigm, our method simultaneously searches and trains the target architecture. Our method achieves state-of-the-art performance under several FLOPs configurations on ImageNet with a small searching cost. We open our entire codebase at: https://github.com/meijieru/AtomNAS. * This work was done during the internship program at Bytedance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Human-designed neural networks are already surpassed by machine-designed ones. Neural Architecture Search (NAS) has become the mainstream approach to discover efficient and powerful network structures <ref type="bibr">(Zoph &amp; Le (2017)</ref>; <ref type="bibr" target="#b25">Pham et al. (2018)</ref>; ; ). Although the tedious searching process is conducted by machines, humans still involve extensively in the design of the NAS algorithms. Designing of search spaces is critical for NAS algorithms and different choices have been explored. <ref type="bibr" target="#b0">Cai et al. (2019)</ref> and <ref type="bibr" target="#b34">Wu et al. (2019)</ref> utilize supernets with multiple choices in each layer to accommodate a sampled network on the GPU. <ref type="bibr" target="#b2">Chen et al. (2019b)</ref> progressively grow the depth of the supernet and remove unnecessary blocks during the search. <ref type="bibr" target="#b31">Tan &amp; Le (2019a)</ref> propose to search the scaling factor of image resolution, channel multiplier and layer numbers in scenarios with different computation budgets. <ref type="bibr" target="#b29">Stamoulis et al. (2019a)</ref> propose to use different kernel sizes in each layer of the supernet and reuse the weights of larger kernels for small kernels. ; <ref type="bibr" target="#b32">Tan &amp; Le (2019b)</ref> adopts Inverted Residuals with Linear Bottlenecks (MobileNetV2 block) <ref type="bibr" target="#b27">(Sandler et al., 2018)</ref>, a building block with light-weighted depth-wise convolutions for highly efficient networks in mobile scenarios.</p><p>However, the proposed search spaces generally have only a small set of choices for each block. DARTS and related methods <ref type="bibr" target="#b2">Chen et al., 2019b;</ref> use around 10 different operations between two network nodes. ; <ref type="bibr" target="#b0">Cai et al. (2019)</ref>; <ref type="bibr" target="#b34">Wu et al. (2019)</ref>; <ref type="bibr" target="#b29">Stamoulis et al. (2019a)</ref> search the expansion ratios in the MobileNetV2 block but still limit them to a few discrete values. We argue that search space of finer granularity is critical to find Published as a conference paper at ICLR 2020 optimal neural architectures. Specifically, the searched building block in a supernet should be as small as possible to generate the most diversified model structures.</p><p>We revisit the architectures of state-of-the-art networks ; <ref type="bibr" target="#b32">Tan &amp; Le (2019b)</ref>; <ref type="bibr" target="#b11">He et al. (2016)</ref>) and discover a commonly used building structure: convolution -channel-wise operation -convolution. We reinterpret this building structure as an ensemble of computationally independent blocks, which we call atomic blocks. As the minimum search unit, the atomic block constitutes a much larger and more fine-grained search space, within which we are able to search for mixed operations (e.g., convolutions with different kernel sizes and their channel numbers).</p><p>For the efficient exploration of the new search space, we propose a NAS framework named Atom-NAS which applies network pruning techniques to architecture search. Specifically, we start from an initial large supernet and rewrite every convolution -channel-wise operation -convolution structure of it in the form the weighted sum of atomic blocks; the weights reflect the contribution of the atomic blocks to the network capacity and are called importance factors. For each atomic block, a penalty term in proportion to its FLOPs is enforced on its importance factor; effectively, the penalty makes AtomNAS favor atomic blocks with less FLOPs. By minimizing the combination of the original network loss and the total penalty on the weights, AtomNAS is able to learn both the parameters of the network and the weights of the atomic blocks. At the end of the learning, atomic blocks with very small weights (e.g., &lt; 0.001) are removed from the network and we obtain the final network which has fewer FLOPs. Since the pruned atomic blocks have little contribution to the network output due to their negligible weights, the final network does not need to be retrained or finetuned.</p><p>Training on the large supernet is computationally demanding. We observe that for many pruned atomic blocks, their weights diminish at the early stage of learning and never "revive" throughout the rest of learning. We propose a dynamic network shrinkage technique which removes those atomic blocks on the fly and greatly reduces the run time of AtomNAS.</p><p>In our experiment, our method achieves 75.9% top-1 accuracy on ImageNet dataset around 360M FLOPs, which is 0.9% higher than state-of-the-art model <ref type="bibr" target="#b29">(Stamoulis et al., 2019a)</ref>. By further incorporating additional modules, our method achieves 77.6% top-1 accuracy. It outperforms MixNet by 0.6% using 363M FLOPs, which is a new state-of-the-art under the mobile scenario.</p><p>In summary, the major contributions of our work are: 1. We design a fine-grained search space which includes the exact number of channels and mixed operations (e.g., combination of different convolution kernels).</p><p>2. We propose an NAS framework, AtomNAS. Within the framework, an efficient end-to-end NAS algorithm is proposed which can simultaneously search the network architecture and train the final model. No finetuning is needed after the algorithm finishes.</p><p>3. With the proposed search space and AtomNAS, we achieve state-of-the-art performance on ImageNet dataset under mobile setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">NEURAL ARCHITECTURE SEARCH</head><p>Recently, there is a growing interest in automated neural architecture design. Reinforce learning based NAS methods <ref type="bibr">(Zoph &amp; Le, 2017;</ref><ref type="bibr" target="#b32">Tan &amp; Le, 2019b;</ref><ref type="bibr">a)</ref> are usually computational intensive, thus hampering its usage with limited computational budget. To accelerate the search procedure, ENAS <ref type="bibr" target="#b25">(Pham et al., 2018)</ref> represents the search space using a directed acyclic graph and aims to search the optimal subgraph within the large supergraph. A training strategy of parameter sharing among subgraphs is proposed to significantly increase the searching efficiency. The similar idea of optimizing optimal subgraphs within a supergraph is also adopted by Liu et al.  among different kernel sizes. Due to this limitation, it is difficult to learn optimal architectures under computational resource constraints. On the contrary, our method takes advantage of the fine-grained search space and is able to search for more flexible network architectures satisfying various resource constraints. The fine-grained search space proposed in this paper is exponentially larger than previous search space. For reference, the total number of possible structures within the experiment is around 10 162 , compared with 10 21 for FBNet. Recently, to improve the final performance of the searched architectures, Yu et al. (2020) utilizes knowledge distillation which is orthogonal to our method. It could be easily integrated into our method by Eq. (5) thanks to the end-to-end learning paradigm of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">NETWORK PRUNING</head><p>Assuming that many parameters in the network are unnecessary, network pruning methods start from a computation-intensive model, identify the unimportant connections and remove them to get a compact and efficient network. Early method <ref type="bibr" target="#b10">(Han et al., 2016)</ref> simultaneously learns the important connections and weights. However, non-regularly removing connections in these works makes it hard to achieve theoretical speedup ratio on realistic hardwares due to extra overhead in caching and indexing. To tackle this problem, structured network pruning methods <ref type="bibr" target="#b13">(He et al., 2017b;</ref><ref type="bibr" target="#b21">Liu et al., 2017;</ref><ref type="bibr" target="#b23">Luo et al., 2017;</ref><ref type="bibr" target="#b36">Ye et al., 2018;</ref><ref type="bibr" target="#b8">Gordon et al., 2018)</ref> are proposed to prune structured components in networks, e.g. the entire channel and kernel. In this way, empirical acceleration can be achieved on modern computing devices. <ref type="bibr" target="#b21">Liu et al. (2017)</ref>; <ref type="bibr" target="#b36">Ye et al. (2018)</ref>; <ref type="bibr" target="#b8">Gordon et al. (2018)</ref> encourage channel-level sparsity by imposing the L-1 regularizer on the channel dimension, which is also used by our method. Recently,  show that in structured network pruning, the learned weights are unimportant. This suggests structured network pruning is actually a neural architecture search focusing on channel numbers. Our method jointly searches the channel numbers and a mix of operations, which is a much larger search space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">ATOMNAS</head><p>We formulate our neural architecture search method in a fine-grained search space with the atomic block used as the basic search unit. An atomic block is comprised of two convolutions connected by a channel-wise operation. By stacking atomic blocks, we obtain larger building blocks (e.g. residual block and MobileNetV2 block proposed in a variety of state-of-the-art models including ResNet, MobileNet V2/V3 <ref type="bibr" target="#b11">(He et al., 2016;</ref><ref type="bibr" target="#b27">Sandler et al., 2018)</ref>. In Section 3.1, We first show larger network building blocks (e.g. MobileNetV2 block) can be represented by an ensembles of atomic blocks. Based on this view, we propose a fine-grained search space using atomic blocks. In Section 3.2, we propose a resource-aware atomic block selection method for end-to-end architecture search. Finally, we propose a dynamic network shrinkage technique in Section 3.3, which greatly reduces the search cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">FINE-GRAINED SEARCH SPACE</head><p>Under the typical block-wise NAS paradigm <ref type="bibr" target="#b32">Tan &amp; Le, 2019b)</ref>, the search space of each block in a neural network is represented as the Cartesian product C = i=1 P i , where each P i is the set of all choices of the i-th configuration such as kernel size, number of channels and type of operation. For example, C = {conv, depth-wise conv, dilated conv} × {3, 5} × {24, 32, 64, 128} represents a search space of three types of convolutions by two kernel sizes and four options of channel number. A block in the resulting model can only pick one convolution type from the three and one output channel number from the four values. This paradigm greatly limits the search space due to the few choices of each configuration. Here we present a more fine-grained search space by decomposing the network into smaller and more basic building blocks.</p><p>We denote f c ,c (X) as a convolution operator, where X is the input tensor and c, c are the input and output channel numbers respectively. A wide range of manually-designed and NAS architectures share a structure that joins two convolutions by a channel-wise operation:</p><formula xml:id="formula_1">Y = f c ,c 1 • g • f c ,c 0 (X)<label>(1)</label></formula><p>where g is a channel-wise operator. For example, in VGG <ref type="bibr" target="#b28">(Simonyan &amp; Zisserman, 2015)</ref> and a Residual Block <ref type="bibr" target="#b11">(He et al., 2016)</ref>, f 0 and f 1 are convolutions and g is one of Maxpool, ReLU and BN-ReLU; in a MobileNetV2 block <ref type="bibr" target="#b27">(Sandler et al., 2018)</ref>, f 0 and f 1 are point-wise convolutions and g is depth-wise convolution with BN-ReLU in the MobileNetV2 block. Eq. (1) can be reformulated as follows:</p><formula xml:id="formula_2">Y = c i=1 f c ,1 1 [i, :] • g[i, :] • f 1,c 0 [:, i] (X),<label>(2)</label></formula><p>where</p><formula xml:id="formula_3">f 1,c 0 [:, i] is the i-th convolution kernel of f 0 , g[i, :] is the operator of the i-th channel of g, and {f c ,1 1 [i, :]} c i=1</formula><p>are obtained by splitting the kernel tensor of f 1 along the the input channel dimension. Each term in the summation can be seen as a computationally independent block, which is called atomic block. This formulation also naturally includes the selection of operators. To gain a better understanding, we first generalize Eq. (2) as:</p><formula xml:id="formula_4">Y = c i=1 f c ,1 1i • g i • f 1,c 0i (X).</formula><p>(3)</p><p>Note the array indices i are moved to subscripts. In this formulation, we can use different types of operators for f 0i , f 1i and g i ; in other words, f 0 , f 1 and g can each be a combination of different operators and each atomic block can use different operators such as convolutions with different kernel sizes.</p><p>Formally, the search space is formulated as a supernet which is built based on the structure in Eq. <ref type="formula" target="#formula_0">(1)</ref>; such structure satisfies Eq.</p><p>(3) and thus can be represented by atomic blocks; each of f 0 , f 1 and g is a combination of operators. The new search space includes some state-of-the-art network architectures. For example, by allowing g to be a combination of convolutions with different kernel sizes, the MixConv block in MixNet <ref type="bibr" target="#b32">(Tan &amp; Le, 2019b</ref>) becomes a special case in our search space. In addition, our search space facilitates discarding any number of channels in g, resulting in a more fine-grained channel configuration. In comparison, the channel numbers are determined heuristically in <ref type="bibr" target="#b32">Tan &amp; Le (2019b)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">RESOURCE-AWARE ATOMIC BLOCK SEARCH</head><p>In this work, we adopt a differentiable neural architecture search paradigm where the model structure is discovered in a full pass of model training. With the supernet defined above, the final model can be produced by discarding part of the atomic blocks during training. Following DARTS (Liu et al.</p><p>(2019a)), we introduce a importance factor α to scale the output of each atomic block in the supernet. Eq.</p><p>(3) then becomes</p><formula xml:id="formula_5">Y = c i=1 α i f c ,1 1i • g i • f 1,c 0i (X).<label>(4)</label></formula><p>Here, each α i is tied with an atomic block comprised of three operators f c ,1 1i ,g i and f 1,c 0i . The importance factors are learned jointly with the network weights. Once the training finishes, the atomic blocks that have negligible effect (i.e., those with factors smaller than a threshold) on the network output are discarded.</p><p>We still need to address two issues related to the importance factors α i 's. The first issue is where in the supernet we should put the α? Let's first consider the case when g only contains linear operations, e.g., convolution, batch normalization and linear activation like ReLU. If g contains at least one BN layer, The scaling parameters in the BN layers can be directly used as such importance factors <ref type="bibr" target="#b21">(Liu et al. (2017)</ref>). If g has no BN layers, which is rare, we can place α anywhere between f 0 and f 1 ; however, we need to apply regularization terms to the weights of f 0 and f 1 (e.g., weight decays) in order to prevent weights in f 0 and f 1 from getting too large and canceling the effect of α. When g contains non-linear operations, e.g., Swish activation and Sigmoid activation, we can only put α behind f 1 .</p><p>The second issue is how to avoid performance deterioration after discarding some of the atomic blocks. For example, DARTS discards operations with small scale factors after iterative training of model parameters and scale factors. Since the scale factors of the discarded operations are not small enough, the performance of the network will be affected which needs re-training to adjust the weights again. In order to maintain the performance of the supernet after dropping some atomics blocks, the importance factors α of those atomic blocks should be sufficiently small. Inspired by the channel pruning work in <ref type="bibr" target="#b21">Liu et al. (2017)</ref>, we add L1 norm penalty loss on α, which effectively pushes many importance factors to near-zero values. At the end of learning, atomic blocks with α close to zero are removed from the supernet. Note that since the BN scales change more dramatically during training due to the regularization term, the running statistics of BNs might be inaccurate and needs to be calculated again using the training set.</p><p>With the added regularization term, the training loss is</p><formula xml:id="formula_6">L = E + λ i∈S c i |α i |,<label>(5)</label></formula><formula xml:id="formula_7">c i =ĉ i / k∈Sĉ k<label>(6)</label></formula><p>where λ is the coefficient of L1 penalty term, S is the index set of all atomic blocks, and E is the conventional training loss (e.g., cross-entropy loss combined with the regularization term like weight decay and distillation loss.). |α i | is weighted by coefficient c i which is proportional to the computation cost of i-th atomic block, i.e.ĉ i . By using computation costs aware regularization, we encourage the model to learn network structures that strike a good balance between accuracy and efficiency. In this paper, we use FLOPs as the criteria of computation cost. Other metrics such as latency and energy consumption can be used similarly. As a result, the whole loss function L trades off between accuracy and FLOPs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">DYNAMIC NETWORK SHRINKAGE</head><p>Usually, the supernet is much larger than the final search result. We observe that many atomic blocks become "dead" starting from the early stage of the search, i.e., their importance factors α are close to zero till the end of the search. To utilize computational resources more efficiently and speed up the search process, we propose a dynamic network shrinkage algorithm which cuts down the network architecture by removing atomic blocks once they are deemed "dead".</p><p>We adopt a conservative strategy to decide whether an atomic block is "dead": for importance factors α, we maintain its momentumα which is updated aŝ  where α t is the importance factors at t-th iteration and β is the decay term. An atomic block is considered "dead" if bothα and α t are smaller than a threshold, which is set to 0.001 throughout experiments.</p><formula xml:id="formula_8">α ← βα + (1 − β)α t ,<label>(7)</label></formula><p>Once the total FLOPs of "dead" blocks reach a predefined threshold, we remove those blocks from the supernet. As discussed above, we recalculate BN's running statistics before deploying the network. The whole training process is presented in Algorithm 1.</p><p>We show the FLOPs of a sample network during the search process in <ref type="figure" target="#fig_3">Fig. 2</ref>. We start from a supernet with 1521M FLOPs and dynamically discard "dead" atomic blocks to reduce search cost. The overall search and train cost only increases by 17.2% compared to that of training the searched model from scratch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENT</head><p>We first describe the implementation details in Section 4.1 and then compare AtomNAS with previous state-of-the-art methods under various FLOPs constraints in Section 4.2. In Section 4.3, we provide more detailed analysis about AtomNAS. Finally, in Section 4.4, we demonstrate the transferability of AtomNAS networks by evaluating them on detection and instance segmentation tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">IMPLEMENTATION DETAILS</head><p>The architecture of the supernet we use for the experiments is shown in table on the right of <ref type="figure" target="#fig_4">Fig.  3</ref>. The supernet contains 21 AtomNAS blocks, the searchable block in our supernet; the picture on the right of <ref type="figure" target="#fig_4">Fig. 3</ref> illustrates the structure of an AtomNAS block, where f 0 is a 1 × 1 pointwise convolutions that expands the input channel number from C to 3×6C; g is a mix of three depth-wise  convolutions with kernel sizes of 3×3, 5×5 and 7×7, and f 1 is another 1×1 pointwise convolutions that projects the channel number to the output channel number. Similar to MobileNetV2 <ref type="bibr" target="#b27">(Sandler et al., 2018)</ref>, if the output dimension stays the same as the input dimension, we use a skip connection to add the input to the output. AtomNAS block is effectively an ensemble of 3 × 6C atomic blocks, whose underlying search space covers the MobileNetV2 block <ref type="bibr" target="#b27">(Sandler et al., 2018)</ref> and its multikernel variant, MixConv <ref type="bibr" target="#b32">(Tan &amp; Le, 2019b)</ref>. Within AtomNAS block, we are able to optimize the distribution of computation resources (i.e., channel numbers) among the three types of depth-wise convolution.</p><p>We use the same training configuration (e.g., RMSProp optimizer, EMA on weights and exponential learning rate decay) as ; <ref type="bibr" target="#b29">Stamoulis et al. (2019a)</ref> and do not use extra data augmentation such as <ref type="bibr">MixUp (Zhang et al., 2018)</ref> and <ref type="bibr">AutoAugment (Cubuk et al., 2018)</ref>. We find that using this configuration is sufficient for our method to achieve good performance. Our results are shown in <ref type="table" target="#tab_3">Table 1 and Table 3</ref>. When training the supernet, we use a total batch size of 2048 on 32 Tesla V100 GPUs and train for 350 epochs. For our dynamic network shrinkage algorithm, we set the momentum factor β in Eq. <ref type="formula" target="#formula_0">(7)</ref> to 0.9999. At the beginning of the training, all of the weights are randomly initialized. To avoid removing atomic blocks with high penalties (i.e., FLOPs) prematurely, the weight of the penalty term in Eq. <ref type="formula" target="#formula_0">(5)</ref> is increased from 0 to the target λ by a linear scheduler during the first 25 epochs. By setting the weight of the L1 penalty term λ to be 1.8×10 −4 , 1.2×10 −4 and 1.0×10 −4 respectively, we obtain networks with three different sizes: AtomNAS-A, AtomNAS-B, and AtomNAS-C. They have the similar FLOPs as previous state-of-the-art networks under 400M: MixNet-S <ref type="bibr" target="#b32">(Tan &amp; Le, 2019b)</ref>, MixNet-M <ref type="bibr" target="#b32">(Tan &amp; Le, 2019b)</ref> and SinglePath <ref type="bibr" target="#b29">(Stamoulis et al., 2019a)</ref>. In Appendix A, we visualize the architecture of AtomNAS-C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">EXPERIMENTS ON IMAGENET</head><p>We apply AtomNAS to search high performance light-weight model on ImageNet 2012 classification task <ref type="bibr" target="#b6">(Deng et al., 2009</ref>  Techniques like Swish activation function <ref type="bibr" target="#b26">(Ramachandran et al., 2018)</ref> and Squeeze-and-Excitation (SE) module <ref type="bibr" target="#b16">(Hu et al., 2018)</ref> consistently improve the accuracy with marginal FLOPs cost. For a fair comparison with methods that use these techniques, we directly modify the searched network by replacing all ReLU activation with Swish and add SE module with ratio 0.5 to every block and then retrain the network from scratch. Note that unlike other methods, we do not search the configuration of Swish and SE, and therefore the performance might not be optimal. Extra data augmentations such as MixUp and AutoAugment are still not used. We train the models from scratch with a total batch size of 4096 on 32 Tesla V100 GPUs for 250 epochs.</p><p>Simply adding these techniques improves the results further. AtomNAS-A+ achieves 76.3% top-1 accuracy with 260M FLOPs, which outperforms many heavier models including MnasNet-A2. Without extra data augmentations, it performs as well as Efficient-B0 (Tan &amp; Le, 2019a) by using 130M less FLOPs. It also outperforms the previous state-of-the-art MixNet-S by 0.5%. In addition, AtomNAS-C+ improves the top-1 accuracy on ImageNet to 77.6%, surpassing previous state-ofthe-art MixNet-M by 0.6% and becomes the overall best performing model under 400M FLOPs. <ref type="figure" target="#fig_5">Fig. 4</ref> visualizes the top-1 accuracy on ImageNet for different models. It's clear that our fine-grained search space and the end-to-end resource-aware search method boost the performance significantly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">ANALYSIS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">RESOURCE-AWARE REGULARIZATION</head><p>To demonstrate the effectiveness of the resource-aware regularization in Section 3.2, we compare it with a baseline without FLOPs-related coefficients c i , which is widely used in network pruning <ref type="bibr" target="#b21">(Liu et al., 2017;</ref><ref type="bibr" target="#b13">He et al., 2017b)</ref>. <ref type="table" target="#tab_4">Table 2</ref> shows the results. First, by using the same L1 penalty coefficient λ = 1.0 × 10 −4 , the baseline achieves a network with similar performance but using much more FLOPs; then by increasing λ to 1.5 × 10 −4 , the baseline obtain a network which has similar FLOPs but inferior performance (i.e., about 1.0% lower). In <ref type="figure">Fig. 6b</ref> we visualized the ratio of different types of atomic blocks of the baseline network obtained by λ = 1.5×10 −4 . The baseline network keeps more atomic blocks in the earlier blocks, which have higher computation cost due to higher input resolution. On the contrary, AtomNAS is aware of the resource constraint, thus keeping more atomic blocks in the later blocks and achieving much better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">BN RECALIBRATION</head><p>As the BN's running statistics might be inaccurate as explained in Section 3.2 and Section 3.3, we re-calculate the running statistics of BN before inference, by forwarding 131k randomly sampled training images through the network. <ref type="table" target="#tab_5">Table 3</ref> shows the impact of the BN recalibration. The top-1 accuracies of AtomNAS-A, AtomNAS-B, and AtomNAS-C on ImageNet improve by 1.4%, 1.7%, and 1.2% respectively, which clearly shows the benefit of BN recalibration.   In this section, we assess the performance of AtomNAS models as feature extractors for object detection and instance segmentation on COCO dataset <ref type="bibr" target="#b19">(Lin et al., 2014)</ref>. We first pretrain AtomNAS models (without Swish activation function <ref type="bibr" target="#b26">(Ramachandran et al., 2018)</ref> and Squeeze-and-Excitation (SE) module <ref type="bibr" target="#b16">(Hu et al., 2018)</ref>) on ImageNet, use them as drop-in replacements for the backbone in the Mask-RCNN model <ref type="bibr" target="#b12">(He et al., 2017a)</ref> by building the detection head on top of the last feature map, and finetune the model on COCO dataset.</p><p>We use the open-source code MMDetection <ref type="bibr" target="#b1">(Chen et al., 2019a)</ref>. All the models are trained on COCO train2017 with batch size 16 and evaluated on COCO val2017. Following the schedule used in the open-source implementation of TPU-trained Mask-RCNN , the learning rate starts at 0.02 and decreases by a scale of 10 at 15-th and 20th epoch respectively. The models are trained for 23 epochs in total. <ref type="table" target="#tab_6">Table 4</ref> compares the results with other baseline backbone models. The detection results of baseline models are from <ref type="bibr" target="#b30">Stamoulis et al. (2019b)</ref>. We can see that all three AtomNAS models outperform the baselines on object detection task. The results demonstrate that our models have better transferability than the baselines, which may due to mixed operations, a.k.a multi-scale here, are more important to object detection and instance segmentation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>In this paper, we revisit the common structure, i.e., two convolutions joined by a channel-wise operation, and reformulate it as an ensemble of atomic blocks. This perspective enables a much larger and more fine-grained search space. For efficiently exploring the huge fine-grained search space, we propose an end-to-end framework named AtomNAS, which conducts architecture search and network training jointly. The searched networks achieve significantly better accuracy than previous state-of-the-art methods while using small extra cost.  <ref type="figure">Figure 5</ref>: The architecture of AtomNAS-C. Blue, orange, cyan blocks denote atomic blocks with kernel size 3, 5 and 7 respectively; the heights of these blocks are proportional to their expand ratios.</p><p>We plot the structure of the searched architecture AtomNAS-C in <ref type="figure">Fig. 5</ref>, from which we see more flexibility of channel number selection, not only among different operators within each block, but also across the network. In <ref type="figure">Fig. 6a</ref>, we visualize the ratio between atomic blocks with different kernel sizes in all 21 search blocks. First, we notice that all search blocks have convolutions of all three kernel sizes, showing that AtomNAS learns the importance of using multiple kernel sizes in network architecture. Another observation is that AtomNAS tends to keep more atomic blocks at the later stage of the network. This is because in earlier stage, convolutions of the same kernel size costs more FLOPs; AtomNAS is aware of this (thanks to its resource-aware regularization) and try to keep as less as possible computationally costly atomic blocks.  <ref type="figure">Figure 6</ref>: Ratio of different types of atomic blocks in all 21 searchable blocks. The text above each pie tells the total number of atomic blocks of the corresponding block in the original supernet. Grey denotes dead atomic blocks; blue, orange, and cyan represent atomic blocks using depth-wise convolutions with kernel size 3, 5, 7 respectively. Blocks without skip connection are highlighted by bold text. (a) Visualization for AtomNAS-C. (b) Visualization for baseline (i.e., without FLOPs related coefficients c i ).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>2019a);<ref type="bibr" target="#b17">Jin et al. (2019)</ref>;<ref type="bibr" target="#b35">Xu et al. (2020)</ref>;<ref type="bibr" target="#b34">Wu et al. (2019)</ref>;<ref type="bibr" target="#b9">Guo et al. (2019)</ref>;<ref type="bibr" target="#b0">Cai et al. (2019)</ref>.<ref type="bibr" target="#b29">Stamoulis et al. (2019a);</ref> Yu et al. (2020)  further share the parameters of different paths within a block using super-kernel representation. A prominent disadvantage of the above methods is that their coarse search spaces only support selecting one out of a set of choices (e.g., selecting one kernel size from {3, 5, 7}). MixNet tries to benefit from mixed operations by using a predefined set of mixed operations {{3}, {3, 5}, {3, 5, 7}, {3, 5, 7, 9}}, where the channels are equally distributed</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Illustration of the ensemble perspective. Arrow means operators. The structure of two convolutions joined by a channel-wise operation is mathematically equivalent to the ensemble of multiple atomic blocks, according to Eq. (2). Colored rectangles represent tensors, with numbers inside indicating their channel numbers; The shaded path on the right is one example of atomic block.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Fig.(1) demonstrate this reformulation. By determining whether to keep each atomic block in the final model individually, the search of channel number c is enabled through channel selection, which greatly enlarges the search space.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>FLOPs change of the supernet during the searching and training for AtomNAS-C. The crossed-out region corresponds to the saved computation compared to training the supernet without the dynamic shrinkage. The region in yellow corresponds to the extra cost compared with training the final model from scratch, the cost of which is the region below the red dashed line.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>(Left)  The searchable block of the supernet. f 0 and f 1 are fixed to 1 × 1 pointwise convolutions; g here is a mix of three convolutions with kernel sizes of 3 × 3, 5 × 5 and 7 × 7. f 0 expands the input channel number from C to 18C and f 1 projects the channel number to the output channel number. If the output dimension stays the same as the input dimension, we use a skip connection to add the input to the output. (Right) Architecture of the supernet. Column-Block denotes the block type; MB denotes MobileNetV2 block; "searchable" means a searchable block shown on the left. Column-f denotes the output channel number of a block. Column-n denotes the number of blocks. Column-s denotes the stride of the first block in a stage. The output channel numbers of the first convolution are 16 for AtomNAS-A, 32 for AtomNAS-B and AtomNAS-C.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>FLOPs versus accuracy on ImageNet. † means methods use extra techniques like Swish activation and Squeeze-and-Excitation module.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>Comparision with state-of-the-arts on ImageNet under the mobile setting. † denotes methods using extra network modules such as Swish activation and Squeeze-and-Excitation module. ‡ denotes using extra data augmentation such as MixUp and AutoAugment. * denotes models searched and trained simultaneously.</figDesc><table><row><cell>Model</cell><cell cols="4">Parameters FLOPs Top-1(%) Top-5(%)</cell></row><row><cell>MobileNetV1 (Howard et al., 2017)</cell><cell>4.2M</cell><cell>575M</cell><cell>70.6</cell><cell>89.5</cell></row><row><cell>MobileNetV2 (Sandler et al., 2018)</cell><cell>3.4M</cell><cell>300M</cell><cell>72.0</cell><cell>91.0</cell></row><row><cell>MobileNetV2 (our impl.)</cell><cell>3.4M</cell><cell>301M</cell><cell>73.6</cell><cell>91.5</cell></row><row><cell>MobileNetV2 (1.4)</cell><cell>6.9M</cell><cell>585M</cell><cell>74.7</cell><cell>92.5</cell></row><row><cell>ShuffleNetV2 (Ma et al., 2018)</cell><cell>3.5M</cell><cell>299M</cell><cell>72.6</cell><cell>-</cell></row><row><cell>ShuffleNetV2 2×</cell><cell>7.4M</cell><cell>591M</cell><cell>74.9</cell><cell>-</cell></row><row><cell>FBNet-A (Wu et al., 2019)</cell><cell>4.3M</cell><cell>249M</cell><cell>73.0</cell><cell>-</cell></row><row><cell>FBNet-C</cell><cell>5.5M</cell><cell>375M</cell><cell>74.9</cell><cell>-</cell></row><row><cell>Proxyless (mobile) (Cai et al., 2019)</cell><cell>4.1M</cell><cell>320M</cell><cell>74.6</cell><cell>92.2</cell></row><row><cell>SinglePath (Stamoulis et al., 2019a)</cell><cell>4.4M</cell><cell>334M</cell><cell>75.0</cell><cell>92.2</cell></row><row><cell>NASNet-A (Zoph &amp; Le, 2017)</cell><cell>5.3M</cell><cell>564M</cell><cell>74.0</cell><cell>91.6</cell></row><row><cell cols="2">DARTS (second order) (Liu et al., 2019a) 4.9M</cell><cell>595M</cell><cell>73.1</cell><cell>-</cell></row><row><cell>PDARTS (cifar 10) (Chen et al., 2019b)</cell><cell>4.9M</cell><cell>557M</cell><cell>75.6</cell><cell>92.6</cell></row><row><cell>DenseNAS-A (Fang et al., 2019)</cell><cell>7.9M</cell><cell>501M</cell><cell>75.9</cell><cell>92.6</cell></row><row><cell>FairNAS-A (Chu et al., 2019b)</cell><cell>4.6M</cell><cell>388M</cell><cell>75.3</cell><cell>92.4</cell></row><row><cell>AtomNAS-A  *</cell><cell>3.9M</cell><cell>258M</cell><cell>74.6</cell><cell>92.1</cell></row><row><cell>AtomNAS-B  *</cell><cell>4.4M</cell><cell>326M</cell><cell>75.5</cell><cell>92.6</cell></row><row><cell>AtomNAS-C  *</cell><cell>4.7M</cell><cell>360M</cell><cell>75.9</cell><cell>92.7</cell></row><row><cell>SCARLET-A  † (Chu et al., 2019a)</cell><cell>6.7M</cell><cell>365M</cell><cell>76.9</cell><cell>93.4</cell></row><row><cell>MnasNet-A1  † (Tan et al., 2019)</cell><cell>3.9M</cell><cell>312M</cell><cell>75.2</cell><cell>92.5</cell></row><row><cell>MnasNet-A2  †</cell><cell>4.8M</cell><cell>340M</cell><cell>75.6</cell><cell>92.7</cell></row><row><cell>MixNet-S  † (Tan &amp; Le, 2019b)</cell><cell>4.1M</cell><cell>256M</cell><cell>75.8</cell><cell>92.8</cell></row><row><cell>MixNet-M  †</cell><cell>5.0M</cell><cell>360M</cell><cell>77.0</cell><cell>93.3</cell></row><row><cell>EfficientNet-B0  † ‡ (Tan &amp; Le, 2019a)</cell><cell>5.3M</cell><cell>390M</cell><cell>76.3</cell><cell>93.2</cell></row><row><cell>SE-DARTS+  † ‡ (Liang et al., 2019)</cell><cell>6.1M</cell><cell>594M</cell><cell>77.5</cell><cell>93.6</cell></row><row><cell>AtomNAS-A+  †</cell><cell>4.7M</cell><cell>260M</cell><cell>76.3</cell><cell>93.0</cell></row><row><cell>AtomNAS-B+  †</cell><cell>5.5M</cell><cell>329M</cell><cell>77.2</cell><cell>93.5</cell></row><row><cell>AtomNAS-C+  †</cell><cell>5.9M</cell><cell>363M</cell><cell>77.6</cell><cell>93.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Influence of awareness of resource metric. The upper block uses equal penalties for all atomic blocks. The lower part uses our resource-aware atomic block selection. shrinkage algorithm speedups the search and train process significantly. For AtomNAS-C, the total time for search-and-training is 25.5 hours. For reference, training the final architecture from scratch takes 22 hours. Note that as the supernet shrinks, both the GPU memory consumption and forward-backward time are significantly reduced. Thus it's possible to dynamically change the batch size once having sufficient GPU memory, which would further speed up the whole procedure.</figDesc><table><row><cell>λ</cell><cell cols="2">FLOPs Top-1(%)</cell></row><row><cell cols="2">1.0 × 10 −4 445M</cell><cell>76.1</cell></row><row><cell cols="2">1.5 × 10 −4 370M</cell><cell>74.9</cell></row><row><cell cols="2">1.0 × 10 −4 360M</cell><cell>75.9</cell></row><row><cell cols="2">4.3.3 COST OF DYNAMIC NETWORK SHRINKAGE</cell></row><row><cell>Our dynamic network</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Influence of BN recalibration.</figDesc><table><row><cell>Model</cell><cell cols="2">w/o Recalibration w/ Recalibration</cell></row><row><cell>AtomNAS-A</cell><cell>73.2</cell><cell>74.6 (+1.4)</cell></row><row><cell>AtomNAS-B</cell><cell>73.8</cell><cell>75.5 (+1.7)</cell></row><row><cell>AtomNAS-C</cell><cell>74.7</cell><cell>75.9 (+1.2)</cell></row><row><cell cols="3">4.4 EXPERIMENTS ON COCO DETECTION AND INSTANCE SEGMENTATION</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Comparision with baseline backbones on COCO object detection and instance segmentation. Cls denotes the ImageNet top-1 accuracy; detect-mAP and seg-mAP denotes mean average precision for detection and instance segmentation on COCO dataset. The results of baseline models are from<ref type="bibr" target="#b30">Stamoulis et al. (2019b)</ref>. SinglePath+<ref type="bibr" target="#b30">(Stamoulis et al., 2019b)</ref> contains SE module.</figDesc><table><row><cell>Model</cell><cell cols="4">FLOPs Cls (%) detect-mAP (%) seg-mAP (%)</cell></row><row><cell>MobileNetV2 (Sandler et al., 2018)</cell><cell>301M</cell><cell>73.6</cell><cell>30.5</cell><cell>-</cell></row><row><cell>Proxyless (mobile) (Cai et al., 2019)</cell><cell>320M</cell><cell>74.6</cell><cell>32.9</cell><cell>-</cell></row><row><cell>Proxyless (mobile) (our impl.)</cell><cell>320M</cell><cell>74.9</cell><cell>32.7</cell><cell>30.0</cell></row><row><cell cols="2">SinglePath+ (Stamoulis et al., 2019b) 353M</cell><cell>75.6</cell><cell>33.0</cell><cell>-</cell></row><row><cell>SinglePath (our impl.)</cell><cell>334M</cell><cell>75.0</cell><cell>32.0</cell><cell>29.7</cell></row><row><cell>AtomNAS-A</cell><cell>258M</cell><cell>74.6</cell><cell>32.7</cell><cell>30.1</cell></row><row><cell>AtomNAS-B</cell><cell>326M</cell><cell>75.5</cell><cell>33.6</cell><cell>30.8</cell></row><row><cell>AtomNAS-C</cell><cell>360M</cell><cell>75.9</cell><cell>34.1</cell><cell>31.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>https://github.com/tensorflow/tpu/tree/master/models/official/mask_ rcnn Jiahui Yu, Pengchong Jin, Hanxiao Liu, Gabriel Bender, Pieter-Jan Kindermans, Mingxing Tan, Thomas Huang, Xiaodan Song, and Quoc Le. Scaling up neural architecture search with big single-stage models, 2020. URL https://openreview.net/forum?id=HJe7unNFDH. Hongyi Zhang, Moustapha Cissé, Yann N. Dauphin, and David Lopez-Paz. mixup: Beyond empirical risk minimization. In ICLR, 2018. Barret Zoph and Quoc V. Le. Neural architecture search with reinforcement learning. In ICLR, 2017.</figDesc><table><row><cell cols="8">A VISUALIZATION</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>3</cell><cell>5</cell><cell></cell><cell>7</cell><cell></cell><cell></cell></row><row><cell>3x224x224</cell><cell>Conv 3x3</cell><cell>32x112x112</cell><cell>16x112x112</cell><cell>24x56x56</cell><cell>24x56x56</cell><cell>24x56x56</cell><cell>24x56x56</cell><cell>40x28x28</cell><cell>40x28x28</cell><cell>40x28x28</cell><cell>40x28x28</cell><cell>80x14x14</cell><cell>80x14x14</cell><cell>80x14x14</cell><cell>80x14x14</cell><cell>96x14x14</cell><cell>96x14x14</cell><cell>96x14x14</cell><cell>96x14x14</cell><cell>192x7x7</cell><cell>192x7x7</cell><cell>192x7x7</cell><cell>192x7x7</cell><cell>320x7x7</cell><cell>Conv 1x1</cell><cell>1280x7x7</cell><cell>Pooling FC</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Proxylessnas: Direct neural architecture search on target task and hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ligeng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangmiao</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuyang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wansen</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiarui</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dazhi</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenchen</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianheng</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qijie</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Buyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.07155</idno>
		<title level="m">Chen Change Loy, and Dahua Lin. MMDetection: Open mmlab detection toolbox and benchmark</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Progressive differentiable architecture search: Bridging the depth gap between search and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
		<idno>abs/1904.12760</idno>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Scarletnas: Bridging the gap between scalability and fairness in neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangxiang</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jixiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruijun</forename><surname>Xu</surname></persName>
		</author>
		<idno>abs/1908.06022</idno>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Fairnas: Rethinking evaluation fairness of weight sharing neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangxiang</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruijun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jixiang</forename><surname>Li</surname></persName>
		</author>
		<idno>abs/1907.01845</idno>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Autoaugment: Learning augmentation policies from data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Ekin Dogus Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dandelion</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Mané</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<idno>abs/1805.09501</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei-Fei</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Densely connected search space for more flexible neural architecture search. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiemin</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuzhu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1906" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Morphnet: Fast &amp; simple resource-constrained structure learning of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ariel</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Eban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ofir</forename><surname>Nachum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tien-Ju</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1586" to="1595" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Single path one-shot neural architecture search with uniform sampling. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zichao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoyuan</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zechun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1904" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep compression: Compressing deep neural network with pruning, trained quantization and huffman coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huizi</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">J</forename><surname>Dally</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Mask R-CNN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<meeting><address><addrLine>Venice, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-10-22" />
			<biblScope unit="page" from="2980" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Channel pruning for accelerating very deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yihui</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1398" to="1406" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Ruoming Pang, Vijay Vasudevan, et al. Searching for mobilenetv3. Corr, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grace</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1905" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Mobilenets: Efficient convolutional neural networks for mobile vision applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">G</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Weyand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Andreetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<idno>abs/1704.04861</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Squeeze-and-excitation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7132" to="7141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojie</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Slocum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengyang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.12814</idno>
		<title level="m">Resource constrained differentiable architecture search</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Darts+: Improved differentiable architecture search with early stopping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanwen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shifeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiacheng</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingqiu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiran</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kechen</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenguo</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Microsoft COCO: common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2014 -13th European Conference</title>
		<meeting><address><addrLine>Zurich, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
	<note>Proceedings, Part V</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">DARTS: differentiable architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning efficient convolutional networks through network slimming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianguo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoumeng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changshui</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2755" to="2763" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Rethinking the value of network pruning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingjie</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinghui</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations</title>
		<meeting><address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-05-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Thinet: A filter level pruning method for deep neural network compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Hao</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyao</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5068" to="5076" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Shufflenet V2: practical guidelines for efficient CNN architecture design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ningning</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai-Tao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="122" to="138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Efficient neural architecture search via parameter sharing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melody</forename><forename type="middle">Y</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4092" to="4101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Searching for activation functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prajit</forename><surname>Ramachandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-04-30" />
		</imprint>
	</monogr>
	<note>Workshop Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">G</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Zhmoginov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<title level="m">Mobilenetv2: Inverted residuals and linear bottlenecks</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4510" to="4520" />
		</imprint>
	</monogr>
	<note>CVPR</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Single-path NAS: designing hardware-efficient convnets in less than 4 hours</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><surname>Stamoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruizhou</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><surname>Lymberopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodhi</forename><surname>Priyantha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Marculescu</surname></persName>
		</author>
		<idno>abs/1904.02877</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Single-path mobile automl: Efficient convnet design and NAS hyperparameter optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><surname>Stamoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruizhou</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><surname>Lymberopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodhi</forename><surname>Priyantha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Marculescu</surname></persName>
		</author>
		<idno>abs/1907.00959</idno>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Rethinking model scaling for convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Efficientnet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6105" to="6114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Mixed depthwise convolutional kernels. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mixconv</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1907" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Mnasnet: Platform-aware neural architecture search for mobile</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruoming</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2820" to="2828" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Fbnet: Hardware-aware efficient convnet design via differentiable neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bichen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoliang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanghan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuandong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Vajda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Keutzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10734" to="10742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">PC-DARTS: Partial channel connections for memory-efficient architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhui</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaopeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guo-Jun</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongkai</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Rethinking the smaller-norm-less-informative assumption in channel pruning of convolution layers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbo</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
