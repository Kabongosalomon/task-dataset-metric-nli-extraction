<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Group-Wise Semantic Mining for Weakly Supervised Semantic Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueyi</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="laboratory">Beijing Key Laboratory of Intelligent Information Technology</orgName>
								<orgName type="institution">Beijing Institute of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianfei</forename><surname>Zhou</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Computer Vision Laboratory</orgName>
								<orgName type="institution">ETH Zurich</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwu</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="laboratory">Beijing Key Laboratory of Intelligent Information Technology</orgName>
								<orgName type="institution">Beijing Institute of Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhou</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Southeast University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoxiang</forename><surname>Zhang</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Center for Research on Intelligent Perception and Computing</orgName>
								<orgName type="institution">CASIA</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Group-Wise Semantic Mining for Weakly Supervised Semantic Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T21:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acquiring sufficient ground-truth supervision to train deep visual models has been a bottleneck over the years due to the data-hungry nature of deep learning. This is exacerbated in some structured prediction tasks, such as semantic segmentation, which requires pixel-level annotations. This work addresses weakly supervised semantic segmentation (WSSS), with the goal of bridging the gap between image-level annotations and pixel-level segmentation. We formulate WSSS as a novel group-wise learning task that explicitly models semantic dependencies in a group of images to estimate more reliable pseudo ground-truths, which can be used for training more accurate segmentation models. In particular, we devise a graph neural network (GNN) for group-wise semantic mining, wherein input images are represented as graph nodes, and the underlying relations between a pair of images are characterized by an efficient co-attention mechanism. Moreover, in order to prevent the model from paying excessive attention to common semantics only, we further propose a graph dropout layer, encouraging the model to learn more accurate and complete object responses. The whole network is end-toend trainable by iterative message passing, which propagates interaction cues over the images to progressively improve the performance. We conduct experiments on the popular PAS-CAL VOC 2012 and COCO benchmarks, and our model yields state-of-the-art performance. Our code is available at: https</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Semantic segmentation is a fundamental task in computer vision, aiming to assign a semantic category to each pixel in an image. It can benefit a wide variety of applications including autonomous driving, image editing and medical diagnosis. With the recent renaissance of deep neural networks, semantic segmentation has achieved tremendous progress. However, most of the leading approaches <ref type="bibr" target="#b31">(Long, Shelhamer, and Darrell 2015;</ref><ref type="bibr" target="#b49">Wang et al. 2019b;</ref><ref type="bibr">Zhou et al. 2020a,b)</ref> are fully supervised, requiring massive amounts of pixellevel annotated training data, which are extremely expensive and time-consuming to obtain. In contrast, the weak supervision alternatives, e.g., image-level tags <ref type="bibr" target="#b34">(Pathak, Krahenbuhl, and Darrell 2015;</ref><ref type="bibr" target="#b25">Kolesnikov and Lampert 2016;</ref><ref type="bibr" target="#b36">Qi et al. 2016;</ref><ref type="bibr" target="#b56">Wei et al. 2016;</ref><ref type="bibr" target="#b5">Chaudhry, Dokania, and Torr 2017;</ref><ref type="bibr" target="#b1">Ahn and Kwak 2018;</ref><ref type="bibr" target="#b15">Fan et al. 2018)</ref>, scribbles <ref type="bibr" target="#b29">(Lin et al. 2016;</ref><ref type="bibr" target="#b47">Vernaza and Chandraker 2017)</ref> or bounding-box annotations <ref type="bibr" target="#b9">(Dai, He, and Sun 2015;</ref><ref type="bibr" target="#b24">Khoreva et al. 2017;</ref><ref type="bibr" target="#b43">Song et al. 2019)</ref>, are less costly. Thus, it is of interest to explore the potential of these weak supervision cues in providing a data-efficient solution for semantic segmentation. In this paper, we aim to address weakly supervised semantic segmentation (WSSS) under the supervision of image-level tags, which can be obtained effortlessly.</p><p>WSSS based on image tags is extremely challenging because fine-grained pixel-level annotations, which are typically required for semantic segmentation, are difficult to obtain from class labels. The pioneering work, <ref type="bibr" target="#b60">(Zhou et al. 2016)</ref>, proposes an efficient and straightforward way to solve this by recognizing the discriminative regions specific to a given category using class activation maps (CAMs), which are then refined to obtain pseudo ground-truths for supervising a semantic segmentation network. Along this line, a number of approaches have been proposed to improve the estimation of CAMs so that they cover the full extent of objects rather than only the most representative parts. For example, some approaches <ref type="bibr" target="#b55">(Wei et al. 2017;</ref><ref type="bibr" target="#b25">Kolesnikov and Lampert 2016;</ref><ref type="bibr" target="#b8">Choe and Shim 2019)</ref> manipulate internal feature maps to guide the network to perceive easily ignored but essential parts, while others <ref type="bibr" target="#b4">Chang et al. 2020;</ref><ref type="bibr" target="#b12">Fan et al. 2020a;</ref><ref type="bibr" target="#b54">Wang et al. 2020c</ref>) adopt selfensembling or self-supervision to improve localization. However, the mainstream methods above are merely based on single images <ref type="figure" target="#fig_0">(Figure 1 (a)</ref>), ignoring the valuable semantic context existing in a group of images. The very recent studies <ref type="bibr" target="#b14">(Fan et al. 2020b;</ref><ref type="bibr" target="#b44">Sun et al. 2020)</ref> utilized Siamese networks to model the relations between a pair of images, leading to a pair-wise solution <ref type="figure" target="#fig_0">(Figure 1 (b)</ref>). These approaches have proven effective in locating more accurate object regions. However, seeking relations between two images at a time is still limited in capturing substantial semantic context. Accordingly, we introduce a more promising, and fundamentally different group-wise solution <ref type="figure" target="#fig_0">(Figure 1</ref> (c)) which comprehensively mines richer semantics from a group of images. Our main motivation is that the availability of group images containing instances of the same semantic classes can make up for the absence of detailed supervisory information. From this perspective, we hypothesize that it is for training, which bears high similarity with standard classifiers (e.g., VGG). (b) Pair-wise methods extract features from a pair of images using a Siamese network, and make predictions using a pair-wise classifier which has learned the correlation between the two images. (c) We propose a group-wise method that accepts an arbitrary number of images as input. The input images are iteratively processed by a GNN to enable substantial information to exchange, and a group-wise classifier is then adopted for prediction. desirable to take advantage of all available information for WSSS, including not only individual image properties, but also group-level synergetic relationships.</p><p>Based on the above analysis, we propose a novel deep learning model for WSSS. Unlike previous pair-wise approaches, our model is targeted at group-wise semantic mining to capture more comprehensive relations among input images. Specifically, we develop an efficient, end-to-end trainable graph neural network (GNN), and conduct recursive reasoning for group-wise semantic understanding. In our graph, the nodes represent a group of input images, and edges describe pair-wise relations between two connected images. We consider two images as connected only if they share common semantic objects with each other, and their relation is then characterized by an elaborately designed co-attention mechanism. Through iterative message passing, the information from individual elements can be efficiently integrated and broadcasted over the graph structure. In this way, our model is capable of leveraging explicit semantic dependencies among images to obtain better node representations. However, this graph reasoning strategy mainly focuses on co-occurring semantics in a group of images, ignoring isolated objects. To address this, we further introduce a graph dropout layer, which can be seamlessly integrated into the GNN for iterative inference. The graph dropout layer selectively suppresses the most salient objects, forcing the network to be biased toward their counterparts.</p><p>Our method has two appealing characteristics over singleimage and pair-wise methods. First, it is capable of learning semantic relations from an arbitrary number of images using a flexible GNN framework. The GNN empowers our model to inherit the complementary strengths of neural networks in learning capability and graphical models in structure representations. Second, our model adopts multi-step, iterative inference to progressively improve image representations. This is more favorable than directly producing representations by one-step inference in previous approaches</p><p>In summary, our main contributions are three-fold: First, we demonstrate the advantages of group-wise semantic mining for WSSS, and proffer a graph-aware solution for effective inference. Second, we develop a graph dropout layer to promote the missing categories, leading to more accurate localization. Third, we evaluate the proposed approach on two large-scale benchmarks, i.e., <ref type="bibr">PASCAL VOC 2012</ref><ref type="bibr">(Ev-eringham et al. 2010</ref>) and COCO <ref type="bibr" target="#b30">(Lin et al. 2014)</ref>, and the results demonstrate its superiority.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Work</head><p>Weakly Supervised Semantic Segmentation. Recent years have seen a surge of interest in semantic segmentation under weak supervision (e.g., image-level labels, scribbles, bounding boxes), greatly reducing human efforts in manual labeling. In particular, methods operating with imagelevel labels have attracted the most attention since they require minimal annotation efforts. Most of these methods follow a popular pipeline that trains an image classifier using image-level labels, and exploits CAMs to highlight the most discriminative object regions for a particular semantic category as its pseudo ground-truth. However, CAMs are weak in revealing complete object regions, resulting in poor segmentation performance. Some pioneering efforts address this difficulty by learning pixel affinities <ref type="bibr" target="#b1">(Ahn and Kwak 2018)</ref>, erasing the most discriminative parts <ref type="bibr" target="#b55">(Wei et al. 2017;</ref><ref type="bibr" target="#b8">Choe and Shim 2019;</ref><ref type="bibr" target="#b27">Lee et al. 2019)</ref>, optimizing intraclass discrimination <ref type="bibr" target="#b12">(Fan et al. 2020a</ref>), or applying region growing <ref type="bibr" target="#b25">(Kolesnikov and Lampert 2016;</ref><ref type="bibr" target="#b57">Wei et al. 2018;</ref><ref type="bibr" target="#b22">Huang et al. 2018)</ref> to capture the full extent of objects. However, these methods are confined to using only limited image-level information. More recent approaches thus follow the self-supervised paradigm to acquire additional supervisions <ref type="bibr" target="#b41">(Shimoda and Yanai 2019;</ref><ref type="bibr" target="#b54">Wang et al. 2020c)</ref>, or rely on Siamese networks to capture semantic relations between a pair of images <ref type="bibr" target="#b14">(Fan et al. 2020b;</ref><ref type="bibr" target="#b44">Sun et al. 2020)</ref>.</p><p>In this paper, we take a further step toward discovering higher-order relations among images. A graph model is designed to encode such relationships. Through graph reasoning, our model iteratively refines object representations by accepting informative knowledge from other images. Graph Neural Networks. Graph neural networks were proposed in <ref type="bibr" target="#b40">(Scarselli et al. 2008)</ref>, and have since gained widespread attention due to their superiority in dealing with flexible graph-structured data. GNNs typically model the graph elements (e.g., nodes, edges) and approximation inference as learnable neural networks, and conduct iterative reasoning to explicitly discover the relations among nodes. They have achieved wide success in a variety of fields, including molecular biology <ref type="bibr" target="#b17">(Gilmer et al. 2017</ref> </p><formula xml:id="formula_0">), computer CE L 224 × 224 Group Images VGG16 0 2,1 e 0 3,1 e 0 1,1 e 0 1 h 0 2 h 0 3 h 0 4 h 0 4,1 e 1 t h 2 t h 3 t h 4 t h 2,1 t m 3,1 t m 1,1 t m 1 1 t h − 1 2 t h − 1 3 t h − 1 4 t h − 1 t h 2 t h 3 t h 4 t h Initial Graph Construction T-step Graph Reasoning Readout Readout Readout Readout</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Graph Dropout Message Aggregation t-th iteration</head><formula xml:id="formula_1">{Ii} 4 i=1 ), our model uses VGG16 to extract convolutional features (i.e., h 0 i } 4 i=1 )</formula><p>, which are used as the initial embeddings for graph construction. Next, our model conducts T -step graph reasoning to iteratively refine the features by message passing (Eq.(8)), message aggregation (Eq. (2)), and graph dropout (Eq. (10)). The final features (i.e., {ĥ T i } 4 i=1 ) are fed into a readout function (Eq. (9)) to get the predictions (i.e.,</p><formula xml:id="formula_2">{l g i } 4 i=1 ).</formula><p>vision <ref type="bibr" target="#b35">(Qi et al. 2017;</ref><ref type="bibr" target="#b32">Lu et al. 2020;</ref><ref type="bibr" target="#b33">Marino, Salakhutdinov, and Gupta 2017;</ref><ref type="bibr" target="#b48">Wang et al. 2019a;</ref><ref type="bibr" target="#b39">Santoro et al. 2017;</ref><ref type="bibr" target="#b50">Wang et al. 2020a)</ref>, and machine learning <ref type="bibr" target="#b46">(Veličković et al. 2018;</ref><ref type="bibr" target="#b37">Qu, Bengio, and Tang 2019)</ref>. Inspired by these efforts, we build an image-level graph network to model their semantic relations for the WSSS task. Assisted by a graph dropout layer, our model can generate more accurate pseudo ground-truths for semantic segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methodology</head><p>In this section, we elaborate on the proposed model for WSSS. Given training images with only image-level labels, current efforts operate on two sub-tasks to achieve pixelwise predictions. The first one is pseudo ground-truth generation, which relies on an image classification network to localize discriminative regions. The other one is semantic segmentation, which conducts dense predictions using a fully convolutional network (FCN) under the supervision of pseudo labels. Our approach also follows this pipeline. However, unlike previous approaches that treat each single image independently, our model aims to mine common semantic patterns from multiple images by graph inference. In this way, our model can alleviate the incomplete-annotation problem in WSSS and produce more accurate pseudo labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Preliminary: Graph Neural Networks</head><p>We start by revisiting the basic concept of GNNs. We define</p><formula xml:id="formula_3">a graph G = (V, E) by its node set V = {v 1 , . . . , v n } and edge set E = {e i,j = (v i , v j )|v i , v j ∈ V}.</formula><p>We assume that each node v i is associated with a feature embedding vector h i , and each edge e i,j has an edge representation e i,j . During inference, GNNs iteratively improve the feature representations at a node by aggregating its neighborhood features. Specifically, a GNN maps the graph G to the node outputs through two phases: a message passing phase and a readout phase. The message passing phase is defined in terms of a message function F M , whose input is a node's features and output is a message, and an aggregation function F A , whose input is a set of messages and output is the updated features.</p><p>Suppose we conduct T rounds of message passing; the t-th round for a node v i can be described as:</p><formula xml:id="formula_4">message passing: m t i = vj∈Ni F t M (h t−1 i , h t−1 j , e i,j ), (1) message aggregation: h t i = F A (h t−1 i , m t i ),<label>(2)</label></formula><p>where for v i , the message function firstly summarizes the information (i.e., m t i ) from its neighbors N i , and then uses it to update the node state. Then, in the readout phase, a taskspecific readout function F R operates on the final node representation h T i to produce a node output:</p><formula xml:id="formula_5">readout phase: oi = FR(h T i ).<label>(3)</label></formula><p>Next, we will present the details of the proposed graphbased semantic mining model for pseudo ground-truth generation in WSSS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Group-Wise Semantic Mining Network</head><p>Problem Definition: Given a collection of training samples, our first goal is to generate corresponding pseudo groundtruths, which will later be used to supervise semantic segmentation networks. To achieve this, we formulate the problem as graph-based semantic co-mining among multiple images. Formally, we denote</p><formula xml:id="formula_6">I = {(I i , l i )} N i=1 as the training data, where I i ∈ R w×h×3 is an image and l i ∈ {0, 1} L is the corresponding image-level ground-truth with L possible se- mantic categories. During training, we selectively sample K images {I i } K i=1</formula><p>as a mini-batch, and model their relations as a directed graph G = (V, E), where the image I i is denoted as node v i ∈ V, and the relation between v i and v j is represented by edge e i,j ∈ E. To better capture more comprehensive common semantics, we consider two nodes v i and v j to be linked only if there is at least one semantic category shared between them. Besides, we assume that every node has a self-edge, e.g., e i,i for v i .</p><p>Given the above definitions, our network aims to conduct pseudo ground-truth generation in a graph learning scheme, under the full supervision of image-level labels as well as the implicit semantic relations among different images. In this manner, our model can capture richer semantic information and obtain more accurate pseudo labels. Next, we describe the details of each component in our model. Node Embedding: As an initial step, we abstract a highlevel feature representation for each input image. Formally, given I i , we extract features h i ∈ R W×H×C from the convolutional stages of a standard classification network (e.g., VGG <ref type="bibr" target="#b42">(Simonyan and Zisserman 2015)</ref>). The embedding of node v i is then initialized by h i , which is a (W, H, C)dimensional tensor preserving full spatial details for more effective pixel-level matching during graph reasoning. Edge Embedding: For each edge e i,j connecting v i to v j , we aim to learn an edge embedding e t i,j at each iteration t to find the correct semantic correspondence between the two nodes. This is achieved by dense matching over node embeddings using the following bilinear model:</p><formula xml:id="formula_7">e t i,j = h t i W h t j ∈ R W H×W H ,<label>(4)</label></formula><p>where h t i ∈ R W H×C and h t j ∈ R W H×C are flattened into matrix representations for computational convenience. W ∈ R C×C is a trainable weight matrix. In Eq. (4), e t i,j encodes the similarity between h t i and h t j for all pairs of spatial locations. For the edge e j,i , its embedding at iteration t is simply calculated as e t j,i = e t i,j . It should be noted that Eq. (4) introduces a large number of parameters, increasing the computational cost. To alleviate this, W is approximately factorized into two low-rank <ref type="figure" target="#fig_0">1)</ref> is a reduction ratio. Then, Eq. (4) can be rewritten as:</p><formula xml:id="formula_8">matrices P ∈ R C× C d and Q ∈ R C× C d , where d (d &gt;</formula><formula xml:id="formula_9">e t i,j = h t i P Q h t j ∈ R W H×W H .<label>(5)</label></formula><p>Eq. (5) has significant advantages over Eq. (4) in both model parameters and computational cost: 1) it reduces the number of parameters by 2/d times; 2) it only requires (2W HC 2 +W 2 H 2 C)/d multiplication operations, instead of the W HC 2 + W 2 H 2 C in Eq. (4). In addition, for each self-edge e i,i , its embedding e i,i captures the self-relation over the node representation h i . We compute e t i,i at iteration t by self-attention <ref type="bibr" target="#b45">(Vaswani et al. 2017;</ref><ref type="bibr" target="#b51">Wang et al. 2018a)</ref>, which can effectively capture long-range semantic dependencies. In particular, the selfattention calculates the response at a position by attending to all the positions within the same node embedding:</p><formula xml:id="formula_10">e t i,i = softmax(φ f (h t i )φ g (h t i ))φ h (h t i ) + h t i ∈ R W×H×C ,<label>(6)</label></formula><p>where φ {f,g,h} are 1×1 convolutional operators. As seen, we also consider it to be a residual layer in Eq. <ref type="formula" target="#formula_10">(6)</ref>, which can effectively preserve information in the original feature map. Message Passing: Given the node and edge embeddings, our model iteratively updates the hidden states of graph nodes by applying message functions to collect information from their neighboring nodes. More specifically, for a node v i , it absorbs knowledge along two types of edges: 1) a selfedge e i,i that encodes rich context-aware knowledge in v i ; and 2) other edges {e j,i } j that connect v j to v i . For the former, our message function directly reads the message from e i,i , i.e., m t i,i = e t−1 i,i ; while for the latter, the messages are summarized as:</p><formula xml:id="formula_11">m t j,i = softmaxr(e t−1 i,j )h t−1 j ∈ R W H×C ,<label>(7)</label></formula><p>where softmax r denotes the row-wise softmax operation. In Eq. <ref type="formula" target="#formula_11">(7)</ref>, we accumulate knowledge from h t−1 j , which is weighted based on the similarity between h t−1 i and h t−1 j . m t j,i is then reshaped to a (W, H, C)-dimensional tensor. Then, we can easily summarize the message for v i at the t-th iteration as:</p><formula xml:id="formula_12">m t i = v j ∈N i m t−1 j,i + m t−1 i,i .<label>(8)</label></formula><p>Next, the aggregation function A updates the hidden states of nodes, as given in Eq.(2). In our method, A is instantiated by a ConvGRU network <ref type="bibr" target="#b3">(Ballas et al. 2016)</ref>, which is an extension of the GRU update function used in <ref type="bibr" target="#b17">(Gilmer et al. 2017)</ref>. In this way, the message passing algorithm runs for T steps before convergence, iteratively collecting messages and updating node embeddings. Readout Phase: Having repeated the above process for T time steps, we obtain the final node embedding h T i ∈ R W×H×C for v i . Then, the readout function R is applied to the features h T i for image classification:</p><formula xml:id="formula_13">l g i = FR(h T i ) = GAP(φr(h T i )) ∈ R L ,<label>(9)</label></formula><p>where φ r is a class-aware convolutional layer with kernel size 1 × 1 that obtains a feature map with L channels, and GAP denotes a global average pooling layer which produces the final classification outputs. Pseudo Ground-Truth Generation by Self-Ensembling:</p><p>Once the classification results are obtained (Eq.(9)), we discover the discriminative image regions for a particular category following <ref type="bibr" target="#b23">(Jiang et al. 2019</ref>). These regions are further thresholded to generate pseudo ground-truths. Besides, as shown in <ref type="figure" target="#fig_1">Figure 2</ref>, for each input image, our network produces two outputs based on raw convolutional features h 0 i as well as enriched features h T i . This not only introduces additional deeply supervised constraints <ref type="bibr" target="#b26">(Lee et al. 2015)</ref> which could benefit the performance, but also enables the results to be further improved by ensembling the CAMs of multiple outputs. We found that the pseudo ground-truths from different outputs are well complementary with each other, and self-ensembling them by averaging can further improve the performance (see <ref type="table" target="#tab_2">Table 3</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Graph Dropout Layer</head><p>The above graph reasoning scheme enables our model to discover common semantics present in different images (Eq.(5)). The features of these semantics can be accordingly enriched by summarizing all the information from other images (Eq. (8)). However, standalone categories, which may exist only in a single image, are almost ignored in this procedure. To address this, we introduce a graph dropout layer to force the network to pay more attention to these categories. Formally, given the feature map h t i ∈ R W×H×C at the t-th iteration, we average it along the channel dimension to obtain o t i ∈ R W×H . Then, we generate a mask s t i ∈ R W×H as  <ref type="bibr" target="#b16">(Ge, Yang, and Yu 2018)</ref> CVPR18 -55.6% * GAIN <ref type="bibr" target="#b28">(Li et al. 2018)</ref> CVPR18 55.3% 56.8% * MDC  CVPR18 60.4% 60.8% * RRM  AAAI20 60.7% 61.0% † MCOF <ref type="bibr" target="#b53">(Wang et al. 2018b)</ref> CVPR18 60.3% 61.2% † SeeNet  NIPS18 63.1% 62.8% † DSRG  CVPR18 61.4% 63.2% † AffinityNet <ref type="bibr" target="#b1">(Ahn and Kwak 2018)</ref> CVPR18 61.7% 63.7% † SS-WSSS <ref type="bibr" target="#b2">(Araslanov and Roth 2020)</ref> CVPR20 62.7% 64.3% † SSNet <ref type="bibr" target="#b58">(Zeng et al. 2019)</ref> ICCV19 63.3% 64.3% † IRNet <ref type="bibr" target="#b0">(Ahn, Cho, and Kwak 2019)</ref> CVPR19 63.5% 64.8% † CIAN <ref type="bibr" target="#b14">(Fan et al. 2020b)</ref> AAAI20 64.3% 65.3% † FickleNet <ref type="bibr" target="#b27">(Lee et al. 2019)</ref> CVPR19 64.9% 65.3% † IAL  IJCV20 64.3% 65.4% † SSDD <ref type="bibr" target="#b41">(Shimoda and Yanai 2019)</ref> ICCV19 64.9% 65.5% † SEAM <ref type="bibr" target="#b54">(Wang et al. 2020c)</ref> CVPR20 64.5% 65.7% † SubCat <ref type="bibr" target="#b4">(Chang et al. 2020)</ref> CVPR20 66.1% 65.9% † OAA+ <ref type="bibr" target="#b23">(Jiang et al. 2019)</ref> ICCV19 65.2% 66.4% † RRM  AAAI20 66.3% 66.5% † BES <ref type="bibr" target="#b6">(Chen et al. 2020)</ref> ECCV20 65.7% 66.6% † EME <ref type="bibr" target="#b13">(Fan, Zhang, and Tan 2020)</ref> ECCV20 67.2% 66.7% † MCIS  ECCV20 66.2% 66.9% † ICD <ref type="bibr" target="#b12">(Fan et al. 2020a)</ref> CVPR20 67.8% 68.0% * Ours (VGG16) -63.3% 63.6% † Ours (ResNet101) -68.2% 68.5% follows:</p><formula xml:id="formula_14">s t i = sigmoid(o t i ), if r &lt; δ r ; o t i 1(o t i &lt; max(o t i ) * δ d ), otherwise.<label>(10)</label></formula><p>Here, the parameter δ r is a drop rate threshold, determining whether to carry out the dropout operation or not. The parameter r is a scalar generated from a random generator. If r &lt; δ r , s t i is an importance map which supports the activations in h t i ; otherwise, the layer drops the highly activated semantic regions to emphasize standalone semantics. 1(x)</p><p>is a matrix indicator function which returns 1 for the true elements in x, and 0 otherwise. The max(·) operation calculates the maximum value for a 2D tensor. δ d is a threshold controlling the dropout. Finally, we enhance the feature maps by:ĥ</p><formula xml:id="formula_15">t i = h t i ⊗ s t i ,<label>(11)</label></formula><p>where ⊗ denotes spatial-wise multiplication. Note thatĥ t i is then used to replace original features h t i in the next iteration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Detailed Network Architecture</head><p>Our model is comprised of two sub-networks: a classification network for group-wise pseudo ground-truth generation and a segmentation network for semantic segmentation. Classification Network. We choose VGG16 <ref type="bibr" target="#b42">(Simonyan and Zisserman 2015)</ref> as the backbone, which is pre-trained on ImageNet <ref type="bibr" target="#b10">(Deng et al. 2009</ref>). We replace the last convolutional layer in VGG16 by dilated convolutions with a rate </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>Pub. Val BFBP <ref type="bibr" target="#b38">(Saleh et al. 2016)</ref> ECCV16 20.4% SEC <ref type="bibr" target="#b25">(Kolesnikov and Lampert 2016)</ref> ECCV16 22.4% DSRG  CVPR18 26.0% IAL  IJCV20 27.7% Ours -28.4%</p><p>of 2, and the feature maps from this layer are taken as the initial node representations for the GNN. For each image I i , our network has two outputs: an intermediate output l m i which is directly obtained from the backbone <ref type="figure" target="#fig_1">(Figure 2)</ref>, and a final output l g i after graph reasoning <ref type="figure" target="#fig_1">(Figure 2)</ref>. Then, the loss function of the classification network for image i is:</p><formula xml:id="formula_16">L = L CE (l g i , li) + λL CE (l m i , li) ,<label>(12)</label></formula><p>where L CE indicates the standard sigmoid cross entropy loss, and λ balances the two losses.</p><p>After training, we obtain the CAMs for each training image from the two classification layers mentioned earlier, and combine them to obtain foreground object seeds. Besides, we also follow conventional practices <ref type="bibr" target="#b23">(Jiang et al. 2019;</ref><ref type="bibr" target="#b12">Fan et al. 2020a</ref>) to estimate background seeds using an off-theshelf salient object detection model <ref type="bibr" target="#b20">(Hou et al. 2017</ref>). The final pseudo labels are generated by combining the foreground and background seeds. Segmentation Network. Following <ref type="bibr" target="#b4">(Chang et al. 2020;</ref><ref type="bibr" target="#b14">Fan et al. 2020b</ref>), we choose DeepLab-v2 <ref type="bibr" target="#b7">(Chen et al. 2017)</ref> as the segmentation network due to its superior performance in fully supervised semantic segmentation tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments Experimental Setup</head><p>Datasets: We conduct our experiments on two datasets: PASCAL VOC 2012 <ref type="bibr" target="#b11">(Everingham et al. 2010</ref>) and COCO <ref type="bibr" target="#b30">(Lin et al. 2014)</ref>. 1) PASCAL VOC 2012 is currently the most popular benchmark for WSSS. The dataset contains 20 semantic categories (e.g., person, bicycle, cow) and one background category. Following standard protocol <ref type="bibr" target="#b27">Lee et al. 2019;</ref><ref type="bibr" target="#b54">Wang et al. 2020c</ref>), extra data from SBD <ref type="bibr" target="#b18">(Hariharan et al. 2011</ref>) is also used for training, leading to a total of 10,582 training images. We evaluate our model on the standard validation and test sets, which have 1,449 and 1,456 images, respectively. 2) COCO is a more challenging benchmark with 80 semantic classes. Since more complex contextual relations exist among these categories, it is interesting to examine the performance of our model in this dataset. Following ), we use the default train/val splits (80k images for training and 40k for validation) in the experiment. Evaluation Metric: For fair comparison, we utilize a widely used metric <ref type="bibr" target="#b53">(Wang et al. 2018b;</ref><ref type="bibr" target="#b8">Choe and Shim 2019;</ref><ref type="bibr" target="#b44">Sun et al. 2020)</ref>, mean Intersection-over-Union (mIoU), for evaluation. The scores on the test set of PASCAL VOC are obtained from the official evaluation server.</p><p>Training Details: 1) Greedy Mini-Batch Sampling. During training, we design a heuristic, greedy strategy to sample K training images in each mini-batch. Starting from a randomly sampled image I i , we further find another K −1 images, each of which shares as many common semantic objects with I i as possible. These K images are then used to build a K-node GNN. This sampling strategy enables our model to better explore rich relationships among groups of images and improve the results. 2) Training Settings. For the classification network, the number of nodes K and message passing steps T in the GNN are separately set to 4 and 3 by default. The input image size is 224×224. The entire network is trained using the SGD optimizer with initial learning rates of 1e-3 for the backbone and 1e-2 for the GNN, which are reduced by 0.1 every five epochs. The total number of epochs, momentum and weight decay are set to 15, 0.9, and 5e-4, respectively. The λ in Eq. <ref type="formula" target="#formula_4">(12)</ref> is empirically set to 0.4 and the d in Eq. (5) is set to 4. For the segmentation network, we follow the training setting in <ref type="bibr" target="#b7">(Chen et al. 2017</ref>), but use the generated pseudo ground-truths as the supervision. Reproducibility: Our network is implemented in PyTorch and trained on four NVIDIA RTX 2080Ti GPUs with 11GB memory per card. The testing is conducted on the same machine with one GPU card.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Performance on PASCAL VOC 2012</head><p>We evaluate the proposed approach on PASCAL VOC 2012 against current top-performing WSSS methods that only operate with image-level labels. Following conventions, we evaluate the performance of our model using VGG16 (Simonyan and Zisserman 2015) and ResNet101  as the backbones, respectively. As reported in <ref type="table" target="#tab_0">Table 1</ref>, our model with ResNet101 achieves the best performance, scoring 68.2% and 68.5% on the val and test sets, respectively. It significantly outperforms the current leading approach, i.e., ICD <ref type="bibr" target="#b12">(Fan et al. 2020a</ref>), by +0.4% and +0.5% on the two evaluation sets.</p><p>In addition, <ref type="table" target="#tab_0">Table 1</ref> also shows that the proposed approach outperforms both pair-wise models (i.e., CIAN <ref type="bibr" target="#b14">(Fan et al. 2020b</ref>) and MCIS ), and all single-image based models (e.g., RRM , OAA+ <ref type="bibr" target="#b23">(Jiang et al. 2019)</ref>), by a large margin. The reason lies in that existing methods exploit limited context in image collection, while our approach can learn more effective inter-image representations with GNNs.</p><p>In <ref type="figure">Figure 3</ref>, we also provide sample results for representative images in PASCAL VOC 2012 val. The images cover various challenging factors in WSSS, such as multiple objects, different semantic categories, small objects, and cluttered background. We see that our model can deal with these difficulties well, resulting in appealing segmentation results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Performance on COCO</head><p>We further examine the performance of our model on COCO. As reported in <ref type="table" target="#tab_1">Table 2</ref>, our model achieves the best mIoU score (i.e., 28.4%) on the validation set, outperforming the second-best result, i.e., IAL ), by 0.7%. This further proves the superiority of our model. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Diagnostic Experiments</head><p>We further conduct diagnostic analysis on PASCAL VOC 2012 val set to verify the effectiveness of the essential modules in our approach. We use ResNet101 as the default backbone for all the studies. The performance of our full model with default parameters is given in the first row of <ref type="table" target="#tab_2">Table 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Number of Nodes K:</head><p>We first investigate the effect of the node number K used in the GNN, which indicates the number of images in a group. As shown in <ref type="table" target="#tab_2">Table 3</ref>, the model achieves comparably high performance with three or four nodes. However, when more nodes are added, the performance decreases significantly. This can be attributed to the trade-off between meaningful semantic relations and noise brought by group images. When K = 3 or 4, the semantic relations can be fully exploited to improve the integral regions of objects. However, when more images are further considered, meaningful semantic cues reach a bottleneck and noise, introduced by imperfect localization of the classifier, dominates, thus leading to performance degradation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Number of Message Passing</head><p>Steps T : We further evaluate the impact of the message passing steps by comparing the performance with different T ranging from 2 to 5. From Table 3, we observe that the mIoU score is significantly improved when T varies from 2 to 3. The performance decreases slightly when considering more steps. Therefore, we set T = 3 as default for message passing. Graph Dropout Layer: To verify the effectiveness of the proposed graph dropout layer, we design multiple experiments to search the optimal configuration of parameters drop-rate and drop-th. We observe that both parameters have great influences on the performance. As observed in <ref type="table" target="#tab_2">Table 3</ref>, our model reaches the best performance at δ r = 0.8 and δ d = 0.7. If δ d is higher (e.g., 0.9), most discriminative regions will be kept, and thus ignored regions will remain unactivated. In contrast, if the δ d is lower, the regions with high responses will be excessively dropped, leading to degraded classification accuracy. In addition, the parameter δ r controls whether to drop the responses or not during training. As shown in <ref type="table" target="#tab_2">Table 3</ref>, a δ r of 0.8 helps to achieve the best mIoU score. Such a setting not only maintains the classification ability of the network by keeping discriminative regions with a high probability, but also drives the network to mildly attend to other regions. We can also see that by setting δ r to smaller values (e.g., 0.6 or 0.4), the performance encounters a significant decrease.</p><p>Moreover, we examine the performance of our model without the graph dropout layer. As seen, without the dropout layer, the performance of our model decreases by 0.5% in terms of mIoU, which reveals its importance.</p><p>Finally, we illustrate some examples of the final CAMs generated with or without the graph dropout layer. As shown in <ref type="figure">Figure 4</ref>, without the dropout layer, the network only focuses on the most discriminative parts (e.g., heads of the cat and the horse). This is improved with our dropout layer, which helps to highlight non-discriminative object regions. Self-Ensembling: In addition to the supervision on the final outputs, we also introduce deep supervision signals on the intermediate features. Such multi-level supervision has proven effective for improving the performance of various vision tasks. Besides, this enables us to combine the multiple outputs with low cost to further boost the performance. Here, we examine the self-ensembling strategy by building three network variants, i.e., intermediate output, graph output and self-ensembling, in which the final CAMs are separately extracted from the intermediate readout layer, graphaware readout layer, and their ensemble, respectively. As shown in <ref type="table" target="#tab_2">Table 3</ref>, the intermediate output only obtains an mIoU score of 64.1%, greatly lagging behind the 67.8% obtained by the graph output. This demonstrates that through iterative graph reasoning, our model can improve the image representations by integrating information from group images, leading to huge performance gains. Furthermore, the self-ensembling strategy boosts the performance to 68.2%.</p><p>In <ref type="figure">Figure 5</ref>, we illustrate two groups of images with their CAMs from the intermediate readout layer and graph readout layer. As seen, in both groups, the CAMs are wellrefined to cover more complete foreground regions after graph reasoning. Besides, in many cases, the CAMs from two output layers complement with each other well, enabling better results to be obtained by self-ensembling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>In this paper, we have introduced a group-wise learning framework for weakly supervised semantic segmentation (WSSS). We formulate the task within a graph neural network (GNN), which operates on a group of images and explores their semantic relations for representation learning. By iterative graph reasoning, our model provides better pseudo ground-truths, which further lead to significant performance improvement for the semantic segmentation results. We also devise a graph dropout layer to facilitate the discovery of complete object regions. We conduct extensive experiments on PASCAL VOC 2012 and COCO benchmarks, and the results demonstrate that the proposed approach performs favorably against the state-of-the-art methods.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Architecture comparison of existing frameworks vs. Ours. (a) Single-image models feed each image one by one into the network</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Overview of the proposed group-wise semantic mining network during the training phase. Given a group of images (i.e.,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :Figure 4 :Figure 5 :</head><label>345</label><figDesc>Qualitative results on PASCAL VOC 2012 val. From top to bottom: input images, ground-truths, and our segmentation results. Visual comparisons of CAMs generated w/ or w/o the graph dropout layer. Visual comparisons of CAMs. Here we provide the results of two groups of images. For each group, we show the input images, CAMs from the intermediate readout layer and CAMs from the graph readout layer (from left to right). Our model clearly provides more accurate CAMs after group-wise graph reasoning.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Quantitative comparison of different methods on PAS-CAL VOC 2012 val and test in terms of mIoU.</figDesc><table><row><cell>Methods</cell><cell>Pub.</cell><cell>Val</cell><cell>Test</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>* : VGG backbone.† : ResNet backbone.* MEFF</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Quantitative comparison of different methods on COCO val in terms of mIoU. All methods use VGG16 as the backbone.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Diagnostic experiments of our model on PASCAL VOC 2012 val in terms of mIoU. For all variants, we use ResNet101 as the backbone.</figDesc><table><row><cell cols="2">Aspect</cell><cell cols="2">Variant</cell><cell>mIoU</cell></row><row><cell cols="2">Full Model</cell><cell cols="2">T = 3, K = 4 δr = 0.8, δ d = 0.7</cell><cell>68.2%</cell></row><row><cell></cell><cell>Node Number</cell><cell cols="2">K = 3 K = 5 K = 6</cell><cell>68.1% 67.8% 67.6%</cell></row><row><cell>Graph Reasoning</cell><cell>Message Passing</cell><cell cols="2">T = 2 T = 4 T = 5</cell><cell>67.8% 68.0% 68.0%</cell></row><row><cell></cell><cell>Graph Dropout</cell><cell>δr = 0.8 δr = 0.6 δr = 0.4</cell><cell>δ d = 0.9 δ d = 0.5 δ d = 0.7</cell><cell>68.0% 67.7% 66.8% 63.6%</cell></row><row><cell></cell><cell></cell><cell cols="2">w/o dropout</cell><cell>67.7%</cell></row><row><cell></cell><cell></cell><cell cols="2">intermediate output</cell><cell>64.1%</cell></row><row><cell cols="2">Self-Ensembling</cell><cell cols="2">graph output</cell><cell>67.8%</cell></row><row><cell></cell><cell></cell><cell cols="2">self-ensembling</cell><cell>68.2%</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Weakly supervised learning of instance segmentation with inter-pixel relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kwak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2209" to="2218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning pixel-level semantic affinity with image-level supervision for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kwak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4981" to="4990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Single-Stage Semantic Segmentation from Image Labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Araslanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4253" to="4262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Delving deeper into convolutional networks for learning video representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Weakly-Supervised Semantic Segmentation via Sub-Category Exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-T</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-C</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Piramuthu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-H</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8991" to="9000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Discovering class-specific pixels for weakly-supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chaudhry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Dokania</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.05821</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Weakly Supervised Semantic Segmentation with Boundary Exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="834" to="848" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Attention-based dropout layer for weakly supervised object localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2219" to="2228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Boxsup: Exploiting bounding boxes to supervise convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1635" to="1643" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The pascal visual object classes (voc) challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="303" to="338" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning Integral Objects With Intra-Class Discriminator for Weakly-Supervised Semantic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4283" to="4292" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Employing Multi-Estimations for Weakly-Supervised Semantic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">CIAN: Cross-Image Affinity Net for Weakly Supervised Semantic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="10762" to="10769" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Associating inter-image salient instances for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-M</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="367" to="383" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Multi-evidence filtering and fusion for multi-label classification, object detection and semantic segmentation based on weakly supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1277" to="1286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Neural message passing for quantum chemistry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Schoenholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">F</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Semantic contours from inverse detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Arbeláez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="991" to="998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Identity mappings in deep residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="630" to="645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deeply supervised salient object detection with short connections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Borji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3203" to="3212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Self-erasing network for integral object attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="549" to="559" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Weakly-supervised semantic segmentation network with deep seeded region growing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7014" to="7023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Integral object mining via online attention accumulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-T</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-K</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2070" to="2079" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Simple does it: Weakly supervised instance and semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khoreva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hosang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="876" to="885" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Seed, expand and constrain: Three principles for weakly-supervised image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Lampert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="695" to="711" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deeply-supervised nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial intelligence and statistics</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="562" to="570" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Ficklenet: Weakly and semi-supervised semantic image segmentation using stochastic inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5267" to="5276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Tell me where to look: Guided attention inference network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-C</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ernst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="9215" to="9223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Scribblesup: Scribble-supervised convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3159" to="3167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3431" to="3440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Video object segmentation with episodic graph memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Danelljan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The more you know: Using knowledge graphs for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Marino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="20" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Constrained convolutional neural networks for weakly supervised segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Krahenbuhl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1796" to="1804" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">3D graph neural networks for rgbd semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5199" to="5208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Augmented feedback in semantic segmentation under image level supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="90" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">GMNN: Graph Markov Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5241" to="5250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Built-in foreground/background prior for weakly-supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Saleh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Aliakbarian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Petersson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gould</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Alvarez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="413" to="432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A simple neural network module for relational reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Raposo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Malinowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4967" to="4976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The graph neural network model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Scarselli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Tsoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hagenbuchner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Monfardini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TNN</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="80" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Self-supervised difference detection for weakly-supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shimoda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yanai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5208" to="5217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Box-driven class-wise region masking and filling rate guided loss for weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3136" to="3145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Mining Cross-Image Semantics for Weakly Supervised Semantic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ł</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Graph attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Learning random-walk label propagation for weakly-supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vernaza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="7158" to="7166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Zero-shot video object segmentation via attentive graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Crandall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9236" to="9245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Learning compositional neural information fusion for human parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5703" to="5713" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Hierarchical human parsing with typed part-relation reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8929" to="8939" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Non-local neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7794" to="7803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Weakly-Supervised Semantic Segmentation by Iterative Affinity Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>IJCV 1-14</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Weakly-supervised semantic segmentation by iteratively mining common object features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1354" to="1362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Selfsupervised Equivariant Attention Mechanism for Weakly Supervised Semantic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="12275" to="12284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Object region mining with adversarial erasing: A simple classification to semantic segmentation approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1568" to="1576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Stc: A simple to complex framework for weakly-supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2314" to="2320" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Revisiting dilated convolution: A simple approach for weakly-and semi-supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Jie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7268" to="7277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Joint learning of saliency detection and weakly supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhuge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7223" to="7233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Reliability Does Matter: An End-to-End Weakly Supervised Semantic Segmentation Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="12765" to="12772" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Learning deep features for discriminative localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2921" to="2929" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">MATNet: Motion-Attentive Transition Network for Zero-Shot Video Object Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TIP</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="8326" to="8338" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.04253</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">Motion-Attentive Transition for Zero-Shot Video Object Segmentation. arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
