<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Robust and On-the-fly Dataset Denoising for Image Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-04-10">April 10, 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaming</forename><surname>Song</surname></persName>
							<email>tsong@cs.stanford.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lunjia</forename><surname>Hu</surname></persName>
							<email>lunjia@stanford.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
							<email>michaelauli@fb.com</email>
							<affiliation key="aff2">
								<orgName type="department">Facebook AI Research Yann Dauphin</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Google</forename><surname>Brain</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
							<email>tengyuma@stanford.edu</email>
							<affiliation key="aff3">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Robust and On-the-fly Dataset Denoising for Image Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-04-10">April 10, 2020</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T19:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Memorization in over-parameterized neural networks could severely hurt generalization in the presence of mislabeled examples. However, mislabeled examples are hard to avoid in extremely large datasets collected with weak supervision. We address this problem by reasoning counterfactually about the loss distribution of examples with uniform random labels had they were trained with the real examples, and use this information to remove noisy examples from the training set. First, we observe that examples with uniform random labels have higher losses when trained with stochastic gradient descent under large learning rates. Then, we propose to model the loss distribution of the counterfactual examples using only the network parameters, which is able to model such examples with remarkable success. Finally, we propose to remove examples whose loss exceeds a certain quantile of the modeled loss distribution. This leads to On-the-fly Data Denoising (ODD), a simple yet effective algorithm that is robust to mislabeled examples, while introducing almost zero computational overhead compared to standard training. ODD is able to achieve state-ofthe-art results on a wide range of datasets including real-world ones such as WebVision and Clothing1M.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Over-parametrized deep neural networks have remarkable generalization properties while achieving near-zero training error <ref type="bibr" target="#b44">[45]</ref>. However, the ability to fit the entire training set is highly undesirable, as a small portion of mislabeled examples in the dataset could severely hurt generalization <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b0">1]</ref>.</p><p>Meanwhile, an exponential growth in training data size is required to linearly improve generalization in vision <ref type="bibr" target="#b36">[37]</ref>; this progress could be hindered if there are mislabeled examples within the dataset.</p><p>Mislabeled examples are to be expected in large datasets that contain millions of examples. Web-based supervision produces noisy labels <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b25">26]</ref> whereas human labeled datasets sacrifice accuracy for scalability <ref type="bibr" target="#b18">[19]</ref>. Therefore, algorithms that are robust to various levels of mislabeled examples are warranted in order to further improve generalization for very large labeled datasets.</p><p>In this paper, we are motivated by the observation that crowd-sourcing or web-supervision could have multiple disagreeing sources; in such cases, noisy labels could exhibit higher conditional entropy than the ground truth labels. Since the information about the noisy labels (such as the amount of noise) is often scarce, we pursue a general approach by counterfactual Work done at Facebook AI research.</p><p>At epoch E (large learning rate) <ref type="figure">Figure 1</ref>: Pipeline of our method. We utilize the implicit regularization effect of SGD to (counterfactually) reason the loss distribution of examples with uniform label noise. We remove examples that have loss higher than the threshold and train on the remaining examples. There is no assumption that the dataset has to contain uniformly random labels (thus such labels are "counterfactual"); we empirically validate our method on real-world noisy datasets.  Based on this observation, we propose a distribution that simulates the loss distribution of uniform noisy examples based only on the network parameters. Reasonable thresholds can be derived from percentiles of this distribution, which we can then utilize to denoise the dataset. This is critical in real-world applications, because prior knowledge about the distribution of label noise is often scarce; even if we have such information (such as transition matrices of label noise), algorithms that specifically utilize this information are not scalable when there are thousands of labels.</p><p>We proceed to propose On-the-fly Data Denoising (ODD, see <ref type="figure">Figure 1</ref>), a simple and robust method for training with noisy examples based on the implicit regularization effect of stochastic gradient descent. First, we train residual networks with large learning rate schedules and use the resulting losses to separate clean examples from mislabeled ones. This is done by identifying examples whose losses exceed a certain threshold. Finally, we remove these examples from the dataset and continue training until convergence. ODD is a general approach that can be used to train clean dataset as well as noisy datasets with almost no modifications.</p><p>Empirically, ODD performs favorably against previous methods in datasets containing realworld noisy examples, such as WebVision <ref type="bibr" target="#b20">[21]</ref> and Clothing1M <ref type="bibr" target="#b40">[41]</ref>. ODD also achieves equal or better accuracy than the state-of-the-art on clean datasets, such as CIFAR and ImageNet. We further conduct ablation studies to demonstrate that ODD is robust to different hyperparameters and artificial noise levels. Qualitatively, we demonstrate the effectiveness of ODD by detecting mislabeled examples in the "clean" CIFAR-100 dataset without any supervision other than the training labels ( <ref type="figure" target="#fig_1">Figure 2</ref>). These results suggest that we can use ODD in both clean and noisy datasets with minimum computational overhead to the training algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem setup</head><p>The goal of supervised learning is to find a function f ∈ F that describes the probability of a random label vector Y ∈ Y given a random input vector X ∈ X , which has underlying joint distribution P (X, Y ). Given a loss function (y,ŷ), one could minimize the average of over P :</p><formula xml:id="formula_0">R(f ) = (y, f (x)) dP (x, y),<label>(1)</label></formula><p>which is the basis of empirical risk minimization (ERM) The joint distribution P (X, Y ) is usually unknown, but we could gain access to its samples via a potentially noisy labeling process, such as crowdsourcing <ref type="bibr" target="#b18">[19]</ref> or web queries <ref type="bibr" target="#b20">[21]</ref>. We denote the training dataset with N examples as</p><formula xml:id="formula_1">D = (x i , y i ) i∈[N ] = G ∪ B. G represents correctly labeled (clean) examples sampled from P (X, Y ). B</formula><p>represents mislabeled examples that are not sampled from P (X, Y ), but from another distribution Q(X, Y ); G ∩ B = ∅, as a sample cannot be both correctly labeled and mislabeled.</p><p>We aim to learn the function f from D without knowledge about B, G or their statistics (e.g. |B|). A typical approach is to pretend that B = ∅ -i.e., all examples are i.i.d. from P (X, Y ) -and minimize the empirical risk:R</p><formula xml:id="formula_2">(f ) = 1 N N i=1</formula><p>(y, f (x)).</p><p>If B = ∅ is indeed true, then the empirical risk converges to the population risk:R(f ) → R(f ) as N → ∞. However, if B = ∅, thenR(f ) is no longer an unbiased estimator of R(f ). Moreover, when F contains large neural nets with the number of parameters exceeding N , the empirical risk minimizer could fit the entire training dataset, including the mislabeled examples <ref type="bibr" target="#b44">[45]</ref>. Overfitting to wrong labels empirically causes poor generalization. For example, training CIFAR-10 with 20% of uniformly mislabeled examples and a residual network gives a test error of 11.5%, which is significantly higher than the 4.25% error obtained with training on the clean examples 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Entropy-based Assumption over Noisy Labels</head><p>Therefore, if we were able to identify the clean examples belonging to G, we could vastly improve the generalization on P (X, Y ); this requires us to provide valid prior assumptions that could distinguish clean examples from mislabeled ones. We note that these assumptions have to be general enough so as to not depend on additional assumptions specific to each dataset. For example, knowledge about noise transition matrices is not allowed.</p><p>We assume that for any example x ∈ X , the entropy of the clean label distribution is smaller than that of the noisy label distribution:</p><formula xml:id="formula_3">H(P (Y |X = x)) &lt; H(Q(Y |X = x)) ∀x ∈ X (2)</formula><p>where the randomness of labeling Q(Y |X) could arise from noisy labelings, such as Mechanical Turk <ref type="bibr" target="#b18">[19]</ref>. Let be the cross entropy loss, then the ERM objective is essentially trying to minimize the KL divergence between the empirical conditional distribution (denoted asP (y|x)) and the conditional distribution parametrized by our model (denoted as p θ (y|x)):</p><formula xml:id="formula_4">EP (y|x) [− log p θ (y|x)] = H(P (y|x)) + D KL (P (y|x) p θ (y|x))<label>(3)</label></formula><p>which is minimized as D KL → 0; in this case, the cross entropy loss is higher ifP has higher entropy, which suggests that the mislabeled examples are likely to have higher loss than correct ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Denoising datasets on-the-fly with Counterfactual Thresholds</head><p>In the following section, we study the behavior of samples with uniformly random label noise; this allows us to reason about their loss distribution counterfactually, and develop suitable thresholds to remove noisy examples that appear in the training set. The conditional distribution Q U (Y |X) of uniformly random label noise is simply:</p><formula xml:id="formula_5">Q U (Y |X) = Uniform(Y).<label>(4)</label></formula><p>We note that Q U (Y |X) is the distribution that maximizes entropy; therefore, any real-world noise distribution Q(Y |X) will have smaller entropy than Q U . While it is unreasonable to assume that the label noise is uniformly random in practice, we do not make such assumption over our training set. Instead, we reason about the following counterfactual case:</p><p>Had the training set contained some examples with uniform random labels, can we characterize the loss distribution of these examples?</p><p>Then, we illustrate how such a counterfactual analysis allows simple and practical algorithms that work even under real-world noisy datasets.</p><p>• First, we show that when training ResNets via SGD with large learning rates, the training loss of uniform noisy labels and clean labels can be clearly separated.</p><p>• Next, we propose an approach to model the (counterfactual) loss distribution by only looking at the weights of the network. We empirically show that this does not depend on the type or the amount of noisy labels in the dataset, making this approach generalize well to various counterfactual scenarios (such as different portions of uniform random labels in the dataset).</p><p>• Finally, we can simply remove all examples that perform worse than a certain percentile of the counterfactual distribution. Since higher entropy examples tend to have higher loss than lower entropy ones, the samples we remove are more likely to be more noisy. In <ref type="figure" target="#fig_1">Fig. 2</ref>, we empirically demonstrate that the proposed threshold identifies mislabeled samples in CIFAR-100 even without any additional supervision, validating our assumption. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Separating mislabeled examples via SGD</head><p>First, we find that training the model with stochastic gradient descent (SGD) with large learning rates (e.g. 0.1) will result in significant discrepancy between the loss statistics of the clean examples and mislabeled examples. We consider training deep residual networks on CIFAR-100 and ImageNet with different percentages of uniform label noise (20% and 40%), but with large learning rates (close to 0.1), and at specific epochs, we plot the histogram of the loss for each example.</p><p>As demonstrated in <ref type="figure" target="#fig_2">Fig. 3</ref>, the loss distributions of clean examples and mislabeled ones have notable statistical distance. Moreover, it seems that the loss distribution of the uniform labeled examples are relatively stable, and does not depend on the amount of uniform random noise in the training set. This is consistent with the obeservations in <ref type="bibr" target="#b44">[45]</ref>, as the network starts to fit mislabeled examples when learning rate decrease further; decreasing learning rate is crucial for achieving better generalization on clean datasets.</p><p>The working of the implicit regularization of stochastic gradient descent is by and large an open question that attracts much recent attentions <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b26">27]</ref>. Empirically, it has been observed that large learning rates are beneficial for generalization <ref type="bibr" target="#b17">[18]</ref>. Chaudhari and Soatto <ref type="bibr" target="#b3">[4]</ref> have argued that SGD iterates converge to limit cycles with entropic regularization proportional to the learning rate and inversely proportional to batch size. Training with large learning rates under fixed batch sizes could then encourage solutions that are more robust to large random perturbations in the parameter space and less likely to overfit to mislabeled examples.</p><p>Given these empirical and theoretical evidences on large learning rate helps generalization, we propose to classify correct and mislabeled examples through the loss statistics, and achieve better generalization by removing the examples that are potentially mislabeled.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Thresholds that classify mislabeled examples</head><p>The above observation suggests that it is possible to distinguish clean and noisy examples via a threshold over the loss value. In principle, we can claim an example is noisy if its loss value exceeds a certain threshold; by removing the noisy labels from the training set, we could then improve generalization performance on clean validation sets.</p><p>However, to improve generalization in practice, one critical problem is to select a reasonable threshold for classification. High thresholds could include too many examples from B (the mislabeled set), whereas low thresholds could prune too many examples from G (the clean set); reasonable thresholds should also adapt to different ratios of mislabeled examples, which could be unknown to practitioners.</p><p>If we are able to characterize the loss of Q U (Y |X) (the highest entropy distribution), we can select a reasonable threshold from this loss as any example having higher loss is likely to have high entropy labels (and is possibly mislabeled). From <ref type="figure" target="#fig_2">Fig. 3</ref>, the loss distribution for B is relatively stable with different ratios of |B|/|D|; examples in B are making little progress when learning rate is large. This suggests a threshold selecting criteria that is independent of the amount of mislabeled examples in the dataset.</p><p>We propose to characterize the loss distribution of (counterfactual) uniform label noise via the following procedure:</p><formula xml:id="formula_6">l = −ỹ k + log   i∈[N ] exp(ỹ i )   (5) y = fc(relu(x)),x ∼ N (0, I), k ∼ Uniform{0, . . . , K}</formula><p>We denote this counterfactual distribution model as q n (l). q n (l) tries to simulate the behavior of the model (and the loss distribution) with several components.</p><p>• k represents a random label from K classes. This simulates the case where Q(Y |X) has the highest entropy, i.e. uniformly random.</p><p>• fc(·) is the final (fully connected) layer of the network and relu(x) = max(x, 0) is the Rectified Linear Unit. This simulates the behavior at the last layer of the network outputs y.</p><p>•x ∼ N (0, I) suggests that the inputs to the last layer has an identity covariance; the scale of the covariance could result from well-conditioned objectives defined via deep residual networks <ref type="bibr" target="#b9">[10]</ref>, batch normalization <ref type="bibr" target="#b14">[15]</ref> and careful initialization <ref type="bibr" target="#b10">[11]</ref>.</p><p>We qualitatively demonstrate the validity of our characterization on CIFAR-100 and ImageNet datasets in <ref type="figure" target="#fig_2">Fig. 3</ref>, where we plot the histogram of the q n (l) distribution for CIFAR-100 and ImageNet, and compare then with the empirical distribution of the loss of uniform noisy labeled examples. The similarities between the noisy loss distribution and simulated loss distribution q n (l) demonstrate that an accurate characterization of the loss distribution can be made without prior knowledge of the mislabeled examples.</p><p>To effectively trade-off between precision (correctly identifying noisy examples) and recall (identifying more noisy examples), we define a threshold via the p-th percentile of q n (l) using the samples generated by Equation <ref type="bibr" target="#b4">5</ref>; it relates to approximately how much examples in B we would retain if Q(Y |X) is uniform. In Section A.1, we show that this method is able to identify different percentages of uniform label noise with high precision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">A Practical Algorithm for Robust Training</head><p>We can utilize this to remove examples that might harm generalization, leading to On-the-fly Data Denoising (ODD), a simple algorithm robust to mislabeled examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Hyperparameter selection</head><p>ODD introduces two hyperparameters: E determines the amount of training that separates clean examples from noisy ones; p determines T p that specifies the trade-off between less noisy examples and more clean examples. We do not explicitly estimate the portion of noise in the dataset, nor do we assume any specific noise model. Moreover, ODD is compatible with existing practices for learning rate schedules, such as stepwise <ref type="bibr" target="#b9">[10]</ref> or cosine <ref type="bibr" target="#b23">[24]</ref>. In <ref type="figure">Fig. 4</ref> we demonstrate and discuss how to choose the hyperparameters E and p. For E, we wish to perform ODD operation at a point not too early (to allow enough time for training on clean labels to converge) and not too late (to prevent overfitting noisy labels with small learning rates). For p, we wish to trade-off between keeping as much clean data as possible and removing counterfactually noisy data; selecting p ∈ <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b29">30]</ref> typically works for our case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We evaluate our method extensively on several clean and noisy datasets including CIFAR-10, CIFAR-100, ImageNet <ref type="bibr" target="#b33">[34]</ref>, WebVision <ref type="bibr" target="#b20">[21]</ref> and Clothing1M <ref type="bibr" target="#b40">[41]</ref>. CIFAR-10, CIFAR-100 and ImageNet are clean whereas WebVision and Clothing1M are obtained via web supervision and have more noisy labels. Our experiments consider datasets that are clean, have artificial noise (in CIFAR-10, CIFAR-100 and ImageNet), or have inherent noise from web-supervision (as in the case of WebVision and Clothing1M).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">CIFAR-10 and CIFAR-100</head><p>We first evaluate our method on the CIFAR-10 and CIFAR-100 datasets, which contain 50,000 training images and 10,000 validation images of size 32 × 32 with 10 and 100 labels respectively. In our experiments, we train the wide residual network architecture (WRN-28-10) in <ref type="bibr" target="#b43">[44]</ref> for 200 epochs with a minibatch size of 128, momentum 0.9 and weight decay 5 × 10 −4 . We set  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Input-Agnostic Label Noise</head><p>We first consider label noise that are agnostic to inputs. Following <ref type="bibr" target="#b44">[45]</ref>, We randomly replace a 0%/20%/40%) of the training labels to uniformly random ones, and evaluate generalization error on the clean validation set. We compare with the following baselines: Empirical Risk Minimization (ERM, Eq. 1, <ref type="bibr" target="#b7">[8]</ref>) which assumes all examples are clean; MentorNet <ref type="bibr" target="#b15">[16]</ref>, which pretrains an auxiliary model that predicts weights for each example based on its input features; Ren <ref type="bibr" target="#b31">[32]</ref>, which optimizes the weight of examples via meta-learning; mixup <ref type="bibr" target="#b45">[46]</ref>, a data augmentation approach that trains neural networks on convex combinations of pairs of examples and their labels; Generalized Cross Entropy (GCE, <ref type="bibr" target="#b46">[47]</ref>) that includes cross-entropy loss and mean absolute error <ref type="bibr" target="#b6">[7]</ref>; and Luo <ref type="bibr" target="#b24">[25]</ref>, which regularizes the Jacobian of the network. We also consider using mixup training after we pruned noisy examples with ODD.</p><p>We report the top-1 validation error in <ref type="table" target="#tab_0">Table 1</ref>, where denotes methods trained with knowledge of 1000 additional clean labels. Notably, ODD + mixup significantly outperforms all other algorithms (except for LUO with 20% noise on CIFAR-10). On the one hand, this suggests that ODD is able to distinguish the mislabeled examples and improve generalization; on the other hand, it would seem that removing certain examples even in the "clean" dataset does not seem to hinder generalization, suggesting that our thresholds works in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Mislabeled examples in CIFAR-100</head><p>We display the examples in CIFAR-100 training set for which our ODD methods identify as noise across 3 random seeds. One of the most common label such examples have is "leopard"; in fact, 21 of 50 "leopard" examples in the training set are perceived as hard, and we show some of them in <ref type="figure" target="#fig_4">Fig. 5</ref>. It turns out that a lot of the "leopard" examples contains images that clearly <ref type="table">shark   beetle  forest  squirrel  leopard  flatfish  beaver  tiger  rocket  tank   wardrobe  crab  table  forest  table  plain  forest  camel  flatfish  skyscraper   skyscraper  seal  shrew  wolf  bowl  shrew  girl  bottle</ref> ray kangaroo <ref type="figure">Figure 6</ref>: Random CIFAR-100 examples that are classified as mislabeled. contains tigers and black panthers (CIFAR-100 has a label corresponding to "tiger"). We also demonstrate random examples from the CIFAR-100 that are identified as noise in <ref type="figure">Fig. 6</ref>. The examples identified as noise often contains multiple objects, or are more ambiguous in terms of identity. We include more results in Appendix A.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Non-Homogeneous Labels</head><p>We evaluate ERM and ODD on a setting without mislabeled examples, but the ratio of classes could vary. To prevent the model from utilizing the number of examples in a class, we combine multiple classes of CIFAR-100 into a single class, creating the CIFAR-20 and CIFAR-50 tasks.</p><p>In CIFAR-50, we combine an even class with an odd class while we remove c% of the examples in the odd class. In CIFAR-20, we combine 5 classes in CIFAR-100 that belong to the same super-classwhile we remove c% of the examples in 4 out of 5 classes. This is performed for both training and validation datasets. Results for ERM and ODD with p = 10 and E = 75 are shown in <ref type="table" target="#tab_1">Table 2</ref>, where ODD is able to outperform ERM in these settings where the input examples are not uniformly distributed.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">ImageNet</head><p>We consider experiments on the ImageNet-2012 classification dataset <ref type="bibr" target="#b33">[34]</ref>. Input-agnostic random noise of 0%, 20%, 40% are considered. We only use the center 224 × 224 crop for validation. We train ResNet-152 models <ref type="bibr" target="#b9">[10]</ref> for 90 epochs and report top-1 and top-5 validation errors in <ref type="table" target="#tab_2">Table 3</ref>. ODD significantly outperforms ERM and Luo <ref type="bibr" target="#b24">[25]</ref> in terms of both top-1 and top-5 errors with 20% and 40% label noise, while being comparable to ERM on the clean dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">WebVision</head><p>We further verify the effectiveness of our method on a real-world noisy dataset. The WebVision-2017 dataset <ref type="bibr" target="#b20">[21]</ref> contains 2.4 million of real-world noisy labels, that are crawled from Google and Flickr using the 1,000 labels from the ImageNet-2012 dataset. We consider training Inception ResNet-v2 <ref type="bibr" target="#b37">[38]</ref> for 50 epochs and use input images of size 299 × 299. We use both WebVision and ImageNet validation sets for 1-crop validation, following the settings in <ref type="bibr" target="#b15">[16]</ref>. We do not use a pretrained model or additional labeled data from ImageNet. In <ref type="table" target="#tab_3">Table 4</ref>, we demonstrate superior results than other competitive methods tailored for learning with noisy labels. Our ODD method with p = 30 removes 9.3% of the total examples with Inception ResNet-v2 <ref type="bibr" target="#b37">[38]</ref>. <ref type="table" target="#tab_3">Table 4</ref> suggests that our method is able to outperform the baseline methods when the training dataset is noisy, even as we remove a notable portion of examples. In comparison, we removed around 1.1% of examples in ImageNet; this suggest that WebVision labels are indeed much noisier than the ImageNet labels since there are more examples removed by the (counterfactual) threshold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Clothing1M</head><p>Clothing1M <ref type="bibr" target="#b40">[41]</ref> contains 1 million examples with noisy labels and 50,000 examples with clean labels of 14 classes. Following procedures from previous work, we use the ResNet-50 architecture pre-trained on ImageNet, with a starting learning rate of 0.001 trained with 10 epochs. We consider three settings, where the dataset contains clean labels only, noisy labels only, or both types of labels. For ODD, we set E = 1, p = 1 for the noisy dataset (E = 1 because we fine-tune from ImageNet pre-trained model); we then fine-tune on the clean labels if they are available. <ref type="table" target="#tab_4">Table 5</ref> suggests our method compares favorably against existing methods such as GCE, Joint Optimization <ref type="bibr" target="#b38">[39]</ref>, latent class-conditional noise model (LCCN, <ref type="bibr" target="#b42">[43]</ref>) and Determinant based Mutual Information (DMI, <ref type="bibr" target="#b41">[42]</ref>) on the noisy dataset, and is comparable to Loss Correction (LC, <ref type="bibr" target="#b29">[30]</ref>) on the noisy + clean dataset. We note that LC estimates the label confusion matrix using examples with both clean and noisy labels; the complexity of LC scales quadratically in the number of classes, and it would not be feasible for ImageNet or WebVision.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Ablation Studies</head><p>We include additional ablation studies in Appendix A.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.1">Sensitivity to p</head><p>We first evaluate noisy ImageNet classification with varying p. A higher p includes more clean examples at the cost of involving more noisy examples. From <ref type="figure" target="#fig_5">Fig. 7 (left)</ref>, ODD is not very sensitive to p, and empirically p = 10 represents the best trade-off.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.2">Sensitivity to E</head><p>We evaluate the validation error of ODD on CIFAR with 20% and 40% input-agnoistic label noise where E ∈ {25, 50, 75, 100, 150, 200} (E = 200 is equivalent to ERM). The results in <ref type="figure" target="#fig_5">Fig. 7 (right)</ref> demonstrate that the effect of E on final performance behaves according to our suggestion.</p><p>5 Related work</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.0.1">Generalization of SGD Training</head><p>The generalization of neural networks trained with SGD depend heavily on learning rate schedules <ref type="bibr" target="#b23">[24]</ref>. It has been proposed that wide local minima could result in better generalization <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b16">17]</ref>. Several factors could contribute to wider local optima and better generalization, such as smaller minibatch sizes <ref type="bibr" target="#b16">[17]</ref>, reasonable learning rates <ref type="bibr" target="#b17">[18]</ref>, longer training time <ref type="bibr" target="#b13">[14]</ref>, or distance from the initialization point <ref type="bibr" target="#b13">[14]</ref>. In the presence of mislabeled examples, changes in optimization landscape <ref type="bibr" target="#b0">[1]</ref> could result in bad local minima <ref type="bibr" target="#b44">[45]</ref>, although it is argued that larger batch sizes could mitigate this effect <ref type="bibr" target="#b32">[33]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.0.2">Training with Mislabeled Examples</head><p>One paradigm involves estimating the noise distribution <ref type="bibr" target="#b22">[23]</ref> or confusion matrix <ref type="bibr" target="#b35">[36]</ref>. Another line of methods propose to identify and clean the noisy examples <ref type="bibr" target="#b4">[5]</ref> through predictions of auxillary networks <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b29">30]</ref> or via binary predictions <ref type="bibr" target="#b28">[29]</ref>; the noisy labels are either pruned <ref type="bibr" target="#b1">[2]</ref> or replaced with model predictions <ref type="bibr" target="#b30">[31]</ref>. Our method is comparable to these approaches, but the key difference is that we leverage the implicit regularization of SGD to identify noisy examples. We note that ODD is different from hard example mining <ref type="bibr" target="#b34">[35]</ref> which prunes "easier" examples with lower loss; this does not remove mislabeled examples effectively. The method proposed in <ref type="bibr" target="#b28">[29]</ref> is most similar to ours in principle, but is restricted to binary classification settings. Other approaches propose to balance the examples via a pretrained network <ref type="bibr" target="#b15">[16]</ref>, meta learning <ref type="bibr" target="#b31">[32]</ref>, or surrogate loss functions <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b38">39]</ref>. Some methods require a set of trusted examples <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b11">12]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>We have proposed ODD, a straightforward method for robust training with mislabeled examples. ODD utilizes the implicit regularization effect of stochastic gradient descent, which allows us to reason counterfactually about the loss distribution of examples with uniform label noise. Based on quantiles of this (counterfactual) distribution, we can then prune examples that would potentially harm generalization. Empirical results demonstrate that ODD is able to significantly outperform related methods on a wide range of datasets with artificial and realworld mislabeled examples, maintain competitiveness with ERM on clean datasets, as well as detecting mislabeled examples automatically in CIFAR-100.</p><p>The implicit regularization of stochastic gradient descent opens up other research directions for implementing robust algorithms. For example, we could consider removing examples not only once but multiple times, retraining from scratch with the denoised dataset, or other dataaugmentation approaches such as mixup <ref type="bibr" target="#b45">[46]</ref>. Moreover, it would be interesting to understand the ODD from additional theoretical viewpoints, such as the effects of large learning rates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Additional Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Ablation Studies</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1.1 Sensitivity to p</head><p>We first evaluate noisy ImageNet classification with varying p. A higher p includes more clean examples at the cost of involving more noisy examples. From <ref type="figure" target="#fig_7">Figure 8</ref>, ODD is not very sensitive to p, and empirically p = 10 represents the best trade-off.   Training Error (%) E = 50, p = 5 cifar10 cifar100 <ref type="figure">Figure 10</ref>: Training errors of ODD on CIFAR10 with different amount of uniform noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1.4 Precision and recall for classifying noise</head><p>We evaluate precision and recall for examples classified as noise on CIFAR10 and CIFAR100 for different noise levels <ref type="bibr" target="#b0">(1,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b39">40)</ref> in <ref type="figure">Figure 11</ref>. The recall values are around 0.84 to 0.88 where as the precision values range from 0.88 to 0.92. This demonstrates that ODD is able to achieve good precision/recall with default hyperparameters even at different noise levels. Precision (%) CIFAR10 CIFAR100 <ref type="figure">Figure 11</ref>: Recall and precision for ODD on CIFAR10 and CIFAR100 with different levels of uniform random noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1.5 Percentage of samples discared by ODD</head><p>We show the percentage of examples discarded by Noise Classifier in <ref type="table" target="#tab_5">Table 6</ref>; the percentage of discarded examples by p = 10 is very close to the actual noise level, suggesting that it is a reasonable setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1.6 Ablation studies on WebVision</head><p>We include additional ablation on p for WebVision <ref type="table" target="#tab_6">(Table 7)</ref>. While the results for p = 30 is slightly better, our method outperforms other methods (Luo) even with worse hyperparameters.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Images in CIFAR-100 Classified as Noise</head><p>We display the examples in CIFAR-100 training set for which our ODD methods identify as noise across 3 random seeds. One of the most common label such examples have is "leopard"; in fact, 21 of 50 "leopard" examples in the training set are perceived as hard, and we show some of them in <ref type="figure" target="#fig_1">Figure 12</ref>. It turns out that a lot of the "leopard" examples contains images that clearly contains tigers and black panthers (CIFAR-100 has a label corresponding to "tiger"). <ref type="figure" target="#fig_1">Figure 12</ref>: Examples with label "leopard" that are classified as noise.</p><p>We also demonstrate random examples from the CIFAR-100 that are identified as noise in <ref type="figure" target="#fig_2">Figure 13</ref> and those that are not identified as noise in <ref type="figure" target="#fig_3">Figure 14</ref>. The examples identified as noise often contains multiple objects, and those not identified as noise often contains only one object that is less ambiguous in terms of identity.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Mislabeled examples in the CIFAR-100 training set detected by ODD. reasoning of the behavior of noisy examples with high conditional entropy. Specifically, we reason about the counterfactual case of how examples with uniform random noise would behave had they appeared in the training dataset, without actually training on such labels. If a real example has higher loss than what most counterfactual examples with uniform random noise would have, then there is reason to believe that this example is likely to contain a noisy label; removing this example would then improve performance on a clean test set. To reason about the counterfactual loss distribution of examples with uniform random noise, we first show that training residual networks with large learning rates will create a significant gap between the losses of clean examples and noisy examples. The distribution of training loss over clean examples decrease yet that of the uniformly noisy examples does not change, regardless of the proportion of noisy examples in the dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Histogram of the distributions of losses, where "normal", "noise", and "simulated" denote (real) examples with clean labels, (real) examples with uniform random labels and the counterfactual model q n ( ) respectively. q n ( ) matches the loss distribution of noisy examples, which have higher loss than clean ones; q n ( ) depends only on the network parameters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Algorithm 1 Figure 4 :</head><label>14</label><figDesc>On-the-fly Data Denoising Input: dataset D of size N , model f θ , percentile p, epoch E, learning rate schedule η(t). for e = 1 . . . E do Train on D with learning rate η(e). end forT p = p-th percentile of q n ( ) in Eq. (5) G = {(x, y)| (y, f θ (x)) &lt; T p }, B = D \ G. for e = E + 1 . . . doTrain on G with learning rate η(e). Hyperparameter selection. (Left) Cosine learning rate schedule across epochs; we wish to select E before learning rate becomes small, and after training over clean labels have converged. (Right) Histogram of the losses; we wish to select p that does not remove too many clean data, but also removes as many (conterfactually) noisy data as possible.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Examples with label "leopard" that are classified as mislabeled. E = 75 (total number of epochs is 200) and p = 10 in our experiments.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>(Left) ablating p on ImageNet. (Right) ablating E on CIFAR10.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>ODD has several appealing properties compared to existing methods. First, the thresholds for classifying mislabeled examples from ODD do not rely on estimations of the noise confusion matrix. Next, ODD does not require additional trusted examples. Finally, ODD removes potentially noisy examples on-the-fly; it has little computational overhead compared to standard SGD training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>Ablation studies over the hyperparameter p on ImageNet under different levels of mislabeled examples.A.1.2 Sensitivity to EWe evaluate the validation error of ODD on CIFAR with 20% and 40% input-agnoistic label noise where E ∈ {25, 50, 75, 100, 150, 200} (E = 200 is equivalent to ERM). The results inFigure 9suggest that our method is able to separate noisy and clean examples if E is relatively small where the learning rate is high, but is unable to perform well when the learning rate decreases.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 :</head><label>9</label><figDesc>Validation errors of ODD on CIFAR10 with different values of E.A.1.3 Sensitivity to the amount of noiseFinally, we evaluate the training error of ODD on CIFAR under input-agnostic label noise of {1%, 5%, 10%, 20%, 30%, 40%} with p = 5, E = 50 or 75. This reflects how much examples exceed the threshold and are identified as noise at epoch E. FromFigure 10, we observe that the training error is almost exactly the amount of noise in the dataset, which demonstrates that the loss distribution of noise can be characterized by our threshold regardless of the percentage of noise in the dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 14 :</head><label>14</label><figDesc>Random CIFAR-100 examples that are not classified as noise.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Validation accuracy (in percentage) with uniform label noise. ± 0.1 88.5 ± 0.1 84.4 ± 0.5 81.6 ± 0.2 69.6 ± 0.1 55.7 ± 0.5 ODD + mixup 97.2 ± 0.1 95.6 ± 0.1 95.5 ± 0.2 82.5 ± 0.1 79.1 ± 0.1 76.5 ± 0.4</figDesc><table><row><cell></cell><cell></cell><cell>CIFAR-10</cell><cell></cell><cell></cell><cell>CIFAR-100</cell><cell></cell></row><row><cell>% mislabeled</cell><cell>0</cell><cell>20</cell><cell>40</cell><cell>0</cell><cell>20</cell><cell>40</cell></row><row><cell cols="7">ERM 96.3 mixup 97.0 ± 0.1 93.9 ± 0.3 91.7 ± 0.1 81.4 ± 0.3 71.2 ± 0.3 59.4 ± 0.4</cell></row><row><cell>GCE</cell><cell>-</cell><cell cols="2">89.9 ± 0.2 87.1 ± 0.2</cell><cell>-</cell><cell cols="2">66.8 ± 0.4 62.7 ± 0.2</cell></row><row><cell>Luo</cell><cell cols="6">96.2 ± 0.1 96.2 ± 0.2 94.9 ± 0.2 81.4 ± 0.2 80.6 ± 0.5 74.2 ± 0.5</cell></row><row><cell>Ren</cell><cell>-</cell><cell>-</cell><cell>86.9 ± 0.2</cell><cell>-</cell><cell>-</cell><cell>61.4 ± 2.0</cell></row><row><cell>MentorNet</cell><cell>-</cell><cell>92.0</cell><cell>89.0</cell><cell>-</cell><cell>73.0</cell><cell>68.0</cell></row><row><cell>ODD</cell><cell cols="6">96.2 ± 0.1 94.7 ± 0.1 92.8 ± 0.2 81.8 ± 0.1 77.2 ± 0.1 72.4 ± 0.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Results on non-homogeneous labels.</figDesc><table><row><cell>Task</cell><cell>% samples removed (c)</cell><cell>ERM</cell><cell>ODD</cell></row><row><cell></cell><cell>30</cell><cell cols="2">78.5 ± 0.1 79.0 ± 0.1</cell></row><row><cell>CIFAR-50</cell><cell>50</cell><cell cols="2">77.9 ± 0.1 78.6 ± 0.2</cell></row><row><cell></cell><cell>70</cell><cell cols="2">77.5 ± 0.1 78.1 ± 0.1</cell></row><row><cell></cell><cell>30</cell><cell cols="2">86.4 ± 0.2 86.6 ± 0.1</cell></row><row><cell>CIFAR-20</cell><cell>50</cell><cell cols="2">85.1 ± 0.1 85.4 ± 0.2</cell></row><row><cell></cell><cell>70</cell><cell cols="2">84.4 ± 0.3 84.7 ± 0.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table><row><cell cols="4">Top-1 (top-5) accuracy on ImageNet.</cell></row><row><cell>% mislabeled</cell><cell>0</cell><cell>20</cell><cell>40</cell></row><row><cell>ERM</cell><cell cols="3">78.7 (94.3) 72.6 (90.2) 61.2 (84.4)</cell></row><row><cell>Luo</cell><cell cols="3">76.7 (93.3) 75.2 (92.3) 73.2 (91.0)</cell></row><row><cell>MentorNet</cell><cell>-</cell><cell>-</cell><cell>65.1 (85.9)</cell></row></table><note>ODD (p = 10) 78.7 (94.0) 77.5 (93.5) 74.8 (92.1)</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Top-1 (top-5) accuracy on WebVision and ImageNet validation sets when trained on WebVision.</figDesc><table><row><cell>Method</cell><cell>WebVision ImageNet</cell></row><row><cell>LASS [1]</cell><cell>66.6 (85.6) 59.0 (80.8)</cell></row><row><cell>CleanNet [20]</cell><cell>68.5 (86.5) 60.2 (81.1)</cell></row><row><cell>ERM</cell><cell>69.7 (87.0) 62.9 (83.6)</cell></row><row><cell cols="2">MentorNet [16] 70.8 (88.0) 62.5 (83.0)</cell></row><row><cell cols="2">CurriculumNet [9] 73.1 (89.2) 64.7 (84.9)</cell></row><row><cell>Luo [25]</cell><cell>73.4 (89.5) 65.9 (85.7)</cell></row><row><cell>ODD</cell><cell>74.6 (90.6) 66.7 (86.3)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Validation accuracy on Clothing1M.</figDesc><table><row><cell>Method</cell><cell>Setting</cell><cell>Accuracy</cell></row><row><cell>ERM</cell><cell>noisy</cell><cell>68.9</cell></row><row><cell>GCE</cell><cell>noisy</cell><cell>69.1</cell></row><row><cell>Loss Correction [30]</cell><cell>noisy</cell><cell>69.2</cell></row><row><cell>LCCN [43]</cell><cell>noisy</cell><cell>71.6</cell></row><row><cell>Joint Opt. [39]</cell><cell>noisy</cell><cell>72.2</cell></row><row><cell>DMI [42]</cell><cell>noisy</cell><cell>72.5</cell></row><row><cell>ODD</cell><cell>noisy</cell><cell>73.5</cell></row><row><cell>ERM</cell><cell>clean</cell><cell>75.2</cell></row><row><cell>Loss Correction</cell><cell>noisy + clean</cell><cell>80.4</cell></row><row><cell>ODD</cell><cell>noisy + clean</cell><cell>80.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Percentage of example discraded by ODD on ImageNet-2012.</figDesc><table><row><cell>% Mislabeled</cell><cell>1</cell><cell>Hyperparameter p 10 30 50 80</cell><cell>Network</cell></row><row><cell>0%</cell><cell cols="2">5.5 2.3 1.1 0.7 0.4</cell><cell></cell></row><row><cell>20%</cell><cell cols="2">23.8 20.8 19.2 17.5 0.7</cell><cell>ResNet-152</cell></row><row><cell>40%</cell><cell cols="2">44.1 40.2 36.2 27.6 0.6</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc>Additional results on WebVision with varying p. 89.93 65.77 85.40 10 74.31 90.55 66.09 85.86 30 74.62 90.63 66.73 86.32 50 74.43 90.78 66.58 86.21 80 74.33 90.30 66.23 86.24</figDesc><table><row><cell>p Webvision</cell><cell>ImageNet</cell></row><row><cell cols="2">Top1 Top5 Top1 Top 5</cell></row><row><cell>1 74.01</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>Random CIFAR-100 examples that are classified as noise.</figDesc><table><row><cell>shark</cell><cell>beetle</cell><cell></cell><cell>forest</cell><cell>squirrel</cell><cell>leopard</cell><cell>flatfish</cell><cell>beaver</cell><cell>tiger</cell><cell>rocket</cell><cell>tank</cell></row><row><cell>wardrobe</cell><cell>crab</cell><cell></cell><cell>table</cell><cell>forest</cell><cell>table</cell><cell>plain</cell><cell>forest</cell><cell>camel</cell><cell>flatfish</cell><cell>skyscraper</cell></row><row><cell>skyscraper</cell><cell>seal</cell><cell></cell><cell>shrew</cell><cell>wolf</cell><cell>bowl</cell><cell>shrew</cell><cell>girl</cell><cell>bottle</cell><cell>ray</cell><cell>kangaroo</cell></row><row><cell cols="3">Figure 13: cattle boy</cell><cell>train</cell><cell>elephant</cell><cell>sunflower</cell><cell>keyboard</cell><cell>squirrel</cell><cell>pine_tree</cell><cell>pine_tree</cell><cell>oak_tree</cell></row><row><cell>bicycle</cell><cell>rabbit</cell><cell cols="2">streetcar</cell><cell>table</cell><cell>mountain</cell><cell>skyscraper</cell><cell>tractor</cell><cell>butterfly</cell><cell>sea</cell><cell>chair</cell></row><row><cell>hamster</cell><cell>lion</cell><cell cols="2">sweet_pepper</cell><cell>orange</cell><cell>camel</cell><cell>caterpillar</cell><cell>forest</cell><cell>possum</cell><cell>cloud</cell><cell>snail</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">See Table.1, Section 4.1 for the exact experiment setup.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">A closer look at memorization in deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Arpit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jastrzkebski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Kanwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Maharaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lacoste-Julien</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.05394</idno>
		<imprint>
			<date type="published" when="2017-06" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Others: Identifying and eliminating mislabeled training instances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Brodley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Friedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Conference on Artificial Intelligence</title>
		<meeting>the National Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="799" to="805" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chaudhari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Choromanska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Baldassi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Borgs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chayes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sagun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zecchina</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01838</idno>
		<title level="m">Entropy-SGD: Biasing gradient descent into wide valleys</title>
		<imprint>
			<date type="published" when="2016-11" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Stochastic gradient descent performs variational inference, converges to limit cycles for deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chaudhari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 Information Theory and Applications Workshop (ITA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Casting out demons: Sanitizing training data for anomaly sensors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">F</forename><surname>Cretu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Stavrou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Locasto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Stolfo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Keromytis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SP 2008. IEEE Symposium on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="81" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.00900</idno>
		<title level="m">Algorithmic regularization in learning deep homogeneous models: Layers are automatically balanced</title>
		<imprint>
			<date type="published" when="2018-06" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Robust loss functions under label noise for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Sastry</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>AAAI</publisher>
			<biblScope unit="page" from="1919" to="1925" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Noordhuis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wesolowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kyrola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tulloch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02677</idno>
		<title level="m">Accurate, large minibatch SGD: Training ImageNet in 1 hour</title>
		<imprint>
			<date type="published" when="2017-06" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Curriculumnet: Weakly supervised learning from large-scale web images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="135" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.03385</idno>
		<title level="m">Deep residual learning for image recognition</title>
		<imprint>
			<date type="published" when="2015-12" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.01852</idno>
		<title level="m">Delving deep into rectifiers: Surpassing Human-Level performance on ImageNet classification</title>
		<imprint>
			<date type="published" when="2015-02" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Using trusted data to train deep networks on labels corrupted by severe noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mazeika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.05300</idno>
		<imprint>
			<date type="published" when="2018-02" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">SIMPLIFYING NEURAL NETS BY DISCOVERING FLAT MINIMA</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>Tesauro, G., Touretzky, D.S., Leen, T.K.</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1995" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="529" to="536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Train longer, generalize better: closing the generalization gap in large batch training of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hoffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Hubara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Soudry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>Garnett, R.</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1731" to="1741" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03167</idno>
		<title level="m">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.05055</idno>
		<title level="m">MentorNet: Learning Data-Driven curriculum for very deep neural networks on corrupted labels</title>
		<imprint>
			<date type="published" when="2017-12" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">S</forename><surname>Keskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mudigere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nocedal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Smelyanskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">T P</forename><surname>Tang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.04836</idno>
		<title level="m">On Large-Batch training for deep learning: Generalization gap and sharp minima</title>
		<imprint>
			<date type="published" when="2016-09" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">An alternative view: When does SGD escape local minima?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.06175</idno>
		<imprint>
			<date type="published" when="2018-02" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Embracing error to enable rapid crowdsourcing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kravitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Shamma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
		<idno type="DOI">10.1145/2858036.2858115</idno>
		<ptr target="https://doi.org/10.1145/2858036.2858115" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2016 CHI Conference on Human Factors in Computing Systems<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3167" to="3179" />
		</imprint>
	</monogr>
	<note>CHI &apos;16</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Cleannet: Transfer learning for scalable image classifier training with label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5447" to="5456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Agustsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.02862</idno>
		<title level="m">WebVision database: Visual learning and understanding from web data</title>
		<imprint>
			<date type="published" when="2017-08" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Algorithmic regularization in over-parameterized matrix sensing and neural networks with quadratic activations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.09203</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1411.7718</idno>
		<title level="m">Classification with noisy labels by importance reweighting</title>
		<imprint>
			<date type="published" when="2014-11" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">SGDR: Stochastic gradient descent with warm restarts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.03983</idno>
		<imprint>
			<date type="published" when="2016-08" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">A simple yet effective baseline for robust deep learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pfister</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.09338</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Exploring the limits of weakly supervised pretraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Paluri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bharambe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.00932</idno>
		<imprint>
			<date type="published" when="2018-05" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Stochastic gradient descent as approximate bayesian inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="4873" to="4907" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Neyshabur</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.01953</idno>
		<title level="m">Implicit regularization in deep learning</title>
		<imprint>
			<date type="published" when="2017-09" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Learning with confident examples: Rank pruning for robust classification with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G</forename><surname>Northcutt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">L</forename><surname>Chuang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.01936</idno>
		<imprint>
			<date type="published" when="2017-05" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Making deep neural networks robust to label noise: A loss correction approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Patrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rozza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2233" to="2241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6596</idno>
		<title level="m">Training deep neural networks on noisy labels with bootstrapping</title>
		<imprint>
			<publisher>December</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Learning to reweight examples for robust deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.09050</idno>
		<imprint>
			<date type="published" when="2018-03" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rolnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Veit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shavit</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.10694</idno>
		<title level="m">Deep learning is robust to massive label noise</title>
		<imprint>
			<date type="published" when="2017-05" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">ImageNet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11263-015-0816-y</idno>
		<ptr target="https://doi.org/10.1007/s11263-015-0816-y" />
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Training region-based object detectors with online hard example mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="761" to="769" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Paluri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.2080</idno>
		<title level="m">Training convolutional networks with noisy labels</title>
		<imprint>
			<date type="published" when="2014-06" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Revisiting unreasonable effectiveness of data in deep learning era</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.02968</idno>
		<imprint>
			<date type="published" when="2017-07" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Inception-v4, Inception-ResNet and the impact of residual connections on learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alemi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.07261</idno>
		<imprint>
			<date type="published" when="2016-02" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Joint optimization framework for learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ikami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yamasaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Aizawa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.11364</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Learning from noisy Large-Scale datasets with minimal supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Veit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Alldrin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chechik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Krasin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6575" to="6583" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Learning from massive noisy labeled data for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2691" to="2699" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.03388</idno>
		<title level="m">L dmi: An information-theoretic noise-robust loss function</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Safeguarded dynamic label regression for noisy supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.07146</idno>
		<title level="m">Wide residual networks</title>
		<imprint>
			<date type="published" when="2016-05" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.03530</idno>
		<title level="m">Understanding deep learning requires rethinking generalization</title>
		<imprint>
			<date type="published" when="2016-11" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<title level="m">mixup: Beyond empirical risk minimization</title>
		<imprint>
			<date type="published" when="2017-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Generalized cross entropy loss for training deep neural networks with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sabuncu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8778" to="8788" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
