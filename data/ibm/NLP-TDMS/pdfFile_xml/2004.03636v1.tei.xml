<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">EFFICIENT LONG-DISTANCE RELATION EXTRACTION WITH DG-SPANBERT</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-04-09">April 9, 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Chen</surname></persName>
							<email>jun.chen@kaust.edu.sa</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Hoehndorf</surname></persName>
							<email>robert.hoehndorf@kaust.edu.sa</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Elhoseiny</surname></persName>
							<email>mohamed.elhoseiny@kaust.edu.sa</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangliang</forename><surname>Zhang</surname></persName>
							<email>xiangliang.zhang@kaust.edu.sa</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">King Abduallah University of Science and Technology</orgName>
								<address>
									<postCode>23955</postCode>
									<settlement>Thuwal</settlement>
									<country key="SA">Saudi Arabia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">King Abduallah University of Science and Technology Thuwal</orgName>
								<address>
									<postCode>23955</postCode>
									<country key="SA">Saudi Arabia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">King Abduallah University of Science and Technology Thuwal</orgName>
								<address>
									<postCode>23955</postCode>
									<country key="SA">Saudi Arabia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">King Abduallah University of Science and Technology Thuwal</orgName>
								<address>
									<postCode>23955</postCode>
									<country key="SA">Saudi Arabia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">EFFICIENT LONG-DISTANCE RELATION EXTRACTION WITH DG-SPANBERT</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-04-09">April 9, 2020</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T22:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In natural language processing, relation extraction seeks to rationally understand unstructured text. Here, we propose a novel SpanBERT-based graph convolutional network (DG-SpanBERT) that extracts semantic features from a raw sentence using the pre-trained language model SpanBERT and a graph convolutional network to pool latent features. Our DG-SpanBERT model inherits the advantage of SpanBERT on learning rich lexical features from large-scale corpus. It also has the ability to capture long-range relations between entities due to the usage of GCN on dependency tree. The experimental results show that our model outperforms other existing dependency-based and sequence-based models and achieves a state-of-the-art performance on the TACRED dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Relation extraction aims to discern the semantic relation that exists between two entities within the context of a sentence. For example, in the sentence "The key was in a chest", "key" is a subject entity and "chest" is an object entity. The target for relation extraction is to predict the relation between "key" and "chest", which is "Content-Container". Relation extraction plays a fundamental role in natural language understanding of unstructured text, such as knowledge base population [1], question answering [2] and information extraction <ref type="bibr" target="#b2">[3]</ref>.</p><p>The existing solutions for relation extraction can be categorized into dependency-based and sequence-based approaches. Dependency-based models rely on the dependency trees that are able to provide rich structural and syntactic information for classifying relations; see, for example, [4] and <ref type="bibr" target="#b4">[5]</ref>. Sequence-based models directly operate on the word sequences and forgo the information of dependency structures. For example, the model described in [6] relies on a multi-level attention mechanism to capture the attentions regarding target entities and relations. Bidirectional Long Short-Term Memory (LSTM) is applied on sentences to capture the semantic features in <ref type="bibr" target="#b6">[7]</ref>. Recently, BERT-related models <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10]</ref> have shown their ability to improve relation extraction tasks and achieve state-of-the-art results.</p><p>Although BERT-based models are strong on learning rich semantic features, they may not effectively capture the long-range syntactic relations. For example, in the sentence "Arcandor said in documents filed Wednesday with a district court in Essen, where it is based, that the 15 companies include Corporate Service Group GmbH", with "Arcandor" as the subject and "Corporate Service Grroup GmbH" as the object, it is difficult for sequence-based models to extract features between such long-distance entities. Therefore, we propose DG-SpanBERT model, which is the first to combine BERT-related model with Graph Convolutional Network (GCN) on relation extraction. Specifically, our model groups BERT sentence-embedding in a dependency tree structure and then uses a GCN network to extract features from the tree.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>DG-SpanBERT thus has a unique advantage that leverages the local features and better captures long-distance relations than other models. Our model obtains an F1-score of 71.5% in TACRED and achieves a state-of-the-art performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Early research efforts on relation extraction were based on statistical methods. <ref type="bibr" target="#b10">[11]</ref> introduced a shallow tree-based kernel to determine the relation between two entities. <ref type="bibr" target="#b11">[12]</ref> parsed the sentence into a dependency graph and recognized the relation types from the shortest path between two named entities. <ref type="bibr" target="#b12">[13]</ref> predicted the relations by finding maximal cliques of entities. <ref type="bibr" target="#b13">[14]</ref> dealed with a long sentence by adding syntax features to a statistical classifier. Neural-based models have achieved a lot of success in relation extraction. <ref type="bibr" target="#b14">[15]</ref> used a deep convolutional neural network (CNN) on the relation classification, which outperformed the previous statistical machine learning methods. Then many neural models followed, such as attention-based Bidirectional LSTM <ref type="bibr" target="#b6">[7]</ref> and CNN with two levels of attention <ref type="bibr" target="#b5">[6]</ref>. With the born of BERT <ref type="bibr" target="#b15">[16]</ref>, solutions to relation extraction reached a new high-level <ref type="bibr" target="#b16">[17]</ref>. The most significant improvement was achieved by SpanBERT <ref type="bibr" target="#b7">[8]</ref>, which masks continuous spans of text instead of random tokens in pre-training that results in better word embedding and outperforms the BERT model for many NLP tasks, in particular for relation extraction. SpanBERT is the most recent state-of-the-art model for relation extraction across the family of different methods. Another stream of solutions demonstrates that incorporating a dependency tree into neural models could improve relation extraction. <ref type="bibr" target="#b17">[18]</ref> designed a dependency-based neural network (DepNN) that uses the recursive neural network to model the sub-tree and also incorporates the CNN to learn features from the shortest path between two entities. <ref type="bibr" target="#b18">[19]</ref> argued that a dependency tree could help a neural model to capture the long-distance relations and thus, they applied LSTM to the shortest dependency path between two target entities. More recently, <ref type="bibr" target="#b4">[5]</ref> proposed to use GCN on a pruned dependency tree that is tailored to relation extraction.</p><p>Our work is inspired by the superior performance of the SpanBERT model <ref type="bibr" target="#b7">[8]</ref> and the capability of a dependency tree on grouping long clauses together and extracting the grammar structure of the sentence <ref type="bibr" target="#b4">[5]</ref>. We show that our DG-SpanBERT model achieves the best performance on the TACRED dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DG-SpanBERT model</head><p>In this section, we first describe the SpanBERT model, and then explain how we use GCN to learn features of the dependency tree. Finally, we introduce our model architecture that combines SpanBERT and GCNs for relation extraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Pre-trained Model SpanBERT</head><p>The SpanBERT model <ref type="bibr" target="#b7">[8]</ref> extends BERT model <ref type="bibr" target="#b15">[16]</ref> to better represent and predict spans of text. SpanBERT differs from BERT in three ways: First, during pre-training, spans of tokens are masked, rather than individual tokens. Second, in SpanBERT, a span boundary objective (SBO) is introduced and only the tokens at the span's boundary are predicted, which represents the entire masked span. Third, SpanBERT only trains single contiguous segments of text for the masked language modeling (MLM) task. With these modifications of the original BERT, the SpanBERT model shows a significant improvement for many NLP tasks. Usually, when we input a sequence of words or sub-word tokens X = (x 1 , ..., x n ) into a BERT-like model, it can produce a contextualized vector representation for each token: O = vec(x 1 , ..., x n ). The BERT model also appends the token '[CLS]' to the beginning of the sequence X, and the first token in the final output hidden states is used to represent the whole sentence embedding for classification tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Graph Convolutional Network</head><p>The GCN model <ref type="bibr" target="#b19">[20]</ref> has been popularly used for learning graph representation. Given a graph with n nodes, we can use an n × n adjacency matrix A to represent the graph structure, where A ij = 1 if there is an edge connecting between node i and node j, A ij = 0 otherwise. For a node i, its representation at the l-th layer is obtained by</p><formula xml:id="formula_0">h l i = σ( n j=1 A ij W l h l−1 j + b l )<label>(1)</label></formula><p>where h l−1 is the node representation from (l − 1)-th layer, W l is the weight, σ is the nonlinear activation function and b l is a bias term. This operation updates the representation of node i by aggregating its neighborhood via a convolution kernel. , where x i is the i th token, and X s and X o correspond to the subject entity and object entity, respectively. A relation extraction task, by definition, is to classify the relation r ∈ R (predefined relations) between X s and X o . <ref type="figure" target="#fig_0">Figure 1</ref> shows the overall architecture of our model. To enable the SpanBERT module to capture the location of X s and X o without overfitting to these two token spans, we replace each subject and object token with "[unused_index]", where the index is defined corresponding to the token name entity recognition (NER) types. For example, after we replace subject and object entities with special tokens, the sentence Alan Gross was working in Cuba for a development contractor when he was arrested in December with subject Alan Gross and object Cuba is converted to: "[CLS] [unused_1] [unused_1] was working in [unused_2] for a development contractor when he was arrested in December [SEP]". SpanBERT tokenizes each word into its sub-word representations. The natural language dependency parser, such as the Stanford Parser <ref type="bibr" target="#b20">[21]</ref>, parses the sentence into a dependency tree. A dependency parser usually groups phrases together and analyzes the grammatical structure of a sentence. Due to the semantic gap between different tokenization systems of SpanBERT and dependency parser, we align the SpanBERT tokens with dependency parser tokens via random sampling. According to our random sampling strategy, if one word is tokenized into several sub-words by SpanBERT, we randomly select one sub-word to represent the whole word. This operation has an advantage that each sub-word can be mapped to its original word, based on which we build a more meaningful and smaller dependency tree, comparing to that using all subwords.</p><p>Suppose the final hidden state output from SpanBERT is H = [h 0 , ..., h n ], where the first token h 0 represents the whole sentence embedding. The rest of the hidden states [h 1 , ..., h n ] will be used as the initial representation of each token in X : [x 1 , ..., x n ]. We then convert the sentence into a dependency tree structure, where a node is a token with an attributed vector h i . To allow the information in layer l − 1 to be properly carried to the next layer l in the graph convolution operation, we add a self-loop to each node for forming a graph, represented by an adjacency matrix A. As shown in Eq. (1), GCN iteratively updates the node representation h l i layer by layer, through integrating the node's neighborhood information. Our GCN operates on H from SpanBERT and A of dependency tree, and thus results in a seamless integration of rich lexical features and semantic relevance of entities in a long range. That's the key to make our DG-SpanBERT perform better than other models on extracting long-distance relations.</p><p>After applying an L-layer GCN over the adjacency matrix A and SpanBERT hidden states H, we obtain the convolved features for each token. To generate a sentence representation, we use max pooling to map from n token vectors to one vector,</p><p>h sentence = f <ref type="figure">(GCN (H, A)</ref>)</p><formula xml:id="formula_1">(2)</formula><p>where f is the pooling function: R d×n → R d . The same max pooling is applied to extract subject and object entity representation h s and h o , respectively.</p><p>The representation h sentence , h s and h o are then concatenated and fed into a feed-forward neural network (FFNN), which outputs a transformed feature representation. Finally, we concatenate the SpanBERT sentence representation h 0 and the transformed GCN feature representation to produce the final representation, as shown in the last layer of <ref type="figure" target="#fig_0">Figure  1</ref>:</p><formula xml:id="formula_2">h f inal = [h 0 ; W c ([h sentence ; h s ; h o ]) + b c ]<label>(3)</label></formula><p>In the end, h f inal is fed to another FFNN with softmax operation to output a probability distribution over relations. The loss function is defined based on cross entropy for the end-to-end model parameter optimisation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset and Experimental Setup</head><p>The TACRED dataset <ref type="bibr" target="#b21">[22]</ref> contains over 106K sentences, and it covers 41 relation types (e.g., per:schools_attended and org:members) and one "no relation" label to describe the relation between the subject and the object in the sentences. The types of subject and object mentions are categorized into 17 fine-grained types, including person, organization and location, etc. We replace the subject and object entities with their NER tags by following the entity masking schema as described in <ref type="bibr" target="#b21">[22]</ref>.</p><p>We train our SpanBERT model and the GCN part with a different learning rate (3e-5 and 0.01, respectively). We follow the SpanBERT settings for other hyperparameters. To make an appropriate comparison, all evaluated models in this paper are trained with the same setting. The GCN hidden states dimension is set to be 400. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results and Discussion</head><p>We compare our model with previously existing dependency-based and sequence-based neural models that do not introduce external features. The results in <ref type="table" target="#tab_0">Table 1</ref> show that DG-SpanBERT outperforms all the sequence-based models by at least 0.8 F1 and outperforms all the dependency-based models by at least 3.7 F1. That's saying: our model achieves a new state-of-the-art performance on TACRED. Moreover, if we only consider the base pre-trained models, our model outperforms other BERT-related models by at least 2.1 F1. Due to the natural integration of H (from SpanBERT) and A (from dependency tree) by GCN, our DG-SpanBERT is expected to perform well on predicting long-distance relations. Therefore, we evaluate the performance of several models on predicting relations with different number of tokens between the subject and object. As shown in <ref type="figure" target="#fig_1">Figure  2</ref>, all models perform similarly on relations with distance less than 8, since it is an easy task to predict short-distance relations. However, for long-distance relations (≥8), our DG-SpanBERT significantly outperforms all other baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Avg  <ref type="table">Table 2</ref>: Compare average F1 performance for those token distances ≥ 11 tokens between the subject and object. Bold indicates the best performance among all.</p><p>Since the average distance between the subject and object is approximately 12 tokens, we report the average F1 performance of these models on predicting relations with span distance ≥ 11 tokens, in <ref type="table">Table 2</ref>. We observe that DG-SpanBERT outperforms other BERT-related models by at least 3.1 F1, and other dependency-based models by at least 8.3 F1. This significant improvement confirms the effectiveness of our DG-SpanBERT model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we proposed a novel neural network model based on SpanBERT and a graph convolutional network for relation extraction. We showed how our model achieves the state-of-the-art results on a large-scale TACRED dataset. We also showed how our model is particularly effective at capturing long-distance relations compared to other models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Architecture of the DG-SpanBERT model 3.3 Our proposed DG-SpanBERT model Given a sentence X = [x 1 , ..., x n ] and two non-overlapping entity spans, X s = [x s1 , ..., x sn ] and X o = [x o1 , ..., x on ]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Comparison of BERT, SpanBERT, DG-SpanBERT, CGCN and AGGCN w.r.t. the distance between the subject and object.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Compare DG-SpanBERT with other models on TACRED dataset. Bold indicates the best performance among all.</figDesc><table><row><cell>Model</cell><cell>P</cell><cell>R</cell><cell>F1</cell></row><row><cell>C-GCN</cell><cell cols="3">68.9 66.3 67.6</cell></row><row><cell>C-AGGCN</cell><cell>69.6</cell><cell>66</cell><cell>67.8</cell></row><row><cell>Google Bert(base)</cell><cell cols="3">68.1 67.7 67.9</cell></row><row><cell>SpanBert(base)</cell><cell cols="3">67.6 68.6 68.1</cell></row><row><cell cols="4">DG-SpanBERT(base) 68.3 72.1 70.2</cell></row><row><cell>Google Bert(large)</cell><cell>69.2</cell><cell>72</cell><cell>70.6</cell></row><row><cell>SpanBert(large)</cell><cell cols="3">71.2 70.4 70.8</cell></row><row><cell cols="4">DG-SpanBERT(large) 71.4 71.6 71.5</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Knowledge base population: Successful approaches and challenges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th annual meeting of the association for computational linguistics: Human language technologies</title>
		<meeting>the 49th annual meeting of the association for computational linguistics: Human language technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1148" to="1158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Improved neural relation detection for knowledge base question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenpeng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kazi Saidul Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Cicero Dos Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.06194</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Identifying relations for open information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the conference on empirical methods in natural language processing</title>
		<meeting>the conference on empirical methods in natural language processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1535" to="1545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Cross-sentence n-ary relation extraction with graph lstms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoifung</forename><surname>Poon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Quirk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="101" to="115" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Graph convolution over pruned dependency trees improves relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.10185</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Relation classification via multi-level attention cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linlin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhu</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><forename type="middle">De</forename><surname>Melo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th annual meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th annual meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1298" to="1307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Attention-based bidirectional long short-term memory networks for relation classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenyu</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingchen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongwei</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="207" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Levy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.10529</idno>
		<title level="m">Spanbert: Improving pre-training by representing and predicting spans</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Enriching pre-trained language model with entity information for relation classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanchan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.08284</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Matching the blanks: Distributional similarity for relation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Livio Baldini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Soares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kwiatkowski</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.03158</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Kernel methods for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Zelenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chinatsu</forename><surname>Aone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Richardella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1083" to="1106" />
			<date type="published" when="2003-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A shortest path dependency kernel for relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Razvan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Bunescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT &apos;05</title>
		<meeting>the Conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT &apos;05<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="724" to="731" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Simple algorithms for complex relation extraction with applications to biomedical ie</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seth</forename><surname>Kulick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Winters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pete</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 43rd Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="491" to="498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction without labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Mintz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rion</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1003" to="1011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Relation classification via convolutional deep neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daojian</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siwei</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyou</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Simple bert models for relation extraction and semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.05255</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">A dependency-based neural network for relation classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houfeng</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1507.04646</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Classifying relations via long short term memory networks along shortest dependency paths</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lili</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ge</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchuan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the 2015 conference on empirical methods in natural language processing</title>
		<meeting>the 2015 conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1785" to="1794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Parsing with compositional vector grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Y</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="455" to="465" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Position-aware attention and supervised data improve slot filling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="35" to="45" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
