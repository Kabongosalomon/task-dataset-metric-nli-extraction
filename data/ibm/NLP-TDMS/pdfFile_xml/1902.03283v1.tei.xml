<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MACHINE LEARNING AND CHORD BASED FEATURE ENGINEERING FOR GENRE PREDICTION IN POPULAR BRAZILIAN MUSIC A PREPRINT</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-02-12">February 12, 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruna</forename><forename type="middle">D</forename><surname>Wundervald</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Statistics</orgName>
								<orgName type="institution">Hamilton Institute Maynooth University</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walmes</forename><forename type="middle">M</forename><surname>Zeviani</surname></persName>
							<email>walmes@ufpr.br</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Statistics Paraná Federal University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">MACHINE LEARNING AND CHORD BASED FEATURE ENGINEERING FOR GENRE PREDICTION IN POPULAR BRAZILIAN MUSIC A PREPRINT</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-02-12">February 12, 2019</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T10:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>feature engineering · MIR · random forests · chords · genre classification</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Music genre can be hard to describe: many factors are involved, such as style, music technique, and historical context. Some genres even have overlapping characteristics. Looking for a better understanding of how music genres are related to musical harmonic structures, we gathered data about the music chords for thousands of popular Brazilian songs. Here, 'popular' does not only refer to the genre named MPB (Brazilian Popular Music) but to nine different genres that were considered particular to the Brazilian case. The main goals of the present work are to extract and engineer harmonically related features from chords data and to use it to classify popular Brazilian music genres towards establishing a connection between harmonic relationships and Brazilian genres. We also emphasize the generalisation of the method for obtaining the data, allowing for the replication and direct extension of this work. Our final model is a combination of multiple classification trees, also known as the random forest model. We found that features extracted from harmonic elements can satisfactorily predict music genre for the Brazilian case, as well as features obtained from the Spotify API. The variables considered in this work also give an intuition about how they relate to the genres.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Many factors are involved in the configuration of a music genre: style, music techniques, historical context, regional identity, harmonic structures and so on <ref type="bibr" target="#b0">[1]</ref>. A list of popular music genres can be easily found, but it usually does not come with no proper description for each one <ref type="bibr" target="#b1">[2]</ref>. For the Brazilian case, some music genres even hold overlapping characteristics, making it harder to distinguish one from another. Musical genres facilitate the search for music, enveloping a simplification of what each song is. <ref type="bibr" target="#b2">[3]</ref> found that users prefer to look for music of their interest by genre rather than by other metrics, such as artist similarity. Thereby, inconsistencies and blurriness in the definition of musical genres pose an important problem in various aspects of music studies.</p><p>Meanwhile, as <ref type="bibr" target="#b3">[4]</ref> and <ref type="bibr" target="#b4">[5]</ref> observed, mid-level music features such as chords configure a rich resource of informa-tion regarding genres. The chords sequence of a song fully describes its harmonic progression and, by consequence, represents a meaningful part of the total music structure. Therefore, the focus of this work is to establish a connection between harmonic information and genre specification in Brazilian popular music. Here, the term 'popular' does not refer only to the genre named MPB, that stands for Música Popular Brasileira <ref type="bibr" target="#b5">[6]</ref>, or Brazilian Popular Music, but to nine genres that were considered familiar to the Brazilian context.</p><p>Musical data is available in a wide variety of formats for the genre classification task: music sheets, chords, lyrics, MIDI, audio files, and others <ref type="bibr" target="#b6">[7]</ref>. Each one of those formats carries different levels of information about the pieces. The choice of a data format to work also defines what kind of information will be available for the analysis. The choice of symbolic chords data allows us to extract harmonically related features for the genre classification. More than just using raw information, we can capture deeper characteristics of the songs by representing their chords structures in different and meaningful forms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>arXiv:1902.03283v1 [cs.IR] 8 Feb 2019</head><p>Related work has been done for most of the usual representations of music data. For audio data, we can mention <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref> and <ref type="bibr" target="#b10">[11]</ref>, all of which focused in music genre classification using audio extracted features. Concerning text data related to music, <ref type="bibr" target="#b11">[12]</ref> presents a discussion about the characterization of genres through song lyrics. A recent interesting publication is <ref type="bibr" target="#b12">[13]</ref>, where the authors introduced a vector based representation for chords sequences. This work is notable in the sense that it brings to light a new and effective way to extract information about symbolic chords data. A similar problem to ours was attacked in <ref type="bibr" target="#b13">[14]</ref>, where the authors also focused on harmonic features for genre classification. However, only three musical genres were considered, while the role of chords in the classification was given only by its symbolic form, making it overly simplistic and leaving room for a better representation of the chords structures. Furthermore, in all of the mentioned, researchers did not focus neither on the manual extraction and consequent interpretation of the features or on extending the method used for the obtention of the data, which are the premises of our approach.</p><p>It is also important to notice that, until recent times, studies about popular music in Brazil were conducted typically by folklorists and musicians who worked mainly with classic Brazilian genres, such as Samba and Bossa Nova ( <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref> and <ref type="bibr" target="#b16">[17]</ref>). Music research was more focused on tradition and ethnic matters of Brazilian culture and their authenticity against foreign music. During the last few years, research in Brazilian popular music has become stronger and more inclusive concerning genres, but we still lack references when looking for works within the machine learning context. Recognizing that music information retrieval is an impactive study field <ref type="bibr" target="#b17">[18]</ref>, we see this as an opportunity to bring the two subjects together.</p><p>The main goals of the present work are to extract and engineer harmonically related features from chords data and use it to correctly classify popularly Brazilian music genres, towards establishing a connection between harmonic relationships and music genres. We also emphasize on the generalization of the method for obtaining the data, allowing for the replication and direct extension of this work. The following section describes how the data was obtained and analyzed, being complemented in Section 3 by the methods for the music genre modeling. We present the results regarding the construction of the variables, exploratory analysis and machine learning models applied in Section 4. Conclusions are in Section 5, containing a summary of the results, future work and final remarks about the project.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">MATERIALS</head><p>A musical chord is a grouping of three or more notes played simultaneously <ref type="bibr" target="#b18">[19]</ref>. There is usually a third interval between each note. When the chord is composed of three notes we have a triad, and when it has four notes, a tetrad. Triads are formed by a fundamental note, a third and a fifth note, being that a tetrad is different because it is added by a seventh note. These simple structures can be altered in many different ways, either by changing the current, removing or adding notes. Other nomenclatures rise depending on the change made, namely major, minor, augmented and diminished chords.</p><p>The same chords can have different tonal functions, which are determined by their positions (or degrees) in the underlying music scale of a song. For example, the C major chord is the first degree in the C scale, characterizing it as the tonic chord, the one that gives the human ear a sensation of closure. On the other hand, the C major chord has a totally different function when played within the F scale, where it assumes the dominant role and carries a tension feel.</p><p>Chords progressions are a sequence of chords that happen in a particular form. Some chords progressions have familiar patterns and it is well known in harmony theory that the occurrence of a chord is correlated to the previous one for a reason <ref type="bibr" target="#b18">[19]</ref>. The most common case of this dependence is when a tension chord happens and it is followed by a resolution chord, giving the human ear a feeling of satisfaction after the tense moment. Even with the existence of patterns, those structures can actually be very diverse, inducing a wide range of sensations <ref type="bibr" target="#b19">[20]</ref>. The way how a progression of chords is organized defines how the harmonics of a song is structured and different genres explore it in their own way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data Extraction</head><p>The data was extracted through webscraping techniques <ref type="bibr" target="#b20">[21]</ref>, from the Cifraclub website (https://www.cifraclub.com.br/), an online collaborative Brazilian page of music-sharing. The website has a big collection of music chords for different instruments, and it is colaborative in the sense that most of the chords information present there are contributions of the users, what confers to the extracted data a natural high variability.</p><p>In total, nine music genres were used: Reggae, Pop, Forró, Bossa Nova, Sertanejo, MPB, Rock and Samba, chosen for being considered good representatives of the Brazilian music, since they are constantly present in the dynamic 'Top Brasil' Spotify playlist <ref type="bibr" target="#b21">[22]</ref>. Also, all of the nine genres appear on the main page of the Cifraclub website, where the most popular genres are. Other famous genres, as the Brazilian Funk and electronic music were, not evaluated as they can be better described by their percussion characteristics instead of the harmonics. From the selected genres, 106 different artists were available (solo singers or bands) on the Cifraclub platform.</p><p>Our extraction method consists of the access of the source code of each song for all the artists and, from the underlying html structures of the web pages, the collection of chords, keys, name of the artist and the name of the songs. Complementary variables about the release year and popularity were obtained with the aid of the Spotify API. We finished with a dataset of almost 484.000 rows related to 106 artists and 8339 different songs from the 9 Brazilian music genres.</p><p>To amplify the coverage of this work, the data extraction process resulted in the chorrrds package <ref type="bibr" target="#b22">[23]</ref>, for the statistical software R <ref type="bibr" target="#b23">[24]</ref>. The package is available for download and use from CRAN 1 , the official repository of R packages. We point out that the creation of the package is especially beneficial for the reproducibility purposes of this analysis, and for ensuring that the method can be generalized and even extended.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Feature Engineering</head><p>One important step of modeling is feature engineering <ref type="bibr" target="#b24">[25]</ref>, that can directly influence the effectiveness of a statistical model. Feature engineering techniques are used when transformations of variables into features that represent the adjacent problem in a better way are needed <ref type="bibr" target="#b25">[26]</ref>, which depends on the context of the problem. The usefulness of the method for this work is explicit once the symbolic representation of chords progressions do not capture all of the possible useful information.</p><p>If we account for the chords in their simplest form, ignoring the possible alterations, it is noticeable that the same chord progressions inevitably turn up in some music genres, for example. Out of that, we consider that using only the raw information about the chords progression may cause a lot of information to be lost in the process. The details, such as if the chord was changed in some way or how prevalent they are in a song, should be taken into consideration. We emphasized on obtaining various distinct features from the chords, being able to make use of more information than only their symbolic form.</p><p>Feature engineering is typically automatic <ref type="bibr" target="#b25">[26]</ref>, meaning that the model learns the features without much human intervention. These features are hard to interpret or the interpretation is out of the scope of the research. Here, an opposite approach was employed, We chose to employ a hand-engineering approach to the variables, as we are interested in obtaining features that are interpretable in accordance to the posed problem. The resulting features will not only help with the modeling problem, but also have a clear interpretation of harmonic characteristics of the considered songs. In <ref type="table" target="#tab_0">Table 1</ref>, a small demonstration of how the features were constructed is presented. The technique allowed us to have a dataset composed of 23 variables related to the songs, detailed in the next section of this paper. These features were divided into four thematic groups: triads (6), tetrads (6), common transitions (3) and miscellany <ref type="bibr" target="#b7">(8)</ref>. As the objective is not to model the songs but the music genres in which they are classified, the features went through a summarizing process. For example, consider the second column of <ref type="table" target="#tab_0">Table 1</ref>. This column shows an indicator variable of the current chord being major or not. For each song, this column was turned into the percentage of major chords. The same was adequate for the last two columns of the example table. In this fashion, we summarized our extracted variables, ending up with one row of information per song.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MUSIC GENRE MODELING</head><p>In this section, we discuss how the variables were extracted and the method used for the music genre modeling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Extracted and Engineered Variables</head><p>As mentioned before, one of our main concerns is that the new features can be interpretable. The engineered variables were separated into four thematic groups, organized as follows:</p><p>• First group -Triads and simple tetrads: C/E, C/G, C/Bb). 6. Mean distance of the chords to the 'C' chord in the circle of fifths. 7. Mean distance of the chords to the 'C' chord in semitones. 8. Absolute quantity of the most common chord.</p><p>The first group contains information about small changes that can be done in the fundamental state of a chord. It captures when the song is the result of slight alterations in the chords. The second comprises more unusual extensions, commonly made by experienced musicians. By forming these groups of variables we can expect that if differences in harmonic structures between genres are really relevant, those characteristics would be pertinent to the harmonic characterization of the genres.</p><p>The set of transition variables is also organized with the intention of capturing the refinement of harmonic structures. For example, simplistic pieces tend to have a lesser variety of chords, but this does not mean that the songs last less time. This implies that the same group of chords and their transitions will be repeated many times for the whole duration of the song. In consequence, the top most common transitions would have high percentages, since there are not numerous different transitions happening in the song. A new dimension of complexity of the songs is mapped in this group of features.</p><p>The last group is a complete miscellany. It mixes very dissimilar predictors, possibly with distinct interpretations to the genres. We still have some features that concern the harmonic structures, in case they were not captured before, including the total of chords, the percentage of chords with varying bass and mean distances of the chord to the circle of fifths and by semitones. To explain a little, the first variable contains the information about the duration of the song, while the varying bass is also indicative of a more complex piece.</p><p>Besides that, in music theory relationships between chords can be measured with the circle of fifths <ref type="bibr" target="#b26">[27]</ref>. To contextualize, this a circle that represents music chords, each one being a fifth apart from its neighbor. Usually, the neighbors appear together in a song, as their distance in a circle of fifths works as an indicator of their harmonic functions. For example, when the C chord is been played, it is very likely to be followed by the G, which is its adjacent neighbor in the circle of fifths <ref type="bibr" target="#b27">[28]</ref>. We made use of this meaningful representation to obtain the distance features from our data. By calculating the mean distances in the circle of fifths for each song, we can estimate how the variations of chords happen in the selected songs. We already know from <ref type="bibr" target="#b28">[29]</ref> that some pieces do not have highly varying progressions, while others experiment with particular combinations. As for the last features, the year has the temporal dimension and popularity is composed of the public opinion about the songs, which is as external element. These two last features were extracted from the Spotify API.</p><p>Starting only with the symbolic representation of the chords, we gathered a broad set of information about the considered pieces. A fundamental characteristic of this data is the interpretation behind each feature. Since one of our goals is to better understand how genres are related to musical harmony in general, the interpretation is a primary element of this work. The variables were complemented with selected features extracted from the Spotify API that carry important details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Trees and Random Forests</head><p>First, consider a variable of interest Y i ∈ R and x = (x i1 , . . . , x ip ) the set of predictor features, 1 ≤ i ≤ p. A statistical framework for non-parametric regression characterizes their relationship as</p><formula xml:id="formula_0">y i = f 0 (x i ) + i , i iid ∼ N (0, σ 2 ),<label>(1)</label></formula><p>where f 0 is an unknown regression function. A regression tree is a completely non-parametric model, described graphically by a tree, that can be used to reconstruct f 0 by mapping the predictors into a set of decisions at each step. On the literature, trees are applied in decision problems where there is no stochastic assumption made, but instead, there is interest in finding rules that would lead to the right predictions <ref type="bibr" target="#b29">[30]</ref>. Each rule has the form: x j &gt; x j,th , where x j describes the value of the feature at j and x j,th is the decision cut point <ref type="bibr" target="#b30">[31]</ref>. For the purpose of explaining how the trees work, consider a classification task for a factor target variable. In our case, this factor variable is the music genres. At the start, the full training dataset is all in just one node of the tree. In each step of the algorithm, a binary partition is made in the covariables space, meaning that a split results in two children that separate better the target variable in its classes. The usual criteria to choose the best threshold for a new node is the Gini impurity <ref type="bibr" target="#b31">[32]</ref>, measured by</p><formula xml:id="formula_1">Gini = 1 − r c=1 p 2 c ,<label>(2)</label></formula><p>where p c is the observed proportion for each class c = 1, ..r. in the dataset. This measure has its minimum when the individuals belong to the same class. Thereby, partitions are made in order to minimize the difference between  the impurity, or heterogeneity, of the current state of the model and the next step with the candidate new node. This difference is written as</p><formula xml:id="formula_2">∆Imp = Imp O − n 1 n O Imp 1 + n 2 n O Imp 2 ,<label>(3)</label></formula><p>where 1 e 2 are the candidate divisions, starting at region O. Consequently, the algorithm looks for the splitting cut point that leads to the minimal combined impurity of the groups.</p><p>There exist a few advantages of the use of trees. Non-linear decision regions between the covariables are better captured by this algorithm than with usual regression models. Consider <ref type="figure" target="#fig_0">Figure 1</ref> as an example: a linear model would not be able to reproduce the relationship between the two variables very well. As we see in <ref type="figure" target="#fig_1">Figure 2</ref>, a tree model with the decision rules configured as the gray lines displayed, on the other hand, would satisfactorily separate the observations in the two existing classes.</p><p>The performance of the tree algorithm needs to be evaluated regarding its prediction power. A test set is generally used to produce the predictions for never seen data. The comparison is performed between what was observed for the test set and what the tree model predicts. The closer the predictions are to the vector of observations, the better the algorithm is doing, and an accuracy measure is calculated as</p><formula xml:id="formula_3">Acc = 1 n n i=1 I(y i =ŷ i )<label>(4)</label></formula><p>where I is the indicator for whether the model predictionŷ i is compatible with what was observed and n is the sample size <ref type="bibr" target="#b31">[32]</ref>.</p><p>Once we defined decision trees, we can extend the definition to the random forest algorithm. A random forest is an ensemble learning algorithm introduced by Breiman <ref type="bibr" target="#b32">[33]</ref>, that works by constructing a large number B of trees and combining their results <ref type="bibr" target="#b31">[32]</ref>. For each tree, a bootstrapped dataset <ref type="bibr" target="#b33">[34]</ref> and only a set of m predictors, from the p total, are considered. Typically, the variables are selected randomly for each step of the algorithm and m is chosen as approximately √ p <ref type="bibr" target="#b31">[32]</ref>.</p><p>Since the correlation between the trees can be an issue, selecting just a few variables for each step is useful to overcome this problem <ref type="bibr" target="#b34">[35]</ref>. If the trees are allowed to consider different variables at each time, strong predictors will not dominate the algorithm, as sometimes they will not be even available for the split. Using this criterion, the results produced by the uncorrelated trees are more reliable <ref type="bibr" target="#b31">[32]</ref>. The final prediction for the random forest classification algorithm is the majority vote of the B trees or, in other words, the classification proposed by most of the trees is the one that will be taken as the prediction of the final model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Genre Modeling</head><p>The nine music genres present in our dataset were modeled with a random forest algorithm. Our target variable is the music genres, while the predictors are the extracted and engineered features. In total, four models were fitted, in a nested fashion, structured as 1. First model: triads <ref type="formula">(6)</ref> 2. Second model: triads (6) + tetrads <ref type="formula">(6)</ref> 3. Third model: triads (6) + tetrads (6) + common transitions <ref type="formula" target="#formula_2">(3)</ref> 4. Fourth model: triads (6) + tetrads (6) + common transitions (3) + miscellany <ref type="bibr" target="#b7">(8)</ref>.</p><p>Our first model accounted for the first six variables, related to the triad features of the chords. The following model was added the tetrads variables and the third model was built using also the common transitions variables. Lastly, the fourth model also considered the miscellany variables, adding up to 23 predictors. In this way, we could compare the predictions for all the different four models. The interest relied on assess the information brought by each thematic group of predictors.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS</head><p>In this section, we present a summary of the exploratory analysis along with the results of the fitted models. The discussion is shown in the following section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Exploratory Analysis</head><p>Non-linearity between predictor variables is not an assumption of the random forest model, but rather a problem that the algorithm can overcome. Nevertheless, <ref type="figure" target="#fig_2">Figures 3, 4</ref> and 5 illustrate the the relationship between some variables of the first group. It is clear that the relationships between the variables follow a diversity of patterns between the music genres. With the plots, we can notice that the patterns would be poorly described if a linear function was considered for this task, as there is evidence of non-linear relationships in our dataset.</p><p>In addition to that, it has become common sense to say that some music genres are harmonically simpler than others <ref type="bibr" target="#b18">[19]</ref>. We established as a diversity measure the mean of the count of distinct chords, obtained per song for each genre.  <ref type="figure">Figure 6</ref> shows how this mean behaves and has changed over the years for the genres (1957 to 2018). Clearly, genres known as traditionally Brazilian, like Samba, MPB, and Bossa Nova, have higher values of the mean count of distinct chords. These genres also have a higher variation over time, which is in agreement with popular knowledge <ref type="bibr" target="#b0">[1]</ref>. Bossa Nova is the most unstable one, having different values along the years with an increasing trend, followed by Samba, that also looks to have been going through similar changes. Sertanejo is the one that has the most evident decrease, having a peak around 2000 and decay since that. The remaining genres are more harmonically uniform and stable through time. We also observe that data is not available for all of the years and genres, once some genres just appeared in Brazil in recent years <ref type="bibr" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Random Forests Models</head><p>The random forest model was chosen as the classification algorithm for the music genres. All of the final variables were used in the modeling. Our choice for this algorithm is justified by three main points:</p><p>• it easily allows the obtention of an importance measure of the predictors,</p><p>• there is no need to normalize or transform the variables, once the trees are invariant to the predictor's scale,</p><p>• accommodation of non-linear relationships between the predictors and the response, which are overcome by the model.</p><p>The full dataset was randomly partitioned in train (70%) and test (30%) set, with balancing by music genre. The train set was used for the training of the model, while the test set serves for the calculation of performance measures in data not seen by the trained model. <ref type="table" target="#tab_2">Table 2</ref> presents the structure of the two datasets and the measures of goodness of fit of the four models are in <ref type="table" target="#tab_3">Table 3</ref> Figure 6: Mean count of distinct chords in the songs for each year, by music genre. The white curve represents a local regression non-parametric smoother to highlight the trend of the observations. The Kappa statistic shown in <ref type="table" target="#tab_3">Table 3</ref> is a metric of comparison between the observed accuracy and the expected accuracy. Also known as Non Information Rate, or N.I.R, the expected accuracy is the proportion of the most recurrent genre in the dataset, that in this case is 34%. The statistic is used to decide whether the classification proposed by the model is more accurate than saying that all observations belong to the most recurrent genre of the dataset <ref type="bibr" target="#b35">[36]</ref>. The formula for the Kappa statistic is given as</p><formula xml:id="formula_4">kappa = p 0 − p e 1 − p e ,<label>(5)</label></formula><p>where p 0 is the observed accuracy and p e is the expected accuracy, and the Kappa statistics follows an approximate Normal distribution asymptotically <ref type="bibr" target="#b35">[36]</ref>, which makes it easily testable. In the last column of <ref type="table" target="#tab_3">Table 3</ref>, the p-values indicate whether the accuracy of the models is significantly higher than the N.I.R. We observe that, for all different models, there are evidence of their accuracy being significantly higher than using a naive classification in the most common genre, or the non-information rate of the data.</p><p>From <ref type="table" target="#tab_3">Table 3</ref>, we can also conclude that the addition of new predictors sets progressively increased the accuracy of the models. We need to remember that, in random forests models, the accuracy does not behave as the R 2 , used in the evaluation of linear models <ref type="bibr" target="#b36">[37]</ref>. The R 2 invariably increases if we add more variables to the model, once this measure it's not penalized by the total number of parameters (in the case of a parametric model). The random forest accuracy, on the other hand, can be negatively affected by the inclusion of non-informative features that introduce noise, making the distinction between the classes a harder task <ref type="bibr" target="#b31">[32]</ref>. Because of this property, it is safe to say that the variables added to the model are in fact making the prediction capacity higher.</p><p>The increase in the general accuracy is seemingly uniform: to each new set of variables added, the increase is in about 3%. The fourth model, will all the features, has a prediction capacity of around 62%, almost twice as the N.I.R.. We conclude that genres of the songs present in our dataset can be well predicted by looking at their harmonic features as we extracted here. We can also analyze the confusion matrices, that serve to show a detailed report about how the classes of the factor variable are being classified <ref type="bibr" target="#b31">[32]</ref>. If the classes are being mistaken by a specific one, for example, this is the  From <ref type="table" target="#tab_4">Table 4</ref> to <ref type="table" target="#tab_5">Table 5</ref>, there is a considerable increase on the correct classification rate, especially for Bossa Nova (about 15%), MPB (about 8%) and Samba (about 6%). This means that with the addition of the variables about the tetrads, the most popular genres of Brazilian music are more easily identified by the model. In <ref type="table" target="#tab_6">Table 6</ref>, the increase occurs to MPB (about 6%), Samba and Sertanejo (about 2% for both), but it's more intense for Reggae (4%). On the previous models, this genre was being completely missed, but with the information about the common chords transitions, at least some percentage of it is being distinguished, which is considered a significative information gain. Lastly, on <ref type="table" target="#tab_7">Table 7</ref>, the increase was specially high for Rock (about 8%), followed MPB and Reggae (about 4% for both) and Sertanejo (about 3% of increase). With that, we verify that the fourth set of variables, the miscellany that includes the popularity, year of the song and distances to the 'C' chord is notably relevant in the classification of those genres, with emphasis on Rock.</p><p>At last, we consider the specific importance of the features. An importance plot is used to show the measures of how relevant to the model the features are, by demonstrating the decrease in the Gini criteria attributed to the splits in each variable <ref type="bibr" target="#b31">[32]</ref>. Therefore it is easy to perceive the prediction strength of our variables, being that the strongest ones will appear in the top of the plot. Given this and the plot being shown in <ref type="figure" target="#fig_5">Figure 7</ref>, we notice that the first model has three main variables used in the correct classification: the percentage of chords with the seventh,  the percentage of minor chords with the seventh. After the addition of the second set of variables, the same variables have remained on top <ref type="figure" target="#fig_6">(Figure 8</ref>). By that, we can infer that these three variables have higher discriminant power so far, unlike the second set of variables. The third set of variables, for which the addition is reported on <ref type="figure" target="#fig_7">Figure 9</ref>, have some strong variables, which are taking place of the old ones when added to the model. This aspect shows that the features of the third set carry a notorious amount of information about the response variables, our music genres. Finally, from the importance plot of the model with all of the variables, shown in <ref type="figure" target="#fig_0">Figure 10</ref>, we conclude that the most relevant one out of the miscellany set is the year of release of the song, followed by the popularity and the total number of chords in each song. Those features took the place of the ones that were introduced previously, which highlights how informative they are.</p><p>In summary, the first set of variables is the most informative one. By using features related to the triads and simple tetrads, the first features set makes it possible for us to separate the nine Brazilain genres, especially for the traditional ones <ref type="table" target="#tab_4">(Table 4</ref>). This means that with the basic information about the songs we already obtained good results. The results improved mostly by the addition of external variables, such as the year and popularity of each song, showing how the features from the streaming software Spotify carry relevant information about the boundaries of the evaluated genres. Next, in the importance sequence, we have the transitions and distances variables, strengthening the idea  of harmonic characteristics being important to discriminate music genre and also clearing the path about what should be the further steps on the improvement of the analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSIONS AND DISCUSSION</head><p>With our results, we can conclude that is possible to predict music genres of the Brazilian popular music combining features extracted from their harmonic structures and external variables. The overall accuracy of the final model is 62% with a confidence interval of [60%, 64%], being that the better-classified genres are the Brazilian Sertanejo, Samba, MPB (also known as Brazilian Popular Music) and Rock. The most discriminative variables for the model are the percentage of chords with the seventh note, percentage of minor chords with the seventh note, the percentage of minor chords, the year of release of the songs, their popularity, the behavior of the most common chord transitions, the mean distances of the chords having the 'C' chord in the circle of fifth as a reference and the total number of chords in each song. On this group, prevail the features that can be extracted purely with the symbolic part of the chords. The features obtained with the aid of the Spotify API are also very influent, what makes sense once they came from a very influent music streaming software and its data is reliable <ref type="bibr" target="#b21">[22]</ref>. This accentuates how having access to data via the Spotify API is useful and pertinent to research in general.</p><p>We emphasize that method for the obtention of the data is implemented in the chorrrds package for R <ref type="bibr" target="#b22">[23]</ref>. If data for different artists is required, the package would be the best the option for that task. Moreover, every step of this analysis can be reproduced using the code available at:</p><p>https://github.com/brunaw/genre_classification It is very important for the authors that not only this work is entirely reproducible, but can also be easily extended.</p><p>Next steps of this work include specially the engineering of the new variables and applying different algorithms to model the data. The modeling section can be improved in two fundamental ways: changing the algorithm itself for another suitable technique and improving the existent model. Options of possible new modeling techniques would be deep learning models <ref type="bibr" target="#b38">[38]</ref> and naive Bayes models <ref type="bibr" target="#b39">[39]</ref>. References about similar approaches using deep learning can be found in <ref type="bibr" target="#b40">[40]</ref> and <ref type="bibr" target="#b41">[41]</ref>.</p><p>As for changing the existing model, alternatives are removing non-informative variables and creating new ones. Using the importance criterion, we have a very good direction about which variables should be reconsidered to be kept in the model. More sophisticated techniques such as Principal Component Analysis <ref type="bibr" target="#b42">[42]</ref> could also play an important role in the task of reducing the dimension of columns used in the model. Analogously, reducing the amount of observations is considered a potential next step. The idea here is to find the songs that carry most part of the variance for each genre and thereby can be useful to summarize them, allowing us to use less data to obtain similar results. Regardless of that, finding ways of engineering new variables is a key point of interest. As the main goal of this work is focused on showing how Brazilian music genres can be predicted using interpretable engineered features, assessing more information about the songs via the creation of more features is essential.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Two covariables with the target variable groups mapped in the color of the points.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Exemplification of the decision rules that would separate the two groups well.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Percentage of minor chords in the song versus the percentage of suspended chords, identifying the music genre.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Percentage of minor chords in the song versus the percentage of chords with the seventh note, identifying the music genre.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Percentage of minor chords in the song versus the percentage of augmented chords, identifying the music genre.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Importance plot for the model with only the first set of variables.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Importance plot for the second model with the first and second sets of variables.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 :</head><label>9</label><figDesc>Importance plot for third model with the first, second and third sets of variables.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 10 :</head><label>10</label><figDesc>Importance plot for the fourth model with all the considered variables.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Example of how features were manually extracted.</figDesc><table><row><cell cols="4">chord major contain 7th contain 6th</cell></row><row><cell>C</cell><cell>1</cell><cell>0</cell><cell>0</cell></row><row><cell>Gm7</cell><cell>0</cell><cell>1</cell><cell>0</cell></row><row><cell></cell><cell></cell><cell>extracted f eatures</cell><cell></cell></row></table><note>1 https://cran.r-project.org/web/packages/chorrrds/index.html</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Percentage of the first most common chord transition in the song. 2. Percentage of the second most common chord transition in the song.3. Percentage of the third most common chord transition in the song.• Fourth group -Miscellany:1. Popularity of the song, extracted from the Spotify API. 2. Total of non-distinct chords in the song. 3. Year of album release, extracted from the Spotify API. 4. Indicator of the key of the song being the same as the most common chord. 5. Percentage of chords with varying bass (e.g.</figDesc><table><row><cell>g.</cell></row><row><cell>C7).</cell></row><row><cell>3. Percentage of minor chords with the seventh</cell></row><row><cell>(interaction between the minor third and the</cell></row><row><cell>seventh) (e.g. Em7, C#m7).</cell></row><row><cell>4. Percentage of minor chords (e.g. Em, C#m).</cell></row><row><cell>5. Percentage of diminished chords (e.g. B o ).</cell></row><row><cell>6. Percentage of augmented chords (e.g.</cell></row><row><cell>Baug).</cell></row><row><cell>• Second group -Dissonant Tetrads:</cell></row><row><cell>1. Percentage of chords with the fourth (e.g.</cell></row><row><cell>D4).</cell></row><row><cell>2. Percentage of chords with the sixth (e.g.</cell></row><row><cell>E6).</cell></row><row><cell>3. Percentage of chords with the ninth (e.g.</cell></row><row><cell>G9).</cell></row><row><cell>4. Percentage of minor chords with the major</cell></row><row><cell>seventh (e.g. F7+, Am7+).</cell></row><row><cell>5. Percentage of chords with a diminished fifth</cell></row><row><cell>(e.g. C5-or C5b).</cell></row><row><cell>6. Percentage of chords with as augmented fifth</cell></row><row><cell>(e.g. C5+ ou C5#).</cell></row><row><cell>• Third group -Main Chord Transitions:</cell></row><row><cell>1.</cell></row></table><note>1. Percentage of suspended chords (e.g. Gsus). 2. Percentage of chords with the seventh (e.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Amount of songs for each genre, in each partition, and representation (%) of the genre in the full dataset.</figDesc><table><row><cell>Genre</cell><cell>Train</cell><cell>Test</cell><cell>Representativity</cell></row><row><cell cols="2">Bossa Nova 305 (68%)</cell><cell>133 (32%)</cell><cell>438 (5.3%)</cell></row><row><cell>Forró</cell><cell>115 (73%)</cell><cell>48 (27%)</cell><cell>163 (2%)</cell></row><row><cell>MPB</cell><cell cols="3">1196 (67.8%) 476 (32.2%) 1679 (20.3%)</cell></row><row><cell>Pop</cell><cell>104 (66.4%)</cell><cell>39 (33.6%)</cell><cell>143 (1.7%)</cell></row><row><cell>Reggae</cell><cell>46 (68.1%)</cell><cell>24 (31.9%)</cell><cell>70 (0.8%)</cell></row><row><cell>Rock</cell><cell cols="3">1127 (69.8%) 552 (30.2%) 1679 (20.4%)</cell></row><row><cell>Samba</cell><cell>877 (70.8%)</cell><cell cols="2">378 (29.2%) 1255 (15.1%)</cell></row><row><cell>Sertanejo</cell><cell cols="3">1992 (68.2%) 849 (31.8%) 2841 (34.4%)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Goodness of fit for the four models: overall accuracy with lower and upper bounds and Kappa statistic with the respective p-value.</figDesc><table><row><cell>Model</cell><cell cols="3">Accuracy L.B. U.B. Kappa P-Value</cell></row><row><cell cols="2">Model 1 0.53</cell><cell>0.51 0.55 0.37</cell><cell>&lt; 0.0001</cell></row><row><cell cols="2">Model 2 0.57</cell><cell>0.54 0.59 0.42</cell><cell>&lt; 0.0001</cell></row><row><cell cols="2">Model 3 0.59</cell><cell>0.56 0.60 0.44</cell><cell>&lt; 0.0001</cell></row><row><cell cols="2">Model 4 0.62</cell><cell>0.60 0.64 0.49</cell><cell>&lt; 0.0001</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Confusion matrix for the model with only the first set of variables.</figDesc><table><row><cell></cell><cell cols="2">B. Nova Forró MPB Pop Reggae Rock Samba Sert.</cell></row><row><cell>B. Nova</cell><cell>0.14 0.00 0.33 0.00</cell><cell>0.00 0.05 0.33 0.15</cell></row><row><cell>Forró</cell><cell>0.00 0.00 0.10 0.00</cell><cell>0.00 0.15 0.12 0.62</cell></row><row><cell>MPB</cell><cell>0.03 0.00 0.41 0.00</cell><cell>0.00 0.14 0.23 0.20</cell></row><row><cell>Pop</cell><cell>0.00 0.00 0.15 0.00</cell><cell>0.00 0.26 0.23 0.36</cell></row><row><cell>Reggae</cell><cell>0.00 0.00 0.25 0.00</cell><cell>0.00 0.50 0.04 0.21</cell></row><row><cell>Rock</cell><cell>0.01 0.00 0.11 0.00</cell><cell>0.00 0.34 0.07 0.47</cell></row><row><cell>Samba</cell><cell>0.02 0.00 0.26 0.00</cell><cell>0.00 0.05 0.57 0.11</cell></row><row><cell>Sert.</cell><cell>0.00 0.00 0.02 0.00</cell><cell>0.00 0.12 0.02 0.84</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Confusion matrix for the second model with the first and second sets of variables.</figDesc><table><row><cell></cell><cell cols="2">B. Nova Forró MPB Pop Reggae Rock Samba Sert.</cell></row><row><cell>B. Nova</cell><cell>0.29 0.00 0.35 0.00</cell><cell>0.00 0.05 0.19 0.14</cell></row><row><cell>Forró</cell><cell>0.00 0.00 0.10 0.00</cell><cell>0.00 0.15 0.12 0.62</cell></row><row><cell>MPB</cell><cell>0.03 0.00 0.49 0.00</cell><cell>0.00 0.13 0.17 0.18</cell></row><row><cell>Pop</cell><cell>0.00 0.00 0.15 0.00</cell><cell>0.00 0.31 0.18 0.36</cell></row><row><cell>Reggae</cell><cell>0.00 0.00 0.17 0.00</cell><cell>0.00 0.50 0.12 0.21</cell></row><row><cell>Rock</cell><cell>0.00 0.00 0.13 0.00</cell><cell>0.00 0.36 0.06 0.44</cell></row><row><cell>Samba</cell><cell>0.02 0.00 0.20 0.00</cell><cell>0.00 0.04 0.63 0.10</cell></row><row><cell>Sert.</cell><cell>0.00 0.00 0.02 0.00</cell><cell>0.00 0.12 0.02 0.84</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Confusion matrix for third model with the first, second and third sets of variables.</figDesc><table><row><cell></cell><cell cols="2">B. Nova Forró MPB Pop Reggae Rock Samba Sert.</cell></row><row><cell>B. Nova</cell><cell>0.29 0.00 0.35 0.00</cell><cell>0.00 0.05 0.17 0.13</cell></row><row><cell>Forró</cell><cell>0.00 0.00 0.06 0.00</cell><cell>0.00 0.21 0.08 0.65</cell></row><row><cell>MPB</cell><cell>0.03 0.00 0.55 0.00</cell><cell>0.00 0.12 0.15 0.15</cell></row><row><cell>Pop</cell><cell>0.00 0.00 0.23 0.00</cell><cell>0.00 0.13 0.21 0.44</cell></row><row><cell>Reggae</cell><cell>0.00 0.00 0.38 0.00</cell><cell>0.04 0.46 0.04 0.08</cell></row><row><cell>Rock</cell><cell>0.00 0.00 0.14 0.00</cell><cell>0.00 0.35 0.06 0.45</cell></row><row><cell>Samba</cell><cell>0.02 0.00 0.21 0.00</cell><cell>0.00 0.03 0.66 0.08</cell></row><row><cell>Sert.</cell><cell>0.00 0.00 0.02 0.00</cell><cell>0.00 0.09 0.02 0.86</cell></row><row><cell cols="3">proper method to access this behavior. For each of the four</cell></row><row><cell cols="3">models, we show the confusions matrices in Tables 4, 5, 6</cell></row><row><cell>and 7.</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 :</head><label>7</label><figDesc>Confusion matrix for the fourth model with all the considered variables. B. Nova Forró MPB Pop Reggae Rock Samba Sert.</figDesc><table><row><cell>B. Nova</cell><cell>0.28 0.00 0.40 0.00</cell><cell>0.00 0.05 0.16 0.12</cell></row><row><cell>Forró</cell><cell>0.00 0.00 0.12 0.00</cell><cell>0.00 0.12 0.10 0.65</cell></row><row><cell>MPB</cell><cell>0.01 0.00 0.59 0.00</cell><cell>0.00 0.11 0.13 0.15</cell></row><row><cell>Pop</cell><cell>0.00 0.00 0.13 0.00</cell><cell>0.00 0.28 0.15 0.44</cell></row><row><cell>Reggae</cell><cell>0.00 0.00 0.25 0.00</cell><cell>0.08 0.46 0.08 0.12</cell></row><row><cell>Rock</cell><cell>0.00 0.00 0.16 0.00</cell><cell>0.00 0.43 0.05 0.35</cell></row><row><cell>Samba</cell><cell>0.01 0.00 0.20 0.00</cell><cell>0.00 0.03 0.66 0.10</cell></row><row><cell>Sert.</cell><cell>0.00 0.00 0.02 0.00</cell><cell>0.00 0.07 0.02 0.89</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Iniciação à Música Popular Brasileira</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waldenyr</forename><surname>Caldas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Classification as culture: Types and trajectories of music genres</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><forename type="middle">C</forename><surname>Lena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">A</forename><surname>Peterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Sociological Review</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Survey of music information needs, uses, and seeking behaviours: preliminary findings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Ha Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stephen Downie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Automatic chord recognition for music classification and retrieval</title>
	</analytic>
	<monogr>
		<title level="m">2008 IEEE International Conference on Multimedia and Expo, ICME 2008 -Proceedings</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">A survey on symbolic data-based music genre classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Débora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><forename type="middle">Ap</forename><surname>Corrêa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rodrigues</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">O livro de ouro da MPB: a história de nossa música popular de sua origem até hoje. Livros de ouro</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Albin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Music Information Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Ashley Burgoyne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ichiro</forename><surname>Fujinaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stephen Downie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">A New Companion to Digital Humanities</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Improvements of Audio-Based music similarity and genre classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elias</forename><surname>Pampalk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Flexer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Widmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISMIR</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Musical genre classification of audio signals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Tzanetakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Perry</forename><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Speech and Audio Processing</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Music Genre Classification using Machine Learning Techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hareesh</forename><surname>Bahuleyan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Automatic genre classification of music content</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Scaringella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgio</forename><surname>Zoia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Mlynek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The personality of music genres</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Neuman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Perlovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yochai</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danny</forename><surname>Livshits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychology of Music</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">From Context to Concept: Exploring Semantic Relationships in Music with Word2Vec</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kat</forename><surname>Ching-Hua Chuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dorien</forename><surname>Agres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Herremans</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Genre classification of music by tonal harmony</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Pérez-Sancho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Rizo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">José</forename><forename type="middle">M</forename><surname>Iesta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><forename type="middle">J</forename><surname>Ponce De León</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Kersten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafael</forename><surname>Ramirez</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note>Intelligent Data Analysis</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">The mystery of samba : popular music &amp; national identity in Brazil</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Brazilian Musical Values of the 1960s and 1970s: Popular Urban Music from Bossa Nova to Tropicalia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Béhague</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Popular Culture</title>
		<imprint>
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Blues and Samba: Another Side of Bossa Nova History. Luso-Brazilian Review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Mccann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Information retrieval for music and motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meinard</forename><surname>Müller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Almada</surname></persName>
		</author>
		<title level="m">Harmonia Funcional</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">The Cognition of Basic Musical Structures. Music Perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Rowe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Automated Data Collection with R -A Practical Guide to Web Scraping and Text Mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><forename type="middle">M</forename><surname>Iacus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vinicius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Schettino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">José</forename><surname>Braga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Maria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Antônio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Araújo</surname></persName>
		</author>
		<title level="m">Proceedings of the 11th Brazilian Symposium on Software Components, Architectures, and Reuse -SBCARS &apos;17</title>
		<meeting>the 11th Brazilian Symposium on Software Components, Architectures, and Reuse -SBCARS &apos;17</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">The chorrrds package for extraction of music chords data in r</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruna</forename><surname>Wundervald</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>R Core Team</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<pubPlace>Vienna, Austria</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Feature Engineering and Selection: A Practical Approach for Predictive Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kuhn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Johnson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning feature engineering for classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fatemeh</forename><surname>Nargesian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horst</forename><surname>Samulowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Udayan</forename><surname>Khurana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Elias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><surname>Khalil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Turaga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 26th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2529" to="2535" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A formal theory of generalized tonal functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lewin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Music Theory</title>
		<imprint>
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Toward a Formal Theory of Tonal Music</title>
	</analytic>
	<monogr>
		<title level="j">Journal of Music Theory</title>
		<imprint>
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Analysis of chord progression data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Brandt Absolu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitsunori</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ogihara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Studies in Computational Intelligence</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Extending the Linear Model with R: Generalized Linear, Mixed Effects and Nonparametric Regression Models. Chapman &amp; Hall/CRC Texts in Statistical Science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J J</forename><surname>Faraway</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CRC Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">What are decision trees?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Kingsford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Salzberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Biotechnology</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerome</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Trevor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Friedman</forename><surname>Robert</surname></persName>
		</author>
		<title level="m">The Elements of Statistical Learning</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note>Second Edition</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leo</forename><surname>Breiman</surname></persName>
		</author>
		<title level="m">Random forests. Machine Learning</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Bootstrap Methods: Another Look at the Jackknife. The Annals of Statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Efron</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A study of strength and correlation in random forests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Bernard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Heutte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sébastien</forename><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Communications in Computer and Information Science</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A Coefficient of Agreement for Nominal Scales</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Educational and Psychological Measurement</title>
		<imprint>
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Robert</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">1908</biblScope>
			<pubPlace>Robert George Douglas</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Principles and procedures of statistics : with special reference to the biological sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">H</forename><surname>Torrie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1960" />
			<publisher>McGraw-Hill</publisher>
			<pubPlace>James Hiram; New York</pubPlace>
		</imprint>
	</monogr>
	<note>Includes bibliographical references</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kevin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Naive Bayes classifiers. Bernoulli</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Music genre classification using machine learning techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hareesh</forename><surname>Bahuleyan</surname></persName>
		</author>
		<idno>abs/1804.01149</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Multi-label music genre classification from audio, text, and images using deep features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>Oramas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Nieto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Barbieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Serra</surname></persName>
		</author>
		<idno>abs/1707.04916</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Principal Component Analysis. Second Edition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I T Jolliffe</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
