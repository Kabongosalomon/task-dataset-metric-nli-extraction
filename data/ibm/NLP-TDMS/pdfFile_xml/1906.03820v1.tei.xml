<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Open-Domain Targeted Sentiment Analysis via Span-Based Extraction and Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghao</forename><surname>Hu</surname></persName>
							<email>huminghao09@nudt.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">National University of Defense Technology</orgName>
								<address>
									<settlement>Changsha</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxing</forename><surname>Peng</surname></persName>
							<email>pengyuxing@nudt.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">National University of Defense Technology</orgName>
								<address>
									<settlement>Changsha</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Huang</surname></persName>
							<email>huangzhen@nudt.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">National University of Defense Technology</orgName>
								<address>
									<settlement>Changsha</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongsheng</forename><surname>Li</surname></persName>
							<email>dsli@nudt.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">National University of Defense Technology</orgName>
								<address>
									<settlement>Changsha</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">†</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiwei</forename><surname>Lv</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Macau</orgName>
								<address>
									<settlement>Macau</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Open-Domain Targeted Sentiment Analysis via Span-Based Extraction and Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T06:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Open-domain targeted sentiment analysis aims to detect opinion targets along with their sentiment polarities from a sentence. Prior work typically formulates this task as a sequence tagging problem. However, such formulation suffers from problems such as huge search space and sentiment inconsistency. To address these problems, we propose a span-based extract-then-classify framework, where multiple opinion targets are directly extracted from the sentence under the supervision of target span boundaries, and corresponding polarities are then classified using their span representations. We further investigate three approaches under this framework, namely the pipeline, joint, and collapsed models. Experiments on three benchmark datasets show that our approach consistently outperforms the sequence tagging baseline. Moreover, we find that the pipeline model achieves the best performance compared with the other two models.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Open-domain targeted sentiment analysis is a fundamental task in opinion mining and sentiment analysis <ref type="bibr" target="#b28">(Pang et al., 2008;</ref><ref type="bibr" target="#b25">Liu, 2012)</ref>. Compared to traditional sentence-level sentiment analysis tasks <ref type="bibr" target="#b24">(Lin and He, 2009;</ref><ref type="bibr" target="#b17">Kim, 2014)</ref>, the task requires detecting target entities mentioned in the sentence along with their sentiment polarities, thus being more challenging. Taking <ref type="figure" target="#fig_1">Figure 1</ref> as an example, the goal is to first identify "Windows 7" and "Vista" as opinion targets and then predict their corresponding sentiment classes.  Typically, the whole task can be decoupled into two subtasks. Since opinion targets are not given, we need to first detect the targets from the input text. This subtask, which is usually denoted as target extraction, can be solved by sequence tagging methods <ref type="bibr" target="#b15">(Jakob and Gurevych, 2010;</ref><ref type="bibr" target="#b26">Liu et al., 2015;</ref><ref type="bibr" target="#b41">Wang et al., 2016a;</ref><ref type="bibr" target="#b32">Poria et al., 2016;</ref><ref type="bibr" target="#b36">Shu et al., 2017;</ref><ref type="bibr" target="#b43">Xu et al., 2018)</ref>. Next, polarity classification aims to predict the sentiment polarities over the extracted target entities <ref type="bibr" target="#b16">(Jiang et al., 2011;</ref><ref type="bibr" target="#b8">Dong et al., 2014;</ref><ref type="bibr" target="#b37">Tang et al., 2016a;</ref><ref type="bibr" target="#b42">Wang et al., 2016b;</ref><ref type="bibr" target="#b6">Chen et al., 2017;</ref><ref type="bibr" target="#b44">Xue and Li, 2018;</ref><ref type="bibr" target="#b9">Fan et al., 2018)</ref>. Although lots of efforts have been made to design sophisticated classifiers for this subtask, they all assume that the targets are already given.</p><p>Rather than using separate models for each subtask, some works attempt to solve the task in a more integrated way, by jointly extracting targets and predicting their sentiments <ref type="bibr" target="#b27">(Mitchell et al., 2013;</ref><ref type="bibr" target="#b45">Zhang et al., 2015;</ref><ref type="bibr" target="#b22">Li et al., 2019)</ref>. The key insight is to label each word with a set of target tags <ref type="bibr">(e.g., B, I, O)</ref> as well as a set of polarity tags <ref type="bibr">(e.g., +, -, 0)</ref>, or use a more collapsed set of tags <ref type="bibr">(e.g., B+, I-)</ref> to directly indicate the boundary of targeted sentiment, as shown in <ref type="figure" target="#fig_2">Figure 2</ref> <ref type="bibr">(a)</ref>. As a result, the entire task is formulated as a sequence tagging problem, and solved using either a pipeline model, a joint model, or a collapsed model under the same network architecture. However, the above annotation scheme has several disadvantages in target extraction and polarity classification. <ref type="bibr" target="#b20">Lee et al. (2016)</ref> show that, when using BIO tags for extractive question answering tasks, the model must consider a huge search space due to the compositionality of labels (the power set of all sentence words), thus being less effective. As for polarity classification, the sequence tagging scheme turns out to be problematic for two reasons. First, tagging polarity over each word </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Collapsed:</head><p>Polarity: +, -Target start: 3+, 11-Target end: 4+, 11- <ref type="bibr">(b)</ref> Span-based labeling. The number denotes the start/end position of the given target in the sentence. ignores the semantics of the entire opinion target. Second, since predicted polarities over target words may be different, the sentiment consistency of multi-word entity can not be guaranteed, as mentioned by <ref type="bibr" target="#b22">Li et al. (2019)</ref>. For example, there is a chance that the words "Windows" and "7" in <ref type="figure" target="#fig_2">Figure 2</ref>(a) are predicted to have different polarities due to word-level tagging decisions.</p><p>To address the problems, we propose a spanbased labeling scheme for open-domain targeted sentiment analysis, as shown in <ref type="figure" target="#fig_2">Figure 2</ref> <ref type="bibr">(b)</ref>. The key insight is to annotate each opinion target with its span boundary followed by its sentiment polarity. Under such annotation, we introduce an extract-then-classify framework that first extracts multiple opinion targets using an heuristic multispan decoding algorithm, and then classifies their polarities with corresponding summarized span representations. The advantage of this approach is that the extractive search space can be reduced linearly with the sentence length, which is far less than the tagging method. Moreover, since the polarity is decided using the targeted span representation, the model is able to take all target words into account before making predictions, thus naturally avoiding sentiment inconsistency.</p><p>We take BERT <ref type="bibr" target="#b7">(Devlin et al., 2018)</ref> as the default backbone network, and explore two research questions. First, we make an elaborate comparison between tagging-based models and span-based models. Second, following previous works <ref type="bibr" target="#b27">(Mitchell et al., 2013;</ref><ref type="bibr" target="#b45">Zhang et al., 2015)</ref>, we compare the pipeline, joint, and collapsed models under the span-based labeling scheme. Extensive experiments on three benchmark datasets show that our models consistently outperform sequence tagging baselines. In addition, the pipeline model firmly improves over both the joint and collapsed models. Source code is released to facilitate future research in this field 1 . 1 https://github.com/huminghao16/SpanABSA</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Apart from sentence-level sentiment analysis <ref type="bibr" target="#b24">(Lin and He, 2009;</ref><ref type="bibr" target="#b17">Kim, 2014)</ref>, targeted sentiment analysis, which requires the detection of sentiments towards mentioned entities in the open domain, is also an important research topic.</p><p>As discussed in §1, this task is usually divided into two subtasks. The first is target extraction for identifying entities from the input sentence. Traditionally, Conditional Random Fields (CRF) <ref type="bibr" target="#b18">(Lafferty et al., 2001)</ref> have been widely explored <ref type="bibr" target="#b15">(Jakob and Gurevych, 2010;</ref><ref type="bibr" target="#b41">Wang et al., 2016a;</ref><ref type="bibr" target="#b36">Shu et al., 2017)</ref>. Recently, many works concentrate on leveraging deep neural networks to tackle this task, e.g., using CNNs <ref type="bibr" target="#b32">(Poria et al., 2016;</ref><ref type="bibr" target="#b43">Xu et al., 2018)</ref>, RNNs <ref type="bibr" target="#b26">(Liu et al., 2015;</ref>, and so on. The second is polarity classification, assuming that the target entities are given. Recent works mainly focus on capturing the interaction between the target and the sentence, by utilizing various neural architectures such as LSTMs <ref type="bibr" target="#b12">(Hochreiter and Schmidhuber, 1997;</ref><ref type="bibr" target="#b37">Tang et al., 2016a)</ref> with attention mechanism <ref type="bibr" target="#b42">(Wang et al., 2016b;</ref><ref type="bibr" target="#b9">Fan et al., 2018)</ref>, CNNs <ref type="bibr" target="#b44">(Xue and Li, 2018;</ref><ref type="bibr" target="#b14">Huang and Carley, 2018)</ref>, and Memory Networks <ref type="bibr" target="#b38">(Tang et al., 2016b;</ref><ref type="bibr" target="#b6">Chen et al., 2017;</ref><ref type="bibr" target="#b23">Li and Lam, 2017)</ref>.</p><p>Rather than solving these two subtasks with separate models, a more practical approach is to directly predict the sentiment towards an entity along with discovering the entity itself. Specifically, <ref type="bibr" target="#b27">Mitchell et al. (2013)</ref> formulate the whole task as a sequence tagging problem and propose to use CRF with hand-crafted linguistic features. <ref type="bibr" target="#b45">Zhang et al. (2015)</ref> further leverage these linguistic features to enhance a neural CRF model. Recently, <ref type="bibr" target="#b22">Li et al. (2019)</ref> have proposed a unified model that contains two stacked LSTMs along with carefully-designed components for maintaining sentiment consistency and improving target   <ref type="bibr" target="#b7">(Devlin et al., 2018)</ref> that contains L pre-trained Transformer blocks <ref type="bibr" target="#b39">(Vaswani et al., 2017)</ref>. The last block's hidden states are used to (a) propose one or multiple candidate targets based on the probabilities of the start and end positions, <ref type="bibr">(b)</ref> predict the sentiment polarity using the span representation of the given target. word detection. Our work differs from these approaches in that we formulate this task as a spanlevel extract-then-classify process instead.</p><p>The proposed span-based labeling scheme is inspired by recent advances in machine comprehension and question answering <ref type="bibr" target="#b35">(Seo et al., 2017;</ref><ref type="bibr" target="#b43">Hu et al., 2018)</ref>, where the task is to extract a continuous span of text from the document as the answer to the question <ref type="bibr" target="#b33">(Rajpurkar et al., 2016</ref>). To solve this task, <ref type="bibr" target="#b20">Lee et al. (2016)</ref> investigate several predicting strategies, such as BIO prediction, boundary prediction, and the results show that predicting the two endpoints of the answer is more beneficial than the tagging method. <ref type="bibr" target="#b40">Wang and Jiang (2017)</ref> explore two answer prediction methods, namely the sequence method and the boundary method, finding that the later performs better. Our approach is related to this line of work. However, unlike these works that extract one span as the final answer, our approach is designed to dynamically output one or multiple opinion targets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Extract-then-Classify Framework</head><p>Instead of formulating the open-domain targeted sentiment analysis task as a sequence tagging problem, we propose to use a span-based labeling scheme as follows: given an input sentence x = (x 1 , ..., x n ) with length n, and a target list T = {t 1 , ..., t m }, where the number of targets is m and each target t i is annotated with its start position, its end position, and its sentiment polarity. The goal is to find all targets from the sentence as well as predict their polarities.</p><p>The overall illustration of the proposed framework is shown in <ref type="figure" target="#fig_4">Figure 3</ref>. The basis of our frame-work is the BERT encoder <ref type="bibr" target="#b7">(Devlin et al., 2018)</ref>: we map word embeddings into contextualized token representations using pre-trained Transformer blocks <ref type="bibr">(Vaswani et al., 2017) ( §3.1)</ref>. A multitarget extractor is first used to propose multiple candidate targets from the sentence ( §3.2). Then, a polarity classifier is designed to predict the sentiment towards each extracted candidate using its summarized span representation ( §3.3). We further investigate three different approaches under this framework, namely the pipeline, joint, and collapsed models in §3.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">BERT as Backbone Network</head><p>We use Bidirectional Encoder Representations from Transformers (BERT) <ref type="bibr" target="#b7">(Devlin et al., 2018)</ref>, a pre-trained bidirectional Transformer encoder that achieves state-of-the-art performances across a variety of NLP tasks, as our backbone network.</p><p>We first tokenize the sentence x using a 30,522 wordpiece vocabulary, and then generate the input sequencex by concatenating a [CLS] token, the tokenized sentence, and a [SEP] token. Then for each tokenx i inx, we convert it into vector space by summing the token, segment, and position embeddings, thus yielding the input embeddings h 0 ∈ R (n+2)×h , where h is the hidden size.</p><p>Next, we use a series of L stacked Transformer blocks to project the input embeddings into a sequence of contextual vectors h i ∈ R (n+2)×h as:</p><formula xml:id="formula_0">h i = TransformerBlock(h i−1 ), ∀i ∈ [1, L]</formula><p>Here, we omit an exhaustive description of the block architecture and refer readers to <ref type="bibr" target="#b39">Vaswani et al. (2017)</ref> for more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Multi-Target Extractor</head><p>Multi-target extractor aims to propose multiple candidate opinion targets <ref type="bibr">(Figure 3(a)</ref>). Rather than finding targets via sequence tagging methods, we detect candidate targets by predicting the start and end positions of the target in the sentence, as suggested in extractive question answering <ref type="bibr" target="#b40">(Wang and Jiang, 2017;</ref><ref type="bibr" target="#b35">Seo et al., 2017;</ref><ref type="bibr" target="#b43">Hu et al., 2018)</ref>. We obtain the unnormalized score as well as the probability distribution of the start position as:</p><formula xml:id="formula_1">g s = w s h L , p s = softmax(g s )</formula><p>where w s ∈ R h is a trainable weight vector. Similarly, we can get the probability of the end position along with its confidence score by:</p><formula xml:id="formula_2">g e = w e h L , p e = softmax(g e )</formula><p>During training, since each sentence may contain multiple targets, we label the span boundaries for all target entities in the list T. As a result, we can obtain a vector y s ∈ R <ref type="bibr">(n+2)</ref> , where each element y s i indicates whether the i-th token starts a target, and also get another vector y e ∈ R <ref type="bibr">(n+2)</ref> for labeling the end positions. Then, we define the training objective as the sum of the negative log probabilities of the true start and end positions on two predicted probabilities as:</p><formula xml:id="formula_3">L = − n+2 i=1 y s i log(p s i ) − n+2 j=1 y e j log(p e j )</formula><p>At inference time, previous works choose the span (k, l) (k ≤ l) with the maximum value of g s k + g e l as the final prediction. However, such decoding method is not suitable for the multi-target extraction task. Moreover, simply taking top-K spans according to the addition of two scores is also not optimal, as multiple candidates may refer to the same text. <ref type="figure">Figure 4</ref> gives a qualitative example to illustrate this phenomenon.</p><p>Sentence: Great food but the service was dreadful! Targets: food, service Predictions: food but the service, food, Great food, service, service was dreadful, ... <ref type="figure">Figure 4</ref>: An example shows that there are many redundant spans in top-K predictions.</p><p>To adapt to multi-target scenarios, we propose an heuristic multi-span decoding algorithm as shown in Algorithm 1. For each example, top-M indices are first chosen from the two predicted scores g s and g e (line 2), and the candidate span (s i , e j ) (denoted as r l ) along with its heuristicregularized score u l are then added to the lists R and U respectively, under the constraints that the end position is no less than the start position as well as the addition of two scores exceeds a threshold γ (line 3-8). Note that we heuristically calculate u l as the sum of two scores minus the span length <ref type="bibr">(line 6)</ref>, which turns out to be critical to the performance as targets are usually short entities. Next, we prune redundant spans in R using the non-maximum suppression algorithm <ref type="bibr" target="#b34">(Rosenfeld and Thurston, 1971)</ref>. Specifically, we remove the span r l that possesses the maximum score u l from the set R and add it to the set O (line 10-11). We also delete any span r k that is overlapped with r l , which is measured with the word-level F1 function <ref type="bibr">(line 12-14)</ref>. This process is repeated for remaining spans in R, until R is empty or top-K target spans have been proposed (line 9).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Heuristic multi-span decoding</head><p>Input: g s , g e , γ, K g s denotes the score of start positions g e denotes the score of end positions γ is a minimum score threshold K is the maximum number of proposed targets 1: Initialize R, U, O = {}, {}, {} 2: Get top-M indices S, E from g s , g e 3: for si in S do 4:</p><p>for ej in E do 5:</p><p>if si ≤ ej and g s s i + g e e j ≥ γ then 6:</p><p>u l = g s s i + g e e j − (ej − si + 1) 7:</p><p>r l = (si, ej) 8:</p><formula xml:id="formula_4">R = R ∪ {r l }, U = U ∪ {u l } 9: while R = {} and size(O) &lt; K do 10: l = arg max U 11: O = O ∪ {r l }; R = R − {r l }; U = U − {u l } 12:</formula><p>for r k in R do 13:</p><p>if f1(r l , r k ) = 0 then 14:</p><formula xml:id="formula_5">R = R − {r k }; U = U − {u k } 15: return O</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Polarity Classifier</head><p>Typically, polarity classification is solved using either sequence tagging methods or sophisticated neural networks that separately encode the target and the sentence. Instead, we propose to summarize the target representation from contextual sentence vectors according to its span boundary, and use feed-forward neural networks to predict the sentiment polarity, as shown in <ref type="figure" target="#fig_4">Figure 3(b)</ref>.</p><p>Specifically, given a target span r, we calculate a summarized vector v using the attention mechanism <ref type="bibr" target="#b5">(Bahdanau et al., 2014)</ref> over tokens in its corrsponding bound (s i , e j ), similar to  and <ref type="bibr" target="#b10">He et al. (2018)</ref>:</p><formula xml:id="formula_6">α = softmax(w α h L s i :e j ) v = e j t=s i α t−s i +1 h L t where w α ∈ R h is a trainable weight vector.</formula><p>The polarity score is obtained by applying two linear transformations with a Tanh activation in between, and is normalized with the softmax function to output the polarity probability as:</p><formula xml:id="formula_7">g p = W p tanh(W v v) , p p = softmax(g p )</formula><p>where W v ∈ R h×h and W p ∈ R k×h are two trainable parameter matrices.</p><p>We minimize the negative log probabilities of the true polarity on the predicted probability as:</p><formula xml:id="formula_8">J = − k i=1 y p i log(p p i )</formula><p>where y p is an one-hot label indicating the true polarity, and k is the number of sentiment classes. During inference, the polarity probability is calculated for each candidate target span in the set O, and the sentiment class that possesses the maximum value in p p is chosen.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Model Variants</head><p>Following <ref type="bibr" target="#b27">Mitchell et al. (2013)</ref>; <ref type="bibr" target="#b45">Zhang et al. (2015)</ref>, we investigate three kinds of models under the extract-then-classify framework:</p><p>Pipeline model We first build a multi-target extractor where a BERT encoder is exclusively used. Then, a second backbone network is used to provide contextual sentence vectors for the polarity classifier. Two models are separately trained and combined as a pipeline during inference.</p><p>Joint model In this model, each sentence is fed into a shared BERT backbone network that finally branches into two sibling output layers: one for proposing multiple candidate targets and another for predicting the sentiment polarity over each extracted target. A joint training loss L + J is used to optimize the whole model. The inference procedure is the same as the pipeline model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Collapsed model</head><p>We combine target span boundaries and sentiment polarities into one label space. For example, the sentence in <ref type="figure" target="#fig_2">Figure 2</ref>(b) has a positive span (3+, 4+) and a negative span  <ref type="table">Table 1</ref>: Dataset statistics. '#Sent' and '#Targets' denote the number of sentences and targets, respectively. '+', '-', and '0' refer to the positive, negative, and neutral sentiment classes. <ref type="bibr">(11-, 11-)</ref>. We then modify the multi-target extractor by producing three sets of probabilities of the start and end positions, where each set corresponds to one sentiment class ( e.g., p s+ and p e+ for positive targets). Then, we define three objectives to optimize towards each polarity. During inference, the heuristic multi-span decoding algorithm is performed on each set of scores (e.g., g s+ and g e+ ), and the output sets O + , O − , and O 0 are aggregated as the final prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Setup</head><p>Datasets We conduct experiments on three benchmark sentiment analysis datasets, as shown in <ref type="table">Table 1</ref>. LAPTOP contains product reviews from the laptop domain in SemEval 2014 ABSA challenges <ref type="bibr" target="#b31">(Pontiki et al., 2014)</ref>. REST is the union set of the restaurant domain from SemEval 2014, 2015 and 2016 <ref type="bibr" target="#b30">(Pontiki et al., 2015</ref><ref type="bibr" target="#b29">(Pontiki et al., , 2016</ref>. TWITTER is built by <ref type="bibr" target="#b27">Mitchell et al. (2013)</ref>, consisting of twitter posts. Following <ref type="bibr" target="#b45">Zhang et al. (2015)</ref>; <ref type="bibr" target="#b22">Li et al. (2019)</ref>, we report the ten-fold cross validation results for TWITTER, as there is no train-test split. For each dataset, the gold target span boundaries are available, and the targets are labeled with three sentiment polarities, namely positive (+), negative <ref type="bibr">(-)</ref>, and neutral (0).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Metrices</head><p>We adopt the precision (P), recall (R), and F1 score as evaluation metrics. A predicted target is correct only if it exactly matches the gold target entity and the corresponding polarity. To separately analyze the performance of two subtasks, precision, recall, and F1 are also used for the target extraction subtask, while the accuracy (ACC) metric is applied to polarity classification.  <ref type="table">Table 2</ref>: Main results on three benchmark datasets. A BERT LARGE backbone network is used for both the "TAG" and "SPAN" models. State-of-the-art results are marked in bold. and refer readers to <ref type="bibr" target="#b7">Devlin et al. (2018)</ref> for details on model sizes. We use Adam optimizer with a learning rate of 2e-5 and warmup over the first 10% steps to train for 3 epochs. The batch size is 32 and a dropout probability of 0.1 is used. The number of candidate spans M is set as 20 while the maximum number of proposed targets K is 10 (Algorithm 1). The threshold γ is manually tuned on each dataset. All experiments are conducted on a single NVIDIA P100 GPU card.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model settings</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baseline Methods</head><p>We compare the proposed span-based approach with the following methods: TAG-{pipeline, joint, collapsed} are the sequence tagging baselines that involve a BERT encoder and a CRF decoder. "pipeline" and "joint" denote the pipeline and joint approaches that utilize the BIO and +/-/0 tagging schemes, while "collapsed" is the model following the collapsed tagging scheme <ref type="figure" target="#fig_2">(Figure 2(a)</ref>). UNIFIED <ref type="bibr" target="#b22">(Li et al., 2019)</ref> is the current stateof-the-art model on targeted sentiment analysis 3 . It contains two stacked recurrent neural networks enhanced with multi-task learning and adopts the collapsed tagging scheme.</p><p>We also compare our multi-target extractor with the following method: DE-CNN <ref type="bibr" target="#b43">(Xu et al., 2018)</ref> is the current stateof-the-art model on target extraction, which combines a double embeddings mechanism with convolutional neural networks (CNNs) 4 .</p><p>Finally, the polarity classifier is compared with the following methods:</p><p>MGAN <ref type="bibr" target="#b9">(Fan et al., 2018)</ref> uses a multi-grained attention mechanism to capture interactions between targets and sentences for polarity classification. TNet  is the current state-of-the-art model on polarity classification, which consists of a multi-layer context-preserving network architecture and uses CNNs as feature extractor 5 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Main Results</head><p>We compare models under either the sequence tagging scheme or the span-based labeling scheme, and show the results in <ref type="table">Table 2</ref>. We denote our approach as "SPAN", and use BERT LARGE as backbone networks for both the "TAG" and "SPAN" models to make the comparison fair.</p><p>Two main observations can be obtained from the <ref type="table">Table.</ref> First, despite that the "TAG" baselines already outperform previous best approach ("UNIFIED"), they are all beaten by the "SPAN" methods. The best span-based method achieves 1.55%, 0.94% and 3.43% absolute gains on three datasets compared to the best tagging method, indicating the efficacy of our extract-then-classify framework. Second, among the span-based methods, the SPAN-pipeline achieves the best performance, which is similar to the results of <ref type="bibr" target="#b27">Mitchell et al. (2013)</ref>; <ref type="bibr" target="#b45">Zhang et al. (2015)</ref>. This suggests that there is only a weak connection between target extraction and polarity classification. The conclusion is also supported by the result of SPANcollapsed method, which severely drops across all datasets, implying that merging polarity labels into target spans does not address the task effectively.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Analysis on Target Extraction</head><p>To analyze the performance on target extraction, we run both the tagging baseline and the multitarget extractor on three datasets, as shown in Table 3. We find that the BIO tagger outperforms our extractor on LAPTOP and REST. A likely reason for this observation is that the lengths of input sentences on these datasets are usually small (e.g., 98% of sentences are less than 40 words in REST), which limits the tagger's search space (the power set of all sentence words). As a result, the computational complexity has been largely reduced, which is beneficial for the tagging method. In order to confirm the above hypothesis, we plot the F1 score with respect to different sentence lengths in <ref type="figure" target="#fig_5">Figure 5</ref>. We observe that the performance of BIO tagger dramatically decreases as the sentence length increases, while our extractor is more robust for long sentences. Our extractor manages to surpass the tagger by 16.1 F1 and 1.0 F1 when the length exceeds 40 on LAPTOP and REST, respectively. The above result demonstrates that our extractor is more suitable for long sentences due to the fact that its search space only increases linearly with the sentence length.</p><p>Since a trade-off between precision and recall can be adjusted according to the threshold γ in our extractor, we further plot the precision-recall curves under different ablations to show the effects of heuristic multi-span decoding algorithm. As can be seen from <ref type="figure">Figure 6</ref>  <ref type="figure">Figure 6</ref>: Precision-recall curves on LAPTOP and REST for target extraction. "NMS" and "heuristics" denote the non-maximum suppression and the length heuristics in <ref type="bibr">Algorithm 1.</ref> heuristics results in consistent performance drops across two datasets. By sampling incorrect predictions we find that there are many targets closely aligned with each other, such as "perfect [size] + and [speed] + ", "[portions] + all at a reasonable [price] + ", and so on. The model without length heuristics is very likely to output the whole phrase as a single target, thus being totally wrong. Moreover, removing the non-maximum suppression (NMS) leads to significant performance degradations, suggesting that it is crucial to prune redundant spans that refer to the same text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Analysis on Polarity Classification</head><p>To assess the polarity classification subtask, we compare the performance of our span-level polarity classifier with the CRF-based tagger in <ref type="table" target="#tab_6">Table  5</ref>. The results show that our approach significantly outperforms the tagging baseline by achieving 9.97%, 8.15% and 15.4% absolute gains on three datasets, and firmly surpasses previous stateof-the-art models on LAPTOP. The large improvement over the tagging baseline suggests that detecting sentiment with the entire span representation is much more beneficial than predicting polarities over each word, as the semantics of the given target has been fully considered.</p><p>To gain more insights on performance improvements, we plot the accuracy of both methods with respect to different target lengths in <ref type="figure" target="#fig_7">Figure 7</ref>. We find that the accuracy of span-level classifier only drops a little as the number of words increases on the LAPTOP and REST datasets. The performance of tagging baseline, however, significantly decreases as the target becomes longer. It demonstrates that the tagging method indeed suffers from the sentiment inconsistency problem when it comes to multi-word target entities. Our  span-based method, on the contrary, can naturally alleviate such problem because the polarity is classified by taking all target words into account. <ref type="table" target="#tab_5">Table 4</ref> shows some qualitative cases sampled from the pipeline methods. As observed in the first two examples, the "TAG" model incorrectly predicts the target span by either missing the word "Mac" or proposing a phrase across two targets ("scallps and prawns"). A likely reason of its failure is that the input sentences are relatively longer, and the tagging method is less effective when dealing with them. But when it comes to shorter inputs (e.g., the third and the fourth examples), the tagging baseline usually performs better than our approach. We find that our approach may sometimes fail to propose target entities (e.g., "adjustments" in (3) and "feel" in (4)), which is due to the fact that a relatively large γ has been set. As a result, the model only makes cautious but confident predictions. In contrast, the tagging method does not rely on a threshold and is observed to have a higher recall. For example, it additionally predicts the entity "food" as a target in the second example. Moreover, we find that the tagging method sometimes fails to predict the correct sen- timent class, especially when the target consists of multiple words (e.g., "battery cycle count" in <ref type="bibr" target="#b3">(5)</ref> and "Casa La Femme" in <ref type="bibr" target="#b4">(6)</ref>), indicating the tagger can not effectively maintain sentiment consistency across words. Our polarity classifier, however, can avoid such problem by using the target span representation to predict the sentiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Case Study</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We re-examine the drawbacks of sequence tagging methods in open-domain targeted sentiment analysis, and propose an extract-then-classify framework with the span-based labeling scheme instead. The framework contains a pre-trained Transformer encoder as the backbone network. On top of it, we design a multi-target extractor for proposing multiple candidate targets with an heuristic multispan decoding algorithm, and introduce a polarity classifier that predicts the sentiment towards each candidate using its summarized span representation. Our approach firmly outperforms the sequence tagging baseline as well as previous stateof-the-art methods on three benchmark datasets. Model analysis reveals that the main performance improvement comes from the span-level polarity classifier, and the multi-target extractor is more suitable for long sentences. Moreover, we find that the pipeline model consistently surpasses both the joint model and the collapsed model.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Sentence: I love [Windows 7]+ which is a vast improvment over [Vista]-. Targets: Windows 7, Vista Polarities: positive, negative</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Open-domain targeted sentiment analysis.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Comparison of different annotation schemes for the pipeline, joint, and collapsed models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>An overview of the proposed framework. Word embeddings are fed to the BERT encoder</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>F1 on LAPTOP and REST w.r.t different sentence lengths for target extraction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Accuracy on LAPTOP and REST w.r.t different number of target words for polarity classification.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>arXiv:1906.03820v1 [cs.CL] 10 Jun 2019</figDesc><table><row><cell>Sentence:</cell><cell cols="7">I love Windows 7 ... over Vista .</cell><cell>Sentence:</cell><cell>I love Windows 7 ... over Vista .</cell></row><row><cell>Pipeline/</cell><cell>O</cell><cell>O</cell><cell>B</cell><cell>I</cell><cell>O</cell><cell cols="2">B O</cell><cell>Pipeline/</cell><cell>Target start: 3, 11 Target end: 4, 11</cell></row><row><cell>Joint:</cell><cell>0</cell><cell>0</cell><cell>+</cell><cell>+</cell><cell>0</cell><cell>-</cell><cell>0</cell><cell>Joint:</cell></row><row><cell cols="2">Collapsed: O</cell><cell>O</cell><cell>B+</cell><cell>I+</cell><cell>O</cell><cell cols="2">B-O</cell><cell></cell></row><row><cell cols="8">(a) Sequence tagging. The B/I/O labels indicate target</cell><cell></cell></row><row><cell cols="8">span boundaries, while +/-/0 refer to sentiment polarities.</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>54.89 57.90 68.64 71.01 69.80 53.08 43.56 48.01 TAG-pipeline 65.84 67.19 66.51 71.66 76.45 73.98 54.24 54.37 54.26 TAG-joint 65.43 66.56 65.99 71.47 75.62 73.49 54.18 54.29 54.20 TAG-collapsed 63.71 66.83 65.23 71.05 75.84 73.35 54.05 54.25 54.12 SPAN-pipeline 69.46 66.72 68.06 76.14 73.74 74.92 60.72 55.02 57.69 SPAN-joint 67.41 61.99 64.59 72.32 72.61 72.47 57.03 52.69 54.55 SPAN-collapsed 50.08 47.32 48.66 63.63 53.04 57.85 51.89 45.05 48.11</figDesc><table><row><cell>Model</cell><cell>LAPTOP Prec. Rec.</cell><cell>F1</cell><cell>REST Prec. Rec.</cell><cell>F1</cell><cell>TWITTER Prec. Rec.</cell><cell>F1</cell></row><row><cell>UNIFIED</cell><cell>61.27</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">We use the publicly available</cell></row><row><cell></cell><cell></cell><cell></cell><cell>BERT LARGE</cell><cell cols="3">2 model as our backbone network,</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell cols="7">: F1 comparison of different approaches for</cell></row><row><cell cols="4">target extraction.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>F1</cell><cell>60 70 80 90</cell><cell>88.7 87.2</cell><cell>80.4 73.2 LAPTOP</cell><cell>55.6 71.7 TAG SPAN</cell><cell cols="2">70 80 90 88.7 85.6</cell><cell>76.8 79.5 REST</cell><cell>69.5 70.5 TAG SPAN</cell></row><row><cell></cell><cell>50</cell><cell cols="3">0-20 20-40 &gt;40 #Lengths</cell><cell>60</cell><cell cols="3">#Lengths 0-20 20-40 &gt;40</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Case study. The extracted targets are wrapped in brackets with the predicted polarities given as subscripts. Incorrect predictions are marked with .</figDesc><table><row><cell>Model</cell><cell cols="3">LAPTOP REST TWITTER</cell></row><row><cell>MGAN</cell><cell>75.39</cell><cell>-</cell><cell>-</cell></row><row><cell>TNet</cell><cell>76.54</cell><cell>-</cell><cell>-</cell></row><row><cell>TAG</cell><cell>71.42</cell><cell>81.80</cell><cell>59.76</cell></row><row><cell>SPAN</cell><cell>81.39</cell><cell>89.95</cell><cell>75.16</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Accuracy comparison of different approaches for polarity classification.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://github.com/google-research/bert</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://github.com/lixin4ever/E2E-TBSA 4 https://www.cs.uic.edu/hxu/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">https:// github.com/lixin4ever/TNet</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous reviewers for their insightful feedback. We also thank Li Dong for his helpful comments and suggestions. This work was supported by the National Key Research and Development Program of China  (2016YFB1000101).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">I thought the transition would be difficult at best and would take some time to fully familiarize myself with the new</title>
		<imprint/>
	</monogr>
	<note>Mac ecosystem] 0</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">+</forename></persName>
		</author>
		<idno>Mac ecosystem] 0</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">+ when I order these kinds of food but for the first time</title>
		<imprint/>
	</monogr>
	<note>I would normally not finish the [brocolli. every piece was as eventful as the first one... the [scallops] + and [prawns] + was so fresh and nicely cooked. [brocolli] -(. scallops and prawns] + (), [food] 0 (</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">However, it did not have any scratches, zero [battery cycle count] + (pretty surprised), and all the [hardware] + seemed to be working perfectly</title>
		<imprint/>
	</monogr>
	<note>battery cycle count] 0 (), [hardware] + [battery cycle count] + , [hardware] +</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">I agree that dining at [Casa La Femme] -is like no other dining experience!</title>
		<imprint/>
	</monogr>
	<note>Casa La Femme] + (. Casa La Femme</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>References Dzmitry Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.0473</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Recurrent attention network on memory for aspect sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongqian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidong</forename><surname>Bing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Adaptive recursive neural network for target-dependent twitter sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanqi</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multi-grained attention network for aspect-level sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feifan</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yansong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.04787</idno>
		<title level="m">Jointly predicting predicates and arguments in neural semantic role labeling</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An unsupervised neural attention model for aspect extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruidan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee Tou</forename><surname>Wee Sun Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dahlmeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Reinforced mnemonic reader for machine reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghao</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxing</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI</title>
		<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Parameterized convolutional neural networks for aspect level sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binxuan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><surname>Carley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Extracting opinion targets in a single-and cross-domain setting with conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niklas</forename><surname>Jakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Target-dependent twitter sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiejun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando Cn</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.07045</idno>
		<title level="m">End-to-end neural coreference resolution</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Learning recurrent span representations for extractive question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shimi</forename><surname>Salant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01436</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Transformation networks for target-oriented sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidong</forename><surname>Bing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wai</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bei</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A unified model for opinion target extraction and target sentiment prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidong</forename><surname>Bing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piji</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wai</forename><surname>Lam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep multi-task learning for aspect term extraction with memory interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wai</forename><surname>Lam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Joint sentiment/topic model for sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenghua</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CIKM</title>
		<meeting>CIKM</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Sentiment analysis and opinion mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthesis lectures on human language technologies</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="167" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Finegrained opinion mining with recurrent neural networks and word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shafiq</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Open domain targeted sentiment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacqui</forename><surname>Aguilar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Opinion mining and sentiment analysis. Foundations and Trends R in Information Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Semeval-2016 task 5: Aspect based sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Pontiki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Galanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haris</forename><surname>Papageorgiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ion</forename><surname>Androutsopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suresh</forename><surname>Manandhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Al-Smadi</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahmoud</forename><surname>Al-Ayyoub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanyan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orphée</forename><surname>De Clercq</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SemEval-2016</title>
		<meeting>SemEval-2016</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Semeval-2015 task 12: Aspect based sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Pontiki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Galanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haris</forename><surname>Papageorgiou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SemEval</title>
		<meeting>SemEval</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Suresh Manandhar, and Ion Androutsopoulos</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Semeval-2014 task 4: Aspect based sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Pontiki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Galanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Pavlopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harris</forename><surname>Papageorgiou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SemEval-2014</title>
		<meeting>SemEval-2014</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Ion Androutsopoulos, and Suresh Manandhar</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Aspect extraction for opinion mining with a deep convolutional neural network. Knowledge-Based Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soujanya</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Gelbukh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="42" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Squad: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Edge and curve detection for visual scene analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Azriel</forename><surname>Rosenfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Thurston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on computers</title>
		<imprint>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="562" to="569" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Bidirectional attention flow for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aniruddha</forename><surname>Kembhavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Lifelong learning crf for supervised aspect extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL</title>
		<meeting>the ACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Effective lstms for target-dependent sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaocheng</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
		<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Aspect level sentiment classification with deep memory network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.08900</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Machine comprehension using match-lstm and answer pointer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Recursive neural conditional random fields for aspect-based sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenya</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaokui</forename><surname>Dahlmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Attention-based lstm for aspect-level sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yequan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Double embeddings and cnn-based sequence labeling for aspect extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Aspect based sentiment analysis with gated convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.07043</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Neural networks for open domain targeted sentiment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meishan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duy Tin</forename><surname>Vo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
