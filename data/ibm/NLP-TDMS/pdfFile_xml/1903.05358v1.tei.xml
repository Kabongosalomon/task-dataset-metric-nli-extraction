<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CIA-Net: Robust Nuclei Instance Segmentation with Contour-aware Information Aggregation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanning</forename><surname>Zhou</surname></persName>
							<email>ynzhou@cse.cuhk.edu.hk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong SAR</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><forename type="middle">Fahri</forename><surname>Onder</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Imsight Medical Technology</orgName>
								<address>
									<addrLine>Co., Ltd. Hong Kong SAR</addrLine>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Dou</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Efstratios</forename><surname>Tsougenis</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Imsight Medical Technology</orgName>
								<address>
									<addrLine>Co., Ltd. Hong Kong SAR</addrLine>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Chen</surname></persName>
							<email>hchen@cse.cuhk.edu.hk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong SAR</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Imsight Medical Technology</orgName>
								<address>
									<addrLine>Co., Ltd. Hong Kong SAR</addrLine>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pheng-Ann</forename><surname>Heng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong SAR</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">Department of Computer Science and Engineering</orgName>
								<orgName type="department" key="dep2">Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences</orgName>
								<orgName type="laboratory">Kong and Guangdong Provincial Key Laboratory of Computer Vision and Virtual Reality Technology</orgName>
								<orgName type="institution">The Chinese University of Hong</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">CIA-Net: Robust Nuclei Instance Segmentation with Contour-aware Information Aggregation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T12:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Accurate segmenting nuclei instances is a crucial step in computer-aided image analysis to extract rich features for cellular estimation and following diagnosis as well as treatment. While it still remains challenging because the wide existence of nuclei clusters, along with the large morphological variances among different organs make nuclei instance segmentation susceptible to over-/under-segmentation. Additionally, the inevitably subjective annotating and mislabeling prevent the network learning from reliable samples and eventually reduce the generalization capability for robustly segmenting unseen organ nuclei. To address these issues, we propose a novel deep neural network, namely Contour-aware Informative Aggregation Network (CIA-Net) with multilevel information aggregation module between two task-specific decoders. Rather than independent decoders, it leverages the merit of spatial and texture dependencies between nuclei and contour by bi-directionally aggregating task-specific features. Furthermore, we proposed a novel smooth truncated loss that modulates losses to reduce the perturbation from outliers. Consequently, the network can focus on learning from reliable and informative samples, which inherently improves the generalization capability. Experiments on the 2018 MICCAI challenge of Multi-Organ-Nuclei-Segmentation validated the effectiveness of our proposed method, surpassing all the other 35 competitive teams by a significant margin.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Digital pathology is nowadays playing a crucial role for accurate cellular estimation and prognosis of cancer <ref type="bibr" target="#b17">[18]</ref>. Specifically, nuclei instance segmentation which not only captures location and density information but also rich morphology features, such as magnitude and the cytoplasmic ratio, is critical in tumor diagnosis and following treatment procedures <ref type="bibr" target="#b22">[23]</ref>. However, automatically segmenting the nuclei at instance-level still remains challenging due to several reasons. First, the vast existence of nuclei occlusions and clusters can easily cause over or under-segmentation, which impedes accurate morphological measurements of nuclei instances. Second, the blurred border and inconsistent staining makes images inevitable to contain indistinguishable instances, and hence introduces subjective annotations and mislabeling, which is challenging to get robust and objective results <ref type="bibr" target="#b7">[8]</ref>. Third, the variability in cell appearance, magnitude, and density among diverse cell types and organs requires the method to possess good generalization ability for robust analysis.</p><p>Most of the earlier methods are based on thresholding and morphological operations <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b9">10]</ref>, which fail to find reliable threshold in the complex background. While deep learning-based methods are generally more robust and have become the benchmark for medical image segmentation <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b10">11]</ref>. For example, Chen et al. <ref type="bibr" target="#b1">[2]</ref> proposed a deep contour-aware network (DCAN) for the task of instance segmentation that firstly harnesses the complementary information of contour and instances to separate the attached objects. In order to utilize contour-specific features to assist nuclei prediction, BES-Net <ref type="bibr" target="#b16">[17]</ref> directly concatenates the output contour features with nuclei features in decoders. However, it only learns complementary information in nuclei branch but ignores the potentially reversed benefits from nuclei to contour, which is more essential since contour appearance is more complicated and has larger intra-variance than that of nuclei.</p><p>Another challenge is to eliminate the effect from inevitably noisy and subjective annotations. Different training strategies and loss functions have been proposed <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b18">19]</ref>. A bootstrapped loss <ref type="bibr" target="#b19">[20]</ref> was proposed to rebalance the loss weight by taking the consistency between the label and reliable output into account. However, when dealing with noise labeling especially the mislabeling nuclei, the network tends to predict probability with a high confidence score, where the negative log-likelihood magnitude is non-trivial and cannot be appropriately adjusted by the consistent term. As we will show later (Sec. 2.3), these outliers overwhelm others in loss calculation and dominate the gradient.</p><p>To address the issues mentioned above, we have following contributions in this paper. 1). We propose an Information Aggregation Module (IAM) which enables the decoders to collaboratively refine details of nuclei and contour by leveraging the spatial and texture dependencies in bi-directionally feature aggregation. 2). A novel smooth truncated Loss is proposed to modulate the outliers' perturbation in loss calculation, which endows the network with the ability to robustly segment nuclei instances by focusing on learning informative samples. Moreover, eliminating outliers alleviates the network from overfitting on these noisy samples, eventually enabling the network with better generalization capability.</p><p>3). We validate the effectiveness of our proposed Contour-aware Information Aggregation Network (CIA-Net) with the advantages of pyramidal information aggregation and robustness on Multi-Organ Nuclei Segmentation (MoNuSeg) dataset with seven different organs, and achieved the 1st place on 2018 MICCAI Challenge, demonstrating the superior performance of the proposed approach.  <ref type="figure" target="#fig_0">Fig. 1</ref> presents overview of the CIA-Net, which is a fully convolutional network (FCN) consisting of one densely connective encoder and two task-specific information aggregated decoders for refinement. To fully leverage the benefit of complementary information from highly correlated tasks, instead of directly concatenating task-specific features, our method conducts a hierarchical refinement procedure by aggregating multi-level task-specific features between decoders.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Densely Connected Encoder with Pyramidal Feature Extraction</head><p>To effectively train the deep FCN, dense connectivity is introduced in encoder <ref type="bibr" target="#b6">[7]</ref>. In each Dense Module (DM), let x i denotes the output of the i-th layer, dense connectivity can be described as x i = F i ([x 1 , x 2 , . . . , x i−1 ], W i ). It sets up direct connections from any bottleneck layer to all subsequent layers by concatenation, which not only effectively and efficiently reuses features but also benefits gradient back-propagation in the deep network. Transition Module (TM) is added after DM to reduce the spatial resolution and make the features more compact, which contains a 1 × 1 convolution layer and an average pooling layer with a stride of 2. Next, we hierarchically stack four DMs where each followed by a TM except the last one. For each DM, it consists of {6, 12, 24, 16} bottleneck layers, respectively.</p><p>Inspired by feature pyramid network <ref type="bibr" target="#b12">[13]</ref> which takes advantage of multi-scale features for accurate object detection, we propose to make full use of pyramidal features hierarchically by building multi-level lateral connections between encoder and decoders. In this way, localization and texture information from earlier layers can help the low-resolution while strong-semantic features refine the details. The encoder features with {1/2, 1/4, 1/8} of original size are passed through the lateral connections by a 1 × 1 convolution to reduce feature map number and merged with the upsampled deeper features in decoders by summation operation, as shown in <ref type="figure" target="#fig_1">Fig. 2</ref>(a). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Bi-directional Feature Aggregation for Accurate Segmentation</head><p>Given that contour region encases the corresponding nuclei, it is intuitive that nuclei and contour have high spatial and contextual relevance, which is helpful for decoders to localize and focus on learning informative patterns. In other words, the neural response from the specific kernel in nuclei branch can be considered as an extra spatial or contexture cue for localizing contour to refine details and vice versa. In this regard, we proposed Information Aggregation Module (IAM) which aims at utilizing information from highly-correlated sub-tasks to bidirectionally aggregate the task-specific features between two decoders. <ref type="figure" target="#fig_1">Fig. 2(b)</ref> shows the details of IAM structure, it takes features after lateral connection as inputs, and then selects and aggregates informative features for each sub-task.</p><p>To start the iteration, we attach a 3×3 convolution on the top of the encoder to generate the coarsest feature maps. For each decoder, the feature maps M i−1 from a higher level are upsampled by bilinear interpolation to double the resolution and added with high-resolution feature maps from encoder through lateral connections (see <ref type="figure" target="#fig_1">Fig. 2</ref>(a)). After that, the IAM takes the merged maps D i−1 as inputs and adds a 3 × 3 convolution without nonlinear activation to smoothen and eliminate the grid effects. Then the smooth features are fed into the classifier to predict multi-resolution score maps. Meanwhile, these task-specific features are concatenated along the channel dimension and then passed through two parallel convolution layers to select and integrate the complementary informative features M i for further details refinement in the next iteration.</p><p>Besides, to prevent the network from relying on single level discriminative features, deep supervision mechanism <ref type="bibr" target="#b3">[4]</ref> is introduced at each stage to strengthen learning of multi-level contextual information. This also benefits training of deeper network architectures by shortening the back-propagation path.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Smooth Truncated Loss for Robust Nuclei Segmentation</head><p>The existence of blurred edge and inconsistent staining makes images inevitably contain indistinguishable instances, which leads to subjective annotations such as mislabelled objects and inaccurate boundary. Additionally, to enhance the ability to split attached nuclei, conventional practice is to preprocess the training ground truth by subtracting the dilated contour mask, which is also suboptimal and has the risk of introducing noises. Both factors show that it is unavoidable for pixel-wise nuclei annotations to contain imperfect labels, which is harmful to network training from at least two aspects. Firstly, the inaccurate labeling encountered during training has the tendency to overwhelm other regions in loss calculation and dominate the gradients. This phenomenon is observed from the sorted cumulative distribution function of normalized loss in <ref type="figure" target="#fig_2">Fig. 3</ref>(b) using a converged model. Notice that top 10% samples account for more than 80% value of cross-entropy loss, which prevents network learning from informative samples during gradient back-propagation. Secondly, forcibly learning the subjective labeling would eventually push the network to particularly fit them and tend to overfitting, which is even more pernicious when predicting unseen organ nuclei. To handle the noisy and incomplete labeling, <ref type="bibr" target="#b19">[20]</ref> proposed bootstrapped loss (L BST ) to rebalance the loss weight by considering the consistency between the label and reliable output. However, as can be seen in <ref type="figure" target="#fig_2">Fig. 3(b)</ref>, when faced with errors with low predicted probability, it cannot easily compensate for the loss with non-trivial magnitude.</p><p>To solve this problem, our insight is to reduce outliers' interference in training by modulating contribution in loss calculation. Under the premise of high credibility of network prediction, the majority of outliers will lie in low predicted probability regions and get large values of error. Inspired by Huber loss <ref type="bibr" target="#b4">[5]</ref> for robust regression, which is quadratic for small values of error and linear for large values to decline the influence of outliers, we propose the prototype of loss function, namely Truncated Loss (L T ), which reduces the contribution of outliers with high confidence prediction. Let p t denotes the predicted probability of the ground truth, p t = p if t = 1 and p t = 1−p otherwise, in which t ∈ {0, 1} specifics the ground truth label. Formally, the loss is truncated when the corresponding p t is smaller than a threshold γ ∈ [0, 0.5]:</p><formula xml:id="formula_0">L T = − max(log(p t ), log(γ)).<label>(1)</label></formula><p>The truncated loss only clips outliers with p t &lt; γ, while preserves loss value for the other. Intuitively, this operation adds a constraint of maximum contribution in loss calculation from each pixel and hence can ease the gradient domination from outliers and benefit of learning the informative samples. However, in Eq. (1) the derivative of L T at clipping point p t = γ is undefined. Meanwhile, the perturbation of low p t prediction will not be reflected in loss calculation if we force the loss value larger than the threshold to a constant, therefore the smoothed version is preferred for optimization. In this regard, we propose Smooth Truncated Loss L ST :</p><formula xml:id="formula_1">L ST = − log(γ) + 1 2 (1 − p 2 t γ 2 ), p t &lt; γ − log(p t ), p t γ<label>(2)</label></formula><p>A quadratic function with the same value and derivative as negative loglikelihood at the truncated point γ is used to modulate the loss weight for outliers. By incorporating constraint for the loss magnitude, it reduces the contribution of outliers, where the smaller p t , the more considerable modulation. This, in turn, let the network discard the indistinguishable parts and focus on informative and learnable regions. Furthermore, by reducing the influence of the outlier samples that interferences the network training, it encourages the network to predict with higher confidence scores and narrow the uncertain regions, which is helpful for alleviating over-segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Overall Loss Function</head><p>Based on the proposed Smooth Truncated Loss, we can derive the overall loss function. Note that the contour prediction is much more difficult than that of nuclei due to irregularly curved form. In this case, the primary component of regions with high loss is not by the outliers, but the inlier samples, and hence utilizing truncated loss may confuse the network. Instead, we use Soft Dice Loss to learn the shape similarity:</p><formula xml:id="formula_2">L Dice = 1 − 2 n i=1 p i q i n i=1 p 2 i + n i=1 q 2 i ,<label>(3)</label></formula><p>where p i denotes the predicted probability of i-th pixel and q i denotes the corresponding ground truth. In sum, the total loss function for proposed CIA-Net training is:</p><formula xml:id="formula_3">L total = L ST + λL Dice + β W 2 2 ,<label>(4)</label></formula><p>where the first and second terms calculate error from contour and nuclei prediction respectively, and the third term is the weight decay. λ and β are hyperparameters to balance three components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset and Evaluation Metrics</head><p>We validated our proposed method on MoNuSeg dataset of 2018 MICCAI challenge, which contains 30 images (size: 1000 × 1000 ) captured by The Cancer Genomic Atlas (TCGA) from whole slide images (WSIs) <ref type="bibr" target="#b11">[12]</ref>. The dataset consists of breast, liver, kidney, prostate, bladder, colon and stomach containing both benign and malignant cases, which is then divided into training set (Train), test set1 from the same organs of training data (Test1 ) and test set2 from unseen organs (Test2 ) with 14, 8 and 6 images, respectively. The Train contains 4 organs -breast, kidney, liver and prostate with 4 images from each organ, the Test1 includes 2 images from per organ mentioned in Train, and Test2 contains 2 images from each unseen organ, i.e., bladder, colon and stomach. We employed Average Jaccard Index (AJI) <ref type="bibr" target="#b11">[12]</ref> for comparison, which considers an aggregated intersection cardinality numerator and an aggregated union cardinality denominator for all ground truth and segmented nuclei. Let G = {G 1 , G 2 , . . . G n } denotes the set of instance ground truths, S = {S 1 , S 2 , . . . S m } denotes the set of segmented objects and N denotes the set of segmented objects with none intersection to ground truth. AJI =</p><formula xml:id="formula_4">n i=1 G i S j n i=1 G i S j + k∈N S k , where j = argmax k G i S k G i S k . F1-score (F 1 = 2 · P recision · Recall P recision + Recall ) [2]</formula><p>is used for nuclei instance detection performance evaluation and we also report it for reference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Implementation Details</head><p>We implemented our network using Tensorflow (version 1.7.0). The default parameters provided at https://github.com/pudae/tensorflow-densenet is used in the Densenet backbone. Stain normalization method <ref type="bibr" target="#b15">[16]</ref> was performed before training. Data augmentations including crop, flip, elastic transformation and color jitter were utilized. The outputs of nuclei and contour maps were first subtracted and then the connected components were detected get the final results. The network was trained on one NVIDIA TITAN Xp GPU with a mini-batch size of three. We utilized the pre-trained DenseNet model <ref type="bibr" target="#b6">[7]</ref> from ImageNet to initialize the encoder. The hyper-parameters λ and β were set as 0.42 and 0.0001 to balance the loss and regularization. AdamW optimizer was used to optimize the whole network and learning rate was initialized as 0.001 and decayed according to cosine annealing and warm restarts strategy <ref type="bibr" target="#b14">[15]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Evaluation and Comparison</head><p>Effectiveness of contour-aware information aggregation architecture. Firstly, we conduct a series of experiments to compare different informative feature aggregation strategies in decoders: (1) Cell Profiler [1]: a python-based software for computational pathology employing intensity thresholoding method. Proposed CIA-Net: Our Contour-aware Information Aggregation Network with Information Aggregation Module between nuclei and contour decoders. Notice that unless specified otherwise, we utilized the same encoder structure with pyramidal feature extraction strategy and loss functions to establish fair comparison. It is observed that all CNN-based approaches achieved much higher results on all evaluation criterions than conventional approaches, highlighting the superiority of deep learning based methods for segmentation related tasks. Moreover, results from (4) to (8) have a striking improvement regarding the evaluation metric of AJI on both Test1 and Test2 compared with (3), validating the efficacy of dense connectivity structure, which is more powerful to leverage multilevel features and mitigate gradient vanishing in training deep neural network. While methods (4) to <ref type="bibr" target="#b6">(7)</ref> achieved comparable performance on the evaluation performance of Test1, the results from BES-Net and proposed CIA-Net w/o IAM outperform others significantly on AJI of Test2, demonstrating the exploitation of high spatial and context relevance between nuclei and contour can generate task-specific features for assisting feature refinement between both tasks. This can help enhance the generalization capability to unseen data. Meanwhile, in comparison with BES-Net and proposed CIA-Net w/o IAM, our proposed network CIA-Net further outperforms these two methods consistently regarding the metric of AJI, achieving overall best performance and boosting results to 0.6306 on Test2 and 0.6129 on Test1. Different from BES-Net which directly concatenates features in contour decoder to nuclei branch, the proposed CIA-Net with IAM bi-directionally aggregating the task-specific features and passing them through parallel convolutions to iteratively aggregate informative features in decoders. Therefore, it is a learnable procedure for network to find favorable features, which mutually benefits two sub-tasks. Compared with the improvement on AJI, the improvement on F1-score is less significant, this is because AJI is a segment-based metric while F1-score is the detection-based metric.   As can be seen in <ref type="table">Table 2</ref>, the improvement of L BST compared to L BCE is limited. Compared with first two rows, results from L T and L ST outperform others on Test2 consisting of unseen organs by a large margin (nearly 2.5% for L ST and 1% for L T ) regarding the metric of AJI, and are analogous on Test1. The proposed L ST achieved significant improvements in comparison with L T on Test2, shows it is less sensitive on γ and has better generalization capability on different organ images. The proposed Smooth Truncated loss introduces one new hyper-parameter, the truncating parameter γ, which controls the starting point of down-weighting outliers. When γ = 0, the loss function degenerates into Binary Cross-entropy L BCE . As γ increases, more examples with p t lower than γ are considered as outliers or less informative samples to down-weight in loss calculation. <ref type="figure" target="#fig_5">Fig. 4</ref> illustrates the influence of varying γ. We can see L ST have a striking overall improvement compared with L BST and L T . More importantly, results from L ST demonstrate less sensitivity for choosing different γ.</p><p>We visualize the nuclei heatmaps from setting different γ in L ST (see <ref type="figure" target="#fig_6">Fig. 5</ref>) to give an intuitive understanding of our proposed method. It is observed that heatmaps trained by L BCE <ref type="figure" target="#fig_6">(Fig. 5(b)</ref>) contain massive blur and noise, which is unfavorable for binarizing instances. As γ increases, the heatmaps turn to be more concrete with less uncertain areas, which is of great significance for instance segmentation to prevent over-segmentation. While setting too large γ increases the risk of under-segmentation, as can be seen in <ref type="figure" target="#fig_6">Fig. 5(f)</ref>. This is because over suppressing low p t region also penalties learning from informative inlier samples, especially boundary regions where the p t is relatively small. 2018 MICCAI MoNuSeg Challenge results. We employed above entire dataset for training and 14 additional images provided by organizer for independent evaluation with ground truth held out 1 . Top 20 results of 36 teams are shown in <ref type="figure" target="#fig_7">Fig. 6</ref>. Our submitted entry surpassed all the other methods, highlighting the strength of the proposed CIA-Net and Smooth Truncated loss. Qualitative analysis. <ref type="figure" target="#fig_8">Fig. 7</ref> shows representative samples from Test1 and Test2 with challenging cases such as diffuse-chromatin nuclei and irregular shape. Notice that our proposed CIA-Net ( <ref type="figure" target="#fig_8">Fig. 7(e)</ref>) can generate the segmentation results similar to the annotations of human experts, outperforming others with less over or under-segmentation on the prolific nuclei clusters and attached cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>Instance-level nuclei segmentation is the pivotal step for cell estimation and further pathological analysis. In this paper, we propose CIA-Net with the smooth truncated loss to tackle the challenges of prolific nuclei clusters and inevitable labeling noise in pathological images. Our method inherently can be adapted to a wide range of medical image segmentation tasks to boost the performance such as histology gland segmentation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>An overview of our proposed CIA-Net for nuclei instance segmentation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Detail structure of (a) Lateral Connected Refinement and (b) Information Aggregation Module in proposed CIA-Net.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Visualization of different loss functions (a) with γ = 0.2 and the cumulative loss functions of normalized loss from foreground regions (b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>( 2 )</head><label>2</label><figDesc>Fiji [22]: a Java-based software utilizing watershed transform nuclear segmentation method. (3) CNN3 [12]: a 3-class FCN without deep dense connectivity. (4) DCAN [2]: a deep FCN with multi-task learning strategy for objects and contours. (5) PA-Net<ref type="bibr" target="#b13">[14]</ref>: a modified path aggregation network by adding path augmentation in two independent decoders to enhance the instance segmentation performance. (6) BES-Net<ref type="bibr" target="#b16">[17]</ref>: the original boundary-enhanced segmentation network which concatenated contour features with nuclei features to enhance learning in boundary region.<ref type="bibr" target="#b6">(7)</ref> CIA-Net w/o IAM : the proposed network architecture with two independent decoders for nuclei and contour prediction respectively, but without Information Aggregation Module in decoders.<ref type="bibr" target="#b7">(8)</ref> </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Effectiveness of proposed Smooth Truncated loss. Toward the potential of clinical application, the proposed method should be robust under the numerous circumstances, especially for the diffused-chromatin and attached nuclei in unseen organs, which is evaluated in Test2 set. We compare the results of our proposed CIA-Net with four different functions: (1) L BCE : Binary Cross-Entropy loss. (2) L BST : Soft Bootstrapped loss by rebalancing the loss weight. (3) L T : Proposed Truncated loss without smoothing around truncated point, i.e., Eq. (1). (4) L ST : Proposed Smooth Truncated loss which utilizes quadratic function as soft modulation, i.e., Eq. (2).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 .</head><label>4</label><figDesc>Results of varying γ for LT and LST on Test2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 .</head><label>5</label><figDesc>Visualization of heatmaps in different γ values from T est2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 6 .</head><label>6</label><figDesc>The instance segmentation results of different methods in 2018 MICCAI Multi-Organ Nuclei Segmentation Challenge (top 20 of 36 methods are shown in figure).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 7 .</head><label>7</label><figDesc>Qualitative results of multi-organ nuclei (from top to bottom: breast, kidney, colon) on Test1 and Test2. Yellow rectangles highlight the difference among predictions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Performance comparison of different methods on Test1 (seen organ) and Test2 (unseen organ).</figDesc><table><row><cell></cell><cell></cell><cell>AJI</cell><cell></cell><cell cols="2">F1-score</cell></row><row><cell></cell><cell>Method</cell><cell>Test1</cell><cell>Test2</cell><cell>Test1</cell><cell>Test2</cell></row><row><cell>(1)</cell><cell>Cell Profiler [1]</cell><cell>0.1549</cell><cell>0.0809</cell><cell>0.4143</cell><cell>0.3917</cell></row><row><cell>(2)</cell><cell>Fiji [22]</cell><cell>0.2508</cell><cell>0.3030</cell><cell>0.6402</cell><cell>0.6978</cell></row><row><cell>(3)</cell><cell>CNN3 [12]</cell><cell>0.5154</cell><cell>0.4989</cell><cell>0.8226</cell><cell>0.8322</cell></row><row><cell>(4)</cell><cell>DCAN [2]</cell><cell>0.6082</cell><cell>0.5449</cell><cell>0.8265</cell><cell>0.8214</cell></row><row><cell>(5)</cell><cell>PA-Net [14]</cell><cell>0.6011</cell><cell>0.5608</cell><cell>0.8156</cell><cell>0.8336</cell></row><row><cell>(6)</cell><cell>BES-Net [17]</cell><cell>0.5906</cell><cell>0.5823</cell><cell>0.8118</cell><cell>0.7952</cell></row><row><cell>(7)</cell><cell>CIA-Net w/o IAM</cell><cell>0.6106</cell><cell>0.5817</cell><cell>0.8279</cell><cell>0.8356</cell></row><row><cell>(8)</cell><cell>Proposed CIA-Net</cell><cell cols="2">0.6129 0.6306</cell><cell>0.8244</cell><cell>0.8458</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://monuseg.grand-challenge.org</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments. This work was supported by Hong Kong Innovation and Technology Fund (Project No. ITS/041/16), Guangdong province science and technology plan project (No.2016A020220013).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Cellprofiler: image analysis software for identifying and quantifying cell phenotypes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Carpenter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">R</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Lamprecht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">H</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Friman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Guertin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Lindquist</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Moffat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genome biology</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">100</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Dcan: Deep contour-aware networks for object instance segmentation from histology images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical image analysis</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="135" to="146" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Segmentation of clustered nuclei with shape markers and marking function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Rajapakse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="741" to="748" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">3d deeply supervised network for automated segmentation of volumetric medical images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical image analysis</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="40" to="54" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
		<title level="m">The elements of statistical learning</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer series in statistics</publisher>
			<date type="published" when="2001" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Training deep neural-networks using a noise adaptation layer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ben-Reuven</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">2017</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Crowdsourcing image annotation for nucleus detection and segmentation in computational pathology: evaluating experts, automated methods, and the crowd</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Irshad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Montaser-Kouhsari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Waltz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bucur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nowak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Knoblauch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Beck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pac Symp Biocomput</title>
		<imprint>
			<publisher>World Scientific</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="294" to="305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Mentornet: Learning datadriven curriculum for very deep neural networks on corrupted labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICML</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Segmenting clustered nuclei using h-minima transformbased marker extraction andcontour parameterization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2600" to="2604" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kazeminia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Baur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kuijper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Ginneken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Albarqouni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mukhopadhyay</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.06222</idno>
		<title level="m">Gans for medical image analysis</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A dataset and a technique for generalized nuclear segmentation for computational pathology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bhargava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vahadane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sethi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1550" to="1560" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Feature pyramid networks for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>IEEE CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Path aggregation network for instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Fixing weight decay regularization in adam</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.05101</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">A method for normalizing histology slides for quantitative analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Macenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Niethammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Marron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Borland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Woosley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">E</forename><surname>Thomas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>IEEE ISBI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Besnet: Boundary-enhanced segmentation of cells in histopathological images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Oda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chiba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sokolić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kitasaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Oda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hinoki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Uchida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Schnabel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI 2018</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">11071</biblScope>
			<biblScope unit="page" from="228" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Digital images and the future of digital pathology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pantanowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Pathol Inform</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Making deep neural networks robust to label noise: A loss correction approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Patrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rozza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krishna Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>IEEE CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6596</idno>
		<title level="m">Training deep neural networks on noisy labels with bootstrapping</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI 2015</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">9351</biblScope>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">an open-source platform for biological-image analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schindelin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Arganda-Carreras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Frise</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kaynig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Longair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pietzsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Preibisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rueden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Saalfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">676</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Prognostic value of automatically extracted nuclear morphometric features in whole slide images of male breast cancer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Veta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kornegoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Huisman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">H</forename><surname>Verschuur-Maes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Viergever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Pluim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Van Diest</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mod. Pathol</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">1559</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Robust learning at noisy labeled medical images: Applied to skin lesion classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Heng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>IEEE ISBI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Walia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Babyn</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.07294</idno>
		<title level="m">Generative adversarial network in medical imaging: A review</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
