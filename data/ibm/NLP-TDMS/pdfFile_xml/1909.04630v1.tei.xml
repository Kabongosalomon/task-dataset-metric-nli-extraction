<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Meta-Learning with Implicit Gradients</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><surname>Rajeswaran</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Washington</orgName>
								<address>
									<settlement>Seattle</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of California Berkeley</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sham</forename><surname>Kakade</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Washington</orgName>
								<address>
									<settlement>Seattle</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of California Berkeley</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Meta-Learning with Implicit Gradients</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A core capability of intelligent systems is the ability to quickly learn new tasks by drawing on prior experience. Gradient (or optimization) based meta-learning has recently emerged as an effective approach for few-shot learning. In this formulation, meta-parameters are learned in the outer loop, while task-specific models are learned in the inner-loop, by using only a small amount of data from the current task. A key challenge in scaling these approaches is the need to differentiate through the inner loop learning process, which can impose considerable computational and memory burdens. By drawing upon implicit differentiation, we develop the implicit MAML algorithm, which depends only on the solution to the inner level optimization and not the path taken by the inner loop optimizer. This effectively decouples the meta-gradient computation from the choice of inner loop optimizer. As a result, our approach is agnostic to the choice of inner loop optimizer and can gracefully handle many gradient steps without vanishing gradients or memory constraints. Theoretically, we prove that implicit MAML can compute accurate meta-gradients with a memory footprint no more than that which is required to compute a single inner loop gradient and at no overall increase in the total computational cost. Experimentally, we show that these benefits of implicit MAML translate into empirical gains on few-shot image recognition benchmarks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A core aspect of intelligence is the ability to quickly learn new tasks by drawing upon prior experience from related tasks. Recent work has studied how meta-learning algorithms <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b40">41]</ref> can acquire such a capability by learning to efficiently learn a range of tasks, thereby enabling learning of a new task with as little as a single example <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b14">15]</ref>. Meta-learning algorithms can be framed in terms of recurrent <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b47">48]</ref> or attention-based <ref type="bibr" target="#b56">[57,</ref><ref type="bibr" target="#b37">38]</ref> models that are trained via a meta-learning objective, to essentially encapsulate the learned learning procedure in the parameters of a neural network. An alternative formulation is to frame meta-learning as a bi-level optimization procedure <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b14">15]</ref>, where the "inner" optimization represents adaptation to a given task, and the "outer" objective is the meta-training objective. Such a formulation can be used to learn the initial parameters of a model such that optimizing from this initialization leads to fast adaptation and generalization. In this work, we focus on this class of optimization-based methods, and in particular the model-agnostic meta-learning (MAML) formulation <ref type="bibr" target="#b14">[15]</ref>. MAML has been shown to be as expressive as black-box approaches <ref type="bibr" target="#b13">[14]</ref>, is applicable to a broad range of settings <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b17">18]</ref>, and recovers a convergent and consistent optimization procedure <ref type="bibr" target="#b12">[13]</ref>.</p><p>Despite its appealing properties, meta-learning an initialization requires backpropagation through the inner optimization process. As a result, the meta-learning process requires higher-order derivatives, imposes a non-trivial computational and memory burden, and can suffer from vanishing gradients. These limitations make it harder to scale optimization-based meta learning methods to tasks involving medium or large datasets, or those that require many inner-loop optimization steps. Our goal is to develop an algorithm that addresses these limitations. , the MAML algorithm differentiates through the optimization path, as shown in green, while first-order MAML computes the meta-gradient by approximating dφi dθ as I. Our implicit MAML approach derives an analytic expression for the exact meta-gradient without differentiating through the optimization path by estimating local curvature.</p><p>The main contribution of our work is the development of the implicit MAML (iMAML) algorithm, an approach for optimization-based meta-learning with deep neural networks that removes the need for differentiating through the optimization path. Our algorithm aims to learn a set of parameters such that an optimization algorithm that is initialized at and regularized to this parameter vector leads to good generalization for a variety of learning tasks. By leveraging the implicit differentiation approach, we derive an analytical expression for the meta (or outer level) gradient that depends only on the solution to the inner optimization and not the path taken by the inner optimization algorithm, as depicted in <ref type="figure" target="#fig_0">Figure 1</ref>. This decoupling of meta-gradient computation and choice of inner level optimizer has a number of appealing properties.</p><p>First, the inner optimization path need not be stored nor differentiated through, thereby making implicit MAML memory efficient and scalable to a large number of inner optimization steps. Second, implicit MAML is agnostic to the inner optimization method used, as long as it can find an approximate solution to the inner-level optimization problem. This permits the use of higher-order methods, and in principle even non-differentiable optimization methods or components like samplebased optimization, line-search, or those provided by proprietary software (e.g. Gurobi). Finally, we also provide the first (to our knowledge) non-asymptotic theoretical analysis of bi-level optimization. We show that an -approximate meta-gradient can be computed via implicit MAML using O(log(1/ )) gradient evaluations andÕ(1) memory, meaning the memory required does not grow with number of gradient steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Problem Formulation and Notations</head><p>We first present the meta-learning problem in the context of few-shot supervised learning, and then generalize the notation to aid the rest of the exposition in the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Review of Few-Shot Supervised Learning and MAML</head><p>In this setting, we have a collection of meta-training tasks {T i } M i=1 drawn from P (T ). Each task T i is associated with a dataset D i , from which we can sample two disjoint sets: D tr i and D test i . These datasets each consist of K input-output pairs. Let x ∈ X and y ∈ Y denote inputs and outputs, respectively. The datasets take the form D tr</p><formula xml:id="formula_0">i = {(x k i , y k i )} K k=1 , and similarly for D test i . We are interested in learning models of the form h φ (x) : X → Y, parameterized by φ ∈ Φ ≡ R d .</formula><p>Performance on a task is specified by a loss function, such as the cross entropy or squared error loss. We will write the loss function in the form L(φ, D), as a function of a parameter vector and dataset. The goal for task T i is to learn task-specific parameters φ i using D tr i such that we can minimize the population or test loss of the task, L(φ i , D test i ).</p><p>In the general bi-level meta-learning setup, we consider a space of algorithms that compute taskspecific parameters using a set of meta-parameters θ ∈ Θ ≡ R d and the training dataset from the task, such that φ i = Alg(θ, D tr i ) for task T i . The goal of meta-learning is to learn meta-parameters that produce good task specific parameters after adaptation, as specified below:</p><formula xml:id="formula_1">outer−level θ * ML := argmin θ∈Θ F (θ) , where F (θ) = 1 M M i=1 L inner−level Alg θ, D tr i , D test i .<label>(1)</label></formula><p>We view this as a bi-level optimization problem since we typically interpret Alg θ, D tr i as either explicitly or implicitly solving an underlying optimization problem. At meta-test (deployment) time, when presented with a dataset D tr j corresponding to a new task T j ∼ P (T ), we can achieve good generalization performance (i.e., low test error) by using the adaptation procedure with the metalearned parameters as φ j = Alg(θ * ML , D tr j ). In the case of MAML <ref type="bibr" target="#b14">[15]</ref>, Alg(θ, D) corresponds to one or multiple steps of gradient descent initialized at θ. For example, if one step of gradient descent is used, we have:</p><formula xml:id="formula_2">φ i ≡ Alg(θ, D tr i ) = θ − α∇ θ L(θ, D tr i ). (inner-level of MAML)<label>(2)</label></formula><p>Typically, α is a scalar hyperparameter, but can also be a learned vector <ref type="bibr" target="#b33">[34]</ref>. Hence, for MAML, the meta-learned parameter (θ * ML ) has a learned inductive bias that is particularly well-suited for finetuning on tasks from P (T ) using K samples. To solve the outer-level problem with gradient-based methods, we require a way to differentiate through Alg. In the case of MAML, this corresponds to backpropagating through the dynamics of gradient descent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Proximal Regularization in the Inner Level</head><p>To have sufficient learning in the inner level while also avoiding over-fitting, Alg needs to incorporate some form of regularization. Since MAML uses a small number of gradient steps, this corresponds to early stopping and can be interpreted as a form of regularization and Bayesian prior <ref type="bibr" target="#b19">[20]</ref>. In cases like ill-conditioned optimization landscapes and medium-shot learning, we may want to take many gradient steps, which poses two challenges for MAML. First, we need to store and differentiate through the long optimization path of Alg, which imposes a considerable computation and memory burden. Second, the dependence of the model-parameters {φ i } on the meta-parameters (θ) shrinks and vanishes as the number of gradient steps in Alg grows, making meta-learning difficult. To overcome these limitations, we consider a more explicitly regularized algorithm:</p><formula xml:id="formula_3">Alg (θ, D tr i ) = argmin φ ∈Φ L(φ , D tr i ) + λ 2 ||φ − θ|| 2 .<label>(3)</label></formula><p>The proximal regularization term in Eq. 3 encourages φ i to remain close to θ, thereby retaining a strong dependence throughout. The regularization strength (λ) plays a role similar to the learning rate (α) in MAML, controlling the strength of the prior (θ) relative to the data (D tr T ). Like α, the regularization strength λ may also be learned. Furthermore, both α and λ can be scalars, vectors, or full matrices. For simplicity, we treat λ as a scalar hyperparameter. In Eq. 3, we use to denote that the optimization problem is solved exactly. In practice, we use iterative algorithms (denoted by Alg) for finite iterations, which return approximate minimizers. We explicitly consider the discrepancy between approximate and exact solutions in our analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">The Bi-Level Optimization Problem</head><p>For notation convenience, we will sometimes express the dependence on task T i using a subscript instead of arguments, e.g. we write:</p><formula xml:id="formula_4">L i (φ) := L φ, D test i ,L i (φ) := L φ, D tr i , Alg i θ := Alg θ, D tr i .</formula><p>With this notation, the bi-level meta-learning problem can be written more generally as:</p><formula xml:id="formula_5">θ * ML := argmin θ∈Θ F (θ) , where F (θ) = 1 M M i=1 L i Alg i (θ) , and Alg i (θ) := argmin φ ∈Φ G i (φ , θ), where G i (φ , θ) =L i (φ ) + λ 2 ||φ − θ|| 2 .<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Total and Partial Derivatives</head><p>We use d to denote the total derivative and ∇ to denote partial derivative. For nested function of the form L i (φ i ) where φ i = Alg i (θ), we have from chain rule</p><formula xml:id="formula_6">d θ L i (Alg i (θ)) = dAlg i (θ) dθ ∇ φ L i (φ) | φ=Algi(θ) = dAlg i (θ) dθ ∇ φ L i (Alg i (θ))</formula><p>Note the important distinction between d θ L i (Alg i (θ)) and ∇ φ L i (Alg i (θ)). The former passes derivatives through Alg i (θ) while the latter does not. ∇ φ L i (Alg i (θ)) is simply the gradient function, i.e. ∇ φ L i (φ), evaluated at φ = Alg i (θ). Also note that d θ L i (Alg i (θ)) and ∇ φ L i (Alg i (θ)) are d-dimensional vectors, while dAlgi(θ) dθ is a (d × d)-size Jacobian matrix. Throughout this text, we will also use d θ and d dθ interchangeably.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The Implicit MAML Algorithm</head><p>Our aim is to solve the bi-level meta-learning problem in Eq. 4 using an iterative gradient based algorithm of the form θ ← θ − η d θ F (θ). Although we derive our method based on standard gradient descent for simplicity, any other optimization method, such as quasi-Newton or Newton methods, Adam <ref type="bibr" target="#b27">[28]</ref>, or gradient descent with momentum can also be used without modification. The gradient descent update be expanded using the chain rule as</p><formula xml:id="formula_7">θ ← θ − η 1 M M i=1 dAlg i (θ) dθ ∇ φ L i (Alg i (θ)).<label>(5)</label></formula><formula xml:id="formula_8">Here, ∇ φ L i (Alg i (θ)) is simply ∇ φ L i (φ) | φ=Alg i (θ)</formula><p>which can be easily obtained in practice via automatic differentiation. For this update rule, we must compute</p><formula xml:id="formula_9">dAlg i (θ) dθ ,</formula><p>where Alg i is implicitly defined as an optimization problem (Eq. 4), which presents the primary challenge. We now present an efficient algorithm (in compute and memory) to compute the meta-gradient..</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Meta-Gradient Computation</head><p>If Alg i (θ) is implemented as an iterative algorithm, such as gradient descent, then one way to compute</p><formula xml:id="formula_10">dAlg i (θ) dθ</formula><p>is to propagate derivatives through the iterative process, either in forward mode or reverse mode. However, this has the drawback of depending explicitly on the path of the optimization, which has to be fully stored in memory, quickly becoming intractable when the number of gradient steps needed is large. Furthermore, for second order optimization methods, such as Newton's method, third derivatives are needed which are difficult to obtain. Furthermore, this approach becomes impossible when non-differentiable operations, such as line-searches, are used. However, by recognizing that Alg i is implicitly defined as the solution to an optimization problem, we may employ a different strategy that does not need to consider the path of the optimization but only the final result. This is derived in the following Lemma. Lemma 1. (Implicit Jacobian) Consider Alg i (θ) as defined in Eq. 4 for task</p><formula xml:id="formula_11">T i . Let φ i = Alg i (θ) be the result of Alg i (θ). If I + 1 λ ∇ 2 φL i (φ i ) is invertible, then the derivative Jacobian is dAlg i (θ) dθ = I + 1 λ ∇ 2 φLi (φ i ) −1 .<label>(6)</label></formula><p>Note that the derivative (Jacobian) depends only on the final result of the algorithm, and not the path taken by the algorithm. Thus, in principle any approach of algorithm can be used to compute Alg i (θ), thereby decoupling meta-gradient computation from choice of inner level optimizer.</p><p>Practical Algorithm: While Lemma 1 provides an idealized way to compute the Alg i Jacobians and thus by extension the meta-gradient, it may be difficult to directly use it in practice. Two issues are particularly relevant. First, the meta-gradients require computation of Alg i (θ), which is the exact solution to the inner optimization problem. In practice, we may be able to obtain only approximate solutions. Second, explicitly forming and inverting the matrix in Eq. 6 for computing the Jacobian may be intractable for large deep neural networks. To address these difficulties, we consider approximations to the idealized approach that enable a practical algorithm.</p><p>First, we consider an approximate solution to the inner optimization problem, that can be obtained with iterative optimization algorithms like gradient descent. Definition 1. (δ-approx. algorithm) Let Alg i (θ) be a δ-accurate approximation of Alg i (θ), i.e. Sample mini-batch of tasks</p><formula xml:id="formula_12">Alg i (θ) − Alg i (θ) ≤ δ</formula><formula xml:id="formula_13">{T i } B i=1 ∼ P (T ) 4:</formula><p>for Each task T i do 5:</p><p>Compute task meta-gradient g i = Implicit-Meta-Gradient(T i , θ, λ) 6: end for 7:</p><p>Average above gradients to get∇F (θ) = (1/B)</p><formula xml:id="formula_14">B i=1 g i 8:</formula><p>Update meta-parameters with gradient descent: θ ← θ − η∇F (θ) // (or Adam) 9: end while Algorithm 2 Implicit Meta-Gradient Computation 1: Input: Task T i , meta-parameters θ, regularization strength λ 2: Hyperparameters: Optimization accuracy thresholds δ and δ 3: Obtain task parameters φ i using iterative optimization solver such that:</p><formula xml:id="formula_15">φ i − Alg i (θ) ≤ δ 4: Compute partial outer-level gradient v i = ∇ φ L T (φ i ) 5:</formula><p>Use an iterative solver (e.g. CG) along with reverse mode differentiation (to compute Hessian vector products) to compute g i such that:</p><formula xml:id="formula_16">g i − I + 1 λ ∇ 2L i (φ i ) −1 v i ≤ δ 6: Return: g i</formula><p>Second, we will perform a partial or approximate matrix inversion given by: Definition 2. (δ -approximate Jacobian-vector product) Let g i be a vector such that</p><formula xml:id="formula_17">g i − I + 1 λ ∇ 2 φLi (φ i ) −1 ∇ φ L i (φ i ) ≤ δ where φ i = Alg i (θ)</formula><p>and Alg i is based on definition 1.</p><p>Note that g i in definition 2 is an approximation of the meta-gradient for task T i . Observe that g i can be obtained as an approximate solution to the optimization problem:</p><formula xml:id="formula_18">min w w I + 1 λ ∇ 2 φLi (φ i ) w − w ∇ φ L i (φ i )<label>(7)</label></formula><p>The conjugate gradient (CG) algorithm is particularly well suited for this problem due to its excellent iteration complexity and requirement of only Hessian-vector products of the form ∇ 2L i (φ i )v. Such hessian-vector products can be obtained cheaply without explicitly forming or storing the Hessian matrix (as we discuss in Appendix C). This CG based inversion has been successfully deployed in Hessian-free or Newton-CG methods for deep learning <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b43">44]</ref> and trust region methods in reinforcement learning <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b46">47]</ref>. Algorithm 1 presents the full practical algorithm. Note that these approximations to develop a practical algorithm introduce errors in the meta-gradient computation. We analyze the impact of these errors in Section 3.2 and show that they are controllable. See Appendix A for how iMAML generalizes prior gradient optimization based meta-learning algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Theory</head><p>In Section 3.1, we outlined a practical algorithm that makes approximations to the idealized update rule of Eq. 5. Here, we attempt to analyze the impact of these approximations, and also understand the computation and memory requirements of iMAML. We find that iMAML can match the minimax computational complexity of backpropagating through the path of the inner optimizer, but is substantially better in terms of memory usage. This work to our knowledge also provides the first non-asymptotic result that analyzes approximation error due to implicit gradients. Theorem 1 provides the computational and memory complexity for obtaining an -approximate meta-gradient. We assume L i is smooth but do not require it to be convex. We assume that G i in Eq. 4 is strongly convex, which can be made possible by appropriate choice of λ. The key to our analysis is a second order Lipshitz assumption, i.e.L i (·) is ρ-Lipshitz Hessian. This assumption and setting has received considerable attention in recent optimization and deep learning literature <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b41">42]</ref>. <ref type="table">Table 1</ref>: Compute and memory for computing the meta-gradient when using a δ-accurate Algi, and the corresponding approximation error. Our compute time is measured in terms of the number of ∇Li computations. All results are inÕ(·) notation, which hide additional log factors; the error bound hides additional problem dependent Lipshitz and smoothness parameters (see the respective Theorem statements). κ ≥ 1 is the condition number for inner objective Gi (see <ref type="bibr">Equation 4</ref>), and D is the diameter of the search space. The notions of error are subtly different: we assume all methods solve the inner optimization to error level of δ (as per definition 1). For our algorithm, the error refers to the 2 error in the computation of d θ Li(Alg i (θ)). For the other algorithms, the error refers to the 2 error in the computation of d θ Li(Algi(θ)). We use Prop 3.1 of Shaban et al. <ref type="bibr" target="#b52">[53]</ref> to provide the guarantee we use. See Appendix D for additional discussion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm</head><p>Compute Memory Error <ref type="table">Table 1</ref> summarizes our complexity results and compares with MAML and truncated backpropagation <ref type="bibr" target="#b52">[53]</ref> through the path of the inner optimizer. We use κ to denote the condition number of the inner problem induced by G i (see <ref type="bibr">Equation 4</ref>), which can be viewed as a measure of hardness of the inner optimization problem. Mem(∇L i ) is the memory taken to compute a single derivative ∇L i . Under the assumption that Hessian vector products are computed with the reverse mode of autodifferentiation, we will have that both: the compute time and memory used for computing a Hessian vector product are with a (universal) constant factor of the compute time and memory used for computing ∇L i itself (see Appendix C). This allows us to measure the compute time in terms of the number of ∇L i computations. We refer readers to Appendix D for additional discussion about the algorithms and their trade-offs.</p><formula xml:id="formula_19">MAML (GD + full back-prop) κ log D δ Mem(∇Li) · κ log D δ 0 MAML (Nesterov's AGD + full back-prop) √ κ log D δ Mem(∇Li) · √ κ log D δ 0 Truncated back-prop [53] (GD) κ log D δ Mem(∇Li) · κ log 1 Implicit MAML (this work) √ κ log D δ Mem(∇Li) δ</formula><p>Our main theorem is as follows: Theorem 1. (Informal Statement; Approximation error in Algorithm 2) Suppose that: L i (·) is B Lipshitz and L smooth function; that G i (·, θ) (in Eq. 4) is a µ-strongly convex function with condition number κ; that D is the diameter of search space for φ in the inner optimization problem (i.e. Alg i (θ) ≤ D); andL i (·) is ρ-Lipshitz Hessian.</p><p>Let g i be the task meta-gradient returned by Algorithm 2. For any task i and desired accuracy level , Algorithm 2 computes an approximate task-specific meta-gradient with the following guarantee:</p><formula xml:id="formula_20">||g i − d θ L i (Alg i (θ))|| ≤ .</formula><p>Furthermore, under the assumption that the Hessian vector products are computed by the reverse mode of autodifferentiation (Assumption 1), Algorithm 2 can be implemented using at most O √ κ log poly(κ,D,B,L,ρ,µ,λ) gradient computations ofL i (·) and using at most 2 · Mem(∇L i ) memory.</p><p>The formal statement of the theorem and the proof are provided the appendix. Importantly, the algorithm's memory requirement is equivalent to the memory needed for Hessian-vector products which is a small constant factor over the memory required for gradient computations, assuming the reverse mode of auto-differentiation is used. Finally, the next corollary shows that iMAML efficiently finds a stationary point of F (·), due to iMAML having controllable exact-solve error. Corollary 1. (iMAML finds stationary points) Suppose the conditions of Theorem 1 hold and that F (·) is an L F smooth function. Then the implicit MAML algorithm (Algorithm 1), when the batch size is M (so that we are doing gradient descent), will find a point θ such that:</p><p>∇F (θ) ≤ in a number of calls to Implicit-Meta-Gradient that is at most</p><formula xml:id="formula_21">4M L f (F (0)−min θ F (θ)) 2</formula><p>. Furthermore, the total number of gradient computations (of ∇L i ) is at most</p><formula xml:id="formula_22">O M √ κ L f (F (0)−min θ F (θ)) 2</formula><p>log poly(κ,D,B,L,ρ,µ,λ) , and onlyÕ(Mem(∇L i )) memory is required throughout.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Results and Discussion</head><p>In our experimental evaluation, we aim to answer the following questions empirically: (1) Does the iMAML algorithm asymptotically compute the exact meta-gradient? (2) With finite iterations, does iMAML approximate the meta-gradient more accurately compared to MAML? (3) How does the computation and memory requirements of iMAML compare with MAML? (4) Does iMAML lead to better results in realistic meta-learning problems? We have answered (1) -(3) through our theoretical analysis, and now attempt to validate it through numerical simulations. For <ref type="formula" target="#formula_1">(1)</ref> and <ref type="formula" target="#formula_2">(2)</ref>, we will use a simple synthetic example for which we can compute the exact meta-gradient and compare against it (exact-solve error, see definition 3). For <ref type="formula" target="#formula_3">(3)</ref> and <ref type="formula" target="#formula_5">(4)</ref>, we will use the common few-shot image recognition domains of Omniglot and Mini-ImageNet.</p><p>To study the question of meta-gradient accuracy, <ref type="figure" target="#fig_2">Figure 2</ref> considers a synthetic regression example, where the predictions are linear in parameters. This provides an analytical expression for Alg i allowing us to compute the true meta-gradient. We fix gradient descent (GD) to be the inner optimizer for both MAML and iMAML. The problem is constructed so that the condition number (κ) is large, thereby necessitating many GD steps. We find that both iMAML and MAML asymptotically match the exact meta-gradient, but iMAML computes a better approximation in finite iterations. We observe that with 2 CG iterations, iMAML incurs a small terminal error. This is consistent with our theoretical analysis. In Algorithm 2, δ is dominated by δ when only a small number of CG steps are used. However, the terminal error vanishes with just 5 CG steps. The computational cost of 1 CG step is comparable to 1 inner GD step with the MAML algorithm, since both require 1 hessianvector product (see section C for discussion). Thus, the computational cost as well as memory of iMAML with 100 inner GD steps is significantly smaller than MAML with 100 GD steps.</p><p>To study <ref type="formula" target="#formula_3">(3)</ref>, we turn to the Omniglot dataset <ref type="bibr" target="#b29">[30]</ref> which is a popular few-shot image recognition domain. <ref type="figure" target="#fig_2">Figure 2</ref> presents compute and memory trade-off for MAML and iMAML (on 20-way, 5-shot Omniglot). Memory for iMAML is based on Hessian-vector products and is independent of the number of GD steps in the inner loop. The memory use is also independent of the number of CG iterations, since the intermediate computations need not be stored in memory. On the other hand, memory for MAML grows linearly in grad steps, reaching the capacity of a 12 GB GPU in approximately 16 steps. First-order MAML (FOMAML) does not back-propagate through the optimization process, and thus the computational cost is only that of performing gradient descent, which is needed for all the algorithms. The computational cost for iMAML is also similar to FOMAML along with a constant overhead for CG that depends on the number of CG steps. Note however, that FOMAML does not compute an accurate meta-gradient, since it ignores the Jacobian. Compared to FOMAML, the compute cost of MAML grows at a faster rate. FOMAML requires only gradient computations, while backpropagating through GD (as done in MAML) requires a Hessian-vector products at each iteration, which are more expensive.</p><p>Finally, we study empirical performance of iMAML on the Omniglot and Mini-ImageNet domains. Following the few-shot learning protocol in prior work <ref type="bibr" target="#b56">[57]</ref>, we run the iMAML algorithm on the   <ref type="bibr" target="#b42">[43]</ref>. iMAML with gradient descent (GD) uses 16 and 25 steps for 5-way and 20-way tasks respectively. iMAML with Hessian-free uses 5 CG steps to compute the search direction and performs line-search to pick step size. Both versions of iMAML use λ = 2.0 for regularization, and 5 CG steps to compute the task meta-gradient.</p><p>Algorithm 5-way 1-shot 5-way 5-shot 20-way 1-shot 20-way 5-shot MAML <ref type="bibr" target="#b14">[15]</ref> 98.7 ± 0.4% 99.9 ± 0.1% 95.8 ± 0.3% 98.9 ± 0.2% first-order MAML <ref type="bibr" target="#b14">[15]</ref> 98.3 ± 0.5% 99.2 ± 0.2% 89.4 ± 0.5% 97.9 ± 0.1% Reptile <ref type="bibr" target="#b42">[43]</ref> 97.68 ± 0.04% 99. <ref type="bibr" target="#b47">48</ref>  dataset for different numbers of class labels and shots (in the N-way, K-shot setting), and compare two variants of iMAML with published results of the most closely related algorithms: MAML, FOMAML, and Reptile. While these methods are not state-of-the-art on this benchmark, they provide an apples-to-apples comparison for studying the use of implicit gradients in optimization-based meta-learning. For a fair comparison, we use the identical convolutional architecture as these prior works. Note however that architecture tuning can lead to better results for all algorithms <ref type="bibr" target="#b26">[27]</ref>.</p><p>The first variant of iMAML we consider involves solving the inner level problem (the regularized objective function in Eq. 4) using gradient descent. The meta-gradient is computed using conjugate gradient, and the meta-parameters are updated using Adam. This presents the most straightforward comparison with MAML, which would follow a similar procedure, but backpropagate through the path of optimization as opposed to invoking implicit differentiation. The second variant of iMAML uses a second order method for the inner level problem. In particular, we consider the Hessian-free or Newton-CG <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b35">36]</ref> method. This method makes a local quadratic approximation to the objective function (in our case, G(φ , θ) and approximately computes the Newton search direction using CG.</p><p>Since CG requires only Hessian-vector products, this way of approximating the Newton search direction is scalable to large deep neural networks. The step size can be computed using regularization, damping, trust-region, or linesearch. We use a linesearch on the training loss in our experiments to also illustrate how our method can handle non-differentiable inner optimization loops. We refer the readers to Nocedal &amp; Wright <ref type="bibr" target="#b43">[44]</ref> and Martens <ref type="bibr" target="#b35">[36]</ref> for a more detailed exposition of this optimization algorithm. Similar approaches have also gained prominence in reinforcement learning <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b46">47]</ref>.  <ref type="table" target="#tab_0">Tables 2 and 3</ref> present the results on Omniglot and Mini-ImageNet, respectively. On the Omniglot domain, we find that the GD version of iMAML is competitive with the full MAML algorithm, and substatially better than its approximations (i.e., first-order MAML and Reptile), especially for the harder 20-way tasks. We also find that iMAML with Hessian-free optimization performs substantially better than the other methods, suggesting that powerful optimizers in the inner loop can offer benifits to meta-learning. In the Mini-ImageNet domain, we find that iMAML performs better than MAML and FOMAML. We used λ = 0.5 and 10 gradient steps in the inner loop. We did not perform an extensive hyperparameter sweep, and expect that the results can improve with better hyperparameters. 5 CG steps were used to compute the meta-gradient. The Hessian-free version also uses 5 CG steps for the search direction. Additional experimental details are Appendix F.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Our work considers the general meta-learning problem <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b40">41]</ref>, including few-shot learning <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b56">57]</ref>. Meta-learning approaches can generally be categorized into metric-learning approaches that learn an embedding space where non-parametric nearest neighbors works well <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b2">3]</ref>, black-box approaches that train a recurrent or recursive neural network to take datapoints as input and produce weight updates <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b47">48]</ref> or predictions for new inputs <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b37">38]</ref>, and optimization-based approaches that use bi-level optimization to embed learning procedures, such as gradient descent, into the meta-optimization problem <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b22">23]</ref>. Hybrid approaches have also been considered to combine the benefits of different approaches <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b55">56]</ref>. We build upon optimization-based approaches, particularly the MAML algorithm <ref type="bibr" target="#b14">[15]</ref>, which metalearns an initial set of parameters such that gradient-based fine-tuning leads to good generalization. Prior work has considered a number of inner loops, ranging from a very general setting where all parameters are adapted using gradient descent <ref type="bibr" target="#b14">[15]</ref>, to more structured and specialized settings, such as ridge regression <ref type="bibr" target="#b7">[8]</ref>, Bayesian linear regression <ref type="bibr" target="#b22">[23]</ref>, and simulated annealing <ref type="bibr" target="#b1">[2]</ref>. The main difference between our work and these approaches is that we show how to analytically derive the gradient of the outer objective without differentiating through the inner learning procedure.</p><p>Mathematically, we view optimization-based meta-learning as a bi-level optimization problem. Such problems have been studied in the context of few-shot meta-learning (as discussed previously), gradient-based hyperparameter optimization <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b9">10]</ref>, and a range of other settings <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b30">31]</ref>. Some prior works have derived implicit gradients for related problems <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b3">4]</ref> while others propose innovations to aid back-propagation through the optimization path for specific algorithms <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b23">24]</ref>, or approximations like truncation <ref type="bibr" target="#b52">[53]</ref>. While the broad idea of implicit differentiation is well known, it has not been empirically demonstrated in the past for learning more than a few parameters (e.g., hyperparameters), or highly structured settings such as quadratic programs <ref type="bibr" target="#b3">[4]</ref>. In contrast, our method meta-trains deep neural networks with thousands of parameters. Closest to our setting is the recent work of Lee et al. <ref type="bibr" target="#b31">[32]</ref>, which uses implicit differentiation for quadratic programs in a final SVM layer. In contrast, our formulation allows for adapting the full network for generic objectives (beyond hinge-loss), thereby allowing for wider applications.</p><p>We also note that prior works involving implicit differentiation make a strong assumption of an exact solution in the inner level, thereby providing only asymptotic guarantees. In contrast, we provide finite time guarantees which allows us to analyze the case where the inner level is solved approximately. In practice, the inner level is likely to be solved using iterative optimization algorithms like gradient descent, which only return approximate solutions with finite iterations. Thus, this paper places implicit gradient methods under a strong theoretical footing for practically use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we develop a method for optimization-based meta-learning that removes the need for differentiating through the inner optimization path, allowing us to decouple the outer metagradient computation from the choice of inner optimization algorithm. We showed how this gives us significant gains in compute and memory efficiency, and also conceptually allows us to use a variety of inner optimization methods. While we focused on developing the foundations and theoretical analysis of this method, we believe that this work opens up a number of interesting avenues for future study.</p><p>Broader classes of inner loop procedures. While we studied different gradient-based optimization methods in the inner loop, iMAML can in principle be used with a variety of inner loop algorithms, including dynamic programming methods such as Q-learning, two-player adversarial games such as GANs, energy-based models <ref type="bibr" target="#b38">[39]</ref>, and actor-critic RL methods, and higher-order model-based trajectory optimization methods. This significantly expands the kinds of problems that optimizationbased meta-learning can be applied to.</p><p>More flexible regularizers. We explored one very simple regularization, 2 regularization to the parameter initialization, which already increases the expressive power over the implicit regularization that MAML provides through truncated gradient descent. To further allow the model to flexibly regularize the inner optimization, a simple extension of iMAML is to learn a vector-or matrix-valued λ, which would enable the meta-learner model to co-adapt and co-regularize various parameters of the model. Regularizers that act on parameterized density functions would also enable meta-learning to be effective for few-shot density estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Relationship between iMAML and Prior Algorithms</head><p>The presented iMAML algorithm has close connections, as well as notable differences, to a number of related algorithms like MAML <ref type="bibr" target="#b14">[15]</ref>, first-order MAML, and Reptile <ref type="bibr" target="#b42">[43]</ref>. Conventionally, these algorithms do not consider any explicit regularization in the inner-level and instead rely on early stopping, through only a few gradient descent steps. In our problem setting described in Eq. 4, we consider an explicitly regularized inner-level problem (refer to discussion in Section 2.2). We describe the connections between the algorithms in this explicitly regularized setting below. and that f is µ-strongly convex if f is convex and if for all x, x ∈ R d ,</p><formula xml:id="formula_23">||∇f (x) − ∇f (x )|| ≥ µ||x − x || .</formula><p>We will make use of the following black-box complexity of first-order gradient methods for minimizing strongly convex and smooth functions. Lemma 2. (δ-approximate solver; see <ref type="bibr" target="#b8">[9]</ref>) Suppose f is a function that is L-smooth and µ strongly convex. Define κ := L/µ, and let x = argmin f (x). Nesterov's accelerated gradient descent can be used to find a point x such that:</p><p>x − x ≤ δ using a number of gradient computations of f that is bounded as follows:</p><formula xml:id="formula_24"># gradient computations of f (·) ≤ 2 √ κ log 2κ x δ .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Review: Time and Space Complexity of Hessian-Vector Products</head><p>We briefly discuss the time and space complexity of Hessian-vector product computation using the reverse mode of automatic differentiation. The reverse mode of automatic differentiation <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b21">22]</ref> is the widely used method for automatic differentiation in modern software packages like TensorFlow and PyTorch <ref type="bibr" target="#b6">[7]</ref>. Recall that for a differentiable function f (x), the reverse mode of automatic differentiation computes ∇f (x) in time that is no more than a factor of 5 of the time it takes to compute f (x) itself (see <ref type="bibr" target="#b21">[22]</ref> for review). As our algorithm makes use of Hessian vector products, we will make use of the following assumption as to how Hessian vector products will be computed when executing Algorithm 2.</p><p>Assumption 1. (Complexity of Hessian-vector product) We assume that the time to compute the Hessian-vector product ∇ 2 φL i (φ)v is no more than a (universal) constant over the time used to compute ∇L i (φ) (typically, this constant is 5). Furthermore, we assume that the memory used to compute the Hessian-vector product ∇ 2 φL i (φ)v is no more than twice the memory used when computing ∇L i (φ). This assumption is valid if the reverse mode of automatic differentiation is used to compute Hessian vector products (see <ref type="bibr" target="#b20">[21]</ref>).</p><p>A few remarks about this assumption are in order. With regards to computation, first observe that the gradient of the scalar function ∇ φLi (φ) v is the desired Hessian vector product ∇ 2 φL i (φ)v. Thus computing the Hessian vector product using the reverse mode is within a constant factor of computing the function itself, which is simply the cost of computing ∇L i (φ) v. The issue of memory is more subtle (see <ref type="bibr" target="#b20">[21]</ref>), which we now discuss. The memory used to compute the gradient of a scalar cost function f (x) using the reverse mode of auto-differentiation is proportional to the size of the computation graph; precisely, the memory required to compute the gradient is equal to the total space required to store all the intermediate variables used when computing f (x). In practice, this is often much larger than the memory required to compute f (x) itself, due to that all intermediate variables need not be simultaneously stored in memory when computing f (x). However, for the special case of computing the gradient of the function f (φ) = ∇ φLi (φ) v, the factor of 2 in the memory bound is a consequence of the following reason: first, using the reverse mode to compute f (φ) means we already have stored the computation graph ofL i (φ) itself. Furthermore, the size of the computation graph for computing f (φ) = ∇ φLi (φ) v is essentially the same size as the computation graph ofL i (φ). This leads to the factor of 2 memory bound; see Griewank <ref type="bibr" target="#b20">[21]</ref> for further discussion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Additional Discussion About Compute and Memory Complexity</head><p>Our main complexity results are summarized in <ref type="table">Table 1</ref>. For these results, we consider two notions of error that are subtly different, which we explicitly define below. Let g i be the computed metagradient for task T i . Then, the errors we consider are: Definition 3. Exact-solve error (our notion of error): Our goal is to accurately compute the gradient of F (θ) as defined in <ref type="bibr">Equation 4</ref>, where Alg i (θ) is an exact algorithm. Specifically, we seek to compute a g i such that:</p><formula xml:id="formula_25">g i − d θ L i (Alg i (θ)) ≤</formula><p>where is the error in the gradient computation. Definition 4. Approx-solve error: Here we suppose that Alg i computes a δ-accurate solution to the inner optimization problem over G i in Eq. 4, i.e. that Alg i satisfies Alg i (θ) − Alg i (θ) ≤ δ, as per definition 1. Then the objective is to compute a g such that:</p><formula xml:id="formula_26">g − d θ L i (Alg i (θ)) ≤</formula><p>where is the error in the gradient computation of d θ L i (Alg i (θ)). Subtly, note that the gradient is with respect to the δ-approximate algorithm, as opposed to using Alg i .</p><p>For the complexity results, we assume that MAML invokes Alg i to get a δ-approximate solution for inner problem (recall definition 1). The exact-solve error for MAML is not known in the literature; in particular, even as δ → 0 it is not evident if the approx-solve solution tends to the exact-solve solution, unless further regularity conditions are imposed. The approx-solve error for MAML is 0, ignoring finite-precision and numerical issues, since it backpropagates through the path. Truncated backprop <ref type="bibr" target="#b52">[53]</ref> also invokes Alg i to obtain a δ-approximate solution but instead performs a truncated or partial back-propagation so that it uses a smaller number of iterations when computing the gradient through the path of Alg i (θ). Exact-solve error for truncated backprop is also not known, but a small approx-solve error can be obtained with less memory than full back-prop. We use Prop 3.1 of Shaban et al. <ref type="bibr" target="#b52">[53]</ref> to provide a guarantee that leads to an -accurate approximation of the full-backprop (i.e. MAML) gradient. It is not evident how accurate the truncated procedure is when an accelerated method is used instead. Finally, our iMAML algorithm also invokes an approximate solver Alg i rather than Alg i . However, importantly, we guarantee a small exact-solve error even though we do not require access to Alg i . Furthermore, the iMAML algorithm also requires substantially less memory. Up to small constant factors, it only utilizes the memory required for computing a single gradient ofL i (·).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Proofs</head><p>Lemma 1, restated. Consider Alg i (θ) as defined in Eq. 4 for task T i . Let φ i = Alg i (θ) be the result of Alg i (θ). If I + 1 λ ∇ 2 φL i (φ i ) is invertible, then the derivative Jacobian is</p><formula xml:id="formula_27">dAlg i (θ) dθ = I + 1 λ ∇ 2 φLi (φ i ) −1 .</formula><p>Proof. We drop the task i subscripts in the proof for convenience. Since φ = Alg (θ) is the minimizer of G(φ , θ) in Eq. 4, the stationary point conditions imply that</p><formula xml:id="formula_28">∇ φ G(φ , θ) | φ =φ = 0 =⇒ ∇L(φ) + λ(φ − θ) = 0 =⇒ φ = θ − 1 λ ∇L(φ),</formula><p>which is an implicit equation that often arises in proximal point methods. When the derivative exists, we can differentiate the above equation to obtain:</p><formula xml:id="formula_29">dφ dθ = I − 1 λ ∇ 2L (φ) dφ dθ =⇒ I + 1 λ ∇ 2L (φ) dφ dθ = I.</formula><p>which completes the proof.</p><p>Recall that:</p><formula xml:id="formula_30">G i (φ , θ) :=L i (φ ) + λ 2 ||φ − θ|| 2 .</formula><p>Assumption 2. (Regularity conditions) Suppose the following holds for all tasks i:</p><formula xml:id="formula_31">1. L i (·) is B Lipshitz and L smooth.</formula><p>2. For all θ, G i (·, θ) is both a β-smooth function and a µ-strongly convex function. Define:</p><formula xml:id="formula_32">κ := β µ . 3.L i (·) is ρ-Lipshitz Hessian, i.e. ∇ 2L i (·) is ρ-Lipshitz.</formula><p>4. For all θ, suppose the arg-minimizer of G i (·, θ) is unique and bounded in a ball of radius D, i.e. for all θ,</p><formula xml:id="formula_33">Alg i (θ) ≤ D .</formula><p>Lemma 3. (Implicit Gradient Accuracy) Suppose Assumption 2 holds. Fix a task i. Suppose that φ i satisfies:</p><formula xml:id="formula_34">φ i − Alg i (θ) ≤ δ</formula><p>and that g i satisfies:</p><formula xml:id="formula_35">g i − I + 1 λ ∇ 2L i (φ) −1 ∇ φ L i (φ) ≤ δ .</formula><p>Assuming that δ &lt; µ/(2ρ), we have that:</p><formula xml:id="formula_36">g i − d θ L i (Alg i (θ)) ≤ 2 λρ µ 2 B + λL µ δ + δ</formula><p>Proof. First, observe that:</p><formula xml:id="formula_37">d θ L i (Alg i (θ)) = I + 1 λ ∇ 2L i (Alg i (θ)) −1 ∇ φ L i (Alg i (θ))</formula><p>For notational convenience, we drop the i subscripts within the proof. We have:</p><formula xml:id="formula_38">d θ L(Alg (θ)) − g ≤ d θ L(Alg (θ)) − I + 1 λ ∇ 2L (φ) −1 ∇ φ L(φ) + δ ≤ d θ L(Alg (θ)) − I + 1 λ ∇ 2L (φ) −1 ∇ φ L(Alg (θ)) + I + 1 λ ∇ 2L (φ) −1 (∇ φ L(Alg (θ)) − ∇ φ L(φ)) + δ</formula><p>where the first inequality uses the triangle inequality.</p><p>We now bound each of these terms. For the second term,</p><formula xml:id="formula_39">I + 1 λ ∇ 2L (φ) −1 (∇ φ L(Alg (θ)) − ∇ φ L(φ)) ≤ I + 1 λ ∇ 2L (φ) −1 ∇ φ L(Alg (θ)) − ∇ φ L(φ) ≤ λL λI + ∇ 2L (φ) −1 Alg (θ) − φ = λL ∇ 2 φ G(φ, θ) −1 Alg (θ) − φ ≤ λL µ δ</formula><p>where we the second inequality uses that ∇ φ L is L-smooth and the final inequality uses that G is µ strongly convex.</p><p>For the first term, we have:</p><p>To ensure the bound of δ , the algorithm will be solving the sub-problem in Equation <ref type="bibr" target="#b6">7</ref>. First observe that in the context of in Lemma 2, note that x = I + 1 λ ∇ 2L i (φ) −1 ∇L i (φ) ≤ (λ/µ)B, and so it suffices to use a number of iterations that is bounded by:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">log 2κ</head><p>x δ ≤ 2 log 4κ (λ/µ)B , which completes the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Experiment Details</head><p>Here, we provide additional details of the experimental set-up for the experiments in Section 4. All training runs were conducted on a single NVIDIA (Titan Xp) GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.1 Synthetic Experiments</head><p>For the synthetic experiments, we consider a linear regression problem. We consider parametric models of the form h φ (x) = φ T x, where x can either be the raw inputs or features (e.g. Fourier features) of the input. For task T i , we can equivalently write a quadratic objective that represents the task loss as:L</p><formula xml:id="formula_40">i (φ) = 1 2 E (x,y)∼D tr i h φ (x) − y 2 = 1 2 φ T A i φ + φ T b i ,</formula><p>where A i = E (x,y)∼D tr i xx T and b i = E (x,y)∼D tr i x T y . Thus, the inner level objective and corresponding minimizer can be written as:</p><formula xml:id="formula_41">G i (φ , θ) = 1 2 φ T A i φ + φ T b i + λ 2 (φ − θ) T (φ − θ) Alg i (θ) = (A i + λI) −1 (λθ − b i )</formula><p>Thus, the exact meta-gradient can be written as d θ L i (Alg i (θ)) = λ(A i + λI) −1 ∇ φ L i (θ) | φ=Alg i (θ) .</p><p>We compare this gradient with the gradients computed by the iMAML and MAML algorithms. We considered the case of x ∈ R 50 , y ∈ R, λ = 5.0, and κ = 50, for the presented results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.2 Omniglot and Mini-ImageNet experiments</head><p>We follow the standard training and evaluation protocol as in prior works <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b14">15]</ref>.</p><p>Omniglot Experiments The GD version of iMAML uses 16 gradient steps for 5-way 1-shot and 5-way 5-shot settings, and 25 gradient steps for 20-way 1-shot and 20-way 5-shot settings. A regularization strength of λ = 2.0 was used for both. 5 steps of conjugate gradient was used to compute the meta-gradient for each task in the mini-batch, and the meta-gradients were averaged before taking a step with the default parameters of Adam in the outer loop.</p><p>The Hessian-free version of MAML proceeds by using Hessian-free or Newton-CG method for solving the inner optimization problem (with respect to φ) with objective G i (φ, θ). This method proceeds by constructing a local quadratic approximation to the objective and approximately computing the Newton direction with conjugate gradient. 5 CG steps are used for this process in our experiments. This allows us to compute the search direction, following which a step size has to be picked. We pick the step size through line-search. This procedure of computing the approximate Newton direction and linesearch is repeated 3 times in our experiments to solve the inner optimization problem well.</p><p>Mini-ImageNet For the GD version of iMAML, 10 GD steps were used with regularization strength of λ = 0.5. Again, 5 CG steps are used to compute the meta-gradient. Similarly, in the Hessian-Free variant, we again use 5 CG steps to compute the search direction followed by line search. This process is repeated 3 times to solve the inner level optimization. Again, to compute the meta-gradient, 5 steps of CG are used.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>To compute the meta-gradient i dLi(φi) dθ</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Algorithm 1 1 :</head><label>11</label><figDesc>Implicit Model-Agnostic Meta-Learning (iMAML) Require: Distribution over tasks P (T ), outer step size η, regularization strength λ,2:  while not converged do3:    </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Accuracy, Computation, and Memory tradeoffs of iMAML, MAML, and FOMAML. (a) Metagradient accuracy level in synthetic example. Computed gradients are compared against the exact meta-gradient per Def 3. (b) Computation and memory trade-offs with 4 layer CNN on 20-way-5-shot Omniglot task. We implemented iMAML in PyTorch, and for an apples-to-apples comparison, we use a PyTorch implementation of MAML from: https://github.com/dragen1860/MAML-Pytorch</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2 :</head><label>2</label><figDesc>Omniglot results. MAML results are taken from the original work of Finn et al. [15], and first-order MAML and Reptile results are from Nichol et al.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table><row><cell cols="2">Mini-ImageNet 5-way-1-shot accuracy</cell></row><row><cell>Algorithm</cell><cell>5-way 1-shot</cell></row><row><cell>MAML</cell><cell>48.70 ± 1.84 %</cell></row><row><cell>first-order MAML</cell><cell>48.07 ± 1.75 %</cell></row><row><cell>Reptile</cell><cell>49.97 ± 0.32 %</cell></row><row><cell cols="2">iMAML GD (ours) 48.96 ± 1.84 %</cell></row><row><cell cols="2">iMAML HF (ours) 49.30 ± 1.88 %</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The conjugate gradient descent algorithm also suffices and give a slightly improved iteration complexity in terms of log factors.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>Aravind Rajeswaran thanks Emo Todorov for valuable discussions about implicit gradients and potential application domains; Aravind Rajeswaran also thanks Igor Mordatch and Rahul Kidambi for helpful discussions and feedback. Sham Kakade acknowledges funding from the Washington Research Foundation for innovation in Data-intensive Discovery; Sham Kakade also graciously acknowledges support from ONR award N00014-18-1-2247, NSF Award CCF-1703574, and NSF CCF 1740551 award.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Due to that ∇ 2L (·) is Lipshitz Hessian, ∆ ≤ ρδ. Also, by our assumption on δ, we have that:</p><p>The proof is completed by substitution.</p><p>Theorem 2. (Approximate Implicit Gradient Computation) Suppose Assumption 2 holds. Fix a task i. Let</p><p>Suppose Nesterov's accelerated gradient descent algorithm is used to compute φ (as desired in Algorithm 2), using a number of iterations that is:</p><p>and suppose Nesterov's accelerated gradient descent algorithm (or the conjugate gradient algorithm 1 ) is used to compute g i using a number of iterations that is:</p><p>We have that:</p><p>Proof. The result will follow from the guarantees in Lemma 2. Specifically, let us set δ = min{ /(2B 1 ), µ/(2ρ)} and δ = /2. To ensure the bound of δ, by Lemma 3, it suffices to use a number of iterations that is bounded by:</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Continuous adaptation via meta-learning in nonstationary and competitive environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maruan</forename><surname>Al-Shedivat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trapit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuri</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Mordatch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<idno>abs/1710.03641</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferran</forename><surname>Alet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomás</forename><surname>Lozano-Pérez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leslie</forename><forename type="middle">P</forename><surname>Kaelbling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.10166</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">Modular meta-learning. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Infinite mixture prototypes for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Kelsey R Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanul</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tenenbaum</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.04552</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Optnet: Differentiable optimization as a layer in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brandon</forename><surname>Amos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kolter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="136" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning to learn by gradient descent by gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Andrychowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Misha</forename><surname>Denil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Pfau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendan</forename><surname>Schaul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nando De</forename><surname>Shillingford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3981" to="3989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The complexity of partial derivatives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><surname>Baur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Volker Strassen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="317" to="330" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Automatic differentiation in machine learning: a survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Atilim Gunes Baydin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Barak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Pearlmutter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Radul</surname></persName>
		</author>
		<idno>abs/1502.05767</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Meta-learning with differentiable closed-form solvers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Bertinetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joao</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vedaldi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.08136</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastien</forename><surname>Bubeck</surname></persName>
		</author>
		<title level="m">Convex optimization: Algorithms and complexity. Foundations and Trends in Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Efficient multiple hyperparameter learning for log-linear models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chuong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan-Sheng</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Foo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Generic methods for optimization-based modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Domke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Rl2: Fast reinforcement learning via slow reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Abbeel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.02779</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Learning to Learn with Gradients</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
		<respStmt>
			<orgName>UC Berkeley</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Meta-learning and universality: Deep representations and gradient descent can approximate any learning algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.11622</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Model-agnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">One-shot visual imitation learning via meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianhe</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.04905</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Probabilistic model-agnostic meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="9516" to="9527" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Online meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><surname>Rajeswaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sham</forename><surname>Kakade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Forward and reverse gradient-based hyperparameter optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Franceschi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Donini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Frasconi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano</forename><surname>Pontil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1165" to="1173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Recasting gradient-based meta-learning as hierarchical bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erin</forename><surname>Grant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Some bounds on the complexity of gradients, jacobians, and hessians</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Griewank</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Evaluating Derivatives: Principles and Techniques of Algorithmic Differentiation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Griewank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Walther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Society for Industrial and Applied Mathematics</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>second edition</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Meta-learning priors for efficient online bayesian regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apoorva</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Pavone</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.08912</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Enabling user-driven checkpointing strategies in reverse-mode automatic differentiation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Hascoët</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mauricio</forename><surname>Araya-Polo</surname></persName>
		</author>
		<idno>abs/cs/0606042</idno>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning to learn using gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Younger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Peter R Conwell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Neural Networks</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">How to escape saddle points efficiently</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praneeth</forename><surname>Netrapalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Kakade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jordan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Auto-meta: Automated gradient based meta learner search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaehong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngduck</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moonsu</forename><surname>Cha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jung</forename><forename type="middle">Kwon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangyeul</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungwan</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongseok</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwon</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.06927</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Siamese neural networks for one-shot image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML Deep Learning Workshop</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">One shot learning of simple visual concepts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Brenden M Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference of the Cognitive Science Society (CogSci)</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">A differentiable augmented lagrangian method for bilevel nonlinear optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Landry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Manchester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Pavone</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.03319</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwonjoon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avinash</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.03758</idno>
		<title level="m">Meta-learning with differentiable convex optimization</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Learning to optimize</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.01885</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Meta-sgd: Learning to learn quickly for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenguo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengwei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.09835</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Gradient-based hyperparameter optimization through reversible learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dougal</forename><surname>Maclaurin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2113" to="2122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deep learning via hessian-free optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Martens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Meta-learning for low-resource natural language generation in task-oriented dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Mi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiyong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boi</forename><surname>Faltings</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.05644</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">A simple neural attentive meta-learner</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostafa</forename><surname>Rohaninejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.03141</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Concept learning with energy-based models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Mordatch</surname></persName>
		</author>
		<idno>abs/1811.02486</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Meta networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsendsuren</forename><surname>Munkhdalai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="2554" to="2563" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Meta-neural networks that learn by learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Devang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mammone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Neural Netowrks (IJCNN)</title>
		<imprint>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Cubic regularization of newton method and its global performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yurii</forename><surname>Nesterov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><forename type="middle">T</forename><surname>Polyak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Program</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="177" to="205" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">On first-order meta-learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Achiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.02999</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Numerical optimization (springer series in operations research and financial engineering)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorge</forename><surname>Nocedal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><forename type="middle">J</forename><surname>Wright</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Tadam: Task dependent adaptive metric for improved few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Oreshkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Pau Rodríguez López</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lacoste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="721" to="731" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Pedregosa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.02355</idno>
		<title level="m">Hyperparameter optimization with approximate gradient</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Towards Generalization and Simplicity in Continuous Control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><surname>Rajeswaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kendall</forename><surname>Lowrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emanuel</forename><surname>Todorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sham</forename><surname>Kakade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Optimization as a model for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Meta-learning with latent embedding optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Andrei A Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakub</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Sygnowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raia</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hadsell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.05960</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Meta-learning with memory-augmented neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Bartunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Evolutionary principles in self-referential learning. Diploma thesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jurgen</forename><surname>Schmidhuber</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
		</imprint>
		<respStmt>
			<orgName>Institut f. Informatik, Tech. Univ. Munich</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Trust region policy optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Michael I Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Moritz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Truncated backpropagation for bilevel optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amirreza</forename><surname>Shaban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ching-An</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivia</forename><surname>Hirschey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Byron</forename><surname>Boots</surname></persName>
		</author>
		<idno>abs/1810.10667</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4077" to="4087" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Learning to learn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorien</forename><surname>Pratt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleni</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Goroshin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carles</forename><surname>Gelada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre-Antoine</forename><surname>Manzagol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.03096</idno>
		<title level="m">Metadataset: A dataset of datasets for learning to learn from few examples</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeb</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruva</forename><surname>Kurth-Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hubert</forename><surname>Tirumala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><forename type="middle">Z</forename><surname>Soyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remi</forename><surname>Leibo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Munos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Blundell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.05763</idno>
		<title level="m">Dharshan Kumaran, and Matt Botvinick. Learning to reinforcement learn</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Deep meta-learning: Learning to learn in the concept space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengwei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenguo</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.03596</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Fast context adaptation via meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Luisa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyriacos</forename><surname>Zintgraf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vitaly</forename><surname>Shiarlis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katja</forename><surname>Kurin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shimon</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Whiteson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.03642</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
