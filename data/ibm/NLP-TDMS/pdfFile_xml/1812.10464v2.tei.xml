<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikel</forename><surname>Artetxe</surname></persName>
							<email>mikel.artetxe@ehu.eus</email>
							<affiliation key="aff0">
								<orgName type="institution">University of the Basque Country (UPV/EHU)</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
							<email>schwenk@fb.com</email>
							<affiliation key="aff1">
								<orgName type="department">Facebook AI Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T11:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We introduce an architecture to learn joint multilingual sentence representations for 93 languages, belonging to more than 30 different families and written in 28 different scripts. Our system uses a single BiLSTM encoder with a shared BPE vocabulary for all languages, which is coupled with an auxiliary decoder and trained on publicly available parallel corpora. This enables us to learn a classifier on top of the resulting embeddings using English annotated data only, and transfer it to any of the 93 languages without any modification. Our experiments in cross-lingual natural language inference (XNLI dataset), cross-lingual document classification (ML-Doc dataset) and parallel corpus mining (BUCC dataset) show the effectiveness of our approach. We also introduce a new test set of aligned sentences in 112 languages, and show that our sentence embeddings obtain strong results in multilingual similarity search even for low-resource languages. Our implementation, the pretrained encoder and the multilingual test set are available at https://github.com/ facebookresearch/LASER.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>While the recent advent of deep learning has led to impressive progress in Natural Language Processing (NLP), these techniques are known to be particularly data hungry, limiting their applicability in many practical scenarios. An increasingly popular approach to alleviate this issue is to first learn general language representations on unlabeled data, which are then integrated in task-specific downstream systems. This approach was first popularized by word embeddings <ref type="bibr" target="#b15">(Mikolov et al., 2013b;</ref><ref type="bibr">*</ref> This work was performed during an internship at Facebook AI Research. <ref type="bibr" target="#b17">Pennington et al., 2014)</ref>, but has recently been superseded by sentence-level representations <ref type="bibr" target="#b18">(Peters et al., 2018;</ref><ref type="bibr">Devlin et al., 2019)</ref>. Nevertheless, all these works learn a separate model for each language and are thus unable to leverage information across different languages, greatly limiting their potential performance for low-resource languages.</p><p>In this work, we are interested in universal language agnostic sentence embeddings, that is, vector representations of sentences that are general with respect to two dimensions: the input language and the NLP task. The motivations for such representations are multiple: the hope that languages with limited resources benefit from joint training over many languages, the desire to perform zero-shot transfer of an NLP model from one language (typically English) to another, and the possibility to handle code-switching. To that end, we train a single encoder to handle multiple languages, so that semantically similar sentences in different languages are close in the embedding space.</p><p>While previous work in multilingual NLP has been limited to either a few languages <ref type="bibr" target="#b21">(Schwenk and Douze, 2017;</ref><ref type="bibr" target="#b29">Yu et al., 2018)</ref> or specific applications like typology prediction <ref type="bibr" target="#b13">(Malaviya et al., 2017)</ref> or machine translation <ref type="bibr" target="#b16">(Neubig and Hu, 2018)</ref>, we learn general purpose sentence representations for 93 languages (see <ref type="table" target="#tab_1">Table 1</ref>). Using a single pre-trained BiLSTM encoder for all the 93 languages, we obtain very strong results in various scenarios without any fine-tuning, including crosslingual natural language inference (XNLI dataset), cross-lingual classification (MLDoc dataset), bitext mining (BUCC dataset) and a new multilingual similarity search dataset we introduce covering 112 languages. To the best of our knowledge, this is the first exploration of general purpose massively multilingual sentence representations across a large variety of tasks. arXiv:1812.10464v2 [cs.CL] 25 Sep 2019 2 Related work Following the success of word embeddings <ref type="bibr" target="#b15">(Mikolov et al., 2013b;</ref><ref type="bibr" target="#b17">Pennington et al., 2014)</ref>, there has been an increasing interest in learning continuous vector representations of longer linguistic units like sentences <ref type="bibr" target="#b10">(Le and Mikolov, 2014;</ref><ref type="bibr" target="#b5">Kiros et al., 2015)</ref>. These sentence embeddings are commonly obtained using a Recurrent Neural Network (RNN) encoder, which is typically trained in an unsupervised way over large collections of unlabelled corpora. For instance, the skip-thought model of <ref type="bibr" target="#b5">Kiros et al. (2015)</ref> couple the encoder with an auxiliary decoder, and train the entire system to predict the surrounding sentences over a collection of books. It was later shown that more competitive results could be obtained by training the encoder over labeled Natural Language Inference (NLI) data <ref type="bibr">(Conneau et al., 2017)</ref>. This was later extended to multitask learning, combining different training objectives like that of skip-thought, NLI and machine translation <ref type="bibr" target="#b1">(Cer et al., 2018;</ref><ref type="bibr" target="#b24">Subramanian et al., 2018)</ref>.</p><p>While the previous methods consider a single language at a time, multilingual representations have attracted a large attention in recent times. Most of this research focuses on cross-lingual word embeddings <ref type="bibr" target="#b19">(Ruder et al., 2017)</ref>, which are commonly learned jointly from parallel corpora <ref type="bibr">(Gouws et al., 2015;</ref><ref type="bibr" target="#b12">Luong et al., 2015)</ref>. An alternative approach that is becoming increasingly popular is to separately train word embeddings for each language, and map them to a shared space based on a bilingual dictionary <ref type="bibr" target="#b14">(Mikolov et al., 2013a;</ref><ref type="bibr">Artetxe et al., 2018a)</ref> or even in a fully unsupervised manner <ref type="bibr">(Conneau et al., 2018a;</ref><ref type="bibr">Artetxe et al., 2018b)</ref>. Cross-lingual word embeddings are often used to build bag-of-word representations of longer linguistic units by taking their respective (IDF-weighted) average <ref type="bibr" target="#b6">(Klementiev et al., 2012;</ref><ref type="bibr">Dufter et al., 2018)</ref>. While this approach has the advantage of requiring weak or no cross-lingual signal, it has been shown that the resulting sentence embeddings work poorly in practical crosslingual transfer settings <ref type="bibr">(Conneau et al., 2018b)</ref>.</p><p>A more competitive approach that we follow here is to use a sequence-to-sequence encoderdecoder architecture <ref type="bibr" target="#b21">(Schwenk and Douze, 2017;</ref><ref type="bibr" target="#b2">Hassan et al., 2018</ref>). The full system is trained end-to-end on parallel corpora akin to multilingual neural machine translation <ref type="bibr" target="#b4">(Johnson et al., 2017)</ref>: the encoder maps the source sequence into a fixed-length vector representation, which is used by the decoder to create the target sequence. This decoder is then discarded, and the encoder is kept to embed sentences in any of the training languages. While some proposals use a separate encoder for each language <ref type="bibr" target="#b21">(Schwenk and Douze, 2017)</ref>, sharing a single encoder for all languages also gives strong results <ref type="bibr" target="#b20">(Schwenk, 2018)</ref>.</p><p>Nevertheless, most existing work is either limited to few, rather close languages <ref type="bibr" target="#b21">(Schwenk and Douze, 2017;</ref><ref type="bibr" target="#b29">Yu et al., 2018)</ref> or, more commonly, consider pairwise joint embeddings with English and one foreign language <ref type="bibr">(España-Bonet et al., 2017;</ref><ref type="bibr" target="#b1">Guo et al., 2018)</ref>. To the best of our knowledge, existing work on learning multilingual representations for a large number of languages is limited to word embeddings <ref type="bibr" target="#b0">(Ammar et al., 2016;</ref><ref type="bibr">Dufter et al., 2018)</ref> or specific applications like typology prediction <ref type="bibr" target="#b13">(Malaviya et al., 2017)</ref> or machine translation <ref type="bibr" target="#b16">(Neubig and Hu, 2018)</ref>, ours being the first paper exploring general purpose massively multilingual sentence representations.</p><p>All the previous approaches learn a fixed-length representation for each sentence. A recent research line has obtained very strong results using variable-length representations instead, consisting of contextualized embeddings of the words in the sentence (Dai and <ref type="bibr">Le, 2015;</ref><ref type="bibr" target="#b18">Peters et al., 2018;</ref><ref type="bibr" target="#b3">Howard and Ruder, 2018;</ref><ref type="bibr">Devlin et al., 2019)</ref>. For that purpose, these methods train either an RNN or self-attentional encoder over unnanotated corpora using some form of language modeling. A classifier can then be learned on top of the resulting encoder, which is commonly further fine-tuned during this supervised training. Concurrent to our work, <ref type="bibr" target="#b8">Lample and Conneau (2019)</ref> propose a cross-lingual extension of these models, and report strong results in cross-lingual natural language inference, machine translation and language modeling. In contrast, our focus is on scaling to a large number of languages, for which we argue that fixed-length approaches provide a more versatile and compatible representation form. 1 Also, our approach achieves strong results without taskspecific fine-tuning, which makes it interesting for tasks with limited resources. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Proposed method</head><p>We use a single, language agnostic BiLSTM encoder to build our sentence embeddings, which is coupled with an auxiliary decoder and trained on parallel corpora. From Section 3.1 to 3.3, we describe its architecture, our training strategy to scale to 93 languages, and the training data used for that purpose.</p><p>3.1 Architecture <ref type="figure" target="#fig_0">Figure 1</ref> illustrates the architecture of the proposed system, which is based on <ref type="bibr" target="#b20">Schwenk (2018)</ref>. As it can be seen, sentence embeddings are obtained by applying a max-pooling operation over the output of a BiLSTM encoder. These sentence embeddings are used to initialize the decoder LSTM through a linear transformation, and are also concatenated to its input embeddings at every time step. Note that there is no other connection between the encoder and the decoder, as we want all relevant information of the input sequence to be captured by the sentence embedding. We use a single encoder and decoder in our system, which are shared by all languages involved. For that purpose, we build a joint byte-pair encoding (BPE) vocabulary with 50k operations, which is learned on the concatenation of all training corpora. This way, the encoder has no explicit signal on what the input language is, encouraging it to learn language independent representations. In contrast, the decoder takes a language ID embedding that specifies the language to generate, which is concatenated to the input and sentence embeddings at every time step.</p><p>Scaling up to almost one hundred languages calls for an encoder with sufficient capacity. In this paper, we limit our study to a stacked BiLSTM with 1 to 5 layers, each 512-dimensional. The resulting sentence representations (after concatenating both directions) are 1024 dimensional. The decoder has always one layer of dimension 2048. The input embedding size is set to 320, while the language ID embedding has 32 dimensions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Training strategy</head><p>In preceding work <ref type="bibr" target="#b21">(Schwenk and Douze, 2017;</ref><ref type="bibr" target="#b20">Schwenk, 2018)</ref>, each input sentence was jointly translated into all other languages. However, this approach has two obvious drawbacks when trying to scale to a large number of languages. First, it requires an N-way parallel corpus, which is difficult to obtain for all languages. Second, it has a quadratic cost with respect to the number of languages, making training prohibitively slow as the number of languages is increased. In our preliminary experiments, we observed that similar results can be obtained using only two target languages. 2 At the same time, we relax the requirement for N-way parallel corpora by considering separate alignments for each language combination. Training minimizes the cross-entropy loss on the training corpus, alternating over all combinations of the languages involved. For that purpose, we use Adam with a constant learning rate of 0.001 and dropout set to 0.1, and train for a fixed number of epochs. Our implementation is based on fairseq, 3 and we make use of its multi-GPU support to train on 16 NVIDIA V100 GPUs with a total batch size of 128,000 tokens. Unless otherwise specified, we train our model for 17 epochs, which takes about 5 days. Stopping training earlier decreases the overall performance only slightly.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Training data and pre-processing</head><p>As described in Section 3.2, training requires bitexts aligned with two target languages. We choose English and Spanish for that purpose, as most of the data is aligned with these languages. <ref type="bibr">4</ref> We collect training corpora for 93 input languages by combining the Europarl, United Nations, Open-Subtitles2018, Global Voices, Tanzil and Tatoeba corpus, which are all publicly available on the OPUS website 5 <ref type="bibr" target="#b25">(Tiedemann, 2012)</ref>. Appendix A provides a more detailed description of this training data, while <ref type="table" target="#tab_1">Table 1</ref> summarizes the list of all languages covered and the size of the bitexts. Our training data comprises a total of 223 million parallel sentences. All pre-processing is done with  . However, all these datasets only cover a subset of our 93 languages, so we also introduce a new test set for multilingual similarity search in 112 languages, including several languages for which we have no training data but whose language family is covered (Section 4.4). We remark that we use the same pre-trained BiLSTM encoder for all tasks and languages without any fine-tuning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">XNLI: cross-lingual NLI</head><p>NLI has become a widely used task to evaluate sentence representations <ref type="bibr">(Bowman et al., 2015;</ref><ref type="bibr" target="#b28">Williams et al., 2018)</ref>. Given two sentences, a premise and a hypothesis, the task consists in deciding whether there is an entailment, contradiction or neutral relationship between them. XNLI is a recent effort to create a dataset similar to the English MultiNLI for several languages <ref type="bibr">(Conneau et al., 2018b)</ref>. It consists of 2,500 development and 5,000 test instances translated from En-glish into 14 languages by professional translators, making results across different languages directly comparable.</p><p>We train a classifier on top of our multilingual encoder using the usual combination of the two sentence embeddings: (p, h, p·h, |p−h|), where p and h are the premise and hypothesis. For that purpose, we use a feed-forward neural network with two hidden layers of size 512 and 384, trained with Adam. All hyperparameters were optimized on the English XNLI development corpus only, and then, the same classifier was applied to all languages of the XNLI test set. As such, we did not use any training or development data in any of the foreign languages. Note, moreover, that the multilingual sentence embeddings are fixed and not fine-tuned on the task or the language.</p><p>We report our results in <ref type="table" target="#tab_3">Table 2</ref>, along with several baselines from <ref type="bibr">Conneau et al. (2018b)</ref> and the multilingual BERT model <ref type="bibr">(Devlin et al., 2019)</ref>. 9 Our proposed method obtains the best results in zero-shot cross-lingual transfer for all languages but Spanish. Moreover, our transfer results are strong and homogeneous across all languages: 9 Note that the multilingual variant of BERT is not discussed in its paper <ref type="bibr">(Devlin et al., 2019)</ref>. Instead, the reported results were extracted from the README of the official GitHub project at https://github.com/google-research/bert/ blob/master/multilingual.md on July 5, 2019.  for 11 of them, the zero-short performance is (at most) 5% lower than the one on English, including distant languages like Arabic, Chinese and Vietnamese, and we also achieve remarkable good results on low-resource languages like Swahili. In contrast, BERT achieves excellent results on English, outperforming our system by 7.5 points, but its transfer performance is much weaker. For instance, the loss in accuracy for both Arabic and Chinese is 2.5 points for our system, compared to 19.3 and 17.6 points for BERT. 10 Finally, we also outperform all baselines of Conneau et al. <ref type="formula">(2018b)</ref> by a substantial margin, with the additional advantage that we use a single pre-trained encoder, whereas X-BiLSTM learns a separate encoder for each language. We also provide results involving Machine Translation (MT) from <ref type="bibr">Conneau et al. (2018b)</ref>. This can be done in two ways: 1) translate the test data into English and apply the English NLI classifier, or 2) translate the English training data and train a separate NLI classifier for each language. Note that we are not evaluating multilingual sentence embeddings anymore, but rather the quality of the MT system and a monolingual model. Moreover, the use of MT incurs in an important overhead with either strategy: translating test makes inference substantially more expensive, whereas translating train results in a separate model for each language. As shown in <ref type="table" target="#tab_3">Table 2</ref>, our approach outperforms all translation baselines of <ref type="bibr">Conneau et al. (2018b)</ref>. We also outperform MT BERT for Arabic and Thai, and are very close for 10 Concurrent to our work, <ref type="bibr" target="#b8">Lample and Conneau (2019)</ref> report superior results using another variant of BERT, outperforming our method by 4.5 points in average. However, note that these results are not fully comparable because 1) their system uses development data in the foreign languages, whereas our approach is fully zero-shot, 2) their approach requires fine-tuning on the task, 3) our system handles a much larger number of languages, and 4) our transfer performance is substantially better (an average loss of 4 vs 10.6 points with respect to the respective English system).</p><p>Urdu. Thanks to its multilingual nature, our system can also handle premises and hypothesis in different languages. As reported in Appendix B, the proposed method obtains very strong results in these settings, even for distant language combinations like French-Chinese.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">MLDoc: cross-lingual classification</head><p>Cross-lingual document classification is a typical application of multilingual representations. In order to evaluate our sentence embeddings in this task, we use the MLDoc dataset of <ref type="bibr" target="#b22">Schwenk and Li (2018)</ref>, which is an improved version of the Reuters benchmark <ref type="bibr" target="#b11">(Lewis et al., 2004;</ref><ref type="bibr" target="#b6">Klementiev et al., 2012)</ref> with uniform class priors and a wider language coverage. There are 1,000 training and development documents and 4,000 test documents for each language, divided in 4 different genres. Just as with the XNLI evaluation, we consider the zero-shot transfer scenario: we train a classifier on top of our multilingual encoder using the English training data, optimizing hyperparameters on the English development set, and evaluating the resulting system in the remaining languages. We use a feed-forward neural network with one hidden layer of 10 units.</p><p>As shown in <ref type="table" target="#tab_5">Table 3</ref>, our system obtains the best published results for 5 of the 7 transfer languages. We believe that our weaker performance on Japanese can be attributed to the domain and sentence length mismatch between MLDoc and the parallel corpus we use for this language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">BUCC: bitext mining</head><p>Bitext mining is another natural application for multilingual sentence embeddings. Given two comparable corpora in different languages, the task consists in identifying sentence pairs that are translations of each other. For that purpose, one would commonly score sentence pairs by taking the cosine similarity of their respective embeddings, so parallel sentences can be extracted  through nearest neighbor retrieval and filtered by setting a fixed threshold over this score <ref type="bibr" target="#b20">(Schwenk, 2018)</ref>. However, it was recently shown that this approach suffers from scale inconsistency issues <ref type="bibr" target="#b1">(Guo et al., 2018)</ref>, and Artetxe and Schwenk (2018) proposed the following alternative score addressing it:</p><p>score(x, y) = margin(cos(x, y),</p><formula xml:id="formula_0">z∈NN k (x) cos(x, z) 2k + z∈NN k (y) cos(y, z) 2k )</formula><p>where x and y are the source and target sentences, and NN k (x) denotes the k nearest neighbors of x in the other language. The paper explores different margin functions, with ratio (margin(a, b) = a b ) yielding the best results. This notion of margin is related to CSLS (Conneau et al., 2018a).</p><p>We use this method to evaluate our sentence embeddings on the BUCC mining task <ref type="bibr" target="#b32">(Zweigenbaum et al., , 2018</ref>, using exact same hyperparameters as Artetxe and <ref type="bibr" target="#b20">Schwenk (2018)</ref>. The task consists in extracting parallel sentences from a comparable corpus between English and four foreign languages: German, French, Russian and Chinese. The dataset consists of 150K to 1.2M sentences for each language, split into a sample, training and test set, with about 2-3% of the sentences being parallel. As shown in <ref type="table" target="#tab_7">Table 4</ref>, our system establishes a new state-of-the-art for all language pairs with the exception of English-Chinese test. We also outperform Artetxe and Schwenk (2018) themselves, who use two separate models covering 4 languages each. Not only are our results better, but our model also covers many more languages, so it can potentially be used to mine bitext for any combination of the 93 languages supported.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Tatoeba: similarity search</head><p>While XNLI, MLDoc and BUCC are well established benchmarks with comparative results available, they only cover a small subset of our 93 languages. So as to better assess the performance of our model in all these languages, we introduce a new test set of similarity search for 112 languages based on the Tatoeba corpus. The dataset consists of up to 1,000 English-aligned sentence pairs for each language. Appendix C describes how the dataset was constructed in more details. Evaluation is done by finding the nearest neighbor for each sentence in the other language according to cosine similarity and computing the error rate.</p><p>We report our results in <ref type="table" target="#tab_1">Table 1</ref>. Contrasting these results with those of XNLI, one would assume that similarity error rates below 5% are indicative of strong downstream performance. 11 This is the case for 37 languages, while there are 48 languages with an error rate below 10% and 55 with less than 20%. There are only 15 languages with error rates above 50%. Additional result analysis is given in Appendix D.</p><p>We believe that our competitive results for many low-resource languages are indicative of the benefits of joint training, which is also supported by our ablation results in Section 5.3. In relation to that, Appendix E reports similarity search results for 29 additional languages without any training data, showing that our encoder can also generalize to unseen languages to some extent as long as it was trained on related languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Ablation experiments</head><p>In this section, we explore different variants of our approach and study the impact on the performance <ref type="bibr">11</ref> We consider the average of en→xx and xx→en   for all our evaluation tasks. We report average results across all languages. For XNLI, we also report the accuracy on English. <ref type="table" target="#tab_9">Table 5</ref> reports the performance on the different tasks for encoders with 1, 3 or 5 layers. We were not able to achieve good convergence with deeper models. It can be seen that all tasks benefit from deeper models, in particular XNLI and Tatoeba, suggesting that a single layer BiLSTM has not enough capacity to encode so many languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Encoder depth</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Multitask learning</head><p>Multitask learning has been shown to be helpful to learn English sentence embeddings <ref type="bibr" target="#b24">(Subramanian et al., 2018;</ref><ref type="bibr" target="#b1">Cer et al., 2018)</ref>. The most important task in this approach is arguably NLI, so we explored adding an additional NLI objective to our system with different weighting schemes. As shown in <ref type="table" target="#tab_10">Table 6</ref>, the NLI objective leads to a better performance on the English NLI test set, but this comes at the cost of a worse cross-lingual transfer performance in XNLI and Tatoeba. The effect in BUCC is negligible.  Czech, French, German and Spanish, so results between both models are directly comparable. As shown in <ref type="table" target="#tab_12">Table 7</ref>, the full model equals or outperforms the one covering the evaluation languages only for all tasks but MLDoc. This suggests that the joint training also yields to overall better representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Number of training languages</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>In this paper, we propose an architecture to learn multilingual fixed-length sentence embeddings for 93 languages. We use a single language-agnostic BiLSTM encoder for all languages, which is trained on publicly available parallel corpora and applied to different downstream tasks without any fine-tuning. Our experiments on cross-lingual natural language inference (XNLI), cross-lingual document classification (MLDoc), and bitext mining (BUCC) confirm the effectiveness of our approach. We also introduce a new test set of multilingual similarity search in 112 languages, and show that our approach is competitive even for low-resource languages. To the best of our knowledge, this is the first successful exploration of general purpose massively multilingual sentence representations.</p><p>In the future, we would like to explore alternative encoder architectures like self-attention <ref type="bibr" target="#b26">(Vaswani et al., 2017)</ref>. We would also like to explore strategies to exploit monolingual data, such as using pre-trained word embeddings, backtranslation <ref type="bibr" target="#b23">(Sennrich et al., 2016;</ref><ref type="bibr">Edunov et al., 2018)</ref>, or other ideas from unsupervised <ref type="bibr">MT (Artetxe et al., 2018c;</ref><ref type="bibr" target="#b9">Lample et al., 2018)</ref>. Finally, we would like to replace our language dependant pre-processing with a language agnostic approach like SentencePiece. <ref type="bibr">12</ref> Our implementation, the pre-trained encoder and the multilingual test set are freely available at https://github.com/ facebookresearch/LASER. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Training data</head><p>Our training data consists of the combination of the following publicly available parallel corpora:</p><p>• Europarl: 21 European languages. The size varies from 400k to 2M sentences depending on the language pair.</p><p>• United Nations: We use the first two million sentences in Arabic, Russian and Chinese.</p><p>• OpenSubtitles2018: A parallel corpus of movie subtitles in 57 languages. The corpus size varies from a few thousand sentences to more than 50 million. We keep at most 2 million entries for each language pair.</p><p>• Global Voices: News stories from the Global Voices website (38 languages). This is a rather small corpus with less than 100k sentence in most of the languages.</p><p>• Tanzil: Quran translations in 42 languages, average size of 135k sentences. The style and vocabulary is very different from news texts.</p><p>• Tatoeba: A community supported collection of English sentences and translations into more than 300 languages. We use this corpus to extract a separate test set of up to 1,000 sentences (see Appendix C). For languages with more than 1,000 entries, we use the remaining ones for training.</p><p>Using all these corpora would provide parallel data for more languages, but we decided to keep 93 languages after discarding several constructed languages with little practical use (Klingon, Kotava, Lojban, Toki Pona and Volapük). In our preliminary experiments, we observed that the domain of the training data played a key role in the performance of our sentence embeddings. Some tasks (BUCC, MLDoc) tend to perform better when the encoder is trained on long and formal sentences, whereas other tasks (XNLI, Tatoeba) benefit from training on shorter and more informal sentences. So as to obtain a good balance, we used at most two million sentences from Open-Subtitles, although more data is available for some languages. The size of the available training data varies largely for the considered languages (see <ref type="table" target="#tab_1">Table 1</ref>). This favours high-resource languages when the joint BPE vocabulary is created and the training of the joint encoder. In this work, we did not try to counter this effect by over-sampling lowresource languages. <ref type="table" target="#tab_15">Table 8</ref> reports the accuracies of our system on the XNLI test set when the premises and hypothesis are in a different language. The numbers in the diagonal correspond to the main results reported in <ref type="table" target="#tab_3">Table 2</ref>. Our approach obtains strong results when combining different languages. We do not have evidence that distant languages perform considerably worse. Instead, the combined performance seems mostly bounded by the accuracy of the language that performs worst when used alone. For instance, Greek-Russian achieves very similar results to Bulgarian-Russian, two Slavic languages. Similarly, combing French with Chinese, two totally different languages, is only 1.5 points worse than French-Spanish, two very close languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B XNLI results for all language combinations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Tatoeba: dataset</head><p>Tatoeba 13 is an open collection of English sentences and high-quality translations into more than 300 languages. The number of available translations is updated every Saturday. We downloaded the snapshot on November 19th 2018 and performed the following processing: 1) removal of sentences containing "@" or "http", as emails and web addresses are not language specific; 2) removal of sentences with less than three words, as they usually have little semantic information; 3) removal of sentences that appear multiple times, either in the source or the target. After filtering, we created test sets of up to 1,000 aligned sentences with English. This amount is available for 72 languages. Limiting the number of sentences to 500, we increase the coverage to 86 languages, and 112 languages with 100 parallel sentences. It should be stressed that, in general, the English sentences are not the same for different languages, so error rates are not directly comparable across languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Tatoeba: result analysis</head><p>In this section, we provide some analysis on the results given in <ref type="table" target="#tab_1">Table 1</ref>. We have 48 languages with an error rate below 10% and 55 with less than 20%, respectively (English included).   languages with less than 20% error belong to 20 different families and use 12 different scripts, and include 6 languages for which we have only small amounts of bitexts (less than 400k), namely Esperanto, Galician, Hindi, Interlingua, Malayam and Marathi, which presumably benefit from the joint training with other related languages. Overall, we observe low similarity error rates on the Indo-Aryan languages, namely Hindi, Bengali, Marathi and Urdu. The performance on Berber languages ("ber" and "kab") is remarkable, although we have less than 100k sentences to train them. This is a typical example of languages which are spoken by several millions of people, but for which the amount of written resources is very limited. It is quite unlikely that we would be able to train a good sentence embedding with language specific corpora only, showing the benefit of joint training on many languages.</p><p>Only 15 languages have similarity error rates above 50%. Four of them are low-resource languages with their own script and which are alone in their family (Amharic, Armenian, Khmer and Georgian), making it difficult to benefit from joint training. In any case, it is still remarkable that a language like Khmer performs much better than random with only 625 training examples. There are also several Turkic languages (Kazakh, Tatar, Uighur and Uzbek) and Celtic languages (Breton and Cornish) with high error rates. We plan to further investigate its cause and possible solutions in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Tatoeba: results for unseen languages</head><p>We extend our experiments to 29 languages without any training data (see <ref type="table" target="#tab_16">Table 9</ref>). Many of them are recognized minority languages spoken in specific regions (e.g. Asturian, Faroese, Frisian, Kashubian, North Moluccan Malay, Piemontese, Swabian or Sorbian). All share some similarities, at various degrees, with other major languages that we cover, but also differ by their own grammar or specific vocabulary. This enables our encoder to perform reasonably well, even if it did not see these languages during training.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Architecture of our system to learn multilingual sentence embeddings.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>67k 88k 8.2M 14k 254k 5k 62k 4.9M 913k 29k 4.2M 813k 1k 5.5M 7.9M 8.7M en→xx err. 11.20 60.71 8.30 n/a 44.10 31.20 29.80 4.50 10.80 83.50 3.95 4.00 24.20 3.10 3.90 0.90 xx→en err. 9.90 55.36 7.80 n/a 23.90 36.50 33.70 5.40 10.00 84.90 3.11 4.20 21.70 3.80 4.00 1.00 1k 90k 6.5M 2.6M 397k 4.8M 5.3M 1.2M 7.9M 8.8M 732 349k 127k 4.1M 288k 4.0M en→xx err. 92.10 n/a 5.30 n/a 2.70 1.90 3.20 5.70 3.70 4.40 93.80 4.60 n/a 8.10 5.80 2.80 xx→en err. 93.50 n/a 4.80 n/a 2.80 2.10 3.40 5.00 3.70 4.30 95.80 4.40 n/a 7.60 4.80 2.70 0M 8.3M 3.2M 296k 15k 4k 625 1.4M 50k 2k en→xx err. 3.90 59.97 5.40 5.20 14.70 17.40 4.40 4.60 3.90 60.32 39.10 80.17 77.01 10.60 80.24 91.90 xx→en err. 4.00 67.79 4.10 5.80 12.80 15.20 4.40 4.80 5.40 67.83 44.70 82.61 81.72 11.50 85.37 93.20 560 19k 2k 3.2M 2.0M 355k 1k 4.2M 373k 31k 2.9M 2k 4.1M 12k 8.4M 3k en→xx err. 91.60 41.60 35.90 4.10 4.50 n/a 87.70 5.20 3.35 9.00 3.40 n/a 1.30 18.60 3.10 39.20 xx→en err. 94.10 41.50 35.10 3.40 4.70 n/a 91.50 5.40 2.91 8.00 3.80 n/a 1.10 15.60 4.30 38.40 3M en→xx err. n/a 4.93 47.40 2.30 72.00 59.90 5.80 20.00 82.24 3.40 25.80 37.00 4.10 xx→en err. n/a 4.20 51.50 2.60 65.70 49.60 5.10 16.20 80.37 3.00 25.20 38.90 5.00 test sent.</figDesc><table><row><cell></cell><cell>af</cell><cell>am</cell><cell>ar</cell><cell>ay</cell><cell>az</cell><cell cols="3">be ber bg</cell><cell>bn</cell><cell>br</cell><cell>bs</cell><cell cols="3">ca cbk cs</cell><cell>da</cell><cell>de</cell></row><row><cell>train sent. test sent.</cell><cell cols="16">1000 168 1000 -1000 1000 1000 1000 1000 1000 354 1000 1000 1000 1000 1000</cell></row><row><cell></cell><cell cols="2">dtp dv</cell><cell>el</cell><cell>en</cell><cell>eo</cell><cell>es</cell><cell>et</cell><cell>eu</cell><cell>fi</cell><cell>fr</cell><cell>ga</cell><cell>gl</cell><cell>ha</cell><cell>he</cell><cell>hi</cell><cell>hr</cell></row><row><cell>train sent. test sent.</cell><cell cols="16">1000 -1000 -1000 1000 1000 1000 1000 1000 1000 1000 -1000 1000 1000</cell></row><row><cell></cell><cell>hu</cell><cell>hy</cell><cell>ia</cell><cell>id</cell><cell>ie</cell><cell>io</cell><cell>is</cell><cell>it</cell><cell>ja</cell><cell cols="5">ka kab kk km ko</cell><cell cols="2">ku kw</cell></row><row><cell cols="17">train sent. 5.3M 6k 3k 2.test sent. 9k 4.3M 3k 1000 742 1000 1000 1000 1000 1000 1000 1000 746 1000 575 722 1000 410 1000</cell></row><row><cell></cell><cell>kzj</cell><cell>la</cell><cell>lfn</cell><cell>lt</cell><cell>lv</cell><cell cols="9">mg mhr mk ml mr ms my nb nds</cell><cell>nl</cell><cell>oc</cell></row><row><cell>train sent. test sent.</cell><cell cols="16">1000 1000 1000 1000 1000 -1000 1000 687 1000 1000 -1000 1000 1000 1000</cell></row><row><cell></cell><cell>pl</cell><cell>ps</cell><cell>pt</cell><cell>ro</cell><cell>ru</cell><cell>sd</cell><cell>si</cell><cell>sk</cell><cell>sl</cell><cell>so</cell><cell>sq</cell><cell>sr</cell><cell>sv</cell><cell>sw</cell><cell>ta</cell><cell>te</cell></row><row><cell cols="17">train sent. 5.5M 4.9M 8.3M 4.9M 9.3M 91k 796k 5.2M 5.2M 85k 3.2M 4.0M 7.8M 173k 42k 33k</cell></row><row><cell cols="17">en→xx err. 2.00 7.20 4.70 2.50 4.90 n/a n/a 3.10 4.50 n/a 1.80 4.30 3.60 45.64 31.60 18.38</cell></row><row><cell cols="17">xx→en err. 2.40 6.00 4.90 2.70 5.90 n/a n/a 3.70 3.77 n/a 2.30 5.00 3.20 39.23 29.64 22.22</cell></row><row><cell>test sent.</cell><cell cols="6">1000 1000 1000 1000 1000 -</cell><cell cols="3">-1000 823</cell><cell cols="7">-1000 1000 1000 390 307 234</cell></row><row><cell></cell><cell>tg</cell><cell>th</cell><cell>tl</cell><cell>tr</cell><cell>tt</cell><cell>ug</cell><cell>uk</cell><cell>ur</cell><cell>uz</cell><cell cols="4">vi wuu yue zh</cell><cell></cell><cell></cell></row><row><cell cols="12">train sent. 124k 4.1M 36k 5.7M 119k 88k 1.4M 746k 118k 4.0M 2k</cell><cell cols="2">4k 8.</cell><cell></cell><cell></cell></row></table><note>- 548 1000 1000 1000 1000 1000 1000 428 1000 1000 1000 1000</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table /><note>List of the 93 languages along with their training size, the resulting similarity error rate on Tatoeba, and the number of sentences in it. Dashes denote language pairs excluded for containing less than 100 test sentences.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>BiLSTM 73.7 67.7 68.7 67.7 68.9 67.9 65.4 64.2 64.8 66.4 64.1 65.8 64.1 55.7 58.4 X-CBOW 64.5 60.3 60.7 61.0 60.5 60.4 57.8 58.7 57.5 58.8 56.9 58.8 56.3 50.4 52.2 BERT uncased</figDesc><table><row><cell></cell><cell></cell><cell>EN</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">EN → XX</cell></row><row><cell></cell><cell></cell><cell></cell><cell>fr</cell><cell cols="3">es de el bg ru</cell><cell>tr</cell><cell>ar</cell><cell>vi</cell><cell>th</cell><cell>zh hi sw ur</cell></row><row><cell cols="5">Zero-Shot Transfer, one NLI system for all languages:</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Conneau et al. (2018b)</cell><cell cols="2">X-Transformer 81.4</cell><cell cols="2">-74.3 70.5 -</cell><cell>-</cell><cell>-</cell><cell cols="2">-62.1 -</cell><cell>-63.8 -</cell><cell>-58.3</cell></row><row><cell>Proposed method</cell><cell>BiLSTM</cell><cell cols="7">73.9 71.9 72.9 72.6 72.8 74.2 72.1 69.7 71.4 72.0 69.2 71.4 65.5 62.2 61.0</cell></row><row><cell cols="3">Translate test, one English NLI system:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Conneau et al. (2018b) BiLSTM</cell><cell cols="7">73.7 70.4 70.7 68.7 69.1 70.4 67.8 66.3 66.8 66.5 64.4 68.3 64.2 61.8 59.3</cell></row><row><cell>BERT uncased  *</cell><cell cols="2">Transformer 81.4</cell><cell cols="2">-74.9 74.4 -</cell><cell>-</cell><cell>-</cell><cell cols="2">-70.4 -</cell><cell>-70.1 -</cell><cell>-62.1</cell></row><row><cell cols="5">Translate train, separate NLI systems for each language:</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Conneau et al. (2018b) BiLSTM</cell><cell cols="7">73.7 68.3 68.8 66.5 66.4 67.4 66.5 64.5 65.8 66.0 62.8 67.0 62.1 58.2 56.6</cell></row><row><cell>BERT cased  *</cell><cell cols="2">Transformer 81.9</cell><cell cols="2">-77.8 75.9 -</cell><cell>-</cell><cell>-</cell><cell cols="2">-70.7 -68.9  † 76.6 -</cell><cell>-61.6</cell></row></table><note>*</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Test accuracies on the XNLI cross-lingual natural language inference dataset. All results from Conneau et al. (2018b) correspond to max-pooling, which outperforms the last-state variant in all cases. Results involving MT do not use a multilingual model and are not directly comparable with zero-shot transfer. Overall best results are in bold, the best ones in each group are underlined.</figDesc><table><row><cell>uate multilingual sentence embeddings. The most</cell></row><row><cell>notable effort in this regard is arguably the XNLI</cell></row><row><cell>dataset (Conneau et al., 2018b), which evaluates</cell></row><row><cell>the transfer performance of an NLI model trained</cell></row><row><cell>on English data over 14 additional test languages</cell></row><row><cell>(Section 4.1). So as to obtain a more com-</cell></row><row><cell>plete picture, we also evaluate our embeddings</cell></row><row><cell>in cross-lingual document classification (MLDoc,</cell></row><row><cell>Section 4.2), and bitext mining (BUCC, Section</cell></row><row><cell>4.3)</cell></row></table><note>* Results for BERT (Devlin et al., 2019) are extracted from its GitHub README 9† Monolingual BERT model for Thai from https://github.com/ThAIKeras/bert</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>MultiCCA + CNN 92.20 81.20 72.50 72.38 69.38 67.63 60.80 74.73 BiLSTM (Europarl) 88.40 71.83 66.65 72.83 60.73 77.33 77.95 69.43 60.30 67.78 71.93</figDesc><table><row><cell></cell><cell></cell><cell>EN</cell><cell></cell><cell></cell><cell cols="2">EN → XX</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>de</cell><cell>es</cell><cell>fr</cell><cell>it</cell><cell>ja</cell><cell>ru</cell><cell>zh</cell></row><row><cell>Schwenk</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>and Li</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>(2018)</cell><cell>BiLSTM (UN)</cell><cell>88.83</cell><cell>-</cell><cell cols="2">69.50 74.52</cell><cell>-</cell><cell>-</cell><cell>61.42 71.97</cell></row><row><cell cols="2">Proposed method</cell><cell>89.93</cell><cell>84.78</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Accuracies on the MLDoc zero-shot cross-lingual document classification task (test set).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>F1 scores on the BUCC mining task.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5 :</head><label>5</label><figDesc>Impact of the depth of the BiLSTM encoder.</figDesc><table><row><cell cols="5">NLI Tatoeba BUCC MLDoc XNLI-en XNLI-xx</cell></row><row><cell cols="2">obj. Err [%]</cell><cell cols="3">F1 Acc [%] Acc [%] Acc [%]</cell></row><row><cell>-</cell><cell cols="2">26.31 92.83 72.79</cell><cell>73.67</cell><cell>69.92</cell></row><row><cell cols="3">×1 26.89 93.01 74.51</cell><cell>73.71</cell><cell>69.10</cell></row><row><cell cols="3">×2 28.52 93.06 71.90</cell><cell>74.65</cell><cell>67.75</cell></row><row><cell cols="3">×3 27.83 92.98 73.11</cell><cell>75.23</cell><cell>61.86</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 6 :</head><label>6</label><figDesc>Multitask training with an NLI objective and different weightings.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 7 :</head><label>7</label><figDesc>Comparison between training on 93 languages and training on the 18 evaluation languages only.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head></head><label></label><figDesc>70.0 72.0 72.8 71.6 72.2 72.2 65.9 71.4 61.5 67.6 69.7 61.0 70.7 70.3 69.5 ar 70.5 71.4 71.1 70.1 69.6 70.6 70.0 64.9 69.9 60.1 67.1 68.2 60.6 69.5 70.1 68.2 bg 72.7 71.1 74.2 72.3 71.7 72.1 72.7 65.5 71.7 60.8 69.0 69.8 61.2 70.5 70.5 69.7 de 72.0 69.6 71.8 72.6 70.9 71.7 71.5 65.2 70.8 60.5 68.1 69.1 60.5 70.0 70.7 69.0 el 73.0 70.1 72.0 72.4 72.8 71.5 71.9 65.2 71.7 61.0 68.1 69.5 61.0 70.2 70.4 69.4 es 73.3 70.4 72.4 72.7 71.5 72.9 72.2 65.0 71.2 61.5 68.1 69.8 60.5 70.4 70.4 69.5 fr 73.2 70.4 72.2 72.5 71.1 72.1 71.9 65.9 71.3 61.4 68.1 70.0 60.9 70.9 70.4 69.5 hi 66.7 66.0 66.7 67.2 65.4 66.1 65.6 65.5 66.5 58.9 63.8 65.9 59.5 65.6 66.0 65.0 ru 71.3 70.0 72.3 71.4 70.5 71.2 71.3 64.4 72.1 60.8 67.9 68.7 60.5 69.9 70.1 68.8 sw 65.7 64.5 65.7 65.0 65.1 65.2 64.5 61.5 64.9 62.2 63.3 64.5 58.2 65.0 65.1 64.0 th 70.5 69.2 71.4 70.1 69.6 70.2 69.6 65.2 70.2 62.1 69.2 67.7 60.9 70.0 69.6 68.4 tr 70.6 69.1 70.4 70.3 69.6 70.6 69.8 64.0 69.1 61.3 67.3 69.7 60.6 69.8 69.0 68.1 ur 65.5 64.8 65.3 65.9 65.3 65.7 64.8 62.1 65.3 58.2 63.2 64.1 61.0 64.3 65.0 64.0 vi 71.7 69.7 72.2 71.1 70.7 71.3 70.5 65.4 71.0 61.3 69.0 69.3 60.6 72.0 70.3 69.1 zh 71.6 69.9 71.7 71.1 70.1 71.2 70.8 64.1 70.9 60.5 68.6 68.9 60.3 69.8 71.4 68.7 avg 70.8 69.1 70.8 70.5 69.7 70.3 70.0 64.7 69.8 60.8 67.2 68.3 60.5 69.2 69.3 68.1</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Hypothesis</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>en</cell><cell>ar bg</cell><cell>de el</cell><cell>es</cell><cell>fr</cell><cell>hi ru</cell><cell>sw th</cell><cell>tr</cell><cell>ur</cell><cell>vi zh avg</cell></row><row><cell>en 73.9</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Premise</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>The</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 8 :</head><label>8</label><figDesc>XNLI test accuracies for our approach when the premise and hypothesis are in different languages. 58.96 58.62 31.24 12.60 63.20 81.67 64.23 54.55 89.74 48.64 28.24 46.24 95.66 52.99 42.44 xx→en err. 65.67 62.46 31.03 14.96 64.50 87.00 77.37 58.89 93.04 55.32 28.63 50.29 96.98 58.12 48.65 test sent. 134 911 477 127 231 600 137 253 575 479 262 173 829 117 483 jv max mn nn nov orv pam pms swg tk tzl war xh yi en→xx err. 73.66 48.24 89.55 13.40 33.07 68.26 93.10 50.86 50.00 75.37 54.81 84.20 90.85 93.28 xx→en err. 80.49 50.00 94.09 10.00 35.02 75.45 95.00 49.90 58.04 83.25 55.77 88.60 92.25 95.40 test sent.</figDesc><table><row><cell>ang arq arz ast awa ceb ch csb</cell><cell>cy dsb</cell><cell>fo</cell><cell>fy</cell><cell>gd gsw hsb</cell></row><row><cell cols="5">en→xx err. 205 284 440 1000 257 835 1000 525 112 203 104 1000 142 848</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 9 :</head><label>9</label><figDesc>Performance on the Tatoeba test set for languages for which we have no training data.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">For instance, there is not always a one-to-one correspondence among words in different languages (e.g. a single word of a morphologically complex language might correspond to several words of a morphologically simple language), so having a separate vector for each word might not transfer as well across languages.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Note that, if we had a single target language, the only way to train the encoder for that language would be autoencoding, which we observe to work poorly. Having two target languages avoids this problem.3 https://github.com/pytorch/fairseq</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Note that it is not necessary that all input languages are systematically aligned with both target languages. Once we have several languages with both alignments, the joint embedding is well conditioned, and we can add more languages with one alignment only, usually English. 5 http://opus.nlpl.euMoses tools: 6 punctuation normalization, removing non-printing characters and tokenization. As the only exception, Chinese and Japanese were segmented with Jieba 7 and Mecab, 8 respectively. All the languages are kept in their original script with the exception of Greek, which we romanize into the Latin alphabet. It is important to note that the joint encoder itself has no information on the language or writing script of the tokenized input texts. It is even possible to mix multiple languages in one sentence.4 Experimental evaluationIn contrast with the well-established evaluation frameworks for English sentence representations(Conneau et al., 2017;<ref type="bibr" target="#b27">Wang et al., 2018)</ref>, there is not yet a commonly accepted standard to eval-6 http://www.statmt.org/moses 7 https://github.com/fxsjy/jieba 8 https://github.com/taku910/mecab</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12">https://github.com/google/ sentencepiece</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13">https://tatoeba.org/eng/</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Massively multilingual word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waleed</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Mulcaire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulia</forename><surname>Tsvetkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<idno>abs/1602.01925</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Effective parallel corpus mining using bilingual sentence embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandy</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinlan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinfei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heming</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustavo</forename><forename type="middle">Hernandez</forename><surname>Abrego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Stevens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Hsuan</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Strope</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ray</forename><surname>Kurzweil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Conference on Machine Translation: Research Papers</title>
		<meeting>the Third Conference on Machine Translation: Research Papers<address><addrLine>Belgium, Brussels</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="165" to="176" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hany</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Aue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishal</forename><surname>Chowdhary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuedong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Junczys-Dowmunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shujie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renqian</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arul</forename><surname>Menezes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Seide</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lijun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuangzhi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingce</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongdong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhirui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Achieving human parity on automatic Chinese to English news translation. CoRR, abs/1803.05567</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Universal language model fine-tuning for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="328" to="339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Google&apos;s multilingual neural machine translation system: Enabling zero-shot translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melvin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Thorat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernanda</forename><surname>Viégas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Wattenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Macduff</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00065</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="339" to="351" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Antonio Torralba, and Sanja Fidler</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="3294" to="3302" />
		</imprint>
	</monogr>
	<note>Skip-thought vectors</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Inducing crosslingual distributed representations of words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Klementiev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binod</forename><surname>Bhattarai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2012</title>
		<meeting>COLING 2012</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1459" to="1474" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">India</forename><surname>Mumbai</surname></persName>
		</author>
		<title level="m">The COLING 2012 Organizing Committee</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Cross-lingual language model pretraining. CoRR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<idno>abs/1901.07291</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Phrase-based &amp; neural unsupervised machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludovic</forename><surname>Denoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc&amp;apos;aurelio</forename><surname>Ranzato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5039" to="5049" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Distributed representations of sentences and documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Machine Learning</title>
		<meeting>the 31st International Conference on Machine Learning<address><addrLine>Bejing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1188" to="1196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">RCV1: A new benchmark collection for text categorization research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">D</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tony</forename><forename type="middle">G</forename><surname>Rose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="361" to="397" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Bilingual word representations with monolingual quality in mind</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/W15-1521</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Workshop on Vector Space Modeling for Natural Language Processing</title>
		<meeting>the 1st Workshop on Vector Space Modeling for Natural Language Processing<address><addrLine>Denver, Colorado</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="151" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning language representations for typology prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaitanya</forename><surname>Malaviya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Littell</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-1268</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2529" to="2535" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Exploiting similarities among languages for machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sutskever</surname></persName>
		</author>
		<idno>abs/1309.4168</idno>
		<imprint>
			<date type="published" when="2013" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Rapid adaptation of neural machine translation to new languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="875" to="880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">GloVe: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/D14-1162</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep contextualized word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-1202</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2227" to="2237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">A survey of cross-lingual embedding models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vulic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Søgaard</surname></persName>
		</author>
		<idno>abs/1706.04902</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Filtering and mining parallel data in a joint multilingual space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="228" to="234" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning joint multilingual sentence representations with neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W17-2619</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Representation Learning for NLP</title>
		<meeting>the 2nd Workshop on Representation Learning for NLP<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="157" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A corpus for multilingual document classification in eight languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xian</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC-2018)</title>
		<meeting>the Eleventh International Conference on Language Resources and Evaluation (LREC-2018)<address><addrLine>Miyazaki, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>European Languages Resources Association (ELRA</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Improving neural machine translation models with monolingual data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P16-1009</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="86" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning general purpose distributed sentence representations via large scale multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandeep</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">J</forename><surname>Pal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Conference on Learning Representations</title>
		<meeting>the 6th International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Parallel data, tools and interfaces in OPUS</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörg</forename><surname>Tiedemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC-2012)</title>
		<meeting>the Eighth International Conference on Language Resources and Evaluation (LREC-2012)<address><addrLine>Istanbul, Turkey</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2214" to="2218" />
		</imprint>
	</monogr>
	<note>European Languages Resources Association (ELRA</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">GLUE: A multi-task benchmark and analysis platform for natural language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanpreet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP</title>
		<meeting>the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="353" to="355" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A broad-coverage challenge corpus for sentence understanding through inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adina</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikita</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Bowman</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-1101</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1112" to="1122" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Multilingual seq2seq training with similarity loss for cross-lingual document classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoran</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barlas</forename><surname>Oguz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Third Workshop on Representation Learning for NLP</title>
		<meeting>The Third Workshop on Representation Learning for NLP<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="175" to="179" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">zNLP: Identifying parallel sentences in Chinese-English comparable corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Zweigenbaum</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W17-2510</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th Workshop on Building and Using Comparable Corpora</title>
		<meeting>the 10th Workshop on Building and Using Comparable Corpora<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="51" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Overview of the second BUCC shared task: Spotting parallel sentences in comparable corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Zweigenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Sharoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reinhard</forename><surname>Rapp</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W17-2512</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th Workshop on Building and Using Comparable Corpora</title>
		<meeting>the 10th Workshop on Building and Using Comparable Corpora<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="60" to="67" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Overview of the Third BUCC Shared Task: Spotting Parallel Sentences in Comparable Corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Zweigenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Sharoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reinhard</forename><surname>Rapp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th Workshop on Building and Using Comparable Corpora</title>
		<meeting>the 11th Workshop on Building and Using Comparable Corpora</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
