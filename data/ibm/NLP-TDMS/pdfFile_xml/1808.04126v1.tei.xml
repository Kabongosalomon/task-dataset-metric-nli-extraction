<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Modeling Semantics with Gated Graph Neural Networks for Knowledge Base Question Answering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniil</forename><surname>Sorokin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Ubiquitous Knowledge Processing Lab (UKP) and Research Training Group AIPHES</orgName>
								<orgName type="institution">Technische Universität Darmstadt</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Ubiquitous Knowledge Processing Lab (UKP) and Research Training Group AIPHES</orgName>
								<orgName type="institution">Technische Universität Darmstadt</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Modeling Semantics with Gated Graph Neural Networks for Knowledge Base Question Answering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T18:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The most approaches to Knowledge Base Question Answering are based on semantic parsing. In this paper, we address the problem of learning vector representations for complex semantic parses that consist of multiple entities and relations. Previous work largely focused on selecting the correct semantic relations for a question and disregarded the structure of the semantic parse: the connections between entities and the directions of the relations. We propose to use Gated Graph Neural Networks to encode the graph structure of the semantic parse. We show on two data sets that the graph networks outperform all baseline models that do not explicitly model the structure. The error analysis confirms that our approach can successfully process complex semantic parses.</p><p>This work is licensed under a Creative Commons Attribution 4.0 International License. License details: http:// creativecommons.org/licenses/by/4.0/ 1 https://www.wikidata.org/ 2 We include results for the most recent systems that have published the output on the WebQuestions data set. We compute the number of needed relations from the manual semantic parses provided by <ref type="bibr" target="#b24">Yih et al. (2016)</ref>. arXiv:1808.04126v1 [cs.CL] 13 Aug 2018 7 Since we use Wikidata and WebQSP-WD, the values reported in this work are not directly comparable to those for Freebase. 8  We use again the manually constructed queries provided by <ref type="bibr" target="#b24">Yih et al. (2016)</ref> to estimate it.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Knowledge base question answering (QA) is an important natural language processing problem. Given a natural language question, the task is to find a set of entities in a knowledge base (KB) that constitutes the answer. For example, for a question "What is Princess Leia's home planet?" the answer, "Alderaan", could be retrieved from a general-purpose KB, such as Wikidata 1 . A successful KB QA system would ultimately provide a universally accessible natural language interface to factual knowledge <ref type="bibr" target="#b9">(Liang, 2016)</ref>.</p><p>QA requires precise modeling of the question semantics through the entities and relations available in the KB in order to retrieve the correct answer. <ref type="figure">Figure 1</ref> shows how the above example question could be modeled using Wikidata. The depicted graph structure consists of entities and relations from the KB and the special q-node. Any entity in the KB that can take the place of the q-node will be a part of the answer.</p><p>In this paper, we describe a semantic parsing approach to the problem of KB QA. That is, for each input question, we construct an explicit structural semantic parse (semantic graph), as in <ref type="figure">Figure 1</ref>. Semantic parses can be deterministically converted to a query to extract the answers from the KB. Similar graphical representations were used in previous work <ref type="bibr" target="#b22">(Yih et al., 2015;</ref><ref type="bibr" target="#b14">Reddy et al., 2016;</ref><ref type="bibr" target="#b0">Bao et al., 2016)</ref>.</p><p>However, the modern semantic parsing approaches usually focus either on the syntactic analysis of the input question <ref type="bibr" target="#b14">(Reddy et al., 2016)</ref> or on detecting individual KB relations <ref type="bibr" target="#b18">(Yu et al., 2017)</ref>, whereas the structure of the semantic parse is ignored or only approximately modeled. <ref type="bibr" target="#b14">Reddy et al. (2016)</ref> use the syntactic structure of the question to build all possible semantic parses and then apply a linear model with manually defined features to choose the correct parse. A subset of their features encodes basic information about the graph structure of the semantic parse (e.g. number of nodes). The state-of-the-art approach of <ref type="bibr" target="#b22">Yih et al. (2015)</ref> and <ref type="bibr" target="#b0">Bao et al. (2016)</ref> restricts all semantic parses to a single core relation and a small set of constraints that can be added to it. Their system uses manual features for the constraints and a similarity score between the core relation and the question to model the semantic parses.</p><p>The abovementioned systems were evaluated on the WebQuestions data set <ref type="bibr" target="#b2">(Berant et al., 2013)</ref>. <ref type="figure">Figure 2</ref> plots results for the state-of-the-art systems by the number of relations that needs to be identified to get the correct answer to a question. <ref type="bibr">2</ref> For example, the question in <ref type="figure">Figure 1</ref>  F-score <ref type="bibr" target="#b22">Yih et al. (2015)</ref> Jain (2016) <ref type="bibr" target="#b14">Reddy et al. (2016)</ref>  <ref type="bibr" target="#b1">Berant and Liang (2014)</ref> Figure 2: F-score QA results from previous work by the number of relations needed to find the correct answer to find the answer. It can be clearly seen in <ref type="figure">Figure 2</ref> that the lack of structure modeling in the modern approaches results in a worse performance on more complex questions that require more than one relation.</p><p>We claim that one needs to explicitly model the semantic structure to be able to find the correct semantic parse for complex questions. In this paper, we address this gap and investigate ways to encode the structure of a semantic parse and to improve the performance for more complex questions. In particular, we adapt Gated Graph Neural Networks (GGNNs), described in <ref type="bibr" target="#b8">Li et al. (2016)</ref>, to process and score semantic parses. To verify that GGNNs indeed offer an improvement, we construct a set of baselines based on the previous work that we train and evaluate in the same controlled QA environment. Throughout the experiments, we use the Wikidata open-domain KB <ref type="bibr" target="#b19">(Vrandečić and Krötzsch, 2014)</ref> to construct semantic parses and retrieve the answers. 3</p><p>Contributions To summarize, the main contributions of our work are:</p><p>(i) Our analysis shows that the current solutions for KB QA do not perform well on complex questions;</p><p>(ii) We apply Gated Graph Neural Networks on directed graphs with labeled edges and adapt them to handle a large set of possible entities and relations types from the KB. To the best of our knowledge, we are the first to use GGNNs for semantic parsing and KB QA;</p><p>(iii) Our Gated Graph Neural Network implementation for semantic parsing improves performance on complex questions in comparison to strong baselines. The results show a 27.4% improvement of the F-score against the best non-graph model.</p><p>Code and data sets Our system can be used with a pre-trained model to answer factual questions with Wikidata or trained anew on any data set that has question-answer pairs. The complete code, the scripts that produce the evaluation data and the installation instructions can be found here: https://github. com/UKPLab/coling2018-graph-neural-networks-question-answering.</p><p>2 Semantic parsing</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Semantic graphs</head><p>We employ structural semantic representations in the form of graphs to encode the meaning of a question. Our semantic graphs consist of a question variable node (q), Wikidata entities (Taylor Swift), relation types from Wikidata (PERFORMER) and constraints (see <ref type="figure">Figure 3</ref> for an example graph with a constraint). The q-node is always present and denotes the answer to the question. That is, all entities from the KB that can take its place so that all relations and constraints hold, constitute the answer to the question. We write down a graph as a set of edges E. Each edge links the q-node to one or two Wikidata entities (binary or ternary edge). The edge set E is defined via Wikidata relations and entities. Formally, Wikidata can be described as a very large graph W = (E, R, I), where E is a set of entities, R is a set of binary  <ref type="figure">Figure 4</ref>: A single graph generation step: applying the add entity action a e on an empty graph relation types and I is a collection of relation instances encoded as r(e 1 , e 2 ), r ∈ R, e 1 , e 2 ∈ E (e. g. CAPITAL (Hawaii, Honolulu)). Ternary relation instances in Wikidata are stored as a main relation triple and an attached modifer which itself is also a binary relation: r 2 r 1 (e 1 , e 2 ), e 3 , r 1 , r 2 ∈ R, e 1 , e 2 , e 3 ∈ E (e.g. CHARACTER ROLE CAST MEMBER (Star Wars, Carrie Fisher), Princess Leia . Then, the edge set E of a semantic graph consists of binary and ternary edges that correspond to Wikidata relation instances with q in place of one of the relation arguments. For temporal relations, the second argument can be either an argmax or an argmin constraint. This means that only entities that have the maximum or the minimum value of that relation are considered for the answer. This definition represents a subset of first-order logic semantic parses restricted to conjunctions of predicates. The graphs are also isomorphic to SPARQL queries that can be used to evaluate a graph against the KB. Our semantic graphs were inspired by the query graphs of <ref type="bibr" target="#b22">Yih et al. (2015)</ref> and their extension in <ref type="bibr" target="#b0">Bao et al. (2016)</ref>, the key difference being that we do not differentiate between the core relation and modifiers, but rather allow graphs that have multiple independent relations. We also allow relations to attach to other nodes rather than the q-node, enabling longer relation paths between a known entity and the q-node. Thus, the semantic graphs defined here are a superset of the query graphs in <ref type="bibr" target="#b22">Yih et al. (2015)</ref> and allow us to model more complex meanings. Consequently, they also correspond to the formalized representations used by <ref type="bibr" target="#b13">Reddy et al. (2014)</ref> and the simple λ-DCS <ref type="bibr" target="#b2">(Berant et al., 2013)</ref>, since those were the foundation for the query graphs <ref type="bibr" target="#b22">(Yih et al., 2015)</ref>. <ref type="bibr" target="#b22">Yih et al. (2015)</ref> defined a step-by-step staged graph generation that does not need full syntactic parses and was also adopted in subsequent publications <ref type="bibr" target="#b0">(Bao et al., 2016;</ref><ref type="bibr" target="#b11">Peng et al., 2017)</ref>. We use the same procedure as <ref type="bibr" target="#b22">Yih et al. (2015)</ref> to construct semantic graphs with a set of modifications that allow us to build more expressive and complex graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Semantic graph construction</head><p>We define a set of states and a set of actions that can be applied at each state to extend the current semantic graph. A state is a tuple of a graph and a set of free entities: S = (E, F), where the graph is E, as defined above, and F = {e|e ∈ E}. The set of free entities F is the entities that were identified in the question but were not yet added to the graph. <ref type="bibr">4</ref> The first state is a tuple of an empty graph with no edges and a set of all entities identified in the question S 1 = ({}, F).</p><p>Let A = {a e , a c , a m } be the set of actions that can be taken to extend the graph at the current state. The action a e (add entity) pops a free entity e from the set F at the current state S t . Then it queries the KB and retrieves the set of available relation types R e for the entity e. For each relation type r ∈ R e , it creates a new copy of the graph and adds a new directed edge between the q-node and e with the relation type r: a e (E, F) = {E ∪ r(q, e), F − e | e ∈ F, r ∈ R e }. Contrary to <ref type="bibr" target="#b22">Yih et al. (2015)</ref> and <ref type="bibr" target="#b0">Bao et al. (2016)</ref>, we allow two-step paths between the q-node and the entity e: r(q, d) ∧ r(d, e). <ref type="bibr">5</ref> The action a c (add constraint) pops a free entity e and follows the same procedure as a e , but instead of adding a new edge, it adds a modifier to the last added edge of the graph, thus creating a ternary edge: a c (E, F) = {E ∪ r 2 (r 1 (q, e 1 ), e 2 ), F − e 2 | e 2 ∈ F, r 2 ∈ R e 2 , r 1 (q, e 1 ) ∈ E}. Finally, the action a m   <ref type="figure">Figure 6</ref>: Encoding a graph into initial hidden states </p><formula xml:id="formula_0">h t−1 v h t−1 v h t−1 v h t v h t v h t v</formula><formula xml:id="formula_1">, F) = {E ∪ r(q, argmax), F; E ∪ r(q, argmin), F | r ∈ R d },</formula><p>where R d is a set of KB relation types that allow dates as values. Our semantic graph construction process allows to effectively search the space of possible graphs for a given question through an iterative application of the defined actions A on the last state S t (see, for example, <ref type="figure">Figure 4</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Representation learning</head><p>We follow the state-of-the-art approaches for QA <ref type="bibr" target="#b22">(Yih et al., 2015;</ref><ref type="bibr" target="#b4">Dong et al., 2015;</ref><ref type="bibr" target="#b0">Bao et al., 2016)</ref> and learn representations for the question and every possible semantic graph. Then we use a simple reward function γ to judge if a semantic graph is a correct semantic parse of the input question. Below we describe the architectures that we use to learn the representations for questions and graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Deep Convolutional Networks</head><p>We use Deep Convolutional Neural Networks (DCNN) to learn a representation for a question. DCNNs have been proven effective for constructing sentence-level representations on a variety of NLP tasks, including named entity recognition <ref type="bibr" target="#b18">(Strubell et al., 2017)</ref> and KB QA <ref type="bibr" target="#b22">(Yih et al., 2015;</ref><ref type="bibr" target="#b4">Dong et al., 2015)</ref>. The DCNN architecture is depicted in <ref type="figure" target="#fig_1">Figure 5</ref>, where it is used to map an input question to a fixed-size vector representation. The input question is first tokenized and the special start and end tokens are added to the sequence: x = { s , x 1 , x 2 . . . x n , f }. Next, we map the tokens in x to d w -dimensional pre-trained word embeddings, using a matrix W glove ∈ R |Vw|×dw , where |V w | is the size of the vocabulary. We use 50-dimensional GloVe embeddings that were trained on a 6 billion corpus <ref type="bibr" target="#b12">(Pennington et al., 2014)</ref>. The sequence of word embeddings is further processed by an array of CNN layers. We apply a pooling operation after the last CNN layer and transform the output with a fully connected layer H and a ReLU non-linearity. We take the resulting vector v q as the representation of the question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Gated Graph Neural Networks</head><p>Gate Graph Neural Networks (GGNN) process graphs by iteratively updating representations of graph nodes based on the neighboring nodes and relations <ref type="bibr" target="#b8">(Li et al., 2016)</ref>. We adopt GGNNs for semantic parsing to learn a vector representation of a semantic graph. <ref type="bibr" target="#b8">Li et al. (2016)</ref> give a formulation of GGNNs for graphs with labeled nodes and typed directed edges. We extend their formulation to include labeled edges. To the best of our knowledge, we are the first to apply GGNN to semantic parsing and KB QA.</p><p>For a graph E, we extract a set of all entities V in the graph and a set of all relation types R of its edges. We use labels from Wikidata to compute vectors for entities and relation types ( <ref type="figure">Figure 6</ref>). This enables us to directly incorporate the information on millions of entities and hundreds of relation types from the KB. For an entity e ∈ V or a relation type r ∈ R we retrieve the label and tokenize it: l = {l 1 , l 2 . . . l n }. Then we map each token in l e , l r to a word embedding using the matrix W glove , sum them and process with a fully connected layer to get a single label vector: h l = tanh W l |l| n=1 w n + b l . We initialize the hidden states for the graph nodes with the label vectors of the entities: h</p><p>(1) v = h le . We further transform the relation label vectors to get directional embeddings for relations types:</p><formula xml:id="formula_2">h r = W → h lr , h r = W ← h lr .</formula><p>Using the same word embeddings as an input to construct the question and relation representations has been shown successful in previous work <ref type="bibr" target="#b6">(Jain, 2016)</ref>.</p><p>Propagation Model GGNNs are a type of recurrent neural networks. The recurrence is unrolled for a fixed number of steps T and the gating mechanism works akin to Gated Recurrent Units <ref type="bibr" target="#b3">(Cho et al., 2014)</ref>. The propagation model for GGNN is defined as follows:</p><formula xml:id="formula_3">a (t) v = A v: h (t−1) 1 . . . h (t−1) |V| + A r: h 1 . . . h |R| , h 1 . . . h |R| (1) z t v = σ W z a (t) v + U z h (t−1) v + b z (2) r t v = σ W r a (t) v + U r h (t−1) v + b r (3) h (t) v = tanh Wa (t) v + U r t v h (t−1) v + b (4) h (t) v = (1 − z t v ) h t−1 v + z t v h (t) v ,<label>(5)</label></formula><p>where σ is the logistic sigmoid function and is the element-wise multiplication. The matrix A ∈ R |V|×2|V| stores the structure of the graph: a row of the matrix A v: records the edges between the node v and the other nodes in the graph (we differentiate between incoming and outgoing edges). The second matrix A ∈ R |V|×2|R| stores the relation types of the incoming and outgoing edges. The main difference from the model defined in <ref type="bibr" target="#b8">Li et al. (2016)</ref> is that we compute activations a (t) v based on both the node hidden vectors h (t−1) v and relation hidden vectors h r (Eq 1). The z t v in Eq 2 and r t v in Eq 3 are update and reset gates, that incorporate information from nodes, relation types and from the previous step to update nodes' hidden states at each iteration. We do not make updates to the hidden vectors of the relations and use them only to pass the information to the nodes' hidden states.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Graph-level Output Vector</head><p>We unroll the recurrence for T = 5 steps in the experiments <ref type="figure" target="#fig_2">(Figure 7)</ref>. To produce a graph-level output vector, we take the hidden vector for the q-node at the last time step t = T and transform it with a fully-connected layer and the ReLU non-linearity: v g = ReLU Wh </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data</head><p>We use Wikidata to show experimentally that GGNNs are better at learning representations of semantic graphs than previous approaches. Hence, we choose two data sets that can be processed with Wikidata to compare the GGNNs to other models: WebQSP-WD and QALD-7.</p><p>WebQSP-WD We derive WebQSP-WD from WebQSP <ref type="bibr" target="#b24">(Yih et al., 2016)</ref>, which is a corrected version of the popular WebQuestions data set <ref type="bibr" target="#b2">(Berant et al., 2013)</ref>. WebQSP contains natural language questions, Freebase IDs of the correct answers and SPARQL queries to retrieve them that also use Freebase. Freebase was a common choice of a KB among the previous work, but was discontinued and is no longer up-to-date, including unavailability of APIs and new dumps. The questions in the data set were collected with the Google Suggest API and are thus more 'natural' than manually constructed questions. The answers were retrieved from Freebase with the help of crowd-sourcing. The data set contains both simple questions that can be answered with a single relation as well as complex questions that require multiple relations and constraints. It is a common benchmark for semantic parsers and information retrieval systems and was used in the most recent studies on KB QA. We automatically map Freebase IDs in the WebQSP train and test sets to Wikidata IDs and filter out questions which answers do not have the mapping. We designate this version of the dataset WebQSP-WD. It is important to note that this does not ensure that a question is answerable with Wikidata as there still might be no relation paths in the KB that connect the entities in the question with the answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>QALD-7</head><p>As the second data set, we use QALD-7 that was developed for Task 4 of the QALD-7 Shared Task, "English question answering over Wikidata" <ref type="bibr">(Usbeck et al., 2017)</ref>. The QALD-7 data set contains a small number of manually constructed complex questions that were specifically created to test system's ability to process questions with multiple entities and constraints. The data set uses Wikidata IDs for all annotations. We do not train on QALD-7 data set and use it solely for an out-of-domain evaluation. The data set statistics can be found in <ref type="table">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Models</head><p>We define five models for our experiments, including three baselines and two graph models. We use cosine similarity between the question representation and the semantic graph representation as a reward function that judges whether the semantic graph is the correct parse of the question: γ = cos(v s , v g ).</p><p>1. STAGG (re-implementation of <ref type="bibr" target="#b22">Yih et al. (2015)</ref>) -We implement a model that uses a combination of a neural network and manual features suggested in <ref type="bibr" target="#b22">Yih et al. (2015)</ref> and in the follow up work of <ref type="bibr" target="#b0">Bao et al. (2016)</ref>. The approach of <ref type="bibr" target="#b22">Yih et al. (2015)</ref> performed best among the previous work on complex questions (see <ref type="figure">Figure 2</ref>). First, DCNN is used to produce a representation for the input question, as described in Section 3.1. Then, we replace the entity tokens in the input question with a special entity symbol e and apply DCNN on it again to get a second representation for the question.</p><p>For each semantic graph, we take the label of the relation in the first edge (core edge), tokenize it and likewise apply DCNN on it to get a representation. We produce two representations for the core relation: one that includes the label of the attached entity and one that includes the entity symbol. The manual features include binary indicators for modifiers and constraints in the semantic graphs, as well as features for certain keywords in the question (see <ref type="bibr" target="#b22">Yih et al. (2015)</ref> for a detailed description). 3. Pooled Edges model -We use the DCNN to encode the question and the label of each edge in the semantic graph. To get a fixed-vector representation of the graph, we apply a pooling operation over the representation of the individual edges. This model encodes all information about the semantic graphs, but disregards their structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Graph Neural Network (GNN) -</head><p>To judge the effect of the gated graph neural architecture, we also include a model variant that does not use the gating mechanism and directly computes the hidden state as a combination of the activations (Eq 1) and the previous state.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Gated</head><p>Graph Neural Network (GGNN) -We use the GGNN to process semantic parses, as described in Section 3.2. This model encodes all information from semantic graphs, including their structure, into a vector representation. To encode the question we use the same DCNN model (see Section 3.1).</p><p>The defined baselines use either manual features to capture the structure of the semantic graph (STAGG), a simple pooling mechanism (Pooled Edges) or disregard the structure completely (Single Edge). The two graph models (GNN and GGNN) make the full use of the graph structure of a semantic parse and encode it with graph neural networks. With this set-up, we are able to demonstrate what effect different levels of inclusion of the graph structure into the model have on the final performance for KB QA. We do not include the published models of <ref type="bibr" target="#b2">Berant et al. (2013)</ref> and <ref type="bibr" target="#b13">Reddy et al. (2014)</ref> in the comparison since they were trained on Freebase and are not compatible with Wikidata. We use the more recent STAGG approach to position the graph models against the previous work and the feature-based models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Training the model</head><p>To train the model, we need positive pairs of questions and semantic graphs. Since WebQSP does not contain semantic parses for Wikidata, we use weak supervision as suggested in <ref type="bibr" target="#b2">Berant et al. (2013)</ref>. Specifically, we follow <ref type="bibr" target="#b22">Yih et al. (2015)</ref> and run our semantic graph construction procedure to create training instances (see Section 2.2). We use the state-of-the-art S-MART entity linking system for noisy data <ref type="bibr" target="#b20">(Yang and Chang, 2015)</ref> to extract a set of entities F from each question. 6 Instead of scoring the semantic graphs with the model, we evaluate each graph against Wikidata and compare the extracted answers to the manual answers in the data set. The semantic graphs that result in a correct answer are stored as positive training instances and the rest of the graphs generated during the same process are used as negative instances. Due to the differences between Freebase and Wikidata, some question can not be answered exactly using Wikidata. We generate positive semantic graphs for 1945 questions out of 2880 (see <ref type="table">Table 1</ref>) and put 628 as a development set aside. Practical considerations At each training epoch, we take all positive semantic graphs and up to 100 negative graphs per question. We optimize the maximum margin loss function:</p><formula xml:id="formula_4">L = g∈C max 0, (m − γ(v q , v + g ) + γ(v q , v − g )) ,</formula><p>where C is a set of semantic parses for the given question. From the loss function, we compute updates for the GGNN and the DCNN parts of the model.</p><p>All models are trained using the Adam optimizer <ref type="bibr" target="#b7">(Kingma and Ba, 2014)</ref> with a batch size of 64. We use an early stopping criterion on the development data to determine the number of training epochs. The learning rate is fixed to 0.001 and the other optimization parameters are set as recommended in <ref type="bibr" target="#b7">Kingma and Ba (2014)</ref>: β 1 = 0.9, β 2 = 0.999, = 1e − 08. We apply Dropout <ref type="bibr" target="#b17">(Srivastava et al., 2014)</ref> at every fully-connected layer as well as on the embeddings layers. We determine the hyper-parameters, such as the size of the hidden layer, with the random search on the development set (see <ref type="table" target="#tab_3">Table 2</ref>). On the 1945 training questions, the GGNN model has usually finished training in under two hours on a single GPU.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Inference</head><p>We take the steps described in Section 2.2 to construct possible semantic graphs for a question at inference time. For WebQSP-WD, we use the entities produced by S-MART <ref type="bibr" target="#b20">(Yang and Chang, 2015)</ref> to start the graph construction. On QALD-7, we use the annotated entities provided by the Shared Task organizers. Each question and semantic graph are encoded into fixed-size vector representations and the reward function γ is used to score the graphs. The highest scoring graph is used to retrieve the answers from Wikidata. Given the iterative nature of our semantic graph construction procedure, we adopt beam search to speed up the computation. We score the graphs after each step and select the top 10 to proceed.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>We follow the previous work <ref type="bibr" target="#b2">(Berant et al., 2013)</ref> and use precision, recall and F-score to evaluate the models. The measures are computed for each individual question and then macro-averaged. This ensures a fair evaluation, since a system might provide a partially correct answer that is nevertheless better than a complete miss. We compare the graph models to the baselines including the previous state-of-the-art STAGG architecture. 7</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">WebQSP-WD</head><p>We compare the results on the WebQSP-WD data set in <ref type="table" target="#tab_5">Table 3</ref>. As can be seen, the graph models outperform all other models across precision, recall and F-score, with GGNN showing the best overall result. We confirm thereby that the architecture that encodes the structure of a semantic parse has an advantage over other approaches. To validate the results, we have re-trained the model with different random seeds and observed little variance in the results (F-score, σ = 0.0205). The STAGG architecture delivers the worst results in our experiments, the main reason being supposedly that the model had to rely on manually defined features that are less flexible. The Single Edge model outperforms the more complex Pooled Edges model by a noticeable margin. The Single Edge baseline prefers simple graphs that consist of a single edge which is a good strategy to achieve higher recall values.</p><p>Since our main goal is to produce better encoding of semantic graphs, we break down the performance of the evaluated models by the number of relations that are needed to find the correct answer. 8 In <ref type="figure" target="#fig_5">Figure 8</ref>, we see that for the STAGG and Single Edge baselines the performance on more complex questions drops compared to the results on simpler questions. The Pooled Edges model maintains a better performance across questions of different complexity, which shows the benefits of encoding all graph edges. Looking at <ref type="figure" target="#fig_5">Figure 8</ref> we also get a further insight into the difference between the Single Edge and the Pooled Edges models. These two models achieve almost identical results on the simple questions, which is to be expected since these models are equivalent when the number of edges is 1. On other questions, the Single Edge baseline performs mostly under the Pooled Edges model, but significantly outperforms it on the questions that need 4 edges to get the correct answer.</p><p>We see that the GGNN model offers the best results both on simple and complex questions, as it effectively encodes the structure of semantic graphs. The performance of the model drops for the most complex questions (# of edges ≥ 4). That does not happen for the GNN model variant without the gating mechanism. We conjecture that this happens because GGNN has more parameters than GNN and therefore needs more data to learn. By looking at the model errors on the most complex questions, we could see that GGNN tends to incorrectly predict one of the relations in the graph, which results in a wrong answer. GNN, on the other hand, more often predicts less relations that are needed and therefore gets a non-zero score for a partially correct answer. For example for the question "Who is the prime minister of Spain 2011?", GNN predicts a graph of two relations INSTANCE OF (human) and HEAD OF GOVERNMENT which returns a list of all Spanish prime ministers. The complete correct graph would also include temporal constraints.   Notably, GGNN also has the best performance on the most simple semantic parses that only have one edge. In these cases, two nodes in the graph interact with each other through the single edge in both directions. The GGNN is better at capturing this interaction than other models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">QALD-7</head><p>Next, we examine the out-of-domain results on the QALD-7 data set for the five models (see <ref type="table" target="#tab_6">Table 4</ref>). The difference in performance is less prominent on this data set, but we can observe the same trends. The Single Edge model outperforms both the STAGG and Pooled Edges baselines. The GGNN delivers the best performance, although overall the best result is worse than on the WebQSP-WD data set. QALD-7 is much smaller, but also more complex on average (cf. the average number of edges needed to find the correct answer in <ref type="table">Table 1</ref>). Overall, we can conclude that the explicit modeling of the structure of semantic graphs with GGNN results in a better performance both in-domain on WebQSP-WD and out-of-domain on QALD-7 that was only used for evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Error analysis</head><p>To better understand the difference between the approaches that encode graph structure and the approaches that disregard it, we closely look at the output of GGNN compared to the Pooled Edges model. The first two rows in <ref type="table" target="#tab_8">Table 5</ref> show how often the respective model has returned an answer with F-score higher than 0.5 which is a mostly correct answer and how often it returned an answer that was not just completely wrong (F-score &gt; 0.0). We see that GGNN delivers an acceptable answer almost 25% more often than Pooled Edges model, but there is still a lot of questions that are not answered correctly.</p><p>We have manually analyzed 100 sample answers from the two models where the resulting F-score was lower than 0.5 (see rows 3 through 6 in <ref type="table" target="#tab_8">Table 5</ref>). Since GGNN makes less mistakes in general, the error propagation from the entity linking takes a slightly larger portion of the final error count. In 18% of the cases, it was impossible to find the answer in Wikidata since there were no path between entities in the question and the answer. For example, for the question "Where did Harper Lee attend high school?", the correct answer "Monroe County High School" is a valid entity in Wikidata, but it is not connected to "Harper Lee" via the EDUCATED AT relation. 14% of the time, the data set contained an inconsistent answer and even though the model has predicted the correct semantic graph, the answers did not match. For example, a correct answer for a question about someone's place of birth is usually a city or a town, yet for a smaller set of questions a city borough (e.g. Manhattan) or a country are listed in the data set.</p><p>Overall, in 32% of the cases the error was caused by the gap between the KB and the data set. This lets us put the current results into a perspective with the previously reported numbers for the Freebase KB. If we approximately adjust our results for this kind of errors, we achieve between 0.469 and 0.51 F-score. <ref type="bibr" target="#b14">Reddy et al. (2016)</ref> report results for various approaches ranging from 0.404 to 0.503 F-score on the original WebQuestions data set that is a superset of WebQSP-WD (see Section 4.1).</p><p>The majority of errors for both models are caused by wrong predictions (row 6 in <ref type="table" target="#tab_8">Table 5</ref>). GGNN selects significantly less wrong semantic graphs and more often successfully handles graphs with multiple edges. For example, for a question "What language do people speak in Brazil?", the GGNN model correctly predicts the graph with two edges HOME COUNTRY and NATIVE LANGUAGE to get a list of all languages that are spoken in Brazil. Whereas the other models either select the relation OFFICIAL LANGUAGE that returns only the official language of the country or choose a wrong interpretation altogether. We also look at the hit@10 measure that shows how often the correct semantic graph was in the top 10 scored graphs by the model (row 7 in <ref type="table" target="#tab_8">Table 5</ref>). Notably, in 44% of the cases the correct semantic graph was still among the top scored graphs for the GGNN model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related work</head><p>We have focused on the problem of the increasing error rates for complex questions and the encoding of the semantic graph structure. In this paper, we describe a semantic parsing system for KB QA and follow the approach of <ref type="bibr" target="#b22">Yih et al. (2015)</ref> who do not rely on syntactic parsing to construct semantic parses. Our semantic graphs do not cover some aspects of the first-order logic, such as negation. <ref type="bibr" target="#b14">Reddy et al. (2016)</ref> define a semantic parser that builds first-order logic representations from syntactic dependencies. They further specify how it can be extended with negation in <ref type="bibr" target="#b5">Fancellu et al. (2017)</ref>.</p><p>We only train on the WebQSP-WD data set and we note that more data might be necessary to effectively train the gated graph architecture. <ref type="bibr" target="#b13">Reddy et al. (2014)</ref> suggest an unsupervised learning method to learn a model from a large web corpus, while Su et al. (2016) use patterns and crowdsourcing to create new data with specific properties. These techniques can be used to further improve the performance of our model.</p><p>An alternative solution to semantic parsing is to build an information extraction pipeline that views the question as a query and the KB as a source of relevant information <ref type="bibr" target="#b21">(Yao et al., 2014)</ref>. <ref type="bibr" target="#b4">Dong et al. (2015)</ref> and Jain (2016) construct a vector representation for the question and use it to directly score candidate answers from the KB. However, such approaches are hard to analyze for errors or to modify with explicit constraints. For example, it is not directly possible to implement the temporal sorting constraint (argmax).</p><p>We apply GGNNs to the problem of semantic parsing. <ref type="bibr" target="#b8">Li et al. (2016)</ref> have developed the gated architecture based on the graph neural network formulation of <ref type="bibr" target="#b15">Scarselli et al. (2009)</ref>. Recently, a slightly different design of Graph Convolutional Networks was proven effective on a KB completion task <ref type="bibr" target="#b16">(Schlichtkrull et al., 2018)</ref>. <ref type="bibr" target="#b7">Kipf and Welling (2017)</ref> introduced Graph Convolutional Networks, while <ref type="bibr" target="#b10">Marcheggiani and Titov (2017)</ref> employed them for natural language processing for the first time and compared them to other formulations. Graph Convolutional Networks have a similar gated architecture and share most of the same properties with the Gated Graph Neural Networks used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>In this work, we have used Gated Graph Neural Networks to encode the structure of the target semantic parse for KB QA. We have shown that disregarding the semantic structure leads to a falling performance on questions that require complex semantic parses to get the correct answers. Our GGNN architecture was able to successfully model the structure of semantic parses. We have compared the performance of GGNNs against the previous work and non-graph models on two data sets and have broken down the results by question complexity. The analysis has shown that the suggested graph architectures do not have the same drop in performance on complex questions and produce better overall results.</p><p>Recently, <ref type="bibr" target="#b11">Peng et al. (2017)</ref> and <ref type="bibr" target="#b18">Yu et al. (2017)</ref> have attempted to incorporate entity linking into a feature based QA model. In the future, we plan to follow their work and integrate GGNNs with entity linking into a single model. We also see possible applications for GGNNs on other semantic parsing tasks, such as text comprehension.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure 1: Semantic graph for an example question "What is Princess Leia's home planet?"</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 5 :</head><label>5</label><figDesc>Deep Convolutional Neural Networks (DCNN) architecture, here used to process an exam-</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 7 :</head><label>7</label><figDesc>Unrolled recurrence for one timestep, solid lines show updates along the direction of the relation in the graph and the dashed lines in the opposite direction (add argmax/argmin) adds a new edge with either argmax or argmin sorting constraint to the semantic graph: a m (E</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>The original system and the models of<ref type="bibr" target="#b22">Yih et al. (2015)</ref> and of<ref type="bibr" target="#b0">Bao et al. (2016)</ref> are not available and therefore we use our own implementation of their approach. There is a number of small difference with the original model: we use a deep CNN instead of a single CNN layer and train the DCNN together with the manual features, whereas<ref type="bibr" target="#b22">Yih et al. (2015)</ref> pre-trained the CNN model on a separate corpus and used its output in the feature model.2. Single Edge model -We use the DCNN to encode the question and the label of the first edge of a semantic graph. The rest of the information is ignored.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 :</head><label>8</label><figDesc>Evaluation results by # of relations needed to find the correct answer (bars show # of questions)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>s</head><label></label><figDesc>What was the first Taylor Swift album? f</figDesc><table><row><cell>Question vector</cell><cell></cell><cell></cell><cell>vq</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>H</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Pooling</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>CNN Layer</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>CNN Layer</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>. . .</cell></row><row><cell>Word Emb.</cell><cell>W</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Sent. Tokens</cell><cell>x</cell><cell>x1</cell><cell>x2</cell><cell>x3</cell><cell>x4</cell><cell>. . .</cell></row></table><note>xn . . .</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Optimized hyper-parameter values</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell></cell><cell>P</cell><cell>R</cell><cell>F</cell></row><row><cell>STAGG</cell><cell cols="3">0.1934 0.2463 0.1861</cell></row><row><cell>Single Edge</cell><cell cols="3">0.2173 0.1963 0.1951</cell></row><row><cell>Pooled Edges</cell><cell cols="3">0.1904 0.1800 0.1605</cell></row><row><cell>GNN</cell><cell cols="3">0.1652 0.2072 0.1703</cell></row><row><cell>GGNN</cell><cell cols="3">0.2176 0.2751 0.2131</cell></row><row><cell>: Results on the WebQSP-WD test set</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Results on the QALD-7 data set</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5</head><label>5</label><figDesc></figDesc><table><row><cell>: Manual error analysis results on</cell></row><row><cell>WebQSP-WD</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">At the moment, Wikidata contains more than 40 million entities and 350 million relation instances: https://www.wikidata.org/wiki/Special:Statistics</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">We use an off-the-shelf entity linker to identify and disambiguate entity mentions in the question (see Section 4.4). 5 Freebase relation instances always have an intermediate node and a two-step path corresponds to a single step in Wikidata.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">S-MART is not openly available, but the output on the WebQuestions dataset was made available by<ref type="bibr" target="#b22">Yih et al. (2015)</ref>: https://github.com/scottyih/STAGG</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work has been supported by the German Research Foundation as part of the Research Training Group AIPHES (grant No. GRK 1994/1), and via the QA-EduInf project (grant GU 798/18-1 and RI 803/12-1). We gratefully acknowledge the support of NVIDIA Corporation with the donation of the Titan X GPU.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Constraint-Based Question Answering with Knowledge Graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>References</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on Computational Linguistics (COLING)</title>
		<meeting>the 26th International Conference on Computational Linguistics (COLING)<address><addrLine>Osaka, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2503" to="2514" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Semantic Parsing via Paraphrasing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>52nd Annual Meeting of the Association for Computational Linguistics (ACL)<address><addrLine>Baltimore, MD, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1415" to="1425" />
		</imprint>
	</monogr>
	<note>Berant and Liang2014</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Semantic Parsing on Freebase from Question-Answer Pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Seattle, WA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1533" to="1544" />
		</imprint>
	</monogr>
	<note>Berant et al.2013</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation Kyunghyun</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1724" to="1734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Question Answering over Freebase with Multi-Column Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (ACL-IJCNLP)</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (ACL-IJCNLP)<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="260" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Universal Dependencies to Logical Forms with Negation Scope</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Fancellu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bonnie</forename><surname>Webber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop &quot;Computational Semantics Beyond Events and Roles</title>
		<meeting>the Workshop &quot;Computational Semantics Beyond Events and Roles<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="22" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Question Answering over Knowledge Base using Factual Memory Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarthak</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL Student Research Workshop</title>
		<meeting>the NAACL Student Research Workshop<address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="109" to="115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Semi-Supervised Classification with Graph Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ba2014] Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Conference on Learning Representations (ICLR)</title>
		<meeting>the 5th International Conference on Learning Representations (ICLR)<address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
	<note>Adam: A Method for Stochastic Optimization</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Gated Graph Sequence Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th International Conference on Learning Representations (ICLR)</title>
		<meeting>the 4th International Conference on Learning Representations (ICLR)<address><addrLine>San Juan, Puerto Rico</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning Executable Semantic Parsers for Natural Language Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="68" to="76" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Encoding Sentences with Graph Convolutional Networks for Semantic Role Labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Marcheggiani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Marcheggiani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1506" to="1515" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Maximum Margin Reward Networks for Learning from Explicit and Implicit Supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2358" to="2368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">GloVe: Global Vectors for Word Representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pennington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Large-scale Semantic Parsing without Question-Answer Pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Reddy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="377" to="392" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Siva Reddy, Mirella Lapata, and Mark Steedman</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Transforming Dependency Structures to Logical Forms for Semantic Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Reddy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="127" to="140" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Dipanjan Das, Mark Steedman, and Mirella Lapata</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The Graph Neural Network Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Scarselli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="80" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Modeling relational data with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schlichtkrull</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Semantic Web</title>
		<editor>Aldo Gangemi, Roberto Navigli, Maria-Esther Vidal, Pascal Hitzler, Raphaël Troncy, Laura Hollink, Tordai Anna, and Mehwish Alam</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="593" to="607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Dropout: A Simple Way to Prevent Neural Networks from Overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Srivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Fast and Accurate Entity Recognition with Iterated Dilated Convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Strubell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<editor>Mauro Dragoni, Monika Solanki, and Eva Blomqvist</editor>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Copenhagen, Denmark; Austin, Texas; Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="59" to="69" />
		</imprint>
	</monogr>
	<note>Semantic Web Challenges</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Wikidata: A Free Collaborative Knowledgebase</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denny</forename><surname>Vrandečić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Krötzsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="78" to="85" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">S-MART: Novel Tree-based Structured Learning Algorithms Applied to Tweet Entity Linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (ACL-IJCNLP)</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (ACL-IJCNLP)<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="504" to="513" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Freebase QA: Information Extraction or Semantic Parsing?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2014 Workshop on Semantic Parsing</title>
		<meeting>the ACL 2014 Workshop on Semantic Parsing<address><addrLine>Baltimore, MD, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="82" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Semantic Parsing via Staged Query Graph Generation: Question Answering with Knowledge Base</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd</title>
		<meeting>the 53rd</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (ACL-IJCNLP)</title>
		<meeting><address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="1321" to="1331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The Value of Semantic Parse Labeling for Knowledge Base Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<editor>Yu, Wenpeng Yin, Kazi Saidul Hasan, Cicero dos Santos, Bing Xiang, and Bowen Zhou</editor>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics (ACL)<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="201" to="206" />
		</imprint>
	</monogr>
	<note>Proceedings of the 55th</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting><address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="571" to="581" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
