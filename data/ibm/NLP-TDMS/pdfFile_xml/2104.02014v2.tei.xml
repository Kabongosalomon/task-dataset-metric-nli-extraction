<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SPGISpeech: 5,000 hours of transcribed financial audio for fully formatted end-to-end speech recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><forename type="middle">K</forename><surname>O&amp;apos;neill</surname></persName>
							<email>patrick.oneill@kensho.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Kensho Technologies</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vitaly</forename><surname>Lavrukhin</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">NVIDIA Technologies</orgName>
								<address>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Somshubra</forename><surname>Majumdar</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">NVIDIA Technologies</orgName>
								<address>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vahid</forename><surname>Noroozi</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">NVIDIA Technologies</orgName>
								<address>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuekai</forename><surname>Zhang</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Johns Hopkins University</orgName>
								<address>
									<settlement>Baltimore</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksii</forename><surname>Kuchaiev</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">NVIDIA Technologies</orgName>
								<address>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jagadeesh</forename><surname>Balam</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">NVIDIA Technologies</orgName>
								<address>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuliya</forename><surname>Dovzhenko</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Kensho Technologies</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keenan</forename><surname>Freyberg</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Kensho Technologies</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">D</forename><surname>Shulman</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Kensho Technologies</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Ginsburg</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">NVIDIA Technologies</orgName>
								<address>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinji</forename><surname>Watanabe</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Johns Hopkins University</orgName>
								<address>
									<settlement>Baltimore</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Kucsko</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Kensho Technologies</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SPGISpeech: 5,000 hours of transcribed financial audio for fully formatted end-to-end speech recognition</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T06:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Abstract</head><p>In the English speech-to-text (STT) machine learning task, acoustic models are conventionally trained on uncased Latin characters, and any necessary orthography (such as capitalization, punctuation, and denormalization of non-standard words) is imputed by separate post-processing models. This adds complexity and limits performance, as many formatting tasks benefit from semantic information present in the acoustic signal but absent in transcription. Here we propose a new STT task: endto-end neural transcription with fully formatted text for target labels. We present baseline Conformer-based models trained on a corpus of 5,000 hours of professionally transcribed earnings calls, achieving a CER of 1.7. As a contribution to the STT research community, we release the corpus free for noncommercial use. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Introduction</head><p>In the English speech-to-text (STT) task, acoustic model output typically lacks orthography, the full set of conventions for expressing the English language in writing (and especially print) 2 <ref type="bibr">[1]</ref>. Acoustic models usually render uncased Latin characters, and standard features of English text such as capitalization, punctuation, denormalization of non-standard words, and other formatting information are omitted. While such output is suitable for certain purposes like closed captioning, it falls short of the standard of English orthography expected by readers and can even pose problems for certain downstream NLP tasks such as natural language understanding, neural machine translation and summarization <ref type="bibr">[2,</ref><ref type="bibr" target="#b0">3]</ref>. In contexts where standard English orthography is required, therefore, it is typically provided after the fact by a pipeline of post-processing models that infer a single aspect of formatting each from the acoustic model output.</p><p>This approach suffers several drawbacks. First, rendering orthographically correct text is the more natural task: if asked to transcribe audio and given no further instructions, a normally literate English speaker will tend to generate orthographic text. By contrast, writing in block capitals without punctuation, spelling out numbers in English and so on, is a far less conventional style. Secondly, certain types of orthographic judgments 1 https://datasets.kensho.com/datasets/scribe 2 We concede that the precise details of English orthography can vary by time, geographical region, and even publication house style. We nevertheless ostensively define orthographic text here to mean "text as it generally appears in U.S. print publications". are possible only with acoustic information and cannot be reliably inferred from text alone. Consider, for example, the problem of inferring the correct EOS marker for the sentence "the CEO retired" (either of a period or question mark) without the information carried in vocal pitch. Third, the practice of chaining orthography-imputing models into pipelines tends to encumber STT systems. Each orthographic feature may require a model of significant engineering effort in its own right (cf. <ref type="bibr" target="#b1">[4,</ref><ref type="bibr" target="#b2">5,</ref><ref type="bibr" target="#b3">6,</ref><ref type="bibr" target="#b4">7,</ref><ref type="bibr" target="#b5">8,</ref><ref type="bibr" target="#b6">9]</ref>), and improvements to one model's performance may degrade end-to-end performance as a whole due to distribution shift <ref type="bibr" target="#b7">[10]</ref>.</p><p>Modern STT models require large volumes of high-quality training data, and to our knowledge there is no extant public corpus suitable for the fully-formatted, end-to-end STT task. To address this limitation we release SPGISpeech 3 , a subset of the financial audio corpus described in <ref type="bibr" target="#b8">[11]</ref>. SPGISpeech offers: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Prior Work</head><p>There are many extant STT corpora, varying in their volumes as well as in the details of their formats. Early corpora include the Wall Street Journal corpus, consisting of 80 hours of narrated news articles <ref type="bibr" target="#b9">[12]</ref>, SWITCHBOARD, containing approximately 300 hours of telephone conversations <ref type="bibr" target="#b10">[13]</ref>; TIMIT, consisting of a set of ten phonetically balanced sentences read by hundreds of speakers (∼ 50 h) <ref type="bibr" target="#b11">[14]</ref>; and the Fisher corpus of transcribed telephone conversations (2,000 h) <ref type="bibr" target="#b12">[15]</ref>. The LibriSpeech corpus, a standard benchmark for STT models, consists of approximately 1000 hours of narrated audiobooks <ref type="bibr" target="#b13">[16]</ref>. Although the use of audiobooks as an STT corpus allows researchers to leverage a large pre-existing body of transcription work, this approach poses several limitations. First, LibriSpeech consists entirely of narrated text, hence it <ref type="bibr" target="#b0">3</ref> Rhymes with "squeegee".  <ref type="table" target="#tab_3">Table 3</ref>.</p><p>lacks many of the acoustic and prosodic features of spontaneous speech. Second, as the narrated books are public domain texts, there is a bias in the corpus towards older works, and hence against more modern registers of English.</p><p>Other corpora include TED-LIUM (450 hours of transcribed TED talks) <ref type="bibr" target="#b14">[17]</ref> and Common Voice (a multilingual corpus of narrated prompts with ∼ 1,100 validated hours in English) <ref type="bibr" target="#b15">[18]</ref>, and GigaSpeech (10,000 hours from audiobooks, podcasts and YouTube videos) <ref type="bibr" target="#b16">[19]</ref>. We present a comparison to select corpora in <ref type="table">Table 1</ref>; a more exhaustive catalogue of prior STT corpora can be found in <ref type="bibr" target="#b17">[20]</ref>.</p><p>Within this field of previous work, SPGISpeech is distinctive for being over ten times larger than the next largest corpus with orthographic ground truth labels. It also contains approximately 50,000 speakers, the largest number to our knowledge of any public corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Corpus Definition</head><p>The SPGISpeech corpus is derived from company earnings calls manually transcribed by S&amp;P Global, Inc. according to a professional style guide detailing conventions for capitalization, punctuation, denormalization of non-standard words and transcription of disfluencies in spontaneous speech. The basic unit of SPGISpeech is a pair consisting of a 5 to 15 second long 16 bit, 16kHz mono wav audio file and its transcription.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Alignment and Slicing</head><p>Earnings calls last 30-60 minutes in length and are typically transcribed as whole units, without internal timestamps. In order to produce short audio slices suitable for STT training, the files were segmented with Gentle [21], a double-pass forced aligner, with the beginning and end of each slice of audio imputed by voice activity detection with py-webrtc <ref type="bibr" target="#b19">[22]</ref>. While there is inevitably a potential to introduce certain systematic biases through this process, the fraction of recovered aligned audio per call ranges from approximately 40% in the calls of lowest audio quality to approximately 70% in the highest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Corpus Definition</head><p>Slices in SPGISpeech are not a simple random sample of the available data, but are subject to certain exclusion criteria.</p><p>1. We sampled no more than four consecutive slices from any call. We also redacted the corpus out of concern for individual privacy. Though earnings calls are public, we nevertheless identified full names with the spaCy en core web large model <ref type="bibr" target="#b20">[23]</ref>, which we selected on grounds of its wall clock performance for scanning the entire corpus. We withheld slices containing names that appeared fewer than ten times (7% of total). Full names appearing ten times or more in the data were considered to be public figures and were retained. This necessarily incomplete approach to named entity recognition was complemented with randomized manual spot checks which uncovered no false negatives missed by the automated approach.</p><p>2. We excluded all slices that contain currency information (8% of total), on the grounds that currency utterances often have non-trivial denormalizations and misquotation issues that require global context in order to render correctly. The utterance ''one twenty three'', for example, might be correctly transcribed as any of $1.23, £1.23, $1.23 million, and so on, depending on context. Given the potential for material errors in a business setting if reported incorrectly, moreover, misquotation of currency values in spontaneous speech are typically corrected in transcription. Lacking the means to verify the correct spoken form for each currency mention, we simply exclude them.</p><p>3. We excluded slices with transcriptions containing non-ASCII characters. In particular we excluded all slices whose transcripts did not consist entirely of the upperand lowercase ASCII alphabet; digits; the comma, period, apostrophe, hyphen, question mark, percent sign, and space characters.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Corpus Analysis</head><p>We briefly characterize the data. Summary statistics are given in <ref type="table" target="#tab_3">Table 3</ref>. Several representative examples are given in <ref type="table" target="#tab_2">Table 2</ref>, highlighting some of the challenges SPGISpeech presents for end-to-end training. The table contains samples from the validation split where the correct EOS marker is difficult to infer from the transcription of the slice alone, non-standard words that must be denormalized, disfluencies and hesitations arising from self-correction in spontaneous speech, and instances like year abbreviations where semantic information is likely necessary to determine the correct orthography. In each instance we also report characteristic Conformer model output (see Section 6), demonstrating the feasibility of end-to-end orthographic transcription for these examples. SPGISpeech contains many specialized forms and entity types such as acronyms (15% of all slices), pauses (10%), organizations (25%), persons (8%), and locations (8%). For each form we estimate its prevalence from a random sample of transcripts. Prevalences of the named entity types person, organization and location were estimated using Flair <ref type="bibr" target="#b21">[24]</ref>, which we selected on grounds of its accuracy and acceptable wall clock performance for scanning a small sample of the corpus.</p><p>There are roughly 50,000 speakers in SPGISpeech, drawn from corporate officers and analysts appearing in English earnings calls and spanning a broad cross-section of L1 and L2 accents. We attempted to characterize this linguistic diversity by tabulating the domiciles of the corporate headquarters of the companies in the corpus. In <ref type="figure" target="#fig_0">Fig. 1</ref> we report the distribution of the global region associated with each company's headquarters as listed in in the S&amp;P Capital IQ database <ref type="bibr" target="#b22">[25]</ref>. To fur- ther refine the picture of accent composition, we next considered the distribution of countries of corporate domicile. We found it to be long-tailed, the top five most common nations (US, Japan, UK, India, Canada) comprising 2/3 rds of the data. Although a few of the twenty most frequent countries are reputed for encouraging strategic corporate domiciling, we find that their combined share of the total is low, suggesting that their inclusion does not significantly distort the bulk statistics. While imputation of speaker accent from corporate domicile is a necessarily limited approach, we found the observed statistics to be broadly concordant with direct estimation of accent in a random sample. The number of speakers and diversity of accents in SPGISpeech is, to our knowledge, the widest of any public corpus of spontaneous speech, making it especially suitable for training robust STT models.</p><p>Lastly, we analyzed the industrial composition of included companies in order to ensure that they constituted a representative cross-section of business topics. All eleven top-level sectors of the Global Industry Classification Standard (GICS) <ref type="bibr" target="#b23">[26]</ref> are reflected in the data at rates roughly comparable to their proportions in the US economy. SPGISpeech, not being constrained to any particuar company or industrial sector, therefore offers a fairly synoptic view of modern English business discourse.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Transcription Experiments</head><p>To illustrate the feasibility of the end-to-end orthographic approach we train several models on SPGISpeech, including Conformer (ESPnet) and Conformer-CTC (Nemo).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Model Descriptions and Methods</head><p>Both presented models are based on the recently proposed Conformer (Convolution-Augmented Transformer) architecture <ref type="bibr" target="#b24">[27]</ref> which combines the local sensitivities of convolutional neural networks <ref type="bibr" target="#b25">[28,</ref><ref type="bibr" target="#b26">29]</ref>, with the long-range interactions of transformers <ref type="bibr" target="#b27">[30]</ref> in order to capture both local and global dependencies in audio sequences. The unit of prediction for both models consists of SentencePiece tokenized text <ref type="bibr" target="#b28">[31]</ref>, whose detokenized output is upper-and lower-case characters, digits, the comma, period, apostrophe, hyphen, question mark, percent sign, and the space character, covering the full range of characters present in SPGISpeech.</p><p>The ESPnet Conformer model presented consists of 12 conformer blocks with an output dimension of 512 and a kernel size of 31 in the encoder, and 6 transformer blocks in the decoder. Both encoder and decoder have 8 attention heads with 2048 feed-forward unit dimension. The size of the vocabulary was chosen at ∼5k. The model was trained using four 24Gb memory Titan RTX GPUs for 35 epochs. Adam optimizer with no weight decay was used and Noam learning rate scheduler was applied with 25k warmup steps and a learning rate of 0.0015. SpecAug was used with 2 frequency masks and 5 time masks. The last 10 best checkpoints were averaged for the final model. Detailed setups can be found in the ESPnet recipe <ref type="bibr" target="#b1">4</ref> .</p><p>The Conformer-CTC model, provided through the NeMo toolkit <ref type="bibr" target="#b29">[32]</ref>, is a CTC-based variant of the Conformer which has the same encoder but uses CTC loss <ref type="bibr" target="#b30">[33]</ref> instead of RNNT <ref type="bibr" target="#b31">[34]</ref>. It also replaces the LSTM decoder with a linear decoder on the top of the encoder. This makes Conformer-CTC a nonautoregressive model unlike the original Conformer, allowing for significantly faster inference speeds. The presented model was trained for 230 epochs at an effective batch size of 4096, with Adam optimizer and no weight decay. SpecAug was applied with 2 frequency maskings of 27, and 5 time maskings at a maximum ratio of 0.05. Noam learning scheduler was used with a warmup of 10k steps and learning rate of 2.0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Results and Discussion</head><p>As performance on the orthographic STT task hinges in large part on single-character distinctions such as capitalization and punctuation, we report both WER and CER for the test split of SPGISpeech, closely tracking the performance on the val split. We also estimate the respective error rates for a normalized transcription task by lowercasing the output and filtering all but letters, the apostrophe and the space character to conform to the conventional choice of STT vocabulary. Both results are shown in <ref type="table" target="#tab_5">Table 4</ref>.</p><p>Our results demonstrate CERs in the orthographic STT task comparable to those obtained on standard normalized corpora. While we caution against laying undue stress upon any one particular comparison made across studies, they suggest on the  whole that English orthography is within the grasp of modern acoustic architectures, and hence end-to-end orthographic STT is a feasible task. Both models achieve WERs of less than 6.0 and CERs less than 2.0, making them broadly comparable to previous results obtained with Conformer in other corpora <ref type="bibr" target="#b24">[27]</ref>.</p><p>A comparison of the ortho and norm error rates suggests that 1/2 to 2/3 rds of the error is due to orthographic issues. One must recall, however, that there is a lower bound imposed by irreducible error: in some cases there is genuine disagreement as to whether a pause merits a comma, or whether a hesitation should be recorded or emended. For the disfluency given in <ref type="table" target="#tab_2">Table 2</ref>, for example, the model smoothly emends the first repeated word but records the second correction while omitting the partially pronounced word "limit": some degree of judgment in the training labels, and hence irreducible error, is inevitable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusions</head><p>In this work we introduced a new end-to-end task of fully formatted speech recognition, in which the acoustic model learns to predict complete English orthography. This approach is both conceptually simpler and can lead to improved accuracy due to acoustic cues only present in the the audio, which are needed for full formatting. We demonstrated the feasibility of this approach by training models on SPGISpeech, a corpus uniquely suited for the task of large scale, fully formatted end-to-end transcription in English. As a contribution to the STT research community, we also offer SPGISpeech for free academic use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Acknowledgements</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Distribution of Speakers by Global Region. Speaker distribution is estimated in a random sample according to reported region of corporate domicile.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Comparison of SPGISpeech to peer corpora. For a select group of comparable STT corpora, we compare the recording format, discursive domain, metadata and quantity of audio. Numeric data are rounded; precise values for SPGISpeech are given in</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Corpus name</cell><cell cols="2">Acoustic condition</cell><cell>Speaking style</cell></row><row><cell></cell><cell></cell><cell cols="2">Switchboard</cell><cell></cell><cell>Telephone</cell><cell>Spontaneous</cell></row><row><cell></cell><cell></cell><cell cols="2">Librispeech</cell><cell cols="2">Close-talk mic.</cell><cell>Narrated</cell></row><row><cell></cell><cell></cell><cell cols="2">TedLium-3</cell><cell cols="2">Close-talk mic.</cell><cell>Narrated</cell></row><row><cell></cell><cell></cell><cell cols="2">Common Voice</cell><cell cols="2">Teleconference</cell><cell>Narrated</cell></row><row><cell></cell><cell></cell><cell cols="2">SPGISpeech</cell><cell cols="2">Teleconference</cell><cell>Spontaneous, Narrated</cell></row><row><cell></cell><cell></cell><cell>Corpus name</cell><cell cols="5">Transcription Style Speaker Count Vocabulary Size Amount (h)</cell></row><row><cell></cell><cell></cell><cell>Switchboard</cell><cell cols="2">Orthographic</cell><cell>550</cell><cell>25,000</cell><cell>300</cell></row><row><cell></cell><cell></cell><cell>Librispeech</cell><cell cols="2">Non-orthographic</cell><cell>2,400</cell><cell>200,000</cell><cell>960</cell></row><row><cell></cell><cell></cell><cell>TedLium-3</cell><cell cols="2">Non-orthographic</cell><cell>2,000</cell><cell>160,000</cell><cell>450</cell></row><row><cell></cell><cell></cell><cell>Common Voice</cell><cell cols="2">Non-orthographic</cell><cell>40,000</cell><cell>220,000</cell><cell>1,400</cell></row><row><cell>arXiv:2104.02014v2 [cs.CL] 6 Apr 2021</cell><cell>Table 1:</cell><cell>SPGISpeech</cell><cell cols="2">Orthographic</cell><cell>50,000</cell><cell>100,000</cell><cell>5,000</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Punctuation Transcript: early in April versus what was going on at the beginning of the quarter? Verbatim: early you know in april versus uh what was going on at the beginning of the quarter Model Output: early in April versus what was going on at the beginning of the quarter? Non-standard words Transcript: [...] for the first time in our 92-year history, we [...] Verbatim: [...] for the first time in our ninety two year history we [...] Model Output: [...] for the first time in our 92-year history, we [...] Disfluency Transcript: As respects our use of insurance to put out --reinsurance to put out [...] Verbatim: as as respects our use of insurance to put out lim reinsurance to put out [...] Model: As respects our use of insurance to put out --reinsurance to put out [...] Abbreviations Transcript: in '15, and got margins back to that kind of mid-teens level [...] Verbatim: in fifteen and got margins back to that kind of mid teens level [...] Model Output: in '15 and got margins back to kind of that mid-teens level [...] Examples of non-standard text in SPGISpeech. For each textual feature we give an example of the ground truth transcript label, a verbatim transcription without casing or punctuation, and Conformer model output with end-to-end orthographic training.</figDesc><table><row><cell></cell><cell>Train</cell><cell>Val</cell></row><row><cell>Events</cell><cell>55,289</cell><cell>1,114</cell></row><row><cell>Slices</cell><cell cols="2">1,966,109 39,341</cell></row><row><cell>Time (h)</cell><cell>5,000</cell><cell>100</cell></row><row><cell>Vocabulary</cell><cell>100,166</cell><cell>19,865</cell></row><row><cell>OOV</cell><cell>-</cell><cell>703</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>SPGISpeech Summary Statistics.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Model Results. Greedy word error rate and character error rate on the SPGISpeech test set. ortho numbers refer to the unnormalized, fully formatted orthographic output, while norm numbers refer to a lowercased and reduced vocabulary to remove the effects of text formatting.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">. Remaining slices were randomly subsampled in order to construct the published corpus, which consists of two splits, train and val, having no call events in common. We also construct a private test split, defined exactly as val and having no calls in common with it, which we do not release.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">https://github.com/espnet/espnet/tree/ master/egs2/spgispeech</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The authors wish to thank the S&amp;P Global Market Intelligence Transcripts team for data collection and annotation; Bhavesh Dayalji, Abhishek Tomar, Richard Neale and Gabriela Pereyra for their project support; and Shea Hudson Kerr and Stacey Steele for helpful legal guidance.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">References</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Modeling punctuation prediction as machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Peitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Freitag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Workshop on Spoken Language Translation (IWSLT</title>
		<meeting>the International Workshop on Spoken Language Translation (IWSLT</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Rnn approaches to text normalization: A challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sproat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jaitly</surname></persName>
		</author>
		<idno>abs/1611.00068</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Deep learning for punctuation restoration in medical reports</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Salloum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Finley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Suendermann-Oeft</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/W17-2319" />
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2017-08" />
			<biblScope unit="page" from="159" to="164" />
		</imprint>
	</monogr>
	<note>Canada</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">A mostly data-driven approach to inverse text normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pusateri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Ambati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brooks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Plátek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcallaster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nagesha</surname></persName>
		</author>
		<editor>INTERSPEECH</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Fast and accurate capitalization and punctuation for automatic speech recognition using transformer and chunk merging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">B H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Phuong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">T</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Mai</surname></persName>
		</author>
		<idno type="DOI">10.1109/O-COCOSDA46868.2019.9041202</idno>
		<ptr target="https://doi.org/10.1109/O-COCOSDA46868.2019.9041202" />
	</analytic>
	<monogr>
		<title level="m">22nd Conference of the Oriental COCOSDA International Committee for the Co-ordination and Standardisation of Speech Databases and Assessment Techniques, O-COCOSDA 2019</title>
		<meeting><address><addrLine>Cebu, Philippines</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Correction of automatic speech recognition with transformer sequence-to-sequence model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Hrinchuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Popova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ginsburg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<biblScope unit="page" from="7074" to="7078" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sunkara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shivade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bodapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kirchhoff</surname></persName>
		</author>
		<title level="m">Neural inverse text normalization</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Hidden technical debt in machine learning systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sculley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Holt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Golovin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Davydov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ebner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-F</forename><surname>Crespo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dennison</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>C. Cortes, N. Lawrence, D. Lee, M. Sugiyama, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">28</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Cross-language transfer learning, continuous learning, and domain adaptation for end-to-end automatic speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Kuchaiev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>O&amp;apos;neill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lavrukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Flores</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kucsko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ginsburg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Multimedia and Expo</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The design for the Wall Street Journal-based CSR corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Baker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Speech and Natural Language: Proceedings of a Workshop Held at</title>
		<meeting><address><addrLine>Harriman, New York</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">SWITCH-BOARD: Telephone speech corpus for research and development</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Godfrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">C</forename><surname>Holliman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mcdaniel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICASSP</title>
		<imprint>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">DARPA TIMIT acoustic phonetic continuous speech corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Garofolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">F</forename><surname>Lamel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">M</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Fiscus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Pallett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">L</forename><surname>Dahlgren</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The Fisher Corpus: a resource for the next generations of speech-to-text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Walker</surname></persName>
		</author>
		<ptr target="http://www.lrec-conf.org/proceedings/lrec2004/pdf/767.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC&apos;04)</title>
		<meeting>the Fourth International Conference on Language Resources and Evaluation (LREC&apos;04)<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-05" />
		</imprint>
	</monogr>
	<note>European Language Resources Association (ELRA)</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Librispeech: an ASR corpus based on public domain audio books</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Panayotov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Povey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Khudanpur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">TED-LIUM 3: twice as much data and corpus repartition for experiments on speaker adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hernandez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghannay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tomashenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Estève</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Common Voice: A massively-multilingual speech corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ardila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Henretty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kohler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Morais</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Saunders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tyers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Weber</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Gi-gaSpeech: An evolving, multi-domain ASR corpus with 10,000 hours of transcribed audio</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">W</forename><surname>Wei-Qiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Povey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Trmal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Khudanpur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yan</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>submitted to INTERSPEECH, 2021</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A categorization of robust speech processing datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Roux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mitsubishi Electric Research Labs TR2014-116</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gentle</forename><surname>Lowerquality</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Aligner</surname></persName>
		</author>
		<ptr target="https://lowerquality.com/gentle/" />
		<imprint>
			<date type="published" when="2020-05-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wiseman</surname></persName>
		</author>
		<ptr target="https://github.com/wiseman/py-webrtcvad" />
		<imprint>
			<date type="published" when="2016-05-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">spaCy 2: Natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Honnibal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Montani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Contextual string embeddings for sequence labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Akbik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Blythe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vollgraf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING 2018, 27th International Conference on Computational Linguistics</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1638" to="1649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">S&amp;p capital iq</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
		<ptr target="www.capitaliq.com" />
		<imprint>
			<date type="published" when="2012-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">The global industry classification standard (GICS)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S C</forename></persName>
		</author>
		<ptr target="https://www.msci.com/gics" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Conformer: Convolutionaugmented transformer for speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gulati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-C</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.08100</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fukushima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="193" to="202" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Hamid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Penn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.1109/TASLP.2014.2339736</idno>
		<ptr target="https://doi.org/10.1109/TASLP.2014.2339736" />
	</analytic>
	<monogr>
		<title level="j">IEEE ACM Trans. Audio Speech Lang. Process</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1533" to="1545" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">U</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
	<note>Online</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">SentencePiece: A simple and language independent subword tokenizer and detokenizer for neural text processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Richardson</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/D18-2012" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations. Brussels, Belgium: Association for Computational Linguistics</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations. Brussels, Belgium: Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018-11" />
			<biblScope unit="page" from="66" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Nemo: a toolkit for building ai applications using neural modules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Kuchaiev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Hrinchuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Leary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ginsburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kriman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Beliaev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lavrukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Castonguay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Popova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Cohen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fernández</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gomez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning</title>
		<meeting>the International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="369" to="376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Sequence transduction with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML 29</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
