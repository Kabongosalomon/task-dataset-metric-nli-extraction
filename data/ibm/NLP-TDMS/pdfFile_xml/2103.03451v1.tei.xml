<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Study Group Learning: Improving Retinal Vessel Segmentation Trained with Noisy Labels</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqian</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanchao</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Humphrey</forename><surname>Shi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Oregon</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Study Group Learning: Improving Retinal Vessel Segmentation Trained with Noisy Labels</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T21:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Retinal vessel segmentation · Image enhancement</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Retinal vessel segmentation from retinal images is an essential task for developing the computer-aided diagnosis system for retinal diseases. Efforts have been made on high-performance deep learningbased approaches to segment the retinal images in an end-to-end manner. However, the acquisition of retinal vessel images and segmentation labels requires onerous work from professional clinicians, which results in smaller training dataset with incomplete labels. As known, data-driven methods suffer from data insufficiency, and the models will easily overfit the small-scale training data. Such a situation becomes more severe when the training vessel labels are incomplete or incorrect. In this paper, we propose a Study Group Learning (SGL) scheme to improve the robustness of the model trained on noisy labels. Besides, a learned enhancement map provides better visualization than conventional methods as an auxiliary tool for clinicians. Experiments demonstrate that the proposed method further improves the vessel segmentation performance in DRIVE and CHASE DB1 datasets, especially when the training labels are noisy. Our code is available at https://github.com/SHI-Labs/ SGL-Retinal-Vessel-Segmentation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Retinal inspection is an effective approach for the diagnose of multiple retinal diseases including diabetic retinopathy, epiretinal membrane, retinal detachment, retinal tear etc. Among them, retinal vacular disorders which affects retinal blood vessels are usually caused by other medical diseases like artherosclerosis, hypertension, or human blood circulation problems <ref type="bibr" target="#b1">[2]</ref>. Those disorders will severely influence human's vision functions and cause obvious symptoms, but can be effectively diagnosed and analyzed by retinal vessel inspection in the collected fundus images. Advanced medical imaging system makes it possible to obtain high-resolution fundus images. However, in practical medical services, visual inspection may still require the involvement and tedious work of neurologists, cardiologists, ophthalmologists, and other experts in retinal vascular diseases. To release their burden on screening multiple diseased retino from thousands even millions of healthy retinos, an automatic and high-performance Computer-Aided Diagnosis (CAD) system is desirable to conduct pre-screening and other auxiliary works. Specifically for retinal vascular diseases, we expect the system to provide high-quality enhanced images for a better visualization, and reasonable segmentation of the vessel patterns from the complex and noisy images.</p><p>Plenty of previous efforts have been made in automatic retinal vessel segmentation. Conventionally, hand-crafted filters <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b26">27]</ref> like Gabor <ref type="bibr" target="#b12">[13]</ref> and Gaussian-based ones <ref type="bibr" target="#b11">[12]</ref> are explored to extract features for pixel selection, vessel clustering and segmentation. Recently, data-driven based methods utilize UNet-based model <ref type="bibr" target="#b16">[17]</ref> or its variants <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b9">10]</ref> to achieve significant performance compared with traditional methods. Those deep learning methods focus on the design of UNet structures with better feature representation <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b23">24]</ref>, or the decouple of structure and textures of retinal images <ref type="bibr" target="#b28">[29]</ref>. However, datadriven methods highly suffer from over-fitting issues when the given training data is insufficient. Previously proposed methods cannot overcome the issues of small-scale training data with noisy labels given by the clinicians.</p><p>Effectively training networks with noisy labels <ref type="bibr" target="#b19">[20]</ref> is a rigid need in industry and an interesting task in academia. Previous research works mostly focus on image classification tasks and develop methodologies like optimizing robust loss functions <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b30">31]</ref>, regularizing labels <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b13">14]</ref>, or actively selecting samples <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b6">7]</ref> etc.. However, noisy pixel-level labels existing in segmentation tasks are not wellstudied, especially for medical image processing tasks. Shu et al. proposed a LVC-Net <ref type="bibr" target="#b17">[18]</ref> to adjust the incorrect pixel-wise labels via a deformable spatial transformation module guided by low-level visual cues. But their method cannot be applied to retinal blood vessel images, because the entire small blood vessels may be mislabeled and cannot be corrected via spatial transformation. Xue et al. <ref type="bibr" target="#b25">[26]</ref> studied a multi-stage training framework with sample selection for chest Xray images. They synthesized noisy annotations with image dilation and erosion. However, due to the thickness of blood vessels and less training data compared to other medical image data, neither label synthesis nor sampling procedures are suitable for blood vessel images. Considering the characteristics of blood vessel images, we introduce a novel noisy label synthesis pipeline for retinal vessel images, and propose a Study-Group Learning (SGL) framework to improve the model robustness on noisy labels.</p><p>In this paper, we mainly study the two main practical problems for retinal vessel segmentation task. First, we explore the deeply unsupervised learned enhancement of the original retinal images compared with traditional contrast adjustment methods like CLAHE <ref type="bibr" target="#b14">[15]</ref>. Second, suppose the ground truth segmentation labels given by the clinicians are incomplete and noisy, which yields missing annotations of some vessel segments, we study the effective learning scheme to improve the robustness of the model while training on noisy labels. Therefore, the contributions can be summarized in the following aspects.</p><p>-First, to better visualize the retinal image and understand the model, we design the network to output the learned enhancement map. Compared with other baselines, the high-contrast learned map are better visually plausible, and provides a better auxiliary tool to aid clinicians for visual inspection or manual segmentation.  -Second, we design a pipeline to manipulate vessel segmentation labels. Given a complete annotations, the proposed approach simulates to automatically erase some vessel segments. -Third, we propose a Study Group Learning (SGL) framework to improve the generalization ability of the learned model, and better address the missing annotation problems in the training set. The model achieves a more robust performance even some of the vessel pixels are mislabeled.</p><formula xml:id="formula_0">!! !" " ! Enhancement Module Segmentation Module Concatenated Model … !! !" !# "! "" "# Validation Set Training Set Concatenated Model Data Trained Model #$ ! $ #$ " $ #$ # % ! #$ &amp; 3×3 Conv (BN) 2×2 Max Pool 2×2</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Model Structure</head><p>The proposed baseline model structure is illustrated in <ref type="figure" target="#fig_0">Fig. 1</ref>. We utilize the concatenated UNet consisting of the enhancement and segmentation modules to learn both the enhancement and the segmentation map. Different from previous works, we do not pre-process the retinal images, but directly utilize the raw captured images to preserve the entire information. Specifically, given a three-channel raw retinal image I as the input, we aim to process the image by enhancing its contrast and highlighting the vessel structures in I e , and estimate the segmentation mapÎ c of the vessels matched with the ground truth segmentation map I c given by professional clinicians. Notice that I e preserves the maximum image contents including the vessel structures and retinal textures. It helps the clinicians to inspect the segmentation resultsÎ c and better explains the learned model. During testing, we enhance the raw image and infer the segmentation maps from unseen retinal images. To cope with noisy labels in vessel segmentation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Retinal Image Input</head><p>Enhanced Image Overfitting the Ground Truth Map Pseudo Label <ref type="figure">Fig. 2</ref>. Inference results on one training example. Clinicians may only label some salient vessels while ignoring the ambiguous ones. The model trained on the entire set will overfit the ground truth annotations. However, inference results from the model trained on the subset can serve as the pseudo label for model regularization purpose.</p><p>datasets, we propose and follow a Study Group Learning (SGL) scheme to train the baseline model, which is explained in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Study Group Learning (SGL) Scheme</head><p>Tasks like retinal vessel segmentation faces the problem of small-scale dataset and incorrect or incomplete vessel annotations. These two practical problems will make the deeply trained model very easily over-fitting the training set. The severe over-fitting problem does harm to the generalization ability and robustness of the model to unseen testing data. In addition to conventional data augmentation approaches like image transformation and random warping, we propose to alternate the training scheme. Inspired by K-fold cross-validation scheme and knowledge distillation <ref type="bibr" target="#b7">[8]</ref> approaches, we propose the K-fold Study Group Learning (SGL) to better cope with noisy labels in small datasets, especially for the retinal vessel segmentation task. The pipeline is illustrated in <ref type="figure" target="#fig_0">Fig. 1</ref>. Specifically, we first randomly and averagely split the whole training set (G,</p><formula xml:id="formula_1">I c ) into K subsets {(G k , I ck )}, where k ∈ [1, K].</formula><p>Like the cross-validation scheme, we train totally K models {M k }. For each M k , we train it on (G\G k , I c \I ck ) using pixel-wise binary cross entropy loss. After optimizing the model set {M k } as {M * k }, we infer the estimated segmentation labelĨ ck of G k as the pseudo label, wherẽ</p><formula xml:id="formula_2">I ck = M * k (G k ), k ∈ [1, K].<label>(1)</label></formula><p>Finally, we train a model M from scratch by jointly optimizing the ground truth vessel labels I c and the obtained pseudo label setĨ c = K k=1Ĩ ck as,</p><formula xml:id="formula_3">L SGL = CE(Î c , I c ) + λCE(Î c ,Ĩ c ),<label>(2)</label></formula><p>whereÎ c = M (G), CE is the cross entropy loss, and λ = 1. Intuitively, we name the proposed learning scheme as Study Group Learning (SGL) because each model M k trained with partial training set can be regarded . . . <ref type="figure">Fig. 3</ref>. Vessel label erasing process. Given the complete label map Ic, we compute the skeleton of the vessels, and dilate the vessel skeleton to mask by drawing the polylines with width t. We then rank the vessel segments by their approximated thickness, and include the thick vessels according to ratio r. The second row shows one instance of label erasing with r from 1 to 0.3.</p><p>as a 'Study Group'. The final model M is a process of group discussion by merging and fusing the knowledge from different study groups. Theoretically, the second term in Equ. 2 can be regarded as a regularization to avoid over-fitting the ground-truth labels, especially when the given labels contain some noises and possibly incorrect annotations. <ref type="figure">Fig. 2</ref> shows one example of such cases. In this example, we set K = 2, and the inference of the training samples I from M 1 and M 2 are shown in the right two columns, where I is in the training set of M 1 but not in the training partition of M 2 . M 1 highly overfits the given labels of I by ignoring multiple thin and ambiguous vessels. However, if not trained on I, M 2 can infer some of the ignored vessels as the pseudo labels. While combining these two labels, the final model M can intuitively learn better representation and become more generalized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Vessel Label Erasing</head><p>Annotating the retinal vessels requires the involvement of professional clinicians, and the process of manual labeling is onerous, which reveals one of the reasons why public retinal vessel databases are always small-scale or partially-labeled. It is also common that some labels of thinner vessels are missing due to the annotators' errors. To resemble this practical situation in industry, we propose to synthesize an incomplete map I r c by erasing some labeled vessel segments I r from the ground truth segmentation map I c = I r c ∪ I r , where r is the removal ratio. The process is illustrated in <ref type="figure">Fig. 3</ref>.</p><p>To generate I r c , we first compute and approximate the skeleton of I c using the method proposed by Zhang et al. <ref type="bibr" target="#b29">[30]</ref> followed by a skeleton tracing approach <ref type="bibr" target="#b2">3</ref> . This algorithm converts the binary segmentation map into a set of polylines L c = {l i } c , where i ∈ [1, M ] and each l i is stored as an array of coordinates i.e. l i = {p d }. The geometric polylines and their spatial relationship represent the topological skeleton of the annotated vessels. We utilize it to locate the vessel center lines, and roughly compute the thickness of the vessels.</p><p>Second, to compute and rank the thickness of each vessel segment, we redraw the polylines with larger width t on a black canvas to form the complete mask M t c . Notice that t is the least value which makes M t c cover the entire vessel regions in I c . For each l i , the corresponding pixel regions covered by the drawing lines of width t is denoted by l t i , then the thickness s i of the vessel segment is measured by s i = Ir∩l t i l t i . We rank the polylines according to their thickness s i , and include the thickest vessels in order in the partial set L r c = {l j }, where j ∈ [1, N ] and N ≤ M . In L r c , we include the top-r thick vessels. Finally, we form the selected mask M t r from L r c , and the synthetic segmentation mask ablating some of the thin vessels with ratio r can be computed by I r c = M t r I c . <ref type="figure">Fig. 3</ref> shows one example of I r c where r is from 1 to 0.3. Adding a small portions of thin vessels helps the model maintain the ability of segmenting smaller objects. Therefore, we also randomly select 50% of thin vessels in the set and add them to L r c .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset and Implementation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DRIVE:</head><p>The Digital Retinal Images for Vessel Extraction (DRIVE) <ref type="bibr" target="#b21">[22]</ref> dataset consists of 40 images of size 565 × 584. The training and testing set are fixed, and the ground truth manual annotations are given. We do not resize the image to alternate the resolution or change the Aspect-Ratio. CHASE DB1: <ref type="bibr" target="#b2">[3]</ref> It consists of 28 retinal images of size 999 × 960. For a fair comparison with previous methods, we use the first 20 images for training, and the remaining 8 images for testing. While training the model, we randomly crop the images into 256 × 256 patches, and apply data augmentation including horizontal and vertical flip, rotation, transpose, and random elastic warping <ref type="bibr" target="#b18">[19]</ref>. While testing, suppose the image size is W × H, we zero-pad the input image to size (2 4 × m, 2 4 × m), where 2 4 × m &gt; max(W, H) &gt; 2 4 × (m − 1), and crop the estimated map accordingly. Specifically, m is 37 for DRIVE and 63 for CHASE DB1 dataset. It makes the arbitrary-sized inputs adaptive to the UNet structure with four down-sampling layers, and retain the original resolution and aspect-ratio of the image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Learned Retinal Image Enhancement</head><p>We learn the enhanced map of the original input images by supervising the model on the manual segmentation labels. We extract the bottleneck 3-channel  output which can be visualized in a better contrast level. We compare the learned enhancement of the retinal images with other baseline methods including Histogram Equalization (HE), Contrast Limited Adaptive Histogram Equalization (CLAHE) <ref type="bibr" target="#b14">[15]</ref>, and Retinex <ref type="bibr" target="#b31">[32]</ref>. <ref type="figure" target="#fig_2">Fig. 4</ref> shows one example of the visual comparison. Traditional methods like HE, CLAHE and Retinex cannot achieve a uniform contrast level both locally and globally. The cropped patches are from either a brighter or darker regions of the image, making the vessel pixels hard to parse accurately by the inspector. However, the learned map in the fifth column demonstrates a better contrast and intensity level, enhancing the vessel information for a better identifiable visualization for clinicians, especially for the dark regions in CHASE DB1 images. It highlights the vessel regions while preserving the textures. The obtained enhancement images can also be utilized for visual inspection or labeling.  <ref type="table" target="#tab_1">Table 1</ref> and 2 illustrate the effectiveness of the proposed SGL scheme. Compared with previous works, the proposed learning scheme can boost the DICE score <ref type="bibr" target="#b20">[21]</ref> and other evaluation metrics by a large margin. <ref type="figure" target="#fig_3">Fig. 5</ref> shows the DICE and Area Under the Receiver Operating Characteristic (ROC) Curve (AUC) of the model in the simulated training set with label noise ratio r = [1, 0.9, 0.7, 0.5], where r = 1 represents the original training set. As shown in the figure, erasing some vessel labels in the training set will drastically degrade the system performance, while the SGL learning scheme overall improves the robustness on both datasets. Among all the metrics, AUC does not relate to the thresholding method, indicating a better ability of the model segmenting vessel pixels. Besides, a better sensitivity indicates the model is able to extract more thin vessels and boundary pixels. More results can be found in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Study Group Learning</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>In this paper, we studied the learning-based retinal vessel segmentation model trained with noisy labels. Specifically, we designed the pipeline of synthesizing noisy labels, and proposed a Study Group Learning (SGL) scheme boosting the performance of model trained with imperfect labels. Besides, the learned enhanced images as a side product made the model explainable and helped the clinicians for visual inspection. We still discovered the gap between models trained with different levels of noisy labels, leaving for future work to further improve the model sensitivity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Acknowledgement</head><p>This project has been funded by the Jump ARCHES endowment through the Health Care Engineering Systems Center. This work also utilizes resources supported by the National Science Foundation's Major Research Instrumentation program, grant number 1725729, as well as the University of Illinois at Urbana-Champaign.</p><p>6 Appendix: Quantitative and Qualitative Result   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Baseline model structure and the proposed Study Group Learning (SGL) scheme. The baseline network is a concatenated UNet consisting of an enhancement module and a segmentation module. The three-channel enhancement map Ie is obtained from the bottleneck structure. The SGL is inspired by the cross-validation training scheme and knowledge distillation idea. We first split the whole training set G into K subsets {G k } and feed the model M k with G k . The obtained estimationĨ k c of G k is utilized as the pseudo labels for joint optimization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 .</head><label>4</label><figDesc>The learned enhancement map Ie compared with other baseline methods including Histogram Equalization (HE), Contrast Limited Adaptive Histogram Equalization (CLAHE)<ref type="bibr" target="#b14">[15]</ref>, and Single-scale Retinex<ref type="bibr" target="#b31">[32]</ref>. The learned map demonstrates a better contrast and intensity, enhancing the vessel information for a better identifiable visualization for clinicians. Top row is from DRIVE dataset and the bottom row is from CHASE DB1 dataset. Zooming in for better visualization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>The performance of the model in the simulated training set with label noise ratio r = [1, 0.9, 0.7, 0.5]. The proposed SGL learning scheme overall improves the robustness in all K. Left two columns: DICE and AUC scores on DRIVE. Right two columns: on CHASE DB1 dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Enhancement and segmentation results on DRIVE. From left to right: the raw retinal image, the learned enhanced image, the probability map, and the binary segmentation result. Red color indicates false negative, and green color indicates false positive. Thin vessels are still very challenging to be segmented.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .</head><label>7</label><figDesc>Enhancement and segmentation results on CHASE DB1. From left to right: the raw retinal image, the learned enhanced image, the probability map, and the binary segmentation result. Red color indicates false negative, and green color indicates false positive.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Comparison with other baseline methods on DRIVE dataset.</figDesc><table><row><cell cols="5">Method Year Sensitivity Specificity DICE Accuracy</cell><cell>AUC</cell></row><row><cell>R2U-Net [1] 2018</cell><cell>0.7792</cell><cell>0.9813</cell><cell>0.8171</cell><cell>0.9556</cell><cell>0.9784</cell></row><row><cell>LadderNet [33] 2018</cell><cell>0.7856</cell><cell>0.9810</cell><cell>0.8202</cell><cell>0.9561</cell><cell>0.9793</cell></row><row><cell>Dual E-UNet [23] 2019</cell><cell>0.7940</cell><cell>0.9816</cell><cell>0.8270</cell><cell>0.9567</cell><cell>0.9772</cell></row><row><cell>IterNet [11] 2020</cell><cell>0.7791</cell><cell>0.9831</cell><cell>0.8218</cell><cell>0.9574</cell><cell>0.9813</cell></row><row><cell>SA-UNet [6] 2020</cell><cell>0.8212</cell><cell>0.9840</cell><cell>0.8263</cell><cell>0.9698</cell><cell>0.9864</cell></row><row><cell>BEFD-UNet [28] 2020</cell><cell>0.8215</cell><cell>0.9845</cell><cell>0.8267</cell><cell>0.9701</cell><cell>0.9867</cell></row><row><cell>Our Baseline 2021</cell><cell>0.8341</cell><cell>0.9827</cell><cell>0.8262</cell><cell>0.9695</cell><cell>0.9867</cell></row><row><cell>Our SGL (K=8) 2021</cell><cell>0.8380</cell><cell>0.9834</cell><cell>0.8316</cell><cell>0.9705</cell><cell>0.9886</cell></row><row><cell cols="6">Table 2. Comparison with other baseline methods on CHASE DB1 dataset.</cell></row><row><cell cols="5">Method Year Sensitivity Specificity DICE Accuracy</cell><cell>AUC</cell></row><row><cell>R2U-Net [1] 2018</cell><cell>0.7756</cell><cell>0.9712</cell><cell>0.7928</cell><cell>0.9634</cell><cell>0.9815</cell></row><row><cell>LadderNet [33] 2018</cell><cell>0.7978</cell><cell>0.9818</cell><cell>0.8031</cell><cell>0.9656</cell><cell>0.9839</cell></row><row><cell>Dual E-UNet [23] 2019</cell><cell>0.8074</cell><cell>0.9821</cell><cell>0.8037</cell><cell>0.9661</cell><cell>0.9812</cell></row><row><cell>IterNet [11] 2020</cell><cell>0.7969</cell><cell>0.9881</cell><cell>0.8072</cell><cell>0.9760</cell><cell>0.9899</cell></row><row><cell>SA-UNet [6] 2020</cell><cell>0.8573</cell><cell>0.9835</cell><cell>0.8153</cell><cell>0.9755</cell><cell>0.9905</cell></row><row><cell>Our Baseline 2021</cell><cell>0.8502</cell><cell>0.9854</cell><cell>0.8232</cell><cell>0.9769</cell><cell>0.9913</cell></row><row><cell>Our SGL (K=8) 2021</cell><cell>0.8690</cell><cell>0.9843</cell><cell>0.8271</cell><cell>0.9771</cell><cell>0.9920</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .Table 4 .</head><label>34</label><figDesc>Results of different label missing ratio r and fold number K on DRIVE. Results of different label missing ratio r and fold number K on CHASE DB1.</figDesc><table><row><cell cols="2">r K Accuracy</cell><cell>AUC</cell><cell cols="4">Sensitivity Specificity DICE (F1) Vessel IoU</cell></row><row><cell>1 1</cell><cell>0.9695</cell><cell>0.9867</cell><cell>0.8341</cell><cell>0.9827</cell><cell>0.8262</cell><cell>0.7041</cell></row><row><cell>2</cell><cell>0.9701</cell><cell>0.9884</cell><cell>0.8432</cell><cell>0.9825</cell><cell>0.8309</cell><cell>0.7110</cell></row><row><cell>4</cell><cell>0.9705</cell><cell>0.9887</cell><cell>0.8358</cell><cell>0.9836</cell><cell>0.8312</cell><cell>0.7115</cell></row><row><cell>8</cell><cell>0.9705</cell><cell>0.9886</cell><cell>0.8380</cell><cell>0.9834</cell><cell>0.8316</cell><cell>0.7120</cell></row><row><cell>0.9 1</cell><cell>0.9697</cell><cell>0.9867</cell><cell>0.8262</cell><cell>0.9837</cell><cell>0.8260</cell><cell>0.7040</cell></row><row><cell>2</cell><cell>0.9706</cell><cell>0.9884</cell><cell>0.8231</cell><cell>0.9850</cell><cell>0.8299</cell><cell>0.7095</cell></row><row><cell>4</cell><cell>0.9706</cell><cell>0.9886</cell><cell>0.8323</cell><cell>0.9840</cell><cell>0.8310</cell><cell>0.7111</cell></row><row><cell>8</cell><cell>0.9703</cell><cell>0.9887</cell><cell>0.8418</cell><cell>0.9828</cell><cell>0.8313</cell><cell>0.7116</cell></row><row><cell>0.7 1</cell><cell>0.9691</cell><cell>0.9858</cell><cell>0.8045</cell><cell>0.9852</cell><cell>0.8194</cell><cell>0.6945</cell></row><row><cell>2</cell><cell>0.9696</cell><cell>0.9873</cell><cell>0.8102</cell><cell>0.9851</cell><cell>0.8224</cell><cell>0.6988</cell></row><row><cell>4</cell><cell>0.9702</cell><cell>0.9879</cell><cell>0.8081</cell><cell>0.9860</cell><cell>0.8250</cell><cell>0.7024</cell></row><row><cell>8</cell><cell>0.9701</cell><cell>0.9882</cell><cell>0.8104</cell><cell>0.9857</cell><cell>0.8251</cell><cell>0.7027</cell></row><row><cell cols="2">r K Accuracy</cell><cell>AUC</cell><cell cols="4">Sensitivity Specificity DICE (F1) Vessel IoU</cell></row><row><cell>1 1</cell><cell>0.9769</cell><cell>0.9913</cell><cell>0.8502</cell><cell>0.9854</cell><cell>0.8232</cell><cell>0.6998</cell></row><row><cell>2</cell><cell>0.9774</cell><cell>0.9920</cell><cell>0.8586</cell><cell>0.9855</cell><cell>0.8275</cell><cell>0.7060</cell></row><row><cell>4</cell><cell>0.9769</cell><cell>0.9920</cell><cell>0.8632</cell><cell>0.9846</cell><cell>0.8248</cell><cell>0.7020</cell></row><row><cell>8</cell><cell>0.9771</cell><cell>0.9920</cell><cell>0.8690</cell><cell>0.9843</cell><cell>0.8271</cell><cell>0.7054</cell></row><row><cell>0.9 1</cell><cell>0.9765</cell><cell>0.9901</cell><cell>0.8483</cell><cell>0.9851</cell><cell>0.8204</cell><cell>0.6957</cell></row><row><cell>2</cell><cell>0.9761</cell><cell>0.9913</cell><cell>0.8716</cell><cell>0.9831</cell><cell>0.8211</cell><cell>0.6967</cell></row><row><cell>4</cell><cell>0.9771</cell><cell>0.9915</cell><cell>0.8494</cell><cell>0.9856</cell><cell>0.8236</cell><cell>0.7004</cell></row><row><cell>8</cell><cell>0.9768</cell><cell>0.9917</cell><cell>0.8652</cell><cell>0.9843</cell><cell>0.8246</cell><cell>0.7017</cell></row><row><cell>0.7 1</cell><cell>0.9759</cell><cell>0.9891</cell><cell>0.8182</cell><cell>0.9864</cell><cell>0.8111</cell><cell>0.6824</cell></row><row><cell>2</cell><cell>0.9761</cell><cell>0.9904</cell><cell>0.8250</cell><cell>0.9863</cell><cell>0.8131</cell><cell>0.6852</cell></row><row><cell>4</cell><cell>0.9761</cell><cell>0.9906</cell><cell>0.8341</cell><cell>0.9856</cell><cell>0.8155</cell><cell>0.6887</cell></row><row><cell>8</cell><cell>0.9757</cell><cell>0.9910</cell><cell>0.8480</cell><cell>0.9843</cell><cell>0.8151</cell><cell>0.6881</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">skeleton-tracing: https://github.com/LingDong-/skeleton-tracing</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Recurrent residual u-net for medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Z</forename><surname>Alom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yakopcic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Taha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">K</forename><surname>Asari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">14006</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Management of retinal vascular diseases: a patient-centric approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Brand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eye</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An ensemble classification-based approach applied to retinal blood vessel segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Fraz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Remagnino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hoppe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Uyyanonvara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Rudnicka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G</forename><surname>Owen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Barman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2538" to="2548" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Robust loss functions under label noise for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sastry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6572</idno>
		<title level="m">Explaining and harnessing adversarial examples</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Szemenyei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.03696</idno>
		<title level="m">Sa-unet: Spatial attention u-net for retinal vessel segmentation</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.06872</idno>
		<title level="m">Co-teaching: Robust training of deep neural networks with extremely noisy labels</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<title level="m">Distilling the knowledge in a neural network</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2304" to="2313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An elastic interaction-based loss function for medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="755" to="764" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Iternet: Retinal image segmentation utilizing structural redundancy in vessel networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Nakashima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Nagahara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kawasaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Winter Conference on Applications of Computer Vision</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3656" to="3665" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Niemeijer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Staal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Ginneken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Loog</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Abramoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Comparative study of retinal vessel segmentation methods on a new publicly available database</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">5370</biblScope>
			<biblScope unit="page" from="648" to="656" />
		</imprint>
	</monogr>
	<note>Medical imaging 2004: image processing</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Detection of blood vessels in fundus images of the retina using gabor wavelets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Oloumi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Rangayyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Oloumi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Eshghzadeh-Zanjani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">J</forename><surname>Ayres</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">29th Annual International Conference of the IEEE Engineering in Medicine and Biology Society</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="6451" to="6454" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pereyra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chorowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.06548</idno>
		<title level="m">Regularizing neural networks by penalizing confident output distributions</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Adaptive histogram equalization and its variations. Computer vision, graphics, and image processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Pizer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Amburn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cromartie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geselowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Greer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ter Haar Romeny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Zimmerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zuiderveld</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="355" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Retinal blood vessel segmentation using line operators and support vector classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Perfetti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on medical imaging</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1357" to="1365" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical image computing and computer-assisted intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Lvc-net: Medical image segmentation with noisy label based on local visual cues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="558" to="566" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Best practices for convolutional neural networks applied to visual document analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">Y</forename><surname>Simard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Steinkraus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Platt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In: Icdar. vol</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.08199</idno>
		<title level="m">Learning from noisy labels with deep neural networks: A survey</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A method of establishing groups of equal amplitude in plant sociology based on similarity of species content and its application to analyses of the vegetation on danish commons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">A</forename><surname>Sorensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biol. Skar</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1" to="34" />
			<date type="published" when="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Ridge-based vessel segmentation in color images of the retina</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Staal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Abràmoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Niemeijer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Viergever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Ginneken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on medical imaging</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="501" to="509" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Dual encoding u-net for retinal vessel segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="84" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Rvseg-net: An efficient feature pyramid cascade network for retinal vessel segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="796" to="805" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Boosting connectivity in retinal vessel segmentation via a recursive semantics-guided network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="786" to="795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Cascaded robust learning at imperfect labels for chest x-ray segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="579" to="588" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Segmentation of retinal blood vessels using the radial projection and semi-supervised approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">M</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern recognition</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="2314" to="2324" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Befd: Boundary enhancement and feature denoising for vessel segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="775" to="785" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Retinal image segmentation with a structure-texture demixing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="765" to="774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A fast parallel algorithm for thinning digital patterns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="236" to="239" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Sabuncu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.07836</idno>
		<title level="m">Generalized cross entropy loss for training deep neural networks with noisy labels</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Retinal vessel segmentation: An efficient graph cut approach with retinex and local phase</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Harding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">122332</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhuang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.07810</idno>
		<title level="m">Laddernet: Multi-path networks based on u-net for medical image segmentation</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
