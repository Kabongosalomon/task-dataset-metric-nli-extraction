<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Self-Supervised Convolutional Subspace Clustering Network</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-05-01">1 May 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjian</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Berkeley ♯ Shenzhen Research Institute of Big Data</orgName>
								<orgName type="department" key="dep2">School of EECS</orgName>
								<orgName type="laboratory">Key Laboratory of Machine Perception (MOE)</orgName>
								<orgName type="institution" key="instit1">University of Posts and Telecommunications ‡ EECS</orgName>
								<orgName type="institution" key="instit2">University of California</orgName>
								<orgName type="institution" key="instit3">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Guang</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Berkeley ♯ Shenzhen Research Institute of Big Data</orgName>
								<orgName type="department" key="dep2">School of EECS</orgName>
								<orgName type="laboratory">Key Laboratory of Machine Perception (MOE)</orgName>
								<orgName type="institution" key="instit1">University of Posts and Telecommunications ‡ EECS</orgName>
								<orgName type="institution" key="instit2">University of California</orgName>
								<orgName type="institution" key="instit3">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">†</forename></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Berkeley ♯ Shenzhen Research Institute of Big Data</orgName>
								<orgName type="department" key="dep2">School of EECS</orgName>
								<orgName type="laboratory">Key Laboratory of Machine Perception (MOE)</orgName>
								<orgName type="institution" key="instit1">University of Posts and Telecommunications ‡ EECS</orgName>
								<orgName type="institution" key="instit2">University of California</orgName>
								<orgName type="institution" key="instit3">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>You</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Berkeley ♯ Shenzhen Research Institute of Big Data</orgName>
								<orgName type="department" key="dep2">School of EECS</orgName>
								<orgName type="laboratory">Key Laboratory of Machine Perception (MOE)</orgName>
								<orgName type="institution" key="instit1">University of Posts and Telecommunications ‡ EECS</orgName>
								<orgName type="institution" key="instit2">University of California</orgName>
								<orgName type="institution" key="instit3">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianbiao</forename><surname>Qi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Berkeley ♯ Shenzhen Research Institute of Big Data</orgName>
								<orgName type="department" key="dep2">School of EECS</orgName>
								<orgName type="laboratory">Key Laboratory of Machine Perception (MOE)</orgName>
								<orgName type="institution" key="instit1">University of Posts and Telecommunications ‡ EECS</orgName>
								<orgName type="institution" key="instit2">University of California</orgName>
								<orgName type="institution" key="instit3">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honggang</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Berkeley ♯ Shenzhen Research Institute of Big Data</orgName>
								<orgName type="department" key="dep2">School of EECS</orgName>
								<orgName type="laboratory">Key Laboratory of Machine Perception (MOE)</orgName>
								<orgName type="institution" key="instit1">University of Posts and Telecommunications ‡ EECS</orgName>
								<orgName type="institution" key="instit2">University of California</orgName>
								<orgName type="institution" key="instit3">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Guo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Berkeley ♯ Shenzhen Research Institute of Big Data</orgName>
								<orgName type="department" key="dep2">School of EECS</orgName>
								<orgName type="laboratory">Key Laboratory of Machine Perception (MOE)</orgName>
								<orgName type="institution" key="instit1">University of Posts and Telecommunications ‡ EECS</orgName>
								<orgName type="institution" key="instit2">University of California</orgName>
								<orgName type="institution" key="instit3">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouchen</forename><surname>Lin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Berkeley ♯ Shenzhen Research Institute of Big Data</orgName>
								<orgName type="department" key="dep2">School of EECS</orgName>
								<orgName type="laboratory">Key Laboratory of Machine Perception (MOE)</orgName>
								<orgName type="institution" key="instit1">University of Posts and Telecommunications ‡ EECS</orgName>
								<orgName type="institution" key="instit2">University of California</orgName>
								<orgName type="institution" key="instit3">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beijing</forename><surname>Sice</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Berkeley ♯ Shenzhen Research Institute of Big Data</orgName>
								<orgName type="department" key="dep2">School of EECS</orgName>
								<orgName type="laboratory">Key Laboratory of Machine Perception (MOE)</orgName>
								<orgName type="institution" key="instit1">University of Posts and Telecommunications ‡ EECS</orgName>
								<orgName type="institution" key="instit2">University of California</orgName>
								<orgName type="institution" key="instit3">Peking University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Self-Supervised Convolutional Subspace Clustering Network</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-05-01">1 May 2019</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T18:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Subspace clustering methods based on data selfexpression have become very popular for learning from data that lie in a union of low-dimensional linear subspaces. However, the applicability of subspace clustering has been limited because practical visual data in raw form do not necessarily lie in such linear subspaces. On the other hand, while Convolutional Neural Network (ConvNet)   has been demonstrated to be a powerful tool for extracting discriminative features from visual data, training such a ConvNet usually requires a large amount of labeled data, which are unavailable in subspace clustering applications. To achieve simultaneous feature learning and subspace clustering, we propose an end-to-end trainable framework, called Self-Supervised Convolutional Subspace Clustering Network (S 2 ConvSCN), that combines a ConvNet module (for feature learning), a self-expression module (for subspace clustering) and a spectral clustering module (for selfsupervision) into a joint optimization framework. Particularly, we introduce a dual self-supervision that exploits the output of spectral clustering to supervise the training of the feature learning module (via a classification loss) and the self-expression module (via a spectral clustering loss). Our experiments on four benchmark datasets show the effectiveness of the dual self-supervision and demonstrate superior performance of our proposed approach.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In many real-world applications such as image and video processing, we need to deal with a large amount of highdimensional data. Such data can often be well approximated by a union of multiple low-dimensional subspaces, where each subspace corresponds to a class or a category. For example, the frontal facial images of a subject taken under varying lighting conditions approximately span a linear subspace of dimension up to nine <ref type="bibr" target="#b10">[11]</ref>; the trajectories of feature points related to a rigidly moving object in a video sequence span an affine subspace of dimension up to three <ref type="bibr" target="#b41">[42]</ref>; the set of handwritten digit images of a single digit also approximately span a low-dimensional subspace <ref type="bibr" target="#b7">[8]</ref>. In such cases, it is important to segment the data into multiple groups where each group contains data points from the same subspace. This problem is known as subspace clustering <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b45">46]</ref>, which we formally define as follows.</p><p>Problem (Subspace Clustering). Let X ∈ IR D×N be a real-valued matrix whose columns are drawn from a union of n subspaces of IR D , n i=1 {S i }, of dimensions d i ≪ min{D, N }, for i = 1, . . . , n. The goal of subspace clustering is to segment the columns of X into their corresponding subspaces.</p><p>In the past decade, subspace clustering has become an important topic in unsupervised learning and many subspace clustering algorithms have been developed <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b17">18]</ref>. These methods have been successfully applied to various applications such as motion segmentation <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b40">41]</ref>, face image clustering <ref type="bibr" target="#b2">[3]</ref>, genes expression microarray clustering <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b19">20]</ref> and so on.</p><p>Despite the great success in the recent development of subspace clustering, its applicability to real applications is very limited because practical data do not necessarily conform with the linear subspace model. In face image clustering, for example, practical face images are often not aligned and often contain variations in pose and expression of the subject. Subspace clustering cannot handle such cases as images corresponding to the same face no longer lie in linear subspaces. While there are recently developed techniques for joint image alignment and subspace clustering <ref type="bibr" target="#b20">[21]</ref>, such a parameterized model is incapable of handling a broader range of data variations such as deformation, translation and so on. It is also possible to use manually designed invariance features such as SIFT <ref type="bibr" target="#b24">[25]</ref>, HOG <ref type="bibr" target="#b0">[1]</ref> and PRICoLBP <ref type="bibr" target="#b38">[39]</ref> of the images before performing subspace clustering, e.g., in <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b35">36]</ref>. However, there has been neither theoretical nor practical evidence to show that such features follow the linear subspace model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recently, Convolutional Neural Networks (ConvNets)</head><p>have demonstrated superior ability in learning useful image representations in a wide range of tasks such as face/object classification and detection <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b31">32]</ref>. In particular, it is shown in <ref type="bibr" target="#b15">[16]</ref> that when applied to images of different classes, ConvNets are able to learn features that lie in a union of linear subspaces. The challenge for training such a ConvNet, however, is that it requires a large number of labeled training images which is often unavailable in practical applications.</p><p>In order to train ConvNet for feature learning without labeled data, many methods have been recently proposed by exploiting the self-expression of data in a union of subspaces <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b53">54]</ref>. Specifically, these methods supervise the training of ConvNet by inducing the learned features to be such that each feature vector can be expressed as a linear combination of the other feature vectors. However, it is difficult to learn good feature representations in such an approach due to the lack of effective supervision.</p><p>Paper contribution. In this paper, we develop an endto-end trainable framework for simultaneous feature learning and subspace clustering, called Self-Supervised Convolutional Subspace Clustering Network (S 2 ConvSCN). In this framework, we use the current clustering results to self-supervise the training of feature learning and selfexpression modules, which is able to significantly improve the subspace clustering performance. In particular, we introduce the following two self-supervision modules:</p><p>1. We introduce a spectral clustering module which uses the current clustering results to supervise the learning of the self-expression coefficients. This is achieved by inducing the affinity generated from the selfexpression to form a segmentation of the data that aligns with the current class labels generated from clustering.</p><p>2. We introduce a classification module which uses the current clustering results to supervise the training of feature learning. This is achieved by minimizing the classification loss between the output of a classifier trained on top of the feature learning module and the current class labels generated from clustering.</p><p>We propose a training framework where the feature representation, the data self-expression and the data segmentation are jointly learned and alternately refined in the learning procedure. Conceptually, the initial clustering results do not align exactly with the true data segmentation, therefore the initial self-supervision incurs errors to the training. Nonetheless, the feature learning is still expected to benefit from such self-supervision as there are data with correct labels that produce useful information. An improved feature representation subsequently helps to learn a better self-expression and consequently produce a better data segmentation (i.e., with less wrong labels). Our experiments on four benchmark datasets demonstrate superior performance of the proposed approach.</p><p>Paper Outline. The remainder of this paper is organized as follows. Section 2 reviews the relevant work. Section 3 presents our proposal-the components in S 2 ConvSCN, the used cost functions, and the training strategy. Section 4 shows experimental results with discussions, and Section 5 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>In this section, we review the relevant prior work in subspace clustering. For clarity, we group them into two categories: a) subspace clustering in original space; and b) subspace clustering in feature space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Subspace Clustering in Original Space</head><p>In the past years, subspace clustering has received a lot of attention and many methods have been developed. Among them, methods based on spectral clustering are the most popular, e.g., <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b49">50]</ref>. These methods divide the task of subspace clustering into two subproblems. The first subproblem is to learn a data affinity matrix from the original data, and the second subproblem is to apply spectral clustering on the affinity matrix to find the segmentation of the data. The two subproblems are solved successively in onepass <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b50">51]</ref> or solved alternately in multipass <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b17">18]</ref>.</p><p>Finding an informative affinity matrix is the most crucial step. Typical methods to find an informative affinity matrix are based on the self-expression property of data <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b45">46]</ref>, which states that a data point in a union of subspaces can be expressed as a linear combination 1 of other data points, i.e., x j = i =j c ij x i + e j , where e j is used to model the noise or corruption in data. It is expected that the linear combination of data point x j uses the data points that belong to the same subspace as x j . To achieve this objective, different types of regularization terms on the linear combination coefficients are used. For example, in <ref type="bibr" target="#b1">[2]</ref> the ℓ 1 norm is used to find sparse linear combination; in <ref type="bibr" target="#b22">[23]</ref> the nuclear norm of the coefficients matrix is used to find low-rank representation; in <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b50">51]</ref> the mixture of the ℓ 1 norm and the ℓ 2 norm or the nuclear norm is used to balance the sparsity and the denseness of the linear combination coefficients; and in <ref type="bibr" target="#b48">[49]</ref> a data-dependent sparsity-inducing regularizer is used to find sparse linear combination. On the other hand, different ways to model the noise or corruptions in data have also been investigated, e.g., the vector ℓ 1 norm is used in <ref type="bibr" target="#b1">[2]</ref>, <ref type="figure">Figure 1</ref>. Architecture of the proposed Self-Supervised Convolutional Subspace Clustering Network (S 2 ConvSCN). It consists of mainly five modules: a) stacked convolutional encoder module, which is used to extract convolutional features; b) stacked convolutional decoder module, which is used with the encoder module to initialize the convolutional module; c) self-expression module, which is used to learn the self-expressive coefficient matrix and also takes the self-supervision information from the result of spectral clustering to refine the self-expressive coefficients matrix; d) FC-layers based self-supervision module, which builds a self-supervision path back to the stacked convolutional encoder module; e) spectral clustering module, which provides self-supervision information to guide the self-expressive model and FC-layers module. The modules with solid line box are the backbone components; whereas the modules in dashed box are the auxiliary components to facilitate the training of the whole network. the ℓ 2,1 norm is adopted in <ref type="bibr" target="#b22">[23]</ref>, and the correntropy term is used in <ref type="bibr" target="#b8">[9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Subspace Clustering in Feature Space</head><p>For subspace clustering in feature space, we further divide the existing methods into two types. The first type uses latent feature space, which is induced via a Mercer kernel, e.g., <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b47">48]</ref>, or constructed via matrix decomposition, e.g., <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b33">[34]</ref>. The second type use explicit feature space, which is designed by manual feature extraction, e.g., <ref type="bibr" target="#b36">[37]</ref>, or is learned from data, e.g., <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b53">54]</ref>. Latent Feature Space. Many recent works have employed the kernel trick to map the original data into a highdimensional latent feature space, in which subspace clustering is performed, e.g., <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b47">48]</ref>. For example, predefined polynomial and Gaussian kernels are used in the kernel sparse subspace clustering method <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b32">33]</ref> and the kernel low-rank representation method <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b11">12]</ref>. Unfortunately, it is not guaranteed that the data in the latent feature space induced with such predefined kernels lie in low-dimensional subspaces. <ref type="bibr" target="#b1">2</ref> On the other hand, the latent feature space has also been constructed via matrix decomposition, e.g., <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b33">[34]</ref>. In <ref type="bibr" target="#b23">[24]</ref>, a linear transform matrix and a low-rank representation are computed simultaneously; in <ref type="bibr" target="#b33">[34]</ref>, a linear transform and a sparse representation are optimized jointly. However, the representation power of the learned linear transform is still limited.</p><p>Explicit Feature Space. Deep learning has gained a lot of research interests due to its powerful ability to learn hierarchical features in an end-to-end trainable way <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b14">15]</ref>. Recently, there are a few works that use techniques in deep learning for feature extraction in subspace clustering. For example, in <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b35">36]</ref>, a fully connected deep auto-encoder network with hand-crafted features (e.g., SIFT or HOG features) combined with a sparse self-expression model is developed; in <ref type="bibr" target="#b13">[14]</ref>, a stacked convolutional auto-encoder network with a plus-in self-expression model is proposed. While promising clustering accuracy has been reported, these methods are still suboptimal because neither the potentially useful supervision information from the clustering result has been taken into the feature learning step nor a joint optimization framework for fully combining feature learning and subspace clustering has been developed. More recently, in <ref type="bibr" target="#b53">[54]</ref>, a deep adversarial network with a subspace-specific generator and a subspace-specific discriminator is adopted in the framework of <ref type="bibr" target="#b13">[14]</ref> for subspace clustering. However, the discriminator need to use the dimension of each subspace, which is usually unknown.</p><p>In this paper, we attempt to develop a joint optimization framework for combining feature learning and subspace clustering, such that the useful self-supervision information from subspace clustering result could be used to guide the feature learning and to refine the self-expression model. Inspired by the success of Convolutional Neural Networks in recent years for classification tasks on images and videos datasets <ref type="bibr" target="#b14">[15]</ref> and the recent work <ref type="bibr" target="#b13">[14]</ref>, we integrate the convolutional feature extraction module into subspace clustering to form an end-to-end trainable joint optimization framework, called Self-Supervised Convolutional Subspace Clustering Network (S 2 ConvSCN). In S 2 ConvSCN, both the stacked convolutional layers based feature extraction and the self-expression based affinity learning are effectively self-supervised by exploiting the feedback from spectral clustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Our Proposal: Self-Supervised Convolutional Subspace Clustering Network</head><p>In this section, we present our S 2 ConvSCN for joint feature learning and subspace clustering. We start with introducing our network formulation (see <ref type="figure">Fig. 1</ref>), then introduce the self-supervision modules. Finally, we present an effective procedure for training the proposed network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Network Formulation</head><p>As aforementioned, our network is composed of a feature extraction module, a self-expression module and selfsupervision modules for training the former two modules.</p><p>Feature Extraction Module. A basic component of our proposed S 2 ConvSCN is the feature extraction module, which is used to extract features from raw data that are amenable to subspace clustering. To extract localized features while preserving spatial locality, we adopt the convolutional neural network which is comprised of multiple convolutional layers. We denote the input to the network as h (0) = x where x is the image. A convolutional layer ℓ contains a set of filters w </p><formula xml:id="formula_0">i } m (L)</formula><p>i=1 are vectorized and concatenated to form a representation vector z, i.e.,</p><formula xml:id="formula_1">z = h (L) 1 (:), · · · , h (L) m (L) (:) ⊤ ,<label>(1)</label></formula><p>where h</p><formula xml:id="formula_2">(L) 1 (:), · · · , h (L)</formula><p>m (L) (:) are row vectors denoting the vectorization of the feature maps h</p><formula xml:id="formula_3">(L) 1 , · · · , h (L) m (L)</formula><p>. These vectors are horizontally concatenated and then transposed to form the vector z.</p><p>To ensure that the learned representation z contains meaningful information from the input data x, the feature maps h</p><formula xml:id="formula_4">(L) 1 , · · · , h (L)</formula><p>m (L) are fed into a decoder network to reconstruct an imagex. The loss function for this encoderdecoder network is the reconstruction error:</p><formula xml:id="formula_5">L 0 = 1 2N N j=1 x j −x j 2 2 = 1 2N X −X 2 F ,<label>(2)</label></formula><p>where N is the number of images in the training set.</p><p>Self-Expression Module. State-of-the-art subspace clustering methods are based on the self-expression property of data, which states that each data point in a union of subspaces can be expressed as a linear combination of other data points <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b45">46]</ref>. In order to learn feature representations that are suitable for subspace clustering, we adopt a selfexpression module that imposes the following loss function:</p><formula xml:id="formula_6">λ C ℓ + 1 2 Z − ZC 2 F s.t. diag(C) = 0,<label>(3)</label></formula><p>where Z = z 1 , · · · , z N is a matrix containing features from the feature extraction module as its columns, C ℓ is a properly chosen regularization term, the constraint diag(C) = 0 is optionally used to rule out a trivial solution of C = I, and λ &gt; 0 is a tradeoff parameter.</p><p>Self-Supervision Modules. Once the self-expression coefficient matrix C is obtained, we can compute a data affinity matrix as A = 1 2 (|C| + |C ⊤ |). Subsequently, spectral clustering can be applied on A to obtain a segmentation of the data by minimizing the following cost:</p><formula xml:id="formula_7">min Q i,j a ij q i − q j 2 2 , s.t. Q ∈ Q,<label>(4)</label></formula><p>where Q = {Q ∈ {0, 1} n×N : 1 ⊤ Q = 1 ⊤ and rank(Q) = n} is a set of all valid segmentation matrices with n groups, and q i and q j are respectively the i-th and j-th columns of Q indicating the membership of each data point to the assigned cluster. In practice, since the search over all Q ∈ Q is combinatorial, spectral clustering techniques usually relax the constraint Q ∈ Q to QQ ⊤ = I.</p><p>Observe that the spectral clustering produces a labeling of the data set which, albeit is not necessarily the correct class label for all the data points, contains meaningful information about the data. This motivates us to supervise the training of the feature extraction and self-expression modules using the output of spectral clustering. In principle, the features learned from the feature extraction module should contain enough information for predicting the class labels of the data points. Therefore, we introduce a classification layer on top of the feature extraction module which is expected to produce labels that aligns with the labels generated in spectral clustering. Furthermore, the segmentation produced by spectral clustering can also be used to construct a binary segmentation matrix, which contains information regarding which data points should be used in the expression of a particular data point. Therefore, we incorporate the objective function of spectral clustering as a loss function in our network formulation, which has the effect of supervising the training of the self-expression module. We present the details of these two self-supervision modules in the following two subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Self-Supervision for Self-Expression</head><p>To exploit the information in the labels produced by spectral clustering, we incorporate spectral clustering as a module of the network which provides a feedback to the self-expression model (see <ref type="figure">Fig. 1</ref>).</p><p>To see how the objective function of spectral clustering in (4) provides such feedback, we rewrite (4) to a weighted ℓ 1 norm of C as in <ref type="bibr" target="#b16">[17]</ref>, that is,</p><formula xml:id="formula_8">1 2 i,j a ij q i − q j 2 2 = i,j |c ij | q i − q j 2 2 2 := C Q ,<label>(5)</label></formula><p>where we have used the fact that a ij = 1 2 (|c ij | + |c ji |). It can be seen from (5) that C Q measures the discrepancy between the coefficients matrix C and the segmentation matrix Q. When Q is provided, minimizing the cost C Q has the effect of enforcing the self-expression matrix C to be such that an entry c ij is nonzero only if the i-th and j-th data points have the same class labels. Therefore, incorporating the term C Q in the network formulation helps the training of the self-expression module. That is, the result of previous spectral clustering can be incorporated into the self-expression model to provide self-supervision for refining the self-expression matrix C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Self-Supervision for Feature Learning</head><p>We also use the class labels generated from spectral clustering to supervise the training of the feature extraction module. Notice that the output of spectral clustering is an n-dimensional vector which indicates the membership to n subspaces (i.e., clusters). Thus, we design FC layers as p × N 1 × N 2 × n, where p is the dimension of the extracted convolutional feature, which is defined as the concatenation of the different feature maps of the last convolutional layer in the encoder block, and N 1 and N 2 are the numbers of neurons in the two FC layers, respectively.</p><p>Denote y as the n-dimensional output of the FC layers, where y ∈ IR n . Note that the output {q j } N j=1 of spectral clustering will be treated as the target output of the FC layers. To exploit the self-supervision information to train the convolutional encoder, we define a mixture of cross-entropy loss and center loss (CEC) as follows:</p><formula xml:id="formula_9">L 4 = 1 N N j=1 (ln(1 + e −ỹ ⊤ j q j ) + τ y j − µ π(y j ) 2 2 ),<label>(6)</label></formula><p>whereỹ j is a normalization of y j via softmax, µ π(y j ) denotes the cluster center which corresponds to y j , π(y j ) is to take the index of y j from the output of spectral clustering, and 0 ≤ τ ≤ 1 is a tradeoff parameter. The first term of L 4 is effectively a cross-entropy loss and the second term of L 4 is a center loss which compresses the intra-cluster variations. An important issue in defining such a loss function is that the output of spectral clustering {q j } N j=1 provides merely pseudo labels for the input data. That is, the label index assigned to a cluster in the returned result of spectral clustering is up to an unknown permutation. Therefore, the class labels from two successive epochs might not be consistent. To address this issue, we propose to perform a permutation of the new pseudo labels via Hungarian algorithm <ref type="bibr" target="#b28">[29]</ref> to find an optimal assignment between the pseudo labels of successive iterations before feeding them into the selfsupervision module with the cross-entropy loss in <ref type="bibr" target="#b5">(6)</ref>. Remark 1. Note that the output of spectral clustering is used in two interrelated self-supervision modules and thus we call it a dual self-supervision mechanism. <ref type="bibr" target="#b2">3</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Training S 2 ConvSCN</head><p>To obtain an end-to-end trainable framework, we design the total cost function of S 2 ConvSCN by putting together the costs in (2), (3), <ref type="bibr" target="#b4">(5)</ref>, and (6) as follows:</p><formula xml:id="formula_10">L = L 0 + γ 1 L 1 + γ 2 L 2 + γ 3 L 3 + γ 4 L 4 ,<label>(7)</label></formula><p>where L 1 = C ℓ , L 2 = 1 2 Z − ZC 2 F , L 3 = C Q , and γ 1 , γ 2 , γ 3 and γ 4 are four tradeoff parameters. The tradeoff parameters are set roughly to be inversely proportional to the value of each cost in order to obtain a balance amongst them.</p><p>To train S 2 ConvSCN, we propose a two-stage strategy as follows: a) pre-train the stacked convolutional layers to provide an initialization of S 2 ConvSCN; b) train the whole network with the assistance of the self-supervision information provided by spectral clustering. Fixed Q, update the other parts T0 epoches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>8:</head><p>Run spectral clustering once to update Q and set t ← t+1. 9: end while Ensure: trained S 2 ConvSCN and Q. set the weights in the two FC layers as zeros, which yield zeros output. Meanwhile, we also set the output of spectral clustering as zero vectors, i.e., q j = 0 for j = 1, · · · , N . By doing so, the two FC layers are "sleeping" during this pre-training stage. Moreover, we set the coefficient matrix C as an identity matrix, which is equivalent to training S 2 ConvSCN without the self-expression layer. As an optional pre-training, we can also use the pre-trained stacked CAE to train the stacked CAE with the self-expression layer. Stage II: Training the Whole S 2 ConvSCN. In this stage, we use the total cost L to train the whole S 2 ConvSCN as a stacked CAE assisted with the self-expression module and dual self-supervision. To be more specific, given the spectral clustering result Q, we update the other parameters in S 2 ConvSCN for T 0 epoches, and then perform spectral clustering to update Q. For clarity, we provide the detailed procedure to train S 2 ConvSCN in Algorithm 1. Remark 2. In the total cost function as <ref type="formula" target="#formula_10">(7)</ref>, if we set γ 3 = γ 4 = 0, then the two self-supervision blocks will disappear and our S 2 ConvSCN reduces to DSCNet <ref type="bibr" target="#b13">[14]</ref>. Thus, it would be interesting to add an extra pre-training stage, i.e., using the cost function L 0 + γ 1 L 1 + γ 2 L 2 to train the stacked convolutional module and the self-expressive layer together before evoking the FC layers and the spectral clustering layer. This is effectively a DSCNet <ref type="bibr" target="#b13">[14]</ref>. In experiments, as used in <ref type="bibr" target="#b13">[14]</ref>, we stop the training by setting a maximum number of epoches T max .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Evaluations</head><p>To evaluate the performance of our proposed S 2 ConvSCN, we conduct experiments on four benchmark data sets: two face image data sets, the Extended Extended Yale B ORL Layers kernel size channels kernel size channels encoder-1 5 × 5 <ref type="table">Table 1</ref>. Network settings for Extended Yale B and ORL.</p><formula xml:id="formula_11">10 3 × 3 3 encoder-2 3 × 3 20 3 × 3 3 encoder-3 3 × 3 30 3 × 3 5 decoder-1 3 × 3 30 3 × 3 5 decoder-2 3 × 3 20 3 × 3 3 decoder-3 5 × 5 10 3 × 3 3</formula><p>Yale B <ref type="bibr" target="#b5">[6]</ref> and ORL <ref type="bibr" target="#b39">[40]</ref>, and two object image data sets, COIL20 and COIL100 <ref type="bibr" target="#b29">[30]</ref>. We compare our proposed S 2 ConvSCN with the following baseline algorithms, including Low Rank Representation (LRR) <ref type="bibr" target="#b22">[23]</ref>, Low Rank Subspace Clustering (LRSC) <ref type="bibr" target="#b43">[44]</ref>, Sparse Subspace Clustering (SSC) <ref type="bibr" target="#b2">[3]</ref>, Kernel Sparse Subspace Clustering (KSSC) <ref type="bibr" target="#b34">[35]</ref>, SSC by Orthogonal Matching Pursuit (SSC-OMP) <ref type="bibr" target="#b51">[52]</ref>, Efficient Dense Subspace Clustering (EDSC) <ref type="bibr" target="#b12">[13]</ref>, Structured SSC (S 3 C) <ref type="bibr" target="#b17">[18]</ref>, SSC with the pre-trained convolutional auto-encoder features (AE+SSC), EDSC with the pre-trained convolutional auto-encoder features (AE+EDSC), Deep Subspace Clustering Networks (DSCNet) <ref type="bibr" target="#b13">[14]</ref> and Deep Adversarial Subspace Clustering (DASC) <ref type="bibr" target="#b53">[54]</ref>. For EDSC, AE+EDSC, DSCNet and DASC, we directly cite the best results reported in <ref type="bibr" target="#b13">[14]</ref> and <ref type="bibr" target="#b53">[54]</ref>. For S 3 C, we use soft S 3 C with a fixed parameter α = 1.</p><p>The architecture specification of S 2 ConvSCN used in our experiments for each dataset are listed in <ref type="table">Table 1</ref> and Table 4. In the stacked convolutional layers, we set the kernel stride as 2 in both horizontal and vertical directions, and use Rectified Linear Unit (ReLU) <ref type="bibr" target="#b14">[15]</ref> as the activation function σ(·). In addition, the learning rate is set to 1.0 × 10 −3 in all our experiments. The whole data set is used as one batch input. For the FC layers, we set N 1 = N 2 and N 2 = n. To find informative affinity matrix, we adopt the vector ℓ 1 norm and the vector ℓ 2 norm to define C ℓ and denote as S 2 ConvSCN-ℓ 1 and S 2 ConvSCN-ℓ 2 , respectively. In the second training stage, we update the stacked convolutional layers, the self-expression model, and the FC layers for T 0 epochs and then update the spectral clustering module once, where T 0 is set to 5 ∼ 16 in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experiments on Extended Yale B</head><p>The Extended Yale B database <ref type="bibr" target="#b5">[6]</ref> consists of face images of 38 subjects, 2432 images in total, with approximately 64 frontal face images per subject taken under different illumination conditions, where the face images of each subject correspond to a low-dimensional subspace. In our experiments, we follow the protocol used in <ref type="bibr" target="#b13">[14]</ref>: a) each image is down-sampled from 192 × 168 to 48 × 42 pixels; b) experiments are conducted using all choices of n ∈ {10, 15, 20, 25, 30, 35, 38}.</p><p>To make a fair comparison, we use the same setting as  that used in DSCNet <ref type="bibr" target="#b13">[14]</ref>, in which a three-layer stacked convolutional encoders is used with {10, 20, 30} channels, respectively. The detailed settings for the stacked convolutional network used on Extended Yale B are shown <ref type="table">Table  1</ref>. The common parameters γ 1 and γ 2 are set the same as that in DSCNet, where γ 1 = 1 (for the term C ℓ ) and γ 2 = 1.0 × 10 n 10 −3 . For the specific parameters used in S 2 ConvSCN, we set γ 3 = 16 for the term C Q and γ 4 = 72 for the cross-entropy term, respectively. We set T 0 = 5 and T max = 10 + 40n.</p><p>The experimental results are presented in <ref type="table" target="#tab_2">Table 2</ref>. We observe that our proposed S 2 ConvSCN-ℓ 1 and S 2 ConvSCN-ℓ 2 remarkably reduced the clustering errors and yield the lowest clustering errors with n ∈ {10, <ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b34">35</ref>, 38} than all the listed baseline methods. We note that DASC <ref type="bibr" target="#b53">[54]</ref> reported a clustering error of 1.44% on Extended Yale B with n = 38, which is slightly better than our results.</p><p>To gain further understanding of the proposed dual selfsupervision, we use S 2 ConvSCN-ℓ 1 as an example and evaluate the effect of using the dual self-supervision modules via an ablation study. Due to space limitation, we only list the experimental results of using a single self-supervision via L 3 , using a single self-supervision via L 4 , and using dual self-supervision of L 3 plus L 4 on datasets Extended Yale B in <ref type="table" target="#tab_4">Table 3</ref>. As a baseline, we show the experimental results of DSCNet <ref type="bibr" target="#b13">[14]</ref>, which uses the loss L 0 + L 1 + L 2 . As could be read from <ref type="table" target="#tab_4">Table 3</ref> that, using only a single self-supervision module, i.e., L 0 + L 1 + L 2 plus L 3 , or L 0 + L 1 + L 2 plus L 4 , the clustering errors are reduced. Compared to using the self-supervision via a spectral clustering loss L 3 in the self-expression module, using the selfsupervision via the classification loss L 4 in FC block is more effective. Nonetheless, using the dual supervision modules further reduces the clustering errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Experiments on ORL</head><p>The ORL dataset <ref type="bibr" target="#b39">[40]</ref> consists of face images of 40 distinct subjects, each subjects having 10 face images under varying lighting conditions, with different facial expressions (open/closed eyes, smiling/not smiling) and facial details (glasses / no glasses) <ref type="bibr" target="#b39">[40]</ref>. As the images were took under variations of facial expressions, this data set is more challenging for subspace clustering due to the nonlinearity and small sample size per subject.</p><p>In our experiments, each image is down-sampled from 112×92 to 32×32. We reduce the kernel size in convolution module to 3 × 3 due to small image size and set the number of channels to {3, 3, 5}. The specification of the network structure is shown in <ref type="table">Table 1</ref>. For the tradeoff parameters, we set γ 1 = 0.1, γ 2 = 0.01, γ 3 = 8, and γ 4 = 1.2 for our S 2 ConvSCN. For the fine-tuning stage, we set T 0 = 5 and T max = 940. Experimental results are shown in <ref type="table">Table 5</ref>. Again, our proposed approaches yield the best results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Experiments on COIL20 and COIL100</head><p>To further verify the effectiveness of our proposed S 2 ConvSCN, we conduct experiments on dataset COIL20 and COIL100 <ref type="bibr" target="#b29">[30]</ref>. COIL20 contains 1440 gray-scale images of 20 objects; whereas COIL100 contains 7200 images of 100 objects. Each image was down-sampled to 32 × 32. The settings of the stacked convolutional networks used for COIL20 and COIL100 are listed in <ref type="table">Table 4</ref>.</p><p>For the tradeoff parameters on COIL20, we set γ 1 = 1, γ 2 = 30 as same as used in DSC-Net <ref type="bibr" target="#b13">[14]</ref>, and γ 3 = 8, γ 4 = 6, T 0 = 4, and T max = 80 in our S 2 ConvSCN. For the tradeoff parameters on COIL100, we set γ 1 = 1, γ 2 = 30 as same as used in DSC-Net <ref type="bibr" target="#b13">[14]</ref>, and γ 3 = 8, γ 4 = 7, T 0 = 16, and T max = 110 in our S 2 ConvSCN.</p><p>For experiments on COIL20 and COIL100, we initialize the convolutional module with stacked CAE at first, and   then train a stacked CAE assisted with a self-expressive model. This is effectively DSCNet <ref type="bibr" target="#b13">[14]</ref>. And then, we train the whole S 2 ConvSCN. Experimental results are listed in <ref type="table">Table 5</ref>. As could be read, our S 2 ConvSCN-ℓ 1 and S 2 ConvSCN-ℓ 2 reduce the clustering errors significantly. This result confirms the effectiveness of the designed dual self-supervision components for the proper use of the useful information from the output of spectral clustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Convergence Behaviors</head><p>To show the convergence behavior during training iterations, we conduct experiments on Extended Yale B with n = 10. We record the clustering errors and each cost function during training period, and show them as a function of the number of epoches in <ref type="figure">Fig. 2</ref>. As could be observed from <ref type="figure">Fig. 2(a)</ref>, (c), (d) and (e), the cost functions L, L 0 , L 2 , and L 4 , and the cluster error decrease rapidly and tend to "flat". To show more details in the iterations, in <ref type="figure">Fig. 2 (b)</ref> and (f), we show the curves of C 1 , C Q and C Q C 1 . Note that C Q and C Q C 1 are the cost and the relative cost of spectral clustering, respectively. Compared to C Q , we argue that C Q C 1 is more indicative to the clustering performance. As could be observed, while C 1 and C Q are increasing 4 , the curve of C Q C 1 tends to "flat"-which is largely <ref type="bibr" target="#b3">4</ref> The observation that the curves of L 1 and L 3 go up is because the entries of the extracted feature Z are slowly shrinking and thus the absolute values of entries of C are slowly increasing, due to the absence of normalization step in feature learning at each epoch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>COIL20</head><p>COIL100 Layers kernel size channels kernel size channels encoder-1 3 × 3 15 5 × 5 50 decoder-1 3 × 3 15 5 × 5 50 <ref type="table">Table 4</ref>. Network settings for COIL20 and COIL100.</p><p>consistent to the curve of the clustering error in <ref type="figure">Fig. 2 (e</ref>  <ref type="table">Table 5</ref>. Clustering Error (%) on ORL, COIL20 and COIL100.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We have proposed an end-to-end trainable framework for simultaneous feature learning and subspace clustering, called Self-Supervised Convolutional Subspace Clustering Network (S 2 ConvSCN). Specifically, in S 2 ConvSCN, the feature extraction via stacked convolutional module, the affinity learning via self-expression model, and the data segmentation via spectral clustering are integrated into a joint optimization framework. By exploiting a dual selfsupervision mechanism, the output of spectral clustering are effectively used to improve the training of the stacked convolutional module and to refine the self-expression model, leading to superior performance. Experiments on benchmark datasets have validated the effectiveness of our proposed approach.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>i , i = 1, · · · , m (ℓ) , and produces m (ℓ) feature maps from the output of the previous layer. The feature maps {h(L) i } i=1,··· ,m (L) in the top layer L of the network are then used to form a representation of the input data x. Specifically, the m (L) feature maps {h (L)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>L 3 L 1 Figure 2 .</head><label>312</label><figDesc>The cost functions and clustering error of S 2 ConvSCN-ℓ1 during training period on Extended Yale B (n = 10).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Stage I: Pre-Training Stacked Convolutional Module. The pre-training stage uses the cost L 0 . In this stage, we Algorithm 1 Procedure for training S 2 ConvSCN Require: Input data, tradeoff parameters, maximum iteration Tmax, T0, and t=1. 1: Pre-train the stacked convolutional module via stacked CAE.</figDesc><table><row><cell>2: (Optional) Pre-train the stacked</cell></row><row><cell>convolutional module with the</cell></row><row><cell>self-expressive layer.</cell></row><row><cell>3: Initialize the FC layers.</cell></row><row><cell>4: Run self-expressive layer.</cell></row><row><cell>5: Run spectral clustering layer to get the</cell></row><row><cell>segmentation Q.</cell></row><row><cell>6: while t ≤ Tmax do</cell></row><row><cell>7:</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Clustering Error (%) on Extended Yale B. The best results are in bold and the second best results are underlined.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Mean Median Mean Median Mean Median Mean Median Mean Median Mean Median Mean MedianL 0 + L 1 + L 2 (DSC-ℓ 1 [14]) + L 1 + L 2 + L 3 + L 4</figDesc><table><row><cell>No. Subjects</cell><cell cols="2">10 subjects</cell><cell cols="2">15 subjects</cell><cell cols="2">20 subjects</cell><cell cols="2">25 subjects</cell><cell cols="2">30 subjects</cell><cell cols="2">35 subjects</cell><cell cols="2">38 subjects</cell></row><row><cell>Losses</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>2.23</cell><cell>2.03</cell><cell>2.17</cell><cell>2.03</cell><cell>2.17</cell><cell>2.11</cell><cell>2.53</cell><cell>2.19</cell><cell>2.63</cell><cell>2.81</cell><cell>3.09</cell><cell>3.10</cell><cell>3.33</cell><cell>3.33</cell></row><row><cell>L 0 + L 1 + L 2 + L 3</cell><cell>1.58</cell><cell>1.25</cell><cell>1.63</cell><cell>1.55</cell><cell>1.67</cell><cell>1.57</cell><cell>1.61</cell><cell>1.63</cell><cell>2.74</cell><cell>1.82</cell><cell>2.64</cell><cell>2.65</cell><cell>2.75</cell><cell>2.75</cell></row><row><cell>L 0 + L 1 + L 2 + L 4</cell><cell>1.32</cell><cell>1.09</cell><cell>1.31</cell><cell>1.30</cell><cell>1.54</cell><cell>1.48</cell><cell>1.48</cell><cell>1.98</cell><cell>1.87</cell><cell>1.61</cell><cell>1.82</cell><cell>1.84</cell><cell>1.92</cell><cell>1.92</cell></row><row><cell cols="2">L 0 1.18</cell><cell>1.09</cell><cell>1.12</cell><cell>1.14</cell><cell>1.30</cell><cell>1.25</cell><cell>1.29</cell><cell>1.28</cell><cell>1.67</cell><cell>1.72</cell><cell>1.62</cell><cell>1.60</cell><cell>1.52</cell><cell>1.52</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 .</head><label>3</label><figDesc>Ablation Study on S 2 ConvSCN-ℓ1 on Extended Yale B.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">If data points lie in a union of affine subspaces<ref type="bibr" target="#b18">[19]</ref>, then the linear combination will be modified to affine combination.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">In<ref type="bibr" target="#b11">[12]</ref>, while the data matrix in the latent feature space is encouraged to be low-rank, it is not necessary that the data in feature space are encouraged to align with a union of linear subspaces.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">While it is also sensible to term our approach with "self-training", we prefer to use the term "self-supervision" in order to emphasizes on the mechanism of guiding the training of the whole framework, that is to make each component as consistent as possible (i.e., be separable, selfexpressive, and block diagonal).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>J. Zhang   </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Histograms of oriented gradients for human detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Sparse subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Elhamifar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE International Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="2790" to="2797" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Sparse subspace clustering: Algorithm, theory, and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Elhamifar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="2765" to="2781" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A closed form solution to robust subspace estimation and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Favaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ravichandran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1801" to="1807" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Robust subspace segmentation with block-diagonal prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3818" to="3825" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">From few to many: Illumination cone models for face recognition under variable lighting and pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A.-S</forename><surname>Georghiades</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-N</forename><surname>Belhumeur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-J</forename><surname>Kriegman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="643" to="660" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Robust subspace segmentation by simultaneously learning data representations and their affinity matrix</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 24th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3547" to="3553" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Metrics and models for handwritten character recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-Y</forename><surname>Simard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical Science</title>
		<imprint>
			<biblScope unit="page" from="54" to="65" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Information theoretic subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2643" to="2655" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-E</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A.-R</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Sainath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="82" to="97" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Clustering appearances of objects under varying illumination conditions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-J</forename><surname>Kriegman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE International Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="11" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.04974v4</idno>
		<title level="m">Adaptive low-rank kernel subspace clustering</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Efficient dense subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Winter conferance on Applications of Computer Vision</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="461" to="468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep subspace clustering networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Ole: Orthogonal low-rank embedding -a plug and play geometric loss for deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lezama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Muse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE International Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8109" to="8118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Structured sparse subspace clustering: A unified optimization framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE International Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="277" to="286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Structured sparse subspace clustering: A joint affinity learning and subspace clustering framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2988" to="3001" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">On geometric analysis of affine sparse subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal on Selected Topics in Signal Processing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Constrained sparse subspace clustering with side information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on Pattern Recognition (ICPR)</title>
		<meeting>the 24th International Conference on Pattern Recognition (ICPR)</meeting>
		<imprint>
			<date type="published" when="2018-08" />
			<biblScope unit="page" from="2093" to="2099" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Transformation invariant subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="page" from="142" to="155" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Robust recovery of subspace structures by low-rank representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-C</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="171" to="184" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Robust subspace segmentation by low-rank representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Machine Learning</title>
		<meeting>International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="663" to="670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Latent low-rank representation for subspace segmentation and feature extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1615" to="1622" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Correlation adaptive subspace segmentation by trace lasso</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Computer Vision</title>
		<meeting>IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1345" to="1352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Robust and efficient subspace segmentation via least squares regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-C</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of European Conference on Computer Vision</title>
		<meeting>European Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="347" to="360" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Subspace clustering of high dimensional data: a predictive approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mcwilliams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Montana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="736" to="772" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Algorithms for the assignment and transportation problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Munkres</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Society for Industrial and Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="32" to="38" />
			<date type="published" when="1957" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-A</forename><surname>Nene</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-K</forename><surname>Nayar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Murase</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
		<respStmt>
			<orgName>Columbia object image library. Columbia University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Kernel lowrank representation for face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">155</biblScope>
			<biblScope unit="page" from="32" to="42" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Deep face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">M</forename><surname>Parkhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Latent space sparse and low-rank subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Signal Processing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="691" to="701" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Latent space sparse subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V.-M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Computer Vision</title>
		<meeting>IEEE International Conference on Computer Vision<address><addrLine>Dev</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="225" to="232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Kernel sparse subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V.-M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Image Processing</title>
		<meeting>IEEE International Conference on Image Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2849" to="2853" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Deep sparse subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.08374</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Deep subspace clustering with sparsity prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Y</forename><surname>Yau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1925" to="1931" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Constructing the l2-graph for robust subspace learning and subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cybernetics</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1053" to="1066" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Pairwise rotation invariant co-occurrence local binary pattern</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2199" to="2213" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Parameterisation of a stochastic model for human face identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F.-S</forename><surname>Samaria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A.-C</forename><surname>Harter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Harter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second IEEE Workshop on Applications of Computer Vision</title>
		<meeting>the Second IEEE Workshop on Applications of Computer Vision</meeting>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="138" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Motion segmentation in the presence of outlying, incomplete, or corrupted trajectories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Roberto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1832" to="1845" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Shape and motion from image streams under orthography: a factorization method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal on Computer Vision</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="137" to="154" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="52" to="68" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Low rank subspace clustering (lrsc)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Favaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="47" to="61" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Generalized Principal Component Analysis (GPCA)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sastry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Generalized Principal Component Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sastry</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Springer Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Provable subspace clustering: when lrr meets ssc</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Leng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="64" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Robust kernel lowrank representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-Y.</forename><surname>Dong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2268" to="2281" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Building invariances into sparse subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wipf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="449" to="462" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Scalable exemplar-based subspace clustering on class-imbalanced data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of European Conference on Computer Vision</title>
		<meeting>European Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2018-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Oracle based active set algorithm for scalable elastic net subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE International Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3928" to="3937" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Scalable sparse subspace clustering by orthogonal matching pursuit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE International Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3918" to="3927" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Low-rank and structured sparse subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of IEEE Visual Communication and Image Processing</title>
		<meeting>eeding of IEEE Visual Communication and Image essing</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Deep adversarial subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE International Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018-06" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
