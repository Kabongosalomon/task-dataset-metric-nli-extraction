<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Unsupervised Domain Adaptive Re-Identification: Theory and Practice</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangchen</forename><surname>Song</surname></persName>
							<email>liangchen.song@horizon.ai</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lefei</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Wuhan University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Du</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Wuhan University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhang</surname></persName>
							<email>qian01.zhang@horizon.ai</email>
							<affiliation key="aff1">
								<orgName type="department">Horizon Robotics</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Huang</surname></persName>
							<email>chang.huang@horizon.ai</email>
							<affiliation key="aff1">
								<orgName type="department">Horizon Robotics</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
							<email>xgwang@hust.edu.cn</email>
							<affiliation key="aff2">
								<orgName type="institution">Huazhong Univ. of Science and Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Unsupervised Domain Adaptive Re-Identification: Theory and Practice</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T12:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We study the problem of unsupervised domain adaptive re-identification (re-ID) which is an active topic in computer vision but lacks a theoretical foundation. We first extend existing unsupervised domain adaptive classification theories to re-ID tasks. Concretely, we introduce some assumptions on the extracted feature space and then derive several loss functions guided by these assumptions. To optimize them, a novel self-training scheme for unsupervised domain adaptive re-ID tasks is proposed. It iteratively makes guesses for unlabeled target data based on an encoder and trains the encoder based on the guessed labels. Extensive experiments on unsupervised domain adaptive person re-ID and vehicle re-ID tasks with comparisons to the state-of-the-arts confirm the effectiveness of the proposed theories and self-training framework. Our code is available on GitHub.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>To re-identify a particular is to identify it as (numerically) the same particular as one encountered on a previous occasion <ref type="bibr" target="#b23">[24]</ref>. Image/video re-identification (re-ID) is a fundamental problem in computer vision and re-ID techniques serve as an indispensable tool for numerous real life applications, for instance, person re-ID for public safety <ref type="bibr" target="#b33">[34]</ref>, travel time measurement via vehicle re-ID <ref type="bibr" target="#b4">[5]</ref>. The key component of re-ID tasks is the notion of identity, which makes re-ID tasks quite different from traditional classification tasks in the following ways: Firstly, determining the label involves two samples, i.e., there is no label when an individual sample is given; secondly, in re-ID tasks the samples in test sets belong to a previously unseen identity while in classification tasks the test samples all fall into a known class. Take the person re-ID task as an example, our target is to spot a person of interest in an image set, which do not have a specific class and is not accessible in the training set.</p><p>In many practical situations, we face the problem that the training data and testing data are in different domains. Going back to the person re-ID example, data from a new camera is placed in a new environment, i.e., a new domain is added, which are too costly and impractical to be annotated, a serviceable re-ID model should have a satisfactory accuracy on unlabeled data. Unsupervised domain adaptation means that learning a model for target domain when given both a fully annotated source dataset and an unlabeled target dataset. Existing algorithms for unsupervised domain adaptive re-ID tasks typically learn domain-invariant representation or generate data for target domain through some newly designed networks, which are practical solutions but lack theoretical support <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b5">6]</ref>. Meanwhile, current theoretical analysis of unsupervised domain adaptation are only concerned with classification tasks <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b16">17]</ref>, which is not suitable for re-ID tasks. A theoretical guarantee of the domain adaptive re-ID problem is in need.</p><p>In this paper, we first theoretically analyze unsupervised domain adaptive re-ID tasks based on <ref type="bibr" target="#b2">[3]</ref>, in which three assumptions are introduced for classification. It is assumed that the source domain and the target domain share a same label space in <ref type="bibr" target="#b2">[3]</ref>. However, in re-ID tasks, the notion of label is defined for pairwise data and the label indicates a data pair belongs to a same ID or not. We adapt the three assumptions for the input space of pairwise data. Moreover, instead of imposing the assumptions on the raw data as <ref type="bibr" target="#b2">[3]</ref>, we assume the resemblance between the feature space of two domains. The first assumption is that the criteria of classifying feature pairs is the same between two domains, which is referred to as covariate assumption. The second one is Separately Probabilistic Lipschitzness, indicating that the feature pairs can be divided into clusters. And the last assumption is weight ratio, concerning the probability of existing a repeated feature among all the features from the two domains. Based on the three assumptions, we show the learnability of unsupervised domain adaptive re-ID tasks. Moreover, since our guarantee is built on well extracted features from real images, the encoder, i.e. feature extractor, is trained via a novel self-training framework, which is originally proposed for NLP tasks <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20]</ref>. Concretely, we iteratively refine the encoder by making guesses on unlabeled target domain and then train the encoder with these samples. In the light of the mentioned assumptions, we propose several loss functions on the encoder and samples with guessed label. And the problem of selecting which sample with guessed label to train is optimized by minimizing the proposed loss functions. For the Separately Probabilistic Lipschitzness assumption, we wish to minimize the intra-cluster and inter-cluster distance. Then the sample selecting problem is turned into data clustering problem and minimizing loss functions is transformed into finding a distance metric for the data. Also, another metric for Weight Ratio is designed. After combining the two metrics together, we have a distance evaluating the confidence of the guessed labels. Finally, the DBSCAN clustering method <ref type="bibr" target="#b4">[5]</ref> is employed to generate data clusters according to a threshold on the distance. With pseudo-labels on selected data cluster from target domain, the encoder is trained with triplet loss <ref type="bibr" target="#b31">[32]</ref>, which is effective for re-ID tasks.</p><p>We carry out experiments on diverse re-ID tasks, which demonstrate the priority of our framework. First the well studied person re-ID task is tested and we show the adaptation results between two large scale datasets, i.e. Market-1501 <ref type="bibr" target="#b32">[33]</ref> and DukeMTMC-reID <ref type="bibr" target="#b24">[25]</ref>. Then we evaluate our algorithm on vehicle re-ID task, in which larger datasets VeRi-776 <ref type="bibr" target="#b15">[16]</ref> and PKU-VehicleID <ref type="bibr" target="#b14">[15]</ref> are involved. To sum up, the structure of our paper is shown in <ref type="figure" target="#fig_0">Figure 2</ref> and our contributions are as follows:</p><p>• We introduce the theoretical guarantees of unsupervised domain adaptive re-ID based on <ref type="bibr" target="#b2">[3]</ref>. A learnability result is shown under three assumptions that concerning the feature space.</p><p>To the best of our knowledge, our paper is the first theoretical analysis work on domain adaptive re-ID tasks. • We theoretically turn the goal of satisfying the assumptions into tractable loss functions on the encoder network and data samples. • A self-training scheme is proposed to iteratively minimizing the loss functions. Our framework is applicable to all re-ID tasks and the effectiveness is verified on large-scale datasets for diverse re-ID tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Related work</head><p>Unsupervised domain adaptation has been widely studied for decades and the algorithms are divided into four categories in a survey <ref type="bibr" target="#b17">[18]</ref>. Using the notions in the survey, our proposed method can be viewed as a combination of feature representation and self-training. Nevertheless, recently unsupervised domain adaptation is widely studied for the person re-ID task.</p><p>Unsupervised domain adaptation and feature representation. Feature representation based methods try to find a latent feature space shared between domains. In <ref type="bibr" target="#b25">[26]</ref>, they wish to minimize a distance between means of the two domains. In a more general manner, <ref type="bibr" target="#b21">[22]</ref> and <ref type="bibr" target="#b3">[4]</ref> try to find a feature space in which the source and target distributions are similar and the statistic Maximum Mean Discrepancy (MMD) is employed. Also, <ref type="bibr" target="#b9">[10]</ref> utilize features that cannot discriminate between source and target domains. Our method and these methods have a same intuition that some features from the source and target domain are generalizable. However, unlike these methods, the process of approximating the intuition in our method is in an iterative manner and we do not directly optimize on the distribution of target domain features.</p><p>Unsupervised domain adaptation and self-training. Self-training methods make guesses on target domain and iteratively refine the guesses and are closely related to the Expectation Maximization (EM) algorithm <ref type="bibr" target="#b20">[21]</ref>. In <ref type="bibr" target="#b26">[27]</ref>, they increase the weight on the target data at each iteration, which is actually altering the relative contribution of source and target domains. A more similar work is <ref type="bibr" target="#b0">[1]</ref>, in which the model is initially trained on source domain, and then the top-1 recognition hypotheses on the target domain are used for adapting their language model. In our algorithm, we do not guess the labels since different re-ID datasets have totally different labels (identities) and instead we perform clustering on the data.</p><p>Unsupervised domain adaptive person re-ID. Due to the rapid development of person re-ID techniques, some useful unsupervised domain adaptive person re-ID methods are proposed. <ref type="bibr" target="#b22">[23]</ref> adopt a multi-task dictionary learning scheme to learn a view-invariant representation. Besides, generative models are also applied to domain adaptation in <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b30">31]</ref>. Wang et al. <ref type="bibr" target="#b29">[30]</ref> design a network learning an attribute-semantic and identity discriminative feature representation. Similarly, Li et al. <ref type="bibr" target="#b13">[14]</ref> leverages information across datasets and derives domain-invariant features via an adaptation and a re-ID network. Though all the above methods solve the adaptation problem, they are not supported by a theoretical framework and their generalization abilities are not verified in other re-ID tasks. Fan et al. <ref type="bibr" target="#b7">[8]</ref> propose a progressive unsupervised learning method consisting of clustering and fine-tuning the network, which is similar to our self-training scheme. However, they only focuses on unsupervised learning, not unsupervised domain adaptation. In addition, their iteration framework is not guided by specific assumptions thus having no theoretical derived loss functions as ours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Notations and Basic Definitions</head><p>In classification tasks, let X ⊆ R d be the input space and Y ⊂ R be the output space, and each sample from the input space is denoted by black lower case letters x ∈ X. We denote source domain as S and target domain as T , and both of them are probability distribution over the input space X. Moreover, the real label of each sample is denoted by a labeling function l : X → Y. However, the above notations could not be directly used to analyze the re-ID tasks, because there is no same identity in two domains, i.e. S and T do not have the same output (label) space. Fortunately, for re-ID tasks, by treating re-ID as classifying same or different data pairs we are still able to utilize the notations and former results with some simple reformulations.</p><p>Specifically, in re-ID tasks, we have a training set consist of data pairs, which means that the input space is (Z, Z) ⊆ R n×n , and the output space is Y = {0, 1}, where 1 means the identities in the pair are the same and 0 means different. Observing that in re-ID tasks, the two domain indeed have some overlapping cues, such as color of clothes, wearing a backpack or not in person re-id. That is, we can encode the original data from the two domains with some feature variables or latent variables, and then it is reasonable to assume that distribution of features from two domains satisfy some criteria just as the assumptions used in <ref type="bibr" target="#b2">[3]</ref> for classification tasks. Formally, we denote the feature encoder as x(·) and x : Z → R d , and then the labeling function is l : X × X → {0, 1}, where X ⊆ R d is the extracted feature space. For simplicity, we denote l(x(z 1 ), x(z 2 )) = l(x 1 , x 2 ), where z 1 , z 2 means two different raw data. Note that the labeling function is symmetric, i.e. l(x 1 , x 2 ) = l(x 2 , x 1 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Assumptions and DA-Learnability</head><p>In this section, we first introduce some assumptions reflecting how the source domain interacting with target domain. Then with these assumptions we show the learnability of unsupervised domain adaptive re-ID.</p><p>The first assumption is covariate shift, which means that the criteria of classifying data pairs are the same for source domain and target domain. In other words, we have l S (x) = l T (x) for classification tasks, and similarly we can define the covariate shift for re-id tasks on the extracted feature space. Definition 1 (Covariate Shift). We say that source and target distribution satisfy the covariate shift assumption if they have the same labeling function, i.e. if we have l S (x 1 ,</p><formula xml:id="formula_0">x 2 ) = l T (x 1 , x 2 ).</formula><p>Another assumption is inspired by the "Probabilistic Lipschitzness", which is originally proposed for semi-supervised learning in <ref type="bibr" target="#b27">[28]</ref> and then investigated with application to domain adaptation tasks in <ref type="bibr" target="#b2">[3]</ref>. This assumption captures the intuition that in a classification task, the data can be divided into label-homogeneous clusters and are separated by low-density regions. However, in re-id tasks, the labeling function is a multivariable function, thus the original Probabilistic Lipschitzness is not applicable. Note that the intuition of re-id tasks is that similar pairs can form as a cluster. That is, for an instance, the similar data can be divided into a cluster and the cluster is separated out from the data space with a low-density gap. Mathematically, we have the following definition.</p><formula xml:id="formula_1">Definition 2 (Separately Probabilistic Lipschitzness (SPL)). Let φ : R → [0, 1] be monotonically increasing. Symmetric function f : X × X → R is φ-SPL with respect to a distribution D on X, if for all λ &gt; 0, P x1,x2∼D (∃y : |f (x 1 , x 2 ) − f (x 1 , y)| λ x 2 − y ) φ(λ)<label>(1)</label></formula><p>To ensure the learnability of the domain adaptation task, we still need a critical assumption concerning how much overlap there is between the source and target domain. We again follow the assumption used in <ref type="bibr" target="#b2">[3]</ref> on the source and target distribution, which is a relaxation of the pointwise density ratio between the two distributions. Definition 3 (Weight Ratio). Let B ⊆ 2 X be a collection of subsets of the input space X measurable with respect to both S and T . For some η &gt; 0 we define the η-weight ratio of the source distribution and the target distribution with respect to B as</p><formula xml:id="formula_2">C B,η (S, T ) = inf b∈B T (b) η S(b) T (b)<label>(2)</label></formula><p>Further, we define the weight ratio of the source distribution and the target distribution with respect to B as</p><formula xml:id="formula_3">C B (S, T ) = inf b∈B T (b) =0 S(b) T (b)<label>(3)</label></formula><p>Following the notations in <ref type="bibr" target="#b2">[3]</ref>, we also assume that our domain is the unit cube X = [0, 1] d and let B denote the set of axis aligned rectangles in [0, 1] d . For our re-ID tasks, the risk of a classifier h on target domain is</p><formula xml:id="formula_4">R T (h) = E x1,x2∼T [L(h(x 1 , x 2 ), l(x 1 , x 2 ))].<label>(4)</label></formula><p>Let the Nearest Neighbor classifier be h NN , then the following theorem implies the learnability of domain adaptive re-ID, of which the proof is included in supplemental materials. Theorem 1. Let the domain be the unit cube,X = [0, 1] d , and for some C &gt; 0, let (S, T ) be a pair of source and target distributions over X satisfying the covariate shift assumption, with C B (S, T ) C, and their common deterministic labeling function l : X × X → {0, 1} satisfying the φ-SPL property with respect to the target distribution, for some function φ. Then, for all , δ &gt; 0, for all (S, T ), if S is a source generated sample set of size at least</p><formula xml:id="formula_5">m 4 δCe φ −1 4 √ d d</formula><p>then, with probability at least 1 − δ (over the choice of S), R T (h NN ) is at most .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Reinforcing the Assumptions</head><p>In previous section, we show that with some assumptions on the extracted feature space, unsupervised domain adaptation is learnable. Thus we are concerned with how to train a feature extractor, i.e. encoder, satisfying the mentioned assumptions. Briefly speaking, we first derive several loss functions according to the assumptions and then iteratively train the encoder to minimize the loss functions via a self-training framework.</p><p>Self-training framework. Assume that we have an encoder x and some samples D with guessed label l on target domain, and the loss function is L(x, D, l). In self-training, at first a x (i) is used to extract features from all available unlabeled samples, and the target now is minimizing the loss through selecting samples, that is min D,l L(x (i) , D, l). On the next round, with these selected samples, the encoder x (i) is updated by solving the minimization problem min x L(x, D (i) , l (i) ).</p><p>It is worthwhile to note that the covariate shift assumption only depends on the property of labeling function, thus in this section we only consider the proposed SPL and weight ratio.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Reinforcing the SPL</head><p>Recall that the original data is z ∈ Z and we wish to iteratively find a encoder x(·) such that in the feature space the SPL property is satisfied as much as possible. So we first need a definition to evaluate whether one encoder is better than another concerning the SPL property.</p><p>Definition 4. Encoder x a (·) is said to be more clusterable than x b (·) with respect to a labeling function l and a distribution D over Z, if there exists ∈ (0, 1), and λ ∈ {λ 1 , λ 2 } with λ 1 λ 2 &lt; 0, such that P z1,z2∼D</p><formula xml:id="formula_6">∃z 3 : |l(x a (z 1 ), x a (z 2 )) − l(x a (z 1 ), x a (z 3 ))| − λ x a (z 2 ) − x a (z 3 ) P z1,z2∼D ∃z 3 : |l(x b (z 1 ), x b (z 2 )) − l(x b (z 1 ), x b (z 3 ))| − λ x b (z 2 ) − x b (z 3 )</formula><p>The above equation differs from the original SPL (1) for the reason that the original form is too strict to be satisfied. Now we can easily define a loss function</p><formula xml:id="formula_7">L(x, D, l; , λ) = E z1,z2∼D ∃z 3 : |l(x(z 1 ), x(z 2 )) − l(x(z 1 ), x(z 3 ))| − λ x(z 2 ) − x(z 3 ) ,</formula><p>where D means a set of samples and l is the guessed labeling function. However, directly performing optimization on the loss function is infeasible since the analytical form is unknown. To overcome the difficulty, we adopt intra-cluster distance and inter-cluster distance,</p><formula xml:id="formula_8">L intra (x, D, l) = l(x(z1),x(z2))=1 x(z 1 ) − x(z 2 ) ,<label>(5)</label></formula><formula xml:id="formula_9">L inter (x, D, l) = l(x(z1),x(z2))=0 − x(z 1 ) − x(z 2 ) .<label>(6)</label></formula><p>We show that minimizing L intra and L inter is appropriate for being more clusterable through the following theorem. Theorem 2. For two encoders x a , x b , a distribution D and a labeling function l, then</p><formula xml:id="formula_10">x a is more clusterable than x b ⇔ L intra (x a , D, l) L intra (x b , D, l) L inter (x a , D, l) L inter (x b , D, l)</formula><p>For proof we refer reader to the supplemental materials. Here, Definition 4 and Theorem 2 describe how to evaluate an encoder with a fixed distribution D and labeling function l. Obviously, we can fix the encoder and rewrite the results to evaluate the samples with guessed labels. For the sake of conciseness, the details are omitted. When D and l are fixed during the iteration procedure, minimizing L intra and L inter are straightforward. Contrastingly, we have to focus more on the strategy of picking out samples with guessed labels.</p><p>Selecting samples via clustering. In spite of the similarity between L intra and L inter , they do not share a same strategy regarding the sample selection step. For L intra , if all the data in T are encoded with a x, then for each pair (x i , x j ), it is natural to assume that a smaller x i − x j implies a higher confidence that l(x i , x j ) = 1. Likewise, a larger x i − x j implies a higher confidence that l(x i , x j ) = 0. But choosing a high confidence different pair as training data does not really improve the real performance, because the accuracy is more sensitive about the minimal distance of different pairs, i.e., inf i:</p><formula xml:id="formula_11">l(x d ,xi)=0 x(z d ) − x(z i )</formula><p>. So rather than directly selecting different pairs, we treat the selected samples as a series of clusters and dissimilar pairs are selected on the basis of different clusters. That is to say, in order to minimize L intra and L inter simultaneously, we perform clustering on the data with guessed labels.</p><p>Distance metrics and loss functions. Up to this point, we are facing an unsupervised clustering problem, which is largely settled by the distance metric. In other words, designing a sample selecting strategy to minimize a loss turns into designing a distance metric between samples, and a better distance should lead to a lower L intra and L inter . It is a common practice in image retrieval that the contextual similarity <ref type="bibr" target="#b11">[12]</ref> measure is more robust and beneficial for a lower L intra .</p><p>In our practice, we adopt the k-reciprocal encoding in <ref type="bibr" target="#b34">[35]</ref> as the distance metric, which is a variation of Jaccard distance between nearest neighbors sets. Precisely, with an encoder x, all samples from T are encoded and with these features a distance matrix M ∈ R mt×mt is computed where M ij = x i − x j 2 and m t is the total number of target samples. Then M is updated by</p><formula xml:id="formula_12">M ij = e −Mij if j ∈ I i , 0</formula><p>otherwise.</p><p>where the indices set I i is the so called robust set for x i . I i is determined by first choosing mutual k nearest neighbors for the probe, then incrementally adding elements. Specifically, denote the indices of mutual k nearest neighbors of x i as K k (x i ) and then for all</p><formula xml:id="formula_14">s ∈ K k (x i ), if |K k (x i ) ∩ K k 2 (x s )| 2 3 |K k 2 (x s )|, let I i ← K k (x i ) ∪ K k 2 (x s ). In particular, for a pair (x i , x j ), we have d J (x i , x j ) = 1 − mt k=1 min(M ik , M jk ) mt k=1 max(M ik , M jk ) .<label>(8)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Reinforcing the weight ratio</head><p>As mentioned before, weight ratio is a crucial part to support the learnability of domain adaptation. Apart from directly define a loss based on the original weight ratio definition, a similar way as the SPL case is minimizing the loss</p><formula xml:id="formula_15">L WR (x, D) = E z d ∼D inf zs∼S x(z d ) − x(z s ) ,<label>(9)</label></formula><p>where S is the source domain. The intuition here is to enhance the degree of similarity, which means that each target feature is close to some source features. We denote C B,η (S, T ; x) as the weight ratio when using x as the encoder, where B is defined in Section 3. The following theorem demonstrate that our L WR makes sense and the proof is in the supplemental materials. Theorem 3. For two encoders x a , x b , a distribution D, if η is a random variable and its support is a subset of R + , then</p><formula xml:id="formula_16">L WR (x a , D) L WR (x b , D) ⇔ E [C B,η (S, D; x a )] E C B,η (S, D; x b )</formula><p>However, unlike L inter and L intra , it is hard to optimize on x for L WR because of the infimum. On the other hand, selecting samples is easily done via giving more confidence to the sample with smaller inf zs∼S x(z d ) − x(z s ) . More specifically, for each x i from T , we search the nearest neighbor in S. The function measuring the confidence for each x i is denoted by</p><formula xml:id="formula_17">d W (x i ) = 1 − e − xi−N S (xi) 2 .<label>(10)</label></formula><p>where N S (x i ) means the nearest neighbor of x i in source domain S, and a smaller d W means a higher confidence. To transform d W and d J onto the same scale, we perform a simple normalization on d W , i.e., divided by max i d W (x i ). Combining with d J , the final distance matrix is</p><formula xml:id="formula_18">M ij = d(x i , x j ) and d(x i , x j ) = (1 − λ)d J (x i , x j ) + λ(d W (x i ) + d W (x j )),<label>(11)</label></formula><p>where λ ∈ [0, 1] is a balancing parameter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Overall algorithm</head><p>So far, general outlines of reinforcing the assumptions have been elaborated, except the details about the clustering method. In our framework, a good clustering method should possess the following properties: (a) it does not require the number of clusters as an input, because in fact a cluster means an identity and the number of identities is trivial and unknown; (b) it is able to avoid pairs of low confidence, that is allowing some points not belonging to any clusters; (c) it is scalable enough to incorporate our theoretically derived distance metric. We employ the clustering method named DBSCAN <ref type="bibr" target="#b6">[7]</ref>, which has stood the test of time and exactly have the mentioned advantages.</p><p>Now we provide some other practical details of our domain adaptive re-ID algorithm. At the beginning, an encoder x (0) is well trained on S and all the pairs are computed with Eqn. <ref type="bibr" target="#b10">(11)</ref>. Next, we describe how we set the threshold controlling whether a pair should be used to train. Intuitively, the threshold should be irrelevant to tasks since the scale of d varies from tasks. So in our method, we first sort all the distance from lowest to highest and the average value of top pN pairs is set to be the threshold τ , where N is the total number of possible pairs and p is percentage. On these data with pseudo-labels, the encoder is then trained with triplet loss <ref type="bibr" target="#b31">[32]</ref>. Our whole framework is concluded in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>In this section, we test our unsupervised domain adaptation algorithm on person re-ID and vehicle re-ID. The performance are evaluated by cumulative matching characteristic (CMC) and mean Average Precision (mAP), which are multi-gallery-shot evaluation metrics defined in <ref type="bibr" target="#b32">[33]</ref>.</p><p>Algorithm 1: Unsupervised Domain Adaptation for Re-ID input :source domain dataset S, unlabeled target domain dataset T with mt samples, balancing parameter λ, percentage p, the minimum size of a cluster N1, iteration number N2 output :an encoder x for target domain 1 Train an encoder x (0) on S; <ref type="formula" target="#formula_1">(11)</ref>; 4 Sort all the N elements in M (0) from low to high and record the mean of top pN values as threshold τ ; 5 Select train data D (0) = DBSCAN(M (0) ; τ, N1); 6 Train x (1) on D; 7 for i = 1 to N2 do <ref type="bibr" target="#b7">8</ref> Compute</p><formula xml:id="formula_19">2 Compute T (0) = x (0) (T ), S (0) = x (0) (S); 3 Compute a distance matrix M (0) on T (0) , S (0) by Eqn.</formula><formula xml:id="formula_20">T (i) = x (i) (T (i−1) ), S (i) = x (i) (S (i−1) ); 9</formula><p>Compute M (i) on T (i) , S (i) ; <ref type="bibr" target="#b9">10</ref> Select D (i) = DBSCAN(M (i) ; τ, N1); <ref type="bibr" target="#b10">11</ref> Train x (i+1) on D (i) ; 12 end Parameter settings and implementation details. In all the following re-ID experiments, we empirically set λ = 0.1, p = 1.6 × 10 −3 , N 1 = 4 and N 2 = 20. Basically, the encoder is ResNet-50 <ref type="bibr" target="#b10">[11]</ref> pre-trained on ImageNet. Both triplet and softmax loss are used for initializing the network on source domain, while only triplet loss is used for refining the encoder on target domain. More details about the network, training parameters and visual examples from different domains are included in the supplemental materials. Moreover, in the supplemental materials we also investigate other distance metrics and clustering methods.  <ref type="bibr" target="#b32">[33]</ref> and DukeMTMC-reID <ref type="bibr" target="#b24">[25]</ref> are two large scale datasets and frequently used for unsupervised domain adaptation experiments. Both of the two datasets are split into a training set and a testing set. The details including the number of identities and images are shown in <ref type="table" target="#tab_0">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Person re-ID</head><p>Comparison methods are selected in three aspects. Firstly, we show the performance of direct transfer, that is directly using the initial sourcetrained encoder on the target domain. Also, the plain self-training scheme is compared as a baseline, which means sample selection only depends on their Euclidean distance. Secondly, our method is compared with three most recent state-of-the-art methods 2 : SPGAN <ref type="bibr" target="#b5">[6]</ref>, TJ-AIDL <ref type="bibr" target="#b29">[30]</ref> and ARN <ref type="bibr" target="#b13">[14]</ref>. We report the original results quoted from in their papers. Thirdly, we show the results of our methods with and without d W , which can be viewed as ablation studies. The results are shown in <ref type="table" target="#tab_1">Table 2</ref>, from which we can observe the following facts: (a) The accuracy of self-training baseline is high and even better than two recent methods, indicating that our clustering based self-training scheme is fairly good; (b) The version without d W is better than self-training baseline, which shows the effectiveness of d J , and after incorporated with d W the final method achieves the highest accuracy, reflecting the advantage of d W . Thus our two assumptions are both useful according to the ablation studies. (c) Although the proposed d W is beneficial, the increase of accuracy brought by it varies from different tasks. We think this is related to the distribution of source and target domains. Please refer to for more discussion in B.3 on this problem.</p><p>Furthermore, we draw the mAP curves <ref type="figure">(Figure 1</ref>) during the iterations of the adaptation task Duke→Market, in which self-training baseline, using distance without d W and λ = {0.05, 0.1, 0.5, 0.7} are compared. We can see that except the baseline, all the curves have a similar   <ref type="figure">Figure 1</ref>: Convergence comparison tendency toward convergence. A subtle distinction is that after 18 iterations methods with smaller λ become unstable, while methods with larger λ move toward convergence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Vehicle re-ID</head><p>We use VeRi-776 <ref type="bibr" target="#b15">[16]</ref> and part of PKU-VehicleID <ref type="bibr" target="#b14">[15]</ref> for vehicle re-ID experiments <ref type="bibr" target="#b2">3</ref> , the details are included in <ref type="table" target="#tab_0">Table 1</ref>. Unlike person re-ID, currently there are no unsupervised domain adaptation algorithms designed for vehicle re-ID. Thus, we use the existing solutions for person re-ID as comparisons <ref type="bibr" target="#b3">4</ref> . As shown in <ref type="table" target="#tab_2">Table 3</ref>, not only are the conclusions from person re-ID verified again, but also the generalization ability of our method is shown. We discover that the compared SPGAN generates quite presentable images and we put the images into supplemental materials, but their accuracy is still lower than the self-training baseline, not to mention our proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>In this work, we bridge the gap between theories of unsupervised domain adaptation and re-id tasks. Inspired by previous work <ref type="bibr" target="#b2">[3]</ref>, we make assumptions on the extracted feature space and then show the learnability of unsupervised domain adaptive re-id tasks. Treating the assumptions as the goal of our encoder, several loss functions are proposed and then minimized via self-training framework.</p><p>Though the proposed solution is effective and outperforms state-of-the-art methods, there are still problems unsolved in our algorithm. Firstly, with regard of the weight ratio assumption, we propose the loss function L WR , which is ignored when updating the encoder because of the intractable infimum. So designing another feasible loss function is an interesting direction of research. Another promising issue is to improve the data selecting step in the self-training scheme. We turn the data selecting step into a clustering problem, which can be thought of as a version with hard threshold. This suggest that there may be a better strategy which utilize the relative values between distances. We hope that our analyses could open the door to develop new domain adaptive re-ID tasks and can lift the burden of designing large and complicate networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Materia</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Theorems and Proofs</head><p>To prove Theorem 1, we first give a lemma on the upper error bound of R T (h NN ). Let B denote the set of axis aligned rectangles in [0, 1] d and, given some η &gt; 0, let B η denotes the class of axis aligned rectangles with side-length η. For a sample set S from source domain, we have Lemma 1. Let the domain be the unit cube, X = [0, 1] d , and for some C &gt; 0 and some η 0, let (S, T ) be source and target distributions over X satisfying the covariate shift assumption, with C B,η (S, T ) C, and their common re-id labeling function l : X × X → {0, 1} satisfying the φ-SPL property with respect to the target distribution, for some function φ. Then, for all m, and all (S, T ),</p><formula xml:id="formula_21">E S∼S m [R T (h NN )] 2φ( 1 η √ d ) + 2 η d Cme<label>(12)</label></formula><p>Proof. A test pair (x 1 , x 2 ) gets the wrong label under two conditions: (a) at least one test data do not have a close neighbor with all the m training data; (b) (x 1 , x 2 ) have a close neighbor pair which have the opposite label. For (a), we can use the results from Lemma 7 and Theorem 8 in <ref type="bibr" target="#b2">[3]</ref>. Specifically, let C 1 , C 2 , · · · , C 1 /η d be a cover of the set [0, 1] d using boxes of side-length η. We have</p><formula xml:id="formula_22">E S∼S m i:S∩Ci=∅ T (C i ) 1 η d Cme .<label>(13)</label></formula><p>If x is in the box C x , then the probability of (a) can be expressed as</p><formula xml:id="formula_23">P(C x1 ∩ S = ∅ ∨ C x2 ∩ S = ∅).</formula><p>Observing that</p><formula xml:id="formula_24">P(C x1 ∩ S = ∅ ∨ C x2 ∩ S = ∅) P(C x1 ∩ S = ∅) + P(C x2 ∩ S = ∅)</formula><p>and P(C x ∩ S = ∅) = i:S∩Ci=∅ P(C i ), so (a) is bounded by 2 η d Cme . For (b), we denote the nearest neighbor to x in S is N S (x) and then (b) means in the box we have</p><formula xml:id="formula_25">l(x 1 , x 2 ) = l(N S (x 1 ), N S (x 2 )) ∧ N S (x 1 ) − x 1 η √ d ∧ N S (x 2 ) − x 2 η √ d.<label>(14)</label></formula><p>Seeing that</p><formula xml:id="formula_26">|l(x 1 , x 2 ) − l(N S (x 1 ), N S (x 2 ))| = |l(x 1 , x 2 ) − l(x 1 , N S (x 2 )) + l(x 1 , N S (x 2 )) − l(N S (x 1 ), N S (x 2 ))| |l(x 1 , x 2 ) − l(x 1 , N S (x 2 ))| + |l(x 1 , N S (x 2 )) − l(N S (x 1 ), N S (x 2 ))| So P l(x 1 , x 2 ) =l(N S (x 1 ), N S (x 2 )) ∧ N S (x 1 ) − x 1 η √ d ∧ N S (x 2 ) − x 2 η √ d P |l(x 1 , x 2 ) − l(x 1 , N S (x 2 ))| 1 η √ d N S (x 2 ) − x 2 + P |l(x 1 , N S (x 2 )) − l(N S (x 1 ), N S (x 2 ))| 1 η √ d N S (x 1 ) − x 1 2φ( 1 η √ d )</formula><p>Combining the two bounds together, we conclude our proof.</p><p>If we have a stronger weight ratio assumption, i.e. C B (S, T ) C, we get the following result of domain adaptation learnability. Theorem 4. Let the domain be the unit cube,X = [0, 1] d , and for some C &gt; 0, let (S, T ) be a pair of source and target distributions over X satisfying the covariate shift assumption, with C B (S, T ) C, and their common deterministic labeling function l : X × X → {0, 1} satisfying the φ-SPL property with respect to the target distribution, for some function φ. Then, for all , δ &gt; 0, for all (S, T ), if S is a source generated sample set of size at least</p><formula xml:id="formula_27">m 4 δCe φ −1 4 √ d d</formula><p>then, with probability at least 1 − δ (over the choice of S), the target error of the Nearest Neighbor classifier is at most .</p><p>Proof. From the proof in Theorem 1, the error was bounded under two circumstances. As for (a), we apply Markov's inequality and get</p><formula xml:id="formula_28">E S∼S m 2 i:S∩Ci=∅ T (C i ) 2 4 η d Cme<label>(15)</label></formula><p>Then for (b), we just set 2φ( 1</p><formula xml:id="formula_29">η √ d ) = 2 , so η = √ d φ −1 ( /4) .</formula><p>Finally, setting the probability to be smaller than δ yields that if</p><formula xml:id="formula_30">m 4 δCe φ −1 4 √ d d</formula><p>then with probability at least 1 − δ, the target error of the Nearest Neighbor classifier is at most .</p><p>Theorem 5. For two encoders x a , x b , a distribution D and a labeling function l, then</p><p>x a is more clusterable than</p><formula xml:id="formula_31">x b ⇔ L intra (x a , D, l) L intra (x b , D, l) L inter (x a , D, l) L inter (x b , D, l)</formula><p>Proof. (⇒) There exists ∈ (0, 1), and λ ∈ {λ 1 , λ 2 } with λ 1 λ 2 &lt; 0, such that P z1,z2∼D</p><formula xml:id="formula_32">∃z 3 : |l(x a (z 1 ), x a (z 2 )) − l(x a (z 1 ), x a (z 3 ))| − λ x a (z 2 ) − x a (z 3 ) P z1,z2∼D ∃z 3 : |l(x b (z 1 ), x b (z 2 )) − l(x b (z 1 ), x b (z 3 ))| − λ x b (z 2 ) − x b (z 3 )</formula><p>When l(z 1 , z 2 ) = 1, l(z 1 , z 3 ) = 1, and λ = λ 1 &lt; 0, P z1,z2∼D</p><formula xml:id="formula_33">∃z 3 : x a (z 2 ) − x a (z 3 ) − λ 1 P z1,z2∼D ∃z 3 : x b (z 2 ) − x b (z 3 ) − λ 1 .</formula><p>So L intra (x a , D, l) L intra (x b , D, l). And let l(z 1 , z 2 ) = 1, l(z 1 , z 3 ) = 0, and λ = λ 2 &gt; 0, then P z1,z2∼D</p><formula xml:id="formula_34">∃z 3 : x a (z 2 ) − x a (z 3 ) 1 − λ 1 P z1,z2∼D ∃z 3 : x b (z 2 ) − x b (z 3 ) 1 − λ 1 . So L inter (x a , D, l) L inter (x b , D, l). (⇐) We have l(x a (z1),x a (z2))=1 x a (z 1 ) − x a (z 2 ) l(x b (z1),x b (z2))=1 x b (z 1 ) − x b (z 2 ) .</formula><p>Denote C 1 as the mean value of L intra (x b , D, l), then P z1,z2∼D</p><formula xml:id="formula_35">∃z 3 : x a (z 2 ) − x a (z 3 ) C 1 P z1,z2∼D ∃z 3 : x b (z 2 ) − x b (z 3 ) C 1 .</formula><p>In like manner, denote C 2 as the mean value of L inter (x a , D, l), then P z1,z2∼D</p><formula xml:id="formula_36">∃z 3 : x a (z 2 ) − x a (z 3 ) C 2 P z1,z2∼D ∃z 3 : x b (z 2 ) − x b (z 3 ) C 2 .</formula><p>Theorem 6. For two encoders x a , x b , a distribution D, if η is a random variable and its support is a subset of R + , then</p><formula xml:id="formula_37">L WR (x a , D) L WR (x b , D) ⇔ E [C B,η (S, D; x a )] E C B,η (S, D; x b )</formula><p>Proof.</p><formula xml:id="formula_38">L WR (x a , D) L WR (x b , D) ⇔ P z d ∼D zs∼S ( x a (z d ) − x a (z s ) η) P z d ∼D zs∼S ( x b (z d ) − x b (z s ) η) ⇔ (∀b 0 ∈ B) P z d ∼D zs∼S (x a (z s ) ∈ b 0 |x a (z d ) ∈ b 0 ) P z d ∼D zs∼S (x b (z s ) ∈ b 0 |x b (z d ) ∈ b 0 ) ⇔ P zs∼S (x a (z s ) ∈ b 0 |T (b 0 ; x a ) η) P zs∼S (x b (z s ) ∈ b 0 |T (b 0 ; x b ) η) ⇔ E [C B,η (S, D; x a )] E C B,η (S, D; x b )</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Additional Experimental Details and Results</head><p>We present the structure of the paper in <ref type="figure" target="#fig_0">Figure 2</ref> and the most important contributions in our work are Theorem 2 and 3, both of which aim to turn the abstract and somewhat too theoretical assumptions into practical loss functions. Although Theorem 1 seems like a straightforward extension of previous work <ref type="bibr" target="#b2">[3]</ref>, it plays a fundamental role in the paper. Through the DA-learnability shown in Theorem 1, we can see that the three assumptions imposed on the distribution of two domains in Section 3 are sufficient for solving the domain adaptive re-ID problem. In other words, the sufficiency of reinforcing the three assumptions in Section 4 is shown via Theorem 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DA-learnability (Theorem 1)</head><p>Covariate  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Visualization of datasets and results</head><p>To understand the variations between different domains more clearly, <ref type="figure">Figure 3</ref> presents some samples from the datasets used in our experiments. These datasets all have their own special characteristics. For instance, people riding a bicycle are common in Market-1501, while these people are rare in DukeMTMC-reID. More importantly, the images in these re-ID datasets are heavily related to the cameras, which means that the images contain information closely knitted together with the camera, such as background, viewpoints or lighting condition.</p><p>Moreover, we present some generated samples of SPGAN for vehicle re-ID. As shown in <ref type="figure">Figure 4</ref>, their image-image translation indeed works but fails to produce satisfactory re-ID results as person re-ID. This indicates that either their proposed generative method is not suitable for unsupervised domain adaptive vehicle re-ID, or their parameters need careful tuned for a new task.</p><p>(a) Sample images from Market-1501 <ref type="bibr" target="#b32">[33]</ref> (b) Sample images from DukeMTMC-reID <ref type="bibr" target="#b24">[25]</ref> (c) Sample images from VeRi-776 <ref type="bibr" target="#b15">[16]</ref> (d) Sample images from PKU-VehicleID <ref type="bibr" target="#b14">[15]</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Encoder network</head><p>Basically, the encoder network is ResNet-50 <ref type="bibr" target="#b10">[11]</ref> pre-trained on ImageNet and the whole network is presented in <ref type="figure">Figure 5</ref>.</p><p>Person re-ID. The size of input images is 256 × 128 × 3, so the output of conv5 is 8 × 4 × 2048 and a average pool layer is added after conv5 to have a output of size 1 × 1 × 2048. We denote the output of this layer as feat1. During training on the source domain, feat1 is connected to a fully-connected (fc) layer with output 2048, denoted fc0, then the 2048 fc layer is connected to a fc layer with output 751 (Market-1501) or 702 (DukeMTMC-reID). Let the output of finally fc layer be fc1. The loss functions are Softmax(fc1) and Triplet(feat1), which are added directly (without extra balancing parameter). The model is trained by Adam optimizer <ref type="bibr" target="#b12">[13]</ref>. Training parameters are set as follows: batch size 128 (PK sampling with P=16, K=8); maximum number epochs 70; learning rate 3e-4.</p><p>When training with data from target domain, there is no fc1 layer and we use two triplet loss, that is Triplet(feat1) and Triplet(fc0). The trick of using two triplet losses comes from <ref type="bibr" target="#b28">[29]</ref>. The model is trained by stochastic gradient descent and in each iteration step we perform data augmentation (random flip and random erasing) on the data. Training parameters are set as follows: batch size 128 (PK sampling with P=32, K=4); momentum 0.9; maximum number epochs 70; learning rate 6e-5. The networks are trained with two TITAN X GPUs.</p><p>Vehicle re-ID. All parameters including network architecture are same as person re-ID, except the size of input data. The input data here are resized to 224 × 224 × 3 and the output of conv5 is 7 × 7 × 2048.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 More results</head><p>Effectiveness of d W . From <ref type="table" target="#tab_1">Table 2</ref>, <ref type="table" target="#tab_2">Table 3</ref> and <ref type="figure">Figure 1</ref>, we observe that in a practical view, using d W actually is not appealing. We think the reasons are two folds. Firstly, the effectiveness of d W depends on the distribution of source and target domain. In <ref type="figure">Fig.(6)</ref>, we design a simple example in 2D feature space to show the validity of d W . In the left figure, the grey points denotes the extracted feature from source space and the colored points denotes the features of target data with real label. In the middle figure, we show the pseudo labels generated with DBSCAN when setting λ = 0, i.e., not using d W . In the right figure, the results with d W is shown. Comparing the middle figure and the right figure, we can see that d W is important in such situation. The key idea in this demo is that those "easy" target points happen to be near the source data. Here, "easy" target points means the points belonging to the same ID are "close" in the extracted feature space with present encoder. This example can be also used for classification tasks since the Weight Ratio is a shared assumptions between our work and <ref type="bibr" target="#b2">[3]</ref>. Secondly, d W is derived from L WR , but the potential value of L WR is not fully exploited in our algorithm. Thus, using d W in practical application is not appealing. However, when not using d W , the results are stable and good enough and already outperforms existing methods by large margin, which shows the power of the self-training scheme in domain adaptive re-ID problems. For real applications, if the computation resources are limited, we recommend just setting λ = 0 and not making the effort to search for an optimal λ.</p><p>Comparison of distance metrics. As for other contextual distance metrics, we test the performance of using the original Jaccard distance with or without d W (also set λ = 0.1). For the Jaccard distance,  we first compute the k = 20 nearest neighbor set and then compute the distance between the sets. Another conclusion is that taking d W into consideration is also beneficial for Jaccard distance. However, both of the two distance metrics are worse than the self-training baseline, i.e., Euclidean distance. The reason is that the Jaccard distance only consider the nearest neighbor sets and therefore pairs without overlapping nearest neighbors will have a Jaccard distance 1, which is too strict to generate enough training pairs. The shortcoming also leads to a slow or even halted increasing of accuracy, for more details see the convergence comparison paragraph and <ref type="figure">Figure 1</ref>. As is shown in <ref type="table" target="#tab_4">Table 4</ref>, k-reciprocal encoding employed in our method positively improve the performance of plain Jaccard distance.</p><p>Comparison of clustering methods. Due to the restrictions of a suitable clustering method, we only test a version with affinity propagation <ref type="bibr" target="#b8">[9]</ref>. For task DukeMTMC-reID→Market-1501, we investigate the effectiveness of affinity propagation with other distance metrics. It is obvious that affinity propagation is not a proper clustering method for the reason that all data are used for clustering, which means it cannot avoid those pairs of low confidence. As shown in <ref type="table" target="#tab_5">Table 5</ref>, a interesting fact is that with affinity propagation just using Euclidean distance is better than our proposed distance. The reason behind this phenomenon is that the number of IDs (clusters) generated by affinity propagation is much larger when using our proposed distance. In <ref type="figure" target="#fig_3">Figure 7</ref>, we show the number of IDs with respect to each iteration step. Using our distance leads to a larger number of clusters out of the reason that our distance will enlarge the gap between the dissimilar pairs, which is ought to be beneficial of getting rid of these helpless stray samples. However, affinity propagation is a clustering method that every sample is assigned to some cluster and therefore using our distance performs worse than Euclidean distance.  Parameters analysis Among all the parameters in our algorithm, the most influencing parameters are the percentage p and the balancing parameter λ. Since the influence of λ has been reported, here we perform experiments with a series of different p from DukeMTMC-reID to Market-1501 and the results are shown in <ref type="table" target="#tab_6">Table 6</ref>. As we can see from the table, even a small change (2 × 10 −4 ) of p has a discernible impact on the final accuracy. It is because that we use large scale datasets and the number of all possible pairs from target datasets is large. Take Market-1501 as an example, the number of training images is 12,936, so the number of all data pairs is over 8 × 10 7 . Thus a small change of p can cause a large change of the threshold.</p><p>Convergence comparison. In <ref type="figure" target="#fig_5">Figure 8</ref>, we use DukeMTMC-reID as source domain and Market-1501 as target domain and we first show the convergence results with different distance metric and clustering method in (a) and (b). Several conclusions can be drawn from the curves: First, we can see that the Jaccard distance based version becomes more stable after adding d W ; Second, the accuracy of the Jaccard distance based version almost stops increasing after 14 iterations, which is caused by the special property of Jaccard distance mentioned before; Third, using affinity propagation converges very fast and after about 8 iterations the accuracy stop increasing, which is caused by the inaccurate number of clusters and all the samples are used to train the network. Thus the loss functions fail to be minimized through sample selection step. Moreover, we show the results with different p in (c) and (d). It is obvious that all the curves have a similar convergence tendency, which demonstrates that our iteration process is robust with regard of the crucial parameter p.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Structure of the paper.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>Sample images from different datasets. Sample images generated by SPGAN on vehicle datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :Figure 6 :</head><label>56</label><figDesc>The architecture of our unsupervised domain adaptive network with ResNet-50 based encoder. Pseudo labels of target data w/o dW (λ = 0, ρ = 0.6) Pseudo labels of target data with dW (λ = 0.5, ρ = 0.6) An example to show the effectiveness of d W .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 7 :</head><label>7</label><figDesc>The number of IDs (clusters) on the target dataset of each iteration step when using affinity propagation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>mAP curves with different p</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 :</head><label>8</label><figDesc>Convergence comparison of different versions. We use DukeMTMC-reID as source domain and Market-1501 as target domain.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>The details of datasets used in our experiments.</figDesc><table><row><cell>Datasets</cell><cell cols="4">Training #IDs #Images #IDs #Images Testing</cell></row><row><cell>Market [33]</cell><cell>751</cell><cell>12,936</cell><cell>750</cell><cell>19,732</cell></row><row><cell>Duke [25]</cell><cell>702</cell><cell>16,522</cell><cell>702</cell><cell>19,889</cell></row><row><cell>VeRi [16]</cell><cell>576</cell><cell>37,778</cell><cell>200</cell><cell>13,257</cell></row><row><cell>PKU [15]</cell><cell>2,290</cell><cell>24,157</cell><cell>-</cell><cell>-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Comparison of unsupervised domain adaptive person re-ID methods.</figDesc><table><row><cell>Methods</cell><cell cols="8">DukeMTMC-reID→Market-1501 rank-1 rank-5 rank-10 mAP rank-1 rank-5 rank-10 mAP Market-1501→DukeMTMC-reID</cell></row><row><cell>Direct Transfer</cell><cell>46.8</cell><cell>64.6</cell><cell>71.5</cell><cell>19.1</cell><cell>27.3</cell><cell>41.2</cell><cell>47.1</cell><cell>11.9</cell></row><row><cell>Self-training Baseline</cell><cell>66.7</cell><cell>80.0</cell><cell>85.0</cell><cell>39.6</cell><cell>40.8</cell><cell>53.9</cell><cell>60.5</cell><cell>24.7</cell></row><row><cell>SPGAN [6]</cell><cell>57.7</cell><cell>75.8</cell><cell>82.4</cell><cell>26.7</cell><cell>46.4</cell><cell>62.3</cell><cell>68.0</cell><cell>26.2</cell></row><row><cell>TJ-AIDL [30]</cell><cell>58.2</cell><cell>74.8</cell><cell>81.1</cell><cell>26.5</cell><cell>44.3</cell><cell>59.6</cell><cell>65.0</cell><cell>23.0</cell></row><row><cell>ARN [14]</cell><cell>70.3</cell><cell>80.4</cell><cell>86.3</cell><cell>39.4</cell><cell>60.2</cell><cell>73.9</cell><cell>79.5</cell><cell>33.4</cell></row><row><cell>Ours w/o dW</cell><cell>75.1</cell><cell>88.7</cell><cell>92.4</cell><cell>52.5</cell><cell>68.1</cell><cell>80.1</cell><cell>83.2</cell><cell>49.0</cell></row><row><cell>Ours</cell><cell>75.8</cell><cell>89.5</cell><cell>93.2</cell><cell>53.7</cell><cell>68.4</cell><cell>80.1</cell><cell>83.5</cell><cell>49.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Comparison of unsupervised domain adaptive vehicle re-ID methods.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>55</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>50</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>45</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Methods</cell><cell cols="4">PKU-VehicleID→VeRi-776 rank-1 rank-5 rank-10 mAP</cell><cell>mAP</cell><cell>40 35</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Direct Transfer</cell><cell>52.1</cell><cell>65.1</cell><cell>71.1</cell><cell>14.6</cell><cell></cell><cell>30</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Self-training Baseline</cell><cell>74.4</cell><cell>81.6</cell><cell>84.6</cell><cell>33.5</cell><cell></cell><cell>25</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>SPGAN [6]</cell><cell>57.4</cell><cell>70.0</cell><cell>75.6</cell><cell>16.4</cell><cell></cell><cell>20</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Ours w/o dW</cell><cell>76.7</cell><cell>85.5</cell><cell>89.3</cell><cell>35.3</cell><cell></cell><cell>15</cell><cell>0</cell><cell>2</cell><cell>4</cell><cell>6</cell><cell>8</cell><cell>10</cell><cell>12</cell><cell>14</cell><cell>16</cell><cell>18</cell><cell>20</cell></row><row><cell>Ours</cell><cell>76.9</cell><cell>85.8</cell><cell>89.0</cell><cell>35.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Iteration</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Comparison of distance metrics.</figDesc><table><row><cell>Methods</cell><cell cols="4">DukeMTMC-reID→Market-1501 rank-1 rank-5 rank-10 mAP</cell></row><row><cell>Jaccard distance</cell><cell>63.8</cell><cell>80.0</cell><cell>85.3</cell><cell>37.1</cell></row><row><cell>Jaccard distance with d W</cell><cell>65.7</cell><cell>81.2</cell><cell>86.5</cell><cell>38.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Comparison of clustering methods.</figDesc><table><row><cell cols="5">Distance Metrics rank-1 rank-5 rank-10 mAP</cell></row><row><cell>Euclidean</cell><cell>63.5</cell><cell>76.6</cell><cell>80.7</cell><cell>36.9</cell></row><row><cell>Ours w/o d W</cell><cell>62.4</cell><cell>74.6</cell><cell>78.9</cell><cell>35.2</cell></row><row><cell>Ours</cell><cell>62.4</cell><cell>74.5</cell><cell>78.8</cell><cell>35.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>The impact of the parameter p on person re-ID (from DukeMTMC-reID to Market-1501). rank-1 rank-5 rank-10 mAP p = 1.0 × 10 −3</figDesc><table><row><cell></cell><cell>72.7</cell><cell>87.4</cell><cell>91.7</cell><cell>49.0</cell></row><row><cell>p = 1.2 × 10 −3</cell><cell>73.3</cell><cell>86.0</cell><cell>89.5</cell><cell>49.6</cell></row><row><cell>p = 1.4 × 10 −3</cell><cell>74.2</cell><cell>88.0</cell><cell>92.1</cell><cell>50.8</cell></row><row><cell>p = 1.6 × 10 −3</cell><cell>75.8</cell><cell>89.5</cell><cell>93.2</cell><cell>53.7</cell></row><row><cell>p = 1.8 × 10 −3</cell><cell>75.7</cell><cell>89.1</cell><cell>92.8</cell><cell>52.2</cell></row><row><cell>p = 2.0 × 10 −3</cell><cell>75.1</cell><cell>88.7</cell><cell>92.3</cell><cell>51.6</cell></row><row><cell>p = 2.2 × 10 −3</cell><cell>72.9</cell><cell>87.4</cell><cell>91.7</cell><cell>49.2</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Our results also outperforms PTGAN<ref type="bibr" target="#b30">[31]</ref> by large margin, but the comparison with PTGAN is not shown here since we adopt a different backbone network.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">In PKU-VehicleID, the camera information is not provided but needed when computing the CMC and mAP, so we only test with the setting that PKU-VehicleID as source dataset and VeRi-776 as target dataset.<ref type="bibr" target="#b3">4</ref> We only test SPGAN. Because (1) source code of ARN is not available; (2) TJ-AIDL requires attribute labels as an input, which is not available in vehicle re-ID datasets. For SPGAN, the experiments are carried out with their default parameters for person re-ID.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Unsupervised language model adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michiel</forename><surname>Bacchiani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Roark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings.(ICASSP&apos;03). 2003 IEEE International Conference on</title>
		<meeting>.(ICASSP&apos;03). 2003 IEEE International Conference on</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note>Acoustics, Speech, and Signal Processing</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A theory of learning from different domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shai</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><forename type="middle">Wortman</forename><surname>Vaughan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2010-05" />
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="151" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Domain adaptation-can quantity compensate for quality?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shai</forename><surname>Ben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruth</forename><surname>Urner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Mathematics and Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="185" to="202" />
			<date type="published" when="2014-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Extracting discriminative concepts for domain adaptation in text mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wai</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivor</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tak-Lam</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 15th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="179" to="188" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Vehicle re-identification and travel time measurement in real-time on freeways using existing loop detector infrastructure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Coifman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Research Record: Journal of the Transportation Research Board</title>
		<imprint>
			<biblScope unit="issue">1643</biblScope>
			<biblScope unit="page" from="181" to="191" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Image-image domain adaptation with preserved self-similarity and domain-dissimilarity for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijian</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixiang</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoliang</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbin</forename><surname>Jiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A density-based algorithm for discovering clusters a density-based algorithm for discovering clusters in large spatial databases with noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Ester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörg</forename><surname>Sander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second International Conference on Knowledge Discovery and Data Mining, KDD&apos;96</title>
		<meeting>the Second International Conference on Knowledge Discovery and Data Mining, KDD&apos;96</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page" from="226" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Unsupervised Person Re-identification: Clustering and Fine-tuning. arXiv</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hehe</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Clustering by passing messages between data points. science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Brendan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Delbert</forename><surname>Frey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dueck</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">315</biblScope>
			<biblScope unit="page" from="972" to="976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Domain-adversarial training of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaroslav</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniya</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hana</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2096" to="2030" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A contextual dissimilarity measure for accurate and efficient image search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jegou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Harzallah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2007-06" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014-12" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Adaptation and re-identification network: An unsupervised deep transfer learning approach to person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Jhe</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fu-En</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Cheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Ying</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Chiang Frank</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</title>
		<imprint>
			<date type="published" when="2018-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep relative distance learning: Tell the difference between similar vehicles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongye</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaowei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiejun</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2167" to="2175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Large-scale vehicle re-identification in urban surveillance videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE International Conference on Multimedia and Expo (ICME)</title>
		<imprint>
			<date type="published" when="2016-07" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yishay</forename><surname>Mansour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehryar</forename><surname>Mohri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Afshin</forename><surname>Rostamizadeh</surname></persName>
		</author>
		<title level="m">Domain Adaptation: Learning Bounds and Algorithms</title>
		<imprint>
			<date type="published" when="2009-02" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">A literature review of domain adaptation with unlabeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Margolis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1" to="42" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Effective self-training for parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the main conference on human language technology conference of the North American Chapter of the Association of Computational Linguistics</title>
		<meeting>the main conference on human language technology conference of the North American Chapter of the Association of Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="152" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Reranking and self-training for parser adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics</title>
		<meeting>the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="337" to="344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Semi-supervised text classification using em. Semi-Supervised Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kamal</forename><surname>Nigam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Mitchell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="33" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Transfer learning via dimensionality reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="677" to="682" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Unsupervised cross-dataset transfer learning for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peixi</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaowei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano</forename><surname>Pontil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaogang</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiejun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghong</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1306" to="1315" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Things and persons. The Review of Metaphysics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alvin</forename><surname>Plantinga</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1961" />
			<biblScope unit="page" from="493" to="519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Performance measures and a data set for multi-target, multi-camera tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ergys</forename><surname>Ristani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Solera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rita</forename><surname>Cucchiara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlo</forename><surname>Tomasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision workshop on Benchmarking Multi-Target Tracking</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Domain adaptation of conditional probability models via feature subsetting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandeepkumar</forename><surname>Satpal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunita</forename><surname>Sarawagi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Principles of Data Mining and Knowledge Discovery</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="224" to="235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Adapting naive bayes to domain adaptation for sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songbo</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuefen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongbo</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="337" to="349" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Access to unlabeled data can speed up prediction time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruth</forename><surname>Urner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shai</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shai</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on International Conference on Machine Learning, ICML&apos;11</title>
		<meeting>the 28th International Conference on International Conference on Machine Learning, ICML&apos;11<address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<publisher>Omnipress</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="641" to="648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nam</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<title level="m">Generalization in Metric Learning: Should the Embedding Layer be the Embedding Layer? arXiv</title>
		<imprint>
			<date type="published" when="2018-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Transferable joint attribute-identity deep learning for unsupervised person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingya</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiatian</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaogang</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Person transfer gan to bridge domain gap for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Longhui</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiliang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Distance Metric Learning for Large Margin Nearest Neighbor Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Kilian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><forename type="middle">K</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="207" to="244" />
			<date type="published" when="2009-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Scalable Person Re-identification: A Benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2015-12" />
			<biblScope unit="page" from="1116" to="1124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Person Re-identification: Past, Present and Future</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">G</forename><surname>Hauptmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016-10" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Re-ranking person re-identification with kreciprocal encoding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhun</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donglin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaozi</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3652" to="3661" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
