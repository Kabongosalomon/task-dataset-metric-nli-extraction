<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Using Self-Supervised Learning Can Improve Model Robustness and Uncertainty</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
							<email>hendrycks@berkeley.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mantas</forename><surname>Mazeika</surname></persName>
							<email>mantas3@illinois.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurav</forename><surname>Kadavath</surname></persName>
							<email>sauravkadavath@berkeley.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><surname>Song</surname></persName>
							<email>dawnsong@berkeley.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">UC Berkeley</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">UIUC</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Using Self-Supervised Learning Can Improve Model Robustness and Uncertainty</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T11:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Self-supervision provides effective representations for downstream tasks without requiring labels. However, existing approaches lag behind fully supervised training and are often not thought beneficial beyond obviating or reducing the need for annotations. We find that self-supervision can benefit robustness in a variety of ways, including robustness to adversarial examples, label corruption, and common input corruptions. Additionally, self-supervision greatly benefits out-of-distribution detection on difficult, near-distribution outliers, so much so that it exceeds the performance of fully supervised methods. These results demonstrate the promise of self-supervision for improving robustness and uncertainty estimation and establish these tasks as new axes of evaluation for future self-supervised learning research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Self-supervised learning holds great promise for improving representations when labeled data are scarce. In semi-supervised learning, recent self-supervision methods are state-of-the-art <ref type="bibr" target="#b8">[Gidaris et al., 2018</ref><ref type="bibr" target="#b7">, Dosovitskiy et al., 2016</ref><ref type="bibr" target="#b40">, Zhai et al., 2019</ref>, and self-supervision is essential in video tasks where annotation is costly <ref type="bibr" target="#b34">[Vondrick et al., 2016</ref><ref type="bibr" target="#b35">[Vondrick et al., , 2018</ref>. To date, however, self-supervised approaches lag behind fully supervised training on standard accuracy metrics and research has existed in a mode of catching up to supervised performance. Additionally, when used in conjunction with fully supervised learning on a fully labeled dataset, self-supervision has little impact on accuracy. This raises the question of whether large labeled datasets render self-supervision needless.</p><p>We show that while self-supervision does not substantially improve accuracy when used in tandem with standard training on fully labeled datasets, it can improve several aspects of model robustness, including robustness to adversarial examples , label corruptions [Patrini et al., 2017,  Zhang and<ref type="bibr" target="#b42">Sabuncu, 2018]</ref>, and common input corruptions such as fog, snow, and blur <ref type="bibr" target="#b10">[Hendrycks and Dietterich, 2019]</ref>. Importantly, these gains are masked if one looks at clean accuracy alone, for which performance stays constant. Moreover, we find that self-supervision greatly improves out-of-distribution detection for difficult, near-distribution examples, a long-standing and underexplored problem. In fact, using self-supervised learning techniques on CIFAR-10 and ImageNet for out-of-distribution detection, we are even able to surpass fully supervised methods.</p><p>These results demonstrate that self-supervision need not be viewed as a collection of techniques allowing models to catch up to full supervision. Rather, using the two in conjunction provides strong regularization that improves robustness and uncertainty estimation even if clean accuracy does not * Equal Contribution.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>change. Importantly, these methods can improve robustness and uncertainty estimation without requiring larger models or additional data <ref type="bibr" target="#b18">, Kurakin et al., 2017</ref>. They can be used with task-specific methods for additive effect with no additional assumptions. With self-supervised learning, we make tangible progress on adversarial robustness, label corruption, common input corruptions, and out-of-distribution detection, suggesting that future self-supervised learning methods could also be judged by their utility for uncertainty estimates and model robustness. Code and our expanded ImageNet validation dataset are available at https://github.com/hendrycks/ss-ood.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Figure 1: Predicting rotation requires modeling shape. Texture alone is not sufficient for determining whether the zebra is flipped, although it may be sufficient for classification under ideal conditions. Thus, training with self-supervised auxiliary rotations may improve robustness.</p><p>Self-supervised learning. A number of selfsupervised methods have been proposed, each exploring a different pretext task. <ref type="bibr" target="#b6">Doersch et al. [2015]</ref> predict the relative position of image patches and use the resulting representation to improve object detection. <ref type="bibr" target="#b7">Dosovitskiy et al. [2016]</ref> create surrogate classes to train on by transforming seed image patches. Similarly, <ref type="bibr" target="#b8">Gidaris et al. [2018]</ref> predict image rotations <ref type="bibr">(Figure 1)</ref>. Other approaches include using colorization as a proxy task <ref type="bibr" target="#b19">[Larsson et al., 2016]</ref>, deep clustering methods <ref type="bibr" target="#b17">[Ji et al., 2018]</ref>, and methods that maximize mutual information <ref type="bibr" target="#b15">[Hjelm et al., 2019]</ref> with high-level representations <ref type="bibr" target="#b16">, Hénaff et al., 2019</ref>. These works focus on the utility of self-supervision for learning without labeled data and do not consider its effect on robustness and uncertainty.</p><p>Robustness. Improving model robustness refers to the goal of ensuring machine learning models are resistant across a variety of imperfect training and testing conditions. <ref type="bibr" target="#b10">Hendrycks and Dietterich [2019]</ref> look at how models can handle common real-world image corruptions (such as fog, blur, and JPEG compression) and propose a comprehensive set of distortions to evaluate real-world robustness. Another robustness problem is learning in the presence of corrupted labels <ref type="bibr" target="#b24">[Nettleton et al., 2010</ref><ref type="bibr" target="#b25">, Patrini et al., 2017</ref>. To this end, <ref type="bibr" target="#b12">Hendrycks et al. [2018]</ref> introduce Gold Loss Correction (GLC), a method that uses a small set of trusted labels to improve accuracy in this setting. With high degrees of label corruption, models start to overfit the misinformation in the corrupted labels <ref type="bibr">Sabuncu, 2018, Hendrycks et al., 2019a]</ref>, suggesting a need for ways to supplement training with reliable signals from unsupervised objectives.  explore adversarial robustness and propose PGD adversarial training, where models are trained with a minimax robust optimization objective. <ref type="bibr" target="#b41">Zhang et al. [2019]</ref> improve upon this work with a modified loss function and develop a better understanding of the trade-off between adversarial accuracy and natural accuracy.</p><p>Out-of-distribution detection. Out-of-distribution detection has a long history. Traditional methods such as one-class SVMs <ref type="bibr" target="#b28">[Schölkopf et al., 1999]</ref> have been revisited with deep representations <ref type="bibr" target="#b26">[Ruff et al., 2018]</ref>, yielding improvements on complex data. A central line of recent exploration has been with out-of-distribution detectors using supervised representations. <ref type="bibr" target="#b11">Hendrycks and Gimpel [2017]</ref> propose using the maximum softmax probability of a classifier for out-of-distribution detection. <ref type="bibr" target="#b20">Lee et al. [2018]</ref> expand on this by generating synthetic outliers and training the representations to flag these examples as outliers. However, <ref type="bibr" target="#b14">Hendrycks et al. [2019b]</ref> find that training against a large and diverse dataset of outliers enables far better out-of-distribution detection on unseen distributions. In these works, detection is most difficult for near-distribution outliers, which suggests a need for new methods that force the model to learn more about the structure of in-distribution examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Robustness</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Robustness to Adversarial Perturbations</head><p>Improving robustness to adversarial inputs has proven difficult, with adversarial training providing the only longstanding gains <ref type="bibr">Wagner, 2017, Athalye et al., 2018]</ref>. In this section, we demonstrate that auxiliary self-supervision in the form of predicting rotations <ref type="bibr" target="#b8">[Gidaris et al., 2018]</ref>  improve upon standard Projected Gradient Descent (PGD) adversarial training . We also observe that self-supervision can provide gains when combined with stronger defenses such as TRADES <ref type="bibr" target="#b41">[Zhang et al., 2019]</ref> and is not broken by gradient-free attacks such as SPSA <ref type="bibr" target="#b32">[Uesato et al., 2018]</ref>.</p><p>Setup. The problem of defending against bounded adversarial perturbations can be formally expressed as finding model parameters θ for the classifier p that minimize the objective</p><formula xml:id="formula_0">min θ E (x,y)∼D [max x ∈S L CE (y, p(y | x ); θ)] where S = {x : x − x &lt; ε}<label>(1)</label></formula><p>In this paper, we focus on ∞ norm bounded adversaries.  propose that PGD is "a universal first-order adversary." Hence, we first focus on defending against PGD. Let PGD(x) be the K th step of PGD,</p><formula xml:id="formula_1">x k+1 = Π S x k + α sign(∇ x L CE (y, p(y | x k ); θ)) and x 0 = x + U (−ε, ε)<label>(2)</label></formula><p>where K is a preset parameter which characterizes the number of steps that are taken, Π S is the projection operator for the l ∞ ball S, and L CE (y, p(y | x ); θ) is the loss we want to optimize. Normally, this loss is the cross entropy between the model's softmax classification output for x and the ground truth label y. For evaluating robust accuracy, we use 20-step and 100-step adversaries. For the 20-step adversary, we set the step-size α = 2/256. For the 100-step adversary, we set α = 0.3/256 as in . During training, we use 10-step adversaries with α = 2/256.  In all experiments, we use 40-2 Wide Residual Networks <ref type="bibr" target="#b39">Zagoruyko and Komodakis [2016]</ref>. For training, we use SGD with Nesterov momentum of 0.9 and a batch size of 128. We use an initial learning rate of 0.1 and a cosine learning rate schedule <ref type="bibr" target="#b22">Loshchilov and Hutter [2016]</ref> and weight decay of 5 × 10 −4 . For data augmentation, we use random cropping and mirroring. Hyperparameters were chosen as standard values and are used in subsequent sections unless otherwise specified.</p><p>Method. We explore improving representation robustness beyond standard PGD training with auxiliary rotation-based self-supervision in the style of <ref type="bibr" target="#b8">Gidaris et al. [2018]</ref>. In our approach, we train a classification network along with a separate auxiliary head, which takes the penultimate vector from the network as input and outputs a 4-way softmax distribution. This head is trained along with the rest of the network to predict the amount of rotation applied to a given input image (from 0°, 90°, 180°, and 270°). Our overall loss during training can be broken down into a supervised loss and a self-supervised loss L(x, y; θ) = L CE (y, p(y | PGD(x)); θ) + λL SS (PGD(x); θ).</p><p>Note that the self-supervised component of the loss does not require the ground truth training label y as input. The supervised loss does not make use of our auxiliary head, while the self-supervised loss only makes use of this head. When λ = 0, our total loss falls back to the loss used for PGD training.</p><p>For our experiments, we use λ = 0.5 and the following rotation-based self-supervised loss</p><formula xml:id="formula_3">L SS (x; θ) = 1 4   r∈{0 • ,90 • ,180 • ,270 • } L CE (one_hot(r), p rot_head (r | R r (x)); θ)   ,<label>(4)</label></formula><p>where R r (x) is a rotation transformation and L CE (x, r; θ) is the cross-entropy between the auxiliary head's output and the ground-truth label r ∈ {0 • , 90 • , 180 • , 270 • }. In order to adapt the PGD adversary to the new training setup, we modify the loss used in the PGD update equation <ref type="formula" target="#formula_1">(2)</ref> to maximize both the rotation loss and the classification loss. In Appendix C, we find that this modification is optional and that the main source of improvement comes from the rotation loss itself. We report results with the modification here, for completeness. The overall loss that PGD will try to maximize for each training image is L CE (y, p(y | x); θ) + L SS (x; θ). At test-time, the PGD loss does not include the L SS term, as we want to attack the image classifier and not the rotation classifier.</p><p>Results and analysis. We are able to attain large improvements over standard PGD training by adding self-supervised rotation prediction. <ref type="table">Table 1</ref> contains results of our model against PGD adversaries with K = 20 and K = 100. In both cases, we are able to achieve a 5.6% absolute improvement over classical PGD training. In <ref type="figure" target="#fig_1">Figure 2</ref>, we observe that our method of adding auxiliary rotations actually provides larger gains over standard PGD training as the maximum perturbation distance ε increases. The figure also shows that our method can withstand up to 11% larger perturbations than PGD training without any drop in performance.</p><p>In order to demonstrate that our method does not rely on gradient obfuscation, we attempted to attack our models using SPSA <ref type="bibr" target="#b32">[Uesato et al., 2018]</ref> and failed to notice any performance degradation compared to standard PGD training. In addition, since our self-supervised method has the nice property of being easily adaptable to supplement other different supervised defenses, we also studied the effect of adding self-supervised rotations to stronger defenses such as TRADES <ref type="bibr" target="#b41">[Zhang et al., 2019]</ref>. We found that self-supervision is able to help in this setting as well. Our best-performing TRADES + rotations model gives a 1.22% boost over standard TRADES and a 7.79% boost over standard PGD training in robust accuracy. For implementation details, see code.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Robustness to Common Corruptions</head><p>Setup. In real-world applications of computer vision systems, inputs can be corrupted in various ways that may not have been encountered during training. Improving robustness to these common corruptions is especially important in safety-critical applications. <ref type="bibr" target="#b10">Hendrycks and Dietterich [2019]</ref> create a set of fifteen test corruptions and four validation corruptions common corruptions to measure input corruption robustness. These corruptions fall into noise, blur, weather, and digital categories. Examples include shot noise, zoom blur, snow, and JPEG compression.</p><p>We use the CIFAR-10-C validation dataset from <ref type="bibr" target="#b10">Hendrycks and Dietterich [2019]</ref> and compare the robustness of normally trained classifiers to classifiers trained with an auxiliary rotation prediction loss. As in previous sections, we predict all four rotations in parallel in each batch. We use 40-2 Wide Residual Networks and the same optimization hyperparameters as before. We do not tune on the validation corruptions, so we report average performance over all corruptions. Results are in <ref type="figure" target="#fig_2">Figure 3</ref>.</p><p>Results and analysis. The baseline of normal training achieves a clean accuracy of 94.7% and an average accuracy over all corruptions of 72.3%. Training with auxiliary rotations maintains clean accuracy at 95.5% but increases the average accuracy on corrupted images by 4.6% to 76.9%. Thus, the benefits of self-supervision to robustness are masked by similar accuracy on clean images. Performance gains are spread across corruptions, with a small loss of performance in only one corruption type, JPEG compression. For glass blur, clean accuracy improves by 11.4%, and for Gaussian noise it improves by 11.6%. Performance is also improved by 8.9% on contrast and shot noise and 4.2% on frost, indicating substantial gains in robustness on a wide variety of corruptions.</p><p>These results demonstrate that self-supervision can regularize networks to be more robust even if clean accuracy is not affected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Robustness to Label Corruptions</head><p>Setup. Training classifiers on corrupted labels can severely degrade performance. Thus, several prior works have explored training deep neural networks to be robust to label noise in the multi-class  classification setting <ref type="bibr" target="#b30">Sukhbaatar et al. [2014]</ref>, <ref type="bibr" target="#b25">Patrini et al. [2017]</ref>, <ref type="bibr" target="#b12">Hendrycks et al. [2018]</ref>. We use the problem setting from these works. Let x, y, and y be an input, clean label, and potentially corrupted label respectively. Given a dataset D of (x, y) pairs for training, the task is to obtain high classification accuracy on a test dataset D test of cleanly-labeled (x, y) pairs.</p><p>Given a cleanly-labeled training dataset D, we generate D with a corruption matrix C, where C ij = p( y = j | y = i) is the probability of a ground truth label i being corrupted to j. Where K is the range of the label, we construct C according to C = (1 − s)I K + s11 T /K. In this equation, s is the corruption strength, which lies in [0, 1]. At a corruption strength of 0, the labels are unchanged, while at a corruption strength of 1 the labels have an equal chance of being corrupted to any class.</p><p>To measure performance, we average performance on D test over corruption strengths from 0 to 1 in increments of 0.1 for a total of 11 experiments.</p><p>Methods. Training without loss correction methods or self-supervision serves as our first baseline, which we call No Correction in <ref type="table" target="#tab_3">Table 2</ref>. Next, we compare to the state-of-the-art Gold Loss Correction (GLC) <ref type="bibr" target="#b12">Hendrycks et al. [2018]</ref>. This is a two-stage loss correction method based on <ref type="bibr" target="#b30">Sukhbaatar et al. [2014]</ref> and <ref type="bibr" target="#b25">Patrini et al. [2017]</ref>. The first stage of training estimates the matrix C of conditional corruption probabilities, which partially describes the corruption process. The second stage uses the estimate of C to train a corrected classifier that performs well on the clean label distribution. The GLC assumes access to a small dataset of trusted data with cleanly-labeled examples. Thus, we specify the percent of amount of trusted data available in experiments as a fraction of the training set. This setup is also known as a semi-verified setting <ref type="bibr" target="#b3">Charikar et al. [2017]</ref>.</p><p>To investigate the effect of self-supervision, we use the combined loss L CE (y, p(y | x); θ) + λL SS (x; θ), where the first term is standard cross-entropy loss and the second term is the auxiliary rotation loss defined in Section 3.1. We call this Rotations in <ref type="table" target="#tab_3">Table 2</ref>. In all experiments, we set λ = 0.5. <ref type="bibr" target="#b8">Gidaris et al. [2018]</ref> demonstrate that predicting rotations can yield effective representations for subsequent fine-tuning on target classification tasks. We build on this approach and pre-train with the auxiliary rotation loss alone for 100 epochs, after which we fine-tune for 40 epochs with the combined loss.</p><p>We use 40-2 Wide Residual Networks <ref type="bibr" target="#b39">[Zagoruyko and Komodakis, 2016]</ref>. Hyperparameters remain unchanged from Section 3.1. To select the number of fine-tuning epochs, we use a validation split of the CIFAR-10 training dataset with clean labels and select a value to bring accuracy close to that of Normal Training. Results are in <ref type="table" target="#tab_3">Table 2</ref> and performance curves are in <ref type="figure" target="#fig_4">Figure 4</ref>.</p><p>Analysis. We observe large gains in robustness from auxiliary rotation prediction. Without loss corrections, we reduce the average error by 5.6% on CIFAR-10 and 5.2% on CIFAR-100. This corresponds to an <ref type="formula" target="#formula_0">11%</ref>     and a 26% relative improvement on CIFAR-10. In fact, auxiliary rotation prediction with no loss correction outperforms the GLC with 5% trusted data on CIFAR-100. This is surprising given that the GLC was developed specifically to combat label noise.</p><p>We also observe additive effects with the GLC. On CIFAR-10, the GLC with 5% trusted data obtains 14.6% average error, which is reduced to 10.5% with the addition of auxiliary rotation prediction. Note that doubling the amount of trusted data to 10% yields 11.6% average error. Thus, using self-supervision can enable obtaining better performance than doubling the amount of trusted data in a semi-supervised setting. On CIFAR-100, we observe similar complementary gains from auxiliary rotation prediction. Qualitatively, we can see in <ref type="figure" target="#fig_4">Figure 4</ref> that performance degradation as the corruption strength increases is softer with auxiliary rotation prediction.</p><p>On CIFAR-100, error at 0% corruption strength is 2.3% higher with auxiliary rotation predictions. This is because we selected the number of fine-tuning epochs on CIFAR-10 at 0% corruption strength, for which the degradation is only 1.3%. Fine-tuning for longer can eliminate this gap, but also leads to overfitting label noise <ref type="bibr" target="#b42">[Zhang and Sabuncu, 2018]</ref>. Controlling this trade-off of robustness to performance on clean data is application-specific. However, past a corruption strength of 20%, auxiliary rotation predictions improve performance for all tested corruption strengths and methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Out-of-Distribution Detection</head><p>Self-supervised learning with rotation prediction enables the detection of harder out-of-distribution examples. In the following two sections, we show that self-supervised learning improves out-ofdistribution detection when the in-distribution consists in multiple classes or just a single class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Multi-Class Out-of-Distribution Detection.</head><p>Setup. In the following experiment, we train a CIFAR-10 classifier and use it as an out-ofdistribution detector. When given an example x, we write the classifier's posterior distribution over the ten classes with p(y | x). <ref type="bibr" target="#b11">Hendrycks and Gimpel [2017]</ref> show that p(y | x) can enable the detection of out-of-distribution examples. They show that the maximum softmax probability max c p(y = c | x) tends to be higher for in-distribution examples than for out-of-distribution examples across a range of tasks, enabling the detection of OOD examples.</p><p>We evaluate each OOD detector using the area under the receiver operating characteristic curve (AUROC) <ref type="bibr" target="#b4">[Davis and Goadrich, 2006]</ref>. Given an input image, an OOD detector produces an anomaly score. The AUROC is equal to the probability an out-of-distribution example has a higher anomaly score than an in-distribution example. Thus an OOD detector with a 50% AUROC is at random-chance levels, and one with a 100% AUROC is without a performance flaw.</p><p>Method. We train a classifier with an auxiliary self-supervised rotation loss.  <ref type="formula">(r)</ref>, p rot_head (r | R r (x))). We use the KL divergence of the softmax prediction to the uniform distribution U since it combines well with the rotation score, and because <ref type="bibr" target="#b14">Hendrycks et al. [2019b]</ref> show that KL[U p(y | x)] performs similarly to the maximum softmax probability baseline max c p(y = c | x).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method AUROC</head><p>Baseline 91.4% Rotations (Ours) 96.2% <ref type="figure">Figure 5</ref>: OOD detection performance of the maximum softmax probability baseline and our method using self-supervision. Full results are in Appendix A.</p><p>The training loss is standard cross-entropy loss with auxiliary rotation prediction. The detection score is the KL divergence detector from prior work with a rotation score added to it. The rotation score consists of the cross entropy of the rotation softmax distribution to the categorical distribution over rotations with probability 1 at the current rotation and 0 everywhere else. This is equivalent to the negative log probability assigned to the true rotation. Summing the cross entropies over the rotations gives the total rotation score.</p><p>Results and Analysis. We evaluate this proposed method against the maximum softmax probability baseline <ref type="bibr" target="#b11">[Hendrycks and Gimpel, 2017</ref>] on a wide variety of anomalies with CIFAR-10 as the in-distribution data. For the anomalies, we select Gaussian, Rademacher, Blobs, Textures, SVHN, Places365, LSUN, and CIFAR-100 images. We observe performance gains across the board and report average AUROC values in <ref type="figure">Figure 5</ref>. On average, the rotation method increases the AUROC by 4.8%.</p><p>This method does not require additional data as in Outlier Exposure <ref type="bibr" target="#b14">[Hendrycks et al., 2019b]</ref>, although combining the two could yield further benefits. As is, the performance gains are of comparable magnitude to more complex methods proposed in the literature <ref type="bibr" target="#b37">[Xie et al., 2018]</ref>. This demonstrates that self-supervised auxiliary rotation prediction can augment OOD detectors based on fully supervised multi-class representations. More detailed descriptions of the OOD datasets and the full results on each anomaly type with additional metrics are in Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">One-Class Learning</head><p>Setup. In the following experiments, we take a dataset consisting in k classes and train a model on one class. This model is used as an out-of-distribution detector. For the source of OOD examples, we use the examples from the remaining unseen k − 1 classes. Consequently, for the datasets we consider, the OOD examples are near the in-distribution and make for a difficult OOD detection challenge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">CIFAR-10</head><p>Baselines. One-class SVMs <ref type="bibr" target="#b28">[Schölkopf et al., 1999]</ref> are an unsupervised out-of-distribution detection technique which models the training distribution by finding a small region containing most of the training set examples, and points outside this region are deemed OOD. In our experiment, OC-SVMs operate on the raw CIFAR-10 pixels. Deep SVDD <ref type="bibr" target="#b26">[Ruff et al., 2018]</ref> uses convolutional networks to extract features from the raw pixels all while modelling one class, like OC-SVMs.  RotNet <ref type="bibr" target="#b8">[Gidaris et al., 2018</ref>] is a successful self-supervised technique which learns its representations by predicting whether an input is rotated 0°, 90°, 180°, or 270°. After training RotNet, we use the softmax probabilities to determine whether an example is in-or out-of-distribution. To do this, we feed the network the original example (0°) and record RotNet's softmax probability assigned to the 0°c lass. We then rotate the example 90°and record the probability assigned to the 90°class. We do the same for 180°and 270°, and add up these probabilities. The sum of the probabilities of in-distribution examples will tend to be higher than the sum for OOD examples, so the negative of this sum is the anomaly score. Next, <ref type="bibr" target="#b9">Golan and El-Yaniv [2018]</ref> (Geometric) predicts transformations such as rotations and whether an input is horizontally flipped; we are the first to connect this method to self-supervised learning and we improve their method. Deep InfoMax <ref type="bibr" target="#b15">[Hjelm et al., 2019]</ref> networks learn representations which have high mutual information with the input; for detection we use the scores of the discriminator network. A recent self-supervised technique is Invariant Information Clustering (IIC) <ref type="bibr" target="#b17">[Ji et al., 2018]</ref> which teaches networks to cluster images without labels but instead by learning representations which are invariant to geometric perturbations such as rotations, scaling, and skewing. For our supervised baseline, we use a deep network which performs logistic regression, and for the negative class we use Outlier Exposure. In Outlier Exposure, the network is exposed to examples from a real, diverse dataset of consisting in out-of-distribution examples. Done correctly, this process teaches the network to generalize to unseen anomalies. For the outlier dataset, we use 80 Million Tiny Images <ref type="bibr" target="#b31">[Torralba et al., 2008]</ref> with CIFAR-10 and CIFAR-100 examples removed. Crucial to the success of the supervised baseline is our loss function choice. To ensure the supervised baseline learns from hard examples, we use the Focal Loss <ref type="bibr" target="#b21">[Lin et al., 2017]</ref>.</p><p>Method. For our self-supervised one-class OOD detector, we use a deep network to predict geometric transformations and thereby surpass previous work and the fully supervised network. Examples are rotated 0°, 90°, 180°, or 270°then translated 0 or ±8 pixels vertically and horizontally. These transformations are composed together, and the network has three softmax heads: one for predicting rotation (R), one for predicting vertical translations (T v ), and one for predicting horizontal translations (T h ). Concretely, the anomaly score for an example x is</p><formula xml:id="formula_4">r∈R s∈Tv t∈T h p rot_head (r | G(x)) + p vert_transl_head (s | G(x)) + p horiz_transl_head (t | G(x)),</formula><p>where G is the composition of rotations, vertical translations, and horizontal translations specified by r, p, and q respectively. The set R is the set of rotations, and p rot_head (r | ·) is the softmax probability assigned to rotation r by the rotation predictor. Likewise with translations for T v , T h , s, t, p vert_transl_head , and p horiz_transl_head . The backbone architecture is a 16-4 WideResNet <ref type="bibr" target="#b39">[Zagoruyko and Komodakis, 2016]</ref> trained with a dropout rate of 0.3 <ref type="bibr" target="#b29">[Srivastava et al., 2014]</ref>. We choose a 16-4 network because there are fewer training samples. Networks are trained with a cosine learning rate schedule <ref type="bibr" target="#b22">[Loshchilov and Hutter, 2016]</ref>, an initial learning rate of 0.1, Nesterov momentum, and a batch size of 128. Data is augmented with standard cropping and mirroring. Our RotNet and supervised baseline use the same backbone architecture and training hyperparameters. When training our method with Outlier Exposure, we encourage the network to have uniform softmax responses on out-of-distribution data. For Outlier Exposure to work successfully, we applied the aforementioned geometric transformations to the outlier images so that the in-distribution data and the outliers are as similar as possible.</p><p>Results are in <ref type="table" target="#tab_6">Table 3</ref>. Notice many self-supervised techniques perform better than methods specifically designed for one-class learning. Also notice that our self-supervised technique outperforms Outlier Exposure, the state-of-the-art fully supervised method, which also requires access to out-ofdistribution samples to train. In consequence, a model trained with self-supervision can surpass a fully supervised model. Combining our self-supervised technique with supervision through Outlier Exposure nearly solves this CIFAR-10 task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">ImageNet</head><p>Dataset. We consequently turn to a harder dataset to test self-supervised techniques. For this experiment, we select 30 classes from ImageNet <ref type="bibr" target="#b5">Deng et al. [2009]</ref>. See Appendix B for the classes.</p><p>Method. Like before, we demonstrate that a self-supervised model can surpass a model that is fully supervised. The fully supervised model is trained with Outlier Exposure using ImageNet-22K outliers (with ImageNet-1K images removed). The architectural backbone for these experiments is a ResNet-18. Images are resized such that the smallest side has 256 pixels, while the aspect ratio is maintained. Images are randomly cropped to the size 224 × 224 × 3. Since images are larger than CIFAR-10, new additions to the self-supervised method are possible. Consequently, we can teach the network to predict whether than image has been resized. In addition, since we should like the network to more easily learn shape and compare regions across the whole image, we discovered there is utility in self-attention <ref type="bibr" target="#b36">[Woo et al., 2018]</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we applied self-supervised learning to improve the robustness and uncertainty of deep learning models beyond what was previously possible with purely supervised approaches. We found large improvements in robustness to adversarial examples, label corruption, and common input corruptions. For all types of robustness that we studied, we observed consistent gains by supplementing current supervised methods with an auxiliary rotation loss. We also found that selfsupervised methods can drastically improve out-of-distribution detection on difficult, near-distribution anomalies, and that in CIFAR and ImageNet experiments, self-supervised methods outperform fully supervised methods. Self-supervision had the largest improvement over supervised techniques in our ImageNet experiments, where the larger input size meant that we were able to apply a more complex self-supervised objective. Our results suggest that future work in building more robust models and better data representations could benefit greatly from self-supervised approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Acknowledgments</head><p>This material is in part based upon work supported by the National Science Foundation Frontier Grant. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.  <ref type="table">Table 5</ref>: Out-of-distribution example detection results for the maximum softmax probability (MSP) baseline and our rotation method. All results are percentages and the average result of 5 runs.</p><p>The full multi-class out-of-distribution detection results are in <ref type="table">Table 5</ref>. Auxiliary rotation prediction results in large improvements across the board for numerous anomaly types. In all cases, rotation prediction improves performance. This demonstrates that auxiliary rotation prediction is not only useful for one-class detection but can also augment detectors based on multi-class representations. For descriptions of metrics, we refer the reader to <ref type="bibr" target="#b14">Hendrycks et al. [2019b]</ref>.</p><p>OOD Datasets. For multi-class OOD detection, we evaluate our detectors on a wide variety of OOD data with CIFAR-10 as the in-distribution. Gaussian OOD data has each pixel sampled from an isotropic Gaussian distribution. Rademacher images have each pixel sampled IID from an Rademacher distribution, which takes values 1 and −1 with equal probability. Blobs images are algorithmically generated amorphous shapes with distinct edges. Textures is a dataset of describable texture images. SVHN is a dataset of house numbers extracted from Google Street View. Places365 contains images for scene recognition instead of object recognition. LSUN is another scene understanding dataset that fewer classes than Places365 <ref type="bibr" target="#b38">[Yu et al., 2015]</ref>. CIFAR-100 is the 100-class counterpart to CIFAR-10. Importantly, the CIFAR-10 and CIFAR-100 classes do not overlap, so CIFAR-100 data is OOD with CIFAR-10 as the in-distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B ImageNet OOD Dataset</head><p>The classes are 'acorn', 'airliner', 'ambulance', 'American alligator <ref type="bibr">', 'banjo', 'barn', 'bikini', 'digital clock', 'dragonfly', 'dumbbell', 'forklift', 'goblet', 'grand piano', 'hotdog', 'hourglass', 'manhole cover', 'mosque', 'nail', 'parking meter', 'pillow', 'revolver', 'rotary dial telephone', 'schooner', 'snowmobile', 'soccer ball', 'stingray', 'strawberry', 'tank', 'toaster', and 'volcano'</ref>. These classes were selected so that there is no obvious overlap, unlike classes such as 'bee' and 'honeycomb.' There are 1,300 training images per class, and 100 test images per class. To create a dataset with 100 test images per class, we took ImageNet's 50 validation images, and we collected an additional 50 images for each class for an expanded test set. The data is available for download at https://github.com/hendrycks/ss-ood.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Additional Ablations</head><p>Not attacking the rotation branch. To gauge the effect of attacking the rotation branch during training in Section 3.1, we retrain the auxiliary rotation method with the adversary only attacking the classification branch. We find this performs similarly to attacking both the classification and rotation branches, which indicates that the rotation loss itself is the crucial component.</p><p>Comparison with rotation augmentation. Our results demonstrate myriad benefits of rotation prediction, so a natural baseline for comparison is rotation data augmentation. To this end, we retrain the baseline network from Section 3.2 and augment the dataset with rotations of multiples of 90 degrees. We find that this decreases average accuracy across corruptions from 72.3% to 63.7%. By contrast, training with auxiliary rotation prediction improves average accuracy to 76.9%.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>The effect of attack strength on a ε = 8/255 adversarially trained model. The attack strengths are ε ∈ {4/255, 5/255, . . . , 10/255}. Since the accuracy gap widens as ε increases, selfsupervision's benefits are masked when observing the clean accuracy alone.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>A comparison of the accuracy of usual training compared to training with auxiliary rotation self-supervision on the nineteen CIFAR-10-C corruptions. Each bar represents an average over all five corruption strengths for a given corruption type.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>relative improvement over the baseline of normal training on CIFAR-100</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Error curves for label corruption comparing normal training to training with auxiliary rotation self-supervision. Auxiliary rotations improve performance when training without loss corrections and are complementary with the GLC loss correction method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>More steps do not change results, so the attacks converge. Self-supervision through rotations provides large gains over standard adversarial training.</figDesc><table><row><cell></cell><cell cols="3">Clean 20-step PGD 100-step PGD</cell></row><row><cell>Normal Training</cell><cell>94.8</cell><cell>0.0</cell><cell>0.0</cell></row><row><cell>Adversarial Training</cell><cell>84.2</cell><cell>44.8</cell><cell>44.8</cell></row><row><cell cols="2">+ Auxiliary Rotations (Ours) 83.5</cell><cell>50.4</cell><cell>50.4</cell></row><row><cell cols="4">Table 1: Results for our defense. All results use ε = 8.0/255. For 20-step adversaries α = 2.0/255,</cell></row><row><cell>and for 100-step adversaries α = 0.3/255.</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>can</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>Label corruption results comparing normal training to training with auxiliary rotation self- supervision. Each value is the average error over 11 corruption strengths. All values are percentages. The reliable training signal from self-supervision improves resistance to label noise.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>The loss duringtraining is L CE (y, p(y | x)) + r∈{0 • ,90 • ,180 • ,270 • } L CE (one_hot(r), p rot_head (r | R</figDesc><table><row><cell></cell><cell>r (x))), and</cell></row><row><cell cols="2">we only train on in-distribution CIFAR-10 training examples. After training is complete, we score</cell></row><row><cell cols="2">in-distribution CIFAR-10 test set examples and OOD examples with the formula KL[U p(y |</cell></row><row><cell>x)] + 1 4</cell><cell>r∈{0</cell></row></table><note>• ,90 • ,180 • ,270 • } L CE (one_hot</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>OC-SVM DeepSVDD Geometric RotNet DIM IIC Supervised (OE) Ours Ours + OE</figDesc><table><row><cell>Airplane</cell><cell>65.6</cell><cell>61.7</cell><cell>76.2</cell><cell>71.9 72.6 68.4</cell><cell>87.6</cell><cell>77.5</cell><cell>90.4</cell></row><row><cell>Automobile</cell><cell>40.9</cell><cell>65.9</cell><cell>84.8</cell><cell>94.5 52.3 89.4</cell><cell>93.9</cell><cell>96.9</cell><cell>99.3</cell></row><row><cell>Bird</cell><cell>65.3</cell><cell>50.8</cell><cell>77.1</cell><cell>78.4 60.5 49.8</cell><cell>78.6</cell><cell>87.3</cell><cell>93.7</cell></row><row><cell>Cat</cell><cell>50.1</cell><cell>59.1</cell><cell>73.2</cell><cell>70.0 53.9 65.3</cell><cell>79.9</cell><cell>80.9</cell><cell>88.1</cell></row><row><cell>Deer</cell><cell>75.2</cell><cell>60.9</cell><cell>82.8</cell><cell>77.2 66.7 60.5</cell><cell>81.7</cell><cell>92.7</cell><cell>97.4</cell></row><row><cell>Dog</cell><cell>51.2</cell><cell>65.7</cell><cell>84.8</cell><cell>86.6 51.0 59.1</cell><cell>85.6</cell><cell>90.2</cell><cell>94.3</cell></row><row><cell>Frog</cell><cell>71.8</cell><cell>67.7</cell><cell>82.0</cell><cell>81.6 62.7 49.3</cell><cell>93.3</cell><cell>90.9</cell><cell>97.1</cell></row><row><cell>Horse</cell><cell>51.2</cell><cell>67.3</cell><cell>88.7</cell><cell>93.7 59.2 74.8</cell><cell>87.9</cell><cell>96.5</cell><cell>98.8</cell></row><row><cell>Ship</cell><cell>67.9</cell><cell>75.9</cell><cell>89.5</cell><cell>90.7 52.8 81.8</cell><cell>92.6</cell><cell>95.2</cell><cell>98.7</cell></row><row><cell>Truck</cell><cell>48.5</cell><cell>73.1</cell><cell>83.4</cell><cell>88.8 47.6 75.7</cell><cell>92.1</cell><cell>93.3</cell><cell>98.5</cell></row><row><cell>Mean</cell><cell>58.8</cell><cell>64.8</cell><cell>82.3</cell><cell>83.3 57.9 67.4</cell><cell>87.3</cell><cell>90.1</cell><cell>95.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>AUROC values of different OOD detectors trained on one of ten CIFAR-10 classes. Test time out-of-distribution examples are from the remaining nine CIFAR-10 classes. In-distribution examples are examples belonging to the row's class. Our self-supervised technique surpasses a fully supervised model. All values are percentages.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>for this task. Other architectural changes, such as using a Wide RevNet<ref type="bibr" target="#b1">[Behrmann et al., 2018]</ref> instead of a Wide ResNet, can increase the AUROC from 65.3% to 77.5%. AUROCs are shown inTable 4. Self-supervised methods outperform the fully supervised baseline by a large margin, yet there is still wide room for improvement on large-scale OOD detection.</figDesc><table><row><cell>Method</cell><cell>AUROC</cell></row><row><cell>Supervised (OE)</cell><cell>56.1</cell></row><row><cell>RotNet</cell><cell>65.3</cell></row><row><cell>RotNet + Translation</cell><cell>77.9</cell></row><row><cell>RotNet + Self-Attention</cell><cell>81.6</cell></row><row><cell>RotNet + Translation + Self-Attention</cell><cell>84.8</cell></row><row><cell>RotNet + Translation + Self-Attention + Resize (Ours)</cell><cell>85.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4 :</head><label>4</label><figDesc>AUROC values of supervised and self-supervised OOD detectors. AUROC values are an average of 30 AUROCs corresponding to the 30 different models trained on exactly one of the 30 classes. Each model's in-distribution examples are from one of 30 classes, and the test outof-distribution samples are from the remaining 29 classes. The self-supervised methods greatly outperform the supervised method. All values are percentages.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>A Self-Supervised Learning for Multi-Class OOD Detection</figDesc><table><row><cell></cell><cell></cell><cell cols="2">FPR95 ↓</cell><cell cols="2">AUROC ↑</cell><cell cols="2">AUPR ↑</cell></row><row><cell>D in</cell><cell>D test out</cell><cell>MSP</cell><cell>Rotation</cell><cell>MSP</cell><cell>Rotation</cell><cell>MSP</cell><cell>Rotation</cell></row><row><cell></cell><cell>Gaussian</cell><cell>8.1</cell><cell>1.2</cell><cell>96.3</cell><cell>99.0</cell><cell>70.8</cell><cell>85.6</cell></row><row><cell></cell><cell>Rademacher</cell><cell>5.9</cell><cell>1.1</cell><cell>97.5</cell><cell>99.1</cell><cell>79.4</cell><cell>86.3</cell></row><row><cell>CIFAR-10</cell><cell>Blobs Textures SVHN Places365</cell><cell>13.3 45.4 25.7 46.0</cell><cell>2.3 8.9 2.7 38.4</cell><cell>94.6 87.9 91.9 87.7</cell><cell>98.9 97.4 98.9 92.2</cell><cell>68.3 56.2 64.0 57.2</cell><cell>86.5 86.7 89.8 71.3</cell></row><row><cell></cell><cell>LSUN</cell><cell>39.5</cell><cell>28.7</cell><cell>88.5</cell><cell>93.2</cell><cell>57.2</cell><cell>71.0</cell></row><row><cell></cell><cell>CIFAR-100</cell><cell>45.9</cell><cell>44.9</cell><cell>87.2</cell><cell>90.9</cell><cell>54.1</cell><cell>67.7</cell></row><row><cell></cell><cell>Mean</cell><cell>28.7</cell><cell>16.0</cell><cell>91.4</cell><cell>96.2</cell><cell>63.4</cell><cell>80.6</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anish</forename><surname>Athalye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
		<meeting>the 35th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2018-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Behrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Grathwohl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricky</forename><forename type="middle">T Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörn-Henrik</forename><surname>Jacobsen</surname></persName>
		</author>
		<idno>abs/1811.00995</idno>
	</analytic>
	<monogr>
		<title level="j">Invertible residual networks. ArXiv</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Adversarial examples are not easily detected: Bypassing ten detection methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Wagner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Learning from untrusted data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moses</forename><surname>Charikar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Steinhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Valiant</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The relationship between precision-recall and ROC curves</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Goadrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li Jia Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note>ImageNet: A large-scale hierarchical image database. CVPR</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Unsupervised visual representation learning by context prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1422" to="1430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Discriminative unsupervised feature learning with exemplar convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jost</forename><forename type="middle">Tobias</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="1734" to="1747" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Unsupervised representation learning by predicting image rotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Izhak</forename><surname>Golan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ran</forename><surname>El-Yaniv</surname></persName>
		</author>
		<title level="m">Deep anomaly detection using geometric transformations. CoRR, abs/1805.10917</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Benchmarking neural network robustness to common corruptions and perturbations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Dietterich</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">A baseline for detecting misclassified and out-of-distribution examples in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Using trusted data to train deep networks on labels corrupted by severe noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mantas</forename><surname>Mazeika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duncan</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Using pre-training can improve model robustness and uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kimin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mantas</forename><surname>Mazeika</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning</title>
		<meeting>the International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep anomaly detection with outlier exposure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mantas</forename><surname>Mazeika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Dietterich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning deep representations by mutual information estimation and maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>R Devon Hjelm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Fedorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karan</forename><surname>Lavoie-Marchildon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Grewal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Data-efficient image recognition with contrastive predictive coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Olivier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Hénaff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Razavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Ali Eslami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Den Oord</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Invariant information distillation for unsupervised image segmentation and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">João</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<idno>abs/1807.06653</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Adversarial machine learning at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning representations for automatic colorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustav</forename><surname>Larsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Shakhnarovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="577" to="593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Training confidence-calibrated classifiers for detecting out-of-distribution samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kimin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kibok</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinwoo</forename><surname>Shin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Kaiming He, and Piotr Dollár. Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">SGDR: stochastic gradient descent with warm restarts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Towards deep learning models resistant to adversarial attacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksander</forename><surname>Madry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandar</forename><surname>Makelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludwig</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><surname>Vladu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A study of the effect of different types of noise on the precision of supervised learning techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>David F Nettleton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Orriols-Puig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fornells</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif Intell Rev</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Making deep neural networks robust to label noise: a loss correction approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgio</forename><surname>Patrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Rozza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Nock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lizhen</forename><surname>Qu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deep one-class classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Ruff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">A</forename><surname>Vandermeulen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nico</forename><surname>Görnitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Deecke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shoaib</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Siddiqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emmanuel</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kloft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
		<meeting>the 35th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="4393" to="4402" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Adversarially robust generalization requires more data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludwig</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shibani</forename><surname>Santurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunal</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksander</forename><surname>Madry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Support vector method for novelty detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Platt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International Conference on Neural Information Processing Systems, NIPS&apos;99</title>
		<meeting>the 12th International Conference on Neural Information Processing Systems, NIPS&apos;99<address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="582" to="588" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sainbayar</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manohar</forename><surname>Paluri</surname></persName>
		</author>
		<title level="m">Lubomir Bourdev, and Rob Fergus. Training convolutional networks with noisy labels. ICLR Workshop</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">80 million tiny images: A large data set for nonparametric object and scene recognition. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William T</forename><surname>Freeman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Adversarial risk and the dangers of evaluating against weak attacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Uesato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O&amp;apos;</forename><surname>Brendan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Donoghue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushmeet</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kohli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.05666</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Representation learning with contrastive predictive coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yazhe</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Anticipating visual representations from unlabeled video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Vondrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamed</forename><surname>Pirsiavash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
		<idno type="DOI">10.1109/cvpr.2016.18</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Tracking emerges by colorizing videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Vondrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alireza</forename><surname>Fathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2018-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Joon-Young Lee, and In So Kweon. Cbam: Convolutional block attention module</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanghyun</forename><surname>Woo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongchan</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2018-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cihang</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<title level="m">Laurens van der Maaten, Alan Yuille, and Kaiming He. Feature denoising for improving adversarial robustness</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">LSUN: construction of a large-scale image dataset using deep learning with humans in the loop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinda</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuran</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Seff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxiong</forename><surname>Xiao</surname></persName>
		</author>
		<idno>abs/1506.03365</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
		<title level="m">Wide residual networks. BMVC</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">S 4 l: Self-supervised semisupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avital</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaodong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiantao</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><forename type="middle">El</forename><surname>Ghaoui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.08573</idno>
		<title level="m">Theoretically principled trade-off between robustness and accuracy</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Generalized cross entropy loss for training deep neural networks with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mert</forename><surname>Sabuncu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8778" to="8788" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
