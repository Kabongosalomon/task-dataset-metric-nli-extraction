<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Joint Maximum Purity Forest with Application to Image Super-Resolution</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hailiang</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electronic and Information Engineering</orgName>
								<orgName type="institution">The Hong Kong Polytechnic University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kin-Man</forename><surname>Lam</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electronic and Information Engineering</orgName>
								<orgName type="institution">The Hong Kong Polytechnic University</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Li</surname></persName>
							<email>dong.li@gdut.edu.cn</email>
							<affiliation key="aff1">
								<orgName type="department">School of Automation</orgName>
								<orgName type="institution">Guangdong University of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Joint Maximum Purity Forest with Application to Image Super-Resolution</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T11:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Random forest</term>
					<term>regression and classification</term>
					<term>image super-resolution</term>
					<term>ridge regression</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we propose a novel random-forest scheme, namely Joint Maximum Purity Forest (JMPF), for classification, clustering, and regression tasks. In the JMPF scheme, the original feature space is transformed into a compactly pre-clustered feature space, via a trained rotation matrix.</p><p>The rotation matrix is obtained through an iterative quantization process, where the input data belonging to different classes are clustered to the respective vertices of the new feature space with maximum purity.</p><p>In the new feature space, orthogonal hyperplanes, which are employed at the split-nodes of decision trees in random forests, can tackle the clustering problems effectively. We evaluated our proposed method on public benchmark datasets for regression and classification tasks, and experiments showed that JMPF remarkably outperforms other state-of-the-art random-forest-based approaches. Furthermore, we applied JMPF to image super-resolution, because the transformed, compact features are more discriminative to the clustering-regression scheme. Experiment results on several public benchmark datasets also showed that the JMPF-based image super-resolution scheme is consistently superior to recent state-of-the-art image super-resolution algorithms.</p><p>Keywords-Random forest, regression and classification, image super-resolution, ridge regression.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Recently, random forest <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b13">14]</ref> has been employed as an efficient classification or regression tool on a large variety of computer-vision applications, such as object recognition <ref type="bibr" target="#b26">[27]</ref>, face alignment <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b45">46</ref>], data clustering <ref type="bibr" target="#b16">[17]</ref>, image super-resolution <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b18">19]</ref>, and so on. This method is attractive on computervision problems, not only for its simple implementation, but also for its many merits: (1) it can work efficiently on both the training and inference stages, (2) it is feasible for it to be sped up with parallel processing technology, (3) it has an inherent property to handle high-dimensional input features, and <ref type="formula">(4)</ref> it works with divide-and-conquer strategy, which has stable performance on classification and regression tasks as an ensemble machine-learning tool.</p><p>By studying the mechanism of a random forest, we can see that the random-forest approach has some critical properties, as do other powerful classifiers, such as SVM (support vector machine) <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b47">48]</ref> and AdaBoost (short for "Adaptive Boosting") <ref type="bibr" target="#b12">[13]</ref>. Both SVM and AdaBoost work as to approximate Bayes decision rule -known to be the optimal classifiers -via minimizing a margin-based global loss function.</p><p>Each threshold in a decision tree of a random forest works as a hyperplane, and each single decision tree, similar to AdaBoost, attempts to minimize its global loss greedily and recursively on working through from the root-node down to leaf-nodes in the binary tree.</p><p>At each split-node in a decision tree, a hyperplane is learned to separate data into two groups.</p><p>Although each decision tree attempts to achieve maximum purity for the two data groups clustered at each split-node independently during training a random forest, there is no guarantee that the original feature space can meet the expectation of global maximum purity for all the clustered groups. As the hyperplanes in a random forest have the orthogonal constraint, as shown in <ref type="figure">Fig. 1(b)</ref>, which hinders us</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>from achieving the optimal hyperplanes as SVM does (i.e., there is no orthogonal constraint in SVM) in some original feature space, as shown in <ref type="figure" target="#fig_0">Fig. 1(a)</ref>. In this paper, we aim to solve this orthogonalconstraint limitation. With the fixed orthogonal hyperplanes, we propose to rotate the feature space, this is equivalent to rotating the hyperplanes, in such a way that global maximum purity on the clustered data can be achieved, as illustrated in <ref type="figure" target="#fig_1">Fig. 2</ref>. This strategy can achieve a joint maximum purity for all the split-nodes when training a random forest.</p><p>Image super-resolution can be performed based on clustering/classification, according to the recent emerging clustering-regression stream <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b7">8]</ref>, and the JMPF scheme can achieve remarkable performance on both the classification and regression tasks. Therefore, JMPF is applied to single-image super-resolution in this paper. In our algorithm, principal component analysis (PCA) is applied to the features for dimensionality reduction. The projected feature space is then rotated to a compact, preclustered feature space via a learned rotation matrix. Finally, for all the split-nodes trained for a random forest, their thresholds are directly set to the inherent zero-center orthogonal hyperplanes in the rotated feature space to meet the maximum-purity criterion. Experiment results show that JMPF can achieve more accurate clustering/classification performance on random forests, and applying JMPF to image super-resolution can achieve superior quality, compared to state-of-the-art methods.</p><p>Having introduced the main idea of our proposed algorithm, the remainder of this paper is organized as follows. In Section II, we will describe our proposed scheme, the joint maximum purity forest scheme, and present in detail how to compute the rotation matrix via clustering data into the feature-space vertices.</p><p>Section III will evaluate our proposed method and compare its performance with recent state-of-the-art random-forest-based approaches on regression and classification tasks. In Section IV, we will validate the performance of JMPF scheme on single-image super-resolution. Conclusions are given in Section V.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. JOINT MAXIMUM PURITY FOREST SCHEME</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II.1 Random Forest and Our Insights</head><p>A random forest is an ensemble of binary decision trees ( ): → ℝ , where (= 1, 2, … , ) is the index of the trees, ∈ ℝ is the m-dimension feature space, and ℝ = [0, 1] represents the space of class probability distributions over the label space = {1, . . . , }. As shown in <ref type="figure" target="#fig_0">Fig. 1(b)</ref>, the vertical dotted line forms a hyperplane, =0, chosen in the first split-node for separating training samples, and the horizontal dotted line is the hyperplane, =0, for the second split-node to cluster all the feature data assigned to this node. This results in separating the three data samples (Red, Green and Blue) into three leaf-nodes. It can be seen from <ref type="figure" target="#fig_0">Fig. 1(b)</ref> that, for each split-node, the optimal hyperplane with more generalization capability is the one which can achieve maximum purity in clustering samples into two groups. For example, the vertical dotted line is the first optimal hyperplane because it clusters all the red training samples into the right node, while all the blue and green samples are clustered into the left node.</p><p>Furthermore, the left margin and the right margin are equal. Although there is no guarantee that optimal hyperplanes can be determined for all the split-nodes in a random forest, approximated optimal hyperplanes can be obtained through a random bagging strategy.</p><p>The training of a whole random forest is to train all of its decision trees, by choosing the candidate features and thresholds for each of the split-nodes, where the feature dimensions and thresholds are determined using a random bagging strategy. In the prediction stage, each decision tree returns a class probability ( | ) for a given query sample ∈ ℝ , and the final class label y * is then obtained via averaging, as follows: * = arg max ∑ ( | ) .</p><p>The splitting function for a split-node is denoted as ( ; Θ) , where is a sample and Θ is typically parameterized by two values: (i) a feature dimension Θ Î{1, . . . , }, and (ii) a threshold Θ Îℝ.</p><p>The splitting function is defined as follows:</p><formula xml:id="formula_1">( ; Θ) = 0, if (Θ ) &lt; Θ , 1, otherwise,<label>(2)</label></formula><p>where the outcome defines to which child node the sample is routed, and 0 and 1 are the two labels for the left and right child nodes, respectively. Each node chooses the best splitting function Θ * out of a randomly sampled set {Θ } by optimizing the following function:</p><formula xml:id="formula_2">= | | | | | | ( ) + | | | | | | ( ),<label>(3)</label></formula><p>where and are the sets of samples that are routed to the left and the right child nodes, and | | represents the number of samples in the set . During the training of a random forest, the decision trees are provided with a random subset of the training data (i.e. bagging), and are trained independently of each other. Therefore, the decision trees are working as independent experts. Taking random-forest-based classification as an example, training a single decision tree involves recursively splitting each node, such that the training data in each newly created child node is clustered according to their corresponding class labels, so the purity at each node is increasing along a tree. Each tree is grown until a stopping criterion is reached (e.g. the number of samples in a node is less than a threshold or the tree depth reaches a maximum value) and the class probability distributions are estimated in the leaf-nodes. After fulfilling one of these criteria, a density model ( ) in the leaf-node is estimated by all samples falling into this leaf-node for predicting the target value in the testing stage. A simple way to estimate the probability distribution ( ) is averaging all the samples in the leaf-node, while there are also variant methods, such as fitting a Gaussian distribution or kernel density estimation, ridge regression <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b45">46]</ref>, and so on.</p><p>( ) is the local score for a set of samples ( is either or ), which normally is calculated using entropy as in Eqn. (4), but it can be replaced by variance <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b45">46]</ref> or the Gini index <ref type="bibr" target="#b13">[14]</ref>.</p><formula xml:id="formula_3">( ) = − ( | ) * log ( | ) ,<label>(4)</label></formula><p>where K is the number of classes, and ( | ) is the probability for class , given the set . For the regression problem, the differential entropy:</p><formula xml:id="formula_4">( ) = ∫ ( | ) * log ( ( | ) )<label>(5)</label></formula><p>over continuous outputs can be employed, where ( | ) denotes the conditional probability of a target variable given the input sample. Assuming (. , . ) to be a Gaussian distribution and having only a finite set of samples, the differential entropy can be written in closed form as</p><formula xml:id="formula_5">( ) = (1 − log(2π)) + log(det(Σ )),<label>(6)</label></formula><p>where det (Σ ) is the determinant of the estimated covariance matrix of the target variables in . For training each decision tree in a random forest, the goal on each split-node is to maximize the information gain (IG) by reducing the entropy after splitting. IG is defined as follows:</p><formula xml:id="formula_6">IG = entropy(parent) -[average entropy(children)].<label>(7)</label></formula><p>Since each decision tree is a binary tree and each step is to split a current node (a parent set ) into two children nodes ( and sets), IG can be described as follows:</p><formula xml:id="formula_7">arg max ℋ = arg max , (S) − | | | | | | ( ) − | | | | | | ( ),<label>(8)</label></formula><p>where ℋ is the optimal hyperplane of the split-node, and Eqn. <ref type="formula" target="#formula_7">(8)</ref> is the target function of each splitnode when training each decision tree of a random forest. As we can see from <ref type="figure" target="#fig_0">Fig. 1(b)</ref>, all the optimal hyperplanes from split-nodes are achieved independently and locally.</p><p>Since each optimal hyperplane is obtained from a subset of feature-dimension candidates with the randomly bagging strategy, there is no guarantee of obtaining a global optimum with respect to all the hyperplanes in all the split-nodes. An intuitive thinking, which was inspired by the data distribution in <ref type="figure" target="#fig_0">Fig. 1(b)</ref>, is to achieve a global optimum by jointly considering all the hyperplanes of all the split-nodes, in the form as follows:</p><formula xml:id="formula_8">max ℋ = arg max ℋ ∏ ,<label>(9)</label></formula><p>where is the total number of split-nodes that a training sample has routed through a decision tree. As there is no mathematical solution to the problem described in Eqn. <ref type="bibr" target="#b8">(9)</ref>, an alternative way (i.e., an approximate method) to numerically solving Eqn. (9) is to jointly maximize the purity of the clustered data groups at each of the split-nodes. This also means that all the data is clustered into the corners (feature-space vertices) of the feature space, as shown in <ref type="figure" target="#fig_1">Fig. 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II.2 The Joint Maximum Purity Forest Scheme</head><p>To calculate the threshold for each split-node in each decision tree when training a random forest, we are attempting to determine an orthogonal hyperplane for a three-category classification problem, as shown in <ref type="figure" target="#fig_0">Fig. 1</ref>. Since the hyperplanes for the split-nodes of a decision tree are required to be orthogonal to each other, seeking an optimal orthogonal hyperplane locally cannot guarantee obtaining maximum purity for the whole tree globally. As shown in <ref type="figure" target="#fig_1">Fig. 2</ref>, it is easy to determine the vertical hyperplane for maximum purity, but it is hard to obtain the horizontal hyperplane for maximum purity in the original feature space.</p><p>To achieve an optimal classification performance for the whole decision tree, all the split-nodes should be considered globally or simultaneously.</p><p>As shown in <ref type="figure" target="#fig_1">Fig. 2</ref>, a number of split-nodes, which have their hyperplanes orthogonal to each other, are required to separate the samples into different nodes. However, if we can transform the samples (zerocentered feature data) to locate them at the respective corners of the feature space, i.e. {−1,1} for mdimensional features, the feature data can be easily and accurately separated by the orthogonal (either vertical or horizontal) hyperplanes, which contain the space center {0} , as illustrated in <ref type="figure" target="#fig_0">Fig. 1(b)</ref>. The insight behind this is that the data is clustered into the feature-space vertices (the corners in a 2-D feature space means that the data points belong to {−1,1} as the coordinate range is set to [−1, 1]).</p><p>To tackle the original feature data , which is not ideally clustered in the vertices or corners of the feature space or close to them, as shown in <ref type="figure" target="#fig_0">Fig. 1(a)</ref>, an intuitive idea is to rotate the feature space (this is equivalent to rotating the hyperplanes). This transformation clusters the feature data compactly into feature-space vertices {−1,1} with a total of 2 vertices. Therefore, a possible solution to the problem described in Eqn. <ref type="bibr" target="#b9">(10)</ref> is to rotate the data features by a rotation matrix ℛ × , as shown in <ref type="figure" target="#fig_1">Fig.   2</ref>, through which the original feature space is transformed into a more compact clustered feature space, where all the feature data is clustered close to the feature-space vertices . This solution can be mathematically defined as follows:</p><formula xml:id="formula_9">min‖ − ℛ‖ , s.t. ∈ {−1,1} × , ℛ ℛ =<label>(10)</label></formula><p>where ∈ ℝ × contains n samples, each of which is a -dimensional feature vector arranged in a row, and is zero-centered, i.e. all the feature vectors are demeaned by subtracting the mean vector from each feature vector.</p><p>This idea of clustering data into the feature-space vertices can also be found in locality-sensitive hashing (LSH) <ref type="bibr" target="#b0">[1]</ref> and image representation <ref type="bibr" target="#b6">[7]</ref>. In <ref type="bibr" target="#b0">[1]</ref>, a simple and efficient alternating minimization scheme was proposed to find a rotation matrix for zero-centered feature data, which minimizes the quantization errors by mapping the feature data to the vertices of a zero-centered binary hypercube. The method is termed as iterative quantization (ITQ), which can work on multi-class spectral clustering and orthogonal Procrustes problem. Yu et al. <ref type="bibr" target="#b53">[54]</ref> proposed using a circulant matrix to speed up the computation, because the circulant structure enables the use of Fast Fourier Transformation (FFT). As the computation of the rotation matrix in the training and testing stage is ignorable, we choose a similar scheme to ITQ <ref type="bibr" target="#b0">[1]</ref> to determine the rotation matrix (we throw away the final quantization matrix described in Eqn. <ref type="bibr" target="#b9">(10)</ref>, which is used for hashing in <ref type="bibr" target="#b0">[1]</ref>), through which the original feature space can be transformed into a new compact clustered feature space: = ℛ, where the data is located at the respective vertices in the new feature space. After this transformation, a random forest with globally joint maximum purity of all the clustered data can be trained, through all the hyperplanes in the split-nodes of each decision tree. Based on this idea, our proposed scheme is called joint maximum purity forest (JMPF).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II.3 Learning the Rotation Matrix via Clustering Data into Feature-Space Vertices</head><p>Assuming that ∈ ℝ is one point in the -dimensional feature space (zero-centered data), the respective vertices in the zero-centered binary hypercube space can be denoted as</p><formula xml:id="formula_10">( ) ∈ {−1,1} ,</formula><p>and there is a total of 2 vertices in the -dimensional feature space. It is easy to see from <ref type="figure" target="#fig_1">Fig. 2</ref> that ( ) is the vertex in the feature space, such that it is the closest to in terms of Euclidean distance.</p><p>We denote a binary code matrix ∈ {−1,1} × , whose rows = ( ) ∈ . For a matrix or a vector, (. ) applies the sign operation to it element-wise.</p><p>Our objective is to minimize the error between the feature and the feature-space vertices , i.e., min‖ − ‖ . As we can see in <ref type="figure" target="#fig_1">Fig. 2</ref>, when the feature space is rotated, the feature points will be more concentrated around their nearest vertices, which means that the quantization error will become smaller.</p><p>Therefore, the minimization problem of min‖ − ‖ is equivalent to minimizing the error of the zerocentered data with respect to the Frobenius norm, as in the following formulation:</p><formula xml:id="formula_11">( , ℛ) = ‖ − ℛ‖ , s.t. ∈ {−1,1} × , ℛ ℛ = .<label>(11)</label></formula><p>Therefore, the task of this minimization problem is to determine an optimal rotation matrix ℛ to satisfy Eqn. <ref type="bibr" target="#b10">(11)</ref>. Since there are two variables in Eqn. <ref type="bibr" target="#b10">(11)</ref>, the expectation-maximization (E-M) algorithm is applied to cluster data into the feature-space vertices, such that a local minimum of the binary code matrix and the rotation matrix ℛ are computed simultaneously. The idea of rotating feature data to minimize the error between the transformed data and the featurespace vertices can also be found in <ref type="bibr" target="#b6">[7]</ref>, which showed that the rotation matrix ℛ can be initialized randomly, and then iterated to converge to the required rotation matrix. Two iteration steps will be performed: in every iteration, each feature vector in the feature space is firstly quantized to the nearest vertex of the binary hypercube, i.e. to a vertex in , and then the rotation matrix ℛ is updated to minimize the quantization error by fixing . These two alternating steps are described in detail below:</p><p>(1) Fix ℛ and update :</p><formula xml:id="formula_12">( , ℛ) = ‖ − ℛ‖ = ‖ ‖ + ‖ ‖ − 2 ( ℛ ) = × + ‖ ‖ − 2 ( ℛ )<label>(12)</label></formula><p>Because the zero-centered data matrix is fixed, minimizing Eqn. (12) is equivalent to maximizing the following term:</p><formula xml:id="formula_13">( ℛ ) = ∑ ∑<label>(13)</label></formula><p>where is an element of = ℛ. To maximize Eqn. (13) with respect to , = 1 whenever ≥ 0 and = −1 otherwise, i.e. = ( ℛ) ∈ {−1,1} .</p><p>(2) Fix and update ℛ:</p><p>The problem of fixing to obtain a rotation matrix based on the objective function Eqn. <ref type="formula" target="#formula_0">(11)</ref> is relative to the classic orthogonal Procrustes problem <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b54">55]</ref>, in which a rotation matrix is determined to align one point set with another.</p><p>In our algorithm, these two point sets are the zero-centered data set and the quantized matrix .</p><p>Therefore, a closed-form solution for ℛ is available, by applying SVD on the × matrix to obtain Ω (Ω is a diagonal matrix), then set ℛ = to update ℛ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II.4 Proof of the Orthogonal Procrustes Problem:</head><p>For completeness, we prove the orthogonal Procrustes problem, for which the solution can be found in <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b54">55]</ref>:</p><formula xml:id="formula_14">Problem definition: min ℛ ‖ − ℛ‖ subject to: ℛ ℛ = .<label>(14)</label></formula><p>Proof:</p><formula xml:id="formula_15">‖ − ℛ‖ (15) = ( − ℛ)( − ℛ ) = ( ) − 2 ( ℛ ) + (ℛ ℛ )</formula><p>Thus, min ℛ ‖ − ℛ ‖ equals to maximizing:</p><formula xml:id="formula_16">( ℛ ) ([ , Ω, ] = ( )) (16) = ( Ω ℛ ) = (Ω ℛ ) ( = ℛ ) = (Ω ) = ∑ Z , Ω , ≤ ∑ Ω ,</formula><p>The last inequality holds because Z is also an orthonormal matrix, and ∑ , = 1, , ≤ 1 . The objective function can be maximized if Z = , i.e.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ℛ = ∎</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. JOINT MAXIMUM PURITY FOREST FOR REGRESSION AND CLASSIFICATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III.1 The Workflow of Joint Maximum Purity Forest</head><p>Random forest is a machine-learning method using an ensemble of randomized decision trees for classification. Each tree in a random forest consists of split-nodes and leaf-nodes, which can be trained recursively. A random forest is constructed recursively, where each node attempts to find a splitting function or a hyperplane to separate its samples into two leaf-nodes, such that the information gain is optimized. A tree stops growing if the maximum depth is reached or if a node has achieved maximum purity, i.e. it contains only samples from one class. Then, each leaf-node collects the statistics of the samples falling in it. In the evaluation phase, the probability of a query sample x belonging to class k is given by averaging all the trees, or by other methods. Most random-forest-based models <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24]</ref> share a similar workflow, as shown in <ref type="figure" target="#fig_2">Fig. 3</ref>, in which the main task on training a tree in a random forest is to decide thresholds in the split-nodes and learn the regressors or classes in the leaf-nodes. Rigid regression or linear regression is often employed in the leaf-nodes for the prediction task, because rigid regression has a closed-form solution, while linear regression is an efficient optimization tool, and the LibLinear package <ref type="bibr" target="#b52">[53]</ref> can be used to fine-tune its configurations.</p><p>Compared to conventional random forests, our JMPF scheme has one more step, as shown in the left of <ref type="figure" target="#fig_2">Fig. 3</ref>, the rotation matrix. The JMPF scheme transforms the original feature space by rotating it into a more compact, pre-clustered feature space, using a trained rotation matrix learned through clustering feature vectors iteratively into the vertices of a new feature space. The whole workflow of our proposed algorithm, the JMPF scheme, is outlined in <ref type="figure" target="#fig_2">Fig. 3</ref>. The source code of our algorithm is available to download at: https://github.com/HarleyHK/JMPF. a</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III.2 The inherent zero-center hyperplanes as thresholds for split-nodes</head><p>In training a random forest, the two main operations for training (splitting) each split-node are to choose splitting feature(s), and to determine the threshold, using a random bagging strategy, which can avoid over-fitting in training classifiers. In the rotated compact pre-clustered feature space, the inherent zerocenter hyperplanes are inherently the optimal thresholds (to meet the max-purity criterion on two clustered data groups) after training the rotation matrix. Therefore, these inherent zero-center hyperplanes can directly be set as the thresholds to achieve optimal classification performance on training a random forest. Compared to conventional random forests, our proposed JMPF only needs to choose which feature(s) to split data at split-nodes. This can speed up the training process for a random forest.</p><p>Experimental results in the next subsection will validate this performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III.3: Experimental results on JMPF regression and classification</head><p>To evaluate the performances of the proposed JMPF, we test it with 15 standard machine-learning tasks, 7 for classification and 8 for regression. The datasets used in the experiments are summarized in <ref type="table" target="#tab_1">Table-</ref>1. We use standard performance evaluation metrics: error rate for classification and root mean squared error (RMSE) for regression, unless otherwise specified.  We firstly evaluate the proposed approach on two real applications, one for classification <ref type="table" target="#tab_1">(Table-2)</ref> and one for regression <ref type="table" target="#tab_1">(Table-3</ref>). Our proposed JMPF is compared with the original random forest before refinement (denoted as RF), and two state-of-the-art variants: alternating decision forests (ADF) <ref type="bibr" target="#b22">[23]</ref> and alternating regression forests (ARF) <ref type="bibr" target="#b23">[24]</ref>, for classification and regression, respectively. Furthermore, we compare with JMPF+ADF/ARF, for demonstrating that our algorithm can be combined with other methods. We follow the experiment settings in <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24]</ref>. We set the maximum tree depth D at 15, and the minimum sample number in a splitting node is set at 5. The experiments were repeated five times, and the average error and standard deviation were measured. The results are presented in <ref type="table" target="#tab_1">Table-2 and Table-</ref>3, for the classification and regression tasks, respectively. In terms of accuracy, our proposed JMPF significantly outperforms the standard random forest on all classification and regression tasks. Compared to RF, JMPF achieves an average of 23.57% improvement on the classification tasks, and an average of 23.13% improvement on the regression tasks. Our method also consistently outperforms the state-of-theart variants: ADF/ARF. Moreover, the performance of our JMPF algorithm can be further improved by integrating with ADF and ARF, denoted as JMPF + ADF/ARF. As shown in <ref type="table" target="#tab_1">Table-2 and Table-</ref>    <ref type="bibr" target="#b23">[24]</ref>, JMPF: proposed algorithm, JMPF+ARF: our proposed algorithm embedded into ARF. is the error scale. The number of randomly chosen hyperplanes #ℋ is 3. The percentages in brackets for JMPF and JMPF+ARF are the reduction rates in RMSE compared with the RF algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III.4: Discussions on Experimental Results</head><p>The computational complexity of JMPF is similar to that of the standard random forest. As illustrated in the workflow of JMPF in <ref type="figure" target="#fig_2">Fig. 3</ref>, only one additional step, which computes the rotation matrix, is required, when compared to the standard random forest. For a small dataset (e.g., feature dimension size less than 500 and data size less than 10,000), the computation required to compute the rotation matrix for clustering data into the feature-space vertices is acceptable in the training stage (about 10 seconds per level, using MatLab) and negligible in the testing stage. When the dimension size becomes larger, PCA dimensionality reduction can be employed. If the size of the dataset increases, such that using PCA still involves heavy computation, bagging can be used to achieve comparable accuracy and the whole extra computation will be insignificant. To study the stability of JMPF, we choose the letterorig dataset for classification and the kin8nm dataset for regression, and the respective results are shown in <ref type="figure" target="#fig_3">Fig. 4(a)</ref> and <ref type="figure" target="#fig_3">Fig. 4(b)</ref>, respectively. In the experiments, the number of trees, i.e., the number of weak classifiers in the random forest, varies from 10 to 200, and we have three observations. Firstly, as shown in <ref type="figure" target="#fig_3">Fig. 4</ref>, when the number of trees increases, the performance of all the algorithms improves. For classification, as shown in <ref type="figure" target="#fig_3">Fig. 4(a)</ref>, when the number of trees is larger than 100, the errors are converged to become steady. On the contrary, for the regression task as shown in <ref type="figure" target="#fig_3">Fig. 4(b)</ref>, the errors are almost stable, ranged from 10 to 200. Secondly, the results show that JMPF consistently outperforms ADF and RF, irrespective of the number of trees used.</p><p>Finally, <ref type="figure" target="#fig_3">Fig. 4</ref> clearly shows that JMPF can integrate with ADF or ARF to further improve its performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. IMAGE SUPER-RESOLUTION BASED ON JOINT MAXIMUM PURITY FOREST</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV.1 Overview of Image Super-resolution and Related Works</head><p>Image super-resolution (SR), which recovers a high-resolution (HR) image from one single image or a number of low-resolution (LR) images, has been a hot research topic in the field of image processing for decades. SR is a well-known ill-posed problem, which needs artistic skills from mathematics and machine learning. Prior methods on SR are mainly based on edge preserving, such as New Edge-directed Interpolation (NEDI) <ref type="bibr" target="#b48">[49]</ref>, Soft-decision Adaptive Interpolation (SAI) <ref type="bibr" target="#b49">[50]</ref>, Directional Filtering and Data-Fusion (DFDF) <ref type="bibr" target="#b50">[51]</ref>, Modified Edge-Directed Interpolation (MEDI) <ref type="bibr" target="#b51">[52]</ref>, etc.</p><p>The neighbor-embedding (NE) methods <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30]</ref> set the milestone on the patch-learning-based superresolution approach. In this approach, each LR patch is approximated as a linear regression of its nearest LR neighbors in a collected dataset, while its HR counterpart can be reconstructed with the same coefficients of corresponding HR neighbors, based on the non-linear manifold structure. Although the NE method is simple and practical, it requires a huge dataset (millions of patches) to achieve good reconstruction quality and it is computationally intensive, because k-NN is used in searching neighboring patches in the huge dataset. Instead of using the patches extracted directly from natural images, Yang et al. <ref type="bibr" target="#b27">[28]</ref> employed sparse coding <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b27">28]</ref> to represent patch images, of large size, efficiently, which opens the era for sparse coding in the image inverse problems.</p><p>The sparse-coding super-resolution (ScSR) approach is a framework that the HR counterpart of an LR patch can be reconstructed aided by two learned dictionaries, with the sparse constraint on the coefficients via the following formulations: </p><p>The compact LR and HR dictionaries can be jointly learned with a sparsity constraint, using the following sparse representation:</p><formula xml:id="formula_18">D , D = argmin , ‖ − D ‖ + ‖ − D ‖ + ‖ ‖ ,<label>(18)</label></formula><p>where and are the LR patch and the corresponding HR patch, respectively; and D and D are the LR and HR dictionaries learned from the LR and the corresponding HR patch samples, respectively.</p><p>The value of in ‖ ‖ is the sparsity factor of the coefficients . ‖ ‖ is -norm, which means the non-zero count of the coefficients in . For each LR patch of an input LR image , the problem of finding the sparse coefficients can be formulated as follows:</p><formula xml:id="formula_19">min‖ ‖ s.t. ‖D − ‖ ≤ (19) or min‖ ‖ s.t. ‖ D − ‖ ≤ ,<label>(20)</label></formula><p>where is a linear or non-linear feature-extraction operator on the LR patches, which makes the LR patches more discriminative from each other. Typically, can be chosen as a high-pass filter, and a simple high-pass filter can be obtained by subtracting the input from the output of a low-pass filter, as in an early work <ref type="bibr" target="#b43">[44]</ref>. In <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b27">28]</ref>, </p><p>The ideal regularization term for the sparse constraint on the coefficients α is the -norm (nonconvex), but, based on greedy matching, it leads to an NP-hard problem. Alternatively, Yang et al. <ref type="bibr" target="#b27">[28]</ref> relaxed it to -norm, as shown in the following formulation:</p><formula xml:id="formula_21">min‖ ‖ s.t. ‖ D − y‖ ≤ .<label>(22)</label></formula><p>The Lagrange multiplier provides an equivalent formulation as follows:</p><formula xml:id="formula_22">min ‖ D − y‖ + ‖ ‖ ,<label>(23)</label></formula><p>where the parameter balances the sparsity of the solution and the fidelity of the approximation to .</p><p>However, the effectiveness of sparsity was challenged in <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b8">9]</ref>, as to whether real sparsity can help image classification and restoration, or locality property can achieve the same effect. Timofte et al. <ref type="bibr" target="#b1">[2]</ref> proposed an anchored neighborhood regression (ANR) framework, which relaxes the sparse decomposition optimization ( -norm) of <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b27">28]</ref> to a ridge regression ( -norm) problem.</p><p>An important step in the ANR model is the relaxation of the -norm in Eqn. <ref type="bibr" target="#b22">(23)</ref> to the -norm least-squares minimization constraint, as follows:</p><formula xml:id="formula_23">min ‖ D − y‖ + ‖ ‖ ,<label>(24)</label></formula><p>where D and D are the LR and HR patch-based dictionaries, respectively. This -norm constraint problem can be solved with a closed-form solution from the ridge regression <ref type="bibr" target="#b15">[16]</ref> theory. Based on the Tikhonov regularization/ridge-regression theory, the closed-form solution of the coefficients is given:</p><formula xml:id="formula_24">= ( + ) .<label>(25)</label></formula><p>We assume that the HR patches share the same coefficient α from their counterpart LR patches, i.e., = D . From Eqn. (25), we have:</p><formula xml:id="formula_25">= D ( + ) .<label>(26)</label></formula><p>Therefore, the HR patches can be reconstructed by: = y, where can be considered a projection matrix, which can be calculated offline, as follows:</p><formula xml:id="formula_26">= D ( + ) .<label>(27)</label></formula><p>Ridge regression allows the coefficients to be calculated by multiplying the constant projection matrix with the new extracted feature , as described in Eqn. <ref type="bibr" target="#b25">(26)</ref> and Eqn. <ref type="bibr" target="#b26">(27)</ref>. More importantly, the projection matrix can be pre-computed, and this offline learning enables significant speed-up at the prediction stage.</p><p>Timofte et al. <ref type="bibr" target="#b4">[5]</ref> further extended the ANR approach to the A+ approach, which learns regressors from all the training samples, rather than from a small quantity of neighbors of the anchor atoms as ANR does. Later, there are numerous variants and extended approaches, based on ANR and A+ <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b46">47]</ref>. By investigating the ANR model, Li et al. <ref type="bibr" target="#b8">[9]</ref> found that the weights of the supporting atoms can be of different values to represent their similarities to the anchor atom. Based on this idea, the normal collaborative representation (CR) model in ANR is generalized to a weighted model, named as weighted collaborative representation (WCR) model, as follows:</p><formula xml:id="formula_27">min ‖ D − y‖ + ‖ ‖ ,<label>(28)</label></formula><p>where is a diagonal matrix. The weights on the diagonal atoms are proportional to their similarities to the anchor atom. Similarly, the new closed-form solution for the coefficients can be calculated offline, as follows:</p><formula xml:id="formula_28">* = ( + ) y,<label>(29)</label></formula><p>and the new projection matrix is given as follows: * = D ( + ) .</p><p>The WCR model can further improve the ANR or A+ model in terms of image quality, but it is still a time-consuming problem to find the most similar anchor atoms in a dictionary, and this always hinders its applications where fast speed is greatly required.</p><p>Schulter et al. <ref type="bibr" target="#b7">[8]</ref> adopted the random forest as a classifier, and the regressors are learned from the patches in the leaf-nodes. With the same number of regressors, these random-forest-based methods <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b42">43]</ref> can perform on a par with the A+ method in terms of accuracy. However, they achieve an increase in speed, because the sublinear search property of random forest can remarkably reduce the regressors' search complexity.</p><p>Recently, deep learning has become a hot research topic, which has been successfully applied to image super-resolution <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b39">40]</ref> and achieved promising performance, particularly in terms of image quality. In <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b37">38]</ref>, a convolutional neural-network-based image super-resolution (SRCNN) was proposed, in which an end-to-end mapping between LR and HR images is learned through a deep convolutional neural network (CNN). <ref type="bibr" target="#b38">[39]</ref> presented a super-resolution approach with very deep networks with extremely high learning rates, and the deep network convergence rate is sped up by residual learning. Meanwhile, <ref type="bibr" target="#b39">[40]</ref> presented a generative adversarial network (GAN)-based deep residual network model for image super-resolution (SRGAN), in which content loss and adversarial loss are combined as an image perceptual loss function. The proposed deep residual network in <ref type="bibr" target="#b39">[40]</ref> can super-resolve photo-realistic textures from 4-times down-sampled images, and an extensive meanopinion-score (MOS) criterion is proposed to test the perceptual quality gained by using the SRGAN approach. Although deep-learning-based approaches can achieve superior performance compared to other SR methods, their heavy computation is always a big obstacle to their extensive applications with real-time requirements, where the graphics processing unit (GPU) may not be available, such as smart mobile phones.  The recent emerging stream <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b30">31]</ref> on single-image SR is to formulate the problem as a clusteringregression problem, which can be solved with machine-learning tools. These approaches are learningbased methods, which attempt to reconstruct an HR image from patches with the help of an external database. These methods first decompose an image into patches, then classify them into clusters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV.2 JMPF-based Image Super-Resolution</head><p>Regressors are then trained for each of the clusters, which generate mappings from an input LR patch's feature to its corresponding HR patch (see <ref type="figure" target="#fig_6">Fig. 5</ref>). In the testing stage, an LR query image follows the same procedures to cut into patches and to extract features, which are then assigned to their corresponding clusters using the k-NN algorithm <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b18">19]</ref> or random forest <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b6">7]</ref>. The respective HR patches are constructed through regressors learned for the clusters (see <ref type="figure" target="#fig_7">Fig. 6</ref>). This kind of clustering-regression algorithms, based on random forest <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b6">7]</ref>, has achieved state-of-the-art performance in single image super-resolution, both in terms of accuracy and efficiency, because of the use of ensemble learning and sublinear search. As JMPF achieves promising results on both classification and regression tasks, it can be employed for image super-resolution for better performances.</p><p>An overview of the training and testing processes of the proposed JMPF-based image SR method is illustrated in <ref type="figure" target="#fig_6">Fig. 5</ref> and <ref type="figure" target="#fig_7">Fig. 6</ref>, respectively. In our method, the first and second-order gradients are extracted as features from each patch, followed by PCA for dimensionality reduction. These features are then rotated into a more compact, pre-clustered feature space. Finally, all the thresholds are directly set to the inherent zero-center hyperplanes when training the random forest, and similar to other algorithms, the regressors at the leaf-nodes are computed using the rigid regression algorithms. This approach is named as JMPF-based image super-resolution method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV.3 The Working Processes of JMPF-based Image Super-resolution</head><p>JMPF has been shown to achieve a better performance for clustering and classification than other random forest methods. Since image super-resolution can be considered as a clustering/classification problem, using JMPF is likely to result in better performance. This is mainly due to the features transformed to the vertices in the new feature space, so the features become more discriminative. The image super-resolution training and testing processes of our proposed JMPF-based method are described in Algorithm 1 and Algorithm 2, respectively.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV.4 Experimental Results on JMPF-based Image Super-Resolution</head><p>In this section, we evaluate our image SR algorithm on some standard super-resolution datasets, including Set 5, Set14, and B100 <ref type="bibr" target="#b19">[20]</ref>, and compare it with a number of classical or state-of-the-art methods. These include bicubic interpolation, sparse representation SR (Zeyde) <ref type="bibr" target="#b3">[4]</ref>, anchored neighborhood regression (ANR) <ref type="bibr" target="#b1">[2]</ref>, A+ <ref type="bibr" target="#b4">[5]</ref>, standard random forest (RF) <ref type="bibr" target="#b7">[8]</ref>, and alternating regression forests (ARF) <ref type="bibr" target="#b7">[8]</ref>. We set the same parameters for all the random-forest-based algorithms: the number of trees in the random forest is 10, and the maximum depth of each tree is 15. Experiment results are tabulated in <ref type="table" target="#tab_1">Tables-4 and Tables-5,</ref> where JMPF is our proposed JMPF-based image super-resolution method, and JMPF  is a trimmed version, such that the thresholds for the splitnodes are not the inherent zero-center hyperplanes, but set by the standard random-forest bagging strategy.</p><p>We use the same training images (91 images) for all the algorithms as previous works <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b7">8]</ref> do.</p><p>However, for JMPF + , 100 more images from the General-100 dataset <ref type="bibr" target="#b21">[22]</ref> are used, so as to check whether or not more training samples can further improve our proposed algorithm. Table-4 tabulates the performances, in terms of the average peak signal to noise ratio (PSNR) scores, of our proposed algorithm and other image SR methods, on the 3 datasets with different magnification factors. For the Set5 and Set14 datasets, with different magnification factors, our proposed JMPF-based algorithm can achieve a comparable performance to other recent state-of-the-art methods, such as A+ and ARF. As those random-forest-based algorithms may not be stable on small datasets, when evaluation works on extensive datasets, such as B100, our proposed algorithm JMPF can stably outperform A+ and ARF for all magnification factors (×2, ×3, ×4). Moreover, the objective quality metrics on PSNR also</p><p>show that the JMPF algorithm can achieve a better performance when more samples are used for training, as shown from JMPF + in <ref type="table" target="#tab_1">Table-4</ref>. <ref type="table" target="#tab_1">Table-5</ref> provides more details of the performances in datasets Set5.</p><p>To compare the visual quality of our proposed JMPF-based SR algorithm to other methods, <ref type="figure" target="#fig_10">Fig. 7</ref>, shows the reconstructed HR images using different methods. Some regions in the reconstructed images are also enlarged, so as to show the details in the images. In general, our proposed method can produce better quality images, particularly in areas with rich texture, which verifies the feature discrimination of the proposed JMPF scheme. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSIONS</head><p>In this paper, we have proposed a novel random-forest scheme, namely the Joint Maximum Purity Forest (JMPF) scheme, which rotates the feature space into a compact, clustered feature space, by jointly maximizing the purity of all the feature-space vertices. In the new pre-clustered feature space, orthogonal hyperplanes can be effectively used in the split-nodes of a decision tree, which can improve the performance of the trained random forest. Compared to the standard random forests and the recent state-of-the-art variants, such as alternating decision forests (ADF) <ref type="bibr" target="#b22">[23]</ref> and alternating regression forests (ARF) <ref type="bibr" target="#b23">[24]</ref>, our proposed random-forest method inherits the merits of random forests (fast training and testing, multi-class capability, etc.), and also yields promising results on both classification and regression tasks. Experiments have shown that our method achieves an average improvement of about 20% for classification and regression on publicly benchmarked datasets. Furthermore, our proposed scheme can integrate with other methods, such as ADF and ARF, to further improve the performance.</p><p>We have also applied JMPF to single-image super-resolution. We tackle image super-resolution as a clustering-regression problem, and focus on the clustering stage, which happens at the split-nodes of each decision tree. By employing the JMPF strategy, we rotate the feature space into a pre-clustered feature space, which can cluster samples into different sub-spaces more compactly in an unsupervised problem.</p><p>The compact pre-clustered feature space can provide the optimal thresholds for split-nodes in decision trees, which are the zero-centered orthogonal hyperplanes. Our experiment results on intensive image benchmark datasets, such as B100, show that the proposed JMPF-based image super-resolution approach can consistently outperform recent state-of-the-art algorithms, in terms of PSNR and visual quality. Our method also inherits the advantages of random forests, which have fast speed on both the training and inference processes.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>(a) Three classes of samples in a feature space, which are hard to be clustered with orthogonal hyperplanes; and (b) the samples are rotated, and a decision tree of a random forest is used to cluster the data in the new, rotated feature space.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>Two toy examples of rotating a feature space into a more compact clustered feature space: (a) 2-dimensional features and (b) 3-dimensional features. The feature data is clustered into the vertices of a new feature space, by jointly maximizing the purity of all the clustered data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 :</head><label>3</label><figDesc>An overview of the workflow of the JMPF-based random forest.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 :</head><label>4</label><figDesc>Performance with different numbers of trees for (a) classification and (b) regression (dataset for classification is letterorig and dataset for regression is kin8nm, error scale: 10 -2 , the number hyperplane(s) #ℋ on training the random forest is 3).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>≈ D , ∈ ℝ with ‖ ‖ ≪ .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>first and second-order gradient operators are employed on up-sampled versions of low-resolution images, then four patches are extracted from these gradient maps at each location, and concatenate them to become feature vectors. The four 1-D filters used to extract the derivatives are:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 :</head><label>5</label><figDesc>An overview of the training process of the JMPF-based method for image super-resolution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 6 :</head><label>6</label><figDesc>An overview of the testing process of the JMPF-based method for image super-resolution</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Algorithm 1 : 1 : 2 : 3 : 4 :Algorithm 2 :</head><label>112342</label><figDesc>JMPF-based Image Super-Resolution Training Process: Input: { , } : training LR-HR patch pairs, N is the number of training samples. Output: the random forest and ridge regression projection matrices: ℘ = ( , … , ), in leafnodes, where is the number of regressors; the PCA projection matrix ℳ and the rotation matrix ℛ. Discriminative features calculated from patch images based on first and second-order (horizontal and vertical) gradients; ⇒ {Eqn. (21)} Apply PCA on features to compute the PCA projection matrix ℳ; Train a JMPF-based random forest by clustering PCA projected feature data into featurespace vertices, which can rotate the feature space into a compact pre-clustered feature space, at the same time obtain the rotation matrix ℛ; ⇒ {Eqn. (11)} Train ridge regression projection matrices: ℘ = ( , … , ), from LR-HR patch pairs in all the leaf-nodes. ⇒ {Eqn. (27)} JMPF-based Image Super-Resolution Testing Stage: Input: testing LR image , the trained JMPF-based random forest and ridge regression projection matrices: ℘ = ( , … , ) in leaf-nodes; the trained PCA projection matrix ℳ and the trained rotation matrix ℛ.Output: super-resolved image .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>1 : 2 : 3 : 4 :</head><label>1234</label><figDesc>Extract discriminative features for all the patches of image ; ⇒ {Eqn. (21)} Do feature dimension reduction via the PCA projection matrix ℳ; Rotate feature space into a compact pre-clustered feature space via the rotation matrix ℛ; For LR patches from image , based on their features, searching their corresponding regressors from leaf-nodes in the trained random-forest; 5: Produce through all the image patches from image by ridge regression with the trained projection matrices: ℘ = ( , … , ). ⇒ {Eqn. (26)}</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 7 :</head><label>7</label><figDesc>Super-resolved (×3) images from Set5: (a) bicubic, (b) ANR<ref type="bibr" target="#b1">[2]</ref>, (c) A+<ref type="bibr" target="#b4">[5]</ref>, (d) ARF<ref type="bibr" target="#b7">[8]</ref>, (e) proposed algorithm JMPF, and (f) ground truth. The results show that our JMPF-based algorithm can produce more details.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table - 1</head><label>-</label><figDesc>: The properties of the standard machine-learning datasets used for classification and regression. The top 7 are used for classification (c) and the bottom 8 for regression (r). (3/4 means 75% training and 25% testing)</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>3, JMPF+ADF achieves an average 27.86% improvement on the classification tasks, while JMPF+ARF achieves an average 26.88% improvement on the regression tasks. These results on diverse tasks clearly demonstrate the effectiveness of our proposed approach.</figDesc><table><row><cell>dataset</cell><cell>#ℋ</cell><cell>RF</cell><cell>ADF</cell><cell>JMPF</cell><cell>JMPF+ADF</cell><cell></cell></row><row><cell></cell><cell>1</cell><cell>2.261±0.021</cell><cell>2.173±0.014</cell><cell>2.147±0.021 (05%)</cell><cell>2.114±0.016 (07%)</cell><cell></cell></row><row><cell>char74k</cell><cell>3</cell><cell>2.449±0.029</cell><cell>2.236±0.015</cell><cell>2.206±0.027 (10%)</cell><cell>2.143±0.024 (12%)</cell><cell>10 -1</cell></row><row><cell></cell><cell>5</cell><cell>2.452±0.016</cell><cell>2.232±0.021</cell><cell>2.209±0.019 (10%)</cell><cell>2.138±0.017 (13%)</cell><cell></cell></row><row><cell></cell><cell>1</cell><cell>5.656±0.534</cell><cell>5.238±0.539</cell><cell>4.211±0.252 (26%)</cell><cell>3.958±0.508 (30%)</cell><cell></cell></row><row><cell>gas sensor</cell><cell>3</cell><cell>6.264±0.042</cell><cell>5.952±0.323</cell><cell>4.622±0.299 (26%)</cell><cell>4.416±0.370 (30%)</cell><cell>10 -3</cell></row><row><cell></cell><cell>5</cell><cell>6.470±0.332</cell><cell>5.751±0.792</cell><cell>4.775±0.459 (26%)</cell><cell>4.159±0.324 (36%)</cell><cell></cell></row><row><cell></cell><cell>1</cell><cell>6.932±0.281</cell><cell>6.208±0.338</cell><cell>6.153±0.381 (11%)</cell><cell>5.868±0.239 (15%)</cell><cell></cell></row><row><cell>isolet</cell><cell>3</cell><cell>6.501±0.199</cell><cell>6.308±0.330</cell><cell>6.272±0.332 (04%)</cell><cell>5.932±0.177 (09%)</cell><cell>10 -2</cell></row><row><cell></cell><cell>5</cell><cell>7.005±0.362</cell><cell>6.528±0.261</cell><cell>6.381±0.254 (09%)</cell><cell>5.969±0.205 (15%)</cell><cell></cell></row><row><cell></cell><cell>1</cell><cell>6.371±0.099</cell><cell>4.418±0.082</cell><cell>4.114±0.087 (35%)</cell><cell>3.535±0.111 (45%)</cell><cell></cell></row><row><cell>letterorig</cell><cell>3</cell><cell>6.889±0.199</cell><cell>5.196±0.127</cell><cell>4.864±0.267 (29%)</cell><cell>4.146±0.192 (40%)</cell><cell>10 -2</cell></row><row><cell></cell><cell>5</cell><cell>6.739±0.263</cell><cell>5.082±0.097</cell><cell>4.625±0.257 (31%)</cell><cell>4.032±0.131 (40%)</cell><cell></cell></row><row><cell></cell><cell>1</cell><cell>3.528±0.124</cell><cell>3.234±0.106</cell><cell>2.912±0.069 (17%)</cell><cell>2.850±0.136 (19%)</cell><cell></cell></row><row><cell>pendigits</cell><cell>3</cell><cell>3.418±0.171</cell><cell>3.377±0.164</cell><cell>2.969±0.120 (13%)</cell><cell>2.915±0.100 (15%)</cell><cell>10 -2</cell></row><row><cell></cell><cell>5</cell><cell>3.499±0.184</cell><cell>3.283±0.184</cell><cell>3.054±0.081 (13%)</cell><cell>3.002±0.086 (14%)</cell><cell></cell></row><row><cell></cell><cell>1</cell><cell>1.824±0.018</cell><cell>0.972±0.028</cell><cell>0.324±0.005 (82%)</cell><cell>0.253±0.009 (86%)</cell><cell></cell></row><row><cell>sensorless</cell><cell>3</cell><cell>1.026±0.158</cell><cell>0.391±0.007</cell><cell>0.293±0.004 (71%)</cell><cell>0.281±0.003 (73%)</cell><cell>10 -1</cell></row><row><cell></cell><cell>5</cell><cell>0.903±0.150</cell><cell>0.512±0.223</cell><cell>0.268±0.054 (70%)</cell><cell>0.244±0.029 (73%)</cell><cell></cell></row><row><cell></cell><cell>1</cell><cell>6.128±0.181</cell><cell>6.149±0.208</cell><cell>6.085±0.216 (01%)</cell><cell>5.964±0.206 (03%)</cell><cell></cell></row><row><cell>usps</cell><cell>3</cell><cell>6.527±0.203</cell><cell>6.520±0.188</cell><cell>6.285±0.101 (04%)</cell><cell>6.206±0.245 (05%)</cell><cell>10 -2</cell></row><row><cell></cell><cell>5</cell><cell>6.548±0.225</cell><cell>6.441±0.195</cell><cell>6.391±0.063 (02%)</cell><cell>6.213±0.112 (05%)</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table -</head><label>-</label><figDesc></figDesc><table><row><cell>dataset</cell><cell>RF</cell><cell>ARF</cell><cell>JMPF</cell><cell>JMPF+ARF</cell><cell></cell></row><row><cell>delta ailerons</cell><cell>2.970±0.001</cell><cell>2.967±0.006</cell><cell>1.952±0.003 (34%)</cell><cell>1.946±0.002 (34%)</cell><cell>10 -4</cell></row><row><cell>delta elevators</cell><cell>2.360±0.002</cell><cell>2.338±0.008</cell><cell>1.635±0.001 (30%)</cell><cell>1.610±0.006 (32%)</cell><cell>10 -3</cell></row><row><cell>elevators</cell><cell>0.638±0.001</cell><cell>0.635±0.001</cell><cell>0.619±0.001 (03%)</cell><cell>0.606±0.001 (05%)</cell><cell>10 -2</cell></row><row><cell>kin8nm</cell><cell>2.622±0.002</cell><cell>2.545±0.003</cell><cell>1.962±0.003 (25%)</cell><cell>1.667±0.005 (36%)</cell><cell>10 -1</cell></row><row><cell>price</cell><cell>7.281±0.755</cell><cell>6.663±0.794</cell><cell>5.460±0.627 (25%)</cell><cell>5.234±0.666 (28%)</cell><cell>10 1</cell></row><row><cell>pyrim</cell><cell>1.440±0.008</cell><cell>1.042±0.347</cell><cell>1.031±0.017 (28%)</cell><cell>0.631±0.018 (56%)</cell><cell>10 -1</cell></row><row><cell>stock</cell><cell>2.878±0.022</cell><cell>2.823±0.038</cell><cell>2.744±0.019 (05%)</cell><cell>2.678±0.021 (07%)</cell><cell>10 0</cell></row><row><cell>Wiscoin breast cancer</cell><cell>3.669±0.041</cell><cell>3.130±0.044</cell><cell>3.081±0.008 (16%)</cell><cell>3.036±0.023 (17%)</cell><cell>10 1</cell></row></table><note>2: Comparison of classification performances on seven datasets, which can be found at UCI machine-learning repository: https://archive.ics.uci.edu/ml/datasets.html. RF: standard random forest, ADF: alternating decision forests [23], JMPF: proposed algorithm, JMPF+ADF: our proposed algorithm embedded into ADF. #ℋis the number of randomly chosen hyperplane(s) on training a random forest. is the error scale. The percentages in brackets for JMPF and JMPF+ADF are the reduction rates in RMSE (root mean squared error) compared with the RF algorithm.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table - 3</head><label>-</label><figDesc>: Comparison of regression performances on eight datasets, which can be found at http://www.dcc.fc.up.pt/~ltorgo/Regression/DataSets.html. RF: standard random forest, ARF: alternating regression forests</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Results of the proposed method, compared with state-of-the-art methods on 3 datasets, in terms of PSNR (dB), with three different magnification factors (×2, ×3, ×4).</figDesc><table><row><cell>Dataset</cell><cell>scale</cell><cell cols="6">bicubic Zeyde[4] ANR[2] A+[5] RF[8] ARF[8]</cell><cell>JMPF -</cell><cell>JMPF</cell><cell>JMPF +</cell></row><row><cell></cell><cell>×2</cell><cell>33.66</cell><cell>35.78</cell><cell>35.83</cell><cell>36.55</cell><cell>36.52</cell><cell>36.65</cell><cell>36.53</cell><cell>36.59</cell><cell>36.70</cell></row><row><cell>Set5</cell><cell>×3</cell><cell>30.39</cell><cell>31.92</cell><cell>31.93</cell><cell>32.59</cell><cell>32.44</cell><cell>32.53</cell><cell>32.51</cell><cell>32.59</cell><cell>32.67</cell></row><row><cell></cell><cell>×4</cell><cell>28.42</cell><cell>29.74</cell><cell>29.74</cell><cell>30.28</cell><cell>30.10</cell><cell>30.17</cell><cell>30.14</cell><cell>30.17</cell><cell>30.24</cell></row><row><cell></cell><cell>×2</cell><cell>30.23</cell><cell>31.81</cell><cell>31.80</cell><cell>32.28</cell><cell>32.26</cell><cell>32.33</cell><cell>32.27</cell><cell>32.32</cell><cell>32.42</cell></row><row><cell>Set14</cell><cell>×3</cell><cell>27.54</cell><cell>28.68</cell><cell>28.66</cell><cell>29.13</cell><cell>29.04</cell><cell>29.10</cell><cell>29.12</cell><cell>29.13</cell><cell>29.24</cell></row><row><cell></cell><cell>×4</cell><cell>26.00</cell><cell>26.88</cell><cell>26.85</cell><cell>27.33</cell><cell>27.22</cell><cell>27.28</cell><cell>27.29</cell><cell>27.30</cell><cell>27.37</cell></row><row><cell></cell><cell>×2</cell><cell>29.32</cell><cell>30.40</cell><cell>30.44</cell><cell>30.78</cell><cell>31.13</cell><cell>31.21</cell><cell>31.16</cell><cell>31.23</cell><cell>31.31</cell></row><row><cell>B100</cell><cell>×3</cell><cell>27.15</cell><cell>27.87</cell><cell>27.89</cell><cell>28.18</cell><cell>28.21</cell><cell>28.26</cell><cell>28.26</cell><cell>28.30</cell><cell>28.37</cell></row><row><cell></cell><cell>×4</cell><cell>25.92</cell><cell>26.51</cell><cell>26.51</cell><cell>26.77</cell><cell>26.74</cell><cell>26.77</cell><cell>26.78</cell><cell>26.81</cell><cell>26.87</cell></row><row><cell>Table-4:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Table-5: Detailed results of the proposed method, compared with state-of-the-art methods on the dataset Set5, in terms of PSNR (dB) using three different magnification factors (×2, ×3, ×4).</figDesc><table><row><cell cols="4">Set5(×2) bicubic Zeyde[4] ANR[2]</cell><cell>A+[5]</cell><cell>RF[8]</cell><cell>ARF[8]</cell><cell>JMPF -</cell><cell>JMPF</cell><cell>JMPF +</cell></row><row><cell>baby</cell><cell>37.05</cell><cell>38.22</cell><cell>38.42</cell><cell>38.52</cell><cell>38.47</cell><cell>38.48</cell><cell>38.40</cell><cell>38.45</cell><cell>38.45</cell></row><row><cell>bird</cell><cell>36.82</cell><cell>39.91</cell><cell>40.03</cell><cell>41.06</cell><cell>40.98</cell><cell>41.15</cell><cell>40.82</cell><cell>40.99</cell><cell>41.11</cell></row><row><cell>butterfly</cell><cell>27.43</cell><cell>30.64</cell><cell>30.54</cell><cell>32.02</cell><cell>32.27</cell><cell>32.66</cell><cell>32.58</cell><cell>32.50</cell><cell>32.79</cell></row><row><cell>head</cell><cell>34.85</cell><cell>35.62</cell><cell>35.72</cell><cell>35.82</cell><cell>35.69</cell><cell>35.73</cell><cell>35.68</cell><cell>35.73</cell><cell>35.78</cell></row><row><cell>woman</cell><cell>32.14</cell><cell>34.53</cell><cell>34.53</cell><cell>35.31</cell><cell>35.19</cell><cell>35.24</cell><cell>35.15</cell><cell>35.28</cell><cell>35.38</cell></row><row><cell>average</cell><cell>33.66</cell><cell>35.78</cell><cell>35.85</cell><cell>36.55</cell><cell>36.52</cell><cell>36.65</cell><cell>36.53</cell><cell>36.59</cell><cell>36.70</cell></row><row><cell cols="4">Set5(×3) bicubic Zeyde[4] ANR[2]</cell><cell>A+[5]</cell><cell>RF[8]</cell><cell>ARF[8]</cell><cell>JMPF -</cell><cell>JMPF</cell><cell>JMPF +</cell></row><row><cell>baby</cell><cell>33.91</cell><cell>35.13</cell><cell>35.13</cell><cell>35.23</cell><cell>35.25</cell><cell>35.15</cell><cell>35.11</cell><cell>35.16</cell><cell>35.14</cell></row><row><cell>bird</cell><cell>32.58</cell><cell>34.62</cell><cell>34.63</cell><cell>35.53</cell><cell>35.23</cell><cell>35.31</cell><cell>35.25</cell><cell>35.46</cell><cell>35.49</cell></row><row><cell>butterfly</cell><cell>24.04</cell><cell>25.93</cell><cell>25.92</cell><cell>27.13</cell><cell>27.00</cell><cell>27.39</cell><cell>27.46</cell><cell>27.48</cell><cell>27.73</cell></row><row><cell>head</cell><cell>32.88</cell><cell>33.61</cell><cell>33.64</cell><cell>33.82</cell><cell>33.73</cell><cell>33.73</cell><cell>33.72</cell><cell>33.79</cell><cell>33.76</cell></row><row><cell>woman</cell><cell>28.56</cell><cell>30.32</cell><cell>30.31</cell><cell>31.24</cell><cell>30.98</cell><cell>31.08</cell><cell>31.03</cell><cell>31.06</cell><cell>31.24</cell></row><row><cell>average</cell><cell>30.39</cell><cell>31.92</cell><cell>31.93</cell><cell>32.59</cell><cell>32.44</cell><cell>32.53</cell><cell>32.51</cell><cell>32.59</cell><cell>32.67</cell></row><row><cell cols="4">Set5(×4) bicubic Zeyde[4] ANR[2]</cell><cell>A+[5]</cell><cell>RF[8]</cell><cell>ARF[8]</cell><cell>JMPF -</cell><cell>JMPF</cell><cell>JMPF +</cell></row><row><cell>baby</cell><cell>31.78</cell><cell>33.13</cell><cell>33.07</cell><cell>33.3</cell><cell>33.26</cell><cell>33.16</cell><cell>33.09</cell><cell>33.12</cell><cell>33.12</cell></row><row><cell>bird</cell><cell>30.18</cell><cell>31.75</cell><cell>31.82</cell><cell>32.5</cell><cell>32.21</cell><cell>32.26</cell><cell>32.27</cell><cell>32.33</cell><cell>32.47</cell></row><row><cell>butterfly</cell><cell>22.10</cell><cell>23.67</cell><cell>23.58</cell><cell>24.4</cell><cell>24.32</cell><cell>24.56</cell><cell>24.55</cell><cell>24.44</cell><cell>24.63</cell></row><row><cell>head</cell><cell>31.59</cell><cell>32.23</cell><cell>32.34</cell><cell>32.5</cell><cell>32.35</cell><cell>32.37</cell><cell>32.35</cell><cell>32.45</cell><cell>32.47</cell></row><row><cell>woman</cell><cell>26.46</cell><cell>27.94</cell><cell>27.88</cell><cell>28.6</cell><cell>28.38</cell><cell>28.48</cell><cell>28.44</cell><cell>28.50</cell><cell>28.53</cell></row><row><cell>average</cell><cell>28.42</cell><cell>29.74</cell><cell>29.74</cell><cell>30.28</cell><cell>30.10</cell><cell>30.17</cell><cell>30.14</cell><cell>30.17</cell><cell>30.24</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Iterative quantization: A procrustean approach to learning binary codes for large-scale image retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gordo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2916" to="2929" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Anchored neighborhood regression for fast example-based super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Timofte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">De</forename><surname>Smet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1920" to="1927" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Shape quantization and recognition with randomized trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Amit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Geman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1545" to="1588" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">On single image scale-up using sparse-representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zeyde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Protter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on curves and surfaces</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="711" to="730" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A+: Adjusted anchored neighborhood regression for fast super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Timofte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">De</forename><surname>Smet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="111" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A generalized solution of the orthogonal Procrustes problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Schönemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="1966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Aggregating local descriptors into a compact image representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jégou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pérez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="3304" to="3311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Fast and accurate image upscaling with super-resolution forests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schulter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Leistner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3791" to="3799" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fast super-resolution based on weighted collaborative representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-M</forename><surname>Lam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 19th International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="914" to="918" />
		</imprint>
	</monogr>
	<note>Digital Signal Processing</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A tutorial on support vector machines for pattern recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Burges</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data mining and knowledge discovery</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="121" to="167" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">An introduction to support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cristianini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>Cambridge University Press Cambridge</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Hybrid sparse-representation-based approach to image super-resolution reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Electronic Imaging</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="23008" to="023008" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Experiments with a new boosting algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">icml</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="148" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Random forests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">One millisecond face alignment with an ensemble of regression trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kazemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sullivan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1867" to="1874" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Solutions of ill-posed problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Tikhonov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">I A K</forename><surname>Arsenin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>John</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977" />
			<pubPlace>Winston Washington, DC</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Fast discriminative visual codebooks using randomized clustering forests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Moosmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Jurie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Seven ways to improve example-based single image super resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Timofte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rothe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1865" to="1873" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Naive bayes super-resolution forest</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Salvador</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pérez-Pellitero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="325" to="333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eighth IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2001" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="416" to="423" />
		</imprint>
	</monogr>
	<note>in Computer Vision, 2001. ICCV 2001. Proceedings</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Face alignment at 3000 fps via regressing local binary features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1685" to="1692" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Single Image Super-Resolution via Locally Regularized Anchored Neighborhood Regression and Nonlocal Means</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="15" to="26" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Alternating decision forests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schulter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wohlhart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Leistner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saffari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="508" to="515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Alternating regression forests for object detection and pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schulter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Leistner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wohlhart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="417" to="424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Experiments with a new boosting algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">icml</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="148" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Greedy function approximation: a gradient boosting machine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Friedman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="1189" to="1232" />
		</imprint>
	</monogr>
	<note>Annals of statistics</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Class-specific hough forests for object detection,&quot; in Decision forests for computer vision and medical image analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="143" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Image super-resolution via sparse representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on image processing</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2861" to="2873" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Super-resolution through neighbor embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-Y</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 IEEE Computer Society Conference on</title>
		<meeting>the 2004 IEEE Computer Society Conference on</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2004" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note>Computer Vision and Pattern Recognition</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Low-complexity single-image super-resolution based on nonnegative neighbor embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bevilacqua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roumy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Guillemot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Alberi-Morel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Fast direct super-resolution by simple functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="561" to="568" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Learning multiple linear mappings for efficient single image superresolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="846" to="861" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Adaptive local nonparametric regression for fast single image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visual Communications and Image Processing (VCIP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Optimized cartesian k-means</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-S</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">T</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="180" to="192" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Image super-resolution based on dictionary learning and anchored neighborhood regression with mutual incoherence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Image Processing (ICIP), 2015 IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="591" to="595" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">CCR: Clustering and Collaborative Representation for Fast Single Image Super-Resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="405" to="417" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Learning a deep convolutional network for image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="184" to="199" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Accelerating the super-resolution convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="391" to="407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Accurate image super-resolution using very deep convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Kwon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K. Mu</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1646" to="1654" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Photo-realistic single image super-resolution using a generative adversarial network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ledig</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.04802</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Learning Hierarchical Decision Trees for Single Image Super-Resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-C</forename><surname>Siu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Circuits and Systems for Video Technology</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Fast image interpolation via random forests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-C</forename><surname>Siu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-R</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3232" to="3245" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Naive bayes super-resolution forest</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Salvador</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pérez-Pellitero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="325" to="333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Example-based super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pasztor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Computer Graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Jointly Optimized Regressors for Image Super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Timofte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="95" to="104" />
			<date type="published" when="2015" />
			<publisher>Wiley Online Library</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Cascaded Face Alignment via Intimacy Definition Feature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-M</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.06642</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Regressor basis learning for anchored super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Agustsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Timofte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Support-vector networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="297" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">New edge-directed interpolation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Orchard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on image processing</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1521" to="1527" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Image interpolation by adaptive 2-D autoregressive modeling and soft-decision estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="887" to="896" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">An edge-guided image interpolation algorithm via directional filtering and data fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2226" to="2238" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Modified edge-directed interpolation for images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-S</forename><surname>Tam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-W</forename><surname>Kok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-C</forename><surname>Siu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Electronic imaging</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="13011" to="013011" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">LIBLINEAR: A library for large linear classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R.-E</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-J</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Circulant binary embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-F</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="946" to="954" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Active Appearance Model Algorithm with K-Nearest Neighbor Classifier for Face Pose Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-C</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Jen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-R</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-H</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Marine Science and Technology</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="285" to="294" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
