<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Looking back at Labels: A Class based Domain Adaptation Technique</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinod</forename><forename type="middle">Kumar</forename><surname>Kurmi</surname></persName>
							<email>vinodkk@iitk.ac.in</email>
							<affiliation key="aff0">
								<orgName type="institution">Indian Institute of Technology Kanpur</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinay</forename><forename type="middle">P</forename><surname>Namboodiri</surname></persName>
							<email>vinaypn@iitk.ac.in</email>
							<affiliation key="aff1">
								<orgName type="institution">Indian Institute of Technology</orgName>
								<address>
									<settlement>Kanpur</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Looking back at Labels: A Class based Domain Adaptation Technique</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T12:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we solve the problem of adapting classifiers across domains. We consider the problem of domain adaptation for multi-class classification where we are provided a labeled set of examples in a source dataset and we are provided a target dataset with no supervision. In this setting, we propose an adversarial discriminator based approach. While the approach based on adversarial discriminator has been previously proposed; in this paper, we present an informed adversarial discriminator. Our observation relies on the analysis that shows that if the discriminator has access to all the information available including the class structure present in the source dataset, then it can guide the transformation of features of the target set of classes to a more structure adapted space. Using this formulation, we obtain state-of-the-art results for the standard evaluation on benchmark datasets. We further provide detailed analysis which shows that using all the labeled information results in an improved domain adaptation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Deep learning frameworks have solved many computer vision tasks such as object recognition, object detection, image generation, etc. With the advent of deep learning, models that are trained on a large number of images are ubiquitously being used. However, it was shown by Tzeng et al. <ref type="bibr" target="#b0">[1]</ref> that while generically trained deep networks have a reduced dataset bias, there still exists a domain shift between different datasets and it is required to adapt the features appropriately. In the adversarial framework, one of the methods viz. unsupervised domain adaptation through backpropagation <ref type="bibr" target="#b1">[2]</ref>, solved this problem by adding an auxiliary task that solves the problem of domain classification. The main observation for this method is that for classifiers to be adapted across domains, the domain classifier should fail. This can be easily achieved through a gradient reversal layer that modifies features to worsen the ability to classify domains and it requires no labels to be available in the target dataset. But, due to the limited capacity of using a binary discriminator, it introduces a problem of mode collapse in the feature space for source and target domains. The binary discriminator tends to mix all the target (or source) samples into a single domain class. In contrast to a binary discriminator, the proposed informative discriminator considers all the source label information and encourages target samples to be mis-classified into one of the source class. It helps the target sample to preserve its multiple modes. For the source sample, the multiple modes are preserved by Project: https://vinodkkurmi.github.io/DiscriminatorDomainAdaptation the regular classifier. The binary discriminator model <ref type="bibr" target="#b1">[2]</ref> is considered as a baseline for the proposed model. Through the proposed method we show that by making the adversarial domain classifier informative and providing it all the information available at the source, one can obtain an improved performance achieving an impressive improvement of 8.2% over the corresponding baseline of gradient reversal <ref type="bibr" target="#b1">[2]</ref> on the Amazon-DSLR adaptation task. This method also obtains an improvement of 6.21% over the very recently proposed approach that also considers introducing additional source label information <ref type="bibr" target="#b2">[3]</ref>. To summarize, this paper makes the following contributions:</p><p>• We propose a method that uses all source label information in a scalable way by using an informative domain discriminator. <ref type="bibr">•</ref> We show that providing the source label in the discriminator helps to preserve the mode information of target samples. • This paper also provides additional insights into understanding our method by providing results for hyperparameter sensitivity, inclusion of hierarchical class labels, discrepancy distance, statistical significance tests and feature visualization. This level of detailed analysis comprehensively supports our claims regarding the efficacy of the proposed approach. also has been successfully applied. The subspace alignment based model was proposed by the <ref type="bibr" target="#b13">[14]</ref>. In the <ref type="bibr" target="#b14">[15]</ref> model learns a pairwise similarity function between the classes to solve the domain adaptation problem. Image generation task using the Generative adversarial network <ref type="bibr" target="#b15">[16]</ref>, applied in the unsupervised domain adaptation task. In the <ref type="bibr" target="#b16">[17]</ref>, auto encoder framework used to learn the source to target mapping. Recent work by <ref type="bibr" target="#b17">[18]</ref>- <ref type="bibr" target="#b22">[23]</ref> used the similar concept by the generative adversarial network to adapt the target domain. For source to target mapping, cycle consistency framework <ref type="bibr" target="#b23">[24]</ref> for the domain transfer is proposed by the <ref type="bibr" target="#b24">[25]</ref>. Multimodal text generation problem from the image and other modality, has been studied in <ref type="bibr" target="#b25">[26]</ref>. In the asymmetric domain adaptation models, different feature extractors for source and target have been used <ref type="bibr" target="#b26">[27]</ref>- <ref type="bibr" target="#b29">[30]</ref>. In the <ref type="bibr" target="#b30">[31]</ref> different batch normalization used for the adaptation. Other work such as <ref type="bibr" target="#b31">[32]</ref> used the different alignment layer between the source and target network. <ref type="bibr" target="#b32">[33]</ref> propose to maximize the discrepancy between two classifierss outputs to detect target samples that are far from the support of the source. Adversarial dropout <ref type="bibr" target="#b33">[34]</ref> was applied to adapt the target domain. Recently attention based model has been proposed in the <ref type="bibr" target="#b34">[35]</ref> to solve the domain adaptation problem.</p><p>Other exemplar based method <ref type="bibr" target="#b35">[36]</ref> have also explored ways to bring similar attention distributions closer. There are other frameworks based on adversarial learning used to solve the domain adaptation problem. The proposed model lies in the adversarial domain adaptation framework setting. <ref type="bibr" target="#b1">[2]</ref> used a simple binary discriminator to learn indistinguishable feature mapping by the discriminator between the source and target domain. There are other adversarial method such as Adversarial discriminator for domain adaptation (ADDA) <ref type="bibr" target="#b36">[37]</ref>, conditional adversarial domain adaptation (CDAN) <ref type="bibr" target="#b37">[38]</ref>, Multi discriminator for domain adaptation (MADA) <ref type="bibr" target="#b2">[3]</ref>, Cycle-Consistent Adversarial Domain Adaptation (CyCDA) <ref type="bibr" target="#b23">[24]</ref>, PixelDA <ref type="bibr" target="#b19">[20]</ref>, PADA <ref type="bibr" target="#b38">[39]</ref> and other recent adversarial feature learning methods are proposed in the <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b39">[40]</ref>- <ref type="bibr" target="#b43">[44]</ref> Domain adaptation in scene graph was also applied in <ref type="bibr" target="#b44">[45]</ref>. Recent work by <ref type="bibr" target="#b32">[33]</ref> adapts the classifier by maximizing the discrepancy between two classifier's outputs to detect target samples that are far from the support of the source. This method uses the prediction probability of the target samples to measure the discrepancy. The closest related work to our approach is the work by <ref type="bibr" target="#b2">[3]</ref> that extends the gradient reversal work <ref type="bibr" target="#b1">[2]</ref> by including a class specific discriminator. Class structure based adaptation has been explored by CDAN <ref type="bibr" target="#b37">[38]</ref>. CDAN uses the class structure to compute the focal loss by concatenating the class prediction with features. But our objective is to make the discriminator more efficient by providing the sub class structure <ref type="bibr" target="#b45">[46]</ref>, <ref type="bibr" target="#b46">[47]</ref>. So the idea of using the class label structure is different than that of CDAN. Specifically, in the discriminator, we add more information regarding the source classes (the negative class of the discriminator). Other than this, CDAN and MADA both use the predicted target label (from the classifier) to compute the conditional distribution. But in our case, we are not relying on the target prediction score. Our method is complementary to most of the advances made in adversarial techniques and shows that an informative discriminator is crucial for obtaining significant improvements in the adversarial setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. BACKGROUND: DISCRIMINATOR FOR DOMAIN ADAPTATION</head><p>The seminal generative adversarial network (GAN) <ref type="bibr" target="#b15">[16]</ref> and its different variants, used an adversarial loss to make a generator learn the true data distribution. The basic motivation of the adversarial methods <ref type="bibr" target="#b15">[16]</ref> is to align the fake (generated) and real distributions. These, however do so without considering the complex multimodal structures underlying in these data distributions. As a result, all the generated data classes are confused with real data. It leads to loss of the discriminative structure of data for different distribution. The discriminative structure from the discriminator also helps to generate the paraphrase sentence generation problem <ref type="bibr" target="#b47">[48]</ref>. Particularly, in the domain adaptation scenario, it is crucial to preserve the multimodal structured data for solving the classification problem. To overcome the mode collapse problem, one of the solutions is proposed by Odena et al. <ref type="bibr" target="#b48">[49]</ref> by extending the vanilla GAN architecture by introducing the auxiliary classification task on the discriminator. It leads to generated images being more distinct and sharp. Our proposed discriminator considers all the source label information to prevents loss of modes. We also propose a hierarchical structure for the discriminator when suitable. All the adversarial methods performance relies on the efficiency of the discriminator. One could make it more efficient by providing the sub-class structure of the data as suggested by <ref type="bibr" target="#b45">[46]</ref>, <ref type="bibr" target="#b46">[47]</ref>. In the discriminator classification task, class labels can be considered as sub-classes, and they are well defined and distinct. By providing it to the discriminator, we observe that it helps to learn additional structure of the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Domain-Label Discriminator</head><p>Domain label discriminator is a simple binary classifier, which aims to misclassify the source and target domain samples. Most of the adversarial models <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b11">[12]</ref> use the domain label discriminator for the image generation and domain adaptation. In the binary discriminator, all target samples (or generated fake samples) are mis-classified as a single source (true) domain. In the domain adaptation scenario, the target features generated by the feature extractor, obtains invariance in domain, but loses its multimodal structure. This mode information can be preserved by the proposed informative discriminator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Class-Label Discriminator</head><p>If two distributions are underlying the modes, then performance of a binary classifier can be improved by using the sub-class structure of dataset <ref type="bibr" target="#b45">[46]</ref>, <ref type="bibr" target="#b46">[47]</ref>. In the proposed model, we use a class label based discriminator to improve the capacity of the discriminator to classify the source and target distribution. <ref type="bibr" target="#b48">[49]</ref> applied an auxiliary classifier, in the discriminator of the vanilla GAN architecture <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b49">[50]</ref>, to predicts the class label for generate better images without mixing the multimodal structure of data. These works provide an intuition that by providing the information about the structure of data to discriminator, data distribution can be captured effectively. To keep the multi-modal structure of target data MADA <ref type="bibr" target="#b2">[3]</ref> used N -discriminators for each mode (class) of data. The underlying problem with such multiple discriminator approaches is that its scalability is limited. The model will be more complex as the number of classes increases. Another problem with MADA is that it uses the target class prediction score to decide the discriminator. For a wrong prediction it may lead to a different mode. We instead use a single discriminator to perform the source and target classification task along with the task of predicting the correct source label.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. PROPOSED APPROACH</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Problem Description</head><p>We address the problem of unsupervised domain adaptation, where there are no labels in the training data for the target domain. More formally, we are given data for a source domain, </p><formula xml:id="formula_0">S = (x s i , y s i ) ns i=1 of n</formula><formula xml:id="formula_1">(X s , Y s ) and Q(X t , Y t ) respectively, where P = Q.</formula><p>The assumption here is that the label set is common for source and target domains. The aim of our model is to provide a deep neural network that enables learning of transferable features f = G f (x) and an adaptive classifier y = G y (f ) to reduce the shift in the joint distributions across domains, such that the target risk P r (x,y)∼q [G y (G f (x) = y] is minimized by jointly minimizing the source risk and the distribution discrepancy by a discriminated domain adaptation. At the time of training, we have access to all the source domain data along with corresponding labels S = (</p><formula xml:id="formula_2">x s i , y s i ) ns i=1 and all unlabeled target data T = (x t i ) nt i=1 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Proposed Model</head><p>In this proposed model, there are three main components: feature extractor (G f ), classifier (G c ) and informative discriminator (G d ). All the components are deep neural networks. This model is trained in an end-to-end fashion using the adversarial and classification loss. In contrast to <ref type="bibr" target="#b1">[2]</ref> and <ref type="bibr" target="#b2">[3]</ref>, instead of a binary discriminator, we use a multi class discriminator. We also do not use any prediction score to predict or adapt the target samples, and we empirically show that it is actually detrimental in the proposed model. 1) Feature Extractor (G f ): Feature extractor is a deep feed forward convolution neural network architecture consisting of different feed forward layers. The task of this module is to map the input data x in the feature space G f (x). It is parameterized by parameter θ f . We assume that input data x is mapped to a</p><formula xml:id="formula_3">D-dimensional feature vector G f (x, θ f ) ∈ R D 2) Classifier Network (G c ):</formula><p>Classifier is also a deep feed forward network, consisting of fully connected layers. It is parameterised by the θ c . In the training time, it maps the source data feature f s obtained from the feature extractor to class label y.</p><formula xml:id="formula_4">G c (f s , θ c ) ∼ Y where Y is the source class label distribution.</formula><p>This module is trained based only on the crossentropy loss between the predicted source label and the ground truth source label.</p><p>3) Discriminator Network (G d ):</p><p>The task of any discriminator is to learn the source and target discrepancy. It considers the source features f s or target features f t and help to mis-classify them as source or target label. In the proposed model, we used a multi-class discriminator, which maps the source sample to its class label value while target samples are classified as fake label. This module is parameterized by θ d . Using the reverse gradient layer, a target sample will be mis-classified as one of the source class labels. In the case of source sample, all the source samples may also be misclassified. But the loss of multi-modal structure for source is prevented by the classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Training and Loss Function</head><p>During training, there are two objectives for the model, first is to minimize the label prediction loss on the source dataset and optimize the parameters of feature extractor and classifier. Other is to make features more indistinguishable for source and target domain. For making the features indistinguishable, we reverse the gradient from the discriminator to back-propagate to the feature extractor. Our discriminator trains to classify the source class label and target domain. We reverse the gradient to make the features that are unfavorable for the discriminator.</p><p>The additional loss will encourage a target sample to be mis-classified as one of the source classes by the discriminator. In the case of binary discriminator the target sample will be mis-classified as source domain (mixing of all the classes). In contrast to the binary discriminator methods, in the proposed method, the classes will not be mixed up and will be classified as only one of the source class. For all the source samples, the discriminator mis-classifies into a single target domain, but this is already prevented by the classification module that is based on true labels for the source samples. So by the proposed model both target and source sample features are prevented from having a mode collapse.</p><formula xml:id="formula_5">loss(θ f , θ y , θ d ) = 1 n s xi∈Ds L y (G y (G f (x i )), y i )+ λ n s + n t xi∈Ds∪Dt L d (G d (G f (x i )), d i )<label>(1)</label></formula><p>where</p><formula xml:id="formula_6">d i = y i , if x i ∈ D s . |C| + 1, if x i ∈ D t .<label>(2)</label></formula><p>λ is a trade-off parameter between the two objectives and |C| is the number of source classes. L y and L d are the cross entropy loss for classifier and discriminator respectively. D s and D t are the source and target domain respectively. G f , G c and G d are the feature extractor, classifier and discriminator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. RESULTS &amp; EXPERIMENTS</head><p>In this section, we evaluate our model on various widely used benchmarks. Following the common setting in unsupervised domain adaptation, we used the Alexnet <ref type="bibr" target="#b50">[51]</ref> architecture pre-trained on the Imagenet dataset for our base model. Results are compared with the state-ofart methods such as [1]- <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b51">[52]</ref>, <ref type="bibr" target="#b52">[53]</ref>. The proposed model has been evaluated on the Office-31 <ref type="bibr" target="#b53">[54]</ref>, Office-Home datasets <ref type="bibr" target="#b52">[53]</ref>, Caltech-Bing datasets <ref type="bibr" target="#b54">[55]</ref> and ImageCLEF datasets. Other details and codes are provided in the project page https://vinodkkurmi.github.io/DiscriminatorDomainAdaptation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Office-31 dataset</head><p>Office-31 <ref type="bibr" target="#b53">[54]</ref> is a benchmark for domain adaptation, comprising 4,110 images in 31 classes collected from three distinct domains: Amazon (A), which contains images downloaded from amazon.com, Webcam (W) and DSLR (D), which contain images taken by web camera and digital SLR camera with different photographical settings, respectively. To enable unbiased evaluation, we evaluate on all the 6 possible transfer tasks such as A→W, D→ W, W→D, A→D, D→A and W→A. The performance is shown in <ref type="table" target="#tab_0">Table I</ref>. It is noteworthy that the proposed model promotes the classification accuracy substantially on hard transfer tasks, e.g., A→W and A→D, where the source and target domains are substantially different. In the 4 out of 6 shifts, it achieves the highest accuracy. For the other 2 shifts, we achieve comparable performance because in these cases the source domain has fewer examples than target domain. Therefore it becomes hard for the discriminator to learn the modes of the datasets for this case. However, we can see that average performance is better than all the other base line methods. The encouraging results highlights the importance of informative discriminator based domain adaptation in deep neural networks, and suggests that this model is able to learn more transferable representations for effective domain adaptation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Home-Office dataset</head><p>We also evaluated our model on the Office-Home dataset <ref type="bibr" target="#b52">[53]</ref> for unsupervised domain adaptation. This dataset consists of four domains, Art (Ar), Clipart (Cl), Product (Pr) and Real-World (Rw). Each domain has common 65 categories. The Art domain contains the artistic description of objects such as painting, sketches etc. The Clipart are the collection of clipart images. In the Product domain images have no background. The Real-World domain consists of object capture from the regular camera. We evaluated our model by considering the Art data as source data and remaining dataset as target dataset. So we have three adaptation tasks, Ar → Cl, Ar → Pr and Ar → Rw. The performance reported in <ref type="table" target="#tab_0">Table II</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Caltech-Bing dataset</head><p>For demonstrating the idea that if we provide more source dataset information to discriminator, it performs well, we used subset of Caltech-Bing dataset <ref type="bibr" target="#b54">[55]</ref> that consists of 43 classes with 3 parents classes as aquatic (11 classes), terrestrial (23 classes) and avian (9 classes). We call it mini-Bing (B) and mini-Caltech (C) dataset. There are total 4960 images in mini-Caltech and 20731 images in mini-Bing dataset. The performance on both task (Caltech → Bing and Bing → Caltech) are shown in <ref type="table" target="#tab_0">Table III</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. MNIST-MNIST-M dataset</head><p>We also experimented with the MNIST dataset as source data. In order to obtain the target domain (MNIST-M) <ref type="bibr" target="#b56">[57]</ref> we blend digits from the original set over patches randomly extracted from color photos from BSDS500 <ref type="bibr" target="#b57">[58]</ref>. The adaptation result is shown in the Table III.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Results on ImageCLEF Dataset</head><p>ImageCLEF-2014 dataset consists of 3 domains: Caltech-256 (C), ILSVRC 2012 (I), and Pascal-VOC 2012 (P). There are 12 common classes, and each class has 50 samples.There is a total of 600 images in each domain. We evaluate models on all 6 transfer tasks: I→P, P→I, I→C, C→I, C→P, and P→C. The results on the ImageCLEF are reported in <ref type="table" target="#tab_0">Table IV</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. ANALYSIS</head><p>In this section we provide an analysis for the proposed model using the aspects such as distribution discrepancy and statistical significant test. We further provide hyper-parameter sensitivity and feature visualization analysis. A. Target risk error minimization 1) Domain adaptation theory: As suggest by the <ref type="bibr" target="#b58">[59]</ref> the target risk error t (h) for hypothesis h is bounded by the source risk error and distribution distance.</p><formula xml:id="formula_7">t (h 1 , h 2 ) ≤ s (h 1 , h 2 ) + 1 2 d H∆H (D s , D t )<label>(3)</label></formula><p>where the source-target distance is defiend as:</p><formula xml:id="formula_8">d H∆H(Ds,Dt) = 2 sup h1,h2∈H |P Ds [ h(x) = 1]| − |P Dt [ h(x) = 1]| (4) where h(x) = h 1 (x) ⊕ h 2 (x)</formula><p>2) Symmetric hypothesis space for multi-class classification: We can construct a symmetric difference hypothesis H c ∆H c <ref type="bibr" target="#b59">[60]</ref> for multi-class hypothesis. Choose hypothesis</p><formula xml:id="formula_9">h(x) = h 1 (x) ⊕ h 2 (x) · · · ⊕ h c (x). H c ∆H c = {h|h = h 1 (x) ⊕ h 2 (x) · · · ⊕ h c (x) , h 1 , h 2 . . . h c (x) ∈ H} where c</formula><p>is the number of classes. We assume that the hypothesis space H c is the set of all hypothesis produced by the classifier. Similarly hypothesis space H d is the set of all hypothesis produced by the discriminator. Consider fixed D s and D t over the representation space produced by the feature extractor and a family of label predictors H c .  Classification accuracy on office (A→W) dataset, when we consider the most confident predicted target label (from the softmax of classifier) to train the model. Assume that the family of domain classifiers H d is rich enough to contain the symmetric difference hypothesis set of H c . In the proposed class label based discriminator this assumption not only holds but also achieves a more tighter bound than the binary discriminator used in <ref type="bibr" target="#b1">[2]</ref> d Hc∆Hc∆ (D s , D t )</p><formula xml:id="formula_10">≤ 2 sup h∈H d ∆H d |P Ds [ h(x) = 1] − P Dt [ h(x) = 1]| d Hc∆Hc∆ (D s , D t ) ≤ 2 sup h∈H d ∆H d |α(h) − 1|<label>(6)</label></formula><p>where</p><formula xml:id="formula_11">α(h) = P Ds [ h(x) = 1] + P Dt [ h(x) = 0]. Now we construct symmetric hypothesis set H d ∆H d such that h (x) = h(x) ⊕ h c+1 (x) and P Ds [ h c+1 (x) = 1] = 0 ∀x ∈ D s H d ∆H d = {h|h = h 1 (x) ⊕ h 2 (x) · · · ⊕ h c (x) ⊕ h c+1 , h 1 , h 2 . . . h c (x), h c+1 ∈ H} α(h) ≤ P Ds∪Dt [ h (x) = 1] = α(h )<label>(7)</label></formula><p>where c is the number of classes. The hypothesis h is achieved by the class based domain discriminator model G d . Thus, optimal discriminator gives the upper bound for H c ∆H c At the same time, back propagation of the reversed gradient changes the representation space so that α(G d ) becomes smaller effectively reducing d Hc∆Hc (D s , D t ) and leading to the better approximation of s (h) by t (h).</p><p>3) Distribution discrepancy: The domain adaptation theory <ref type="bibr" target="#b58">[59]</ref> suggests A-distance as a measure of cross domain discrepancy, which, together with the source risk, will bound the target risk. The proxy A-distance is defined as d A = 2(1−2 ), where is the generalization error of a classifier (e.g. kernel SVM) trained on the binary task of discriminating source and target. <ref type="figure">Figure 7</ref> shows d A on tasks A →D and A →W, with features of source only model, Binary discriminator <ref type="bibr" target="#b1">[2]</ref>, and proposed informative discriminator model. We observe that d A using our model features is much smaller than d A using source only model and RevGrad(binary discriminator) <ref type="bibr" target="#b1">[2]</ref> features, which suggests that our features can reduce the cross-domain gap more effectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Statistical significance analysis</head><p>We have analysed statistical significance <ref type="bibr" target="#b60">[61]</ref> for our proposed informative discriminator method against binary label discriminator <ref type="bibr" target="#b1">[2]</ref> and source only method for the domain adaptation task. The Critical Difference (CD) for Nemenyi test depends upon the given confidence level (which is 0.05 in our case) for average ranks and number of tested datasets. If the difference in the rank of the two methods lies within CD (in our case CD = 0.6051), then they are not significantly different. <ref type="figure">Figure 6</ref> visualizes the post hoc analysis using the CD diagram for A → D, A → W and B → C dataset respectively. From the figures, it is clear that our Informative discriminator (IDDA) is best and is significantly different from the GRL(binary discriminator) <ref type="bibr" target="#b1">[2]</ref> and source only model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Feature visualization</head><p>Adaptability of target to source features can be visualized using the t-SNE embeddings of images feature. We follow similar setting in <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref> and <ref type="bibr" target="#b2">[3]</ref> and plot t-SNE embeddings of the MNIST → MNIST-M dataset in the Figures 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Parameter sensitivity for discriminator accuracy</head><p>We also investigate the effects of the value of parameter λ ∈ {0, 0.1, 0.4, 0.7, 1, 1.4, 1.7, 2}. We plot in <ref type="figure">Figure 4</ref> the discriminator accuracy on target data (classifying source v/s target domain) with respect to value of λ on tasks Amazon → Webcam. Observe that discriminator accuracy first decreases and then increases as λ varies and demonstrates a U -shaped curve. We choose λ = 1 where the discriminator accuracy are lowest, i.e source and target domain are more indistinguishable. In this experiment we do not use any target labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Empirical evaluation of model by using predicted labels</head><p>In a recent work <ref type="bibr" target="#b2">[3]</ref>, the authors considered the use of predicted target information. In order to validate the idea of using target class prediction label in the proposed model, we consider them in following ways: 1) Using 2N class discriminator: In this case we construct the discriminator for classifying is 2N classes, where N is the number of class label in the dataset. Here each sample is classify by the discriminator from the 2N classes (it could belong to source class label or target class label). For the source data, we used the provided source data label, while in the case of target we used the soft-max output of target prediction probability from the classifier (C). Results for the three task of office dataset are shown in the <ref type="figure" target="#fig_2">Figure 2</ref>. We observed that use of predicted target information actually results in reduced performance.</p><p>2) Using only confident target samples: We experimented for A →W by taking the target samples which are more certain about the class (using the classification softmax probability). We observed that in our cases avoiding use of target labels is better than using predictions. <ref type="figure" target="#fig_3">Figure 3</ref> shows the result for different threshold value for which, we consider that target sample to train the discriminator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSION</head><p>We proposed a method for obtaining an informative discriminator that aids improved domain adaptation. Our analysis showed that this discriminator indeed helps us in obtaining statistically significant improvement that can also be justified theoretically. We further observed through visualization that domain adapted features do result in domain invariant feature representations. In future, we aim to further explore relations with respect to structured source representations that can yield improved domain adaptation. To some extent, we have already justified this through the use of hierarchical classifiers. The incorporation of structure in source and correlating that with the target structure is a promising direction which we have initiated through this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. ACKNOWLEDGEMENT</head><p>The author Vinod Kumar Kurmi acknowledges support from TCS Research Scholarship Program.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>The proposed architecture includes a deep feature extractor (G f ), classifier (Gc) and discriminator (G d ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>s labeled examples and a target domain, T = (x t i ) nt i=1 of n t unlabeled examples. The labels are not provided. The source domain and target domain are sampled from joint distributions P</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>dFig. 2 .</head><label>2</label><figDesc>Hc∆Hc∆ (D s , D t ) = 2 sup h∈Hc∆Hc |P Ds [ h(x) = 1]| − |P Dt [ h(x) = 1]| (5) Classification accuracy on office dataset (A→W, D→W and W→D), when we use the predicted target label(from the softmax of classifier) in the discriminator.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Classification accuracy on office (A→W) dataset, when we consider the most confident predicted target label (from the softmax of classifier) to train the model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .Fig. 5 .</head><label>45</label><figDesc>Sensitivity on the λ experiment. Discriminator accuracy with respect to λ on office (A→W) dataset. Here λ = 1.0 gives the lowest accuracy , which is desired in the domain adaptation task (a) Before Adaptation (b) After Adaptation The effect of adaptation on the distribution of the extracted features (best viewed in color) for MNIST → MNIST-M dataset. The figure shows t-SNE visualizations of the CNN's activation (a) in case when no adaptation was performed and (b) in case when our adaptation procedure was incorporated into training. yellow points correspond to the source domain examples (MNIST data), while violet ones correspond to the target domain (MNIST-M). Adaptation makes the two distributions of features much closer</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .Fig. 7 .</head><label>67</label><figDesc>Analysis of statistically significant difference for (a)A → D, (b)A → W and (c)B → C in Source only, Binary label Discriminator (GRL) [2] and proposed model (IDDA), with a significance level of 0.05. The mean rank is plotted on x-axis. The CD is 0.6051 and all the methods are way outside the CD, so are statistically significant over source only trained model. We can see IDDA is statistically significantly over GRL in all 3 adaptation tasks . (a) A → W (b)A → D Proxy A-distance for Amazon → Webcam and Amazon → DSLR tasks for method Source only, Binary discriminator [2] and proposed model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I CLASSIFICATION</head><label>I</label><figDesc>ACCURACY EVALUATION OF DIFFERENT DOMAIN ADAPTATION APPROACHES ON THE STANDARD OFFICE-31 [54] DATASET. ALL METHODS ARE EVALUATED IN THE "FULLY-TRANSDUCTIVE" PROTOCOL USING THE ALEXNET PRETRAINED [51] MODEL. OUR METHOD (LAST ROW) OUTPERFORMS COMPETITORS ON THE THREE ADAPTATION TASK.</figDesc><table><row><cell>Method</cell><cell>A → W</cell><cell>D → W</cell><cell>W → D</cell><cell>A → D</cell><cell>D → A</cell><cell>W → A</cell><cell>Avg</cell></row><row><cell>DDC [1]</cell><cell>61.0 ± 0.5</cell><cell>95.0 ± 0.3</cell><cell>98.5 ± 0.3</cell><cell>64.9 ± 0.4</cell><cell>47.2 ± 0.5</cell><cell>49.4 ± 0.4</cell><cell>69.3</cell></row><row><cell>DAN [4]</cell><cell>68.5 ± 0.3</cell><cell>96.0 ± 0.1</cell><cell>99.0 ± 0.1</cell><cell>66.8 ± 0.2</cell><cell>50.0 ± 0.4</cell><cell>49.8 ± 0.3</cell><cell>71.6</cell></row><row><cell>DeepCoral [9]</cell><cell>66.4 ± 0.4</cell><cell>95.7 ± 0.3</cell><cell>99.2 ± 0.1</cell><cell>66.8 ± 0.6</cell><cell>52.8 ± 0.2</cell><cell>51.5 ± 0.3</cell><cell>72.0</cell></row><row><cell>WDAN [6]</cell><cell>66.9 ± 0.2</cell><cell>95.9 ± 0.2</cell><cell>99.0 ± 0.1</cell><cell>64.4 ± 0.2</cell><cell>53.8 ± 0.1</cell><cell>52.7 ± 0.2</cell><cell>72.1</cell></row><row><cell>DHN [53]</cell><cell>68.3 ± 0.0</cell><cell>96.1 ± 0.0</cell><cell>98.8 ± 0.0</cell><cell>66.4 ± 0.0</cell><cell>55.5 ± 0.0</cell><cell>53.0 ± 0.0</cell><cell>73.0</cell></row><row><cell>DRCN [52]</cell><cell>68.7 ± 0.3</cell><cell>96.4 ± 0.3</cell><cell>99.0 ± 0.2</cell><cell>66.8 ± 0.5</cell><cell>56.0 ± 0.5</cell><cell>54.9 ± 05</cell><cell>73.6</cell></row><row><cell>RTN [7]</cell><cell>73.3 ± 0.2</cell><cell>96.8 ± 0.2</cell><cell>99.6 ± 0.1</cell><cell>71.0 ± 0.2</cell><cell>50.5 ± 0.3</cell><cell>51.0 ± 0.1</cell><cell>73.7</cell></row><row><cell>GRL [2]</cell><cell>73.0 ± 0.5</cell><cell>96.4 ± 0.3</cell><cell>99.2 ± 0.3</cell><cell>72.3 ± 0.3</cell><cell>52.4 ± 0.4</cell><cell>50.4 ± 0.5</cell><cell>73.9</cell></row><row><cell>I2I [19]</cell><cell>75.3 ± 0.0</cell><cell>96.5 ± 0.0</cell><cell>99.6 ± 0.0</cell><cell>71.1 ± 0.0</cell><cell>50.1 ± 0.0</cell><cell>52.1 ± 0.0</cell><cell>74.1</cell></row><row><cell>JAN [5]</cell><cell>75.2 ± 0.4</cell><cell>96.6 ± 0.2</cell><cell>99.6 ± 0.1</cell><cell>72.8 ± 0.3</cell><cell>57.5 ± 0.2</cell><cell>56.3 ± 0.2</cell><cell>76.3</cell></row><row><cell>CDAN [38]</cell><cell>77.9 ± 0.3</cell><cell>96.9 ± 0.2</cell><cell>100.0 ± 0.0</cell><cell>74.6 ± 0.2</cell><cell>55.1 ± 0.3</cell><cell>57.5 ± 0.4</cell><cell>77.0</cell></row><row><cell>ADIAL [32]</cell><cell>75.5 ± 0.0</cell><cell>96.6 ± 0.0</cell><cell>99.5 ± 0.0</cell><cell>73.6 ± 0.0</cell><cell>58.1 ± 0.0</cell><cell>59.4 ± 0.0</cell><cell>77.1</cell></row><row><cell>MADA [3]</cell><cell>78.5 ± 0.2</cell><cell>99.8 ± 0.1</cell><cell>100.0 ± 0.0</cell><cell>74.1 ± 0.1</cell><cell>56.0 ± 0.2</cell><cell>54.5 ± 0.3</cell><cell>77.1</cell></row><row><cell>IDDA[ours]</cell><cell>82.2 ± 0.8</cell><cell>99.8 ± 0.2</cell><cell cols="2">100.0 ± 0.0 82.4 ± 0.5</cell><cell>54.1 ± 0.4</cell><cell>52.5 ± 0.3</cell><cell>78.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE IV CLASSIFICATION</head><label>IV</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell cols="5">ACCURACY (%) ON ImageCLEF DATASET FOR</cell><cell></cell></row><row><cell cols="7">UNSUPERVISED DOMAIN ADAPTATION (ALEXNET [51])</cell><cell></cell></row><row><cell>Method</cell><cell>I→P</cell><cell>P→I</cell><cell>I→C</cell><cell>C→I</cell><cell cols="2">C→P P→C</cell><cell>Avg</cell></row><row><cell cols="2">AlexNet [51] 66.2</cell><cell>70.0</cell><cell>84.3</cell><cell>71.3</cell><cell>59.3</cell><cell>84.5</cell><cell>73.9</cell></row><row><cell>DAN [4]</cell><cell>67.3</cell><cell>80.5</cell><cell>87.7</cell><cell>76.0</cell><cell>61.6</cell><cell>88.4</cell><cell>76.9</cell></row><row><cell>GRL [2]</cell><cell>66.5</cell><cell>81.8</cell><cell>89.0</cell><cell>79.8</cell><cell>63.5</cell><cell>88.7</cell><cell>78.2</cell></row><row><cell>RTN [7]</cell><cell>67.4</cell><cell>82.3</cell><cell>89.5</cell><cell>78.0</cell><cell>63.0</cell><cell>90.1</cell><cell>78.4</cell></row><row><cell>MADA [3]</cell><cell>68.3</cell><cell>83.0</cell><cell>91.0</cell><cell>80.7</cell><cell>63.8</cell><cell>92.2</cell><cell>79.8</cell></row><row><cell>IDDA</cell><cell>68.3</cell><cell>81.8</cell><cell>92.3</cell><cell>81.6</cell><cell>67.2</cell><cell>92.8</cell><cell>80.6</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Deep domain confusion: Maximizing for domain invariance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.3474</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation by backpropagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1180" to="1189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Multi-adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning transferable features with deep adaptation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="97" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deep transfer learning with joint adaptation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2208" to="2217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Mind the class weight bias: Weighted maximum mean discrepancy for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2272" to="2281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation with residual transfer networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="136" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Correlation alignment for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Domain Adaptation in Computer Vision Applications</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep coral: Correlation alignment for deep domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="443" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Return of frustratingly easy domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Wasserstein distance guided representation learning for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Wasserstein generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="214" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Associative domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haeusser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Frerix</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mordvintsev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Unsupervised visual domain adaptation using subspace alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Habrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sebban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2960" to="2967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation with similarity learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">O</forename><surname>Pinheiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8004" to="8013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Domain generalization for object recognition with multi-task autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghifary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bastiaan Kleijn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Balduzzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2551" to="2559" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning from synthetic data: Addressing domain shift for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">N</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Image to image translation for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Murez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kolouri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kriegman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ramamoorthi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4500" to="4509" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Unsupervised pixel-level domain adaptation with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bousmalis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Silberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Stargan: Unified generative adversarial networks for multi-domain image-to-image translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Generate to adapt: Aligning domains using generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Detach and adapt: Learning cross-domain disentangled deep representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Y</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-C</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-C</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C. Frank</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Cycada: Cycle-consistent adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Unpaired image-toimage translation using cycle-consistent adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Multimodal differential network for visual question generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">N</forename><surname>Patro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">K</forename><surname>Kurmi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Namboodiri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4002" to="4012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Domain separation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bousmalis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Trigeorgis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Silberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="343" to="351" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Beyond sharing weights for deep domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rozantsev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Asymmetric tri-training for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ushiku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2988" to="2997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Residual parameter transfer for deep domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rozantsev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4339" to="4348" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Revisiting batch normalization for practical domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Autodial: Automatic domain alignment layers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Carlucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Porzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bulò</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Maximum classifier discrepancy for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ushiku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3723" to="3732" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Adversarial dropout regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ushiku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Harada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.01575</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Deep adversarial attention alignment for unsupervised domain adaptation: the benefit of target expectation maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Differential attention for visual question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Patro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">P</forename><surname>Namboodiri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7680" to="7688" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Adversarial discriminative domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Conditional adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1645" to="1655" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Partial adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Domain generalization with adversarial feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Kot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit.(CVPR)</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit.(CVPR)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Collaborative and adversarial network for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3801" to="3809" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Adversarial feature augmentation for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Volpi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Morerio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Murino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5495" to="5504" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Re-weighted adversarial adaptation network for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Wassell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chetty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7976" to="7985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Importance weighted adversarial nets for partial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ogunbona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8156" to="8164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Adversarial adaptation of scene graph models for understanding civic issues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Atreja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jain</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.10124</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Can subclasses help a multiclass learning problem?&quot; in Intelligent Vehicles Symposium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="page" from="214" to="219" />
			<date type="published" when="2008" />
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Using subclasses to improve classification learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Compton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Machine Learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="203" to="213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Learning semantic sentence embeddings using sequential pair-wise discriminator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">N</forename><surname>Patro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">K</forename><surname>Kurmi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Namboodiri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2715" to="2729" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Conditional image synthesis with auxiliary classifier gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2642" to="2651" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06434</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Deep reconstruction-classification networks for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghifary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">B</forename><surname>Kleijn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="597" to="613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Deep hashing network for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Venkateswara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Eusebio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Panchanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5018" to="5027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Adapting visual category models to new domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="213" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Exploiting weakly-labeled web images to improve object classification: a domain adaptation approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bergamo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Torresani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="181" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Graph adaptive knowledge transfer for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="37" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Contour detection and hierarchical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Arbelaez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="898" to="916" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">A theory of learning from different domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Vaughan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="151" to="175" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Learning bounds for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wortman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="129" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Statistical comparisons of classifiers over multiple data sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Demšar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine learning research</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
