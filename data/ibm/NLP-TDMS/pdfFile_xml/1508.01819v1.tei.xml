<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Spectral Clustering and Block Models: A Review And A New Algorithm</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2015-08-07">7 Aug 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharmodeep</forename><surname>Bhattacharyya</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Bickel</surname></persName>
						</author>
						<title level="a" type="main">Spectral Clustering and Block Models: A Review And A New Algorithm</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2015-08-07">7 Aug 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We focus on spectral clustering of unlabeled graphs and review some results on clustering methods which achieve weak or strong consistent identification in data generated by such models. We also present a new algorithm which appears to perform optimally both theoretically using asymptotic theory and empirically. <ref type="bibr" target="#b2">3</ref> where P = [P ab ] and B = [B ab ] are K × K symmetric matrices. We call P the connection probability matrix and B the kernel matrix for the connection. So, we have P ab ≤ 1 for all a, b = 1, . . . , K, P1 ≤ 1 and 1 T P ≤ 1 element-wise.</p><p>By definition A ji = A i j , and A ii = 0 (no self-loops).</p><p>This formulation is a reparametrization due to <ref type="bibr" target="#b9">Bickel and Chen (2009)</ref> [8] of the definition of Holland and Leinhardt <ref type="bibr" target="#b21">[20]</ref>. It permits separate consideration asymptotically of the density of the graph and its structure as follows:</p><p>P (Vertex 1 belongs to block a and vertex 2 to block b and are connected) = π a π b P ab with P ab depending on n. P ab = ρ n min(B ab , 1/ρ n ). We can interpret ρ n as the unconditional probability of an edge and B ab essentially as P (Vertex 1 belongs to a and vertex 2 belongs to b| an edge between 1 and 2) .</p><p>Set Π = diag(π 1 , . . . , π K ).</p><p>1. Define the matrices as M = Π B and S = Π 1/2 BΠ 1/2 . 2. Note that the eigenvalues of M are the same as the symmetric matrix S and in particular are real-valued.</p><p>3. The eigenvalues of the expected adjacency matrixĀ ≡ E(A) are also the same as those of S but with multiplicities. We denote the eigenvalues by their absolute order, λ 1 ≥ |λ 2 | ≥ · · · ≥ |λ K |.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Since its introduction in <ref type="bibr" target="#b16">[15]</ref>, spectral analysis of various matrices associated to groups has become one of the most widely used clustering techniques in statistics and machine learning.</p><p>In the context of unlabeled graphs, a number of methods, all of which come under the broad heading of spectral clustering have been proposed. These methods based on spectral analysis of adjacency matrices or some derived matrix such as one of the Laplacians ( <ref type="bibr" target="#b33">[31]</ref>, <ref type="bibr" target="#b30">[28]</ref>, <ref type="bibr" target="#b24">[23]</ref>, <ref type="bibr" target="#b31">[29]</ref>, <ref type="bibr" target="#b34">[32]</ref>) have been studied in connection with their effectiveness in identifying members of blocks in exchangeable graph block models. In this paper after introducing the methods and models, we intend to review some of the literature. We relate it to the results of Mossel, Neeman and Sly (2012) <ref type="bibr" target="#b28">[26]</ref> and <ref type="bibr" target="#b26">Massoulié (2014)</ref>  <ref type="bibr" target="#b26">[24]</ref>, where it is shown that for very sparse models, there exists a phase transition below which members cannot be identified better than chance and also showed that above the phase transition one can do better using rather subtle methods. In <ref type="bibr" target="#b5">[6]</ref> we develop a spectral clustering method based on the matrix of geodesic distances between nodes which can achieve the goals of the work we cited and in fact behaves well for all unlabeled networks, sparse, semisparse and dense. We give a statement and sketch the proof of these claims in [] but give a full argument for the sparse case considered by the above authors only in this paper. We give the necessary preliminaries in Section 2, more history in Section 3 and show the theoretical properties of the method in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries</head><p>There are many standard methods of clustering based on numerical similarity matrices which are discussed in a number of monographs (Eg:Hartigan <ref type="bibr" target="#b20">[19]</ref>, Leroy and Rousseuw <ref type="bibr" target="#b32">[30]</ref>). We shall not discuss these further. Our focus is on unlabeled graphs of n vertices characterized by adjacency matrices, A = ||a i j || for n data points. With a i j = 1 if there is an edge between i and j and a i j = 0 otherwise. The natural assumption then is, A = A T . Our basic goal is to divide the points in K sets such that on some average criterion the points in a given subset are more similar to each other than to those of other subsets. Our focus is on methods of clustering based on the spectrum (eigenvalues and eigenvectors) of A or related matrices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Notation and Formal Definition of Stochastic Block Model</head><p>Definition 1. A graph G K (B, (P, π)) generated from the stochastic block model (SBM) with K blocks and parameters P ∈ (0, 1) K×K and π ∈ (0, 1) K can be defined in following way -each vertex of graph G n is assigned to a community c ∈ {1, . . . , K}. The (c 1 , . . . , c n ) are independent outcomes of multinomial draws with parameter π = (π 1 , . . . , π K ), where π i &gt; 0 for all i. Conditional on the label vector c ≡ (c 1 , . . . , c n ), the edge variables A i j for i &lt; j are independent Bernoulli variables with E[A i j |c] = P c i c j = min{ρ n B c i c j , 1},</p><p>Let us denote (ϕ 1 , . . . , ϕ K ), ϕ i ∈ R K , as the eigenvectors of S corresponding to the eigenvalues λ 1 , . . . , λ K . If a set of λ j 's are equal to λ , we choose eigenvectors from the eigenspace corresponding to the λ as appropriate. Then, we have, φ i = Π −1/2 ϕ i and ψ i = Π 1/2 ϕ i as the left and right eigenvectors of M. Also, φ i , φ j π = ∑ K k=1 π k φ ik φ jk = δ i j . The spectral decomposition of M, S and B are</p><formula xml:id="formula_1">B = K ∑ k=1 λ k φ k φ T k , S = K ∑ k=1 λ k ϕ k ϕ T k , M = K ∑ k=1 λ k ψ k φ T k .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Spectral Clustering</head><p>The basic goal of community detection is to infer the node labels c from the data.</p><p>Although we do not explicitly consider parameter estimation, they can be recovered fromĉ, an estimate of (c 1 , . . . , c n ) by</p><formula xml:id="formula_2">P ab ≡ 1 O ab n ∑ i=1 n ∑ j=1 A i j 1 (ĉ i = a,ĉ j = b) , 1 ≤ a, b ≤ K,<label>(2)</label></formula><p>where,</p><formula xml:id="formula_3">O ab ≡ n a n b , 1 ≤ a, b ≤ K, a = b n a (n a − 1), 1 ≤ a ≤ K, a = b , n a ≡ n ∑ i=1 1 (ĉ i = a) , 1 ≤ a ≤ K</formula><p>There are a number of approaches for community detection based on modularities ( <ref type="bibr" target="#b19">[18]</ref>, <ref type="bibr" target="#b9">[8]</ref>), maximum likelihood and variational likelihood ( <ref type="bibr" target="#b12">[11]</ref>, <ref type="bibr" target="#b6">[7]</ref>) and approximations such as semidefinite programming approaches <ref type="bibr" target="#b2">[3]</ref>, pseudolikelihood <ref type="bibr" target="#b1">[2]</ref> but these all tend to be computationally intensive and/or require good initial assignments of blocks. The methods which have proved both computationally effective and asymptotically correct in a sense we shall discuss are related to spectral analysis of the adjacency or related matrices.They differ in important details.</p><p>Given an n × n symmetric matrix M based on A, the algorithms are of the form:</p><p>1. Using the spectral decomposition of M or a related generalized eigenproblem.</p><p>2. Obtain an n × K matrix of K n × 1 vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Apply K means clustering to the n K-dimensional row vectors of the matrix of</head><p>Step 2.</p><p>4. Identify the indices of the rows belonging to cluster j , j = 1, . . . , K with vertices belonging to block j.</p><p>In addition to A, three graph Laplacian matrices discussed by von Luxburg (2007) <ref type="bibr" target="#b35">[33]</ref>, have been considered extensively, as well as some others we shall mention briefly below and the matrix we shall show has optimal asymptotic properties and discuss in greater detail. The matrices popularly considered are:</p><p>• L = D − A: the graph Laplacian.</p><p>• L rw = D −1 A: the random walk Laplacian.</p><p>• L sym = D −1/2 AD −1/2 : the symmetric Laplacian.</p><p>Here D = diag(A1), the diagonal matrix whose diagonal is the vector of row sums of A. She considers optimization problems which are relaxed versions of combinatorial problems which implicitly define clusters as sets of nodes with more internal than external edges. L and L sym appear in two of these relaxations.</p><p>The form of step 2 differs for L and Lsym with the K vectors of the L problem corresponding to the top K eigenvalues of the generalized eigenvalue problem Lv = λ Dv ,while the n K-dimensional vectors of the L sym problem are obtained by normalizing the rows of the matrix of K eigenvectors corresponding to the top K eigenvalues of L sym . Their relation to the K block model is through asymptotics. Why is spectral clustering expected to work? Given A generated by a K-block model, let c ↔ (n 1 , . . . , n K ) where, n a is the number of vertices assigned to type a. Then we can write,</p><formula xml:id="formula_4">E(A|c) = PQP T</formula><p>where, P is a permutation matrix and Q n×n has succesive blocks of n 1 rows, n 2 rows and so on with all the vectors in each row the same. Thus rank(E(A|c) = K. The same is true of the asymptotic limit of L given c. If asymptotics as n → ∞ justify concentration of A or L around their expectations then we expect all eigenvalues other than the largest K in absolute value are small. It follows that the n rows of the K eigenvectors associated with the top K eigenvalues should be resolvable into K clusters in R K with cluster members identified with rows of A n×n , see <ref type="bibr" target="#b31">[29]</ref>, <ref type="bibr" target="#b34">[32]</ref> for proofs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Asymptotics</head><p>Now we can consider several asymptotic regimes as n → ∞. Let λ n = nρ n be the average degree of the graph.</p><p>(I) The dense regime: λ n = Ω (n).</p><p>(II) The semi dense regime: λ n /log(n) → ∞.</p><p>(III) The semi sparse regime: Not semidense but λ n → ∞.</p><p>(IV)The sparse regime: λ n = O <ref type="bibr" target="#b0">(1)</ref>.</p><p>Here are some results in the different regimes. We define a method of vertex assignment to communities as a random map δ : {1, . . ., n} → {1, . . . , K} where randomness comes through the dependence of delta on A as a function. Thus spectral clustering using the various matrices which depend on A is such a δ . Definition 2. δ is said to be strongly consistent if P(i belongs to a and δ (i) = a for all i, a) → 1 as n → ∞.</p><p>Note that the blocks are only determined up to permutation. <ref type="bibr" target="#b9">Bickel and Chen (2009)</ref>  <ref type="bibr" target="#b9">[8]</ref> show that in the (semi) dense regime a method called profile likelihood is strongly consistent under minimal identifiability conditions and later this result was extended <ref type="bibr" target="#b6">[7]</ref> to fitting by maximum likelihood or variational likelihood. In fact, in the (semi) dense regime, the block model likelihood asymptotically agrees with the joint likelihood of A and vertex block identities so that efficient estimation of all parameters is possible. It is easy to see that the result cannot hold in the (semi)sparse regime since isolated points then exist with probability 1.</p><p>Unfortunately all of these methods are computationally intensive. Although spectral clustering is not strongly consistent, a slight variant, reassigning vertices in any cluster a which are maximally connected to another cluster b rather than a , is strongly consistent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 3. δ is said to be weakly consistent if and only if</head><formula xml:id="formula_5">W ≡ n −1 n ∑ i=1 P (i ∈ a, δ (i) = a|∀i, a) = o(1)</formula><p>Spectral clustering applied to A <ref type="bibr" target="#b34">[32]</ref> or the Laplacians ( <ref type="bibr" target="#b31">[29]</ref> in the manner we have described) has been shown to be weakly consistent in the semi dense to dense regimes. Even weak consistency fails for parts of the sparse regime <ref type="bibr" target="#b0">[1]</ref>. The best that can be hoped for is W &lt; 1 2 . A sharp problem has been posed and eventually resolved in a series of papers, Decelle et al <ref type="bibr" target="#b15">[14]</ref>, Mossel et al <ref type="bibr" target="#b29">[27]</ref>. These writers considered the case K = 2, π 1 = π 2 , B 11 = B 22 . First, Decelle et al. <ref type="bibr" target="#b15">[14]</ref> argued on physical grounds that if, F = 2(B 11 − B 12 ) 2 /(B 11 + B 12 ) ≤ 1, then W ≥ 1/2 for any method and parameters are unestimable from the data even if they satisfy the minimal identifiability conditions given below. On the other hand Mossel et al <ref type="bibr" target="#b29">[27]</ref> and independently Massoulie et al <ref type="bibr" target="#b26">[24]</ref>, devised admittedly slow methods such that if F &gt; 1 then W &lt; 1/2 and parameters can be estimated consistently.</p><p>We now present a fast spectral clustering method given in greater detail in <ref type="bibr" target="#b5">[6]</ref> which yields weak consistency for the semisparse regime on and also has the properties of the Mossel et al and Massoulie methods. In fact, it reaches the phase transition threshold for all K not just K=2, but still restricted to π j = 1/K, all j and</p><formula xml:id="formula_6">B aa + 2 ∑[Bab : b = a] independent of a for all a.</formula><p>We note that Zhao et. al. (2015) <ref type="bibr" target="#b18">[17]</ref> exhibit a two-stage algorithm which exhibits the same behavior but its properties in sparse case are unknown. The algorithm given in the next section involves spectral clustering of a new matrix, that of all geodesic distances between i and j.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Algorithm</head><p>As usual let G n , an undirected graph on n vertices be the data. denote the vertex set by V (G n ) ≡ {v 1 , . . . , v n } and the edge set by E(G n ) ≡ {e 1 , . . . , e m } with cardinalities |V (G n )| = n and E(G n )| = m.</p><p>As usual a path between vertices u and v is a set of edges</p><formula xml:id="formula_7">{(u, v 1 ), (v 1 , v 2 ), . . . , (v ℓ−1 , v)}</formula><p>and the length of such a path is ℓ.</p><p>The algorithm we propose depends on the graph distance or geodesic distance between vertices in a graph. 2. Perform hierarchical clustering to identify the giant component G C of graph G.</p><p>Let n C = |V (G C )|.</p><p>3. Normalize the graph distance matrix on G C , D C bȳ</p><formula xml:id="formula_8">D C = − I − 1 n C 11 T (D C ) 2 I − 1 n C 11 T 4. Perform eigenvalue decomposition onD C . 5.</formula><p>Consider the top K eigenvectors of normalized distance matrixD C andW be the n × K matrix formed by arranging the K eigenvectors as columns inW. Perform K-means clustering on the rowsW, that means, find an n × K matrix C, which has K distinct rows and minimizes ||C −W|| F . General theoretical results on the algorithm will be given in <ref type="bibr" target="#b5">[6]</ref>. In this paper, we first restrict to the sparse regime We do so because the arguments in the sparse regime are essentially different from the others. Curiously, it is in the sparse and part of the semi-sparse regime only that the matrixD C concentrates to an n × n matrix with K distinct types of row vectors as for the other methods of spectral clustering. It does not concentrate in the dense regime, while the opposite is true of A and L.</p><p>They do not concentrate outside the semidense regime. That the geodesic matrix does not concentrate in the dense regime can easily be seen since asymptotically all geodesic paths are of constant length. But the distributions of path lengths differs from block to block ensuring that the spectral clustering works. But we do not touch this further here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Theoretical Results</head><p>Throughout this section we take ρ n = 1 n and specialize to the case</p><formula xml:id="formula_9">B = (p − q)I K×K + q11 T</formula><p>where, I is the identity and 1 = (1, . . . , 1) T . That is, all K blocks have the same probability p of connecting two block members and probability q of connecting members of two different blocks and p &gt; q. We also assume that π a = 1 K , a = 1, . . . , K, all blocks are asymptotically of the same size. We restrict ourselves to this model here because it is the one treated by Mossel, Neeman and Sly (2013) <ref type="bibr" target="#b29">[27]</ref> and already subtle technical details are not obscured. Here is the result we prove. Theorem 1. For the given model, if</p><formula xml:id="formula_10">(p − q) 2 &gt; K(p + (K − 1)q),<label>(3)</label></formula><p>and our algorithm is applied,ĉ results and c is the true assignment function, then,</p><formula xml:id="formula_11">1 n n ∑ i=1 1 (c(v i ) =ĉ(v i )) &lt; 1 2 → 1<label>(4)</label></formula><p>Notes:</p><p>1.</p><p>(3) marks the phase transition conjectured by <ref type="bibr" target="#b15">[14]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">A close reading of our proof shows that as</head><formula xml:id="formula_12">(p − q) 2 /K(p + (K − 1)q) → ∞, 1 n ∑ n i=1 1 (c(v i ) =ĉ(v i )) P → 0.</formula><p>We conjecture that our conclusion in fact holds under the following conditions, (A1) We consider λ 1 &gt; 1, λ 1 &gt; max j≥2 λ j , 1 ≤ j ≤ K and λ K &gt; 0. For M, there exists a k such that (M k ) ab &gt; 0 for all a, b = 1, . . . , K. Also, π j &gt; 0, for j = 1, . . . , K. (A2) Each vertex has the same asymptotic average degree α &gt; 1, that is,</p><formula xml:id="formula_13">α = K ∑ k=1 π k B ak = K ∑ k=1 M ak , for all a ∈ {1, . . . , K} (A3) We assume that λ 2 K &gt; λ 1</formula><p>or alternatively, there exists real positive t, such that,</p><formula xml:id="formula_14">K ∑ k=1 φ k (a)λ t k φ k (b) ≤ n, for all a, b = 1, . . . , K</formula><p>Note that (A1)-(A3) all hold for the case we consider. In fact, under our model,</p><formula xml:id="formula_15">λ 1 = p + (K − 1)q K , λ 2 = p − q K , λ 2 = λ 3 = · · · = λ K</formula><p>with (A3) being the condition of the Theorem.</p><p>Our argument will be stated in a form that is generalizable and we will indicate revisions in intermediate statements as needed, pointing in particular to a lemma whose conclusion only holds if an implication of (A3) we conjecture is valid.</p><p>The theoretical analysis of the algorithm has two main parts -I. Finding the limiting distribution of graph distance between two typical vertices of type a and type b (where, a, b = 1, . . . , K). This part of the analysis is highly dependent on results from multi-type branching processes and their relation with stochastic block models. The proof techniques and results are borrowed from <ref type="bibr" target="#b10">[9]</ref>, <ref type="bibr" target="#b4">[5]</ref> and <ref type="bibr" target="#b3">[4]</ref>. II. Finding the behavior of the top K eigenvectors of the graph distance matrix D using the limiting distribution of the typical graph distances. This part of analysis is highly dependent on perturbation theory of linear operators. The proof techniques and results are borrowed from <ref type="bibr" target="#b23">[22]</ref>, <ref type="bibr" target="#b13">[12]</ref> and <ref type="bibr" target="#b34">[32]</ref>.</p><p>We will state two theorems corresponding to I and II above.</p><p>Theorem 2. Under our model, the graph distance d G (u, v) between two uniformly chosen vertices of type a and b respectively, conditioned on being connected, satisfies the following asymptotic relation -</p><formula xml:id="formula_16">(i) If a = b, for any ε &gt; 0, as n → ∞, P [(1 − ε)τ 1 ≤ d G (u, v) ≤ (1 + ε)τ 1 ] = 1 − o(1)<label>(5)</label></formula><p>where, τ 1 is the minimum real positive t, which satisfies the relation below,</p><formula xml:id="formula_17">λ t 2 + λ t 1 − λ t 2 K = n (6) (ii)If a = b, for any ε &gt; 0, as n → ∞, P [(1 − ε)τ 2 ≤ d G (u, v) ≤ (1 + ε)τ 2 ] = 1 − o(1)<label>(7)</label></formula><p>where, τ 2 is the minimum real positive t, which satisfies the relation below,</p><formula xml:id="formula_18">λ t 1 − λ t 2 K = n<label>(8)</label></formula><p>In Theorem 2 we have a point-wise result. To use matrix perturbation theory for part II we need the following. </p><formula xml:id="formula_19">P D log n − D F ≤ o(n) = 1 − o(1) where, D i j ≡ σ 1 = τ 1 / log n,</formula><p>if v i and v j have same type and D i j ≡ σ 2 = τ 2 / log n, otherwise, where, τ 1 and τ 2 are solutions t in Eq. <ref type="formula">(6)</ref> and <ref type="formula" target="#formula_18">(8)</ref> respectively.</p><p>To generalize Theorem 1, we need appropriate generalizations of Theorem 2 and 3.</p><p>Heuristically, it may be argued that the generalizations (τ sb ), a, b = 1, . . . , K should satisfy the equations,</p><formula xml:id="formula_20">K ∑ k=1 φ k (a)λ t k φ k (b) = (S t ) ab = n, for a ≤ b ∈ [K]<label>(9)</label></formula><p>Our conjecture is that (A1)-(A3) imply that the equations have asymptotic solutions and that the statements of Theorem 2 and 3 hold with obvious modifications.</p><p>Note that in Theorem 2, since λ j = λ 2 , 2 ≤ j ≤ K there are effectively only two equations and modifications are also needed for other degeneracies in the parameters. We next turn to a branching process result in <ref type="bibr" target="#b11">[10]</ref> which we will use heavily.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">A Key Branching Process Result</head><p>As others have done we link the network formed by SBM with the tree network generated by multi-type Galton-Watson branching process. In our case, the Multitype branching process (MTBP) has type space S = {1, . . ., K}, where a particle of type a ∈ S is replaced in the next generation by a set of particles distributed as a Poisson process on S with intensity (B ab π b ) K b=1 = (M ab ) K b=1 . Recall the definitions of B, M and S from Section 2.1. We denote this branching process, started with a single particle of type a, by B B,π (a). We write B B,π for the same process with the type of the initial particle random, distributed according to π. According to Theorem 8.1 of Chapter 1 of <ref type="bibr" target="#b27">[25]</ref>, the branching process has a positive survival probability if λ 1 &gt; 1, where, λ 1 is the Perron-Frobenius eigenvalue of M, a positive regular matrix. Recall that for our special M, λ 1 = p−q K + 1. </p><formula xml:id="formula_21">ρ ≡ ρ(B, π) ≡ K ∑ a=1 ρ(B, π; a)π a<label>(10)</label></formula><p>as the survival probability of the branching process B B,π given that its initial distribution is π</p><p>We denote Z t = (Z t (a)) K a=1 as the population of particles of K different types, with Z t (a) denoting particles of type a, at generation t for the Poisson multi-type branching process B B,π , with B and π as defined in Section 4. From Theorem 24 of <ref type="bibr" target="#b11">[10]</ref>, we get that</p><formula xml:id="formula_22">Theorem 4 ([10]). Let β &gt; 0 and Z 0 = x ∈ N K be fixed. There exists C = C(x, β ) &gt; 0 such that with probability at least 1 − n −β , for all k ∈ [K], all s,t ≥ 0, with 0 ≤ s &lt; t, | φ k , Z s − λ s−t k φ k , Z t | ≤ C(t + 1) 2 λ s/2 1 (log n) 3/2<label>(11)</label></formula><p>Remark: The above stated theorem is a special case of the general theorem stated in <ref type="bibr" target="#b11">[10]</ref>. The general theorem is required for generalizing Theorem 1. The general version of the theorem is</p><formula xml:id="formula_23">Theorem 5 ([10]). Let β &gt; 0 and Z 0 = x ∈ N K be fixed. There exists C = C(x, β ) &gt; 0 such that with probability at least 1 − n −β , for all k ∈ [K 0 ] (where, K 0 is the largest integer such that λ 2 k &gt; λ 1 for all k ≤ K 0 ), all s,t ≥ 0, with 0 ≤ s &lt; t, | φ k , Z s − λ s−t k φ k , Z t | ≤ C(t + 1) 2 λ s/2 1 (log n) 3/2<label>(12)</label></formula><p>and for all k ∈ [K]\[K 0 ], for all t ≥ 0,</p><formula xml:id="formula_24">| φ k , Z t | ≤ C(t + 1) 2 λ t/2 1 (log n) 3/2<label>(13)</label></formula><p>Finally, for all k</p><formula xml:id="formula_25">∈ [K]\[K 0 ], all t ≥ 0, E| φ k , Z t | 2 ≤ C(t + 1) 3 λ t 1 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">The Neighborhood Exploration Process</head><p>The neighborhood exploration process of a vertex v in graph G generated from an SBM gives us a handle on the link between local structures of a graph from SBM and multi-type branching process. Recall the definitions of SBM parameters from Section 2.1 and the definitions of Poisson multi-type branching process from Section 4.1 . We assume all vertices of graph G n generated from a stochastic block model has been assigned a community or type ξ i (say) for vertex v i ∈ V (G n ).</p><p>The neighborhood exploration process, (G, v) L , of a vertex v in graph G n , generates a spanning tree of the induced subgraph of G n consisting of vertices of at most L-distance from v. The spanning tree is formed from the exploration process which starts from a vertex v as the root in the random graph G n generated from stochastic block model. The set of vertices of type a of the random graph G n that are neighbors of v and has not been previously explored are called Γ 1,a (v) and N 1,a (v) = |Γ 1,a (v)| for a = 1, . . . , K and</p><formula xml:id="formula_26">N 1 (v) = (N 1,1 (v), . . . , N 1,K (v)). So, Γ 1 (v) = {Γ 1,1 (v), . . . ,Γ 1,K (v)</formula><p>} are the children of the root v at step ℓ = 1 in the spanning tree of the neighborhood exploration process. The neighborhood exploration process is repeated at second step by looking at the neighbors of type a of the vertices in Γ 1 (v) that has not been previously explored and the set is called Γ 2,a (v) and</p><formula xml:id="formula_27">N 2,a (v) = |Γ 2,a (v)| for a = 1, . . . , K. Similarly, Γ 2 (v) = {Γ 2,1 (v), . . . ,Γ 2,K (v)</formula><p>} are the children of vertices Γ 1 (v) at step ℓ = 2 in the spanning tree of the neighborhood exploration process. The exploration process is continued until step ℓ = L. Note that the process stops when all the vertices in G n has been explored. So, if G n is connected, then, L ≤ the diameter of the graph G n .</p><p>Since, we either consider G n connected or only the giant component of G n , the neighborhood exploration process will end in a finite number of steps but the number of steps may depend on n and is equal to the diameter, L, of the connected component of the graph containing the root v. It follows from Theorem 14.11 of <ref type="bibr" target="#b10">[9]</ref> that L/ log λ 1 (n) P → 1.</p><p>Now, we find a coupling relation between the neighborhood exploration process of a vertex of type a in stochastic block model and a multi-type Galton-Watson process, B(a) starting from a vertex of type a. The Lemma is based on Proposition 31 of <ref type="bibr" target="#b11">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 1. Let w(n) be a sequence such that w(n) → ∞ and w(n)/n → 0. Let (T, v) be the random rooted tree associated with the Poisson multi-type Galton-Watson</head><p>branching process defined in Section 2.1 started from Z 0 = δ c v and (G, v) be the spanning tree associated with neighborhood exploration process of random SBM graph G n starting from v. For ℓ ≤ τ, where τ is the number of steps required to explore w(n) vertices in (G, v), the total variation distance, d TV , between the law of (G, v) ℓ and (T, v) ℓ at step ℓ goes to zero as O n − 1 2 ∨ w(n)/n = o(1).</p><p>Proof. Let us start the neighborhood exploration process starting with vertex v of a graph generated from an SBM model with parameters (P, π) = (B/n, π). Correspondingly the multi-type branching process starts from a single particle of type c v , where, c v is the type or class of vertex v in SBM.</p><p>Let t be such that 0 ≤ t &lt; τ, where, τ is defined in the Lemma statement. Now, for such a t ≥ 0, let (x t+1 (1), . . . , x t+1 (K)) be leaves of (T, v) at time t starting from a vertex v t generated by step t of class c v t = a. Let (y t+1 (1), . . . , y t+1 (K)) be the vertices exposed at step t of the exploration process starting from a vertex of class a, where, a ∈ [K]. Now, if c v t is of type a, then, we have x t+1 (b) follows</p><formula xml:id="formula_29">Bin(n t (b), B ab /n) and y t+1 (b) follows Poi(π b B ab ) for b = 1, . . . , K, where, n t (b)</formula><p>is the number of unused vertices of type b remaining at time t for b = 1, . . . , K.</p><formula xml:id="formula_30">Also, y t+1 (b) for different b are independent. Note that n b ≥ n t (b) ≥ n b − w(n) for b = 1, . . . , K. So, since, we have |n b /n − π b | = O(n −1/2 ) for b = 1, . . . , K, we get that, |n t (b) − π b | &lt; O n −1/2 + w(n)/n for b = 1, . . . , K</formula><p>Now, we know that,</p><formula xml:id="formula_31">d TV Bin(m ′ , λ /m), Poi(m ′ λ /m) ≤ λ m , d TV Poi(λ ), Poi(λ ′ ) ≤ |λ − λ ′ |</formula><p>So, now, we have,</p><formula xml:id="formula_32">d TV (P t+1 , Q t+1 ) ≤ O n −1/2 ∨ w(n)/n = o(1)</formula><p>where, P t+1 is the distribution of y t+1 under neighborhood exploration process and Q t+1 is the distribution of x t+1 under the branching process, and hence Lemma 1 follows.</p><p>Now, we restrict ourselves to the giant component of G n . The size of the giant component of G n , C 1 (G n ), of a random graph generated from SBM(B, π) is related to the multi-type branching process through its survival probability as given in Definition 5. According to Theorem 3.1 of [9], we have,</p><formula xml:id="formula_33">1 n C 1 (G n ) P → ρ(B, π)<label>(15)</label></formula><p>Under this additional condition of restricting to the giant component, the branching process can be coupled with another branching process with a different kernel. The kernel of that branching process is given in following lemma.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 2. If v is in giant component of G n , the new branching process has kernel</head><formula xml:id="formula_34">B ab 2ρ(B, π)/K − ρ 2 (B, π)/K 2 K a,b=1 .</formula><p>Proof. The proof is given in Section 10 of <ref type="bibr" target="#b10">[9]</ref>.</p><p>Since, we will be restricting ourselves to the giant component of G n , we shall be using the B ′ ≡ B ab 2ρ(B, π)/K − ρ 2 (B, π)/K 2 K a,b=1 matrix as the connectivity matrix in stead of B. We abuse notation by referencing to the matrix B ′ as B too.</p><p>We proceed to prove the limiting behavior of typical distance between vertices v and w of G n , where, v, w ∈ V (G n ). We first try to find a lower bound for distance between two vertices. We shall separately give an upper bound and lower bounds for the distance between two vertices of the same type and different types. Proof. Let Γ d (v) ≡ Γ d (v, G n ) denote the d-distance set of v in G n , i.e., the set of vertices of G n at graph distance exactly d from v, and let Γ ≤d The neighborhood exploration process and multi-type branching process can be coupled so that for every d, |Γ d (v)| is at most the number N d + O n − 1 2 ∨ w(n)/n , where, N d is number of particles in generation d of B B (δ a ) and in d generations at most w(n) vertices of G n have been explored.</p><formula xml:id="formula_35">(v) ≡ Γ ≤d (v, G n ) de- note the d-neighborhood ∪ d ′ ≤d Γ d ′ (v) of v. Let Γ d,a (v) ≡ Γ d,a (v, G n ) denote the set of vertices of type a at d-distance in G n and let Γ ≤d,a (v) ≡ Γ ≤d,a (v, G n ) denote the d-neighborhood ∪ d ′ ≤d Γ d ′ ,a (v) of v</formula><p>From Theorem 4, we get that with high probability</p><formula xml:id="formula_36">φ k , Z t λ t k − φ k , Z 0 ≤ C(t + 1) 2 (log n) 3/2</formula><p>Since, for any x ∈ R K , we get the unique representation,</p><formula xml:id="formula_37">x = ∑ K k=1 x, φ k φ k , for any basis {φ k } K k=1 of R K . If we take x = e b ,</formula><p>where, e b is the unit vector with 1 at b-th co-ordinate and 0 elsewhere, b = 1, . . . , K, we can get</p><formula xml:id="formula_38">Z t (b) ≤ K ∑ k=1 φ k (b)λ t k φ k (a) Z 0 (a) + C(t + 1) 2 (log n) 3/2</formula><p>Now, under our model one representation of the eigenvectors is</p><formula xml:id="formula_39">φ 1 = 1 √ K (1, . . . , 1), φ 2 = 1 √ 2 (−1, 1, 0, . . . , 0), φ 3 = 1 √ 6 (−1, −1, 2, 0, . . ., 0), · · · , φ K−1 = 1 √ K(K−1) (−1, . . . , −1, K − 1)</formula><p>. Now using the representation of eigenvectors for branching process starting from vertex of type a, a ∈ [K], we get with high probability</p><formula xml:id="formula_40">K ∑ k=1 Z t (k) ≤ λ t 1 Z 0 (a) + C(t + 1) 2 (log n) 3/2 Z t (a) − Z t (b) ≥ λ t 2 −Z 0 (a) − C(t + 1) 2 (log n) 3/2 , b = 1, . . . , K and b = a.</formula><p>So, we can simplify, for each a ∈ [K] with Z 0 (a) = 1, with high probability,</p><formula xml:id="formula_41">Z t (a) ≤ 1 K λ t 1 + (K − 1)λ t 2 1 + C(t + 1) 2 (log n) 3/2 Z t (b) ≤ λ t 1 − λ t 2 K 1 + C(t + 1) 2 (log n) 3/2 , b ∈ [K] and b = a. Set D 1 = (1 − ε)τ 1 , where, τ 1 is the solution to the equation λ t 2 + λ t 1 − λ t 2 K = n</formula><p>and set D 2 = (1 − ε)τ 2 , where, τ 2 is the solution to the equation</p><formula xml:id="formula_42">λ t 1 − λ t 2 K = n</formula><p>where, ε &gt; 0 is fixed and small. Note that both τ 1 and τ 2 are of the order O(log n). Thus, with high probability, for v of type a and w(n) = O(n 1−ε ),</p><formula xml:id="formula_43">|Γ ≤D 1 ,a (v)| = ∑ D 1 d=0 N a d,a ≤ Z D 1 (a) + O D 1 n − 1 2 ∨ w(n)/n = O(n 1−ε ) |Γ ≤D 2 ,b (v)| = ∑ D 2 d=0 N a d,b ≤ Z D 2 (b) + O D 2 n − 1 2 ∨ w(n)/n = O(n 1−ε ) So, summing over v ∈ C a and v ∈ C b , where, C a = {i ∈ V (G)|c i = a} and C b = {i ∈ V (G)|c i = b}, we have, ∑ v∈C a |Γ ≤D 1 ,a (v)| = |{{v, w} : d G (v, w) ≤ (1 − ε)τ 1 , v, w ∈ C a }| ∑ v∈C a |Γ ≤D 2 ,b (v)| = |{{v, w} : d G (v, w) ≤ (1 − ε)τ 2 , v ∈ C a , w ∈ C b }|</formula><p>and so with high probability</p><formula xml:id="formula_44">|{{v, w} : d G (v, w) ≤ (1 − ε)τ 1 , v, w ∈ C a }| = ∑ v∈V (G n ) |Γ ≤D,a (v)| = O(n 2−ε ) |{{v, w} : d G (v, w) ≤ (1 − ε)τ 2 , v ∈ C a , w ∈ C b }| = ∑ v∈V (G n ) |Γ ≤D,b (v)| = O(n 2−ε )</formula><p>The above statement is equivalent to</p><formula xml:id="formula_45">P |{{v, w} : d G (v, w) ≤ (1 − ε)τ 1 , v, w ∈ C a }| ≤ O(n 2−ε ) = 1 − o(1) P |{{v, w} : d G (v, w) ≤ (1 − ε)τ 2 , v ∈ C a , w ∈ C b }| ≤ O(n 2−ε ) = 1 − o(1)</formula><p>for any fixed ε &gt; 0. Now, we upper bound the typical distance between two vertices of SBM graph G n .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 4. Under our model, for vertices v, w ∈ V (G) and conditioned on the event that the exploration process starts from a vertex in the giant component of G, if,</head><p>(a) type of v = type of w = a (say), then,</p><formula xml:id="formula_46">P (d G (v, w) &lt; (1 + ε)τ 1 ) = 1 − exp(−Ω (n 2η ))</formula><p>where, τ 1 is the minimum real positive t, which satisfies Eq. (6), (b) type of v = a = b = type of w (say), then,</p><formula xml:id="formula_47">P (d G (v, w) &lt; (1 + ε)τ 2 ) = 1 − exp(−Ω (n 2η ))</formula><p>where, τ 2 is the minimum real positive t, which satisfies Eq. <ref type="bibr" target="#b9">(8)</ref>.</p><p>Proof. We consider the multi-type branching process with probability kernel P ab = B ab n ∀a, b = 1, . . ., K and the corresponding random graph G n generated from stochastic block model has in total n nodes. We condition that branching process B K survives.</p><p>Note that an upper bound 1 is obvious, since we are bounding a probability, so it suffices to prove a corresponding lower bound. We may and shall assume that B ab &gt; 0 for some a, b.</p><formula xml:id="formula_48">Again, let Γ d (v) ≡ Γ d (v, G n ) denote the d-distance set of v in G n , i.e.</formula><p>, the set of vertices of G n at graph distance exactly d from v, and let Γ ≤d </p><formula xml:id="formula_49">(v) ≡ Γ ≤d (v, G n ) denote the d-neighborhood ∪ d ′ ≤d Γ d ′ (v) of v. Let Γ d,a (v) ≡ Γ d,a (v, G n ) denote the set of vertices of type a at d-distance in G n and let Γ ≤d,a (v) ≡ Γ ≤d,a (v, G n ) denote the d-neighborhood ∪ d ′ ≤d Γ d ′ ,a (v) of v</formula><formula xml:id="formula_50">N a d = ∑ K c=1 N a d,c and Z t (k) = ∑ t d=0 N a d,k . By Lemma 1, for w(n) = o(n), |Γ d,c (v)| ≥ N d,c − O n − 1 2 ∨ w(n)/n , c = 1, . . . , K.<label>(16)</label></formula><p>for all d s.t. |Γ ≤d (v)| &lt; ω(n). This relation between the number of vertices at generation d of type c of branching process B B (δ a ), denoted by N d,c and the number of vertices of type c at distance d from v for the neighborhood exploration process of G n , denoted by |Γ d,c (v)| becomes highly important later on in this proof, where, c = 1, . . . , K. Note that the relation only holds when |Γ ≤d (v)| &lt; ω(n) for some ω(n) such that ω(n)/n → 0 as n → ∞. From Theorem 4 of the branching process, we get that with high probability</p><formula xml:id="formula_51">φ k , Z t λ t k − φ k , Z 0 ≤ C(log n) 3/2</formula><p>Now following the same line of argument as in proof of Lemma 3, for each a ∈ [K] with Z 0 (a) = 1, with high probability we get that,</p><formula xml:id="formula_52">Z t (a) ≤ 1 K λ t 1 + (K − 1)λ t 2 1 + C(t + 1) 2 (log n) 3/2 Z t (b) ≤ λ t 1 − λ t 2 K 1 + C(t + 1) 2 (log n) 3/2 , b ∈ [K] and b = a.</formula><p>Let D 1 be the integer part of (1 + 2η)τ ′ 1 , where, τ ′ 1 is the solution to the equation</p><formula xml:id="formula_53">λ t 2 + λ t 1 − λ t 2 K = n 1/2−η<label>(17)</label></formula><p>Thus conditioned on survival of the branching process B B (δ a ), N a D 1 ,a ≥ n 1/2+η/2 . Set D 2 = (1 + η)τ ′ 2 , where, τ ′ 2 is the solution to the equation</p><formula xml:id="formula_54">λ t 1 = n 1/2+η<label>(18)</label></formula><p>Thus conditioned on survival of branching process B B (δ a ), N a D 2 ,b ≥ n 1/2+η/2 for b = 1, . . . , K. Furthermore lim d→∞ P(N a d = 0) = ρ(B, a). Now, we have conditioned that the branching process with kernel B is surviving. The right-hand side tends to ρ(B, a) = 1 as η → 0. Hence, given any fixed γ &gt; 0, if we choose η &gt; 0 small enough, and for large enough n, we have</p><formula xml:id="formula_55">P ∀b : N a D 2 ,b ≥ n 1/2+η/2 = 1, P N a D 1 ,a ≥ n 1/2+η/2 = 1.</formula><p>Now, the neighborhood exploration process and branching process can be coupled so that for every d, |Γ d (v)| is at most the number N d of particles in generation d of B B (a) from Lemma 1 and Eq <ref type="bibr" target="#b17">(16)</ref>. So, we have for v of type a, with high probability,</p><formula xml:id="formula_56">|Γ ≤D 1 ,a (v)| ≤ E D 1 ∑ d=0 N d = o(n 2/3 ) |Γ ≤D 2 ,b (v)| ≤ E D 2 ∑ d=0 N d = o(n 2/3 )</formula><p>if η is small enough, since D 1 is integer part of (1 + 2η)τ ′ 1 and D 2 is the integer part of (1 + 2η)τ ′ 2 , where, τ ′ 1 and τ ′ 2 are solutions to Eq. <ref type="formula" target="#formula_0">(17)</ref> and <ref type="bibr" target="#b19">(18)</ref>. Note that the power 2/3 here is arbitrary, we could have any power in the range (1/2, 1). So, now, we are in a position to apply Eq (16), as we have |Γ ≤D (v)| ≤ O(n 2/3 a ) &lt; ω(n), with ω(n)/n → 0. Now let v and w be two fixed vertices of G(n, P), of types a and b respectively.</p><p>We explore both their neighborhoods at the same time, stopping either when we reach distance D in both neighborhoods, or we find an edge from one to the other, in which case v and w are within graph distance 2D + 1. We consider two independent branching processes B B (a), B ′ B (b), with N a d,c and N b d,c vertices of type c in generation d respectively. By the previous argument, with high probability we encounter o(n) vertices in the exploration so, by the argument leading to <ref type="bibr" target="#b17">(16)</ref>, whp either the explorations meet, or</p><formula xml:id="formula_57">|Γ a d,c (w)| ≥ Z (a) d (c) − O n − 1 2 ∨ n − 1 3 , c = 1, . . . , K, c = a |Γ b d,c (w)| ≥ Z (b) d (c) − O n − 1 2 ∨ n − 1 3 , c = 1, . . . , K, c = b</formula><p>with the explorations not meeting, where, Z (a) is the branching process starting from Z 0 = δ a , for a = 1, . . . , K. Using bound on N a d,c and the independence of the branching processes, it follows that for a = b,</p><formula xml:id="formula_58">P d(v, w) ≤ 2D 1 + 1 or |Γ a D 1 ,c (v)|, |Γ a D 1 ,c (w)| ≥ n 1/2+η ≥ 1 − o(1).</formula><p>and for a = b,</p><formula xml:id="formula_59">P d(v, w) ≤ 2D 2 + 1 or ∀c : |Γ a D 2 ,c (v)|, |Γ b D 2 ,c (w)| ≥ n 1/2+η ≥ 1 − o(1).</formula><p>Write these probabilities as P(A j ∪ B j ), j = 1, 2. We now show that P(A c j ∩ B j ) → 0 and since P(A j ∪ B j ) → 1, we will have P(A j ) → 1. We have not examined any edges from Γ D (v) to Γ D (w), so these edges are present independently with their original unconditioned probabilities. For any end vertex types c 1 , c 2 , the expected number of these edges is at least |Γ a D,c (v)||Γ a D,c (w)|B c 1 c 2 /n for first probability and |Γ a D,c 1 (v)||Γ b D,c 2 (w)|B c 1 c 2 /n for second probability. Choosing c 1 , c 2 such that B c 1 c 2 &gt; 0, this expectation is Ω ((n 1/2+η/2 ) 2 /n) = Ω (n η ). It follows that at least one edge is present with probability 1 − exp(−Ω (n η )) = 1 − o <ref type="bibr" target="#b0">(1)</ref>. If such an edge is present, then d(v, w) ≤ 2D 1 + 1 for first probability and d(v, w) ≤ 2D 1 + 1 for second probability. So, the probability that the second event in the above equation holds but not the first is o <ref type="bibr" target="#b0">(1)</ref>. Thus, the last equation implies that</p><formula xml:id="formula_60">P(d(v, w) ≤ 2D 1 + 1) ≥ (1 − γ) 2 − o(1) ≥ 1 − 2γ − o(1) P(d(v, w) ≤ 2D 2 + 1) ≥ (1 − γ) 2 − o(1) ≥ 1 − 2γ − o(1).</formula><p>where, γ &gt; 0 is arbitrary. Choosing η small enough, we have 2D + 1 ≤ (1 + ε) log(n)/ log λ . As γ is arbitrary, we have</p><formula xml:id="formula_61">P(d(v, w) ≤ (1 + ε)τ 1 ) ≥ 1 − exp(−Ω (n 2η )), P(d(v, w) ≤ (1 + ε)τ 2 ) ≥ 1 − exp(−Ω (n 2η )).</formula><p>and the lemma follows.</p><p>The equations <ref type="bibr" target="#b5">(6)</ref> and <ref type="formula" target="#formula_18">(8)</ref> control the asymptotic bounds for the graph distance d G (v, w) between two vertices v and w in V (G n ). Under the condition (A3) it follows that λ 2 2 &gt; λ 1 . If we consider λ 2 2 = cλ 1 , where, c is a constant, then the equations <ref type="formula">(6)</ref> and <ref type="formula" target="#formula_18">(8)</ref> can be written in the form of quadratic equations. So, the solutions τ 1 and τ 2 exist under the condition c τ 1 and c τ 2 are of the order O(n) and the resulting solutions τ 1 and τ 2 are both of the order O(log n). Also, from the expression of the solutions τ 1 and τ 2 , the limits τ 1 log n and τ 2 log n exist and we shall define the limit as σ 1 and σ 2 respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Proof of Theorem 2 and Theorem 3</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Proof of Theorem 2</head><p>We shall try to prove the limiting behavior of the typical graph distance in the giant </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Proof of Theorem 3</head><p>From Definition 4, we have that D i j = graph distance between vertices v i and v j , where, v i , v j ∈ V (G n ). From Lemma 3, we get for any vertices v and w with high probability,</p><formula xml:id="formula_62">|{{v, w} : d G (v, w) ≤ (1 − ε)τ 1 }| ≤ O(n 2−ε ), if type of v = type of w |{{v, w} : d G (v, w) ≤ (1 − ε)τ 2 }| ≤ O(n 2−ε ), if type of v = type of w.</formula><p>Also, from Lemma 4, we get</p><formula xml:id="formula_63">P (d G (v, w) &lt; (1 + ε)τ 1 ) = 1 − exp(−Ω (n 2η )), if type of v = type of w, P (d G (v, w) &lt; (1 + ε)τ 2 ) = 1 − exp(−Ω (n 2η )), if type of v = type of w.</formula><p>Now, σ 1 = τ 1 / log n and σ 2 = τ 2 / log n are asymptotically constant as both τ 1 and τ 2 are of the order log n as follows from equations <ref type="formula">(6)</ref> and <ref type="bibr" target="#b9">(8)</ref>. So, putting the two statements together, we get that with high probability,</p><formula xml:id="formula_64">n ∑ i, j=1:type(v i ) =type(v j ) D i j log n − D i j 2 = O(n 2−ε ) + O(n 2 )</formula><p>.ε 2 since, by Lemma 1, ε = o(1) and (1 − exp(−Ω (n 2η ))) n 2 → 1 as n → ∞. So, putting the two cases together, we get that with high probability, for some ε &gt; 0,</p><formula xml:id="formula_65">n ∑ i, j=1 D i j log n − D i j 2 = O(n 2−ε ) + O(n 2 ).ε 2 = o(n 2 ).</formula><p>Hence, for some ε &gt; 0,</p><formula xml:id="formula_66">D log n − D F ≤ o(n).</formula><p>We have completed proofs of Theorems 2 and 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Perturbation Theory of Linear Operators</head><p>We now establish part II of our program. D can be considered as a perturbation of the operator D. The Davis-Kahan Theorem <ref type="bibr" target="#b14">[13]</ref>] gives a bound on perturbation of eigenspace instead of eigenvector, as discussed previously. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Proof of Theorem 1</head><p>The behavior of the eigenvalues of the limiting operator D can be stated as follows -Lemma 5. Under our model, the eigenvalues of D -|µ 1 (D)| ≥ |µ 2 (D)| ≥ · · · ≥ |µ n (D)|, can be bounded as follows -</p><formula xml:id="formula_67">µ 1 (D) = O(nσ 1 ), |µ K (D)| = O(n(σ 1 − σ 2 )), µ K+1 (D) = · · · = µ n (D) = −σ 1<label>(19)</label></formula><p>Also, With high probability it holds that |µ K (D/ log n)| = O(n(σ 1 − σ 2 )) and µ K+1 (D/ log n) ≤ o(n).</p><p>Proof. The matrix D + σ 1 I n×n is a block matrix with blocks of sizes {n a } K a=1 , with ∑ K a=1 n a = n. The elements of (a, b)th block are all same and equal to σ 1 , if a = b and equal to σ 2 , if a = b. Note, diagonal of D is zero, as diagonal of D is also zero. Now, we have the eigenvalues of the K × K matrix of the values in D to be (σ 1 + (K − 1)σ 2 , σ 1 − σ 2 , . . . , σ 1 − σ 2 ). If we consider, λ 2 2 = cλ 1 , then, if c &gt; 1, we will have σ 1 &gt; σ 2 . So, under our model, we have that σ 1 &gt; σ 2 . So, because of repetitions in the block matrix Also, the gap δ = O(n(σ 1 − σ 2 )) between top K and K + 1th eigenvalues of matrix D. So, now, we can apply Davis-Kahan Theorem 6 and Theorem 3, to get that,</p><formula xml:id="formula_68">||WR −W|| F ≤ √ 2 ||D/ log n − D|| F δ ≤ o(n) O(n(σ 1 − σ 2 )) = o (σ 1 − σ 2 ) −1</formula><p>Now, the relationship between the rows of W can be specified as follows -Lemma 7. For any two rows i, j of W n×K matrix, ||u i − u j || 2 ≥ O(1/ √ n), if type of v i = type of v j .</p><p>Proof. The matrix D + σ 1 Id n×n is a block matrix with blocks of sizes {n a } K a=1 , with ∑ K a=1 n a = n. The elements of (a, b)th block are all same and equal to σ 1 , if a = b and equal to σ 2 , if a = b. Note, diagonal of D is zero, as diagonal of D is also zero. Now, we have the rows of eigenvectors of the K × K matrix of the values in D that have a constant difference. Under our model, we have that σ 1 &gt; σ 2 . So, because of repetitions in the block matrix, rows of D as well as the projection of D into into its top K eigenspace has difference of order O(n −1/2 ) between rows of matrix. Now, if we consider K-means criterion as the clustering criterion onW, then, for the K-means minimizer centroid matrix C is an n × K matrix with K distinct rows corresponding to the K centroids of K-means algorithm. By property of K-means objective function and Lemma 6, with high probability,</p><formula xml:id="formula_69">||C −W|| F ≤ ||WR −W|| F ||C − WR|| F ≤ ||C −W|| F + ||WR −W|| F ||C − WR|| 2 F ≤ 4||WR −W|| 2 F ≤ o (σ 1 − σ 2 ) −2</formula><p>By Lemma 7, for large n, we can get constant C, such that, K balls, B 1 , . . . , B K , of radius r = Cn −1/2 around K distinct rows of W are disjoint. Now note that with high probability the number of rows i such that ||C i − (WR) i || &gt; r is at most cn (σ 1 −σ 2 ) 2 , with arbitrarily small constant c &gt; 0. If the statement does not hold then,</p><formula xml:id="formula_70">||C − WR|| 2 F &gt; r 2 . cn (σ 1 − σ 2 ) 2 ≥ Cn −1 . cn (σ 1 − σ 2 ) 2 = O (σ 1 − σ 2 ) −2</formula><p>So, we get a contradiction, since ||C − WR|| 2 F ≤ o (σ 1 − σ 2 ) −2 . Thus, the number of mistakes should be at most cn (σ 1 −σ 2 ) 2 , with arbitrarily small constant c &gt; 0. So, for each v i ∈ V (G n ), if c(v i ) is the type of v i andĉ(v i ) is the type of v i as estimated from applying K-means on top K eigenspace of geodesic matrix D, we get that for arbitrarily small constant, c &gt; 0,</p><formula xml:id="formula_71">1 n n ∑ i=1 1 (c(v i ) =ĉ(v i )) &lt; c (σ 1 − σ 2 ) 2 → 1</formula><p>So, for constant σ 1 and σ 2 , we get c &gt; 0 such that,</p><formula xml:id="formula_72">1 n n ∑ i=1 1 (c(v i ) =ĉ(v i )) &lt; 1 2 → 1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We have given an overview of spectral clustering in the context of community detection of networks and clustering. We have also introduced a new method of community detection in the paper and we have shown bounds on theoretical performance of the method.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Definition 4 . 1 .</head><label>41</label><figDesc>The Graph or Geodesic distance between two vertices i and j of graph G is given by the length of the shortest path between the vertices i and j, if they are connected. Otherwise, the distance is infinite.So, for any two vertices u, v ∈ V (G), graph distance, d g is defined byd g (u, v) = min{ℓ|∃ path of length ℓ between u and v}, ∞, if u and v are not connected For implementation, we can replace ∞ by n + 1, when, u and v are not connected, since any path with loops can not be a geodesic. The main steps of the algorithm are as follows Find the graph distance matrix D = [d g (v i , v j )] n i, j=1 for a given network but with distance upper bounded by k log n. Assign non-connected vertices an arbitrary high value.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>6 .(</head><label>6</label><figDesc>Alternative to 5.) Perform Gaussian mixture model based clustering on the rows ofW, when there is an indication of highly-varying average degree between the communities. 7. Letĉ : V → [K] be the block assignment function according to the clustering of the rows ofW performed in either Step 5 or 6. Here are some important observations about the implementation of the algorithm -(a) There are standard algorithms for graph distance finding in the algorithmic graph theory literature. In the algorithmic graph theory literature the problem is known as the all pairs shortest path problem. The two most popular algorithms are Floyd-Warshall [16] [34] and Johnson's algorithm [21]. (b) Step 3 of the algorithm is nothing but the classical multi-dimensional scaling (MDS) of the graph distance matrix. (c) In the Step 5 of the algorithm K-means clustering is appropriate if the expected degree of the blocks are equal. However, if the expected degree of the blocks are different, this leads to multi scale behavior in the eigenvectors of the normalized distance matrix and bad behavior in practice. So, we perform Gaussian Mixture Model (GMM) based clustering instead of K-means to take into account that.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Theorem 3 .</head><label>3</label><figDesc>Let D B be the restriction of the geodesic matrix to vertices in the big component of G n . Then, under our model,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Definition 5 .</head><label>5</label><figDesc>(a)Define ρ(B, π; a) as the probability that the branching process, B B,π (a), survives for eternity.(b)Define,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Lemma 3 .</head><label>3</label><figDesc>Under our model, for vertices v, w ∈ V (G), if (a) type of v = type of w = a (say), then, |{{v, w} : d G (v, w) ≤ (1 − ε)τ 1 }| ≤ O(n 2−ε ) with high probabilitywhere, τ 1 is the minimum real positive t, which satisfies Eq.(6), (b) type of v = a = b = type of w (say), then, |{{v, w} : d G (v, w) ≤ (1 − ε)τ 2 }| ≤ O(n 2−ε ) with high probability where, τ 2 is the minimum real positive t, which satisfies Eq. (8).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>consisting of vertices of type a. Let N a d be the number of particles at generation d of the branching process B B (δ a ) and N a d,c be the number of particles at generation d of the branching process B B (δ a ) of type c. So, N a d = ∑ K c=1 N a d,c and Z t (k) = ∑ t d=0 N a d,k . Lemma 1 involved first showing that, for n large enough, the neighborhood exploration process starting at a given vertex v of G n with type a could be coupled with the branching process B B ′ (δ a ), where the B ′ is defined by Lemma 2. As noted we identify B ′ with B.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>consisting of vertices of type a. Let N a d be the number of particles at generation d of branching process B B (δ a ) and N a d,c be the number of particles at generation d of branching process B B (δ a ) of type c. So,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>component as n → ∞. The Theorem essentially follows from Lemma 3 -4. Under the conditions mentioned in the Theorem, part (a) follows from Lemma 3(a) and 4(a) and part (b) follows from Lemma 3(b) and 4(b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Lemma 6 .</head><label>6</label><figDesc>µ 1 (D) = O(nσ 1 ) = O(n) and µ K (D) = O(n(σ 1 − σ 2 )) = O(n), since, by assumption (A3), n a = O(n), for all a = 1, . . . , K. Now, the rest of the eigenvalues of D + σ 1 Id n×n is zero, so the rest of eigenvalues of D is −σ 1 .Now, about the second part of Lemma, By Weyl's Inequality, for all i = 1, . . . , n,||µ i (D/ log n)| − |λ i (D)|| ≤ ||D/ log n − D|| F ≤ o(n)Since, from (A1)-(A3), it follows that σ 1 − σ 2 &gt; c &gt; 0, for some constant c, so,|λ K (D/ log n)| = O(n(σ 1 −σ 2 ))−o(n) = O(n(σ 1 −σ 2 )) for large n and |λ K+1 (D/ log n)| ≤ −σ 1 + o(n) = o(n). Now, let W be the eigenspace corresponding to the top K absolute eigenvalues of D andW be the eigenspace corresponding to the top K absolute eigenvalues of D. Using Davis-Kahan With high probability, there exists an orthogonal matrix R ∈ R K×K suchthat ||WR −W|| F ≤ o (σ 1 − σ 2 ) −1Proof. The top K eigenvalues of both D and D/ log n lies in (Cn, ∞) for some C &gt; 0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Theorem 6 (Davis-Kahan (1970)[13]). Let H, H</head><label></label><figDesc>′ ∈ R n×n be symmetric, suppose V ⊂ R is an interval, and suppose for some positive integer d that W, W ′ ∈ R n×d are such that the columns of W form an orthonormal basis for the sum of the eigenspaces of H associated with the eigenvalues of H in V and that the columns of W ′ form an orthonormal basis for the sum of the eigenspaces of H ′ associated with the eigenvalues of H ′ in V . Let δ be the minimum distance between any eigenvalue of H in V and any eigenvalue of H not in V . Then there exists an orthogonal matrix R ∈ R d×d such that ||WR − W ′ || F ≤ √ 2 ||H−H ′ || F</figDesc><table /><note>δ .</note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Abbe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Bandeira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hall</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1405.3267</idno>
		<title level="m">Exact recovery in the stochastic block model</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Pseudo-likelihood methods for community detection in large sparse networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Amini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Bickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Levina</surname></persName>
		</author>
		<idno type="DOI">10.1214/13-AOS1138</idno>
		<idno>10.1214/ 13-AOS1138</idno>
		<ptr target="http://dx.doi.org/10.1214/13-AOS1138" />
	</analytic>
	<monogr>
		<title level="j">Ann. Statist</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2097" to="2122" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Amini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Levina</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.5647</idno>
		<title level="m">On semidefinite relaxations for the block model</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Branching processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">B</forename><surname>Athreya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Ney</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1972" />
			<publisher>Springer-Verlag</publisher>
			<biblScope unit="volume">28</biblScope>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">First passage percolation on the erdsrenyi random graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bhamidi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Van Der Hofstad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hooghiemstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Combinatorics, Probability &amp; Computing</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="683" to="707" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Bickel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1401.3915</idno>
		<title level="m">Community detection in networks using graph distance</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Asymptotic normality of maximum likelihood and its variational approximation for stochastic blockmodels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Ann. Statist</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1922" to="1943" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<idno type="DOI">10.1214/13-AOS1124</idno>
		<ptr target="http://dx.doi.org/10.1214/13-AOS1124" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A nonparametric view of network models and newman-girvan and other modularities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Bickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">50</biblScope>
			<biblScope unit="page">73</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The phase transition in inhomogeneous random graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bollobás</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Janson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Riordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Random Structures &amp; Algorithms</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="122" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bordenave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lelarge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Massoulié</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1501.06087</idno>
		<title level="m">Non-backtracking spectrum of random graphs: community detection and non-regular ramanujan graphs</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Consistency of maximum-likelihood and variational estimators in the stochastic block model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Celisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Daudin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pierre</surname></persName>
		</author>
		<idno type="DOI">10.1214/12-EJS729</idno>
		<ptr target="http://dx.doi.org/10.1214/12-EJS729" />
	</analytic>
	<monogr>
		<title level="j">Electron. J. Stat</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1847" to="1899" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Spectral Approximation of Linear Operators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chatelin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983" />
			<publisher>SIAM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The rotation of eigenvectors by a perturbation. iii</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">M</forename><surname>Kahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Numerical Analysis</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="46" />
			<date type="published" when="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Asymptotic analysis of the stochastic block model for modular networks and its algorithmic applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Decelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Krzakala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zdeborová</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review E</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">106</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Algebraic connectivity of graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fiedler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Czechoslovak Math. J</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">98</biblScope>
			<biblScope unit="page" from="298" to="305" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Algorithm 97: shortest path</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Floyd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">345</biblScope>
			<date type="published" when="1962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">H</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.03772</idno>
		<title level="m">Achieving optimal misclassification proportion in stochastic block model</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Girvan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Newman</surname></persName>
		</author>
		<title level="m">Community structure in social and biological networks. Proceedings of the National Academy of Sciences</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="7821" to="7826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Clustering algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Hartigan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Wiley Series in Probability and Mathematical Statistics</title>
		<meeting><address><addrLine>New York-London-Sydney</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Holland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">B</forename><surname>Laskey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Leinhardt</surname></persName>
		</author>
		<title level="m">Stochastic blockmodels: First steps. Social networks</title>
		<imprint>
			<date type="published" when="1983" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="109" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Efficient algorithms for shortest paths in sparse networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM (JACM)</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Perturbation theory for linear operators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Katō</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<publisher>springer</publisher>
			<biblScope unit="volume">132</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Consistency of spectral clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Von Luxburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bousquet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Statist</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="555" to="586" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title/>
		<idno type="DOI">10.1214/009053607000000640</idno>
		<ptr target="http://dx.doi.org/10.1214/009053607000000640" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Community detection thresholds and the weak ramanujan property</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Massoulié</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th Annual ACM Symposium on Theory of Computing</title>
		<meeting>the 46th Annual ACM Symposium on Theory of Computing</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="694" to="703" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Mode</surname></persName>
		</author>
		<title level="m">Multitype branching processes: Theory and applications</title>
		<imprint>
			<publisher>American Elsevier Pub. Co</publisher>
			<date type="published" when="1971" />
			<biblScope unit="volume">34</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Mossel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Neeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sly</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1202.1499</idno>
		<title level="m">Stochastic block models and reconstruction</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Mossel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Neeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sly</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1311.4115</idno>
		<title level="m">A proof of the block model threshold conjecture</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">On spectral clustering: Analysis and an algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="849" to="856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Spectral clustering and the high-dimensional stochastic blockmodel</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rohe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.1214/11-AOS887</idno>
		<ptr target="http://dx.doi.org/10.1214/11-AOS887" />
	</analytic>
	<monogr>
		<title level="j">Ann. Statist</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1878" to="1915" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Robust regression and outlier detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Rousseeuw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Leroy</surname></persName>
		</author>
		<idno type="DOI">10.1002/0471725382</idno>
		<ptr target="http://dx.doi.org/10.1002/0471725382" />
	</analytic>
	<monogr>
		<title level="m">Wiley Series in Probability and Mathematical Statistics: Applied Probability and Statistics</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley &amp; Sons, Inc</publisher>
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Normalized cuts and image segmentation. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="888" to="905" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A consistent adjacency spectral embedding for stochastic blockmodel graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Sussman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Fishkind</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Priebe</surname></persName>
		</author>
		<idno type="DOI">10.1080/01621459.2012.699795</idno>
		<ptr target="http://dx.doi.org/10.1080/01621459.2012.699795" />
	</analytic>
	<monogr>
		<title level="j">J. Amer. Statist. Assoc</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">499</biblScope>
			<biblScope unit="page" from="1119" to="1128" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A tutorial on spectral clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Von</forename><surname>Luxburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics and computing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="395" to="416" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A theorem on boolean matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Warshall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM (JACM)</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="11" to="12" />
			<date type="published" when="1962" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
