<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">AMPA-Net: Optimization-Inspired Attention Neural Network for Deep Compressed Sensing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanyu</forename><surname>Li</surname></persName>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">C</forename><surname>Zhou</surname></persName>
							<email>charles.zhou@quantumii.com</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">School of Information Engineering and Automation</orgName>
								<orgName type="institution">Kunming University of science and technology Kunming</orgName>
								<address>
									<postCode>650000</postCode>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Quantum Intelligence Inc. Monterrey, United States</orgName>
								<address>
									<postCode>93943</postCode>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">AMPA-Net: Optimization-Inspired Attention Neural Network for Deep Compressed Sensing</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T11:19+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-CS reconstruction</term>
					<term>optimization inspired neural network</term>
					<term>AMP-Net</term>
					<term>AMPA-Net</term>
					<term>attention</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Compressed sensing (CS) is a challenging problem in image processing due to reconstructing an almost complete image from a limited measurement. To achieve fast and accurate CS reconstruction, we synthesize the advantages of two well-known methods (neural network and optimization algorithm) to propose a novel optimization inspired neural network which dubbed AMP-Net. AMP-Net realizes the fusion of the Approximate Message Passing (AMP) algorithm and neural network. All of its parameters are learned automatically. Furthermore, we propose an AMPA-Net which uses three attention networks to improve the representation ability of AMP-Net. Finally, We demonstrate the effectiveness of AMP-Net and AMPA-Net on four standard CS reconstruction benchmark data sets. Our code is available on https://github.com/puallee/AMPA-Net.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Compressed sensing (CS) <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref> theory demonstrates that we can recover a signal from a limited measurement with a high probability if it is sparse in some optimal transform. This new technology is hardware-friendly and widely used in many fields, such as fast magnetic resonance imaging (fMRI) <ref type="bibr" target="#b2">[3]</ref>, fast and low-dose X-ray imaging <ref type="bibr" target="#b3">[4]</ref>, radio astronomy imaging <ref type="bibr" target="#b4">[5]</ref>, single-pixel camera <ref type="bibr" target="#b5">[6]</ref> and 3D-video <ref type="bibr" target="#b6">[7]</ref>. In this paper, we focus on the CS of natural images, however, our framework can be generalized to other types of data as well. We show examples of CS in <ref type="figure" target="#fig_0">Fig.1</ref>. We define that the size of image signal X is N P , sensing matrix is φ, the size of measurement Y is M P , the degree of under-sampling as CS ratios is M P /N P , and it also means sampling cost. We reconstruct an almost clear image from the measurement Y . CS can be written as an optimization for l 1 norm problem which is presented in Eq. <ref type="formula" target="#formula_0">(1)</ref>:</p><formula xml:id="formula_0">min X 1 2 Y − φX 2 2 + λ DX 1<label>(1)</label></formula><p>λ is a regularization parameter for sparsity, and D is the optimal transform. Optimization algorithms, neural networks, and optimizationinspired neural networks are mainly used in CS reconstruction. Optimization algorithms: Eq.(1) can be solved by optimization algorithms, such as alternating direction method of multipliers (ADMM) <ref type="bibr" target="#b8">[9]</ref>, iterative shrinkage-thresholding algorithm (ISTA) <ref type="bibr" target="#b9">[10]</ref>, and approximate message passing (AMP) <ref type="bibr" target="#b10">[11]</ref>. However, these methods are slow to converge. Because natural images are typically non-stationary, it is heavily laboring and time-consuming to design sensing matrix φ and optimal transform D. Neural network: a fast implicit model for CS Reconstruction, such as DR2-Net <ref type="bibr" target="#b11">[12]</ref>, Recon-Net <ref type="bibr" target="#b12">[13]</ref>, Adaptive-Recon-Net <ref type="bibr" target="#b13">[14]</ref>. These methods lack accuracy because they do not use prior knowledge of Eq.(1). Optimization-inspired neural network: it achieves the fusion of neural network and optimization algorithm to maintain accuracy and fast speed, such as ADMM-Net <ref type="bibr" target="#b2">[3]</ref> fusing ADMM and circular convolution, ISTA-Net + <ref type="bibr" target="#b14">[15]</ref> fusing ISTA and convolution neural network. In this paper, we propose a novel optimizationinspired neural network which fuses AMP and neural network, dubbed as AMP-Net, including full connection layer for adaptive sensing, AMP algorithm and balanced CNN for CS reconstruction. The whole network is trained end to end through Charbonnier loss function. Furthermore, we introduce three attention networks to further improve the performance of CS. In this paper, Our contributions are four-fold:</p><p>• We propose an AMP-Net to synthesize the advantages of approximate messaging passing and neural networks. Our method deal with the problem of fast and accurate CS reconstruction.</p><p>• Its enhanced version AMPA-Net use three attention networks to improve CS reconstruction performance. • To best of our knowledge, we are the first to propose AMP-Net based on the optimization-inspired neural network and our AMPA-Net is the first to incorporate feature attention for deep compressed sensing. • Extensive experiments on four standard benchmark data sets (i.e., Set11, BSD68, BSDS100, and Urban100) show that our methods can reach state-of-the-art performance in CS reconstruction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>In this section, we give a brief review of the optimizationinspired neural network, AMP algorithm, and attention mechanism which are most relevant to our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Optimization-inspired neural network</head><p>The existing optimization-inspired neural networks, including ADMM-Net, ISTA-Net, and ISTA-Net + , usually achieve the fusion of an optimization algorithm and a neural network to synthesize the advantages of both of them. This fusion depends on the similarity between the optimization algorithm and the neural network: (1) the calculation of optimization algorithms are usually differentiable, we can use propagated backward <ref type="bibr" target="#b15">[16]</ref> to learn their parameters. (2) Iteration of the optimization algorithm is similar to the deep stacking of neural networks <ref type="bibr" target="#b2">[3]</ref>. The optimization can unroll into depth structure. Through fusion, the structure of these networks has some well-defined explanatory. What's more, they can combine the advantages of optimization algorithm and neural network to achieve fast and accurate CS reconstruction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. AMP algorithm</head><p>The AMP algorithm is inspired by the message passing in graph theory <ref type="bibr" target="#b10">[11]</ref>. Considering some existing errors of CS reconstruction in each iteration in ISTA, AMP adds an Onsager reaction term, which improves the phase transition <ref type="bibr" target="#b16">[17]</ref> to get an accurate solution. Furthermore, the AMP algorithm has a strong expansibility. First, AMP combine with a welldefined denoising filter, such as: NLM-AMP <ref type="bibr" target="#b17">[18]</ref>, BM3Dprgamp <ref type="bibr" target="#b18">[19]</ref>. Second, AMP combine with trained denoising filer, such as: LD-AMP <ref type="bibr" target="#b19">[20]</ref>. However, there is no real fusion through end to end learning in the above methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Attention mechanism</head><p>The attention mechanism is an effective method in deep learning, such as SE-Net <ref type="bibr" target="#b21">[22]</ref> in image classification, RCAN <ref type="bibr" target="#b22">[23]</ref> in image super-resolution. In CS, we introduce three attention networks to redistribute spatial and channel information of our AMP-Net.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. AMP-NET</head><p>The overview structure of AMP-Net is illustrated in <ref type="figure" target="#fig_1">Fig.2</ref>. Its structure can be corresponding to Algorithm.2. We will describe our approach in detail from three aspects: Algorithm, Framework, and Loss function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Algorithm</head><p>David <ref type="bibr" target="#b10">[11]</ref> proposed an AMP algorithm to solve Eq.(1), AMP algorithm is presented in Algorithm.1. In Algorithm.1,</p><formula xml:id="formula_1">Algorithm 1 Approximate Message Passing Input: Y, φ Output: X = D T S (N ) P arameters : m Initialization S (0) = pinv(φ)Y, Z (0) = Y − φS (0)</formula><p>While not converge,do:</p><formula xml:id="formula_2">S (k) = η(φ T Z (k−1) + S (k−1) ) Z ( (k)) = Y − φS (k−1) + ϕ (k) Z (k−1) ϕ (k) = m(η (φ T Z (k−1) + S (k−1) ))</formula><p>the input is measurement Y and handcrafted sensing matrix φ. The output is reconstructed image X. AMP includes initialization and iteration. In initialization, D is handcrafted optimal transform, S (0) is reconstructed sparse representation <ref type="bibr" target="#b20">[21]</ref>. pinv is a pseudo-inverse operation. In iteration, k is an iteration index,Z (k) is current residual. η is threshold function for l 1 regulation, and η is its derivative of function input. m and ϕ (k) are scale factors. ϕ (k) Z (k−1) is the Onsager reaction item to improve phase transition. In their experiments, AMP needs almost one hundred of iteration to converge for neural images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Framework</head><p>In this part, we expand the traditional AMP to achieve fusion of AMP and neural network. For AMP, when D (k) exists orthogonality <ref type="bibr" target="#b24">[25]</ref> (D (k) T D (k) = I), AMP can be transformed into Eq. <ref type="formula" target="#formula_3">(2)</ref>:</p><formula xml:id="formula_3">X (k) = D (k) T ηD (k) (φ T Z (k−1) + X (k−1) )<label>(2)</label></formula><p>In Eq. <ref type="formula" target="#formula_3">(2)</ref>, D (k) means that D can be different in each iteration. Furthermore, we design a balanced CNN to represent D (k) T ηD (k) , and this balanced CNN is guided by the AMP algorithm to select the optimal solution X (k) , which is presented in Eq. <ref type="formula">(3)</ref>:</p><formula xml:id="formula_4">X (k) = f (k) (φ T Z (k−1) + X (k−1) ) (3) f (k) is a balanced CNN, it's parameters is P (k) .</formula><p>After that, We also use full-connection layer network for adaptive sensing <ref type="bibr" target="#b13">[14]</ref> and initialization to replace handcrafted metric φ and pinv calculation. In <ref type="figure" target="#fig_1">Fig.2</ref>, arrows direct the flow of AMP-Net. W φ is learning sense matrix, and W Q is learning initialization. we define K iteration as K stacking: (we use K = 9, the traditional AMP usually requires K&gt;100), each stacking include AMP calculation and balanced CNN. Inspired by <ref type="bibr" target="#b14">[15]</ref>, Our balanced CNN contains 5 blocks. Intermediate reconstruction R (k) is input, optimal reconstruction X (k) is output. The 1-st block which is composed of a convolution with 3 × 3 × 32 filters. The 2-nd block as D (k) which is composed of a convolution with 3 × 3 × 32 filters, batch normalization (BN), Rectified </p><formula xml:id="formula_5">Algorithm 2 Approximate Message Passing-Inspired Neural Network Input: Y = W φ X, W φ Output: X (N ) Parameters: θ = (W Q , W φ , P (k) , ϕ (k) ), Initialization X (0) = W Q Y , Z (0) = Y − W φ X (0) , For k=1to N: R (k) = W T φ Z (k−1) + X (k−1) X (k) = f (k) (R (k) ) Z (k) = Y − W φ X (k−1) + ϕ (k) Z (k−1)</formula><p>linear unit (ReLU), a convolution with 3 × 3 × 32filters. The 3-rd block which is composed of batch normalization (BN) and Rectified linear unit (ReLU), which corresponds to the threshold function η of AMP because of its non-negativity. The 4-th block as D (k) T which is composed of a convolution with 3 × 3 × 32 filters, batch normalization (BN), Rectified linear unit (ReLU), a convolution with 3 × 3 × 32 filters. The 5-th block which is composed of a convolution with 3×3×1 filters. The skip connections (red line) can facilitate training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Loss function</head><p>Following <ref type="bibr" target="#b12">[13]</ref>, we use image block as network input to maintain speed and stability, such as in <ref type="figure" target="#fig_1">Fig.2</ref>, the dimension of blocks is 33 × 33. Given the training data (X i ) B i of each batch size, B is the number of total image block X i . To learn the network parameters θ in the Algorithm.2, we should not only minimize the CS reconstruction error (X (N ) i − X i ), but also consider the orthogonality (D (k) T D (k) = I), as shown in Eq. <ref type="bibr" target="#b3">(4)</ref>.</p><formula xml:id="formula_6">L total = L R + λL O<label>(4)</label></formula><p>The loss function includes orthogonal constraints L O , and reconstruction errors L R , λ is the regularization parameter, we empirically set λ to 0.01.</p><formula xml:id="formula_7">L R = 1/B B i=1 (X (N ) i − X i ) 2 + 2 (5) L O = 1/B B i=1 N k=1 (D (k) T D (k) − I) 2 + 2<label>(6)</label></formula><p>As shown in Eqs. <ref type="bibr" target="#b4">(5)</ref><ref type="bibr" target="#b5">(6)</ref>, Charbonnier penalty function is adopted for L R and L O with empirically set to 1e-3.</p><p>IV. AMPA-NET In this section, the overview structure of AMPA-Net is illustrated in <ref type="figure" target="#fig_3">Fig.3</ref>, and its structure can be corresponding to Algorithm.3. We will describe our approach in detail from two aspects: Framework and Attention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 3 Approximate Message Passing-Inspired Attention Neural Network</head><formula xml:id="formula_8">Input: Y = W φ X, W φ Output: X (N ) Parameters: θ = (W Q , W φ , P (k) , ϕ (k) , a Q , a (k) s , a (k) c ), Initialization X (0) = W Q Y ⊗ a Q , Z (0) = Y − W φ X (0) , For k=1to N: R (k) = W T φ Z (k−1) + X (k−1) X (k) = f (k) (R (k) ) Z (k) = Y − W φ X (k−1) + ϕ (k) Z (k−1)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Framework</head><p>In <ref type="figure" target="#fig_3">Fig.3</ref>, the arrow indicates the flow direction of AMPA-Net. We add three more attention networks for AMP-Net: initialization attention network, spatial attention network, and channel attention network. The loss function of AMPA-Net is the same as AMP-Net, as shown in Eq.(4). Comparing with AMP-Net, the learning parameters of network (a Q , a  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Attention</head><p>As mentioned above, we introduce three attention networks for CS reconstruction. These networks are as shown in <ref type="figure" target="#fig_4">Fig.4</ref>. For the initialization attention network, we use a multilayer perceptron (MLP) to obtain the attention weight a Q . The MLP is composed of a fully connected layer, Rectified linear unit (ReLU), fully connected layer, and softmax function (Softmax).</p><p>For spatial attention networks,enlightened by CBAM <ref type="bibr" target="#b25">[26]</ref>, we use both global max-pooling and global average-pooling to aggregate global information. First, global information is aggregated through average-pooling and max-pooling respectively and concatenated. Second, a convolution layer is used to get the spatial attention weight a (k) s which is composed of convolution with 3 × 3 × 1 filters (Conv) and sigmoid activation function (Sigmoid). Finally, the more informative representation is obtained by element-wise multiplication.</p><p>For channel attention network, enlightened by CBAM <ref type="bibr" target="#b25">[26]</ref>: First, global information is aggregated by average-pooling and max-pooling respectively. Second, both of them are forwarded to the same Full Convolution Network, which is composed of convolution with 3 × 3 × 8 filters (Conv)(with Zero padding), BN (batch normalization), Rectified linear unit (ReLU), convolution with 3 × 3 × 32 filters(Conv)(with Zero padding), and we add two outputs and get the channel attention weight a (k) c through sigmoid function (Sigmoid). Finally, the more informative representation is obtained by element-wise multiplication.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENT</head><p>In this section, we are divided into four parts: experimental setting, hyperparameters, ablation study, experiments in natural image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Experiment setting</head><p>Network setting: We use TensorFlow to implement our methods. In detailed, we use Adam optimization with a learning rate 0.0001, batch size of 64, the model's stacking number of 9, and the regularization parameter λ of 0.01. Empirically, we use Xavier initialization for balanced CNN (P (k) , a (k) s , a (k) c ) , Gaussian initialization for for (W Q , W φ , a Q ) and the 0.1 initialization for ϕ (k) . All models are trained and tested on Linux with GTX 1080ti GPUs.</p><p>Training setting: For the fair comparison, we use the same 91 images as the training set which has been used in previous CS works <ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref>: random extract luminance component of 8912 randomly cropped image block (each of size 33 × 33) of the image set. According to different CS ratios: (1%, 4%, 10%, 25%.30%, 40%, 50%), we train separately AMP-Net and AMP-Net.</p><p>Testing setting: Following <ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref>, we use two standard benchmark datasets for testing in CS: Set 11 <ref type="bibr" target="#b11">[12]</ref>, BSD68 <ref type="bibr" target="#b31">[32]</ref>, which have 11 and 68 gray images respectively. To test the generalization ability of our methods in a larger dataset or multichannel dataset, we test RGB image datasets (using the same network to recover the individual channels): Urban100 <ref type="bibr" target="#b27">[28]</ref>, BSDS100 <ref type="bibr" target="#b28">[29]</ref>, which have 100 and 100 RGB images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Hyperparameters</head><p>We study the impact of varying hyperparameters (epoch, stacking, batch-size, active function, the regularization parameter γ, loss function) of AMP-Net and AMPA-Net, and CS ratio is 25%, the test set is Set11 because they are often used <ref type="bibr" target="#b14">[15]</ref>. First, we study the impact of epoch and stacking numbers of our methods, other hyperparameters follow the previous network setting. <ref type="figure" target="#fig_5">Fig.5.(a)</ref> shows the average Peak Signal to Noise Ratio(PSNR) curves for Set11 of different numbers of the epoch, <ref type="figure" target="#fig_5">Fig.5.(b)</ref> shows the average PSNR curves for Set11 of different numbers of stacking. Because of the tradeoff between complexity and performance, it can be seen from <ref type="figure" target="#fig_5">Fig.5</ref> that epoch 200 and stacking 9 are the most appropriate parameters of our networks. Second, we also study the impact of batch-size and active function of AMP-Net and AMPA-Net, other hyperparameters also follow the previous network setting. <ref type="figure">Fig.6.(a)</ref> shows the average PSNR curves for Set11 of different numbers of batchsize, <ref type="figure">Fig.6.(b)</ref> shows the average PSNR curves for Set11 of different types of activation functions. They show that batch-size 64 and active function ReLU are more suitable for our networks. Finally, we also study the impact of the <ref type="figure">Fig. 6</ref>. The average PSNR curves for with respect to different batch-size and active function regularization parameter λ and loss function and emphasize that other hyperparameters also follow the previous network setting. <ref type="figure" target="#fig_6">Fig.7.(a)</ref> shows the average PSNR curves for Set11 of different numbers of λ, <ref type="figure" target="#fig_6">Fig.7.(b)</ref> shows the average PSNR curves for Set11 of different types of loss functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Ablation studies</head><p>In this sub-section, we study the contribution of AMP, balanced CNN ,the sensing network (W φ ) in AMP-Net,initialization attention(a Q ), spatial attention (a (k) c ) and s ) in AMPA-Net, to analyze the effectiveness of each component in our method. For testing, benchmark data is Set11 <ref type="bibr" target="#b12">[13]</ref>, CS ratios are (10%, 30%, 50%). The results are shown in Tab.1. In Tab.1, compared with single balanced CNN, single AMP is more important on the accuracy of CS reconstruction. Compared with the random Gaussian matrix, W φ can extract more effective information to assist CS reconstruction <ref type="bibr" target="#b29">[30]</ref>. The effect of attention mechanism on AMP-Net is more obvious when the CS rate is higher. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Experiments in natural image</head><p>We compared our proposed AMP-Net, AMPA-Net with the state-of-the-art image CS methods including optimization methods: BM3D-AMP <ref type="bibr" target="#b18">[19]</ref>, LD-AMP <ref type="bibr" target="#b19">[20]</ref>; neural networks: DR2-Net <ref type="bibr" target="#b11">[12]</ref>, Adaptive-Recon-Net (Ad-Recon-Net) <ref type="bibr" target="#b13">[14]</ref>, FCMN <ref type="bibr" target="#b31">[32]</ref>, Full-Conv <ref type="bibr" target="#b32">[33]</ref>; optimization-inspired neural networks: ISTA-Net, ISTA-Net + <ref type="bibr" target="#b14">[15]</ref>. CS ratios are (1%, 4%, 10%, 25%, 40%, 50%), and the sensing matrix is random Gaussian under-sampling.  <ref type="bibr">SET 11</ref> Tab.2 shows the results of all methods on Set11, including reconstruction accuracy and average time of reconstructing per-image. We observed that ISTA-Net, and ISTA-Net + benefited from the optimization-inspired design, achieving high accuracy across all defined CS ratios, as well as maintaining fast speed. The optimization algorithms achieve high accuracy at high CS ratios but maintain low speed, especially LD-AMP. Neural network algorithms achieve well accuracy at low CS ratios as well as maintaining high speed, especially Adaptive Recon-Net. However, our proposed AMP-Net and AMPA-Net almost outperform all the existing methods across all defined CS ratios and also maintain fast speed. Validating the generalizability of our proposed network on larger datasets (BSD68, BSDS100, and Urban100). In Tab.3-5, we compared our models with the state-of-the-art methods: LD-AMP, Ad-Recon-Net, ISTA-Net, and ISTA-Net + , and our models still surpasses other methods under all defined CS ratios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>In this paper, our method have made three highlights: <ref type="bibr" target="#b0">(1)</ref> We propose an AMP-Net which achieve the fusion of AMP algorithm and balanced CNN to address the problem of fast and accurate CS reconstruction. <ref type="bibr" target="#b1">(2)</ref> We propose the AMPA-Net which uses three attention networks to improve our AMP-Net. (3) Extensive experiments on four CS reconstruction benchmark data sets verify the effectiveness of our AMP-Net and AMPA-Net, including the convergence, speed, accuracy of the models, and the contributions of neural network, optimization algorithm, attention module. Since our AMP-Net and AMPA-Net are quite efficient, one direction of interest for our future work is expanding them to deal with other optimization problems and perform a more theoretical analysis of them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. ACKNOWLEDGE</head><p>We are committed to develop innovative compressed sensing technology in this paper. This technology(AMP-Net and AMPA-Net) has been deployed in Kunming University of science and technology(KUST) in March 2019, and the patent is filed in March 2020 as well. Our project is fully supported by Quantum Intelligence inc. in Monterrey, United States.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>The process of compressed sensing in natural images</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>The diagram of proposed AMP-Net,parts of the formulas is amp algorithm, the others are neural network</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>c ) are added, and others are the same.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>The diagram of proposed AMPA-Net,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>The diagram of attention networks in AMPA-Net</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>The average PSNR curves for with respect to different numbers of stacking and epoch</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>The average PSNR curves for with respect to different the regularization parameter γ and loss function channel attention (a (k)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 .Fig. 9 .</head><label>89</label><figDesc>Average PSNR (dB) performance comparisons on BSD68 Average PSNR (dB) performance comparisons on BSDS100</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I CONTRIBUTION</head><label>I</label><figDesc>OF ATTENTION AND THEIR COMBINATIONS IN SET11</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II AVERAGE</head><label>II</label><figDesc>PSNR (DB) AND SPEED PERFORMANCE COMPARISONS ON</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Compressed sensing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Information Theory</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1289" to="1306" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Near-Optimal Signal Recovery From Random Projections: Universal Encoding Strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E J</forename><surname>Candes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fig. 10. Average PSNR(dB) performance comparisons on Urban100</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="5406" to="5425" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Deep ADMM-Net for compressive sensing MRI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NIPS)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="10" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoseop</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaejoon</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jong</forename><surname>Chul Ye</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.06391</idno>
		<title level="m">Deep Residual Learning for Compressed Sensing CT Reconstruction via Persistent Homology Analysis</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">SparseRI: A Compressed Sensing Framework for Aperture Synthesis Imaging in Radio Astronomy. Publications of the</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wenger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Magnor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pihlström</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Astronomical Society of the Pacific</title>
		<imprint>
			<biblScope unit="volume">122</biblScope>
			<biblScope unit="issue">897</biblScope>
			<biblScope unit="page" from="1367" to="1374" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Single-Pixel Imaging via Compressive Sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M F</forename><surname>Duarte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M A</forename><surname>Davenport</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Takhar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="83" to="91" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Real-time 3D video utilizing a compressed sensing time-of-flight single-pixel camera. Optical Trapping &amp; Optical Micromanipulation XIII. Optical Trapping and Optical Micromanipulation XIII</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M P</forename><surname>Edgar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G M</forename><surname>Gibson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Spalding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="9921" to="99222" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Statistics of natural images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ruderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Network Computation in Neural Systems</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="517" to="548" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations &amp; Trends in Machine Learning</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="122" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Teboulle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Imaging Sciences</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="183" to="202" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Message-passing algorithms for compressed sensing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arian</forename><surname>Maleki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Montanari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences of the United States of America</title>
		<meeting>the National Academy of Sciences of the United States of America</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page">18914</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.05743</idno>
		<title level="m">DR2-Net: Deep Residual Reconstruction Network for Image Compressive Sensing</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Non-Iterative Reconstruction of Images from Compressively Sensed Random Measurements</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lohit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Turaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Reconnet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="449" to="458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Adaptive Measurement Network for CS Image Reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CCF Chinese Conference on Computer Vision (CCCV)</title>
		<meeting>CCF Chinese Conference on Computer Vision (CCCV)<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="407" to="417" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">ISTA-Net: Iterative Shrinkage-Thresholding Algorithm Inspired Deep Network for Image Compressive Sensing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Accelerating the convergence of the back-propagation method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T P</forename><surname>Vogl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J K</forename><surname>Mangis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rigler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">4-5</biblScope>
			<biblScope unit="page" from="257" to="263" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Analysis of approximate message passing algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Maleki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Montanari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Information Sciences &amp; Systems</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">From denoising to compressed sensing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">A</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arian</forename><surname>Maleki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">G</forename><surname>Baraniuk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Information Theory</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="5117" to="5144" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">BM3D-prgamp: compressive stacking retrieval based on BM3D denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">A</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arian</forename><surname>Maleki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">G</forename><surname>Baraniuk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE International Conference on Image Processing (ICIP)</title>
		<meeting>IEEE International Conference on Image Processing (ICIP)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2504" to="2508" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learned D-AMP: Principled Neural Network based Compressive Image Recovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">A</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Mousavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Baraniuk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1772" to="1783" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">ECG beats classification via online sparse dictionary and time pyramid matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujuan</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duo</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Chunyu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE 20th International Conference on Communication Technology (ICCT)</title>
		<meeting>IEEE 20th International Conference on Communication Technology (ICCT)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1537" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Squeeze-and-Excitation Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7132" to="7141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Image Super-Resolution Using Very Deep Residual Channel Attention Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lichen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Bineng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="286" to="301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Image reconstruction in Compressed Sensing based on single-level DWT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Workshop on Electronics, Computer &amp; Applications</title>
		<meeting>IEEE Workshop on Electronics, Computer &amp; Applications</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="941" to="944" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Projected Iterative Soft-thresholding Algorithm for Tight Frames in Compressed Sensing Magnetic Resonance Imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xiaobo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans on Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2130" to="2140" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">CBAM: Convolutional Block Attention Module</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Woo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J Y</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">New constructions of RIP matrices with fast multiplication and fewer rows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wootters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the twenty-fifth annual ACM-SIAM symposium on Discrete algorithms</title>
		<meeting>the twenty-fifth annual ACM-SIAM symposium on Discrete algorithms</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1515" to="1528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Single image super-resolution from transformed self-exemplars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="5197" to="5206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Timothy Lillicrap: deep compressed sensing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihaela</forename><surname>Rosca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Adaptive sensing and recovery via deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mousavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dasarathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G</forename><surname>Baraniuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Deepcodec</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.03386</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">J]. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Perceptual Compressive Sensing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuemei</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenye</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangming</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The First Chinese Conference on Pattern Recognition and Computer Vision (PRCV)</title>
		<imprint>
			<date type="published" when="2018-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Fully convolutional measurement network for compressive sensing image reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">328</biblScope>
			<biblScope unit="page" from="105" to="112" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
