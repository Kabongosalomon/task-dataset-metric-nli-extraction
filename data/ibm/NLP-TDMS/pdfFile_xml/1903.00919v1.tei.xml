<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">3D Graph Convolutional Networks with Temporal Graphs: A Spatial Information Free Framework For Traffic Forecasting</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Mathematical Sciences</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengzhang</forename><surname>Li</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Academy for Advanced Interdisciplinary Studies</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Center for Data Science</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiyong</forename><surname>Zhang</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">School of Automation</orgName>
								<orgName type="institution">Hangzhou Dianzi University</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanxing</forename><surname>Zhu</surname></persName>
							<email>zhanxing.zhu@pku.edu.cn</email>
							<affiliation key="aff2">
								<orgName type="department">Center for Data Science</orgName>
								<orgName type="institution">Peking University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Beijing Institute of Big Data Research (BIBDR)</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">3D Graph Convolutional Networks with Temporal Graphs: A Spatial Information Free Framework For Traffic Forecasting</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T10:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Spatio-temporal prediction plays an important role in many application areas especially in traffic domain. However, due to complicated spatiotemporal dependency and high non-linear dynamics in road networks, traffic prediction task is still challenging. Existing works either exhibit heavy training cost or fail to accurately capture the spatiotemporal patterns, also ignore the correlation between distant roads that share the similar patterns. In this paper, we propose a novel deep learning framework to overcome these issues: 3D Temporal Graph Convolutional Networks (3D-TGCN). Two novel components of our model are introduced.</p><p>(1) Instead of constructing the road graph based on spatial information, we learn it by comparing the similarity between time series for each road, thus providing a spatial information free framework. (2) We propose an original 3D graph convolution model to model the spatio-temporal data more accurately. Empirical results show that 3D-TGCN could outperform state-of-the-art baselines.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Traffic speed prediction is a crucial task for many key purposes in intelligent traffic systems and urban planning. For example, it is useful for not only explicit tasks such as calculating how many lanes a road should have, monitoring whether some places have a traffic jam, but it can also reflect road conditions for downstream traffic problems, e.g., employing it as an important feature for estimating time of arrival, route planning and traffic light control.</p><p>In traffic forecasting problems, we typically choose density <ref type="bibr" target="#b2">[Kriegel et al., 2008]</ref>, speed <ref type="bibr" target="#b3">[Ma et al., 2015]</ref> and volume <ref type="bibr">[Okutani and Stephanedes, 1984]</ref> as indicators to characterize current traffic conditions. The traffic forecasting problem can be categorized into three types, namely, based on the length of prediction, i.e., short-term (less than 30 min) <ref type="bibr">[</ref>  <ref type="bibr" target="#b3">[Ostring and Sirisena, 2001]</ref>, based on the data source, i.e., fixed sensors on several roads <ref type="bibr" target="#b3">[Li et al., 2018]</ref> and moving GPS trajectories treated with map-matching algorithm <ref type="bibr" target="#b1">[Castro et al., 2012]</ref>, and based on the road type, i.e., urban road <ref type="bibr" target="#b3">[Stathopoulos and Karlaftis, 2003</ref>] and highway <ref type="bibr" target="#b1">[Fitzpatrick et al., 2000]</ref>. These prediction types are challenging due to the complexity of spatio-temporal dependencies and particularly the uncertainty of long-term forecasting. Before data-driven approaches spring up, researchers usually apply mathematical tools such as differential equations and traditional traffic knowledge to simulate traffic behaviour by numerical simulation <ref type="bibr" target="#b3">[Vlahogianni, 2015]</ref>. This makes strong assumptions, such as drivers' identical behaviour and no sudden accidents. In the past several decades, many statistical and machine learning methods such as Auto-Regressive Integrated Moving Average (ARIMA) models <ref type="bibr" target="#b3">Williams and Hoel, 2003]</ref>, support vector regression (SVR) <ref type="bibr" target="#b2">[Hong, 2011]</ref> were proposed. However, these methods rely on the stationary assumption of time series that are hard to model highly non-linear traffic flow and they ignore the correlation between different roads. Meanwhile, some works consider spatial structure of input data, namely, applying convolutional neural network (CNN) to capture the adjacent correlation and recurrent neural network (RNN) or long shortterm memory (LSTM) network on time axis <ref type="bibr" target="#b3">[Ma et al., 2017;</ref><ref type="bibr">Wu and Tan, 2016;</ref><ref type="bibr">Zhao et al., 2017]</ref>. However, normal convolutional operation applies on grid structures such as images and videos, not suitable for traffic networks; and training of RNN, LSTM networks is time consuming and difficult.</p><p>To model temporal pattern and spatial dependencies effectively, recent works introduce graph convolutional network (GCN) to learn the traffic networks <ref type="bibr" target="#b3">[Li et al., 2018;</ref><ref type="bibr">Defferrard et al., 2016]</ref>. DCRNN <ref type="bibr" target="#b3">[Li et al., 2018]</ref> utilizes the bi-directional random walks on the traffic graph to model spatial information; and captures temporal dynamics by gated recurrent units (GRU). This sequence-to-sequence model performs well at the cost of very expensive computation during training. STGCN <ref type="bibr">[Yu et al., ]</ref> relies on graph convolution on spatial domain and 1-D convolution along time axis. Though STGCN could significantly save training time due to its pure convolution operations, it processes graph information and time series separately, unfortunately, which might ignore accurately modeling the interaction between spatial and temporal dynamics.</p><p>On the other hand, existing graph-based prediction approaches consider the relationship between roads by relying on the graph constructed based on the spatial distance (e.g. GPS distance), or road connectivity. However, in some practical scenarios, the spatial adjacency matrix is difficult to generate, since for some free editable maps such as <ref type="bibr">Open-StreetMap [Haklay and Weber, 2008]</ref>, acquiring up-to-date and accurate spatial topology information is hard. Meanwhile, the service of commercial map is expensive and its API will constrain query times for distance calculation 1 . More importantly, we argue that this way of graph construction unfortunately ignores the correlation between distant roads that share the similar temporal pattern. For instance, at rush hours, most roads near office buildings that have similar traffic patterns will encounter traffic jams in the same period. Both of these influence could be extracted from the time series themselves.</p><p>To overcome the drawbacks above, we propose a novel methodology for improving traffic prediction from aspects of both model design and graph construction. To extract better spatio-temporal dependencies, we propose a 3D graph convolution network where 3D convolution is applied to simultaneously learn the spatial and temporal patterns together. Furthermore, we offer a spatial information free approach for constructing the graph for traffic network, purely relying on the similarity of time series for each road. This new proposal could capture more effective patterns between different roads than the spatial graph, facilitating superior prediction performance. The contributions of this work can be summarized as follows.</p><p>1. We create a 3D GCN model to jointly learn the static road graph and temporal dynamics together. This new network structure strikes a better balance between training efficiency and effectiveness of feature learning.</p><p>2. Instead of using spatial information, we construct the adjacency matrix between nodes only according to the time series similarity by dynamic time warping (DTW) algorithm. The difference between the two types of graph construction is presented in <ref type="figure">Figure 1</ref>. It solves the difficulty of acquirement of geographic information. We empirically show that the performance of this temporal graph performs much better than spatial graph. To the best of our knowledge, it is the first time to put aside spatial adjacency matrix and construct spatio-temporal graph by a data-driven method which extracts effective features from road networks' time series themselves.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">We conduct extensive experiments on two open largescale real-world datasets. Results show both of 3D</head><p>GCN model and our spatial information free graph ob- <ref type="figure">Figure 1</ref>: Comparison between the constructed graphs based on spatial distance and similarity of time series, respectively. tains significant improvement over state-of-the-art baseline methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminary</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Traffic Forecasting Problem</head><p>We can represent the road network as a graph G = (V, E, W ), where V is a finite set of nodes |V| = n, corresponding to observation of n sensors or roads; E is a set of edges and W ∈ R n×n is a weighted adjacency matrix representing the nodes proximity (e.g. spatial distance or temporal similarity). Denote the observed graph signal X ∈ R n×d , the element of which means observed traffic flow of each sensor. Let X (t) represents the graph signal on time step t. The aim of traffic forecasting is learning a function h(·) from previous M speed observations to predict next H-th traffic speed from N correlated sensors on the road network.</p><p>[</p><formula xml:id="formula_0">X (t−M +1) , · · · , X t ] h(·) −−→ G [X t+H ]<label>(1)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Convolution on graphs</head><p>Different from normal convolutional operation which processes regular grids on images or videos, graph convolution operation mainly has two types. One is based on the spectrum of the graph Laplacian, namely, extending convolutions to graphs in spectral domain by finding the corresponding Fourier basis <ref type="bibr" target="#b1">[Bruna et al., 2013]</ref>. The other is generalizing spatial neighbours by rearranging the neighbours of vertices in a graph to apply regular convolutional operation <ref type="bibr" target="#b3">[Niepert et al., 2016]</ref>. Graph convolutional operation based on the spectrum is able to extract local features with different reception fields from non-Euclidean structures <ref type="bibr" target="#b1">[Hammond et al., 2011]</ref>. It is defined over a graph G = (V, W ), where V(|V| = n) is the set of all vertices in this graph and W ∈ R n×n is the adjacency matrix whose entries represent certain distance between vertices. Let its normalized graph Laplacian matrix be</p><formula xml:id="formula_1">L = I n − D − 1 2 W D − 1 2 = U ΛU T , where I n is an identity matrix, D ∈ R n×n is the degree matrix with D ii = j W ij .</formula><p>U ∈ R n×n is the Fourier basis which is composed of eigenvectors of Laplacian matrix L. The graph signal X ∈ R n is filtered by a diagonal matrix kernel Λ θ with multiplication between U and U T X:X</p><formula xml:id="formula_2">= U Λ θ U T X<label>(2)</label></formula><p>where the kernel Λ θ is a group of parameters to be trained, andX denotes the output of this GCN layer.</p><p>To reduce the number of parameters and generate a kernel which has better spatial localization, the kernel Λ θ can be redesigned as the Chebshev polynomial Λ θ ≈ K−1 k=0 θ k P k (Λ), It has a truncated order K − 1 and utilizes the largest eigenvalue of L to rescale Λ:Λ = 2Λ/λ max − I n <ref type="bibr">[Defferrard et al., 2016]</ref>.</p><p>Then we could reformulate Equation 2 into:</p><formula xml:id="formula_3">X ≈ K−1 k=0 U θ k P k (Λ)U T X = θ k P k (L)X<label>(3)</label></formula><p>whereL = 2L/λ max − I n is the scaled Laplacian and θ 1 , θ 2 , · · · , θ k are parameters which could be trained by Back Propagation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Similarity of Temporal Sequences</head><p>Generally speaking, the methods for measuring the similarity between time series can be divided into three categories: <ref type="formula" target="#formula_0">(1)</ref> timestep-based, such as Euclidean distance reflecting pointwise temporal similarity; (2) shape-based, such as Dynamic Time Warping <ref type="bibr" target="#b1">[Berndt and Clifford, 1994]</ref> according to the trend appearance;</p><p>(3) change-based, such as Gaussian Mixture Model(GMM) <ref type="bibr" target="#b3">[Povinelli et al., 2004]</ref> which reflects similarity of data generation process.</p><p>In this work, we utilize Dynamic Time Warping to measure similarity i.e., the spatial shape of time series, between different roads to predict future time series. Given two time series X = (x 1 , x 2 , · · · , x n ) and Y = (y 1 , y 2 , · · · , y m ) whose length are n and m. We first introduce a series distance matrix M n×m whose entry is Euclidean distance of two series points M i,j = |x i − y j |. Then we can define the cost matrix (accumulated distance matrix) M c :</p><formula xml:id="formula_4">Mc(i, j) = Mi,j + min(Mc(i, j − 1), Mc(i − 1, j), Mc(i, j)) (4)</formula><p>After several iterations of i and j (i.e., each of them increases from 1 to n and m), M c (n, m) is the final distance between X and Y with the best alignment which can represent the similarity between two time series.</p><p>From Equation <ref type="formula">4</ref> we can tell that Dynamic Time Warping is an algorithm based on dynamic programming and its core is solving the warping curve, i.e., matchup of series points x i and y j . In other words the "warping path"</p><formula xml:id="formula_5">Ω = (ω 1 , ω 2 , · · · , ω K ), max(n, m) ≤ K ≤ n + m</formula><p>is generated through iterations of Equation 4. Its element ω k = (i, j) means matchup of x i and y j . The warping path Ω starts from ω 1 = (1, 1) and ends with ω K = (n, m) thus every series points of X and Y must appear in W . Moreover, i and j in ω(i, j) must increase monotonically to avoid crossover of each matchup. For instance, given ω k = (i, j) and ω k+1 = (i , j ) then i ≤ i ≤ i + 1 and j ≤ j ≤ j + 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Proposed Model: 3D-TGCN</head><p>In this section, we explicitly formalize the spatio-temporal traffic prediction problem and describe our 3D Temporal Graph Convolutional Networks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Graph Generation</head><p>Different from those proposed models that requires spatial adjacency matrix, 3D-TGCN could learn those roads' interior temporal pattern by calculating their corresponding time series' distance. This way of graph construction is completely data-driven, helping to capture more effective information than the priori given spatial information. For instance, if traffic data are aggregated every 5 minutes then each road has 288 time steps in one day. Given time series A ∈ R 288×1 for one road and time series B ∈ R 288×1 of another, then we could utilize Dynamic Time Warping algorithm to find optimal match and calculate distance of their time series.</p><p>As shown in <ref type="figure" target="#fig_0">Figure 2</ref>, given two roads' time series whose length is 288 then we could achieve their warping path. The distance of those two time series could be calculated by Equation 4 (i.e., M c (288, 288) in this case). From the figure we could tell the warping path elongates along the diagonal since the trend of two time series are similar, consequently the difference between match i and j of the element ω k = (i, j) of warping path Ω are close.</p><p>Then we generate topology network W . For each road i, we pick up its top 5% most similar roads S = {j, k, · · · } and let W ij = W ik = · · · = 1 while others W is = 0, s / ∈ S. Moreover, it is possible that W ij = 1 while W ji = 0, then we reassign W ji = 1 if W ij = 1. After this treatment, the constructed W could be applied in our 3D-TGCN model, described in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">3D Graph Convolution Networks 3D Graph Convolutional Layer</head><p>Many existing approaches deal with spatial and temporal dependencies separately since they utilize graph convolution on spatial dependencies and leverage 1-D CNN <ref type="bibr">[Yu et al., ]</ref> or RNN-based models <ref type="bibr" target="#b3">[Li et al., 2018]</ref> to extract temporal dependency along time axis. For instance, if 1-D CNN was deployed in the temporal direction, the output of each 1-D convolution could be rewritten as, where K t is the size of convolutional kernel on time-axis at time step t. We now propose a 3D graph convolutional operation on all dimensions, including graph topology and temporal direction.</p><formula xml:id="formula_6">X t = Kt−1 t =0 θ (t) t K−1 k=0 θ kL k X t−t<label>(5)</label></formula><p>For the input X t (1 ≤ t ≤ M ) with C i channels, it can be extended to multi-dimensional arrays X t ∈ R n×Ci . The 3D graph convolutional layer integrates all dimensions together:</p><formula xml:id="formula_7">X t,Co = Ci i=1 Kt−1 t =0 K−1 k=0 θ i,Co,k,t L k X (t−t ),i , t = K t , K t + 1, ..., M<label>(6)</label></formula><p>where C i and C o are the size of input and output of this 3D graph convolutional layer, respectively and θ i,Co,k,t is the parameter to be trained in each output channel of this layer. From Equation 6, the graph convolution operator of each layer could be denoted as "Θ * G X" with Θ ∈ R Ci×Co×Kt×K .</p><p>The 3D graph convolutional layer scans K t neighbours on time-axis without padding and (K − 1)-order neighbourhood of temporal graph G at the same time. This method shortens the length of sequences by K t − 1 each time. It follows by a gated linear units (GLU) whose input is:</p><formula xml:id="formula_8">[G, H] ∈ R (M −Kt+1)×(2×Co)</formula><p>where G, H is split in half with the size of C o channels. As a result, the final output of 3D graph convolutional layer isX = G σ(H) ∈ R (M −Kt+1)×Co where denotes the Hadamard product and σ(·) denotes the sigmoid function.</p><p>This integrated design of 3D graph convolution allows us to jointly learn graph structure and temporal dynamics as a whole. It is also easy for building such multi-layer 3D graph convolutional structures. <ref type="figure" target="#fig_1">Figure 3</ref> sketches the overall architecture of our proposed 3D-TGCN model. It consists of four 3D graph convolutional blocks (3D-Conv blocks), one output block. Each 3D-Conv block contains two 3D graph convolutional layers and a layer normalization layer to prevent overfitting. The output block consists of several 3D graph convolutional layers or 1D temporal convolutional layers and a weight sharing fullyconnected output layer to obtain the predictionX T +H ∈ R n .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">The Entire Architecture of 3D-TGCN Network</head><p>The L 2 loss and L 1 loss will be used together to train our model and the loss function of 3D-TGCN model could be formulated as below:</p><formula xml:id="formula_9">L(X; ∆ θ ) = t ( 1 2 X t+H − X t+H ) 2 2 + X T +H − X T +H 1 )<label>(7)</label></formula><p>In summary, our 3D-TGCN model has several advantages:</p><p>• 3D-TGCN does not require spatial adjacency matrix, instead, it constructs temporal adjacency matrix to learn temporal patterns of different roads in a pure data-driven way.</p><p>• The 3D graph convolution integrates all dimensions (i.e., time-axis on each road and correlation between different roads) into one graph convolutional networks. This design presents a better balance between training efficiency and effectiveness of feature learning on complex spatio-temporal graph, compared with STGCN and DCRNN.</p><p>• 3D-TGCN could be applied into many other tasks that have spatio-temporal features. Its universal framework can learn spatio-temporal dependencies between each participant. By calculating similarity between time series, 3D-TGCN could extract important temporal pattern of different participants which might appear uncorrelated and make accurate prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>Our model is verified on two real-world traffic datasets which are used by two related state-of-the-art models: STGCN <ref type="bibr">[Yu et al., ]</ref> and DCRNN <ref type="bibr" target="#b3">[Li et al., 2018]</ref>.</p><p>PeMSD7 has a medium and a large scale PeMSD7 (M) and PeMSD7 (L) containing 228 and 1, 026 sensors separately among the District 7 of California. The data ranges from May and June of 2012 which are all at weekdays.</p><p>PEMS-BAY has 325 sensors in Bay Area and its collecting time is 6 months, ranging from Jan 2017 to June 2017. These datasets are collected from California Transportation Agencies (Caltrans) Performance Measurement System (PeMS) in real-time by over 39, 000 sensor stations, which are deployed in the major metropolitan areas of California highway system <ref type="bibr" target="#b1">[Chen et al., 2001]</ref>. It is aggregated into 5minute interval (228 time steps per day). To compared strictly with those state-of-the-art models, we follow all data preprocessing methods in each paper such as (1) the proportion and content of training, validation and test set, (2) utilizing the Gaussian kernel <ref type="bibr" target="#b3">[Shuman et al., 2012]</ref> to construct the spatial adjacency matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Settings and Baselines</head><p>All experiments are compiled and tested on a Linux cluster(CPU: Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.20GHz, GPU: Tesla P40). All model parameters are fine-tuned by gird search based on performance on validation set. Each prediction task uses past 60 minutes (i.e., 12 time steps are in time window M = 12) to forecast traffic conditions in the next 15, 30 and 60 minutes (H = 3, 6, 12). Evaluation Metric Several criteria are introduced to evaluate 3D-TGCN, including the Mean Absolute Percentage Errors (MAPE), the Mean Absolute Errors (MAE) and the Root Mean Squared Errors (RMSE). All of them are used widely in traffic prediction tasks. 3D-TGCN model The channels of each 3D graph convolutional layer in 3D-Conv block is 64. Receptive field of temporal graph K is set to 3 and K t is set to 2. We use GLU as activation function in 3d-Conv block and sigmoid in output block. The learning rate is set to 1e − 2 with a decay rate of 0.7 after 3 epochs. We train our models by minimizing the mean square error and mean absolute error using Adam for 30 epochs with batch size as 50.</p><p>Baselines We compare our model with several baselines as follows:</p><p>• HA Historical Average (HA), which treats the traffic speed value as a seasonal process and use weighted average of past several seasons as prediction value. • SVR Support Vector Regression (SVR), which uses linear support vector machine for regression tasks. • FNN Feed-Forward Neural Network (FNN), which is a classical neural network architecture with two hidden layers and loss function is RMSE. • FC-LSTM Full-Connected LSTM <ref type="bibr">[Sutskever et al., 2014]</ref>, which is a Recurrent Neural Network with fully connected LSTM hidden units. • DCRNN Diffusion Convolutional Rrcurrent Neural Network(DCRNN) <ref type="bibr" target="#b3">[Li et al., 2018]</ref>, which models spa-tiotemporal dependencies with graph convolution into gated recurrent unit.</p><p>• STGCN Spatio-Temporal Graph Convolutional Networks(STGCN) <ref type="bibr">[Yu et al., ]</ref>, which models spatiotemporal dependencies with graph convolution into convolution structures.</p><p>All neural network based models are implemented in Tensorflow <ref type="bibr" target="#b0">[Abadi et al., 2016]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Experiment Results</head><p>In this section, we compare our model with those baselines on the two datasets, shown in <ref type="table">Table 1</ref> and 4. It is obvious to observe that, although all methods could perform well in short-term prediction, their performance varies greatly in long-term prediction. Deep learning models generally can achieve better performance than traditional machine learning models. Especially, STGCN and DCRNN, both of them have achieved significant improvement over other deep learning approaches since they extract additional information from spatial topology graph. 3D-TGCN could achieve the state-ofart performance especially when it only combines with temporal graph, demonstrating the importance of our proposed graph construction.</p><p>Accumulated Error of Sequence-to-Sequence Prediction RNN-based model and CNN model are different especially on the format of their output: while RNN-based ones conduct the next few time steps recursively, GCNs could predict few time steps recursively or directly predict the target time step. Generally, RNN-based model performs better in time series tasks since the strategies such as scheduled sampling <ref type="bibr">[Bengio et al., 2015]</ref> which can reduce accumulated error could be adopted on the sequence-to-sequence architecture. To compare these two types of outputs, we check the performance of 3D-TGCN: (1) predicting directly next H-th time step, (2) predicting the value of next 1, 2, · · · , H time steps recursively. As we can see from <ref type="table" target="#tab_3">Table 2</ref>, 3D-TGCN is more suitable for single step prediction task, it performs worse when predicting recursively due to accumulated error since its performance is close to DCRNN. However, 3D-TGCN could achieve better training efficiency since convolutiontype models have less parameters than RNN-based models and STGCN.</p><p>Temporal v.s. Spatial Pattern Previous works focus on incorporating spatial topology information of roads into time   series prediction. Differently, our model switches to their dependencies of temporal patterns and has achieved the best performance on both short and long-term forecasting. The results of two types of graph construction are shown in Table 3. The performance of 3D-TGCN on dataset PeMSD7 is extremely well because road network of PeMSD7 is more complicated and systematic.</p><p>3D-TGCN does not require priori knowledge of spatial topology. On the contrary, it builds graphs on temporal dependency. As illustrated in <ref type="figure">Figure 1</ref>, the left panel is spatial graph and right is temporal graph, the sparsity of them are both 5%. The reason why temporal graph tends to be better than the spatial one is intuitive: (1) realistic data is full of noise, similar temporal dependency of different roads (maybe at distance) is much more important than spatial causality of neighbors; (2) traffic prediction is a time-series prediction task thus learning temporal pattern is more directly meaningful.</p><p>An involuntary doubt about dynamic time warping is its computational complexity. Although O(n 2 ) is somewhat costly, in traffic prediction problem it is acceptable since the length of time series is 288 when time step is 5 min. Dataset PeMSD7(L) is one of biggest dataset in academic traffic speed field which has 1026 roads, in which the scalable version of DTW algorithm is still acceptable.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future works</head><p>In this paper, we propose an original and effective deep learning framework 3D-TGCN for traffic prediction. It learns the relations between roads by comparing temporal similarity from the roads' times series and merges spatial and temporal information into 3D convolution simultaneously in the 3D graph convolutional layers. Numerical experiments show our model outperforms existing state-of-the-art models on two real-world datasets. Especially, our model does not require spatial topology. 3D-TGCN also achieves faster training and better convergence. Our discovery of the new way of graph generation paves a promising way for future graphbased learning approaches, due to the no need for spatial information based adjacency matrix, which in many cases are difficult to generate or achieve.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Two time series of different roads in one day and their warping path calculated by Dynamic Time Warping algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Network architecture of 3D-TGCN</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>LSTM 3.57/ 3.92/ 4.16 8.60/ 9.55/ 10.10 6.20/ 7.03/ 7.51 4.36/ 4.51/ 4.66 11.10/ 11.41/ 11.69 7.68/ 7.94/ 8.</figDesc><table><row><cell>Model</cell><cell>MAE</cell><cell>PeMSD7(M) (15/ 30/ 60 min) MAPE (%)</cell><cell>RMSE</cell><cell>MAE</cell><cell cols="3">PeMSD7(L) (15/ 30/ 60min) MAPE (%)</cell><cell>RMSE</cell></row><row><cell>HA</cell><cell>4.01</cell><cell>10.61</cell><cell>7.20</cell><cell>4.60</cell><cell></cell><cell>12.50</cell><cell>8.05</cell></row><row><cell>LSVR</cell><cell cols="5">2.49/ 3.46/ 4.94 5.91/ 8.42/ 12.41 4.55/ 6.44/ 9.08 2.69/ 3.85/ 4.79</cell><cell>6.27/ 9.48/ 12.42</cell><cell>4.88/ 7.10/ 8.72</cell></row><row><cell>FNN</cell><cell cols="5">2.53/ 3.73/ 5.28 6.05/ 9.48/ 13.73 4.46/ 6.46/ 8.75 2.61/ 3.71/ 5.36</cell><cell>6.11/ 9.20/ 14.68</cell><cell>4.74/ 6.76/ 9.09</cell></row><row><cell cols="8">FC-20</cell></row><row><cell>STGCN</cell><cell cols="5">2.24/ 3.02/ 4.01 5.20/ 7.27/ 9.77 4.07/ 5.70/ 7.55 2.37/ 3.27/ 4.35</cell><cell>5.56/ 7.98/ 11.17</cell><cell>4.32/ 6.21/ 8.27</cell></row><row><cell>DCRNN</cell><cell cols="5">2.25/ 2.98/ 3.83 5.30/ 7.39/ 9.85 4.04/ 5.58/ 7.19 2.36/ 3.24/ 4.34</cell><cell>5.51/ 8.18/ 11.91</cell><cell>4.45/ 6.31/ 8.33</cell></row><row><cell cols="6">3D-TGCN 2.23/ 2.97/ 3.65 5.13/ 7.08/ 8.79 3.93/ 5.31/ 6.66 2.27/ 3.16/ 3.79</cell><cell>5.31/ 7.85/ 9.76</cell><cell>4.18/ 5.71/ 7.13</cell></row><row><cell></cell><cell></cell><cell cols="5">Table 1: Performance comparison of different models on PeMSD7 dataset.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>.98/ 3.83 5.30/ 7.39/ 9.85 4.04/ 5.58/ 7.19 STGCN 2.24/ 3.02/ 4.01 5.20/ 7.27/ 9.77 4.07/ 5.70/ 7.55 3D-TGCN (iteration) 2.25/ 2.97/ 3.77 5.17/ 7.10 9.05 4.06/ 5.59/ 7.19 3D-TGCN (straightly) 2.23/ 2.97/ 3.65 5.13/ 7.08/ 8.79 3.93/ 5.31/ 6.66</figDesc><table><row><cell>Model</cell><cell>MAE</cell><cell>PeMSD7(M) (15/ 30/ 60 min) MAPE (%)</cell><cell>RMSE</cell></row><row><cell>DCRNN</cell><cell>2.25/ 2</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Performance comparison of iteration / no iteration.</figDesc><table><row><cell>Model</cell><cell>MAE</cell><cell>PeMSD7(M) (15/ 30/ 60 min) MAPE (%)</cell><cell>RMSE</cell></row><row><cell>STGCN (spatial)</cell><cell cols="3">2.24/ 3.02/ 4.01 5.20/ 7.27/ 9.77 4.07/ 5.70/ 7.55</cell></row><row><cell>STGCN (temporal)</cell><cell cols="3">2.24/ 3.02/ 3.92 5.19/ 7.13/ 9.29 4.06/ 5.61/ 7.15</cell></row><row><cell>DCRNN (spatial)</cell><cell cols="3">2.25/ 2.98/ 3.83 5.30/ 7.39/ 9.85 4.04/ 5.58/ 7.19</cell></row><row><cell cols="4">DCRNN (temporal) 2.26/ 2.98/ 3.66 5.33/ 7.33/ 9.27 4.04/ 5.50/ 6.73</cell></row><row><cell>TGCN (spatial)</cell><cell cols="3">2.24/ 3.00/ 3.76 5.21/ 7.12/ 8.96 3.96/ 5.37/ 6.64</cell></row><row><cell>TGCN (temporal)</cell><cell cols="3">2.23/ 2.97/ 3.65 5.13/ 7.08/ 8.79 3.93/ 5.31/ 6.66</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Performance comparison of spatial and temporal matrices.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>TGCN 1.34/ 1.69/ 2.07 2.78/ 3.76/ 4.76 2.79/ 3.71/ 4.56</figDesc><table><row><cell>Model</cell><cell>MAE</cell><cell cols="3">PEMS-BAY (15/ 30/ 60 min) MAPE (%)</cell><cell>RMSE</cell></row><row><cell>HA</cell><cell>2.88</cell><cell></cell><cell>6.80</cell><cell>5.59</cell></row><row><cell>SVR</cell><cell cols="4">1.85/ 2.48/ 3.28 3.80/ 5.50/ 8.00 3.59/ 5.18/ 7.08</cell></row><row><cell>FNN</cell><cell cols="4">1.49/ 2.04/ 2.88 3.09/ 4.59/ 7.11 3.25/ 4.45/ 5.99</cell></row><row><cell cols="5">FC-LSTM 2.20/ 2.34/ 2.55 4.85/ 5.30/ 5.84 4.28/ 4.74/ 5.31</cell></row><row><cell>STGCN</cell><cell cols="4">1.41/ 1.84/ 2.37 3.02/ 4.19/ 5.39 3.02/ 4.19/ 5.27</cell></row><row><cell>DCRNN</cell><cell cols="2">1.38/ 1.74/ 2.07</cell><cell>2.9/ 3.9/ 4.9</cell><cell>2.95/ 3.97/ 4.74</cell></row><row><cell>3D-</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Performance comparison of different models on PEMS-BAY dataset.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">For example, Baidu Map, one of the biggest commercial map app around the world, provides individual developers with at most 30, 000 query times per day and its full basic service costs 10 thousand dollars per month. See http://lbsyun.baidu.com/apiconsole/ auth/privilege.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Scheduled sampling for sequence prediction with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>References</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Abadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th {USENIX} Symposium on Operating Systems Design and Implementation ({OSDI} 16)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1171" to="1179" />
		</imprint>
	</monogr>
	<note>Advances in Neural Information Processing Systems</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Alexander Skabardonis, Pravin Varaiya, and Zhanfeng Jia. Freeway performance measurement system: mining loop detector data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clifford ; Donald J</forename><surname>Berndt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Clifford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Bruna</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6203</idno>
	</analytic>
	<monogr>
		<title level="m">Wavelets on graphs via spectral graph theory. Applied and Computational Harmonic Analysis</title>
		<editor>Defferrard et al., 2016] Michaël Defferrard, Xavier Bresson, and Pierre Vandergheynst</editor>
		<meeting><address><addrLine>Seattle, WA</addrLine></address></meeting>
		<imprint>
			<publisher>Haklay and Weber</publisher>
			<date type="published" when="1994" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="129" to="150" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
	<note>Spectral networks and locally connected networks on graphs</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Traffic flow forecasting by seasonal svr with chaotic simulated annealing algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong ; Wei-Chiang</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Kriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 SIAM International Conference on Data Mining</title>
		<meeting>the 2008 SIAM International Conference on Data Mining</meeting>
		<imprint>
			<publisher>SIAM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="692" to="703" />
		</imprint>
	</monogr>
	<note>Matthias Renz, Matthias Schubert, and Andreas Zuefle</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Okutani and Stephanedes, 1984] Iwao Okutani and Yorgos J Stephanedes. Dynamic prediction of traffic volume through kalman filtering theory</title>
		<idno type="arXiv">arXiv:1211.0053</idno>
	</analytic>
	<monogr>
		<title level="m">ICC 2001. IEEE International Conference on Communications. Conference Record (Cat. No. 01CH37240)</title>
		<imprint>
			<publisher>Williams and Hoel</publisher>
			<date type="published" when="1984" />
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="664" to="672" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Journal of transportation engineering</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Shortterm traffic flow forecasting with spatial-temporal correlation in a hybrid deep learning framework</title>
		<idno type="arXiv">arXiv:1612.01022</idno>
		<editor>and Tan, 2016] Yuankai Wu and Huachun Tan</editor>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Spatio-temporal graph convolutional networks: A deep learning framework for traffic forecasting</title>
	</analytic>
	<monogr>
		<title level="m">2004 IEEE International Conference on Acoustics, Speech, and Signal Processing</title>
		<editor>Zhao, Weihai Chen, Xingming Wu, Peter CY Chen, and Jingmeng Liu</editor>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2004" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="68" to="75" />
		</imprint>
	</monogr>
	<note>Lstm network: a deep learning approach for short-term traffic forecast</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
