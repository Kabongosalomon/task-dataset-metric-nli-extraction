<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Evaluating Contextualized Embeddings on 54 Languages in POS Tagging, Lemmatization and Dependency Parsing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-08-20">20 Aug 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milan</forename><surname>Straka</surname></persName>
							<email>straka@ufal.mff.cuni.cz</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Mathematics and Physics Institute of Formal and Applied Linguistics</orgName>
								<orgName type="institution">Charles University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jana</forename><surname>Straková</surname></persName>
							<email>strakova@ufal.mff.cuni.cz</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Mathematics and Physics Institute of Formal and Applied Linguistics</orgName>
								<orgName type="institution">Charles University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hajič</surname></persName>
							<email>hajic@ufal.mff.cuni.cz</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Mathematics and Physics Institute of Formal and Applied Linguistics</orgName>
								<orgName type="institution">Charles University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Evaluating Contextualized Embeddings on 54 Languages in POS Tagging, Lemmatization and Dependency Parsing</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-08-20">20 Aug 2019</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T22:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present an extensive evaluation of three recently proposed methods for contextualized embeddings on 89 corpora in 54 languages of the Universal Dependencies 2.3 in three tasks: POS tagging, lemmatization, and dependency parsing. Employing the BERT, Flair and ELMo as pretrained embedding inputs in a strong baseline of UDPipe 2.0, one of the best-performing systems of the CoNLL 2018 Shared Task and an overall winner of the EPE 2018, we present a one-toone comparison of the three contextualized word embedding methods, as well as a comparison with word2vec-like pretrained embeddings and with end-to-end character-level word embeddings. We report state-of-the-art results in all three tasks as compared to results on UD 2.2 in the CoNLL 2018 Shared Task. Input word cat Pretrained embeddings. Trained embeddings. c a t GRU GRU GRU Character-level word embeddings. Word 1 embeddings ... ... LSTM ... LSTM Word 2 embeddings LSTM LSTM Word N embeddings LSTM LSTM</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>We publish a comparison and evaluation of three recently proposed contextualized word embedding methods: <ref type="bibr">BERT (Devlin et al., 2018)</ref>, <ref type="bibr">Flair (Akbik et al., 2018)</ref> and ELMo <ref type="bibr" target="#b8">(Peters et al., 2018)</ref>, in 89 corpora which have a training set in 54 languages of the Universal Dependencies 2.3 in three tasks: POS tagging, lemmatization and dependency parsing. Our contributions are the following:</p><p>• Meaningful massive comparative evaluation of <ref type="bibr">BERT (Devlin et al., 2018)</ref>, <ref type="bibr">Flair (Akbik et al., 2018)</ref> and ELMo <ref type="bibr" target="#b8">(Peters et al., 2018)</ref> contextualized word embeddings, by adding them as input features to a strong baseline of UDPipe 2.0, one of the best performing systems in the CoNLL 2018 Shared Task <ref type="bibr" target="#b12">(Zeman et al., 2018)</ref> and an overall winner of the EPE 2018 Shared Task <ref type="bibr" target="#b1">(Fares et al., 2018)</ref>. • State-of-the-art results in POS tagging, lemmatization and dependency parsing in UD 2.2, the dataset used in CoNLL 2018 Shared Task <ref type="bibr" target="#b12">(Zeman et al., 2018)</ref>. • We report our best results on UD 2.3. The addition of contextualized embeddings improvements range from 25% relative error reduction for English treebanks, through 20% relative error reduction for high resource languages, to 10% relative error reduction for all UD 2.3 languages which have a training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>A new type of deep contextualized word representation was introduced by <ref type="bibr" target="#b8">Peters et al. (2018)</ref>. The proposed embeddings, called ELMo, were obtained from internal states of deep bidirectional language model, pretrained on a large text corpus. <ref type="bibr">Akbik et al. (2018)</ref> introduced analogous contextual string embeddings called Flair, which were obtained from internal states of a character-level bidirectional language model. The idea of ELMos was extended by <ref type="bibr">Devlin et al. (2018)</ref>, who instead of a bidirectional recurrent language model employ a Transformer <ref type="bibr">(Vaswani et al., 2017)</ref> architecture.</p><p>The Universal Dependencies 1 project <ref type="bibr" target="#b6">(Nivre et al., 2016)</ref> seeks to develop cross-linguistically consistent treebank annotation of morphology and syntax for many languages. The latest version UD 2.3  consists of 129 treebanks in 76 languages, with 89 of the treebanks containing a train a set and being freely available. The annotation consists of UPOS (universal POS tags), XPOS (language-specific POS tags), Feats (universal morphological features), Lemmas, dependency heads and universal dependency labels.</p><p>In 2017 and 2018, CoNLL Shared Tasks Multilingual Parsing from Raw Text to Universal Dependencies <ref type="bibr" target="#b13">(Zeman et al., 2017</ref><ref type="bibr" target="#b12">(Zeman et al., , 2018</ref> were held in order to stimulate research in multi-lingual POS </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head><p>Our baseline is the UDPipe 2.0 <ref type="bibr" target="#b10">(Straka, 2018)</ref> participant system from the CoNLL 2018 Shared Task <ref type="bibr" target="#b12">(Zeman et al., 2018)</ref>. The system is available at http://github.com/CoNLL-UD-2018/ UDPipe-Future.</p><p>A graphical overview of the UDPipe 2.0 is shown in <ref type="figure">Figure 1</ref>. In short, UDPipe 2.0 is a multitask model predicting POS tags, lemmas and dependency trees jointly. After embedding input words, two shared bidirectional LSTM (Hochreiter and Schmidhuber, 1997) layers are performed. Then, tagger and lemmatizer specific bidirectional LSTM layer is executed, with softmax classifiers processing its output and generating UPOS, XPOS, Feats and Lemmas. The lemmas are generated by classifying into a set of edit scripts which process input word form and produce lemmas by performing character-level edits on the word prefix and suffix. The lemma classifier additionally takes the character-level word embeddings as input.</p><p>Finally, the output of the two shared LSTM layers is processed by a parser specific bidirectional LSTM layer, whose output is then passed to a biaffine attention layer <ref type="bibr" target="#b0">(Dozat and Manning, 2016)</ref> producing labeled dependency trees. We refer the readers for detailed treatment of the architecture and the training procedure to <ref type="bibr" target="#b10">Straka (2018)</ref>. The simplest baseline system uses only end-toend word embeddings trained specifically for the task. Additionally, the UDPipe 2.0 system also employs the following two embeddings:</p><p>• word embeddings (WE): We use FastText word embeddings <ref type="bibr">(Bojanowski et al., 2017)</ref> of dimension 300, which we pretrain for each language on Wikipedia using segmentation and tokenization trained from the UD data. 2 • character-level word embeddings (CLE):</p><p>We employ bidirectional GRUs of dimension 256 in line with <ref type="bibr" target="#b5">Ling et al. (2015)</ref>: we represent every Unicode character with a vector of dimension 256, and concatenate GRU output for forward and reversed word characters. The character-level word embeddings are trained together with UDPipe network. Optionally, we add pretrained contextual word embeddings as another input to the neural network. Contrary to finetuning approach used by the BERT authors <ref type="bibr">(Devlin et al., 2018)</ref>, we never finetune the embeddings.</p><p>•  Employing only the BERT embeddings results in significant improvements, compared to both WE and CLE individually, with highest increase for syntactic parsing, less for morphology and worse performance for lemmatization than CLE. Considering BERT versus WE+CLE, BERT offers higher parsing performance, comparable UPOS accuracy, worse morphological features and substantially lower lemmatization performance. We therefore conclude that the representation computed by BERT captures higher-level syntactic and possibly even semantic meaning, while providing less information about morphology and orthographical composition required for lemmatization.</p><p>Combining BERT and CLE results in an increased performance, especially for morphological features and lemmatization. The addition of WE provides minor improvements in all metrics, suggesting that the BERT embeddings encompass substantial amount of information which WE adds to CLE. In total, adding BERT embeddings to a baseline with WE and CLE provides a 16.9% relative error reduction for UPOS tags, 12% for mor-  phological features, 4.3% for lemmatization, and 14.5% for labeled dependency parsing. The influence of multilingual and languagespecific BERT models is analyzed in <ref type="table" target="#tab_2">Table 2</ref>. Surprisingly, averaged results of the four English treebanks show very little decrease when using the multilingual BERT model compared to Englishspecific one, most likely owing to the fact that English is the largest language used to train the multilingual model. Contrary to English, the Chinese BERT model shows substantial improvements compared to a multilingual model when utilized on the Chinese-GSD treebank, and minor improvements on the Japanese-GSD treebank.</p><p>Note that according to the above comparison, the substantial improvements offered by BERT embeddings can be achieved using a single multilingual model, opening possibilities for interesting language-agnostic approaches. <ref type="table" target="#tab_4">Table 3</ref> shows the experiments in which WE, CLE, Flair and BERT embeddings are added to the baseline, averaging results for 23 UD 2.3 treebanks for which the Flair embeddings were available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Flair</head><p>Comparing Flair and BERT embeddings, the former demonstrates higher performance in POS tagging, morphological features, and lemmatization, while achieving worse results in dependency parsing, suggesting that Flair embeddings capture more morphological and orthographical information. A comparison of Flair+WE+CLE with BERT+WE+CLE shows that the introduc-tion of WE+CLE embeddings to BERT encompasses nearly all information of Flair embeddings, as demonstrated by BERT+WE+CLE achieving better performance in all tasks but lemmatization, where it is only slightly behind Flair+WE+CLE.</p><p>The combination of all embeddings produces best results in all metrics. In total, addition of BERT and Flair embeddings to a baseline with WE and CLE provides a 25.4% relative error reduction for UPOS tags, 18.8% for morphological features, 10% for lemmatization and 21% for labeled dependency parsing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">ELMo</head><p>Given that pretrained ELMo embeddings are available for English only, we present results for ELMo, Flair, and BERT contextualized embeddings on four macro-averaged English UD 2.3 treebanks in <ref type="table" target="#tab_6">Table 4</ref>.</p><p>Flair and BERT results are consistent with the previous experiments.</p><p>Employing solely ELMo embeddings achieves best POS tagging and lemmatization compared to using only BERT or Flair, with dependency parsing performance higher than Flair, but lower than BERT. Therefore, ELMo embeddings seem to encompass the most morphological and ortographical features compared to BERT and Flair, more syntactical features than Flair, but less than BERT.</p><p>When comparing ELMo with Flair+WE+CLE, the former surpass the latter in all metrics but lemmatization (and lemmatization performance is equated when employing ELMo+WE+CLE).   <ref type="bibr" target="#b10">(Straka, 2018</ref><ref type="bibr">) 95.73 94.79 94.11 95.12 85.28 81.83 71.71 74.67 HIT-SCIR Harbin (Che et al., 2018</ref><ref type="bibr">) 3-model ensemble 96.23 95.16 91.20 93.42 87.61 84.37 70.12 75.05 HIT-SCIR Harbin (Che et al., 2018</ref> w/o ensembling 83.75 Stanford <ref type="bibr" target="#b9">(Qi et al., 2018</ref><ref type="bibr">) 95.93 94.95 94.14 95.25 86.56 83.03 72.67 75.46 TurkuNLP (Kanerva et al., 2018</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">CoNLL 2018 Shared Task Results</head><p>Given that the inputs in the CoNLL 2018 Shared Task are raw texts, we reuse tokenization and segmentation employed by original UDPipe 2.0. Also, we pretrain WE not only on Wikipedia, but on all plaintexts provided by the shared tasks organizers. The resulting F1 scores of UDPipe 2.0 WE+CLE and WE+CLE+BERT on treebanks with development sets (so called big treebanks in the shared task) are presented in <ref type="table" target="#tab_7">Table 5</ref>.</p><p>The inclusion of BERT embeddings results in state-of-the-art single-model performance in UPOS, XPOS, UFeats, MLAS, and BLEX met-rics, and state-of-the-art ensemble performance in all metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">BERT and Flair Improvement Levels</head><p>To investigate which languages benefit most from BERT embeddings, <ref type="figure">Figure 2</ref> presents relative error reductions in UPOS tagging, lemmatization, and unlabeled and labeled dependency parsing, as a function of logarithmic size of the respective Wikipedia (which corresponds to the size of BERT Multilingual model training data). The results indicate that consistently with intuition, larger amount of data used to pretrain the BERT model leads to higher performance.</p><p>To compare BERT and Flair embeddings, <ref type="figure">Figure 3</ref> displays relative error improvements of Flair+WE+CLE, BERT+WE+CLE and BERT+Flair+WE+CLE models compared to WE+CLE, this time as a function of logarithmic training data size. Generally the relative error reduction decrease with the increasing amount of training data. Furthermore, the difference between Flair and BERT is clearly visible, with BERT excelling in dependency parsing and Flair in lemmatization. <ref type="table">Table 6</ref> shows a detailed evaluation of all 89 freely available UD 2.3 treebanks with a train set, comparing the WE+CLE baseline to the best performing WE+CLE+BERT+Flair (where Flair available) model. The evaluation includes also 13 treebanks whose languages are not part of BERT Multilingual model. For these treebanks, the effect of using BERT embeddings is mixed, as can be observed in the <ref type="table">Table 6</ref> indicating which UD languages were not part of BERT training. UPOS tagging, unlabeled and labeled dependency parsing profits from BERT embedding utilization, with averaged relative error reduction of 3.8%, 2%, and 0.8%, respectively. On the other hand, lemmatization performance deteriorates, with −2.2% averaged relative error reduction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">UD 2.3 Detailed Performance</head><p>Averaged across all treebanks, relative error improvement of BERT+Flair embeddings inclusion is 15% for UPOS tagging, 2.4% for lemmatization and 11.5% for labeled dependency parsing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>We presented a thorough evaluation of the BERT, Flair, and ELMo contextualized embeddings in 89 languages of the UD in POS tagging, lemmatization, and dependency parsing. We conclude that addition of any of the contextualized embeddings as additional inputs to a neural network results in substantial performance increase. Our findings show that the BERT embeddings yield the greatest improvements, reaching state-of-the-art results in CoNLL 2018 Shared Task and contain most complementary information as compared to word-and character-level word embeddings, while Flair embeddings encompass the morphological and orthographical information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The work described herein has been supported by OP VVV VI LINDAT/CLARIN project of the Ministry of Education, Youth and Sports of the Czech Republic (project CZ.02.1.01/0.0/0.0/16 013/0001781) and it has been supported and has been using language resources developed by the LINDAT/CLARIN project of the the Ministry of Education, Youth and Sports of the Czech Republic (project LM2015071).    <ref type="table">Table 6</ref>: Results on all UD 2.3 treebanks with a train set, comparing inclusion of BERT and possibly Flair embeddings to WE+CLE baseline. Gold tokenization and segmentation is used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>Relative error improvements on UD 2.3 treebanks which have a training set and their language is included in BERT model. The baseline model uses WE and CLE, and the improved model also uses BERT Multilingual contextualized embeddings. The value on the x-axis is the logarithmic size of the corresponding Wikipedia, which corresponds to training data size of the BERT Multilingual model. Relative error improvements of the baseline with WE+CLE and a model additionally including Flair and/or BERT Multilingual contextual embeddings. The value on the x-axis is the logarithmic UD train data size.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>88.51 86.50 88.64 79.43 73.55 56.52 60.84 WE 94.91 93.51 91.89 92.10 85.98 81.73 68.47 70.64 CLE 95.75 94.69 93.43 96.24 86.99 82.96 71.06 75.78 WE CLE 96.39 95.53 94.28 96.51 87.79 84.09 73.30 77.36 Base 96.35 95.08 93.56 93.29 89.31 85.69 74.11 75.45</figDesc><table><row><cell cols="3">WE CLE Bert UPOS XPOS UFeats Lemma UAS LAS MLAS BLEX</cell></row><row><cell cols="3">90.14 WE Base 96.62 95.54 94.08 93.77 89.49 85.96 74.94 76.27</cell></row><row><cell cols="3">CLE Base 96.86 95.96 94.85 96.64 89.76 86.29 76.20 79.87</cell></row><row><cell cols="3">WE CLE Base 97.00 96.17 94.97 96.66 89.81 86.42 76.54 80.04</cell></row><row><cell cols="3">Table 1: BERT Base compared to word embeddings (WE) and character-level word embeddings (CLE). Results</cell></row><row><cell cols="3">for 72 UD 2.3 treebanks with train and development sets and non-empty Wikipedia.</cell></row><row><cell cols="2">Language Bert</cell><cell>UPOS XPOS UFeats Lemma UAS LAS MLAS BLEX</cell></row><row><cell>English</cell><cell>Base</cell><cell>97.38 96.97 97.22 97.71 91.09 88.22 80.48 82.38</cell></row><row><cell>English</cell><cell cols="2">Multi 97.36 96.97 97.29 97.63 90.94 88.12 80.43 82.22</cell></row><row><cell>Chinese</cell><cell>Base</cell><cell>97.07 96.89 99.58 99.98 90.13 86.74 79.67 83.85</cell></row><row><cell>Chinese</cell><cell cols="2">Multi 96.27 96.25 99.37 99.99 87.58 83.96 76.26 81.04</cell></row><row><cell>Japanese</cell><cell>Base</cell><cell>98.24 97.89 99.98 99.53 95.55 94.27 87.64 89.24</cell></row><row><cell>Japanese</cell><cell cols="2">Multi 98.17 97.71 99.99 99.51 95.30 93.99 87.17 88.77</cell></row><row><cell></cell><cell></cell><cell>BERT (Devlin et al., 2018): We employ</cell></row><row><cell></cell><cell></cell><cell>three pretrained models of dimension 768: 3</cell></row><row><cell></cell><cell></cell><cell>an English one for the English treebanks</cell></row><row><cell></cell><cell></cell><cell>(Base Uncased), a Chinese one for Chi-</cell></row><row><cell></cell><cell></cell><cell>nese and Japanese treebanks (Base Chinese)</cell></row><row><cell></cell><cell></cell><cell>and a multilingual one (Base Multilingual</cell></row><row><cell></cell><cell></cell><cell>Uncased) for all other languages. We pro-</cell></row><row><cell></cell><cell></cell><cell>duce embedding of a UD word as an average</cell></row><row><cell></cell><cell></cell><cell>of BERT subword embeddings this UD word</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>: Comparison of multilingual and language-specific BERT models on 4 English treebanks (each experiment</cell></row><row><cell>repeated 3 times), and on Chinese-GSD and Japanese-GSD treebanks.</cell></row><row><cell>was decomposed into, and we average the last</cell></row><row><cell>four layers of the BERT model.</cell></row><row><cell>• Flair (Akbik et al., 2018): Pretrained contex-</cell></row><row><cell>tual word embeddings of dimension 4096 for</cell></row><row><cell>available languages. 4</cell></row><row><cell>• ELMo (Peters et al., 2018): Pretrained con-</cell></row><row><cell>textual word embeddings of dimension 512,</cell></row><row><cell>available only for English.</cell></row><row><cell>We evaluate the metrics defined in Zeman et al.</cell></row><row><cell>(2018) using the official evaluation script. 5 When</cell></row><row><cell>reporting results for multiple treebanks, we com-</cell></row><row><cell>pute macro-average of their scores (following the</cell></row><row><cell>CoNLL 2018 Shared Task).</cell></row><row><cell>4 Results</cell></row><row><cell>Table 1 displays results for 72 UD 2.3 treebanks</cell></row><row><cell>with train and development sets and non-empty</cell></row><row><cell>Wikipedia (raw corpus for the WE), considering</cell></row><row><cell>WE, CLE and Base BERT embeddings. Both</cell></row><row><cell>WE and CLE bring substantial performance boost,</cell></row><row><cell>with CLE providing larger improvements, espe-</cell></row><row><cell>cially for lemmatization and morphological fea-</cell></row><row><cell>4 Models available in Jan 2018, for languages bg, cs, de,</cell></row><row><cell>en, fr, nl, pl, pt, sl, sv.</cell></row><row><cell>5 http://universaldependencies.org/conll18/</cell></row><row><cell>conll18_ud_eval.py</cell></row></table><note>tures. Combining WE and CLE shows that the improvements are complementary and using both embeddings yields further increase.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>WE CLE Bert Flair UPOS XPOS UFeats Lemmas UAS LAS MLAS BLEX 92.77 89.59 88.88 91.52 82.59 77.89 61.52 65.89 WE 96.63 94.48 94.01 94.82 88.55 85.25 73.38 75.74 CLE 96.80 95.11 94.64 97.31 88.88 85.51 74.37 78.87 WE CLE 97.32 95.88 95.44 97.62 89.55 86.46 76.42 80.36 Base 97.49 95.68 95.17 95.45 91.48 88.69 78.61 80.14</figDesc><table><row><cell>WE</cell><cell>Base</cell><cell>97.65 96.11</cell><cell>95.58</cell><cell>95.86 91.59 88.84 79.30 80.79</cell></row><row><cell cols="2">CLE Base</cell><cell>97.79 96.45</cell><cell>95.94</cell><cell>97.75 91.74 88.98 79.97 83.43</cell></row><row><cell cols="2">WE CLE Base</cell><cell>97.89 96.58</cell><cell>96.09</cell><cell>97.78 91.80 89.09 80.30 83.59</cell></row><row><cell></cell><cell></cell><cell>Flair 97.69 96.22</cell><cell>95.69</cell><cell>96.49 90.43 87.57 77.91 80.06</cell></row><row><cell>WE</cell><cell></cell><cell>Flair 97.77 96.37</cell><cell>95.87</cell><cell>96.62 90.53 87.69 78.37 80.37</cell></row><row><cell>CLE</cell><cell></cell><cell>Flair 97.72 96.40</cell><cell>95.94</cell><cell>97.77 90.58 87.74 78.47 81.94</cell></row><row><cell>WE CLE</cell><cell></cell><cell>Flair 97.76 96.50</cell><cell>96.06</cell><cell>97.85 90.66 87.83 78.73 82.16</cell></row><row><cell cols="3">WE CLE Base Flair 98.00 96.80</cell><cell>96.30</cell><cell>97.87 91.92 89.32 80.78 83.96</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table /><note>Flair compared to word embeddings (WE), character-level word embeddings (CLE) and BERT Base.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>WE CLE Bert Flair Elmo UPOS XPOS UFeats Lemmas UAS LAS MLAS BLEX 92.31 91.18 92.11 93.67 82.16 77.27 63.00 66.20 WE 95.69 95.30 96.15 96.27 86.98 83.59 73.29 75.40 CLE 95.50 95.04 95.65 97.06 86.86 83.10 72.60 75.53 WE CLE 96.33 95.86 96.44 97.32 87.83 84.52 75.08 77.65 Base 96.88 96.46 96.94 96.18 90.98 87.98 79.66 79.94</figDesc><table><row><cell>WE</cell><cell>Base</cell><cell>97.04 96.66 97.07</cell><cell>96.38 91.19 88.20 80.08 80.41</cell></row><row><cell cols="2">CLE Base</cell><cell>97.21 96.82 97.08</cell><cell>97.61 91.23 88.32 80.42 82.38</cell></row><row><cell cols="2">WE CLE Base</cell><cell>97.38 96.97 97.22</cell><cell>97.70 91.09 88.22 80.48 82.38</cell></row><row><cell></cell><cell>Flair</cell><cell>96.88 96.45 96.99</cell><cell>97.01 89.50 86.42 78.03 79.36</cell></row><row><cell>WE</cell><cell>Flair</cell><cell>97.06 96.56 97.03</cell><cell>97.12 89.68 86.67 78.55 79.85</cell></row><row><cell>CLE</cell><cell>Flair</cell><cell>97.00 96.52 97.04</cell><cell>97.57 89.75 86.72 78.56 80.56</cell></row><row><cell>WE CLE</cell><cell>Flair</cell><cell>97.02 96.55 97.12</cell><cell>97.63 89.67 86.64 78.41 80.48</cell></row><row><cell></cell><cell></cell><cell>Elmo 97.23 96.83 97.25</cell><cell>97.13 90.15 87.26 79.47 80.49</cell></row><row><cell>WE</cell><cell></cell><cell>Elmo 97.24 96.84 97.28</cell><cell>97.12 90.25 87.34 79.49 80.57</cell></row><row><cell>CLE</cell><cell></cell><cell>Elmo 97.21 96.81 97.23</cell><cell>97.62 90.22 87.30 79.51 81.32</cell></row><row><cell>WE CLE</cell><cell></cell><cell>Elmo 97.21 96.82 97.27</cell><cell>97.63 90.33 87.42 79.66 81.50</cell></row><row><cell cols="2">WE CLE Base Flair</cell><cell>97.45 97.08 97.36</cell><cell>97.76 91.25 88.45 80.94 82.79</cell></row><row><cell cols="2">WE CLE Base</cell><cell>Elmo 97.42 97.05 97.41</cell><cell>97.68 91.09 88.26 80.81 82.48</cell></row><row><cell cols="3">WE CLE Base Flair Elmo 97.44 97.08 97.43</cell><cell>97.67 91.08 88.28 80.76 82.47</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table><row><cell>System</cell><cell cols="2">UPOS XPOS UFeats Lemmas UAS LAS MLAS BLEX</cell></row><row><cell>UDPipe 2.0 WE+CLE</cell><cell>95.84 94.96 94.24</cell><cell>95.89 85.53 82.11 72.12 75.74</cell></row><row><cell>UDPipe 2.0 WE+CLE+BERT</cell><cell>96.23 95.43 94.74</cell><cell>96.03 87.33 84.20 75.15 78.30</cell></row><row><cell>UDPipe 2.0 WE+CLE+BERT 3-model ensemble</cell><cell>96.32 95.55 94.90</cell><cell>96.16 87.64 84.60 75.76 78.88</cell></row><row><cell>Original UDPipe 2.0 ST entry</cell><cell></cell><cell></cell></row></table><note>ELMo, Flair and BERT contextualized word embeddings for four macro-averaged English UD 2.3 tree- banks. All experiments were performed three times and averaged.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>CoNLL 2018 UD Shared Task results on treebanks with development sets (so called big treebanks in the shared task). The relative error reduction compared to WE+CLE range from 30.5% for UPOS tagging, 26% for morphological features, 16.5% for lemmatization and 25.4% for labeled dependency parsing.</figDesc><table><row><cell>Furthermore, morphological feature gener-</cell></row><row><cell>ation performance of ELMo is better than</cell></row><row><cell>BERT+WE+CLE. These results indicate that</cell></row><row><cell>ELMo capture a lot of information present in</cell></row><row><cell>WE+CLE, which is further promoted by the</cell></row><row><cell>fact that ELMo+WE+CLE shows very little</cell></row><row><cell>improvements compared to ELMo only (with the</cell></row><row><cell>exception of lemmatization profiting from CLE).</cell></row><row><cell>Overall, the best-performing model on English</cell></row><row><cell>treebanks is BERT+Flair+WE+CLE, with the ex-</cell></row><row><cell>ception of morphological features, where ELMo</cell></row><row><cell>helps marginally.</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://universaldependencies.org/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">We use -minCount 5 -epoch 10 -neg 10 options and keep at most one million most frequent words.3 From https://github.com/google-research/bert.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Deep Biaffine Attention for Neural Dependency Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Dozat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno>abs/1611.01734</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Murhaf</forename><surname>Fares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Oepen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lilja</forename><surname>Øvrelid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jari</forename><surname>Björne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Johansson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
		<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="22" to="33" />
		</imprint>
		<respStmt>
			<orgName>Shared Task on Extrinsic Parser Evaluation: On the Downstream Utility of English Universal Dependency Parsers</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Long Short-Term Memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Turku neural parser pipeline: An end-to-end system for the CoNLL 2018 shared task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenna</forename><surname>Kanerva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Ginter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niko</forename><surname>Miekka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akseli</forename><surname>Leino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tapio</forename><surname>Salakoski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
		<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="133" to="142" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiago</forename><surname>Luís</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luís</forename><surname>Marujo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramón</forename><surname>Fernandez Astudillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Amir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">W</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabel</forename><surname>Trancoso</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Universal Dependencies v1: A multilingual treebank collection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Ginter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hajič</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sampo</forename><surname>Pyysalo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Silveira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reut</forename><surname>Tsarfaty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Zeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Conference on Language Resources and Evaluation (LREC 2016)</title>
		<meeting>the 10th International Conference on Language Resources and Evaluation (LREC 2016)<address><addrLine>Slovenia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1659" to="1666" />
		</imprint>
	</monogr>
	<note>Portorož. European Language Resources Association</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Universal dependencies 2.3. LINDAT/CLARIN digital library at the Institute of Formal and Applied Linguistics (ÚFAL</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Faculty of Mathematics and Physics</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
		<respStmt>
			<orgName>Charles University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep Contextualized Word Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2227" to="2237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Universal dependency parsing from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Dozat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
		<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="160" to="170" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">UDPipe 2.0 Prototype at CoNLL 2018 UD Shared Task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milan</forename><surname>Straka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL 2018: The SIGNLL Conference on Computational Natural Language Learning</title>
		<meeting>CoNLL 2018: The SIGNLL Conference on Computational Natural Language Learning<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="197" to="207" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>and Illia Polosukhin. 2017. Attention is all you need. CoRR, abs/1706.03762</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Zeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Ginter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hajič</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Popel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milan</forename><surname>Straka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies, Brussels, Belgium. Association for Computational Linguistics</title>
		<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies, Brussels, Belgium. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Zeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Popel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milan</forename><surname>Straka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hajič</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Ginter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juhani</forename><surname>Luotolahti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sampo</forename><surname>Pyysalo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Tyers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Badmaeva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Memduh</forename><surname>Gökırmak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Nedoluzhko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvie</forename><surname>Cinková</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Hajič Jr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaroslava</forename><surname>Hlaváčová</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Václava</forename><surname>Kettnerová</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zdeňka</forename><surname>Urešová</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenna</forename><surname>Kanerva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stina</forename><surname>Ojala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Missilä</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dima</forename><surname>Taji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nizar</forename><surname>Habash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herman</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuela</forename><surname>Sanguinetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Simi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroshi</forename><surname>Kanayama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valeria</forename><surname>De Paiva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kira</forename><surname>Droganova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
		<editor>Héctor Martínez Alonso, Ç agrı Çöltekin, Umut Sulubacak, Hans Uszkoreit, Vivien Macketanz, Aljoscha Burchardt, Kim Harris, Katrin Marheinecke, Georg Rehm, Tolga Kayadelen, Mohammed Attia, Ali Elkahky, Zhuoran Yu, Emily Pitler, Saran Lertpradit, Michael Mandl, Jesse Kirchner, Hector Fernandez Alcalde, Jana Strnadova, Esha Banerjee, Ruli Manurung, Antonio Stella, Atsuko Shimada, Sookyoung Kwak, Gustavo Mendonça, Tatiana Lando, Rattima Nitisaroj, and Josie Li</editor>
		<meeting>the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
