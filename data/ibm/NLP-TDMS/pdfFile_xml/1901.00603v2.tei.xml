<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">COARSE-GRAIN FINE-GRAIN COATTENTION NET- WORK FOR MULTI-EVIDENCE QUESTION ANSWERING</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
							<email>vzhong@cs.washington.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Paul G. Allen School of Computer Science &amp; Engineering</orgName>
								<orgName type="institution">University of Washington</orgName>
								<address>
									<settlement>Seattle</settlement>
									<region>WA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
							<email>cxiong@salesforce.com</email>
							<affiliation key="aff1">
								<orgName type="department">Salesforce Research</orgName>
								<address>
									<settlement>Palo Alto</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Shirish Keskar</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Salesforce Research</orgName>
								<address>
									<settlement>Palo Alto</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
							<email>rsocher@salesforce.com</email>
							<affiliation key="aff1">
								<orgName type="department">Salesforce Research</orgName>
								<address>
									<settlement>Palo Alto</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">COARSE-GRAIN FINE-GRAIN COATTENTION NET- WORK FOR MULTI-EVIDENCE QUESTION ANSWERING</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Published as a conference paper at ICLR 2019</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T08:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>End-to-end neural models have made significant progress in question answering, however recent studies show that these models implicitly assume that the answer and evidence appear close together in a single document. In this work, we propose the Coarse-grain Fine-grain Coattention Network (CFC), a new question answering model that combines information from evidence across multiple documents. The CFC consists of a coarse-grain module that interprets documents with respect to the query then finds a relevant answer, and a fine-grain module which scores each candidate answer by comparing its occurrences across all of the documents with the query. We design these modules using hierarchies of coattention and selfattention, which learn to emphasize different parts of the input. On the Qangaroo WikiHop multi-evidence question answering task, the CFC obtains a new stateof-the-art result of 70.6% on the blind test set, outperforming the previous best by 3% accuracy despite not using pretrained contextual encoders.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>A requirement of scalable and practical question answering (QA) systems is the ability to reason over multiple documents and combine their information to answer questions. Although existing datasets enabled the development of effective end-to-end neural question answering systems, they tend to focus on reasoning over localized sections of a single document <ref type="bibr" target="#b12">(Hermann et al., 2015;</ref><ref type="bibr" target="#b31">Rajpurkar et al., 2016;</ref><ref type="bibr" target="#b41">Trischler et al., 2017)</ref>. For example, <ref type="bibr" target="#b27">Min et al. (2018)</ref> find that 90% of the questions in the Stanford Question Answering Dataset are answerable given 1 sentence in a document. In this work, we instead focus on multi-evidence QA, in which answering the question requires aggregating evidence from multiple documents <ref type="bibr" target="#b45">(Welbl et al., 2018;</ref><ref type="bibr" target="#b17">Joshi et al., 2017)</ref>.</p><p>Our multi-evidence QA model, the Coarse-grain Fine-grain Coattention Network (CFC), selects among a set of candidate answers given a set of support documents and a query. The CFC is inspired by coarse-grain reasoning and fine-grain reasoning. In coarse-grain reasoning, the model builds a coarse summary of support documents conditioned on the query without knowing what candidates are available, then scores each candidate. In fine-grain reasoning, the model matches specific finegrain contexts in which the candidate is mentioned with the query in order to gauge the relevance of the candidate. These two strategies of reasoning are respectively modeled by the coarse-grain and fine-grain modules of the CFC. Each module employs a novel hierarchical attention -a hierarchy of coattention and self-attention -to combine information from the support documents conditioned on the query and candidates. <ref type="figure" target="#fig_0">Figure 1</ref> illustrates the architecture of the CFC.</p><p>The CFC achieves a new state-of-the-art result on the blind Qangaroo WikiHop test set of 70.6% accuracy, beating previous best by 3% accuracy despite not using pretrained contextual encoders. In addition, on the TriviaQA multi-paragraph question answering task <ref type="bibr" target="#b17">(Joshi et al., 2017)</ref>, reranking Most of this work was done while Victor Zhong was at Salesforce Research. outputs from a traditional span extraction model  using the CFC improves exact match accuracy by 3.1% and F1 by 3.0%.</p><p>Our analysis shows that components in the attention hierarchies of the coarse and fine-grain modules learn to focus on distinct parts of the input. This enables the CFC to more effectively represent a large collection of long documents. Finally, we outline common types of errors produced by CFC, caused by difficulty in aggregating large quantity of references, noise in distant supervision, and difficult relation types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">COARSE-GRAIN FINE-GRAIN COATTENTION NETWORK</head><p>The coarse-grain module and fine-grain module of the CFC correspond to coarse-grain reasoning and fine-grain reasoning strategies. The coarse-grain module summarizes support documents without knowing the candidates: it builds codependent representations of support documents and the query using coattention, then produces a coarse-grain summary using self-attention. In contrast, the fine-grain module retrieves specific contexts in which each candidate occurs: it identifies coreferent mentions of the candidate, then uses coattention to build codependent representations between these mentions and the query. While low-level encodings of the inputs are shared between modules, we show that this division of labour allows the attention hierarchies in each module to focus on different parts of the input. This enables the model to more effectively represent a large number of potentially long support documents.</p><p>Suppose we are given a query, a set of N s support documents, and a set of N c candidates. Without loss of generality, let us consider the ith document and the jth candidate. Let L q ∈ R Tq×d emb , L s ∈ R Ts×d emb , and L c ∈ R Tc×d emb respectively denote the word embeddings of the query, the ith support document, and the jth candidate answer. Here, T q , T s , and T c are the number of words in the corresponding sequence. d emb is the size of the word embedding. We begin by encoding each sequence using a bidirectional Gated Recurrent Units (GRUs) <ref type="bibr" target="#b3">(Cho et al., 2014)</ref>. </p><formula xml:id="formula_0">E q = BiGRU (tanh(W q L q + b q )) ∈ R Tq×d hid (1) E s = BiGRU (L s ) ∈ R Ts×d hid (2) E c = BiGRU (L c ) ∈ R Tc×d hid<label>(3)</label></formula><p>Here, E q , E s , and E c are the encodings of the query, support, and candidate. W q and b q are parameters of a query projection layer. d hid is the size of the bidirectional GRU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">COARSE-GRAIN MODULE</head><p>The coarse-grain module of the CFC, shown in <ref type="figure" target="#fig_1">Figure 2</ref>, builds codependent representations of support documents E s and the query E q using coattention, and then summarizes the coattention context using self-attention to compare it to the candidate E c . Coattention and similar techniques are crucial to single-document question answering models <ref type="bibr" target="#b43">Wang &amp; Jiang, 2017;</ref><ref type="bibr" target="#b35">Seo et al., 2017)</ref>. We start by computing the affinity matrix between the document and the query as</p><formula xml:id="formula_1">A = E s (E q ) ∈ R Ts×Tq<label>(4)</label></formula><p>The support summary vectors and query summary vectors are defined as</p><formula xml:id="formula_2">S s = softmax (A) E q ∈ R Ts×d hid (5) S q = softmax (A ) E s ∈ R Tq×d hid<label>(6)</label></formula><p>where softmax(X) normalizes X column-wise. We obtain the document context as</p><formula xml:id="formula_3">C s = BiGRU (S q softmax (A)) ∈ R Ts×d hid<label>(7)</label></formula><p>The coattention context is then the feature-wise concatenation of the document context C s and the document summary vector S s .</p><formula xml:id="formula_4">U s = [C s ; S s ] ∈ R Ts×2d hid<label>(8)</label></formula><p>For ease of exposition, we abbreviate coattention, which takes as input a document encoding E s and a query encoding E q and produces the coattention context U s , as</p><formula xml:id="formula_5">Coattn (E s , E q ) → U s<label>(9)</label></formula><p>Next, we summarize the coattention context -a codependent encoding of the supporting document and the query -using hierarchical self-attention. First, we use self-attention to create a fixedlength summary vector of the coattention context. We compute a score for each position of the  coattention context using a two-layer multi-layer perceptron (MLP). This score is normalized and used to compute a weighted sum over the coattention context.</p><formula xml:id="formula_6">a si = tanh (W 2 tanh (W 1 U si + b 1 ) + b 2 ) ∈ R (10) a s = softmax(a s )<label>(11)</label></formula><formula xml:id="formula_7">G s = Ts iâ si U si ∈ R 2d hid<label>(12)</label></formula><p>Here, a si andâ si are respectively the unnormalized and normalized score for the ith position of the coattention context. W 2 , b 2 , W 1 , and b 1 are parameters for the MLP scorer. U si is the ith position of the coattention context. We abbreviate self-attention, which takes as input a sequence U s and produces the summary conditioned on the query G s , as</p><formula xml:id="formula_8">Selfattn (U s ) → G s<label>(13)</label></formula><p>Recall that G s provides the summary of the ith of N s support documents. We apply another selfattention layer to compute a fixed-length summary vector of all support documents. This summary is then multiplied with the summary of the candidate answer to produce the coarse-grain score. Let G ∈ R Ns×2d hid represent the sequence of summaries for all support documents. We have</p><formula xml:id="formula_9">G c = Selfattn (E c ) ∈ R d hid (14) G = Selfattn (G) ∈ R 2d hid (15) y coarse = tanh (W coarse G + b coarse ) G c ∈ R<label>(16)</label></formula><p>where E c and G c are respectively the encoding and the self-attention summary of the candidate. G is the fixed-length summary vector of all support documents. W coarse and b coarse are parameters of a projection layer that reduces the support documents summary from R 2d hid to R d hid .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">CANDIDATE-DEPENDENT FINE-GRAIN MODULE</head><p>In contrast to the coarse-grain module, the fine-grain module, shown in <ref type="figure" target="#fig_2">Figure 3</ref>, finds the specific context in which the candidate occurs in the supporting documents using coreference resolution 1 . Each mention is then summarized using a self-attention layer to form a mention representation. We then compute the coattention between the mention representations and the query. This coattention context, which is a codependent encoding of the mentions and the query, is again summarized via self-attention to produce a fine-grain summary to score the candidate.</p><p>Let us assume that there are m mentions of the candidate in the ith support document. Let the kth mention corresponds to the i start to i end tokens in the support document. We represent this mention using self-attention over the span of the support document encoding that corresponds to the mention.  <ref type="figure">Figure 4</ref>: An example from the Qangaroo WikiHop QA task. The relevant multiple pieces of evidence required to answer the question is shown in red. The correct answer is shown in blue.</p><formula xml:id="formula_10">M k = Selfattn (E s [i start : i end ]) ∈ R d hid<label>(17)</label></formula><p>Suppose that there are N m mentions of the candidate in total. We extract each mention representation using self-attention to produce a sequence of mention representations M ∈ R Nm×d hid . The coattention context and summary of these mentions M with respect to the query E q are</p><formula xml:id="formula_11">U m = Coattn (M, E q ) ∈ R Nm×2d hid (18) G m = Selfattn (U m ) ∈ R 2d hid<label>(19)</label></formula><p>We use a linear layer to determine the fine-grain score of the candidate</p><formula xml:id="formula_12">y fine = W fine G m + b fine ∈ R<label>(20)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">SCORE AGGREGATION</head><p>We take the sum of the coarse-grain score and the fine-grain score, y = y coarse + y fine , as the score for the candidate. Recall that our earlier presentation is with respect to the jth out of N c candidates. We combine each candidate score to form the final score vector Y ∈ R Nc . The model is trained using cross-entropy loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EXPERIMENTS</head><p>We evaluate the CFC on two tasks to evaluate its effectiveness. The first task is multi-evidence question answering on the unmasked and masked version of the WikiHop dataset <ref type="bibr" target="#b45">(Welbl et al., 2018)</ref>. The second task is the multi-paragraph extractive question answering task TriviaQA, which we frame as a span reranking task <ref type="bibr" target="#b17">(Joshi et al., 2017)</ref>. On the former, the CFC achieves a new stateof-the-art result. On the latter, reranking the outputs of a span-extraction model  using the CFC results in significant performance improvement. <ref type="bibr" target="#b45">Welbl et al. (2018)</ref> proposed the Qangaroo WikiHop task to facilitate the study of multi-evidence question answering. This dataset is constructed by linking entities in a document corpus (Wikipedia) with a knowledge base (Wikidata). This produces a bipartite graph of documents and entities, an edge in which marks the occurrence of an entity in a document. A knowledge base fact triplet consequently corresponds to a path from the subject to the object in the resulting graph. The documents along this path compose the support documents for the fact triplet. The Qangaroo WikiHop task, shown in <ref type="figure">Figure 4</ref>, is as follows: given a query, that is, the subject and relation of a fact triplet, a set  <ref type="bibr" target="#b37">(Song et al., 2018)</ref> 62.8% 65.4% Jenga <ref type="bibr">(Facebook AI Research*, 2018)</ref> 65.3% Vanilla Coattention Model <ref type="bibr">(NTU*, 2018)</ref> 59.9% Coref GRU <ref type="bibr" target="#b8">(Dhingra et al., 2018)</ref> 56.0% 59.3% BiDAF Baseline <ref type="bibr" target="#b45">(Welbl et al., 2018)</ref> 54.5% 42.9%   of plausible candidate objects, and the corresponding support documents for the candidates, select the correct candidate as the answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">MULTI-EVIDENCE QUESTION ANSWERING ON WIKIHOP</head><p>The unmasked version of WikiHop represents candidate answers with original text while the masked version replaces them with randomly sampled placeholders in order to remove correlation between frequent answers and support documents. Official blind, held-out test evaluation is performed using the unmasked version. We tokenize the data using Stanford CoreNLP . We use fixed GloVe embeddings <ref type="bibr" target="#b28">(Pennington et al., 2014)</ref> as well as character ngram embeddings <ref type="bibr" target="#b11">(Hashimoto et al., 2017)</ref>. We split symbolic query relations into words. All models are trained using ADAM <ref type="bibr" target="#b18">(Kingma &amp; Ba, 2015)</ref>. We list detailed experiment setup and hyperparemeters of the best-performing model in A.2 of the Appendix.</p><p>We compare the performance of the CFC to other models on the WikiHop leaderboard in <ref type="table" target="#tab_3">Table 1</ref>. The CFC achieves state-of-the-art results on both the masked and unmasked versions of WikiHop. In particular, on the blind, held-out WikiHop test set, the CFC achieves a new best accuracy of 70.6%. The previous state-of-the-art result by <ref type="bibr" target="#b1">Cao et al. (2018)</ref> uses pretrained contextual encoders, which has led to consistent improvements across NLP tasks <ref type="bibr" target="#b29">(Peters et al., 2018)</ref>. We outperform this result by 3% despite not using pretrained contextual encoders 2 . In addition, we show that the division of labour between the coarse-grain module and the fine-grain module allows the attention hierarchies of each module to focus on different parts of the input. This enables the CFC to more effectively model the large collection of potentially long documents found in WikiHop.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">RERANKING EXTRACTIVE QUESTION ANSWERING ON TRIVIAQA</head><p>To further study the effectiveness of our model, we also experiment on TriviaQA <ref type="bibr" target="#b17">(Joshi et al., 2017)</ref>, another large-scale question answering dataset that requires aggregating evidence from multiple sentences. Similar to <ref type="bibr" target="#b15">Hu et al. (2018b)</ref>; , we decompose the original TriviaQA task into two subtasks: proposing plausible candidate answers and reranking candidate answers.   <ref type="table">Table 3</ref>: Ablation study on the WikiHop dev set. The rows respectively correspond to the removal of coarse-grain module, the removal of finegrain module, the replacement of self-attention with average pooling, the replacement of bidir. with unidir. GRUs, and the replacement of encoder GRUs with projection over word embeddings.</p><p>We address the first subtask using BiDAF++, a competitive span extraction question answering model by  and the second subtask using the CFC. To compute the candidate list for reranking, we obtain the top 50 answer candidates from BiDAF++. During training, we use the answer candidate that gives the maximum F1 as the gold label for training the CFC.</p><p>Our experimental results in <ref type="table" target="#tab_5">Table 2</ref> show that reranking using the CFC provides consistent performance gains over only using the span extraction question answering model. In particular, reranking using the CFC improves performance regardless of whether the candidate answer set obtained from the span extraction model contains correct answers. On the whole TriviaQA dev set, reranking using the CFC results in a gain of 3.1% EM and 3.0% F1, which suggests that the CFC can be used to further refine the outputs produced by span extraction question answering models. <ref type="table">Table 3</ref> shows the performance contributions of the coarse-grain module, the fine-grain module, as well as model decisions such as self-attention and bidirectional GRUs. Both the coarse-grain module and the fine-grain module significantly contribute to model performance. Replacing selfattention layers with mean-pooling and the bidirectional GRUs with unidirectional GRUs result in less performance degradation. Replacing the encoder with a projection over word embeddings result in significant performance drop, which suggests that contextual encodings that capture positional information is crucial to this task. <ref type="figure" target="#fig_4">Figure 5</ref> shows the distribution of model prediction errors across various lengths of the dataset for the coarse-grain-only model (-fine) and the fine-grain-only model (-coarse). The fine-grain-only model under-performs the coarse-grain-only model consistently across almost all length measures. This is likely due to the difficulty of coreference resolution of candidates in the support documents -the technique we use of exact lexical matching tends to produce high precision and low recall. However, the fine-grain-only model matches or outperforms the coarse-grain-only model on examples with a large number of support documents or with long support documents. This is likely because the entity-matching coreference resolution we employ captures intra-document and inter-document dependencies more precisely than hierarchical attention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">ABLATION STUDY</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">QUALITATIVE ANALYSIS</head><p>We examine the hierarchical attention maps produced by the CFC on examples from the Wiki-Hop development set. We find that coattention layers consistently focus on phrases that are similar between the document and the query, while lower level self-attention layers capture phrases that characterize the entity described by the document. Because these attention maps are very large, we do not include them in the main text and instead refer readers to A.3 of the Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 7:</head><p>Fine-grain coattention and self-attention scores for for the query located in the administrative territorial entity hampton wick war memorial, for which the answer is "London borough of Richmond Upon Thames". The coattention tends to align the relation part of the query to the context in which the mention occurs in the text. The first, second, and fourth mentions respectively describe Hampton Wicks, Hampton Hills, and Teddington -all of which are located in Richmond upon Thames. The third describes Richmond upon Thames itself.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 6:</head><p>Coarse-grain summary self-attention scores for the query country of origin the troll, for which the answer is "United Kingdom". The summary selfattention tends to focus on documents relevant to the subject in the query. The top three support documents 2, 4, 5 respectively present information about the literary work The Troll, its author Julia Donaldson, and Old Norse.</p><p>Coarse-grain summary self-attention, described in equation 15, tends to focus on support documents that present information relevant to the object in the query. <ref type="figure">Figure 6</ref> illustrates an example of this in which the self-attention focuses on documents relevant to the literary work "The Troll", namely those about The Troll, its author Julia Donaldson, and Old Norse.</p><p>In contrast, fine-grain coattention over mention representations, described in equation 19, tends to focus on the relation part of the query. <ref type="figure">Figure 7</ref> illustrates an example of this in which the coattention focuses on the relationship between the mentions and the phrase "located in the administrative territorial entity". Attention maps of more examples can be found in A.3 of the Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">ERROR ANALYSIS</head><p>We examine 100 errors the CFC produced on the WikiHop development set and categorize them into four types. We list identifiers and examples of these errors in A.4 of the Appendix. The first type (42% of errors) results from the model aggregating the wrong reference. For example, for the query country of citizenship jamie burnett, the model correctly attends to the documents about Jamie Burnett being born in South Larnarkshire and about Lanarkshire being in Scotland. However it wrongly focuses on the word "england" in the latter document instead of the answer "scotland". We hypothesize that ways to reduce this type of error include using more robust pretrained contextual encoders <ref type="bibr" target="#b26">(McCann et al., 2017;</ref><ref type="bibr" target="#b29">Peters et al., 2018)</ref> and coreference resolution. The second type (28% of errors) results from questions that are not answerable. For example, the support documents do not provide the narrative location of the play "The Beloved Vagabond" for the query narrative location the beloved vagabond. The third type (22% of errors) results from queries that yield multiple correct answers. An example is the query instance of qilakitsoq, for which the model predicts "archaeological site", which is more specific than the answer "town". The second and third types of errors underscore the difficulty of using distant supervision to create large-scale datasets such as WikiHop. The fourth type (8% of errors) results from complex relation types such as parent taxon which are difficult to interpret using pretrained word embeddings. One method to alleviate this type of errors is to embed relations using tunable symbolic embeddings as well as fixed word embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RELATED WORK</head><p>Question answering and information aggregation tasks. QA tasks span a variety of sources such as Wikipedia <ref type="bibr" target="#b49">(Yang et al., 2015;</ref><ref type="bibr" target="#b31">Rajpurkar et al., 2016;</ref><ref type="bibr" target="#b13">Hewlett et al., 2016;</ref><ref type="bibr" target="#b17">Joshi et al., 2017;</ref><ref type="bibr" target="#b45">Welbl et al., 2018)</ref>, news articles <ref type="bibr" target="#b12">(Hermann et al., 2015;</ref><ref type="bibr" target="#b41">Trischler et al., 2017)</ref>, books <ref type="bibr" target="#b33">(Richardson et al., 2013)</ref>, and trivia <ref type="bibr" target="#b16">(Iyyer et al., 2014)</ref>. Most QA tasks seldom require reasoning over multiple pieces of evidence. In the event that such reasoning is required, it typically arises in the form of coreference resolution within a single document <ref type="bibr" target="#b27">(Min et al., 2018)</ref>. In contrast, the Qangaroo WikiHop dataset encourages reasoning over multiple pieces of evidence across documents due to its construction. A similar task that also requires aggregating information from multiple documents is query-focused multi-document summarization, in which a model summarizes a collection of documents given an input query <ref type="bibr" target="#b6">(Dang, 2006;</ref><ref type="bibr" target="#b10">Gupta et al., 2007;</ref><ref type="bibr" target="#b24">Lu et al., 2013)</ref>.</p><p>Question answering models. The recent development of large-scale QA datasets has led to a host of end-to-end QA models. These include early document attention models for cloze-form QA <ref type="bibr" target="#b2">(Chen et al., 2015)</ref>, multi-hop memory networks <ref type="bibr" target="#b39">Sukhbaatar et al., 2015;</ref><ref type="bibr" target="#b20">Kumar et al., 2016)</ref>, as well as cross-sequence attention models for span-extraction QA. Variations of crosssequence attention include match-LSTM <ref type="bibr" target="#b43">(Wang &amp; Jiang, 2017)</ref>, coattention , bidirectional attention <ref type="bibr" target="#b35">(Seo et al., 2017)</ref>, and query-context attention . Recent advances include the use of reinforcement learning to encourage the exploration of close answers that may have imprecise span match <ref type="bibr" target="#b14">Hu et al., 2018a)</ref>, the use of convolutions and self-attention to model local and global interactions , as well as the addition of reranking models to refine span-extraction output <ref type="bibr" target="#b15">Hu et al., 2018b)</ref>. Our work builds upon prior work on single-document QA and generalizes to multi-evidence QA across documents.</p><p>Attention as information aggregation. Neural attention has been successfully applied to a variety of tasks to summarize and aggregate information. <ref type="bibr" target="#b0">Bahdanau et al. (2015)</ref> demonstrate the use of attention over the encoder to capture soft alignments for machine translation. Similar types of attention has also been used in relation extraction <ref type="bibr" target="#b51">(Zhang et al., 2017)</ref>, summarization <ref type="bibr" target="#b34">(Rush et al., 2015)</ref>, and semantic parsing <ref type="bibr" target="#b9">(Dong &amp; Lapata, 2018)</ref>. Coattention as a means to encode codependent representations between two inputs has also been successfully applied to visual question answering <ref type="bibr" target="#b23">(Lu et al., 2016)</ref> in addition to textual question answering. Self-attention has similarly been shown to be effective as a means to combine information in textual entailment <ref type="bibr" target="#b36">(Shen et al., 2018;</ref><ref type="bibr" target="#b7">Deunsol Yoon, 2018)</ref>, coreference resolution <ref type="bibr" target="#b21">(Lee et al., 2017)</ref>, dialogue state-tracking , machine translation <ref type="bibr" target="#b42">(Vaswani et al., 2017)</ref>, and semantic parsing <ref type="bibr" target="#b19">(Kitaev &amp; Klein, 2018)</ref>. In the CFC, we present a novel way to combine self-attention and coattention in a hierarchy to build effective conditional and codependent representations of a large number of potentially long documents.</p><p>Coarse-to-fine modeling. Hierarchical coarse-to-fine modeling, which gradually introduces complexity, is an effective technique to model long documents. Petrov (2009) provides a detailed overview of this technique and demonstrates its effectiveness on parsing, speech recognition, and machine translation. Neural coarse-to-fine modeling has also been applied to question answering <ref type="bibr" target="#b27">Min et al., 2018;</ref><ref type="bibr" target="#b40">Swayamdipta et al., 2018)</ref> and semantic parsing <ref type="bibr" target="#b9">(Dong &amp; Lapata, 2018)</ref>. The coarse and fine-grain modules of the CFC similarly focus on extracting coarse and fine representations of the input. Unlike previous work in which a coarse module precedes a fine module, the modules in the CFC are complementary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>We presented CFC, a new state-of-the-art model for multi-evidence question answering inspired by coarse-grain reasoning and fine-grain reasoning. On the WikiHop question answering task, the CFC achieves 70.6% test accuracy, outperforming previous methods by 3% accuracy. We showed in our analysis that the complementary coarse-grain and fine-grain modules of the CFC focus on different aspects of the input, and are an effective means to represent large collections of long documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A APPENDIX A.1 COREFERENCE RESOLUTION</head><p>In this work, we use simple lexical matching instead of using full-scale coreference resolution systems. The integration of the latter remains a direction for future work. To perform simple lexical matching for a given candidate, we first tokenize the document as well as the candidate. Each time the candidate tokens occur consequetively in the document, we extract the corresponding token span as a coreference mention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 EXPERIMENT SETUP</head><p>For the best-performing model, we train the CFC using Adam (Kingma &amp; Ba, 2015) for a maximum of 50 epochs with a batch size of 80 examples. We use an initial learning rate of 10 −3 with (β 1 , β 2 ) = (0.9, 0.999) and employ a cosine learning rate decay <ref type="bibr" target="#b22">Loshchilov &amp; Hutter (2017)</ref> over the maximum budget. We find this approach to outperform a development set-based annealing heuristic as well as those based on piecewise-constant approximations. We evaluate the accuracy of the model on the development set every epoch, and evaluate the model that obtained the best accuracy on the development set on the held-out test set. We present the convergence plot in <ref type="figure" target="#fig_6">Figure 8</ref>.  We use a embedding size of d emb = 400, 300 of which are from GloVe vectors <ref type="bibr" target="#b28">(Pennington et al., 2014)</ref> and 100 of which are from character ngram vectors <ref type="bibr" target="#b11">(Hashimoto et al., 2017)</ref>. The embeddings are fixed and not tuned during training. All GRUs have a hidden size of d hid = 100. We regularize the model using dropout <ref type="bibr" target="#b38">(Srivastava et al., 2014)</ref> at several locations in the model: after the embedding layer with a rate of 0.3, encoders with a rate of 0.3, coattention layers with a rate of 0.2, and self-attention layers with a rate of 0.2. We also apply word dropout with a rate of 0.25 <ref type="bibr" target="#b51">(Zhang et al., 2017;</ref>. The values for the dropout rates are coarsely tuned and we find that performance is more sensitive to word dropout than other dropout.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 ATTENTION MAPS</head><p>This section includes attention maps produced by the CFC on the development split of WikiHop. We include the fine-grain mention self-attention and coattention, the coarse-grain summary selfattention, and the document self-attention and coattention for the top scoring supporing documents, ranked by the summary self-attention score. The query can be found in the coattention maps.</p><p>We use the answer as the title of the subsection.</p><p>A.3.1 HOUSE OF VALOIS (a) Fine-grain mentions.</p><p>(b) Coarse-grain summary.</p><p>(a) Support 0.     (a) Support 0.   The River Clyde is a river, that flows into the Firth of Clyde in Scotland. It is the eighth-longest river in the United Kingdom, and the second-longest in Scotland. Flowing through the major city of Glasgow, it was an important river for shipbuilding and trade in the British Empire. In the early medieval Cumbric language it was known as "Clud" or "Clut", and was central to the Kingdom of Strathclyde ("Teyrnas Ystrad Clut").</p><p>Scotland (Scots: ) is a country that is part of the United Kingdom and covers the northern third of the island of Great Britain. It shares a border with England to the south, and is otherwise surrounded by the Atlantic Ocean, with the North Sea to the east and the North Channel and Irish Sea to the south-west. In addition to the mainland, the country is made up of more than 790 islands, including the Northern Isles and the Hebrides.</p><p>Avon Water, also known locally as the River Avon, is a river in Scotland, and a tributary of the River Clyde.</p><p>Lanarkshire, also called the County of Lanark is a historic county in the central Lowlands of Scotland.</p><p>A.4.2 TYPE 2 ERROR: UNANSWERABLE Ealing is a major suburban district of west London, England and the administrative centre of the London Borough of Ealing. It is one of the major metropolitan centres identified in the London Plan. It was historically a rural village in the county of Middlesex and formed an ancient parish. Improvement in communications with London, culminating with the opening of the railway station in 1838, shifted the local economy to market garden supply and eventually to suburban development.</p><p>Paris (French: ) is the capital and most populous city of France. It has an area of and a population in 2013 of 2,229,621 within its administrative limits. The city is both a commune and department, and forms the centre and headquarters of the le-de-France, or Paris Region, which has an area of and a population in 2014 of 12,005,077, comprising 18.2 percent of the population of France.</p><p>Bordeaux (Gascon Occitan: "") is a port city on the Garonne River in the Gironde department in southwestern France. The Mediterranean Sea (pronounced ) is a sea connected to the Atlantic Ocean, surrounded by the Mediterranean Basin and almost completely enclosed by land: on the north by Southern Europe and Anatolia, on the south by North Africa, and on the east by the Levant. The sea is sometimes considered a part of the Atlantic Ocean, although it is usually identified as a separate body of water.</p><p>Maurice Auguste Chevalier (September 12, 1888 January 1, 1972) was a French actor, cabaret singer and entertainer. He is perhaps best known for his signature songs, including "Louise", "Mimi", "Valentine", and "Thank Heaven for Little Girls" and for his films, including "The Love Parade" and "The Big Pond". His trademark attire was a boater hat, which he always wore on stage with a tuxedo.</p><p>Nice (; Niard , classical norm, or "", nonstandard, ) is the fifth most populous city in France and the capital of the Alpes-Maritimes "dpartement". The urban area of Nice extends beyond the administrative city limits, with a population of about 1 million on an area of . Located in the French Riviera, on the south east coast of France on the Mediterranean Sea, at the foot of the Alps, Nice is the second-largest French city on the Mediterranean coast and the second-largest city in the Provence-Alpes-Cte dAzur region after Marseille. Nice is about 13 kilometres (8 miles) from the principality of Monaco, and its airport is a gateway to the principality as well.</p><p>Ealing Studios is a television and film production company and facilities provider at Ealing Green in west London. Will Barker bought the White Lodge on Ealing Green in 1902 as a base for film making, and films have been made on the site ever since. It is the oldest continuously working studio facility for film production in the world, and the current stages were opened for the use of sound in 1931. It is best known for a series of classic films produced in the post-WWII years, including "Kind The title refers to a line in Tennysons poem "Lady Clara Vere de Vere": "Kind hearts are more than coronets, and simple faith than Norman blood."</p><p>Europe is a continent that comprises the westernmost part of Eurasia. Europe is bordered by the Arctic Ocean to the north, the Atlantic Ocean to the west, and the Mediterranean Sea to the south.</p><p>To the east and southeast, Europe is generally considered as separated from Asia by the watershed divides of the Ural and Caucasus Mountains, the Ural River, the Caspian and Black Seas, and the waterways of the Turkish Straits. Yet the non-oceanic borders of Europea concept dating back to classical antiquityare arbitrary. The primarily physiographic term "continent" as applied to Europe also incorporates cultural and political elements whose discontinuities are not always reflected by the continents current overland boundaries.</p><p>France, officially the French Republic, is a country with territory in western Europe and several overseas regions and territories. The European, or metropolitan, area of France extends from the Mediterranean Sea to the English Channel and the North Sea, and from the Rhine to the Atlantic Ocean. Overseas France include French Guiana on the South American continent and several island territories in the Atlantic, Pacific and Indian oceans. France spans and had a total population of almost 67 million people as of January 2017. It is a unitary semi-presidential republic with the capital in Paris, the countrys largest city and main cultural and commercial centre. Other major urban centres include Marseille, Lyon, Lille, Nice, Toulouse and Bordeaux.</p><p>The British Broadcasting Corporation (BBC) is a British public service broadcaster. It is headquartered at Broadcasting House in London, is the worlds oldest national broadcasting organisation, and is the largest broadcaster in the world by number of employees, with over 20,950 staff in total, of whom 16,672 are in public sector broadcasting; including part-time, flexible as well as fixed contract staff, the total number is 35,402.</p><p>The Rhine (, , ) is a European river that begins in the Swiss canton of Graubnden in the southeastern Swiss Alps, forms part of the Swiss-Austrian, Swiss-Liechtenstein, Swiss-German and then the Franco-German border, then flows through the Rhineland and eventually empties into the North Sea in the Netherlands. The largest city on the river Rhine is Cologne, Germany, with a population of more than 1,050,000 people. It is the second-longest river in Central and Western Europe (after the Danube), at about , with an average discharge of about .</p><p>The Beloved Vagabond is a 1936 British musical drama film directed by Curtis Bernhardt and starring Maurice Chevalier , Betty Stockfeld , Margaret Lockwood and Austin Trevor . In nineteenth century France an architect posing as a tramp falls in love with a woman . The film was made at Ealing Studios by the independent producer Ludovico Toeplitz .</p><p>The Atlantic Ocean is the second largest of the worlds oceans with a total area of about . It covers approximately 20 percent of the Earths surface and about 29 percent of its water surface area. It separates the "Old World" from the "New World".</p><p>Claude Austin Trevor (7 October 1897 22 January 1978) was a Northern Irish actor who had a long career in film and television.</p><p>The English Channel ("the Sleeve" [hence ] "Sea of Brittany" "British Sea"), also called simply the Channel, is the body of water that separates southern England from northern France, and joins the southern part of the North Sea to the rest of the Atlantic Ocean. Inuit (pronounced or ; Inuktitut: , "the people") are a group of culturally similar indigenous peoples inhabiting the Arctic regions of Greenland, Canada and Alaska. Inuit is a plural noun; the singular is Inuk. The oral Inuit languages are classified in the Eskimo-Aleut family. Inuit Sign Language is a critically endangered language isolate spoken in Nunavut.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4.3 TYPE 3 ERROR: MULTIPLE CORRECT ANSWERS</head><p>Qilakitsoq is an archaeological site on Nuussuaq Peninsula , on the shore of Uummannaq Fjord in northwestern Greenland . Formally a settlement , it is famous for the discovery of eight mummified bodies in 1972 . Four of the mummies are currently on display in the Greenland National Museum . Norway (; Norwegian: (Bokml) or (Nynorsk); Sami: "Norgga"), officially the Kingdom of Norway, is a sovereign and unitary monarchy whose territory comprises the western portion of the Scandinavian Peninsula plus the island Jan Mayen and the archipelago of Svalbard. The Antarctic Peter I Island and the sub-Antarctic Bouvet Island are dependent territories and thus not considered part of the Kingdom. Norway also lays claim to a section of Antarctica known as Queen Maud Land. Until 1814, the Kingdom included the Faroe Islands (since 1035), Greenland (1261), and Iceland <ref type="formula" target="#formula_2">(1262)</ref>. It also included Shetland and Orkney until 1468. It also included the following provinces, now in Sweden: Jmtland, Hrjedalen and Bohusln.</p><p>The Arctic (or ) is a polar region located at the northernmost part of Earth. The Arctic consists of the Arctic Ocean, adjacent seas, and parts of Alaska (United States), Canada, Finland, Greenland (Denmark), Iceland, Norway, Russia, and Sweden. Land within the Arctic region has seasonally varying snow and ice cover, with predominantly treeless permafrost-containing tundra. Arctic seas contain seasonal sea ice in many places.</p><p>Archaeology, or archeology, is the study of human activity through the recovery and analysis of material culture. The archaeological record consists of artifacts, architecture, biofacts or ecofacts, and cultural landscapes. Archaeology can be considered both a social science and a branch of the humanities. In North America, archaeology is considered a sub-field of anthropology, while in Europe archaeology is often viewed as either a discipline in its own right or a sub-field of other disciplines.</p><p>An archaeological site is a place (or group of physical sites) in which evidence of past activity is preserved (either prehistoric or historic or contemporary), and which has been, or may be, investigated using the discipline of archaeology and represents a part of the archaeological record. Sites may range from those with few or no remains visible above ground, to buildings and other structures still in use.</p><p>Nuussuaq Peninsula (old spelling: "Ngssuaq") is a large (180x48 km) peninsula in western Greenland.</p><p>Geologically, a fjord or fiord is a long, narrow inlet with steep sides or cliffs, created by glacial erosion. There are many fjords on the coasts of Alaska, British Columbia, Chile, Greenland, Iceland, the Kerguelen Islands, New Zealand, Norway, Novaya Zemlya, Labrador, Nunavut, Newfoundland, Scotland, and Washington state. Norways coastline is estimated at with fjords, but only when fjords are excluded. The archaeological record is the body of physical (not written) evidence about the past. It is one of the core concepts in archaeology, the academic discipline concerned with documenting and interpreting the archaeological record. Archaeological theory is used to interpret the archaeological record for a better understanding of human cultures. The archaeological record can consist of the earliest ancient findings as well as contemporary artifacts. Human activity has had a large impact on the archaeological record. Destructive human processes, such as agriculture and land development, may damage or destroy potential archaeological sites. Other threats to the archaeological record include natural phenomena and scavenging. Archaeology can be a destructive science for the finite resources of the archaeological record are lost to excavation. Therefore archaeologists limit the amount of excavation that they do at each site and keep meticulous records of what is found. The archaeological record is the record of human history, of why civilizations prosper or fail and why cultures change and grow. It is the story of the world that humans have created.</p><p>The Danish Realm is a realm comprising Denmark proper, The Faroe Islands and Greenland.</p><p>Greenland is an autonomous constituent country within the Danish Realm between the Arctic and Atlantic Oceans, east of the Canadian Arctic Archipelago. Though physiographically a part of the continent of North America, Greenland has been politically and culturally associated with Europe (specifically Norway and Denmark, the colonial powers, as well as the nearby island of Iceland) for more than a millennium. The majority of its residents are Inuit, whose ancestors migrated began migrating from the Canadian mainland in the 13th century, gradually settling across the island.</p><p>Uummannaq is a town in the Qaasuitsup municipality, in northwestern Greenland. With 1,282 inhabitants in 2013, it is the eleventh-largest town in Greenland, and is home to the countrys most northerly ferry terminal. Founded in 1763 as maak, the town is a hunting and fishing base, with a canning factory and a marble quarry. In 1932 the Universal Greenland-Filmexpedition with director Arnold Fanck realized the film SOS Eisberg near Uummannaq.</p><p>The Republic of Iceland, "Lveldi sland" in Icelandic, is a Nordic island country in the North Atlantic Ocean. It has a population of and an area of , making it the most sparsely populated country in Europe. The capital and largest city is Reykjavk. Reykjavk and the surrounding areas in the southwest of the country are home to over two-thirds of the population. Iceland is volcanically and geologically active. The interior consists of a plateau characterised by sand and lava fields, mountains and glaciers, while many glacial rivers flow to the sea through the lowlands. Iceland is warmed by the Gulf Stream and has a temperate climate, despite a high latitude just outside the Arctic Circle. Its high latitude and marine influence still keeps summers chilly, with most of the archipelago having a tundra climate.</p><p>The Canadian Arctic Archipelago, also known as the Arctic Archipelago, is a group of islands north of the Canadian mainland.</p><p>Uummannaq Fjord is a large fjord system in the northern part of western Greenland, the largest after Kangertittivaq fjord in eastern Greenland. It has a roughly south-east to west-north-west orientation, emptying into the Baffin Bay in the northwest. Prediction crabronidae Support documents A honey bee (or honeybee) is any bee member of the genus Apis, primarily distinguished by the production and storage of honey and the construction of perennial, colonial nests from wax. Currently, only seven species of honey bee are recognized, with a total of 44 subspecies, though historically, from six to eleven species have been recognized. The best known honey bee is the Western honey bee which has been domesticated for honey production and crop pollination. Honey bees represent only a small fraction of the roughly 20,000 known species of bees. Some other types of related bees produce and store honey, including the stingless honey bees, but only members of the genus "Apis" are true honey bees. The study of bees including honey bees is known as melittology.</p><p>The superfamily Apoidea is a major group within the Hymenoptera, which includes two traditionally recognized lineages, the "sphecoid" wasps, and the bees. Molecular phylogeny demonstrates that the bees arose from within the Crabronidae, so that grouping is paraphyletic.</p><p>Honey is a sugary food substance produced and stored by certain social hymenopteran insects. It is produced from the sugary secretions of plants or insects, such as floral nectar or aphid honeydew, through regurgitation, enzymatic activity, and water evaporation. The variety of honey produced by honey bees (the genus "Apis") is the most well-known, due to its worldwide commercial production and human consumption. Honey gets its sweetness from the monosaccharides fructose and glucose, and has about the same relative sweetness as granulated sugar. It has attractive chemical properties for baking and a distinctive flavor that leads some people to prefer it to sugar and other sweeteners. Most microorganisms do not grow in honey, so sealed honey does not spoil, even after thousands of years. However, honey sometimes contains dormant endospores of the bacterium "Clostridium botulinum", which can be dangerous to babies, as it may result in botulism. People who have a weakened immune system should not eat honey because of the risk of bacterial or fungal infection. Although some evidence indicates honey may be effective in treating diseases and other medical conditions, such as wounds and burns, the overall evidence for its use in therapy is not conclusive. Providing 64 calories in a typical serving of one tablespoon (15 ml) equivalent to 1272 kj per 100 g, honey has no significant nutritional value. Honey is generally safe, but may have various, potential adverse effects or interactions with excessive consumption, existing disease conditions, or drugs. Honey use and production have a long and varied history as an ancient activity, depicted in Valencia, Spain by a cave painting of humans foraging for honey at least 8,000 years ago.</p><p>Australia, officially the Commonwealth of Australia, is a country comprising the mainland of the Australian continent, the island of Tasmania and numerous smaller islands. It is the worlds sixthlargest country by total area. The neighbouring countries are Papua New Guinea, Indonesia and East Timor to the north; the Solomon Islands and Vanuatu to the north-east; and New Zealand to the south-east. Australias capital is Canberra, and its largest urban area is Sydney.</p><p>Bees are flying insects closely related to wasps and ants, known for their role in pollination and, in the case of the best-known bee species, the European honey bee, for producing honey and beeswax. Bees are a monophyletic lineage within the superfamily Apoidea, presently considered as a clade Anthophila. There are nearly 20,000 known species of bees in seven to nine recognized families, though many are undescribed and the actual number is probably higher. They are found on every continent except Antarctica, in every habitat on the planet that contains insect-pollinated flowering plants.</p><p>Solomon Islands is a sovereign country consisting of six major islands and over 900 smaller islands in Oceania lying to the east of Papua New Guinea and northwest of Vanuatu and covering a land area of . The countrys capital, Honiara, is located on the island of Guadalcanal. The country takes its name from the Solomon Islands archipelago, which is a collection of Melanesian islands that also includes the North Solomon Islands (part of Papua New Guinea), but excludes outlying islands, such as Rennell and Bellona, and the Santa Cruz Islands.</p><p>The Colletidae are a family of bees, and are often referred to collectively as plasterer bees or polyester bees, due to the method of smoothing the walls of their nest cells with secretions applied with their mouthparts; these secretions dry into a cellophane-like lining. The five subfamilies, 54 genera, and over 2000 species are all evidently solitary, though many nest in aggregations. Two of the subfamilies, Euryglossinae and Hylaeinae, lack the external pollen-carrying apparatus (the scopa) that otherwise characterizes most bees, and instead carry the pollen in their crops. These groups, and most genera in this family, have liquid or semiliquid pollen masses on which the larvae develop.</p><p>Indonesia (or ; Indonesian: ), officially the Republic of Indonesia, is a unitary sovereign state and transcontinental country located mainly in Southeast Asia with some territories in Oceania. Situated between the Indian and Pacific oceans, it is the worlds largest island country, with more than seventeen thousand islands. At , Indonesia is the worlds 14th-largest country in terms of land area and worlds 7th-largest country in terms of combined sea and land area. It has an estimated population of over 260 million people and is the worlds fourth most populous country, the most populous Austronesian nation, as well as the most populous Muslim-majority country. The worlds most populous island of Java contains more than half of the countrys population.</p><p>Ants are eusocial insects of the family Formicidae and, along with the related wasps and bees, belong to the order Hymenoptera. Ants evolved from wasp-like ancestors in the Cretaceous period, about 99 million years ago and diversified after the rise of flowering plants. More than 12,500 of an estimated total of 22,000 species have been classified. They are easily identified by their elbowed antennae and the distinctive node-like structure that forms their slender waists.</p><p>Tasmania (abbreviated as Tas and known colloquially as "Tassie") is an island state of the Commonwealth of Australia. It is located to the south of the Australian mainland, separated by Bass Strait. The state encompasses the main island of Tasmania, the 26th-largest island in the world, and the surrounding 334 islands. The state has a population of around 518,500, just over forty percent of which resides in the Greater Hobart precinct, which forms the metropolitan area of the state capital and largest city, Hobart.</p><p>New Zealand is an island nation in the southwestern Pacific Ocean. The country geographically comprises two main landmassesthat of the North Island, or Te Ika-a-Mui, and the South Island, or Te Waipounamuand numerous smaller islands. New Zealand is situated some east of Australia across the Tasman Sea and roughly south of the Pacific island areas of New Caledonia, Fiji, and Tonga. Because of its remoteness, it was one of the last lands to be settled by humans. During its long period of isolation, New Zealand developed a distinct biodiversity of animal, fungal and plant life. The countrys varied topography and its sharp mountain peaks, such as the Southern Alps, owe much to the tectonic uplift of land and volcanic eruptions. New Zealands capital city is Wellington, while its most populous city is Auckland.</p><p>The flowering plants (angiosperms), also known as Angiospermae or Magnoliophyta, are the most diverse group of land plants, with 416 families, approx. 13,164 known genera and a total of c. 295,383 known species. Like gymnosperms, angiosperms are seed-producing plants; they are distinguished from gymnosperms by characteristics including flowers, endosperm within the seeds, and the production of fruits that contain the seeds. Etymologically, angiosperm means a plant that produces seeds within an enclosure, in other words, a fruiting plant. The term "angiosperm" comes from the Greek composite word ("angeion", "case" or "casing", and "sperma", "seed") meaning "enclosed seeds", after the enclosed condition of the seeds.</p><p>Pollination is the process by which pollen is transferred to the female reproductive organs of a plant, thereby enabling fertilization to take place. Like all living organisms, seed plants have a single major goal: to pass their genetic information on to the next generation. The reproductive unit is the seed, and pollination is an essential step in the production of seeds in all spermatophytes (seed plants).</p><p>Insects (from Latin , a calque of Greek [], "cut into sections") are a class of invertebrates within the arthropod phylum that have a chitinous exoskeleton, a three-part body (head, thorax and abdomen), three pairs of jointed legs, compound eyes and one pair of antennae. They are the most diverse group of animals on the planet, including more than a million described species and representing more than half of all known living organisms. The number of extant species is estimated at between six and ten million, and potentially represent over 90</p><p>The Stenotritidae are the smallest of all formally recognized bee families , with only 21 species in two genera , all of them restricted to Australia . Historically , they were generally considered to belong in the family Colletidae , but the stenotritids are presently considered their sister taxon , and deserving of family status . Of prime importance is the stenotritids have unmodified mouthparts , whereas colletids are separated from all other bees by having bilobed glossae . They are large , densely hairy , fast -flying bees , which make simple burrows in the ground and firm , ovoid provision masses in cells lined with a waterproof secretions . The larvae do not spin cocoons . Fossil brood cells of a stenotritid bee have been found in the Pleistocene of the Eyre Peninsula , South Australia .</p><p>A wasp is any insect of the order Hymenoptera and suborder Apocrita that is neither a bee nor an ant. The Apocrita have a common evolutionary ancestor and form a clade; wasps as a group do not form a clade, but are paraphyletic with respect to bees and ants.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>The Coarse-grain Fine-grain Coattention Network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Coarse-grain module.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>The fine-grain module of the CFC.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>WikiHop dev errors across query lengths, support documents lengths, number of support documents, and number of candidates for the coarse-grain-only and fine-grain-only models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Accuracy convergence plot.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>Figure 12: Top supporting documents.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Figure 14: Top supporting documents.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 16 :</head><label>16</label><figDesc>Top supporting documents.A.4 ERROR ANALYSISThis section includes identifiers and examples of the unanswerable questions we found in the development set during error analysis. In particular, these corresponds to 100 randomly sampled errors made by the CFC on the dev split of WikiHop.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>Hearts and Coronets" (1949), "Passport to Pimlico"(1949), "The Lavender Hill Mob"(1951), and "The Ladykillers"(1955). The BBC owned and filmed at the Studios for forty years from 1955 until 1995. Since 2000, Ealing Studios has resumed releasing films under its own name, including the revived "St Trinians" franchise. In more recent times, films shot here include "The Importance of Being Earnest"(2002)  and "Shaun of the Dead" (2004), as well as "The Theory of Everything" (2014), "The Imitation Game" (2014) and "Burnt"(2015). Interior scenes of the British period drama television series "Downton Abbey" are shot in Stage 2 of the studios. The Met Film School London operates on the site.Kind Hearts and Coronets is a British black comedy film of 1949 starring Dennis Price, Joan Greenwood, Valerie Hobson, and Alec Guinness. Guinness plays eight distinct characters. The plot is loosely based on the novel "Israel Rank: The Autobiography of a Criminal" (1907) by Roy Horniman, with the screenplay written by Robert Hamer and John Dighton and the film directed by Hamer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>Model accuracy on the WikiHop leaderboard at the time of submission on September 14, 2018. Missing entries indicate that the published entry did not include the corresponding score. * indicates that the work has not been published.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell cols="3">: Answer reranking results on the dev split of TriviaQA Wikipedia. We use the BiDAF++</cell></row><row><cell cols="3">model with the merge method of span scoring by Clark &amp; Gardner (2018) to propose candidate</cell></row><row><cell cols="3">answers, which are subsequently reranked using the CFC. "Answerable" indicates that the candidate</cell></row><row><cell cols="3">answers proposed contains at least one correct answer. "Unanswerable" indicates that none of the</cell></row><row><cell>candidate answers proposed are correct.</cell><cell></cell><cell></cell></row><row><cell>Model</cell><cell>Dev</cell><cell>∆ Dev</cell></row><row><cell>CFC</cell><cell>66.4%</cell><cell></cell></row><row><cell>-coarse</cell><cell cols="2">61.9% -4.5%</cell></row><row><cell>-fine</cell><cell cols="2">63.6% -2.8%</cell></row><row><cell cols="3">-selfattn 64.8% -1.6%</cell></row><row><cell>-bidir</cell><cell cols="2">65.4% -1.0%</cell></row><row><cell cols="3">-encoder 61.3% -5.1%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>Type 1 Error WH dev 1, WH dev 5,WH dev 8, WH dev 29, WH dev 30, WH dev 36,  WH dev 40, WH dev 66, WH dev 71, WH dev 76, WH dev 77, WH dev 78, WH dev 80,  WH dev 95, WH dev 96, WH dev 97, WH dev 107, WH dev 108, WH dev 109, WH dev 111,  WH dev 113, WH dev 114, WH dev 116, WH dev 125, WH dev 143, WH dev 148,  WH dev 151, WH dev 156, WH dev 161, WH dev 162, WH dev 164, WH dev 175,  WH dev 188, WH dev 190, WH dev 191, WH dev 193, WH dev 196, WH dev 198,  WH dev 212, WH dev 215, WH dev  224, WH dev 256 Type 2 Error WH dev 35, WH dev 68, WH dev 69, WH dev 81, WH dev 87, WH dev 89, WH dev 98, WH dev 123, WH dev 139, WH dev 150, WH dev 153, WH dev 154, WH dev 155, WH dev 158, WH dev 160, WH dev 168, WH dev 200, WH dev 203, WH dev 205, WH dev 208, WH dev 218, WH dev 221, WH dev 226, WH dev 228, WH dev 230, WH dev 239, WH dev 252, WH dev 260Glasgow is the largest city in Scotland, and third largest in the United Kingdom. Historically part of Lanarkshire, it is now one of the 32 council areas of Scotland. It is situated on the River Clyde in the countrys West Central Lowlands. Inhabitants of the city are referred to as Glaswegians.A council area is one of the areas defined in Schedule 1 of the Local Government etc. (Scotland) Act 1994 and is under the control of one of the local authorities in Scotland created by that Act.Edinburgh is the capital city of Scotland and one of its 32 local government council areas. Located in Lothian on the Firth of Forths southern shore, it is Scotlands second most populous city and the seventh most populous in the United Kingdom. The 2014 official population estimates are 464,990 for the city of Edinburgh, 492,680 for the local authority area, and 1,339,380 for the city region as of 2014 (Edinburgh lies at the heart of the proposed Edinburgh and South East Scotland city region). Recognised as the capital of Scotland since at least the 15th century, Edinburgh is home to the Scottish Parliament and the seat of the monarchy in Scotland. The city is also the annual venue of the General Assembly of the Church of Scotland and home to national institutions such as the National Museum of Scotland, the National Library of Scotland and the Scottish National Gallery. At the time of the 2001 census, the population of Carlisle was 71,773, with 100,734 living in the wider city. Ten years later, at the 2011 census, the citys population had risen to 75,306, with 107,524 in the wider city.Hamilton is a town in South Lanarkshire, in the central Lowlands of Scotland. It serves as the main administrative centre of the South Lanarkshire council area. It is the fourth-biggest town in Scotland. It sits south-east of Glasgow, south-west of Edinburgh and north of Carlisle, Cumbria. It is situated on the south bank of the River Clyde at its confluence with the Avon Water. Hamilton is the historical county town of Lanarkshire.South Lanarkshire is one of 32 unitary authorities of Scotland. It borders the south-east of the City of Glasgow and contains some of Greater Glasgows suburbs. It also contains many towns and villages. It also shares borders with Dumfries and Galloway, East Ayrshire, East Renfrewshire, North Lanarkshire, the Scottish Borders and West Lothian. It includes part of the historic county of Lanarkshire.The Central Lowlands or Midland Valley is a geologically defined area of relatively low-lying land in southern Scotland. It consists of a rift valley between the Highland Boundary Fault to the north and the Southern Uplands Fault to the south. The Central Lowlands are one of the three main geographical sub-divisions of Scotland, the other two being the Highlands and Islands which lie to the north, northwest and the Southern Uplands, which lie south of the associated second fault line.</figDesc><table><row><cell>Type 3 Error WH dev 13, WH dev 16, WH dev 18, WH dev 23, WH dev 32, WH dev 58,</cell></row><row><cell>WH dev 65, WH dev 83, WH dev 86, WH dev 100, WH dev 107, WH dev 140, WH dev 144,</cell></row><row><cell>WH dev 172, WH dev 176, WH dev 186, WH dev 189, WH dev 220, WH dev 222,</cell></row><row><cell>WH dev 233, WH dev 243, WH dev 262</cell></row><row><cell>Type 4 Error WH dev 14, WH dev 47, WH dev 115, WH dev 120, WH dev 133,</cell></row><row><cell>WH dev 134, WH dev 142, WH dev 234</cell></row><row><cell>A.4.1 TYPE 1 ERROR: AGGREGATION OF WRONG REFERENCE</cell></row><row><cell>Total 42 100</cell></row><row><cell>Query country of citizenship jamie burnett</cell></row><row><cell>Candidates british empire, england, london, scotland, united kingdom</cell></row><row><cell>Answer scotland</cell></row><row><cell>Prediction england</cell></row><row><cell>Support documents Jamie Burnett ( born 16 September 1975 ) is a professional snooker player</cell></row><row><cell>from Hamilton , South Lanarkshire .</cell></row></table><note>It is the largest financial centre in the UK after London. Carlisle (or from Cumbric: "Caer Luel" ) is a city and the county town of Cumbria. Historically in Cumberland, it is also the administrative centre of the City of Carlisle district in North West England. Carlisle is located at the confluence of the rivers Eden, Caldew and Petteril, south of the Scottish border. It is the largest settlement in the county of Cumbria, and serves as the administrative centre for both Carlisle City Council and Cumbria County Council.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>Support documentsThe North Sea is a marginal sea of the Atlantic Ocean located between Great Britain, Scandinavia, Germany, the Netherlands, Belgium, and France. An epeiric (or "shelf") sea on the European continental shelf, it connects to the ocean through the English Channel in the south and the Norwegian Sea in the north. It is more than long and wide, with an area of around . Britain from a low budget form of novel entertainment to the heights of lavishly-produced epics that were matched only by Hollywood for quality and style .</figDesc><table><row><cell>Total 28 100</cell></row><row><cell>Query narrative location the beloved vagabond</cell></row><row><cell>Candidates 2014, arctic, atlantic ocean, austin, austria, belgium, brittany, burgundy, cyprus, earth,</cell></row><row><cell>england, europe, finland, france, frankfurt, germany, hollywood, israel, lithuania, london, luxem-</cell></row><row><cell>bourg, lyon, marseille, netherlands, paris, portugal, rhine, swiss alps, victoria, worms</cell></row><row><cell>Answer london</cell></row><row><cell>Prediction marseille</cell></row></table><note>Worms is a city in Rhineland-Palatinate, Germany, situated on the Upper Rhine about south- southwest of Frankfurt-am-Main. It had approximately 85,000 inhabitants . William George "Will" Barker (18 January 1868 in Cheshunt 6 November 1951 in Wimbledon) was a British film producer, director, cinematographer, and entrepreneur who took film-making in</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>Slovenia, and Spain. The currency is also officially used by the institutions of the European Union and four other European countries, as well as unilaterally by two others, and is consequently used daily by some 337 million Europeans . Outside of Europe, a number of overseas territories of EU members also use the euro as their currency.Lille is a city in northern France, in French Flanders. On the Dele River, near Frances border with Belgium, it is the capital of the Hauts-de-France region and the prefecture of the Nord department.The Big Pond is a 1930 American Pre-Code romantic comedy film based on a 1928 play of the same name by George Middleton and A.E. Thomas. The film was written by Garrett Fort, Robert Presnell Sr. and Preston Sturges, who provided the dialogue in his first Hollywood assignment, and was directed by Hobart Henley. The film stars Maurice Chevalier and Claudette Colbert, and features George Barbier, Marion Ballou, and Andre Corday, and was released by Paramount Pictures. Passport to Pimlico is a 1949 British comedy film made by Ealing Studios and starring Stanley Holloway, Margaret Rutherford and Hermione Baddeley. It was directed by Henry Cornelius and written by T. E. B. Clarke. The story concerns the unearthing of treasure and documents that lead to a small part of Pimlico to be declared a legal part of the House of Burgundy, and therefore exempt from the post-war rationing or other bureaucratic restrictions active in Britain at the time.Lyon or (more archaically) Lyons (or ) is a city in east-central France, in the Auvergne-Rhne-Alpes region, about from Paris and from Marseille. Inhabitants of the city are called "Lyonnais". "Thank Heaven for Little Girls" is a 1957 song written by Alan Jay Lerner and Frederick Loewe and often associated with performer Maurice Chevalier. It opened and closed the 1958 film "Gigi". Alfred Drake performed the song in the 1973 Broadway stage production of "Gigi", though in the 2015 revival, it was sung as a duet between Victoria Clark and Dee Hoty.The Lavender Hill Mob is a 1951 comedy film from Ealing Studios, written by T.E.B. Clarke, directed by Charles Crichton, starring Alec Guinness and Stanley Holloway and featuring Sid James and Alfie Bass. The title refers to Lavender Hill, a street in Battersea, a district of South London, in the postcode district SW11, near to Clapham Junction railway station. Guiana (pronounced or ), officially called Guiana, is an overseas department and region of France, located on the north Atlantic coast of South America in the Guyanas. It borders Brazil to the east and south, and Suriname to the west. Its area has a very low population density of only 3 inhabitants per km, with half of its 244,118 inhabitants in 2013 living in the metropolitan area of Cayenne, its capital. By land area, it is the second largest region of France and the largest outermost region within the European Union.</figDesc><table><row><cell>French</cell></row><row><cell>The euro (sign: ; code: EUR) is the official currency of the eurozone, which consists of 19 of</cell></row><row><cell>the member states of the European Union: Austria, Belgium, Cyprus, Estonia, Finland, France,</cell></row><row><cell>Germany, Greece, Ireland, Italy, Latvia, Lithuania, Luxembourg, Malta, the Netherlands, Portugal,</cell></row><row><cell>Slovakia, Curtis Bernhardt (15 April 1899 22 February 1981) was a German film director born in Worms,</cell></row><row><cell>Germany, under the name Kurt Bernhardt. He trained as an actor in Germany, and performed on</cell></row><row><cell>the stage, before starting as a film director in 1926. Other films include "A Stolen Life" (1946) and</cell></row><row><cell>"Sirocco" (1951).</cell></row></table><note>Toulouse is the capital city of the southwestern French department of Haute-Garonne, as well as of the Occitanie region. The city lies on the banks of the River Garonne, from the Mediterranean Sea, from the Atlantic Ocean, and from Paris. It is the fourth-largest city in France with 466,297 inhabitants in January 2014. The Toulouse Metro area is, with 1 312 304 inhabitants as of 2014, Frances 4th metropolitan area after Paris, Lyon and Marseille and ahead of Lille and Bordeaux.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head></head><label></label><figDesc>Support documentsNorth America is a continent entirely within the Northern Hemisphere and almost all within the Western Hemisphere. It can also be considered a northern subcontinent of the Americas. It is bordered to the north by the Arctic Ocean, to the east by the Atlantic Ocean, to the west and south by the Pacific Ocean, and to the southeast by South America and the Caribbean Sea.</figDesc><table><row><cell>Total 22 100</cell></row><row><cell>Query instance of qilakitsoq</cell></row><row><cell>Candidates 1, academic discipline, activity, agriculture, archaeological site, archaeological the-</cell></row><row><cell>ory, archaeology, archipelago, architecture, base, bay, branch, century, circle, coast, company, con-</cell></row><row><cell>stituent country, continent, culture, director, endangered language, evidence, family, ferry, five,</cell></row><row><cell>fjord, group, gulf, history, human, humans, hunting, inlet, island, lancaster, language isolate, mate-</cell></row><row><cell>rial, monarchy, municipality, part, peninsula, people, queen, realm, region, republic, science, sea,</cell></row><row><cell>sign, sound, study, subcontinent, system, territory, theory, time, town, understanding, war, world</cell></row><row><cell>war, year</cell></row><row><cell>Answer town</cell></row><row><cell>Prediction archaeological site</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head></head><label></label><figDesc>Baffin Bay (Inuktitut: "Saknirutiak Imanga"; ), located between Baffin Island and the southwest coast of Greenland, is a marginal sea of the North Atlantic Ocean. It is connected to the Atlantic via Davis Strait and the Labrador Sea. The narrower Nares Strait connects Baffin Bay with the Arctic Ocean. The bay is not navigable most of the year because of the ice cover and high density of floating ice and icebergs in the open areas. However, a polynya of about , known as the North Water, opens in summer on the north near Smith Sound. Most of the aquatic life of the bay is concentrated near that region. Extent. The International Hydrographic Organization defines the limits of Baffin Bay as follows: History. The area of the bay has been inhabited since . Around 1200, the initial Dorset settlers were replaced by the Thule (the later Inuit) peoples. Recent excavations also suggest that the Norse colonization of the Americas reached the shores of Baffin Bay sometime between the 10th and 14th centuries. The English explorer John Davis was the first recorded European to enter the bay, arriving in 1585. In 1612, a group of English merchants formed the "Company of Merchants of London, Discoverers of the North-West Passage". Their governor Thomas Smythe organized five expeditions to explore the northern coasts of Canada in search of a maritime passage to the Far East. Henry Hudson and Thomas Buttons explored Hudson Bay, William Gibbons Labrador, and Robert Bylot Hudson Strait and the area which became known as Baffins Bay after his pilot William Baffin. Aboard the "Discovery", Baffin charted the area and named Lancaster, Smith, and Jones Sounds after members of his company. By the completion of his 1616 voyage, Baffin held out no hope of an ice-free passage and the area remained unexplored for another two centuries. Over time, his account came to be doubted until it was confirmed by John Rosss 1818 voyage. More advanced scientific studies followed in 1928, in the 1930s and after World War II by Danish, American and Canadian expeditions.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head></head><label></label><figDesc>Candidates angiosperms, animal, aphid, apocrita, apoidea, area, areas, colletidae, crabronidae, formicidae, honey bee, human, hymenoptera, insects, magnoliophyta, plant, thorax</figDesc><table><row><cell cols="2">A.4.4 TYPE 4 ERROR: COMPLEX RELATION TYPES</cell></row><row><cell>Total</cell><cell>8 100</cell></row><row><cell cols="2">Query parent taxon stenotritidae</cell></row><row><cell cols="2">Answer apoidea</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We use simple lexical matching between candidates and support documents. Details are found in A.1 of the Appendix.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Adding contextual encoders is computationally challenging as the CFC models the entire document context unlike<ref type="bibr" target="#b1">(Cao et al., 2018)</ref>. It is an area for future work.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENT</head><p>The authors thank Luke Zettlemoyer for his feedback and advice and Sewon Min for her help in preprocessing the TriviaQA dataset.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Question answering by reasoning across documents with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>De Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilker</forename><surname>Aziz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.09920</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A thorough examination of the CNN/Daily Mail reading comprehension task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Bolton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Coarse-to-fine question answering for long documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Hewlett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Lacoste</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Simple and effective multi-paragraph reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Overview of DUC</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoa</forename><forename type="middle">Trang</forename><surname>Dang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">DUC</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Dynamic self-attention: Computing attention over words dynamically for sentence embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangkeun</forename><surname>Lee Deunsol Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongbok</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.07383</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Neural models for reasoning over multiple mentions using coreference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhuwan</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiao</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.05922</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Coarse-to-fine decoding for neural semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Measuring importance and query relevance in topic-focused multi-document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Surabhi</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ani</forename><surname>Nenkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">A joint many-task model: Growing a neural network for multiple NLP tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuma</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshimasa</forename><surname>Tsuruoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Teaching machines to read and comprehend</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Moritz Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Kocisky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lasse</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><surname>Suleyman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">WIKIREADING: A novel large-scale language understanding task over Wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Hewlett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Lacoste</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Fandrianto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jay</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Kelcey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Reinforced mnemonic reader for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghao</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxing</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Read + verify: Machine reading comprehension with unanswerable questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghao</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxing</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongsheng</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A neural network for factoid question answering over paragraphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonardo</forename><surname>Claudino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Constituency parsing with a self-attentive encoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikita</forename><surname>Kitaev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Ask me anything: Dynamic memory networks for natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankit</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>Irsoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Ondruska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romain</forename><surname>Paulus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">End-to-end neural coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">SGDR: Stochastic gradient descent with warm restarts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Hierarchical question-image co-attention for visual question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiasen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A sentence compression based framework to query-focused multi-document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hema</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vittorio</forename><surname>Castelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Florian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><forename type="middle">Rose</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learned in translation: Contextualized word vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Efficient and robust question answering from minimal context over documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deep contextualized word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Coarse-to-fine Natural Language Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petrov</forename><surname>Slav Orlinov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<pubPlace>Berkeley</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of California</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">SQuAD: 100, 000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Know what you don&apos;t know: Unanswerable questions for SQuAD</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">MCTest: A challenge dataset for the open-domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erin</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Renshaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A neural attention model for abstractive sentence summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Bidirectional attention flow for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min Joon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aniruddha</forename><surname>Kembhavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Reinforced self-attention network: a hybrid of hard and soft attention for sequence modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqi</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In IJCAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Exploring graph-structured passage representation for multi-hop reading comprehension with graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linfeng</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Florian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.02040</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">End-to-end memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sainbayar</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Multi-mention learning for reading comprehension with neural cascades</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swabha</forename><surname>Swayamdipta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><forename type="middle">P</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">NewsQA: A machine comprehension dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingdi</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaheer</forename><surname>Suleman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 2nd Workshop on Representation Learning for NLP. ACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Machine comprehension using match-LSTM and answer pointer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Evidence aggregation for answer re-ranking in open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Constructing datasets for multi-hop reading comprehension across documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>TACL</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Dynamic coattention networks for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">DCN+: Mixed objective and deep residual coattention for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">WikiQA: A challenge dataset for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Wen Tau Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Combining local convolution with global self-attention for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adams</forename><forename type="middle">Wei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Qanet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Positionaware attention and supervised data improve slot filling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Global-locally self-attentive dialogue state tracker</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
