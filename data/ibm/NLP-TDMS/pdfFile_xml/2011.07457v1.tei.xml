<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Molecular Mechanics-Driven Graph Neural Network with Multiplex Graph for Molecular Structures</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuo</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Ph.D. Program in Computer Science</orgName>
								<orgName type="department" key="dep2">The Graduate Center</orgName>
								<orgName type="institution">The City University of New York</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution" key="instit1">Hunter College</orgName>
								<orgName type="institution" key="instit2">The City University of New York</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution" key="instit1">Hunter College</orgName>
								<orgName type="institution" key="instit2">The City University of New York</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Xie</surname></persName>
							<email>lei.xie@hunter.cuny.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Ph.D. Program in Computer Science</orgName>
								<orgName type="department" key="dep2">The Graduate Center</orgName>
								<orgName type="institution">The City University of New York</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution" key="instit1">Hunter College</orgName>
								<orgName type="institution" key="instit2">The City University of New York</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Helen &amp; Robert Appel Alzheimer&apos;s Disease Research Institute</orgName>
								<orgName type="institution" key="instit2">Feil Family Brain &amp; Mind Research Institute</orgName>
								<orgName type="institution" key="instit3">Weill Cornell Medicine</orgName>
								<orgName type="institution" key="instit4">Cornell University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Molecular Mechanics-Driven Graph Neural Network with Multiplex Graph for Molecular Structures</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The prediction of physicochemical properties from molecular structures is a crucial task for artificial intelligence aided molecular design. A growing number of Graph Neural Networks (GNNs) have been proposed to address this challenge. These models improve their expressive power by incorporating auxiliary information in molecules while inevitably increase their computational complexity. In this work, we aim to design a GNN which is both powerful and efficient for molecule structures. To achieve such goal, we propose a molecular mechanics-driven approach by first representing each molecule as a two-layer multiplex graph, where one layer contains only local connections that mainly capture the covalent interactions and another layer contains global connections that can simulate non-covalent interactions. Then for each layer, a corresponding message passing module is proposed to balance the trade-off of expression power and computational complexity. Based on these two modules, we build Multiplex Molecular Graph Neural Network (MXMNet). When validated by the QM9 dataset for small molecules and PDBBind dataset for large protein-ligand complexes, MXMNet achieves superior results to the existing state-of-the-art models under restricted resources.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Human society benefits greatly from the discovery and design of new molecules with desired properties, from COVID-19 vaccines to solar cells. Artificial intelligence (AI) plays an increasingly important role in accelerating the molecular discovery process. One of the crucial tasks in AI-assisted molecular design is to predict the physicochemical properties of molecules from their structures. In recent years, many machine learning techniques have been proposed for the representational learning of molecules to reduce the computational cost involved in quantum chemistry calculations (DFT) and molecular dynamics simulations (MD) <ref type="bibr">[1]</ref>. Among those methods, Graph Neural Networks (GNNs) have shown superior performance by treating the molecule as a graph and performing message passing scheme on it <ref type="bibr">[2]</ref>.</p><p>To better model the interactions in molecules and increase the expressive power of methods, previous GNNs have adopted auxiliary information such as chemical properties, pairwise distances between atoms, and angular information <ref type="bibr">[3,</ref><ref type="bibr">4,</ref><ref type="bibr">5,</ref><ref type="bibr">6,</ref><ref type="bibr">7,</ref><ref type="bibr">8,</ref><ref type="bibr">9]</ref>. However, adopting such information in GNNs will inevitably increase the computational complexity. For example, when passing messages on a molecular graph that has N nodes with an average of k nearest neighbors for each node, O(N k 2 ) or O(N 3 ) messages are required in the worst case for the previous state-of-the-art GNNs <ref type="bibr">[8,</ref><ref type="bibr">9]</ref> to Figure 1: std. MAE vs. memory consumption on QM9 dataset <ref type="bibr">[11]</ref>. When compared with Schnet <ref type="bibr">[6]</ref>, PhysNet <ref type="bibr">[7]</ref> and DimeNet <ref type="bibr">[8]</ref>, MXMNet gets the state-of-the-art performance and is memory-efficient. capture the angular information. With restricted memory resources, those GNNs could exhibit limited expressive power or even fail when applied to macromolecules like proteins or RNAs.</p><p>To address the limitation, we propose a novel GNN that is both powerful and efficient. Inspired by molecular mechanics methods <ref type="bibr">[10]</ref>, we use the angular information to model only the local connections to avoid using expensive computations on all connections. Besides, we divide the molecular interactions into two categories: local and global. Then a two-layer multiplex graph G = {G l , G g } is constructed for a molecule. In G, the local layer G l only contains the local connections that mainly capture covalent interactions, and the global layer G g contains the global connections that cover non-covalent interactions. With the multiplex molecular graphs, we then design Multiplex Molecular (MXM) module that contains a novel angle-aware message passing operated on G l and an efficient message passing operated on G g . Note that the MXM module reduces the computational complexity by avoiding capturing the angular information in nonlocal interactions. Finally, we construct the Multiplex Molecular Graph Neural Network (MXMNet) for the representation learning of molecules.</p><p>To empirically evaluate the power and efficiency of MXMNet, we conduct experiments on a small molecules dataset QM9 <ref type="bibr">[11]</ref> and a protein-ligand complexes dataset PDBBind <ref type="bibr">[12]</ref>. On both datasets, our model can outperform the baseline models. Regarding the efficiency, our model requires significantly less memory than the previous state-of-the-art model <ref type="bibr">[8]</ref> as shown in <ref type="figure">Figure 1</ref> and achieves a training speedup of 260%. The main contributions of our work are as follows:</p><p>• We propose a molecular mechanics-driven approach to represent the molecule by using a two-layer multiplex graph, where one layer contains local connections and another layer contains global connections. • We propose Multiplex Molecular (MXM) module which performs the message passing on the whole multiplex graph. The MXM module captures the global pairwise distances and local angles to be both powerful and efficient. • We propose Multiplex Molecular Graph Neural Network (MXMNet) based on the MXM module. Experiments on benchmark datasets validate that MXMNet achieves state-of-the-art performance and is efficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>GNNs for Molecules. To learn the representations of graph-structured data using neural networks, Graph Neural Networks (GNNs) have been proposed <ref type="bibr">[3,</ref><ref type="bibr">13,</ref><ref type="bibr">14]</ref> and attracted growing interests. Due to the superior performance achieved by GNNs in various tasks, researchers began to apply GNNs for predicting various properties of molecules. Initial works treat the chemical bonds in molecules as edges and atoms as nodes to create graphs for molecules <ref type="bibr">[3,</ref><ref type="bibr">4,</ref><ref type="bibr">5]</ref>. These GNNs also integrate many hand-picked chemical features to improve performance. However, they do not take account of the 3-dimensional structure of molecules, which is critical for many physiochemical properties of molecules. Thus later works <ref type="bibr">[15,</ref><ref type="bibr">6,</ref><ref type="bibr">16,</ref><ref type="bibr">7]</ref> turn to take the atomic positions into consideration and use interatomic distances to create the edges as well as edge features between atoms. Usually, a cutoff distance is used to find the neighbors in molecules instead of creating a complete graph to reduce the computational complexity and overfitting. However, the setting of cutoff sometimes can lead the GNNs to fail to distinguish certain molecules <ref type="bibr">[8]</ref>. To solve this issue, angular information is further used in GNNs to achieve higher expressive power <ref type="bibr">[8,</ref><ref type="bibr">9]</ref>. However, those angle-aware GNNs have significantly higher time and space complexity than the previous works. They are not scalable to macromolecules or large-batch learning.</p><p>Multiplex Graph. The multiplex graph (a.k.a multi-view graph) consists of multiple types of edges among a set of nodes. Informally, it can be considered as a collection of graphs, where each type of edges with the same set of nodes forms a graph or a layer. To get the representation of each node, both intra-layer relationships and cross-layer relationships have to be addressed properly. In practice, various methods have been proposed to learn the embedding of the multiplex graph <ref type="bibr">[17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21]</ref> and the multiplex graph can be applied in many fields <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24]</ref>. For the representation learning on molecules, previous work <ref type="bibr" target="#b24">[25]</ref> implicitly represents molecular graphs as multiplex graphs and passes messages according to the edge types. In this work, we explicitly represent molecules as multiplex graphs based on the geometric information in molecules. Moreover, we propose different message passing schemes for different layers in the multiplex graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Preliminaries</head><p>In this section, we will introduce the preliminaries about our work. We first introduce the main notations used in this paper. Let G = (V, E) be a graph with N = |V | nodes and M = |E| edges. The nearest neighbors of node i are defined as N (i) = {j|d(i, j) = 1}, where d(i, j) is the shortest distance between node i and j. The average number of the nearest neighbors of each node is k = 2M/N . In the later formulations, we will use h i as the embedding of node i, e ji as the edge embedding between node i and j, which embeds the pairwise distance, m ji as the message being sent from node j to node i in the message passing scheme <ref type="bibr">[5]</ref>, MLP as the multi-layer perceptron, as the concatenation operation, as the element wise production and W as the weight matrix. Next we provide the definition of a multiplex graph: Definition 1. Multiplex Graph. A multiplex graph can be defined as an L + 1-tuple G = (V, E 1 , . . . , E L ) where V is the set of nodes and for each l ∈ {1, 2, . . . , L}, E l is the set of edges in type l that between pairs of nodes in V . By defining the graph G l = (V, E l ) which is also called a plex or a layer, the multiplex graph can be seen as the set of graphs G = {G 1 , G 2 , ..., G L }.</p><p>Now we introduce the message passing scheme <ref type="bibr">[5]</ref> which is a general graph convolution used in spatial-based GNNs [2]: Definition 2. Message Passing. Given a graph G, the node feature of each node i is x i , and the edge feature for each node pair j and i is e ji . The message passing scheme iteratively updates the node embedding h using the following functions:</p><formula xml:id="formula_0">m t ji = f m (h t−1 i , h t−1 j , e ji ), h t i = f u (h t−1 i , j∈N (i) m t ji ),</formula><p>where the superscript t denotes the t-step iteration, h 0 i = x i , the f m and f u are learnable functions.</p><p>In recent works <ref type="bibr">[8,</ref><ref type="bibr">9]</ref>, the message passing scheme has been modified to capture the angular information in a 3D molecular graph G = (V, E) with N nodes and their Cartesian coordinates r = {r 1 , . . . , r N }, where r i ∈ R 3 is the position of node i. To analyze their computational complexity, we start from the number of angles in G to be captured: Theorem 1. Given a 3D molecular graph G, each pair of adjacent edges that share a common node can define an angle in G. There are O(N k 2 ) angles in G, where N is the number of nodes and k is the average number of nearest neighbors for each node.</p><p>The proof is straightforward: For each node in G, there is an average of k edges connected to it. Those k edges can define (k(k − 1))/2 angles. Thus in total, we have O(N k 2 ) angles in G. To capture those angles in message passing scheme, there is at least one message being used to contain each angle in recent approaches <ref type="bibr">[8,</ref><ref type="bibr">9]</ref>. Thus the computational complexity of those models is at least O(N k 2 ) for each graph in an operation.</p><p>Finally we present the problem investigated in this work: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Approach</head><p>In this section, we introduce our molecular mechanics-driven approach including the multiplex molecular graphs, the Multiplex Molecular (MXM) module, and the Multiplex Molecular Graph Neural Network (MXMNet).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Multiplex Molecular Graphs</head><p>In molecular mechanics methods <ref type="bibr">[10]</ref>, the molecular energy E is modeled as E = E local + E nonlocal (see <ref type="figure">Figure 2</ref>(a)), where E local = E bond + E angle + E dihedral models the local, covalent interactions including E bond that depends on bond lengths, E angle on bond angles, and E dihedral on the dihedral angles. E nonlocal models the non-local, non-covalent interactions between atom pairs. When focusing on the geometric information contained in the molecular mechanics method, we will find that the local interactions capture the angles α local and the pairwise distances d local while the nonlocal interactions only capture the pairwise distances d nonlocal (see <ref type="figure">Figure 2</ref>(b)). These inspire us to use the angular information to model only the local interactions instead of all interactions in our model to reduce the computational complexity.</p><p>To achieve our goal, we first divide the geometric information (GI) in molecular mechanics methods into two groups: Local GI that contains α local and d local , and Global GI that contains d local and d nonlocal (see <ref type="figure">Figure 2</ref>(b)). Given a 3D molecule, we then construct the corresponding interaction graphs that contain different GI (see <ref type="figure">Figure 2</ref>(c)). For the local GI, we can create edges by using either chemical bonds or finding the neighbors of each node within a small cutoff distance depending on the task being investigated. For the global GI, we create the edges by defining the neighbors of each node within a relatively large cutoff distance. With the interaction graphs, we treat them as layers to build a multiplex molecular graph G = {G l , G g }, which consists of a local layer G l and a global layer G g (see <ref type="figure">Figure 2(d)</ref>). The resulting G will be used as the input of our model. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Multiplex Molecular (MXM) Module</head><p>With the multiplex molecular graph G, we propose Multiplex Molecular (MXM) module that uses different rules to update the node embeddings based on the different edges in G (see <ref type="figure">Figure 2</ref>(e)).</p><p>For G g , we propose the global layer message passing. For G l , we propose the local layer message passing. To transfer the information between different layers, we use a cross layer mapping. These operations will be introduced as follows in detail.</p><p>Global Layer Message Passing Module. In this module, the message passing is performed on the global layer, which contains both local and non-local connections. We propose a message passing module that can capture the pairwise distances based on the message passing defined in Definition 2.</p><p>Note that the message passing in Definition 2 can only take the one-hop neighbors of the central node in the aggregation per iteration. Inspired by previous works that demonstrate the power of addressing high-order neighbors in GNNs <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28]</ref>, we here propose a message passing that captures up to the two-hop neighbors per iteration. A straightforward way to achieve the goal would be directly aggregating all two-hop neighbors. However, this would require O(N k 2 ) messages on the graph per iteration. Instead, we perform the one-hop based message passing twice in each iteration to address the two-hop neighbors. The resulting operation will only need O(2N k) messages in this way.</p><p>As illustrated in <ref type="figure" target="#fig_1">Figure 3</ref>(b), our global layer message passing module consists of two identical message passing operations that can capture the pairwise distance information e. Each message passing operation is formulated as follows:</p><formula xml:id="formula_1">m ji = MLP([h input j h input i e ji ]) (e ji W ),<label>(1)</label></formula><formula xml:id="formula_2">h output i = h input i + j∈N (i) m ji ,<label>(2)</label></formula><p>where i, j ∈ G global , the superscripts denote the state of h in the operation. In our global layer message passing, an update function f u is used between the two message passing operations. We define f u using multiple residual modules (see <ref type="figure" target="#fig_1">Figure 3(d)</ref>). Each residual module consists of a two-layer MLP and a skip connection (see <ref type="figure" target="#fig_1">Figure 3</ref>(e)).</p><p>Local Layer Message Passing Module. In this module that performs message passing on the local layer, we will incorporate both the pairwise distance and angles associated with local interactions. In practice, we propose a message passing that captures up to the two-hop neighbors per iteration. In this way, the edges can define two kinds of angles: The two-hop angles that between the one-hop edges and the two-hop edges (∠ij 1 k 1 , ∠ij 1 k 2 in <ref type="figure" target="#fig_2">Figure 4</ref>). The one-hop angles that only between the one-hop edges (∠j 1 ij 2 and ∠j 1 ij 3 in <ref type="figure" target="#fig_2">Figure 4</ref>). Our message passing can capture all of those angles. While the previous work <ref type="bibr">[8]</ref> only captures the two-hop angles. In detail, we propose a 3-step message passing scheme to be the local layer message passing:</p><p>Step 1 contains Message Passing 1 that captures the two-hop angles and related pairwise distances to update edge-level embeddings {m ji } (see <ref type="figure" target="#fig_2">Figure 4</ref>(a)).</p><p>Step 2 contains Message Passing 2 that captures the one-hop angles and related pairwise distances to further update {m ji } (see <ref type="figure" target="#fig_2">Figure 4</ref>(b)).</p><p>Step 3 finally aggregates {m ji } to update the node-level embedding h i . These steps in the t-th iteration can be formulated as follows:</p><p>Step 1: Message Passing 1</p><formula xml:id="formula_3">m t−1 kj = MLP kj ([h t−1 k h t−1 j e kj ]) (e kj W e1 ) MLP a1 (a kj,ji ),<label>(3)</label></formula><formula xml:id="formula_4">m t−1 ji = MLP ji ([h t−1 j h t−1 i e ji ]) + k∈N (j)\{i} m t−1 kj ,<label>(4)</label></formula><p>Step 2: Message Passing 2</p><formula xml:id="formula_5">m t−1 j i = MLP j i (m t−1 j i ) (e j i W e2 ) MLP a2 (a j i,ji ),<label>(5)</label></formula><formula xml:id="formula_6">m t−1 ji = MLP ji (m t−1 ji ) + j ∈N (i)\{j} m t−1 j i ,<label>(6)</label></formula><p>Step 3: Aggregation and Update</p><formula xml:id="formula_7">h t i = f u ( j∈N (i) m t−1 ji (e ji W e3 )),<label>(7)</label></formula><p>where i, j, k ∈ G local , a kj,ji is the feature for angle α kj,ji = ∠h k h j h i . We define f u using the same form as in the global layer message passing. These steps need O(2N k 2 + N k) messages in total. <ref type="figure" target="#fig_1">Figure 3</ref>(c) illustrates the architecture of the global layer message passing. Note that we also include an Output module (see <ref type="figure" target="#fig_1">Figure 3</ref>(c) and (f)), which is used for producing the output when creating the whole GNN model later.</p><p>Cross Layer Mapping. After having the message passing modules for the local and global layer, we further use a cross layer mapping function f cross to address the connections between the same nodes across different layers in a multiplex molecular graph (see <ref type="figure">Figure 2(d)</ref>).</p><p>The cross layer mapping function f cross takes either the node embeddings {h g } in the global layer or the node embeddings {h l } in the local layer as input, and maps them to replace the node embeddings in the other layer (see <ref type="figure" target="#fig_1">Figure 3</ref>(a)):</p><formula xml:id="formula_8">h l = f cross (h g ) or h g = f cross (h l ),<label>(8)</label></formula><p>where g ∈ G global , l ∈ G local , the f cross and f cross are learnable functions. In practice, we use multi-layer perceptrons to be f cross and f cross . Each of them needs O(N ) messages being updated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Multiplex Molecular Graph Neural Network (MXMNet)</head><p>With MXM module, we build Multiplex Molecular Graph Neural Network (MXMNet) for the prediction of molecular properties as shown in <ref type="figure" target="#fig_1">Figure 3</ref>(g). In the Embedding module, the atomic numbers Z are represented with randomly initialized, trainable embeddings to be the input node embeddings. In the RBF &amp; SBF module, the Cartesian coordinates r of atoms are used to compute the pairwise distances and angles. We use the basis functions proposed in <ref type="bibr">[8]</ref> to construct the representations of e RBF and a SBF . Then we stack MXM modules to perform message passings. In each MXM module, we use an Output module to get the node-level output. The final prediction y is computed by summing all outputs together among all nodes and all layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Expressive Power and Complexity of MXMNet</head><p>Expressive Power. We analyze the expressive power of MXMNet by focusing on the effect of captured geometric information on representing molecular structures. Since MXMNet takes the pairwise distance information in global connections and the angular information in local connections into consideration, it is more powerful than the GNNs that only captures the pairwise distance information <ref type="bibr">[15,</ref><ref type="bibr">6,</ref><ref type="bibr">16,</ref><ref type="bibr">7]</ref>. When compared with the GNNs that captures both the pairwise distance information and angular information in global connections <ref type="bibr">[8,</ref><ref type="bibr">9]</ref>, MXMNet theoretically has lower expressive power due to the uncaptured angular information in nonlocal connections. However, note that expressive power does not directly speak about the generalization ability of GNNs <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30]</ref>, our experiments will empirically show that MXMNet exhibits good generalization ability with state-of-the-art performance.</p><p>Computational Complexity. To analyze the computational complexity, we focus on the time and space complexity of message passing in MXMNet. We denote the cutoff distance when creating the edges as d g and d l in G g and G l . The average number of the nearest neighbors per node is k g in G g and is k l in G l . For 3D molecules, we have k g ∝ d g 3 and k l ∝ d l 3 . As d g &gt; d l , we know that k g k l . As discussed in previous sections, the message passing operations in our MXM module requires the computation of O(2N k g + 2N k l 2 + N k l + 2N ) messages in total. Therefore, MXMNet is much more efficient than the GNNs capturing angular information in global connections <ref type="bibr">[8,</ref><ref type="bibr">9]</ref>, which require O(N k g 2 ) messages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>In our experiments, we evaluate the generalization power as well as the efficiency of our MXMNet on the QM9 dataset for predicting molecular properties and the PDBBind dataset for predicting the protein-ligand binding affinities. Several state-of-the-art baseline models are also included for comparisons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Setup</head><p>QM9. The QM9 dataset is a widely used benchmark for the prediction of physical properties of molecules in equilibrium <ref type="bibr">[11]</ref>. It consists of around 130k small organic molecules with up to 9 heavy atoms (C, O, N, and F). The properties are computed using density functional theory (DFT) calculations. Following <ref type="bibr">[8]</ref>, we randomly use 110000 molecules for training, 10000 for validation and the rest for testing. We evaluate the mean absolute error (MAE) of the target properties. To create the multiplex molecular graphs, we use the chemical bonds as the edges in the local layer, and a cutoff distance to create the edges in the global layer.</p><p>PDBBind. PDBBind is a database of experimentally measured binding affinities for protein-ligand complexes <ref type="bibr">[12]</ref>. It contains detailed 3D structures and associated inhibition constants K i for the complexes. In our experiment, we use the PDBBind 2015 refined subset which contains roughly 4K structures. In each complex, we exclude the protein residues that are more than 6Å from the ligand. Besides, we remove all hydrogen atoms and use the remaining heavy atoms in the structure. The resulting complexes contain around 200 atoms on average. In the experiment, we split the dataset into training, validation, and testing sets by 8:1:1 and perform 10-fold cross-validation. The mean absolute error (MAE) of the binding free energy and the Pearson correlation coefficient (R) of logK i are reported. To create the multiplex molecular graphs, we use a cutoff distance of 2Å in the local layer and 6Å in the global layer when defining the edges.</p><p>In our experiments, we use the following state-of-the-art models as baselines: SchNet <ref type="bibr">[6]</ref>, PhysNet <ref type="bibr">[7]</ref>, MEGNet-full <ref type="bibr">[16]</ref>, Cormorant <ref type="bibr" target="#b30">[31]</ref>, MGCN <ref type="bibr" target="#b31">[32]</ref> and DimeNet <ref type="bibr">[8]</ref>. On QM9, we use the results  reported in the original works for the baselines. On PDBBind, we conduct the experiments based on the corresponding implementations. All of the experiments are done on an NVIDIA Tesla V100 GPU (32 GB). More details of the parameter settings and training setup are included in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results on QM9</head><p>On the QM9 dataset, we test the performance of MXMNet under different configurations by changing the batch size BS and the cutoff distance d g used in the global layer. As reported in <ref type="table" target="#tab_0">Table 1</ref>, MXMNet variants get better results than the baselines on 9 targets. We also compute the mean standardized MAE (std. MAE) as used in <ref type="bibr">[8]</ref> to evaluate the overall performance of the models. MXMNet (BS=128, d g = 10Å) has the lowest std. MAE among all models and decreases the mean std. MAE by 13% compared to the previous best model DimeNet. The results clearly demonstrate the excellent generalization power of MXMNet.</p><p>Ablation Study. By comparing the results between MXMNet (BS=32, d g = 5Å) and MXMNet (BS=128, d g = 5Å), we find that the effect of batch size on the performance is small. With a relatively large batch size (128), the overall performance is slightly better than using a small batch size <ref type="bibr" target="#b31">(32)</ref>. Moreover, we can benefit from the large batch to achieve faster training.</p><p>To investigate the effect of d g on the performance, we compare the results of the MXMNet variants that using different d g in <ref type="table" target="#tab_0">Table 1</ref>. When using d g = 5Å, MXMNet can get better results than using d g = 10Å on the targets ZPVE, U 0 , U , H, G and c v . This suggests that those properties benefit more from modeling a limited range of interactions rather than simply increasing the interaction range. While for the targets µ, HOMO , LUMO , ∆ and R 2 , the performance of MXMNet can be improved by using a larger d g = 10Å that helps to capture longer range interactions. Therefore, in practice, it is recommended to use different d g for predicting different properties.</p><p>To further test whether our proposed two message passing modules (local layer and global layer) will both contribute to the success of MXMNet, we conduct experiments by using only one of the two modules or even parts of a module. <ref type="table" target="#tab_1">Table 2</ref> shows that all the ablations will decrease the performance of MXMNet. These validate that both of the two message passing modules contribute to the power of MXMNet. Besides, when only using the global layer message passing module, the ablation with only one message passing performs worse than the ablation with two message passings, which shows the effectiveness of capturing the two-hop neighbors. When only using the local layer message passing module, the mean std. MAE increases significantly compared to the original MXMNet, suggesting that the local connections are not adequate for the task. The results also validate the necessity to capture both one-hop angles and two-hop angles: The ablations with either one kind of them perform worse than the ablation with all of them.</p><p>Efficiency Evaluation. To evaluate the space and time efficiency of MXMNet, we first compare the memory consumption during the training on QM9 for SchNet, PhysNet, DimeNet, and MXMNet. For the baselines, the model configurations are the same as those in their original papers. As illustrated in <ref type="figure">Figure 1</ref>, all of the three MXMNet variants use a much smaller memory than DimeNet. For SchNet and PhysNet that consume less memory than MXMNet, they perform worse than MXMNet with higher mean std. MAEs. Then for time efficiency, we focus on the total training time. Note that the total training time is affected by all operations in the models and different models need different computational time for passing one message. Thus a smaller number of messages being passed in a GNN does not guarantee a shorter training time. Instead, we find that the batch size significantly affects the training time: MXMNet can benefit from large batch training with BS=128 to achieve a speedup of the training to 2.6× against DimeNet that can only use BS=32 on our GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Results on PDBBind</head><p>On the PDBBind dataset with much larger molecules than those in QM9, the training of MXMNet is still able to be performed on our GPU. With the same model configuration, DimeNet will raise the out-of-memory error. As shown in <ref type="table" target="#tab_2">Table 3</ref>, when compared with SchNet and PhysNet that do not have the memory issue, MXMNet outperforms them significantly with a higher Pearson R and a lower MAE. Those results validate that our model is both powerful and memory-efficient to be used for macromolecules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we propose a powerful and efficient GNN, MXMNet, for predicting the properties of molecules. Our model can significantly improve both expressive power and memory efficiency of GNNs for molecules. The novelty of MXMNet lies in its representation of molecules as a multiplex graph that is rooted in molecular mechanics. Experiments on QM9 and PDBBind datasets have successfully demonstrated the power and efficiency of MXMNet compared with the state-of-the-art baselines. In future work, it would be interesting to address the dihedral angles in 3D molecules. It is also promising to use MXMNet as a general tool to learn the representations of molecules in more tasks. Moreover, since molecules can have multiple conformations. It remains unclear how these conformations affect our model and other related GNNs. 7 Appendix 7.1 Dataset Sources QM9. For the QM9 dataset, we use the source 1 provided by <ref type="bibr">[1]</ref>. Following the previous works <ref type="bibr">[2,</ref><ref type="bibr">3,</ref><ref type="bibr">4,</ref><ref type="bibr">5,</ref><ref type="bibr">6]</ref>, we process the QM9 dataset by removing about 3k molecules that fail a geometric consistency check or are difficult to converge <ref type="bibr">[7]</ref>. For the properties U 0 , U , H, and G, only the atomization energies are used by subtracting the atomic reference energies as in <ref type="bibr">[8]</ref>. For the property ∆ , we follow the same way as the DFT calculation and predict it by calculating LUMO − HOMO .</p><p>PDBBind. For the PDBBind dataset, we use the version 2 that is included in the MoleculeNet benchmark for molecular machine learning <ref type="bibr">[9]</ref>. We use logK i as the target property being predicted, which is proportional to the binding free energy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Baseline Sources</head><p>For the baselines used in the experiment on PDBBind, we find their codes provided by the original papers are based on different frameworks: SchNet <ref type="bibr">[3]</ref> is based on PyTorch <ref type="bibr">[10]</ref>, while PhysNet <ref type="bibr">[4]</ref> and DimeNet <ref type="bibr">[8]</ref> are based on Tensorflow <ref type="bibr">[11]</ref>. To make fair comparisons and exclude the differences brought by different frameworks, we adopt the implementations of SchNet 3 and DimeNet 4 provided by the widely used PyTorch Geometric library <ref type="bibr">[12]</ref> for graph representation learning. Since DimeNet is built based on PhysNet, by comparing their original implementations, we create the implementation of PhysNet based on 4 by changing the corresponding modules. Besides, the code of our MXMNet is also built based on 4 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Implementation Details</head><p>For the multi-layer perceptrons (MLPs) used in our MXMNet, they all have 2 layers to take advantage of the approximation capability of MLP <ref type="bibr">[13]</ref>. For all activation functions, we use the self-gated Swish activation function <ref type="bibr">[14]</ref>. For the basis functions e RBF and a SBF , we use N SHBF = 7, N SRBF = 6 and N RBF = 16. To initialize all learnable parameters, we use the default settings used in PyTorch without assigning specific initializations except the initialization for the input node embeddings h (0) g in the global layer: h (0) g are initialized with random values uniformly distributed between − √ 3 and √ 3.</p><p>In our experiment on QM9, we use the single-target training following <ref type="bibr">[8]</ref> by using a separate model for each target instead of training a single shared model for all targets. The models are optimized by minimizing the mean absolute error (MAE) loss using the Adam optimizer <ref type="bibr">[15]</ref>. We use a linear learning rate warm-up over 1 epoch and an exponential decay with ratio 0.1 every 600 epochs. The model parameter values for validation and test are kept using an exponential moving average with a decay rate of 0.999. To prevent overfitting, we use early stopping on the validation loss. Besides, we repeat our runs 3 times for each MXMNet variant following <ref type="bibr">[16]</ref>.</p><p>In our experiment on PDBBind, for each model being investigated, we create three weight-sharing, replica networks, one each for predicting the target G of complex, protein pocket, and ligand following <ref type="bibr">[17]</ref>. The final target is computed by ∆G complex = G complex − G pocket − G ligand . The full model is trained by minimizing the mean squared error (MSE) loss between ∆G complex and the true values using the Adam optimizer <ref type="bibr">[15]</ref>. The learning rate is dropped by a factor of 0.2 every 50 epoch. Moreover, we perform 10-fold cross-validation and repeat the experiments 5 times for each model. The validation losses are used for early stopping.</p><p>In  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :Problem 1 .</head><label>21</label><figDesc>Illustration of our molecular mechanics-driven approach. (a) The molecular mechanics (MM) methods. (b) The geometric information (GI) used in MM methods does not contain the angles in nonlocal interactions. We further group the GI into Local GI and Global GI. (c) Given a 3D molecule, interaction graphs are constructed with different GI. We show an example of creating edges around an orange node. (d) The resulting interaction graphs are used to build a multiplex molecular graph G. (e) With G, we design message passing modules to update the node embeddings hierarchically and efficiently. Molecular Properties Prediction. Given a molecule with N atoms and their atomic numbers Z = {Z 1 , . . . , Z N } and Cartesian coordinates r = {r 1 , . . . , r N }, the problem of molecular properties prediction is to predict the target property t ∈ R of the molecule. The regression goal is to find a function f : {Z, r} → R. Sometimes with auxiliary chemical information Θ, the goal function is f : {Z, r, Θ} → R.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Overview of the architecture of the MXM module and the MXMNet. In the illustrations, σ denotes the non-linear transformation, denotes the input for the layer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Illustration of Message Passing 1 and 2 used in the Local Layer Message Passing module. (a) Message Passing 1 can capture the two-hop angles like ∠ij 1 k 1 and ∠ij 1 k 2 when updating m j1i . (b) Message Passing 2 can capture the one-hop angles like ∠j 1 ij 3 and ∠j 1 ij 2 when updating m j1i .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Comparison of MAEs of targets on QM9 for different models.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">MXMNet MXMNet MXMNet</cell></row><row><cell>Target</cell><cell cols="6">SchNet PhysNet MEGNet-f Cormorant MGCN DimeNet</cell><cell>BS=32</cell><cell>BS=128</cell><cell>BS=128</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>d g =5Å</cell><cell>d g =5Å</cell><cell>d g =10Å</cell></row><row><cell>µ (D)</cell><cell>0.021</cell><cell>0.0529</cell><cell>0.040</cell><cell>0.038</cell><cell>0.056</cell><cell>0.0286</cell><cell>0.0396</cell><cell>0.0382</cell><cell>0.0255</cell></row><row><cell>α(a 3 0 )</cell><cell>0.124</cell><cell>0.0615</cell><cell>0.083</cell><cell>0.085</cell><cell>0.030</cell><cell>0.0469</cell><cell>0.0447</cell><cell>0.0482</cell><cell>0.0465</cell></row><row><cell>HOMO (meV)</cell><cell>47</cell><cell>32.9</cell><cell>38</cell><cell>34</cell><cell>42.1</cell><cell>27.8</cell><cell>24.7</cell><cell>23.0</cell><cell>22.8</cell></row><row><cell>LUMO (meV)</cell><cell>39</cell><cell>24.7</cell><cell>31</cell><cell>38</cell><cell>57.4</cell><cell>19.7</cell><cell>19.7</cell><cell>19.5</cell><cell>18.9</cell></row><row><cell>∆ (meV)</cell><cell>74</cell><cell>42.5</cell><cell>61</cell><cell>61</cell><cell>64.2</cell><cell>34.8</cell><cell>32.6</cell><cell>31.2</cell><cell>30.6</cell></row><row><cell>R 2 (a 2 0 )</cell><cell>0.158</cell><cell>0.765</cell><cell>0.265</cell><cell>0.961</cell><cell>0.11</cell><cell>0.331</cell><cell>0.512</cell><cell>0.506</cell><cell>0.088</cell></row><row><cell>ZPVE (meV)</cell><cell>1.616</cell><cell>1.39</cell><cell>1.40</cell><cell>2.027</cell><cell>1.12</cell><cell>1.29</cell><cell>1.15</cell><cell>1.16</cell><cell>1.19</cell></row><row><cell>U 0 (meV)</cell><cell>12</cell><cell>8.15</cell><cell>9</cell><cell>22</cell><cell>12.9</cell><cell>8.02</cell><cell>5.90</cell><cell>6.10</cell><cell>6.59</cell></row><row><cell>U (meV)</cell><cell>12</cell><cell>8.34</cell><cell>10</cell><cell>21</cell><cell>14.4</cell><cell>7.89</cell><cell>5.94</cell><cell>6.09</cell><cell>6.64</cell></row><row><cell>H (meV)</cell><cell>12</cell><cell>8.42</cell><cell>10</cell><cell>21</cell><cell>16.2</cell><cell>8.11</cell><cell>6.09</cell><cell>6.21</cell><cell>6.67</cell></row><row><cell>G (meV)</cell><cell>13</cell><cell>9.40</cell><cell>10</cell><cell>20</cell><cell>14.6</cell><cell>8.98</cell><cell>7.17</cell><cell>7.30</cell><cell>7.81</cell></row><row><cell>c v ( cal molK )</cell><cell>0.034</cell><cell>0.0280</cell><cell>0.030</cell><cell>0.026</cell><cell>0.038</cell><cell>0.0249</cell><cell>0.0224</cell><cell>0.0228</cell><cell>0.0233</cell></row><row><cell>std. MAE (% )</cell><cell>1.78</cell><cell>1.37</cell><cell>1.57</cell><cell>1.61</cell><cell>1.89</cell><cell>1.05</cell><cell>1.06</cell><cell>1.02</cell><cell>0.93</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Comparison of mean std. MAEs of ablations that only contain parts of the MXM module. MXMNet cannot achieve the stat-of-the-art performance without any part of the MXM module.</figDesc><table><row><cell cols="2">Ablation</cell><cell>std. MAE std. MAE of MXMNet</cell></row><row><cell>Only Global Layer</cell><cell>One MP operation</cell><cell>116%</cell></row><row><cell>Message Passing</cell><cell>Two MP operations</cell><cell>110%</cell></row><row><cell>Only Local Layer Message Passing</cell><cell>Step 1, 3 Step 2, 3 Step 1, 2, 3</cell><cell>266% 244% 224%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Results of the Pearson correlation coefficient R and MAEs of different models on PDBBind. '-' denotes that the model raises out-of-memory issue.</figDesc><table><row><cell>Model</cell><cell>Pearson R</cell><cell>MAE</cell></row><row><cell>SchNet</cell><cell>0.601±0.037</cell><cell>1.892±0.071</cell></row><row><cell>PhysNet</cell><cell>0.614±0.034</cell><cell>1.881±0.065</cell></row><row><cell>DimeNet</cell><cell>-</cell><cell>-</cell></row><row><cell cols="3">MXMNet 0.664 ± 0.024 1.733 ± 0.089</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4</head><label>4</label><figDesc>, we list the most important hyperparameters used in our experiments.</figDesc><table /><note>1 https://figshare.com/collections/Quantum_chemistry_structures_and_properties_of_134_kilo_molecules/ 9789042 http://deepchem.io.s3-website-us-west-1.amazonaws.com/datasets/pdbbind_v2015.tar.gz3 https://github.com/rusty1s/pytorch_geometric/blob/73cfaf7e09/examples/qm9_schnet.py4 https://github.com/rusty1s/pytorch_geometric/blob/73cfaf7e09/examples/qm9_dimenet.py</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>List of hyperparameters used in our experiments on QM9 and PDBBind.</figDesc><table><row><cell>Hyperparameters</cell><cell cols="2">Value / Range QM9 PDBBind</cell></row><row><cell>Batch Size</cell><cell>32, 128</cell><cell>32</cell></row><row><cell>Hidden Dim.</cell><cell>128</cell><cell>128</cell></row><row><cell>Initial Learning Rate</cell><cell cols="2">1e-3, 1e-4 1e-3, 5e-4</cell></row><row><cell>Number of Layers</cell><cell>6</cell><cell>2, 3</cell></row><row><cell>Max. Number of Epochs</cell><cell>900</cell><cell>250</cell></row><row><cell>Dropout</cell><cell>0</cell><cell>0</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This project has been funded by National Institute of General Medical Sciences (R01GM122845) and National Institute on Aging (R01AD057555) of the National Institute of Health.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The rise of deep learning in drug discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongming</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ola</forename><surname>Engkvist</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Olivecrona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Blaschke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Drug discovery today</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1241" to="1250" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A comprehensive survey on graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zonghan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shirui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengwen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S Yu</forename><surname>Philip</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Convolutional networks on graphs for learning molecular fingerprints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dougal</forename><surname>David K Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorge</forename><surname>Maclaurin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafael</forename><surname>Iparraguirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Bombarell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alán</forename><surname>Hirzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan P</forename><surname>Aspuru-Guzik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2224" to="2232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Molecular graph convolutions: moving beyond fingerprints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Kearnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Mccloskey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Berndl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Pande</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Riley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of computer-aided molecular design</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="595" to="608" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Neural message passing for quantum chemistry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schoenholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Patrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">E</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1263" to="1272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Schnetpack: A deep learning toolbox for atomistic systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pan</forename><surname>Kt Schutt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Kessel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Gastegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Nicoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K-R</forename><surname>Tkatchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Muller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of chemical theory and computation</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="448" to="455" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Physnet: A neural network for predicting energies, forces, dipole moments, and partial charges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Unke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Meuwly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of chemical theory and computation</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3678" to="3693" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Directional message passing for molecular graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Klicpera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janek</forename><surname>Groß</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Heterogeneous molecular graph neural networks for predicting molecule properties</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeren</forename><surname>Shui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Karypis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.12710</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Molecular modeling and simulation: an interdisciplinary guide</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamar</forename><surname>Schlick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Springer Science &amp; Business Media</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">21</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Quantum chemistry structures and properties of 134 kilo molecules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raghunathan</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Pavlo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Dral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O Anatole Von</forename><surname>Rupp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lilienfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific data</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The pdbbind database: Collection of binding affinities for protein-ligand complexes with known three-dimensional structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renxiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueliang</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yipin</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaomeng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of medicinal chemistry</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2977" to="2980" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning convolutional neural networks for graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathias</forename><surname>Niepert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Kutzkov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2014" to="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Quantum-chemical insights from deep tensor neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kristof</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Farhad</forename><surname>Schütt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Arbabzadah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><forename type="middle">R</forename><surname>Chmiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tkatchenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature communications</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Graph networks as a universal machine learning framework for molecules and crystals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weike</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunxing</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shyue Ping</forename><surname>Ong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chemistry of Materials</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="3564" to="3572" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Principled multilayer network embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pin-Yu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sailung</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toyotaro</forename><surname>Suzumura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingli</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Data Mining Workshops (ICDMW)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="134" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Scalable multiplex network embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liwei</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingling</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqiu</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="3082" to="3088" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Modeling relational data with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rianne</forename><surname>Bloem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Semantic Web Conference</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="593" to="607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Representation learning for attributed multiplex heterogeneous network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukuo</forename><surname>Cen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingren</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1358" to="1368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Multi-dimensional graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suhang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chara</forename><forename type="middle">C</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawei</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 SIAM International Conference on Data Mining</title>
		<meeting>the 2019 SIAM International Conference on Data Mining</meeting>
		<imprint>
			<publisher>SIAM</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="657" to="665" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Layer communities in multiplex networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ta-</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chu</forename><surname>Kao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mason A</forename><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Physics</title>
		<imprint>
			<biblScope unit="volume">173</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="1286" to="1302" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Heterogeneous multi-layered network model for omics data integration and analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bohyun</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandar</forename><surname>Poleksic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Genetics</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">1381</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Abstract diagrammatic reasoning with multiplex graph networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateja</forename><surname>Jamnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Lio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">A graph to graphs framework for retrosynthesis prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chence</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minkai</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyu</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.12725</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Geniepath: Graph neural networks with adaptive receptive paths</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziqi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaochao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Longfei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="4424" to="4431" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Spagan: Shortest path graph attention network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiding</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinchao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingli</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsong</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4099" to="4105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sami</forename><surname>Abu-El-Haija</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amol</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nazanin</forename><surname>Alipourfard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Lerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hrayr</forename><surname>Harutyunyan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.00067</idno>
		<title level="m">Greg Ver Steeg, and Aram Galstyan. Mixhop: Higher-order graph convolutional architectures via sparsified neighborhood mixing</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Understanding deep learning requires rethinking generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moritz</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">How powerful are graph neural networks?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keyulu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Cormorant: Covariant molecular neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brandon</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Son</forename><surname>Truong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Risi</forename><surname>Hy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kondor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="14537" to="14546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Molecular property prediction: A multilevel quantum interactions modeling perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqiang</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenya</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peize</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lixin</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1052" to="1060" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Quantum chemistry structures and properties of 134 kilo molecules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raghunathan</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Pavlo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Dral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O Anatole Von</forename><surname>Rupp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lilienfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific data</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Neural message passing for quantum chemistry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schoenholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Patrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">E</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1263" to="1272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Schnetpack: A deep learning toolbox for atomistic systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pan</forename><surname>Kt Schutt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Kessel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Gastegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Nicoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K-R</forename><surname>Tkatchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Muller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of chemical theory and computation</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="448" to="455" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Physnet: A neural network for predicting energies, forces, dipole moments, and partial charges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Unke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Meuwly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of chemical theory and computation</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3678" to="3693" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Graph networks as a universal machine learning framework for molecules and crystals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weike</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunxing</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shyue Ping</forename><surname>Ong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chemistry of Materials</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="3564" to="3572" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Molecular property prediction: A multilevel quantum interactions modeling perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqiang</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenya</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peize</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lixin</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1052" to="1060" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Prediction errors of molecular machine learning models lower than hybrid dft error</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Felix</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Faber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Hutchison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">E</forename><surname>Schoenholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kearnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Patrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O Anatole Von</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lilienfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of chemical theory and computation</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="5255" to="5264" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Directional message passing for molecular graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Klicpera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janek</forename><surname>Groß</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Moleculenet: a benchmark for molecular machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenqin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Ramsundar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><forename type="middle">N</forename><surname>Feinberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caleb</forename><surname>Geniesse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Aneesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Pappu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Leswing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pande</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chemical science</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="513" to="530" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8026" to="8037" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Tensorflow: A system for large-scale machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martín</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th {USENIX} symposium on operating systems design and implementation ({OSDI} 16)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">Eric</forename><surname>Lenssen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.02428</idno>
		<title level="m">Fast graph representation learning with pytorch geometric</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Multilayer feedforward networks are universal approximators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Hornik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxwell</forename><surname>Stinchcombe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Halbert</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural networks</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="359" to="366" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prajit</forename><surname>Ramachandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.05941</idno>
		<title level="m">Searching for activation functions</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Cormorant: Covariant molecular neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brandon</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Son</forename><surname>Truong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Risi</forename><surname>Hy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kondor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="14537" to="14546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Ramsundar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><forename type="middle">N</forename><surname>Feinberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><forename type="middle">S</forename><surname>Pande</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.10603</idno>
		<title level="m">Atomic convolutional networks for predicting protein-ligand binding affinity</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
