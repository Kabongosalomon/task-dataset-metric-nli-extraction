<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multi-Gradient Descent for Multi-Objective Recommender Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Milojković</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Oracle Labs</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Antognini</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">EPFL</orgName>
								<orgName type="institution" key="instit2">LIA</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giancarlo</forename><surname>Bergamin</surname></persName>
							<affiliation key="aff2">
								<address>
									<settlement>Swisscom</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boi</forename><surname>Faltings</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">EPFL</orgName>
								<orgName type="institution" key="instit2">LIA</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudiu</forename><surname>Musat</surname></persName>
							<affiliation key="aff2">
								<address>
									<settlement>Swisscom</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Multi-Gradient Descent for Multi-Objective Recommender Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T09:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recommender systems need to mirror the complexity of the environment they are applied in. The more we know about what might benefit the user, the more objectives the recommender system has. In addition there may be multiple stakeholders -sellers, buyers, shareholders -in addition to legal and ethical constraints. Simultaneously optimizing for a multitude of objectives, correlated and not correlated, having the same scale or not, has proven difficult so far. We introduce a stochastic multi-gradient descent approach to recommender systems (MGDRec) to solve this problem. We show that this exceeds state-of-the-art methods in traditional objective mixtures, like revenue and recall. Not only that, but through gradient normalization we can combine fundamentally different objectives, having diverse scales, into a single coherent framework. We show that uncorrelated objectives, like the proportion of quality products, can be improved alongside accuracy. Through the use of stochasticity, we avoid the pitfalls of calculating full gradients and provide a clear setting for its applicability.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Today, recommender systems are an inevitable part of everyone's daily digital routine. When a person goes online, they are likely going to use one of the services in which recommendation plays an important role. This applies to streaming music, shopping, socializing on social media platforms or viewing a personalized news feed, among many others. The content is tailored to the user during these activities and is selected by the recommender systems. This automated selection of relevant content makes the entire experience of using digital services more comfortable and engaging <ref type="bibr" target="#b4">(Knijnenburg et al., 2012)</ref>. Without this, the user would be lost in the enormous and continuously growing quantity of information, products, or choices.</p><p>To create the best possible user experience -the most useful recommendations, usually, multiple criteria (often conflicting) have to be taken into account. For example, recommending to users the set of K books, always selected from the set of best-selling books, will not give these users an opportunity to pick some, maybe unpopular, but possibly more appealing book <ref type="bibr" target="#b0">(Abdollahpouri et al., 2017)</ref>. Thus, to reduce the popularity bias in this scenario, the additional criteria would be to create not only relevant but also diverse recommendations.</p><p>Regularly the incentives of the service provider are aligned with the satisfaction of the users of their service. However, the provider is also expecting certain benefits from operating the system. For example, one of the objectives of the online retailer might be to increase their profit. Therefore, during the design of such system we also need to take into account the interests of all parties -stakeholders. These may be correlated but they are not necessarily identical and the differences, however subtle, can give rise to tension in converging towards a generally satisfactory solution.</p><p>Both of these, additional criteria and stakeholders, increase the level of complexity with which the designers of the recommender system have to deal. In this paper we present a general multi-objective optimization algorithm which resolves these issues. Unlike <ref type="bibr" target="#b0">(Burke et al., 2018)</ref>, we go beyond listing the types of possible objectives and propose a way to jointly optimize them.</p><p>Multi-objective recommender systems have long been impractical due to the heavy computation cost involved in the joint optimization. Traditional approaches include evolutionary and genetic algorithms <ref type="bibr" target="#b4">(Lin et al., 2018;</ref><ref type="bibr" target="#b4">Lin et al., 2019a;</ref><ref type="bibr" target="#b4">Geng et al., 2015)</ref>. However, these models can only be applied on tiny sets of users and items, which do not scale beyond datasets counting hundreds of samples. This situation does not reflect real use-cases, where we can encounter orders of magnitude more products <ref type="bibr" target="#b4">(Gomez-Uribe and Hunt, 2015)</ref> and, similarly, orders of magnitude more users <ref type="bibr" target="#b5">(Linden et al., 2003)</ref>.</p><p>To alleviate computational issues, other methods optimize each objective sequentially. Generally the accuracy is optimized in a first step such as <ref type="bibr" target="#b3">(Di Noia et al., 2017;</ref><ref type="bibr" target="#b4">Jugovac et al., 2017)</ref>, which leads to an initial ranking of the items for a particular user. In a second step, the items are re-ranked using one or more additional objectives. This shortcoming is more visible in problems where the product space is tightly constrained. When few products are available to choose from, if the objectives are not correlated, the rankings for each objective will be materially different. Too few items that are ranked highly for the first objective will also be good solutions for the remaining ones.</p><p>To obtain the best of both worlds, existing methods employ a weighted average: either in weighting different losses or in weighting different rankings obtained for each criteria. <ref type="bibr" target="#b10">(Ribeiro et al., 2015)</ref> propose a method that combines the output of different algorithms trained for different criteria, and aggregates their ranked lists to provide the final recommendation.</p><p>Finally, multi-gradient descent approaches have been proposed to optimize all objectives simultaneously <ref type="bibr" target="#b4">(Lin et al., 2019b)</ref>, and provides a better weighting aggregation. In (Lin et al., 2019b) multi-gradient descent is shown to work on correlated objectives. There are however doubts with regard to the mixture of varied objectives and also the applicability on non differentiable functions.</p><p>In this work, we address both of these limitations of previous work on multi-objective recommenders based on multigradient descent (MGDRec). We first focus on a traditional setting where the optimization is done for two correlated objectives. On two separate datasets, with data on movies and books, we show that MGDRec can create solutions that approach the theoretical optimum -the combination of the best result that can be obtained for each individual objective.</p><p>We extend this analysis to show that through gradient normalization and specific training procedures we can extend MGDRec to non-correlated objectives. We focused on recommending unpopular items -documentaries in a movie recommender setup -whose proportion in the recommendation set is anticorrelated with recall. Furthermore, we extend the method to non differentiable problems by using the stochastic multi-subgradient descent algorithm (SMSGDA) instead of multi-gradient descent algorithm (MGDA). Unlike previous work -(Lin et al., 2019b), we formalize the use of stochastic optimization and provide a clear setting for its applicability.</p><p>The main contributions of this paper are: • We find a set of solutions to multi-objective recommendation problems combining varied objectives, using multigradient descent. We show that this yields results superior to the state of the art. • We introduce the novel idea of gradient normalization to the multi gradient recommendations. This allows us to combine fundamentally different objectives into the same objective function by using subgradients to relax the differentiability conditions for individual objectives. This flexibility allows us to deal with objectives coming from multiple stakeholders.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Work</head><p>In recent years a lot of effort in recommender systems research is oriented towards improving end-user experience. This led to the increasing interest in objectives other than accuracy, and consequently to various approaches in the design of multi-objective recommender systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Approaches based on Evolutionary Algorithms</head><p>Traditional approaches include evolutionary or genetic algorithms such as Non-dominated Neighbor Immune Algorithm based Recommender System (NNIA-RS) <ref type="bibr" target="#b4">(Geng et al., 2015)</ref>, Probabilistic Multi-Objective Evolutionary Algorithm (PMOEA) <ref type="bibr" target="#b1">(Cui et al., 2017)</ref>, Non-dominated Sorting Genetic Algorithm II (NSGA-II) <ref type="bibr" target="#b2">(Deb et al., 2002)</ref>, Decomposition-based Multi-Objective Evolutionary Algorithm (MOEA/Ds) <ref type="bibr" target="#b4">(Lin et al., 2019a)</ref> or Multi-Objective Evolutionary Algorithm with Extreme Point Guided (MOEA-EPG) <ref type="bibr" target="#b4">(Lin et al., 2018)</ref>. The main disadvantage of this kind of approach is bad scalability. For example, in <ref type="bibr" target="#b4">(Lin et al., 2018)</ref>, the proposed method grows quadratically with the number of users and linearly with the number of items, which leads to a high computational complexity. Therefore, these models can only be applied on tiny sets of users and items, which do not scale beyond datasets counting hundreds of samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Re-Ranking</head><p>To avoid scalability issues, other works proposed a setup where the recommender is optimized for relevance objective, and then the additional objective is being used for reranking. Examples of such methods are Multiple Objective Optimization in Recommendation Systems <ref type="bibr" target="#b11">(Rodriguez et al., 2012)</ref>, the greedy strategies of <ref type="bibr" target="#b3">(Di Noia et al., 2017)</ref> using Maximal Marginal Relevance (MMR) <ref type="bibr" target="#b15">(Vargas and Castells, 2011)</ref>, Explicit Query Aspect Diversification (xQuAD) <ref type="bibr" target="#b15">(Vargas and Castells, 2013)</ref>, or user-interaction based <ref type="bibr" target="#b9">(Pu and Faltings, 2000;</ref><ref type="bibr" target="#b3">Faltings et al., 2004)</ref>, and the post-processing method Personalized Ranking Adaptation (PRA) <ref type="bibr" target="#b4">(Jugovac et al., 2017)</ref>. Also, there is substantial work where the solution is proposed only for a specific objective.</p><p>However, these methods apply re-ranking either 1) in a post-processing manner <ref type="bibr" target="#b4">(Jugovac et al., 2017)</ref> or 2) on the top-n recommended items during the optimization process <ref type="bibr" target="#b3">(Di Noia et al., 2017)</ref>. The former solution leads to suboptimal solutions, because the recommendation has been trained on a single objective without taking into account others. The latter suffers, in addition, from popularity bias <ref type="bibr" target="#b0">(Abdollahpouri et al., 2017)</ref>, as only the most likely items for a user are reordered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Weighted-Sum of Objectives</head><p>The intuitive and seemingly easy solution to scalability and sub-optimal solutions is to transform the multi-objective problem into a single objective problem. This new single objective would be a weighted sum of all objectives. <ref type="bibr" target="#b10">(Ribeiro et al., 2015)</ref> aggregate multiple ranked lists, weights from a graph modeled under a constraint satisfaction problem framework <ref type="bibr" target="#b14">(Torrens and Faltings, 2002)</ref>. (Lin et al., 2019b) use gradient-descent approaches to provide a better weighting aggregation. Nevertheless, gradient-based methods cannot be applied with non differentiable functions. Finally, the main issue with these method is how to pick an optimal set of weights. In real-world problems doing a grid-search to find these weights might be extremely expensive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-Objective Optimization Problem</head><p>A multi-objective optimization problem (MOOP) is an optimization problem in which several possibly conflicting objectives are being optimized simultaneously. It can be defined as follows:</p><formula xml:id="formula_0">min w∈R D L(w) = min w∈R D L 1 (w) L 2 (w) . . . L n (w) n×1<label>(1)</label></formula><p>where n is the number of objectives to optimize, w the model parameters, D the total number of parameter, L i : R D → R, i = 1, . . . , n, L i is a single objective loss function, and L the multi-objective loss function. In case that a gradientbased optimization algorithm is applied, the gradient of every constituent loss function ∇ w L i (w) has to be a Lipschitz continuous function <ref type="bibr" target="#b6">(Murphy, 2013)</ref>. The operator min in Equation 1 represents the operation of minimization of all objectives simultaneously. This is not a limiting factor, because, without loss of generality, any maximization problem can be transformed into a minimization problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pareto Optimal Solution</head><p>Unlike the single-objective optimization problems, in multi-objective optimization problems, in general, there will not exist a unique solution that is better with respect to all objectives. This holds as we cannot make any assumption about the relationship of constituent objectives (whether they are correlated, not correlated, linearly dependent, or independent). Thus, the solution to the MOOP is not a single solution, but a set of solutions; this set of solutions is called Pareto Set. Before formally defining a concept of Pareto Optimal solution, we first define the concept of Pareto Dominance.</p><p>Definition 1: A solution w * dominates solution w if for all objectives L i (w * ) ≤ L i (w), i = 1, ..., n and at least for one objective L j (w * ) &lt; L j (w), j = 1, ..., n.</p><p>Definition 2: A solution w * is Pareto Optimal if it is not dominated by any other solution w.</p><p>Definition 3: The set of all non-dominated solutions is called Pareto Set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Types of Objectives</head><p>One of the fundamental goals of recommender systems is to create relevant recommendations. Naturally, there is no use in recommending irrelevant items. However, in realworld applications, there are other objectives that we need to satisfy besides relevance: "Good businesses pay attention to what their customers have to say. But what customers ask for and what actually works are very different." <ref type="bibr" target="#b4">(Gomez-Uribe and Hunt, 2015)</ref>. In this section, we describe different types of objectives that occurs in recommender systems domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Semantic Relevance</head><p>Semantic relevance, relevance, accuracy, correctness, all of these are different names denoting the same goal of recommending a just-right item to the end-user. In other words, the goal is to recommend an item or a set of items which the end-user is most probably going to like. A tremendous amount of time and effort are spent both in research and industry towards creating new recommender systems that are better than the state-of-the-art with respect to accuracy. Definitely, this is the most important objective in every recommender system. However, it is not the only one we should care about, because the end-user satisfaction is not always correlated to the relevance <ref type="bibr" target="#b5">(McNee et al., 2006)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Correlated to Semantic Relevance</head><p>This class of objectives are correlated to the semantic relevance objective. For example, it is not possible to have a Revenue bigger than zero if you recommend just irrelevant items. Thus, the Revenue is the example of an objective that is correlated with the semantic relevance objective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Not Correlated to Semantic Relevance</head><p>Finally, this type of objectives is those that are not correlated to the semantic relevance objective. Contrary to the correlated objectives, here we may have a perfectly fair recommendations (if Fairness is, for example, an additional objective), and yet these recommendations can be completely irrelevant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Optimization Algorithm</head><p>To solve the multi-objective optimization problem we will use a gradient-based optimization algorithm. Before presenting the algorithm, we introduce the Common Descent Vectors and present the conditions of optimality for gradient-based solutions in MOOP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Common Descent Vector</head><p>A common descent vector is a convex combination of gradients of each objective. It can be defined as follows <ref type="bibr">(Désidéri, 2012)</ref>:</p><formula xml:id="formula_1">∇ w L(w) = n i=1 α i ∇ w L i (w)<label>(2)</label></formula><p>where n is number of objectives, w the model parameters, ∇ w L(w) the common descent vector, ∇ w L i (w) the gradient of the objective function i, α i weight of the i th gradient. Equation 2 satisfies the following conditions:</p><formula xml:id="formula_2">1. α 1 , . . . , α n ≥ 0 2. n i=1 α i = 1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Optimality Conditions</head><p>In a deterministic multi-objective gradient-based optimization, the necessary conditions for a solution to be optimal are the Karush-Kuhn-Tucker (KKT) conditions. Every solution that satisfies these conditions are called Pareto Stationary (Désidéri, 2012).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 4:</head><p>A solution w is said to be Pareto Stationary if there exists α 1 , ..., α n such that:</p><formula xml:id="formula_3">1. α 1 , ..., α n ≥ 0 2. n i=1 α i = 1 3. n i=1 α i ∇ w L i (w) = 0</formula><p>However, the Pareto Stationarity is only the necessary condition of optimality, but not sufficient. The explanation for this can be found if we start from the single objective case: in a single-objective optimization zero gradient is only a necessary condition. It extends to multi-objective problem where the convex combination of gradients is zero, which is just a necessary condition of optimality, but not sufficient.</p><p>Definition 5: Every Pareto optimal solution has to be Pareto stationary, but not every Pareto stationary solution is Pareto optimal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-Gradient Descent Algorithm (MGDA)</head><p>The Multi-Gradient Descent Algorithm (MGDA) is an extension of the classical Gradient Descent Algorithm to multiple objectives. This algorithm is proved to converge to the Pareto Stationary solution <ref type="bibr">(Désidéri, 2012)</ref>.</p><p>In <ref type="bibr">(Désidéri, 2012)</ref>, the author defines the common descent vector as a minimum L2 norm element in the convex hull of the gradients of each objective. Considering this definition, finding the weights in common descent vector can be formulated as the Quadratic Constrained Optimization Problem (QCOP) <ref type="bibr">(Désidéri, 2012)</ref>.</p><p>The QCOP is defined as follows:</p><formula xml:id="formula_4">min α1,...,αn    n i=1 α i ∇ w L i (w) 2 | n i=1 α i = 1, α i ≥ 0   <label>(3)</label></formula><p>After solving QCOP, the common descent vector can be calculated and based on that value, and we either have that: • ∇ w L(w) = 0, the solution is Pareto Stationary; • ∇ w L(w) = 0, the solution is not Pareto Stationary and ∇ w L(w) is the common descent vector for all objectives.</p><p>Based on the number of objectives, there are two different ways of how QCOP can be solved: with an analytical solution for two objectives or with a constrained optimization problem for more objectives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Two Objectives</head><p>In case of two objectives the QCOP can be defined as:</p><formula xml:id="formula_5">min α∈[0,1] α * ∇ w L 1 (w) + (1 − α) * ∇ w L 2 (w) 2<label>(4)</label></formula><p>Then, there is an analytical solution to this problem:</p><formula xml:id="formula_6">α = (∇ w L 2 (w) − ∇ w L 1 (w)) T * ∇ w L 2 (w) ∇ w L 1 (w) − ∇ w L 2 (w) 2<label>(5)</label></formula><p>where α is clipped to [0, 1].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multiple Objectives</head><p>In case of more than two objectives, we cannot compute an exact solution and have to frame the method under a constrained optimization framework. The efficient solution that scales nicely to the high-dimensional problems is proposed in <ref type="bibr" target="#b11">(Sener and Koltun, 2018)</ref>. The proposed solution is based on Frank-Wolfe constrained optimization algorithm <ref type="bibr" target="#b3">(Frank and Wolfe, 1956)</ref>. In the experiments presented in this paper, the Frank-Wolfe solver is efficient and has excellent convergence properties. Hence, the impact on performance (training time) is insignificant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stochastic Multi-Subgradient Descent Algorithm (SMSGDA)</head><p>Unfortunately, Multi-Gradient Descent Algorithm suffers from multiple drawbacks:</p><p>1. Calculating full gradient at every optimization step is computationally expensive;</p><p>2. As a deterministic optimization algorithm, it can quickly become stuck at a bad Pareto stationary point; the same way as a full gradient descent algorithm can quickly become stuck at the bad local minimum;</p><p>3. The requirement of calculating gradient for the objective function restricts from using non-smooth loss functions as objective functions (e.g. Mean Absolute Error (MAE)).</p><p>These drawbacks limits MGDA from usage in many realworld problems. <ref type="bibr" target="#b8">(Poirion et al., 2017)</ref> propose an extension of MGDA to address its limitation, called Stochastic Multi-Subgradient Descent Algorithm (SMSGDA).</p><p>The stochasticity in SMSGDA: addresses both computational cost and decreases the probability of being stuck at a bad Pareto stationary point. However, given that we do not calculate full gradient anymore, we are not able to satisfy the third KKT condition in Definition 4: n i=1 α i ∇ w L i (w) = 0. Therefore, we cannot choose the same stopping criteria anymore. Nevertheless, we can use some of the criteria that are regularly used in stochastic optimization problems. For example, we could stop the optimization process if:</p><p>• a number of epochs has been reached;</p><p>• the loss of the common descent vector L(w) is plateauing;</p><p>• the gradient norm is less than .</p><p>In <ref type="bibr" target="#b8">(Poirion et al., 2017)</ref>, the authors prove that SMSGDA almost surely converges if non-smooth loss functions are used as objective functions. This alleviates the third drawback of MGDA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gradient Normalization</head><p>When designing recommender systems, we face with various objectives (as described in the Section ). Additionally, these objectives might have values of the different scales. Both MGDA and SMSGDA are sensitive to different value ranges in objective functions; the gradients would have significantly different norms, leading to the case that one objective completely dominates the whole optimization process.</p><p>To alleviate the value range in the multiple objective functions, we propose the following gradient normalization method:∇</p><formula xml:id="formula_7">w L i (w) = ∇ w L i (w) L i (w init )<label>(6)</label></formula><p>where∇ w L i (w) is the normalized gradient vector of a single constituent objective, ∇ w L i (w) the non-normalized gradient vector of a single constituent objective, L i (w init ) the initial loss for the particular objective, w the model parameters, and w init the initial parameters of the model. We consider L i (w init ) to be an empirical maximum loss for the particular objective. Consequently, the proposed normalization should have the same effect as having an objective loss function that is almost always in the domain L i (w) ∈ [0, 1].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Solution selection</head><p>Selecting a Pareto Optimal solution from a Pareto Set is not a trivial task as there is not solution strictly dominating other solutions. However, as a remedy to this problem, there exist several strategies for this task. An overview of the strategies to pick the best solution from a Pareto Set are detailed in <ref type="bibr" target="#b15">(Wang and Rangaiah, 2017)</ref>. In this paper, we employ the Linear Programming Technique for Multidimensional Analysis of Preference (LINMAP); LINMAP selects an optimal solution based on the Euclidean distance from the ideal point, selecting the solution with the shortest distance <ref type="bibr" target="#b13">(Srinivasan and Shocker, 1973)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments Datasets</head><p>In order to assess the effectiveness of our proposed model, we first carried out experiments on the well-known Movielens 20M dataset 1 , and on the Amazon Books dataset <ref type="bibr" target="#b5">(McAuley and Leskovec, 2013)</ref>. The second dataset contains multiple target variables that could be used in a multiobjective task. However, the first only includes ratings. We enriched the first dataset by mapping the movies to the Amazon Movies dataset <ref type="bibr" target="#b5">(McAuley and Leskovec, 2013)</ref>, and then extracting the prices. Finally, the target variables are ratings, prices and genres for the Movielens dataset, and ratings and prices for the Amazon Books.</p><p>For both datasets, we employed the same preprocessing procedure: we first binarized 5-star rating (i.e. ratings at three and above are labeled as positive and the rest as negative); users and items were then filtered to those with at least 5 ratings. A summary of the data we used is shown in Table 1. Finally, we divided the data into training, validation, test sets corresponding to a split of 90%, 5%, 5% respectively. Additionnally, we masked out 20% of the items for the validation and test sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Objectives</head><p>In our experiments we focused on two completely different combinations of objectives, the first one was a combination of semantic relevance and revenue, while the second one was a combination of semantic relevance and content quality.  To assess the performance of our model for the semantic relevance objective we use the Recall@k metric to measure the ratio of relevant items that are in the top-k recommendations.</p><formula xml:id="formula_8">Recall@k(u, ω) := k r=1 I[ω(r) ∈ I u ] min(k, |I u |)<label>(7)</label></formula><p>where ω(r) denotes the item at rank r, I u is the set of held-out items that user u interacted with and I[·] is the indicator function. The denominator is the minimum of k and the size of the held-out set I u <ref type="figure">(Liang et al., 2018)</ref>.</p><p>The main goal behind the revenue objective is more or less self explanatory: it is a revenue maximization. The metric we use to measure the performance for this objective is Revenue@k. That one is a natural extension of the Recall@k metric; the added component here is the price of a particular item. More precisely, we compute the mean revenue of the top-k relevant recommended items.</p><formula xml:id="formula_9">Revenue@k(u, ω, p) := k r=1 p(r) * I[ω(r) ∈ I u ] min(k, |I u |)<label>(8)</label></formula><p>where p(r) is the price of the item at rank r. Finally, the last objective in our experiments is something that we call content quality. For this one, it is almost impossible to find an universally accepted definition. However, in this context, we refer to content quality as to an objective in which the goal is to increase the amount of "content that matters" in the top-k recommendations. The main motivation for choosing that objective is due to the phenomenon known under the name of "Filter Bubble" <ref type="bibr" target="#b7">(Nguyen et al., 2014)</ref>. The impact of Filter Bubbles on end-users is that it limits their ability to explore and perceive different content. Who, as a consequence, has a skewed image of the environment. Tackling such a problem requires a lot of effort and interdisciplinary research. However, as a small step forward, we decided to explore the possibility of recommending the "content that matters". Once again, selecting that kind of content is beyond our knowledge. Thus, we decided to name the documentary genre as "content that matters" (i.e. content quality). Our goal here was to increase the number of documentaries inside the top-k recommendations, which was at the same time also the metric we used for this objective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental setup</head><p>The approach we propose in this paper is model-agnostic. Therefore the designer of the recommender system has full flexibility in choosing what model he wants to use. For our experiments, we decided to use the Multi-VAE model proposed in <ref type="bibr" target="#b4">(Liang et al., 2018)</ref>. The architecture of our model is identical to the one in that paper. The loss function we use for semantic relevance objective is also unchanged.</p><p>For the revenue objective we weight the reconstruction loss of the VAE with a price vector which contains the individual prices of each item.</p><formula xml:id="formula_10">L revenue (w) = price * L reconstruction (w)<label>(9)</label></formula><p>The intuition behind this loss function is that we want to penalize our model based on the item price. In other words, we want to penalize errors on expensive items more severely. The loss function for the quality content objective we define as follows:</p><p>L content (w) = I doc * popularity * L reconstruction (w) <ref type="formula" target="#formula_0">(10)</ref> where I doc is an indicator vector that signals if an item is a documentary or not and popularity is the vector of the popularity of each item (e.g. a count of how many users have interacted with an item). Here we want to penalize our recommender more for making mistakes on documentaries, especially on the ones that are more popular.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training Procedure</head><p>The training of the model differs slightly between objectives correlated to semantic relevance and objectives not correlated to semantic relevance.</p><p>The training procedure starts by computing the initial loss of the model for all objectives. We consider these losses to be the empirical maximum losses. Following this step, we train our model by computing the gradients of all objectives over the individual batches of the training set, we normalize them by the empirical maximum losses and compute the α parameters as described in Equation 5. We then use these α parameters to compute the common descent vector illustrated in Equation 4. And finally, we update the parameters of the model. Algorithm 1 shows the training procedure in pseudo code.</p><p>Algorithm 1 SMSGDA with Gradient Normalization 1: initialize() 2: for i ∈ 1, ..., n do 3: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>19: end for</head><p>Additional steps we do for the combination of semantic relevance with the non-correlated objectives are that we do not start from the randomly initialized model, but as a starting point, we select the model which was optimized for semantic relevance only. Moreover, in order to nudge the model to learn to recommend items from non-correlated distribution, we inject additional information in end-user preferences. In other words, for the content quality objective, we injected a small positive values for selected content in enduser preference vectors (these values sums up to 1). While this amount is effective for the model to learn the chosen representation, it is not too large to degrade the performance of semantic relevance. Finally, in order to prevent the model from learning immediately to recommend quality content only, the values of α parameters should be constrained. <ref type="figure">Figure 1</ref> shows the results for the Movielens dataset enriched with price information from the Amazon Movies dataset. MGD with gradient normalization yields the best results in regard to the solution selection we described above. <ref type="figure">Figure 2</ref> shows a similar result with MDG with gradient normalization outperforming the other approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>To assess how well our algorithm performs we compare it to the other well-known approaches to this problem. As a baseline we use the closest solution to the presented one which was proposed by <ref type="bibr" target="#b11">(Rodriguez et al., 2012)</ref> (baseline), which is a solution based on re-ranking. In addition we compare our algorithm also to a simple weighted-sum of objectives in versions with and without gradient normalization ("WS w/ GN" and "WS w/o GN"). Finally, we compare it also to the models optimized for the single objectives only ("SRO" for semantic relevance only and "RO" for revenue only).</p><p>Both <ref type="figure">Figures 1 and 2 also</ref> show that pure MGD without gradient normalization does not perform well, yielding results comparable to the results of the single objective optimization for semantic relevance. As shown in <ref type="figure">Figure 2</ref> the results of the approaches with gradient normalization outperform the results of the single objective for revenue on the Revenue@k metric. Note that the weighted sum approach also performed significantly better with gradient normalization than without it. This confirms that gradient normalization plays a vital part in increasing the performance of multi objective optimization algorithms. <ref type="figure" target="#fig_2">Figure 3</ref> shows the results of the experiment with the two objectives semantic relevance and content quality. In this experiment we considered movies belonging to the genre "documentaries" as quality content. The MGD with gradient normalization dominated the other approaches as well. Interestingly, this approach outperformed also the single objective semantic relevance algorithm on this very objective itself. This may be due to additional regularization provided by the quality content objective.</p><p>This result shows that for the cost of a small decrease in semantic relevance we can increase the amount of "quality content" in our recommendations drastically. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>The need to optimize for different objectives simultaneously in a recommender system setting is a well recognized problem. While tackling correlated objectives has received more attention previously, it is important for new methods to extend the reach of recommenders to uncorrelated objectives. The optimization problem is more complex when the objectives cease to be correlated or are inversely correlated. In ad- dition, the various objectives may have different scales and may not be differentiable. For these cases, which are actually the norm and stand for real-world concepts like fairness, diversity or revenue, there is a need for novel methods.</p><p>In this work we have shown that multi-gradient descent is applicable in this difficult environment. We first tested in a more traditional setup and showed that revenue and recall can be jointly optimized. In two separate experiments, targeting books and movies, we showed that recommenders based on multi-gradient descent (MGDRec) become the new state of the art. We then show that completely uncorrelated objectives, like the proportion of a certain type of contentfor instance quality or unpopular products -can just as easily be brought into the mix.</p><p>We solve the problem of the differences of scale between the objectives using normalization techniques -a novelty that is key for getting the state of the art results. Results show that using the gradient normalization leads to solutions that are the closest to the theoretical optimum -the intersection of the best possible value for each objective taken individually.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>empirical lossi = Li(w) 4: end for 5: for epoch ∈ 1, ..., M do 6: for batch ∈ 1, ..., B do .., αn = QCOPSolver ∇wL1(w), ..., ∇wLn(w) 16: ∇wL(w) = n i=1 αi∇wLi(w) 17: w = w − η∇wL(w) 18: end for</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :Figure 2 :</head><label>12</label><figDesc>Results for two objectives: semantic relevance and revenue, on Movielens dataset combined with Amazon Movies dataset. Results for two objectives: semantic relevance and revenue, on Amazon Books dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Results for experiments with two objectives semantic: semantic relevance and content quality, on the Movielens dataset combined with Amazon Movies dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Dataset statistics (number of users; number of items; number of user-item interactions; sparsity).</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Balanced neighborhoods for multi-sided fairness in recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>References</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Abdollahpouri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh ACM Conference on Recommender Systems</title>
		<meeting>the Eleventh ACM Conference on Recommender Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="202" to="214" />
		</imprint>
	</monogr>
	<note>Conference on Fairness, Accountability and Transparency</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A novel multi-objective evolutionary algorithm for recommendation systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Cui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Parallel and Distributed Computing</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page" from="53" to="63" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Multiple-gradient descent algorithm (MGDA) for multiobjective optimization / Algorithme de descenteà gradients multiples pour l&apos;optimisation multiobjectif</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Deb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comptes Rendus Mathématique</title>
		<editor>Désidéri, 2012] Désidéri, J.-A.</editor>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="313" to="318" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
	<note>Trans. Evol. Comp. Fascicule 5-6</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Adaptive multi-attribute diversity for recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Di Noia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Intelligence</title>
		<imprint>
			<biblScope unit="volume">382</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="95" to="110" />
			<date type="published" when="1956" />
			<publisher>Frank and Wolfe</publisher>
		</imprint>
	</monogr>
	<note>An algorithm for quadratic programming. Naval research logistics quarterly, 3(1-2</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Evolutionary search with multiple utopian reference points in decomposition-based multiobjective optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Geng</surname></persName>
		</author>
		<idno>13:1-13:19</idno>
	</analytic>
	<monogr>
		<title level="m">Nnia-rs: A multi-objective optimization based recommender system. Physica A: Statistical Mechanics and its Applications</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">424</biblScope>
			<biblScope unit="page" from="20" to="28" />
		</imprint>
	</monogr>
	<note>Proceedings of the 13th ACM Conference on Recommender Systems, RecSys &apos;19</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Hidden factors and hidden topics: understanding rating dimensions with review text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Linden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th ACM conference on Recommender systems</title>
		<meeting>the 7th ACM conference on Recommender systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1097" to="1101" />
		</imprint>
	</monogr>
	<note>Being accurate is not enough: How accuracy metrics have hurt recommender systems</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Machine learning : a probabilistic perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">P</forename><surname>Murphy ; Murphy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, Mass</pubPlace>
		</imprint>
	</monogr>
	<note>u.a.</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Exploring the filter bubble: the effect of using recommender systems on content diversity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd international conference on World wide web</title>
		<meeting>the 23rd international conference on World wide web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="677" to="686" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Descent algorithm for nonsmooth stochastic multiobjective optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Poirion</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Optimization and Applications</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="317" to="331" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Enriching buyers&apos; experiences: the smartclient approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Faltings</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Confernce on Human Factors in Computing Systems (CHI)</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="289" to="296" />
		</imprint>
	</monogr>
	<note>Pu and Faltings</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Multiobjective pareto-efficient approaches for recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Ribeiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Intelligent Systems and Technology</title>
		<imprint>
			<date type="published" when="2015" />
			<publisher>TIST</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multiple objective optimization in recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Rodriguez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth ACM Conference on Recommender Systems, RecSys &apos;12</title>
		<meeting>the Sixth ACM Conference on Recommender Systems, RecSys &apos;12</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="11" to="18" />
		</imprint>
	</monogr>
	<note>Sener and Koltun</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
		<title level="m">Advances in Neural Information Processing Systems 31</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<biblScope unit="page" from="527" to="538" />
		</imprint>
	</monogr>
	<note>Multi-task learning as multi-objective optimization</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Linear programming techniques for multidimensional analysis of preferences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Shocker ; Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Shocker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="337" to="369" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Using soft csps for approximating pareto-optimal solution sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Torrens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Faltings</surname></persName>
		</author>
		<idno>WS-02- 13</idno>
	</analytic>
	<monogr>
		<title level="m">AAAI Workshop on Preferences in Constraint Satisfaction</title>
		<editor>Junker, U.</editor>
		<imprint>
			<publisher>AAAI</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="99" to="106" />
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Application and analysis of methods for selecting an optimal solution from the pareto-optimal front obtained by multiobjective optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Castells ;</forename><surname>Vargas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vargas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Castells</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vargas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Castells</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">P</forename><surname>Rangaiah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th conference on open research areas in information retrieval</title>
		<meeting>the 10th conference on open research areas in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="560" to="574" />
		</imprint>
	</monogr>
	<note>Rank and relevance in novelty and diversity metrics for recommender systems</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
