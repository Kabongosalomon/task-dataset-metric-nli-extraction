<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning Smooth Representation for Unsupervised Domain Adaptation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guanyu</forename><surname>Cai</surname></persName>
							<email>caiguanyu@tongji.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tongji University Shanghai</orgName>
								<address>
									<postCode>201804</postCode>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqin</forename><surname>Wang</surname></persName>
							<email>wangyuqin@tongji.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tongji University Shanghai</orgName>
								<address>
									<postCode>201804</postCode>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lianghua</forename><surname>He</surname></persName>
							<email>helianghua@tongji.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tongji University Shanghai</orgName>
								<address>
									<postCode>201804</postCode>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Learning Smooth Representation for Unsupervised Domain Adaptation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T20:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In unsupervised domain adaptation, existing methods have achieved remarkable performance, but few pay attention to the Lipschitz constraint. It has been studied that not just reducing the divergence between distributions, but the satisfaction of Lipschitz continuity guarantees an error bound for the target distribution. In this paper, we adopt this principle and extend it to a deep end-to-end model. We define a formula named local smooth discrepancy to measure the Lipschitzness for target distribution in a pointwise way. Further, several critical factors affecting the error bound are taken into account in our proposed optimization strategy to ensure the effectiveness and stability. Empirical evidence shows that the proposed method is comparable or superior to the state-of-the-art methods and our modifications are important for the validity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>of the digits classification experiment are shown in Table 1. We compare our three SRDA models, namely SRDA(FGSM), SRDA(VAT) and SRDA(RAN), with other state-of-the-art UDA algorithms such as DAN [25], DANN [12], DSN [5], ADDA [42], CoGAN [24], ATDA [36], ASSC [17], DRCN [13] and MCD [37]</p><p>. Among all four tasks, SRDA ranks first in three of them. Especially in USPS→MNIST which is the most difficult task, our three models are the top three. Only MCD is comparable to them and other methods are inferior to ours with a large margin. In SVHN→MNIST and MNIST→USPS, SRDA (RAN) ranks first. In SYNSIG→GTSRB, our mod-</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The performance of various computer vision problems has been significantly improved with the development of deep convolutional neural networks (CNN) <ref type="bibr">[21]</ref>. However, a precondition of this improvement is that numerous labeled samples are needed and test samples are drawn from the same distribution with training ones. Once there exists a dataset shift between the training and test samples, the performance of a CNN model decreases dramatically <ref type="bibr">[2,</ref><ref type="bibr">11]</ref>. In order to tackle this problem, unsupervised domain adaptation (UDA) transfers knowledge from a labeled source domain to an unlabeled target domain.</p><p>A bunch of classical UDA methods is to match moments of features in the source and target domains. They regard moments of a distribution as the main characteristics <ref type="bibr">[43,</ref><ref type="bibr">41,</ref><ref type="bibr">25]</ref>. By matching moments, they hope to match distributions of different domains. Other kinds of remarkable UDA methods are based on adversarial training strategy. <ref type="bibr">[12]</ref> first introduces a domain classifier to make distributions of distinct domains matching. <ref type="bibr">[24,</ref><ref type="bibr">4]</ref> also propose methods that are effective based on such a principle. In summary, these methods follow a standard schema where they first estimate the divergence between different distributions and then seek an appropriate optimization strategy to minimize it. This schema is proposed in <ref type="bibr">[2]</ref>, and the most remarkable UDA methods are established on it.</p><p>However, this typical schema is limited by two issues. Various divergence estimations indeed capture characteristics of distributions, whereas it is impossible to obtain complete information. Many estimations are proposed <ref type="bibr">[2,</ref><ref type="bibr">43,</ref><ref type="bibr">41,</ref><ref type="bibr">25]</ref>, but none of them is proved to be the most effective one. Furthermore, it is sophisticated to design an optimization strategy to minimize divergence. Direct minimization strategy <ref type="bibr">[43,</ref><ref type="bibr">41,</ref><ref type="bibr">25]</ref> shows poor performance while adversarial training is unstable because of the gradient vanishing problem <ref type="bibr">[7,</ref><ref type="bibr">1]</ref>.</p><p>Another schema proposed in <ref type="bibr">[3]</ref> introduces a basic UDA error bounded by probabilistic Lipschitzness. It inspires us to tackle UDA problem by strengthening Lipschitz continuity in the target distribution with numerous low-quality samples. <ref type="bibr">[38,</ref><ref type="bibr">29]</ref> adopt this principle and propose effective methods. However, these methods still involve typical schema and regard Lipschitz constraint as a regularization term. The reserved adversarial training procedure tends to cause performance drop because of its instability. Moreover, there are several essential factors discussed in <ref type="bibr">[3]</ref>, such as the dimension of samples and batchsize, ignored by previous work which easily lead to a collapsed model.</p><p>In this paper, we further extend the probabilistic Lipschitz constraint by proposing a more concise way to achieve Lipschitz continuity in the target distribution through a newly defined formula, with deep end-to-end networks. An optimization strategy that takes factors analyzed in <ref type="bibr">[3]</ref> into consideration is established to enable our model efficient and stable. In particular, our model contains a feature generator and classifier. The classifier tries to classify source samples correctly and detect sensitive target samples that break down the Lipschitz constraint. The feature generator is trained to strengthen the Lipschitzness of these sensitive samples. To measure the Lipschitzness for target distribution in a pointwise way, we define a formula named local smooth discrepancy. Two specific computing methods are introduced. Utilizing local smooth discrepancy, we propose a detailed optimization strategy to tackle the UDA problem which considers the effects of the dimension and batchsize of samples on the basic error bound.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Realted Work</head><p>A theoretical work proposed in <ref type="bibr">[2]</ref> confirms that a discrepancy between the source and target distributions causes a model invalid in the target domain. Because the distribution of a domain is difficult to illustrate, intuitive thought is to match moments of distributions instead. <ref type="bibr">[25]</ref> matches expectations of features. <ref type="bibr">[41]</ref> takes the covariance of features into consideration. Moreover, <ref type="bibr">[43]</ref> utilizes high-order moments to align distributions of different domains. These methods perform well in numerous settings.</p><p>As <ref type="bibr">DANN [12]</ref> proposed, methods based on adversarial training become popular gradually. These methods introduce a domain classifier to predict which domain a sample is drawn from. At the same time, a feature generator is trained to fool the domain classifier so that features from different domains are matched. <ref type="bibr">[42]</ref> follows this philosophy and implements adversarial training in feature space. Several methods implement adversarial training in pixel level <ref type="bibr">[32,</ref><ref type="bibr">4,</ref><ref type="bibr">24]</ref>. These methods try to generate target images from labeled source images. In this way, a classification model is able to be trained with labeled target images. Specifically, <ref type="bibr">PixelDA [4]</ref> follows the training strategy of generative adversarial networks (GANs) and obtains excellent performance on digits datasets. <ref type="bibr">[32,</ref><ref type="bibr">24]</ref> introduce training strategy similar to cycle GAN to improve their performance.</p><p>Besides taking marginal distribution into consideration, several methods utilize category-discriminative information <ref type="bibr">[8,</ref><ref type="bibr">10,</ref><ref type="bibr">9]</ref>. JAN <ref type="bibr">[28]</ref> modifies <ref type="bibr">DAN [25]</ref> to match joint distributions. CADA <ref type="bibr">[26]</ref> subtly changes the training strategy of <ref type="bibr">DANN [12]</ref> and achieves remarkable results. ATDA <ref type="bibr">[36]</ref> adds two auxiliary classifiers to assist in generating valid pseudo labels for target samples. It constructs decision boundaries for target domain in two different views. Moreover, <ref type="bibr">MCD [37]</ref> gives us a concise explanation of why matching marginal distributions still causes misclassification. It also proposes a siamese-like network and adversarial training strategy to solve the UDA problem. <ref type="bibr">MCD [37]</ref> is comparable or superior to the existing methods on several benchmark domain adaptation datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Preliminary</head><p>In this section, we give a brief description of UDA and define several properties relevant to practical learning challenges. Moreover, a basic UDA error bound is derived from these properties [3] 1 .</p><p>Let (χ, µ) be some domain set where µ : χ 2 → R + is a divergence metric over χ. In UDA setup, we denote P S and P T the source and target distributions, respectively. The marginal distributions of P S and P T over χ are denoted by D S and D T and their labeling rules are denoted by l s : χ → [0, 1] and l t : χ → [0, 1]. The goal is to learn a function f : χ → {0, 1} which predicts correct labels for samples in χ with respect to P T over (χ × {0, 1}). For any hypothesis h : χ → {0, 1}, we define the error with respect to P T by Err P T (h) = P r (x,y)∼P T (y = h(x)). Thus, the Bayes optimal error for P T is opt(P T ) := min h∈{0,1} χ Err P T (h).</p><p>Besides basic notations, in the context of realistic UDA problems, there are some properties expressing either some relationship between the source and target distributions or conditions of these distributions that facilitate learning <ref type="bibr">[3]</ref>.</p><p>Definition 1 (Covariate shift) Source and target distributions satisfy the covariate shift property if they have the same labeling rule, i.e. l s (x) = l t (x) <ref type="bibr">[40]</ref>.</p><p>The common labeling function is denoted as l = l s = l t . While this property seems to make UDA easy, the fact is that it is a rather weak assumption where a UDA learner has no idea how the common labeling rule behaves outside the scope of labeled source samples.</p><formula xml:id="formula_0">Definition 2 (Probabilistic Lipschitzness) Let Φ : R → [0, 1]. f : χ → R is Φ-Lipschitz w.r.t. a distribution D over χ if, for all λ &gt; 0: P r x∼D [∃y : |f (x) − f (y)| &gt; λµ(x, y)] ≤ Φ(λ)<label>(1)</label></formula><p>This definition generalize the standard λ-Lipschitz property where a function f : χ → R holds |f (x)−f (y)| ≤ λµ(x, y) for all x, y ∈ χ. It may be viewed as a formalization of cluster assumption which is widely adopted in semi-supervised learning <ref type="bibr">[30]</ref>. This assumption introduces an additional regularization that decision boundaries not go through the high-density regions are preferred.</p><p>Definition 3 (Weight ratio) Let B ⊆ 2 χ be a collection of subsets of χ measurable with respect to both D S and D T . For some η &gt; 0 we define the η-weight ratio of the source and target distributions with respect to B as</p><formula xml:id="formula_1">R B,η (D S , D T ) = inf b∈B D T (b)≥η D S (b) D T (b) ,<label>(2)</label></formula><p>Further, the weight ratio of the source and target distributions with respect to B is defined as</p><formula xml:id="formula_2">R B (D S , D T ) = inf b∈B D T (b) =0 D S (b) D T (b) ,<label>(3)</label></formula><p>We denote the weight ratio with respect to the collection of all sets that are D S − and D T − measurable by R(D S , D T ). A basic observation about UDA is that it may be infeasible when D S and D T are supported on disjoint domain regions. To guard against such scenarios, it is common to assume R(D S , D T ) &gt; 0.</p><p>According to definition 1, 2 and 3, [3] derives an upper error bound for general UDA learning based on the Nearest Neighbor algorithm. Note that χ should be a fixeddimension space and B should be of finite VC-dimension such that the η-weight ratio can be estimated from finite samples <ref type="bibr">[3]</ref>. In detail, we assume the domain is the unit cube χ = [0, 1] d . B denotes the set of axis aligned rectangles in [0, 1] d and, given some γ &gt; 0, let B γ the class of axis aligned rectangles with sidelength γ.</p><p>Given a labeled sample batch S ⊆ (χ × {0, 1}), and S χ denotes samples without labels of S. For any sample x ∈ S χ , l S (x) denotes the label of x in S (using the majority of their labels) and N S (x) denotes the nearest neighbor to</p><formula xml:id="formula_3">x in S, N S (x) = arg min z∈Sχ µ(x, z). h N N is defined by h N N (x) = l S (N S (x)) for all x ∈ χ.</formula><p>Theorem 1 For some domain χ = [0, 1] d , some R &gt; 0 and γ &gt; 0, let W be a class of pairs (P S , P T ) of source and target distributions over (χ × {0, 1}) satisfying the covariate shift assumption, with R Bγ (D S , D T ) ≥ R, and their common labeling function l : χ → {0, 1} satisfying the Φ-probabilistic-Lipschitz property w.r.t the target distribution, for some function Φ. Then, for all m, and all (P S , P T ) ∈ W,</p><formula xml:id="formula_4">E S∼P m S [Err P T (h N N )] ≤ 2opt(P T ) + Φ(γ) + 4γ √ d Rm 1 d+1 (4)</formula><p>where m denotes the size of S containing points sampled i.i.d. from χ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Learning Smooth Representation</head><p>In theorem 1, the error of general UDA learning is bounded by three terms. First, opt(P T ) refers to the Bayes optimal error for P T . It is an ideal value discussed in the theoretical analysis which is impossible to obtain in practical settings. Therefore, we focus on the other two terms in this paper. Second, Φ(λ) refers to the degree of how target samples satisfying the probabilistic Lipschitzness. Because ES∼P m S [Err P T (h N N )] is positively related to Φ(λ), our goal is to decrease Φ(λ), in other words, strenghthen probabolistic-Lipschitz property with respect to the target distribution. Finally, the last term is relevant to multiple factors, for example, the lower bound R for the weight ratio of source and target distributions, the dimension of domain χ and the size of S. Note that the weight ratio R Bγ (D S , D T ) is predetermined for a specific pair (P S , P T ). Therefore, it is impracticable to optimize its lower bound R. To achieve a tighter error bound for the target distribution, it is reasonable to discover appropriate d and m. These analyses indeed inspire us to tackle the UDA problem, while no applicable algorithm is proposed in <ref type="bibr">[3]</ref>. In this paper, we adopt the well-established principles and extend them to a feasible and effective algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Deep End-to-End Model</head><p>Although the proposed principles are reasonable, the very first problem we should deal with is how to design a deep end-to-end model aligned well with these principles. In recent years, deep neural networks with a huge number of parameters optimized by gradient-based algorithms are powerful on large-scale datasets <ref type="bibr">[2]</ref>. However, the basic error bound is derived with respect to the Nearest Neighbor algorithm which is non-parametric and non-differentiable. In order to make the proposed model's capacity high enough, we replace the Nearest Neighbor algorithm with a deep neural network.</p><p>Let us recall the meaning of ES∼P m S [Err P T (h N N )] first. For any sample x in the target distribution, h N N is responsible for labeling it with the label of N S (x) which denotes the nearest sample in S. The size of S is determined by m and the label of N S (x) is determined by the majority of S. The intuition behind this algorithm is to seek m samples in the source distribution and then use them to label a sample in the target distribution. In fact, this intuition is well-aligned with the deep learning algorithm. In the deep learning algorithm, we can sample m points from the source distribution P S to form a batch, update a neural network with a forward and back propagation, and inference the label of x. Therefore, ES∼P m S [Err P T (h N N )] is revised to Err P T (n θ ), where n θ is a neural network parameterized by θ. θ is updated with some gradient-based algorithm,</p><formula xml:id="formula_5">θ := θ − ∇ θ ES∼P m S [Err P S (n θ )]</formula><p>. m refers to the batchsize during training. In this setting, optimizing θ is an end-toend process after choosing an appropriate loss function.</p><p>Although a deep end-to-end model bring us a higher capacity and convenient optimization procedure, we need to concern two points. First, the non-parametric Nearest Neighbor algorithm can estimate ES∼P m S [Err P T (h N N )] directly without any optimization, while Err P T (n θ ) estimated by n θ changes every iteration because θ is updated. In the beginning, Err P T (n θ ) is large while it converges to a small value as optimizing θ. Second, despite the proposed algorithm aligns well with the intuition in [3], it can not ensure the rigor of theorem 1. Therefore, more modifications are necessary to bound Err P T (n θ ) such that the proposed algorithm can work well in the practical situation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Local Smooth Discrepancy</head><p>Besides extending theorem 1 to a deep end-to-end model, how to decrease Φ(λ) is another crucial problem. According to equation 4, the basic UDA error bound is pos-</p><formula xml:id="formula_6">itively related to Φ(λ). Meanwhile, Φ(λ) is lower bounded by P r x∼D [∃y : |f (x) − f (y)| &gt; λµ(x, y)] as illustrated in definition 2. Thus, minimizing P r x∼D [∃y : |f (x) − f (y)| &gt; λµ(x, y)] instead of Φ(λ) which is troublesome to estimate is a straightforward idea. A naive estimation for P r x∼D [∃y : |f (x) − f (y)| &gt; λµ(x, y)] is E x∼D [ E y∼D [y:|f (x)−f (y)|&gt;λu(x,y) E y∼D [y]</formula><p>]. In this estimation, for any x ∈ D, we should sample a number of y ∈ D to make sure the estimation precise. In a deep end-to-end model, this procedure requires several forward propagations for one batch and it is confronted with large computational quantity. In [16], a replacement named local Lipschitz property for Lipschitz continuity is proposed. Local Lipschitz continuity assumes that every point x ∈ D has a neighborhood U such that f is Lipschitz continuous with respect to x and points in U . According to this assumption, we propose a concrete formula named local smooth discrepancy (LSD) to measure the degree that a sample x breaks down the local Lipschitz property:</p><formula xml:id="formula_7">LSD(x, θ) = D(n θ (x + r), n θ (x)), ||r|| ≤<label>(5)</label></formula><p>where D(·, ·) is a discrepancy function that measures the divergence between two outputs of n θ , and denotes the maximum norm of r. In LSD(x, θ), a sample x adds r to detect another sample in x's neighborhood. controls the range of sampling in x's neighborhood. As for the choice of D(·, ·), we employ cross-entropy loss function in all experiments. In addtion, in this setting, we specifies µ : χ 2 → R + as L1 norm such that for a point x ∈ D, points in its neighborhood denote as x + r, where ||r|| ≤ .</p><p>Although LSD is well-defined, there is still an essential point we should pay more attention to. Specifically, r is limited only by its norm in equation 5 and its direction is ignored. In fact, the goal of adding r includes detecting sensitive samples that not satisfy local Lipschitz property. If all x + r belong to the same category with x, it means that the direction of r could not detect sensitive samples. In this condition, sensitive samples are not modified to be local Lipshitz continuous. In order to solve this problem, we propose two plans to produce r, an isotropic one and an anisotropic one.</p><p>Isotropic Plan In the isotropic plan, we draw r from a Gaussian distribution and normalize it to satisfy r ≤ . The formula of LSD is modified into:</p><p>LSD(x, θ) = D(n θ (x + r ran ), n θ (x)),</p><formula xml:id="formula_8">r ran = m ||m|| 2 , m ∼ N (0, 1)<label>(6)</label></formula><p>Anisotropic Plan Anisotropic plan only looks for r which lead x + r with different labels from x and ignores r in other directions. To reach this goal, we take the insight from adversarial attack <ref type="bibr">[15]</ref>. Adversarial attack applies a certain hardly perceptible perturbation, which is found by maximizing the model's prediction error, to an image to cause the model misclassify <ref type="bibr">[15]</ref>. This philosophy fits well with our goal which tries to seek some noise to make the consequential samples belong to different classes. However, true labels are needed in this setting. In UDA problem, true labels for the target domain is unreachable. Therefore, we make several modifications in traditional adversarial attack methods. In detail, traditional adversarial attack methods approximate adversarial perturbation by:</p><formula xml:id="formula_9">r adv ≈ m ||m|| 2 , m = ∇ x D(n θ (x), y)<label>(7)</label></formula><p>Instead, we approximate it by:</p><formula xml:id="formula_10">r adv ≈ m ||m|| 2 , m = ∇ x D(n θ (x), onehot(n θ (x)))<label>(8)</label></formula><p>where onehot denotes transforming the softmax output of n θ to a one-hot vector. Equation 8 computes gradients of x and replaces y with onehot(n θ (x)). These modifications result in a new LSD for anisotropic noise:</p><formula xml:id="formula_11">LSD(x, θ) = D(n θ (x + r adv ), n θ (x))<label>(9)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Optimization Strategy</head><p>After defining LSD, what we should optimize to reduce Φ(λ) is clearly described, while how to optimize it and what we should concern to constrain the third term in theorem 1 need a detailed discussion.</p><p>Basically, we can adopt equation 6 or 9 to the loss function and use a gradient-based algorithm for optimization. However, there is an essential factor deserved to be considered. The dimension of domain d affects the basic error bound sharply. For instance, if we solve a UDA learning for some image domains, d potentially varies over a large range of values because the size of images is totally different. Considering that a large d leads to a loose error bound, LSD is embedded in feature space instead of image level such that d is decreased acutely. Equation 6 and 9 are revised into</p><formula xml:id="formula_12">LSD(x, θ) = D(C(G(x) + r ran ), C(G(x))), r ran = m ||m|| 2 , m ∼ N (0, 1) (10) LSD(x, θ) = D(C(G(x) + r adv ), C(G(x))) r adv ≈ m ||m|| 2 , m = ∇ g D(C(g), onehot(C(g))), g = G(x)<label>(11)</label></formula><p>where G and C denote the feature extractor and classifier in n θ , respectively. Their parameters are denoted as θ G and θ C . Therefore, we propose an optimization strategy in the feature space in three steps. First, we train G and C in the source domain.</p><formula xml:id="formula_13">min G,C L(X s , Y s ), L(X s , Y s ) = E x,y∼P S [ K k=1 1[k = y]logC(G(x))]<label>(12)</label></formula><p>where 1[] is an indicator function, and K denotes that there are K classes in a task. Then, we produce sensitive samples which break down the local Lipschitz property. Note that in theorem 1, Lipschitz property constraint is satisfied w.r.t the target distribution such that we focus on target samples in this step. In our work, sensitive samples g t are generated in the feature space of G:</p><formula xml:id="formula_14">g t = g t + r<label>(13)</label></formula><p>where g t = G(x t ), and r is a general notation for the adding noise. In practice, we set r = r ran for an isotropic plan or r = r adv for an anisotropic plan. Finally, we train G to minimize LSD for target samples. Only parameters of G are updated in this step. G is trained to project g t to the same category with g t :</p><formula xml:id="formula_15">min G LSD(X t , θ G ), LSD(X t , θ G ) = E x∼Pt D(C(g t ), C(g t ))<label>(14)</label></formula><p>where θ G denotes parameters of G, and D(·, ·) denotes cross-entropy loss function. Equation 12 13 and 14 are repeated in the optimization schedule as shown in <ref type="figure" target="#fig_0">Figure 1</ref>.</p><p>Here we give an intuitive understanding underlying our optimization strategy. As shown in <ref type="figure" target="#fig_0">Figure 1</ref>, a n θ welltrained in the source domain is able to classify source samples correctly. For a robust model, there is a large margin between the decision boundary and samples. Such distribution makes sure that local Lipschitz property is wellsatisfied. However, a dataset shift across different domains results in a probability that a set of target samples would cross the boundary decided by a source domain. These samples are misclassified and local Lipschitz constraint is broken down. Therefore, we regard samples near the decision boundary as sensitive ones which easily lead errors to n θ . It is similar to the overfitting problem where extreme nonlinearity of deep neural networks leads to a phenomenon that performance drop happens when facing out-of-distribution samples. In a UDA problem, the dataset shift further exacerbates this situation. Numerous target samples are regarded as out-of-distribution samples for n θ . In order to obtain a n θ work well in the target domain, G needs to project x ∼ P T into feature space away from the decision boundary.</p><p>In our strategy, we try to form a large margin between target samples and the source decision boundary. Samples close to the boundary are detected and G is forced to project them far away from the boundary. Under such an optimization strategy, representation of the target distribution becomes "smooth" gradually which means that the local Lipschitz constraint is ensured. When the algorithm converges, not only the dataset shift between source and target domain is reduced, but also source and target samples achieve a large margin with the decision boundary. The ideal smooth representation of the target domain is learned in our method. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments and Discussion</head><p>In order to verify the effectiveness of the proposed method (SRDA), we conduct several classification experiments on standard benchmark datasets. First, we test SRDA on several digits classification datasets which are the most common datasets for UDA. Second, we test it on a more complex and massive dataset, VisDA <ref type="bibr">[35]</ref>, to show the advanced performance of SRDA. Then, we conduct experiments to demonstrate how the dimension and batchsize of samples affect the performance of SRDA. Finally, we analyze the limitation of SRDA on Office-31 dataset. In all experiments, we implement models with Pytorch, and employ the optimization schedule we propose.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Digits Classification</head><p>We evaluate four types of adaptation scenarios by utilizing the digits datasets, <ref type="bibr">MNIST [22]</ref>, USPS [20], Synthetic Traffic Signs (SYNSIG) [31], Street View House Numbers (SVHN) <ref type="bibr">[33]</ref> and German Traffic Signs Recognition Benchmark (GTSRB) <ref type="bibr">[39]</ref>. Specifically, MNIST, USPS and SVHN consist of 10 classes, whereas SYNSIG and GTSRB are traffic sign datasets which consist of 43 classes. In this experiment, we set four transfer tasks: SVHN→MNIST, SYNSIG→GTSRB, MNIST→USPS and USPS→MNIST. In detail, the dataset shift in SVHN→MNIST is caused by a different property of an image that SVHN contains RGB images while MNIST contains grayscale images. The shift between USPS and MNIST is relatively small because both of them are handwritten digit datasets and contain grayscale images. Images in SYNSIG and GTSRB have distinct properties because those in SYNSIG are synthesized and the rest is collected from the real world. For a fair comparison, we follow the protocols provided in MCD [37] and ADDA <ref type="bibr">[42]</ref>.</p><p>In this experiment, in order to verify the robustness of SRDA, we implement both isotropic and anisotropic plans. For the isotropic plan, we sample noise from a standard Gaussian distribution. In all four tasks, hyper-parameter is set to 0.5 and the learning rate is set to 1e −3 . For the anisotropic plan, sensitive samples are generated in two different ways. We choose two classical adversarial attack algorithm, namely FGSM <ref type="bibr">[15]</ref> and <ref type="bibr">VAT [30]</ref>, to produce noise adding to a feature vector. Note that FGSM [15] needs true labels to execute a backpropagation to compute gradients, so that we use pseudo labels to replace them. We set batchsize to 128 in all tasks for both plans and all models are trained for 150 epochs. Thus, SRDA can not improve the baseline a lot. The fact that improvement in the easiest task SYNSIG→GTSRB is the smallest verifies our conclusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">VisDA Classification</head><p>We further assess SRDA on a more complex object classification dataset. VisDA in this experiment constructs an adaptation from synthetic-object to real-object images. It contains more than 280K images belonging to 12 categories. These images are divided into training, validation and test sets. There are 152,397 training images synthesized by rendering 3D models with different angles and lighting conditions. The validation images are collected from <ref type="bibr">MSCOCO [23]</ref> and amount to 55,388 in total. In this experiment, we regard the training set as a source domain and the validation set as a target domain. Similarly, in order to ensure fairness, we utilize the same backbone network, ResNet101 [18], with MCD [37]. The setting of generator and classifier networks is also the same. In addition, we also employ the entropy minimization trick used in MCD <ref type="bibr">[37]</ref>.</p><p>In this experiment, we also implement both isotropic and anisotropic plans. For the anisotropic plan, FGSM <ref type="bibr">[15]</ref> and <ref type="bibr">VAT [30]</ref> algorithms are implemented. All models are trained for 15 epochs and batchsize is 32. Learning rate is 1e −4 and hyper-parameter is set to 0.5. Similarly, we compare SRDA(FGSM), SRDA(VAT) and SRDA(RAN) with several typical methods, such as <ref type="bibr">DAN [25]</ref>, <ref type="bibr">DANN [12]</ref>, and MCD <ref type="bibr">[37]</ref> which is the state-of-the-art method.</p><p>Results of the VisDA classification experiment are shown in <ref type="table" target="#tab_1">Table 2</ref>. SRDA and MCD [37] achieve much better accuracy than other methods. Moreover, SRDA(RAN) ranks first among all the models and SRDA (FGSM) obtains comparable accuracy with MCD [37]. In detail, SRDA(RAN) achieves the best results in class plane and person, SRDA(VAT) achieves the best result in class motor cycle and SRDA(FGSM) gets the best result in class knife. An interesting phenomenon is that three models of SRDA perform diversely among these categories. For example, in class knife, SRDA(FGSM) performs much better than the others and SRDA(VAT) ranks first in class motor cycle. Overall, SRDA(RAN) performs best. This reflects the importance of detecting sensitive samples. A well-defined plan which could seek more sensitive samples and a metric that could illustrate the smoothness of samples precisely are hopeful to further promote the proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Image Level versus Feature Space</head><p>In our optimization strategy, LSD is minimized in the feature space instead of image level. We determine it because the dimension of image d makes a great impact on the basic error bound. If the optimization is conducted in the image level, d would be much larger than in the feature space and a loose error bound is formalized. To verify this assumption, we assess SRDA that optimized in the image level on both digits and VisDA datasets. In detail, we adopt equations 6 and 9 for the isotropic and anisotropic plans, respectively, as our optimization goals. The three models are denoted as SRDA*(FGSM), SRDA*(VAT) and SRDA*(RAN). For a fair comparison, all the settings are the same with models optimized in the feature space.</p><p>Results of the models optimized in the image level are shown in <ref type="table" target="#tab_0">Table 1</ref> and 2. Except that SRDA*(RAN) and SRDA*(VAT) perform slightly better than SRDA(RAN) and SRDA(VAT) in USPS→MNIST and MNIST→USPS, respectively, all models optimized in the feature space obtain much better performance than in the image level. Particularly, SRDA*(FGSM) is quite sensitive to d where its performance drops a lot in almost tasks and even it collapses in SYNSIG→GTSRB. In the VisDA classification experiment, SRDA*(FGSM) and SRDA*(VAT) perform like random guessing, and the accuracy of SRDA*(RAN) decrease 15.5% with respect to SRDA(RAN). Large-scale images in VisDA dataset aggravate the influence of d because the difference of d between the image level and feature space is more obvious than in the digits classification experiment. Therefore, we conclude that optimization in the feature space is necessary to reduce the value of d. In addition, we find that the isotropic plan is the most robust plan.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Batchsize Analysis</head><p>According to theorem 1, the basic UDA error bound is related to the batchsize m where a large batchsize leads to a small error bound. This assumption is confirmed in other computer vision problem <ref type="bibr">[19,</ref><ref type="bibr">6]</ref>. In order to verify how m influences the performance of SRDA, we evaluate SRDA with different m ∈ {32, 16, 8, 4}. Except batchsize, other settings follow the VisDA classification experiment.</p><p>Results are shown in <ref type="table" target="#tab_2">Table 3</ref>. For all the three SRDA models, the average accuracy decreases as batchsize gets smaller. Specially, when m is set to 4, the performance drops rapidly even is lower than 30%. When m ≥ 8, the performance drops gradually and maintains the accuracy over 60%. The trend shows a evidence that the batchsize m should be set large enough for optimizing SRDA, otherwise a loose error bound can not ensure the effectiveness. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Limitation</head><p>As illustrated in <ref type="bibr">[3]</ref>, to conpensate the lack of highquality samples, a large quantity of low-quality data is needed. Thus, we choose a small-scale dataset, Office-31 which comprises only 4,110 images and 31 categories collected from three domains: AMAZON (A) with 2,817 images, DSLR (D) with 498 images and WEBCAM (W) with 795 images, to verify this assumption. We focus on the most difficult four task: A→D, A→W, D→A and W→A and test SRDA (RAN) and SRDA (FGSM) in this experiment. Both of them are trained for 50 epochs and batchsize is set to 32. Learning rate is set to 1e-3 and hyper-parameter is set to 0.5 for all four tasks. We compare them with several classical DA models such as GFK <ref type="bibr">[14]</ref>, <ref type="bibr">TCA [34]</ref>, <ref type="bibr">DAN [25]</ref>, <ref type="bibr">RTN [27]</ref> and <ref type="bibr">DANN [12]</ref>. All models utilze the same backbone, ResNet101.</p><p>Results of the Office-31 classification experiment are shown in <ref type="table" target="#tab_3">Table 4</ref>. Overall, SRDA is comparable to RTN and performs worse than DANN. In particular, SRDA performs poor in D→A and W→A whereas in A→D, A→W, its performance is acceptable. Considering the extreme small scale of D and W, the results are reasonable. This experiment comfirms our assumption that SRDA indeed requires a great quantity of data. We suggest that the amount of images in Office-31 is not effficient to detect enough sensitive samples to train G. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper, we propose a method for UDA inspired by the probabilistic Lipschitz constraint. We extend principles analyzed in [3] to a deep end-to-end model and practical optimization strategy. The key to strengthening Lipschitz continuity is to minimize the local smooth discrepancy we defined. To avoid a loose error bound, the optimization strategy is subtly designed by considering the dimension of samples and batchsize. Experiments demonstrate that pure Lipschitz constraint is effective for UDA and factors we discuss are critical to an efficient and stable model. In order to verify that LSD we defined indeed reflects the degree Lipschitz constraint is satisfied and the performance of a model, we show the relationship between LSD and accuracy in <ref type="figure" target="#fig_1">Figure 2</ref>. Three models, SRDA (RAN), SRDA (FGSM) and SRDA (VAT), are assessed on VisDA. We follow the settings in VisDA classification experiment. Note that because we get the accuracy every epoch and LSD is recorded every step, we show the accuracy after a quadratic interpolation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head><p>As shown in <ref type="figure" target="#fig_1">Figure 2(a), 2(b), and 2(c)</ref>, the accuracy of all three models gradually increases as LSD decreases. This indicates that the proposed LSD is a reasonable metric to evaluate the performance of a UDA model. In the VisDA classification experiment, SRDA (RAN) performs best on VisDA, SRDA (FGSM) ranks second and SRDA (VAT) is the worst model among them. In fact, the order of performance on VisDA also corresponds to LSD. SRDA (VAT) shows the highest loss, SRDA (RAN) obtains the lowest loss and SRDA (FGSM) ranks in the middle. The result verifies that Lipschitz continuous property is a key factor that affects the performance of a UDA model. Our explanation of performance drop in the target domain based on smoothness is also confirmed. This is a remarkable property because the adversarial training, which is the most widely used DA method, lacks a metric to supervise the training procedure. Although the adversarial loss is an approximation of H distance, it is not able to reflect the real performance of a model because the training procedure is a min-max game. Instead, LSD is a proper metric to supervise the training period as SRDA utilizes a pure minimization optimization. Moreover, to prove that LSD is a general metric to assess the performance of a UDA model, we further test it on MCD with different accuracy. In this experiment, we follow the settings described in MCD and train models on VisDA. Overall, we train 12 MCD models with different accuracy by tuning hyper-parameters. As LSD is not the objective function of MCD, we introduce the original FGSM algorithm to generate adversarial samples on image level. Traditional white adversarial attack algorithms generate samples with their own networks. This paradigm introduces a new variable that adversarial samples are not the same for different MCD models. Thus, we generate adversarial samples with SRDA (RAN) in this experiment to ensure fairness for each MCD model. is also set to 0.5. With these adversarial images, LSD is calculated with their corresponding images in the target domain. To ensure the validity of the results, both classifiers in MCD are tested.</p><p>As is shown in <ref type="figure" target="#fig_1">Figure 2(d)</ref>, there is an obvious relationship between LSD and accuracy that a low LSD corresponds to high accuracy. We train 12 MCD models with accuracy belongs to <ref type="bibr">{62.42, 64.83, 65.33, 65.86, 66.66, 68.89, 69.79, 70.46, 70.60, 71.76, 71.78, 71</ref>.82}. LSD of both classifiers gradually decreases from 0.6 to 0.3 roughly. This means that LSD is a reasonable general metric to evaluate the performance of a UDA model. However, there are also several MCD model with high accuracy showing relative high LSD. We argue that the randomness of the gradient descent algorithm causes this fluctuation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.">Visualization of Representation</head><p>We further analyze the behavior of SRDA by shown T-SNE embeddings of the feature space where we conduct our optimization strategy. In particular, we visualize the embeddings for MNIST→USPS and VisDA classification.</p><p>MNIST→USPS In <ref type="figure">Figure 3</ref>, we show visualizations of the model without adaptation, SRDA(FGSM), SRDA(VAT) and SRDA(RAN) for MNIST→USPS. SRDA(VAT) and SRDA(RAN) separate target samples into ten clusters whereas SRDA(FGSM) only form nine clusters. It is clear that SRDA (RAN) not only separates target samples into different clusters but also aligns the source and target distributions well. In <ref type="figure">Figure 4</ref>, all SRDA models are optimized in the image level. SRDA*(FGSM) shows a strong clustering of the USPS samples (red). Note that SRDA*(VAT) aligns the source and target distribution well whereas SRDA(VAT) does not show this property. It associates with the fact that SRDA*(VAT) obtains higher accuracy in MNIST→USPS than SRDA(VAT).   <ref type="figure">Figure 6</ref>. T-SNE plots of SRDA which performed optimization in the image level for VisDA classification experiment. Blue points denotes source samples whereas red points denotes target samples.</p><p>VisDA In <ref type="figure">Figure 5</ref>, we show visualizations of SRDA(FGSM), SRDA(VAT) and SRDA(RAN) for the VisDA classification experiment. All three models seperate target samples into several clusters and try to align the source and target distributions. However, none of them could form twelve clusters clearly like the source distribution and there exists adhesion between different clusters. In <ref type="figure">Figure 6</ref>, we show visualizations of SRDA*(FGSM), SRDA*(VAT) and SRDA*(RAN) for the VisDA classification experiment. All of them demonstrate strong clustering of the target samples, even the source samples gather together. The source and target distributions are separated in all models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>A visual illustration of how the proposed method achieves adaptation. (Upper) The left block illustrates the dataset shift between different domains. The other three blocks depict the process of forming a robust margin between target samples and the decision boundary. At the same time, how distributions of the target domains changes are described. At last, distributions of the target and source domains are matched. (Lower) The optimization schedule is able to project sensitive samples to new locations away from the decision boundary in three steps. Dashed lines indicate fixed network parameters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Three figures on the left display relationship between LSD (red line) and accuracy (blue line) during the training period. Three SRDA models are evaluated on VisDA. As discrepancy decreases, the accuracy increases. The figure on the right display relationship between LSD and accuracy in MCD. The model with higher accuracy gets a lower LSD.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>T-SNE plots of SRDA performed optimization in the image level for MNIST (blue)→USPS (red).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Classification accuracy percentage of digits classification experiment among all four tasks. The first row corresponds to the performance if no adaption is implemented. We evaluate three SRDA models with different plans for adding noise. SRDA* denotes the models which are optimized in the image level. The results are cited from each study.</figDesc><table><row><cell></cell><cell>SVHN</cell><cell>SYNSIG</cell><cell>MNIST</cell><cell>USPS</cell></row><row><cell>Method</cell><cell>→</cell><cell>→</cell><cell>→</cell><cell>→</cell></row><row><cell></cell><cell>MNIST</cell><cell>GTSRB</cell><cell>USPS</cell><cell>MNIST</cell></row><row><cell>Source Only</cell><cell>67.1</cell><cell>85.1</cell><cell>76.7</cell><cell>63.4</cell></row><row><cell>DAN [25]</cell><cell>71.1</cell><cell>91.1</cell><cell>-</cell><cell>-</cell></row><row><cell>DANN [12]</cell><cell>71.1</cell><cell>88.7</cell><cell>77.1</cell><cell>73.0</cell></row><row><cell>DSN [5]</cell><cell>82.7</cell><cell>93.1</cell><cell>91.3</cell><cell>-</cell></row><row><cell>ADDA [42]</cell><cell>76.0</cell><cell>-</cell><cell>89.4</cell><cell>90.1</cell></row><row><cell>CoGAN [24]</cell><cell>-</cell><cell>-</cell><cell>91.2</cell><cell>89.1</cell></row><row><cell>ATDA [36]</cell><cell>86.2</cell><cell>96.2</cell><cell>-</cell><cell>-</cell></row><row><cell>ASSC [17]</cell><cell>95.7</cell><cell>82.8</cell><cell>-</cell><cell>-</cell></row><row><cell>DRCN [13]</cell><cell>82.0</cell><cell>-</cell><cell>91.8</cell><cell>73.7</cell></row><row><cell>MCD [37]</cell><cell>96.2</cell><cell>94.4</cell><cell>94.2</cell><cell>94.1</cell></row><row><cell>SRDA(FGSM)</cell><cell>95.96</cell><cell>90.46</cell><cell>81.53</cell><cell>95.78</cell></row><row><cell>SRDA*(FGSM)</cell><cell>22.70</cell><cell>collapse</cell><cell>32.73</cell><cell>85.37</cell></row><row><cell>SRDA(VAT)</cell><cell>97.92</cell><cell>89.51</cell><cell>85.00</cell><cell>95.49</cell></row><row><cell>SRDA*(VAT)</cell><cell>89.47</cell><cell>29.04</cell><cell>88.49</cell><cell>92.17</cell></row><row><cell>SRDA(RAN)</cell><cell>98.91</cell><cell>93.61</cell><cell>94.76</cell><cell>95.03</cell></row><row><cell>SRDA*(RAN)</cell><cell>89.51</cell><cell>49.86</cell><cell>93.25</cell><cell>95.95</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Classification accuracy percentage of VisDA classification experiment. The first row corresponds to the performance if no adaption is implemented. Columns in the middle correspond to different categories and the column on the right represents average accuracy. We evaluate three SRDA models with different plans for adding noise. SRDA* denotes the models which are optimized in the image level. The number behind MCD denotes different hyper-parameters. The results are cited from each study. obtain the best results. We conclude that it is caused by the relative satisfying results when no adaptation is implemented. Once a model without adaptation allocates target samples satisfying Lipschitz constraint well, SRDA is hard to detect enough sensitive samples to optimize G.</figDesc><table><row><cell>Method</cell><cell>Pl</cell><cell>Bc</cell><cell>Bs</cell><cell>Ca</cell><cell>Hr</cell><cell>Kf</cell><cell>Mc</cell><cell>Ps</cell><cell>Pt</cell><cell>Sk</cell><cell>Tr</cell><cell>Tk</cell><cell>Avg</cell></row><row><cell>Source Only</cell><cell cols="13">55.1 53.3 61.9 59.1 80.6 17.9 79.7 31.2 81.0 26.5 73.5 8.5 52.4</cell></row><row><cell>DAN [25]</cell><cell cols="13">87.1 63.0 76.5 42.0 90.3 42.9 85.9 53.1 49.7 36.3 85.8 20.7 61.1</cell></row><row><cell>DANN [12]</cell><cell cols="13">81.9 77.7 82.8 44.3 81.2 29.5 65.1 28.6 51.9 54.6 82.8 7.8 57.4</cell></row><row><cell>MCD(2) [37]</cell><cell cols="13">81.1 55.3 83.6 65.7 87.6 72.7 83.1 73.9 85.3 47.7 73.2 27.1 69.7</cell></row><row><cell>MCD(3) [37]</cell><cell cols="13">90.3 49.3 82.1 62.9 91.8 69.4 83.8 72.8 79.8 53.3 81.5 29.7 70.6</cell></row><row><cell>MCD(4) [37]</cell><cell cols="13">87.0 60.9 83.7 64.0 88.9 79.6 84.7 76.9 88.6 40.3 83.0 25.8 71.9</cell></row><row><cell>SRDA(FGSM)</cell><cell cols="13">90.1 67.0 82.3 56.0 84.8 88.2 90.3 77.0 82.5 26.8 85.0 16.2 71.1</cell></row><row><cell cols="2">SRDA*(FGSM) 0.8</cell><cell>0.9</cell><cell>8.8</cell><cell>3.0</cell><cell cols="4">1.0 12.9 69.5 0.1</cell><cell>2.5</cell><cell cols="4">0.7 26.8 1.4 11.9</cell></row><row><cell>SRDA(VAT)</cell><cell cols="13">89.4 43.5 81.2 60.2 81.1 57.6 93.7 76.6 81.8 41.3 79.6 22.0 69.5</cell></row><row><cell>SRDA*(VAT)</cell><cell>2.6</cell><cell>1.4</cell><cell>2.1</cell><cell>1.6</cell><cell cols="6">4.1 23.3 48.9 0.7 21.8 1.4</cell><cell>3.7</cell><cell>1.3</cell><cell>9.8</cell></row><row><cell>SRDA(RAN)</cell><cell cols="13">90.9 74.8 81.9 59.1 87.5 77.3 89.9 79.4 85.3 40.6 85.1 21.6 73.5</cell></row><row><cell>SRDA*(RAN)</cell><cell cols="13">40.2 40.2 55.9 62.9 60.5 75.9 83.0 61.7 73.0 23.2 80.8 5.7 58.0</cell></row><row><cell>els do not</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Classification accuracy percentage of VisDA classification experiment for different batchsize.</figDesc><table><row><cell>Method</cell><cell cols="2">Batchsize Average Accuracy</cell></row><row><cell></cell><cell>32</cell><cell>71.1</cell></row><row><cell>SRDA(FGSM)</cell><cell>16 8</cell><cell>69.1 64.5</cell></row><row><cell></cell><cell>4</cell><cell>29.5</cell></row><row><cell></cell><cell>32</cell><cell>69.5</cell></row><row><cell>SRDA(VAT)</cell><cell>16 8</cell><cell>66.5 62.2</cell></row><row><cell></cell><cell>4</cell><cell>34.3</cell></row><row><cell></cell><cell>32</cell><cell>73.5</cell></row><row><cell>SRDA(RAN)</cell><cell>16 8</cell><cell>71.1 64.2</cell></row><row><cell></cell><cell>4</cell><cell>51.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>Classification accuracy percentage of Office-31 classification experiment. The first row corresponds to the performance if no adaption is implemented. We evaluate two SRDA models with different plans for adding noise. The results are cited from published papers.</figDesc><table><row><cell></cell><cell>A</cell><cell>A</cell><cell>D</cell><cell>W</cell><cell></cell></row><row><cell>Method</cell><cell>→</cell><cell>→</cell><cell>→</cell><cell>→</cell><cell>AVG</cell></row><row><cell></cell><cell>D</cell><cell>W</cell><cell>A</cell><cell>A</cell><cell></cell></row><row><cell>Source Only</cell><cell cols="5">68.9 68.4 62.5 60.7 65.2</cell></row><row><cell>GFK [14]</cell><cell cols="5">74.5 72.8 63.4 61.0 67.9</cell></row><row><cell>TCA [34]</cell><cell cols="5">74.1 72.7 61.7 60.9 67.4</cell></row><row><cell>DAN [25]</cell><cell cols="5">78.6 80.5 63.6 62.8 71.4</cell></row><row><cell>RTN [27]</cell><cell cols="5">77.5 84.5 66.2 64.8 73.3</cell></row><row><cell>DANN [12]</cell><cell cols="5">79.7 82.0 68.2 67.4 74.3</cell></row><row><cell cols="6">SRDA(FGSM) 82.5 84.7 62.5 61.0 72.7</cell></row><row><cell>SRDA(RAN)</cell><cell cols="5">78.8 83.2 67.3 64.8 73.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>[ 1 ]</head><label>1</label><figDesc>Martin Arjovsky and Leon Bottou. Towards principled methods for training generative adversarial networks. 2017. 1 [2] Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman Vaughan. A theory of learning from different domains. Deep reconstruction-classification networks for unsupervised domain adaptation. In ECCV (4), volume 9908 of Lecture Notes in Computer Science, pages 597-613. Springer, 2016. 6 [14] Boqing Gong, Yuan Shi, Fei Sha, and Kristen Grauman. Geodesic flow kernel for unsupervised domain adaptation. Mingsheng Long, Han Zhu, Jianmin Wang, and Michael I Jordan. Deep transfer learning with joint adaptation networks. In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pages 2208-2217. JMLR. Masashi Sugiyama. Generalization error estimation under covariate shift. In In Workshop on Information-Based Induction Sciences, pages 21-26, 2005. 2 [41] Baochen Sun and Kate Saenko. Deep coral: Correlation alignment for deep domain adaptation. In European Conference on Computer Vision, pages 443-450. Springer, 2016.</figDesc><table><row><cell cols="2">Machine learn-Talon, Andrzej Kasinski, Wilfried Philips, Dan Popescu, and 2 trained on synthetically generated data. In Jacques Blanc-Vision and Pattern Recognition, pages 3722-3731, 2017. 1, ton Konushin. Evaluation of traffic sign recognition methods works. In Proceedings of the IEEE Conference on Computer [31] Boris Moiseev, Artem Konev, Alexander Chigorin, and An-level domain adaptation with generative adversarial net-2018. 2, 6, 7 Dumitru Erhan, and Dilip Krishnan. Unsupervised pixel-Transactions on Pattern Analysis and Machine Intelligence, [4] Konstantinos Bousmalis, Nathan Silberman, David Dohan, method for supervised and semi-supervised learning. IEEE 3, 8 Koyama. Virtual adversarial training: a regularization and Artificial Intelligence, 70(3):185-202, Mar 2014. 1, 2, [30] Takeru Miyato, Shin-ichi Maeda, Shin Ishii, and Masanori quantity compensate for quality? Annals of Mathematics tion, 2019. 1 [3] Shai Ben-David and Ruth Urner. Domain adaptation-can adaptation. arXiv: Computer Vision and Pattern Recogni-ing, 79(1-2):151-175, 2010. 1, 2, 3 [28] org, 2017. 2 [29] Xudong Mao, Yun Ma, Zhenguo Yang, Yangbin Chen, and Qing Li. Virtual mixup training for unsupervised domain 7. Supplementary 7.1. Discussion of Local Smooth Discrepancy</cell><cell>for image recognition. In 2016 IEEE Conference on Com-[18] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning Oct 2017. 6 sentations, 2017. 1, 2 IEEE International Conference on Computer Vision (ICCV), tion learning. International Conference on Learning Repre-and Daniel Cremers. Associative domain adaptation. In The moment discrepancy (cmd) for domain-invariant representa-[17] Philip Haeusser, Thomas Frerix, Alexander Mordvintsev, Thomas Natschläger, and Susanne Saminger-Platz. Central learning by entropy minimization. pages 529-536, 2004. 4 [43] Werner Zellinger, Thomas Grubinger, Edwin Lughofer, [16] Yves Grandvalet and Yoshua Bengio. Semi-supervised Pattern Recognition, pages 7167-7176, 2017. 2, 6 preprint arXiv:1412.6572, 2014. 4, 6, 7 ceedings of the IEEE Conference on Computer Vision and Explaining and harnessing adversarial examples. arXiv rell. Adversarial discriminative domain adaptation. In Pro-[15] Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. [42] Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Dar-In 2012 IEEE Conference on Computer Vision and Pattern Recognition, pages 2066-2073. IEEE, 2012. 8 [40] 1, 2</cell></row><row><cell cols="2">[5] Konstantinos Bousmalis, George Trigeorgis, Nathan Silber-Paul Scheunders, editors, Advanced Concepts for Intelligent</cell><cell>puter Vision and Pattern Recognition (CVPR), pages 770-</cell></row><row><cell cols="2">Vision Systems, pages 576-583, Cham, 2013. Springer Inter-</cell><cell>778, June 2016. 7</cell></row><row><cell>national Publishing. 6</cell><cell></cell><cell>[19] Tong He, Zhi Zhang, Hang Zhang, Zhongyue Zhang, Jun-</cell></row><row><cell cols="2">[32] Zak Murez, Soheil Kolouri, David Kriegman, Ravi Ra-</cell><cell>yuan Xie, and Mu Li. Bag of tricks for image classification</cell></row><row><cell cols="2">mamoorthi, and Kyungnam Kim. Image to image translation</cell><cell>with convolutional neural networks. arXiv: Computer Vision</cell></row><row><cell cols="2">for domain adaptation. In Proceedings of the IEEE Con-</cell><cell>and Pattern Recognition, 2018. 8</cell></row><row><cell cols="2">ference on Computer Vision and Pattern Recognition, pages</cell><cell>[20] J. J. Hull. A database for handwritten text recognition re-</cell></row><row><cell>4500-4509, 2018. 2</cell><cell></cell><cell>search. IEEE Transactions on Pattern Analysis and Machine</cell></row><row><cell cols="2">[33] Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bis-</cell><cell>Intelligence, 16(5):550-554, May 1994. 6</cell></row><row><cell cols="2">sacco, Bo Wu, and Andrew Y. Ng. Reading digits in natural</cell><cell>[21] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton.</cell></row><row><cell cols="2">images with unsupervised feature learning. In NIPS Work-</cell><cell>Imagenet classification with deep convolutional neural net-</cell></row><row><cell cols="2">shop on Deep Learning and Unsupervised Feature Learning</cell><cell>works. In Advances in Neural Information Processing Sys-</cell></row><row><cell>2011, 2011. 6</cell><cell>and Learning</cell><cell>tems, pages 1097-1105, 2012. 1</cell></row><row><cell cols="2">Systems, pages 1-14, 2019. 1 [34] Sinno Jialin Pan, Ivor W Tsang, James T Kwok, and Qiang</cell><cell>[22] Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-</cell></row><row><cell cols="2">[8] D. Das and C. S. George Lee. Unsupervised domain adap-Yang. Domain adaptation via transfer component analy-</cell><cell>based learning applied to document recognition. Proceed-</cell></row><row><cell cols="2">tation using regularized hyper-graph matching. In 2018 25th sis. IEEE Transactions on Neural Networks, 22(2):199-210,</cell><cell>ings of the IEEE, 86(11):2278-2324, Nov 1998. 6</cell></row><row><cell cols="2">IEEE International Conference on Image Processing (ICIP), 2010. 8</cell><cell>[23] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays,</cell></row><row><cell cols="2">pages 3758-3762, Oct 2018. 2 [35] Xingchao Peng, Ben Usman, Neela Kaushik, Judy Hoffman,</cell><cell>Pietro Perona, Deva Ramanan, Piotr Dollár, and C. Lawrence</cell></row><row><cell cols="2">[9] Debasmit Das and C.S. George Lee. Sample-to-sample cor-Dequan Wang, and Kate Saenko. Visda: The visual domain</cell><cell>Zitnick. Microsoft coco: Common objects in context. In</cell></row><row><cell cols="2">respondence for unsupervised domain adaptation. Engineer-adaptation challenge. arXiv: Computer Vision and Pattern</cell><cell>David Fleet, Tomas Pajdla, Bernt Schiele, and Tinne Tuyte-</cell></row><row><cell cols="2">ing Applications of Artificial Intelligence, 73:80 -91, 2018. Recognition, 2017. 6</cell><cell>laars, editors, Computer Vision -ECCV 2014, pages 740-</cell></row><row><cell cols="2">2 [36] Kuniaki Saito, Yoshitaka Ushiku, and Tatsuya Harada.</cell><cell>755, Cham, 2014. Springer International Publishing. 7</cell></row><row><cell cols="2">[10] Debasmit Das and C. S. George Lee. Graph matching and Asymmetric tri-training for unsupervised domain adaptation.</cell><cell>[24] Ming-Yu Liu and Oncel Tuzel. Coupled generative adversar-</cell></row><row><cell cols="2">pseudo-label guided deep unsupervised domain adaptation. In Proceedings of the 34th International Conference on Ma-</cell><cell>ial networks. In Advances in Neural Information Processing</cell></row><row><cell cols="2">In Věra Kůrková, Yannis Manolopoulos, Barbara Hammer, chine Learning-Volume 70, pages 2988-2997. JMLR. org,</cell><cell>Systems, pages 469-477, 2016. 1, 2, 6</cell></row><row><cell cols="2">Lazaros Iliadis, and Ilias Maglogiannis, editors, Artificial 2017. 2, 6</cell><cell>[25] Mingsheng Long, Yue Cao, Jianmin Wang, and Michael Jor-</cell></row><row><cell cols="2">Neural Networks and Machine Learning -ICANN 2018, [37] Kuniaki Saito, Kohei Watanabe, Yoshitaka Ushiku, and Tat-</cell><cell>dan. Learning transferable features with deep adaptation net-</cell></row><row><cell cols="2">pages 342-352, Cham, 2018. Springer International Publish-suya Harada. Maximum classifier discrepancy for unsuper-</cell><cell>works. In Francis Bach and David Blei, editors, Proceedings</cell></row><row><cell cols="2">ing. 2 vised domain adaptation. In Proceedings of the IEEE Con-</cell><cell>of the 32nd International Conference on Machine Learning,</cell></row><row><cell cols="2">[11] Jeff Donahue, Yangqing Jia, Oriol Vinyals, Judy Hoffman, ference on Computer Vision and Pattern Recognition, pages</cell><cell>volume 37 of Proceedings of Machine Learning Research,</cell></row><row><cell cols="2">Ning Zhang, Eric Tzeng, and Trevor Darrell. Decaf: A deep 3723-3732, 2018. 2, 6, 7</cell><cell>pages 97-105, Lille, France, 07-09 Jul 2015. PMLR. 1, 2,</cell></row><row><cell cols="2">convolutional activation feature for generic visual recogni-[38] Rui Shu, Hung Bui, Hirokazu Narui, and Stefano Ermon. A</cell><cell>6, 7, 8</cell></row><row><cell cols="2">tion. pages 647-655, 2014. 1 DIRT-t approach to unsupervised domain adaptation. In In-</cell><cell>[26] Mingsheng Long, Zhangjie Cao, Jianmin Wang, and</cell></row><row><cell cols="2">[12] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pas-ternational Conference on Learning Representations, 2018.</cell><cell>Michael I Jordan. Conditional adversarial domain adapta-</cell></row><row><cell>1</cell><cell></cell><cell>tion. In Advances in Neural Information Processing Systems,</cell></row><row><cell cols="2">[39] J. Stallkamp, M. Schlipsing, J. Salmen, and C. Igel. The ger-</cell><cell>pages 1640-1650, 2018. 2</cell></row><row><cell cols="2">man traffic sign recognition benchmark: A multi-class clas-</cell><cell>[27] Mingsheng Long, Han Zhu, Jianmin Wang, and Michael I</cell></row><row><cell cols="2">sification competition. In The 2011 International Joint Con-</cell><cell>Jordan. Unsupervised domain adaptation with residual trans-</cell></row><row><cell cols="2">ference on Neural Networks, pages 1453-1460, July 2011.</cell><cell>fer networks. In Advances in Neural Information Processing</cell></row><row><cell>6</cell><cell></cell><cell>Systems, pages 136-144, 2016. 8</cell></row></table><note>man, Dilip Krishnan, and Dumitru Erhan. Domain separa- tion networks. In D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett, editors, Advances in Neural Infor- mation Processing Systems 29, pages 343-351. Curran As- sociates, Inc., 2016. 6 [6] Andrew Brock, Jeff Donahue, and Karen Simonyan. Large scale GAN training for high fidelity natural image synthe- sis. In International Conference on Learning Representa- tions, 2019. 8 [7] G. Cai, Y. Wang, L. He, and M. Zhou. Unsupervised domain adaptation with adversarial residual transform net- works. IEEE Transactions on Neural Networkscal Germain, Hugo Larochelle, François Laviolette, Mario Marchand, and Victor Lempitsky. Domain-adversarial train- ing of neural networks. The Journal of Machine Learning Research, 17(1):2096-2030, 2016. 1, 2, 6, 7, 8 [13] Muhammad Ghifary, W. Bastiaan Kleijn, Mengjie Zhang, David Balduzzi, and Wen Li.</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Note that the theorems assume binary classification (y ∈ 0, 1). However, they can be directly extended to multi-class settings</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
