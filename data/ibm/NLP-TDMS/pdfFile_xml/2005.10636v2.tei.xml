<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Graph-based, Self-Supervised Program Repair from Diagnostic Feedback</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michihiro</forename><surname>Yasunaga</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
						</author>
						<title level="a" type="main">Graph-based, Self-Supervised Program Repair from Diagnostic Feedback</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T08:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We consider the problem of learning to repair programs from diagnostic feedback (e.g., compiler error messages). Program repair is challenging for two reasons: First, it requires reasoning and tracking symbols across source code and diagnostic feedback. Second, labeled datasets available for program repair are relatively small. In this work, we propose novel solutions to these two challenges. First, we introduce a programfeedback graph, which connects symbols relevant to program repair in source code and diagnostic feedback, and then apply a graph neural network on top to model the reasoning process. Second, we present a self-supervised learning paradigm for program repair that leverages unlabeled programs available online to create a large amount of extra program repair examples, which we use to pre-train our models. We evaluate our proposed approach on two applications: correcting introductory programming assignments (DeepFix dataset) and correcting the outputs of program synthesis (SPoC dataset). Our final system, DrRepair, significantly outperforms prior work, achieving 68.2% full repair rate on DeepFix (+22.9% over the prior best), and 48.4% synthesis success rate on SPoC (+3.7% over the prior best).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Automatic program repair has the potential to dramatically improve the productivity of programming. In particular, a common source of program errors are compiler errors, which include use of unresolved symbols, missing delimiters (e.g. braces), and type errors. These errors are commonly observed in both beginner programmers <ref type="bibr" target="#b23">(Parihar et al., 2017)</ref> and professional developers <ref type="bibr" target="#b29">(Seo et al., 2014)</ref>, as well as in the predicted code of program synthesis <ref type="bibr" target="#b19">(Kulal et al., 2019)</ref>. Accordingly, the use of machine learning in fixing compiler </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Program with errors</head><p>(`char` should be `string` instead in line 5) Example taken from SPoC dataset ( 909A-45398788.cpp ) line 9:error: request for member 'size' in 'a', which is of non-class type 'char' errors has garnered significant interest recently <ref type="bibr" target="#b10">(Gupta et al., 2017;</ref><ref type="bibr" target="#b13">Hajipour et al., 2019;</ref><ref type="bibr" target="#b21">Mesbah et al., 2019)</ref>.</p><p>In this work, we consider the problem of learning to repair programs based on diagnostic feedback (compiler error messages). <ref type="figure" target="#fig_0">Figure 1</ref> illustrates the setup. Given a broken program and diagnostic feedback, we aim to localize an erroneous line in the program and generate a repaired line. Learning program repair has two major challenges: First, the system needs to connect and jointly reason over the broken source code and the diagnostic feedback <ref type="bibr" target="#b9">(Fitzgerald et al., 2008)</ref>. Second, existing works rely on manual effort to curate labeled datasets for program repair (e.g. broken program, fixed program pairs), which does not scale up <ref type="bibr" target="#b21">(Mesbah et al., 2019)</ref>. Here we present DrRepair, a novel approach to program repair that addresses these two challenges. Our key innovations are two-fold: 1) modeling of program repair with program-feedback graphs and 2) self-supervised learning with unlabeled programs.</p><p>Program-feedback graph. Program repair requires reasoning jointly over the symbols (e.g. identifiers, types, operators) across source code and diagnostic feedback. For instance, in the example given in <ref type="figure" target="#fig_0">Fig. 1</ref>, while the compiler message points to line 9, the error is related to the type of identi-arXiv:2005.10636v2 [cs.SE] 30 Jun 2020</p><p>Graph-based, Self-Supervised Program Repair from Diagnostic Feedback fier 'a', and one needs to track how 'a' has been used or declared earlier to resolve this error. To formalize this reasoning process, we propose a joint graph representation of a program and diagnostic feedback that captures the underlying semantic structure of symbols in the context of program repair (program-feedback graph). Specifically, it takes all identifiers (e.g. a, b) in the source code and any symbols in the diagnostic arguments (e.g. a, char) as nodes, and connects instances of the same symbols with edges to encode the semantic correspondence <ref type="figure" target="#fig_1">(Fig. 2)</ref>. We then design a neural net model with a graph-attention mechanism (Velikovi et al., 2018) on the program-feedback graph to model the symbol tracking process described above. While prior works in program repair purely apply sequence-to-sequence (seq2seq) models to programs <ref type="bibr" target="#b10">(Gupta et al., 2017;</ref><ref type="bibr" target="#b13">Hajipour et al., 2019)</ref> or rely on the program's Abstract Syntax Tree (AST) representations <ref type="bibr" target="#b21">(Mesbah et al., 2019;</ref><ref type="bibr" target="#b31">Tarlow et al., 2019)</ref>, our program-feedback graph directly connects symbols involved in the reasoning process of program repair, and allows efficient information flow across them.</p><p>Self-supervised learning. Motivated by the vast amount of program data available online (e.g. GitHub has 28 million public repositories), we propose a self-supervised learning paradigm for program repair that leverages unlabeled programs to create a large amount of extra training data. Specifically, we collect working programs from online resources related to our problem domain (programming contests in our case), and design a procedure that corrupts a working program into a broken one, thereby generating new examples of broken program, fixed program . In our experiments, we prepare extra data ∼10 times the size of original datasets in this way, use it to pre-train our models, and fine-tune on the target task. We also describe an effective corruption procedure that covers a diverse set of errors. While prior works in program repair rely on labeled datasets <ref type="bibr" target="#b21">(Mesbah et al., 2019;</ref><ref type="bibr" target="#b31">Tarlow et al., 2019;</ref><ref type="bibr" target="#b19">Kulal et al., 2019)</ref>, we are the first to present a self-supervised learning method for program repair that leverages unlabeled programs online.</p><p>We evaluate the efficacy of our proposed approach on two applications, using publicly available datasets: a) Correcting introductory programming assignments. We use DeepFix dataset <ref type="bibr" target="#b10">(Gupta et al., 2017)</ref>, where the task is to repair broken C programs submitted by students. b) Correcting the output code in program synthesis. We use the SPoC dataset <ref type="bibr" target="#b19">(Kulal et al., 2019)</ref>, where the task is to translate pseudocode into C++ implementation, and programs synthesized by prior models (seq2seq) often fail to compile. We apply our repair model to correct the candidate programs generated in this task. Experimental results show that our approach (DrRepair) outperforms prior work significantly, achieving 68.2% full repair on the DeepFix test set (+22.9% absolute over the prior best), and 48.4% synthesis success rate on the SPoC  test set (+3.7% absolute over the prior best at the time of this work). Additionally, our analysis shows that the use of a program-feedback graph is particularly helpful for fixing errors that require reasoning over multiple lines of code, and that self-supervised pre-training facilitates the learning of program repair for the types of errors with fewer training examples in the original dataset. <ref type="figure" target="#fig_0">Figure 1</ref> illustrates the program repair task. The system is given (a) a broken program with L lines, x = (x 1 , ..., x L ), and (b) diagnostic feedback provided by a compiler, f = (i err , m err ), where i err denotes the reported line number, and m err the error message (a sequence of tokens). If the compiler returns multiple error messages, we use only the first one. 1 Our task is to identify the index of an erroneous line k ∈ {1, . . . , L} (error localization), and generate a repaired version of the line y k (repair). Let y = y 1:L denote the fixed version of the full program (y i = x i for i = k).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Problem statement</head><p>In the example given in <ref type="figure" target="#fig_0">Figure 1</ref>, x 5 = " char tmp, a, b; ", i err = 9, m err = " request for ... type char ", and k = 5, y k =" string tmp, a, b; ". Note that the line number reported by a compiler (i err ) does not necessarily match the line we need to repair (k).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Approach</head><p>We approach program repair from two angles. First, we propose a program-feedback graph to model the reasoning process involved in program repair. Second, we introduce a self-supervised learning paradigm that leverages unlabeled programs to create a large amount of extra training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Modeling</head><p>To model program repair, we start off with a sequence-tosequence learning setup, and incorporate the information of </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Program-Feedback Graph</head><p>Multi-Head Attention a program-feedback graph through a graph attention model, which we describe below. Given an input program x 1:L and its feedback f = (i err , m err ), we first tokenize each line x i and the compiler message m err into a sequence of symbols:</p><formula xml:id="formula_0">x i = (x i1 , x i2 , .</formula><p>..) and m err = (m 1 , m 2 , ...). As seen in our motivating example in <ref type="figure" target="#fig_0">Fig. 1</ref>, program repair requires reasoning and tracking symbols across different lines of code and compiler messages (e.g., given the compiler error about 'a', a programmer will jump to the source code line reported by the message, and then track how 'a' has been used/declared in earlier lines). These long-range dependencies of tokens are difficult to capture using previous seq2seq or AST-based models, which only propagate information locally at the line or syntax level <ref type="bibr" target="#b10">(Gupta et al., 2017;</ref><ref type="bibr" target="#b21">Mesbah et al., 2019)</ref>. To enable more efficient information flow, we introduce a program-feedback graph G that directly connects tokens relevant to the reasoning of program repair.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1.">Program-feedback graph</head><p>A program-feedback graph G = (V, E) has nodes V that consist of tokens in the diagnostic arguments (those within ' ' in the message, i.e., size, a, char in <ref type="figure" target="#fig_1">Fig. 2)</ref>, their occurrences in the source code, and all remaining identifiers in the code (e.g. a, b, i, j). The type of each token, such as identifier (for a), operator (for =) and data type (for char), is recognized by the C/C++ tokenizer in <ref type="bibr" target="#b10">Gupta et al. (2017)</ref>.</p><p>We then form the graph by connecting identical tokens in V with undirected edges (E) to capture the semantic correspondence. The resulting graph is as a set of cliques, one for each symbol (e.g. 'a'). We keep the program-feedback graph simple for two reasons: 1) we use the graph and graph-attention to specifically capture the (long-range) connections of tokens crucial to program repair reasoning, and perform other local information propagation via LSTMs (we elaborate in §3.1.2), and 2) it is nontrivial to analyze the code further (e.g. parsing) to add information to the graph, as the program can be syntactically ill-formed. Compared to AST-based graph representations <ref type="bibr" target="#b1">(Allamanis et al., 2018;</ref><ref type="bibr" target="#b31">Tarlow et al., 2019)</ref>, our program-feedback graph is more relaxed and robust to errors in source code. <ref type="figure" target="#fig_2">Fig. 3</ref> illustrates our program repair model. It has an encoder that takes in a program x and feedback f , and a decoder that predicts a distribution over which line is erroneous k and a repaired line y k . The encoder has three stages: 1) initial encoding h = InitEnc(x, f ) which encodes each input token at the line level, 2) graph attention g = GraphAttn(h) which propagates information across tokens on a program-feedback graph, and 3) recontextualization s = ReContext(g) which contextualizes token representations at the line level again to produce an embedding s i for each line i. Finally, Decode(s) outputs a distribution over the erroneous line index and a repaired line (k, y k ). We describe each of the model stages in detail below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">Model architecture</head><p>Initial encoding. Given source code x 1:L and feedback f = (i err , m err ) ( <ref type="figure" target="#fig_2">Fig. 3 bottom)</ref>, we encode each line x i and compiler message m err with two bidirectional LSTM networks <ref type="bibr" target="#b14">(Hochreiter &amp; Schmidhuber, 1997)</ref>, LSTM (1) code and LSTM (1) msg . For the tokens in the source code, we also inject the information of the reported line index (i err ) by concatenating the outputs of LSTM (1) code with the positional encoding <ref type="bibr" target="#b33">(Vaswani et al., 2017)</ref> of the line offset ∆i = i err −i, and applying a feedforward network. We denote the representation of each token in the code and message at this point as h xij and h m , respectively. This stage is analogous to the input encoding in <ref type="bibr" target="#b19">Kulal et al. (2019)</ref>.  <ref type="table">Table 1</ref>. Analysis of common compiler errors in three settings: experienced developers (DeepDelta), beginner programmers (DeepFix), and predicted code of program synthesis (SPoC). For DeepDelta, the statistics is taken from <ref type="bibr" target="#b21">Mesbah et al. (2019)</ref>. The rightmost column shows the program perturbation modules that we design to generate corresponding types of errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Program with errors</head><p>Graph attention. Next, to model the reasoning (symbol tracking) process in program repair, we use a graph attention network <ref type="bibr" target="#b34">(Velikovi et al., 2018)</ref> to allow information to flow across symbols in the program-feedback graph G <ref type="figure" target="#fig_2">(Fig. 3  right)</ref>. In a N -layer graph attention network, each layer computes contextualized representations of tokens via</p><formula xml:id="formula_1">c n = Attention G (h n−1 ) (1) h n = MLP([h n−1 ; c n ])<label>(2)</label></formula><p>where h n−1 , h n denote the input/output representation of each token at the n-th layer. Initially, h 0 is h xij or h m , and the final output g = h N . Attention G (h t ) computes attention weights over the neighboring nodes of a token t on the graph G, N G (t), and takes the weighted average of the token representations among N G (t). MLP is a feedforward network. For a more detailed description about graph attention, we refer readers to <ref type="bibr" target="#b34">Velikovi et al. (2018)</ref>.</p><p>Recontextualization. We allow the information updated via the graph to propagate on the local context again, by passing the token representations g to additional sequence networks, LSTM (2) code and LSTM (2) msg . We obtain an embedding of each line i by concatenating their final hidden states,</p><formula xml:id="formula_2">r i = LSTM (2) code (g xi· ) final ; LSTM (2) msg (g m· ) final<label>(3)</label></formula><p>which is further contextualized to be the final line embedding s i , via s 1:L = LSTM (3) code (r 1:L ) ( <ref type="figure" target="#fig_2">Fig. 3 top)</ref>. Decoding. Given the line embeddings s 1:L , we model the probability of a line k ∈ {1, . . . , L} being erroneous via a feedforward network, and model its repair y k , via a pointer-generator decoder <ref type="bibr" target="#b28">(See et al., 2017)</ref>:</p><formula xml:id="formula_3">p(k | s 1:L ) = softmax(MLP(s 1:L )) (4) p(y k | s 1:L ) = PtrGen(s k ).<label>(5)</label></formula><p>Training. A training example consists of a broken program x, feedback f , an erroneous line index k, and the repaired line y k . The loss on a given example is the standard negative log-likelihood, − log p(k, y k | x, f ). The error localization   and repair components are learned jointly. In §3.2 and §4.1, we will discuss how we generate training examples of this form for pre-training and target applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Program with errors</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Self-supervised learning</head><p>Labeled datasets for program repair ( x, y pairs) are limited in size (10-100K data points) <ref type="bibr" target="#b21">(Mesbah et al., 2019)</ref>, but there is a vast amount of unlabeled programs available online: for instance, GitHub 2 alone has 28 million public repositories as of 2019. Can we leverage this freelyavailable code to improve the learning of program repair?</p><p>With this motivation, we propose a new self-supervised learning paradigm that utilizes unlabeled, working programs to create a large amount of training data for program repair. Specifically, we first collect a large set of working programs y's (ones that compile, in our setting), related to the domain of interest. We design a randomized procedure P that automatically corrupts y into a broken program x to generate a new training example broken code x, ground-truth y . We repeatedly apply this procedure to the collected programs, and use the generated training data to perform pre-training <ref type="bibr" target="#b7">(Erhan et al., 2010)</ref> of our model, facilitating it to learn useful representations for program repair (self-supervised pre-training). Later, we fine-tune the model on a labeled, original (in-domain) dataset.</p><p>Below, we describe the details of our program corruption and data generation process.</p><p>Program corruption procedure. To design an effective corruption procedure that covers a diverse set of program errors, we first analyzed common compiler errors in three settings: experienced developers, beginner programmers, and predicted code of program synthesis. For each case, we collected statistics from <ref type="bibr" target="#b21">Mesbah et al. (2019)</ref>, DeepFix dataset <ref type="bibr" target="#b10">(Gupta et al., 2017)</ref> and SPoC dataset <ref type="bibr" target="#b19">(Kulal et al., 2019)</ref>, and grouped the errors into four major categories: "Expected...", "Type/declaration conflict", "Identifier undeclared", and "Others" (details in <ref type="table">Table 1</ref>).</p><p>Motivated by this analysis, we design a set of perturbation modules (heuristics), M, that aim to modify source code to cause the above types of errors. Specifically, M consists of • Syntax, which randomly deletes, inserts or replaces an operator / punctuation, such as ,.;(){}[]"++&lt;&lt;. This module causes various errors such as "expected @@@". • ID-type, which randomly deletes, inserts or replaces an identifier (ID) type such as int, float, char. This causes errors such as conflicting types and redeclaration. • ID-typo, which randomly deletes, inserts or replaces an identifier. This module causes errors such as missing primary expressions and undeclared identifiers. • Keyword, which randomly deletes, inserts or replaces a use of program language keyword or library function, such as if and size(). This module can cause other miscellaneous errors. <ref type="table" target="#tab_5">Table 2</ref> provides concrete examples of each module. Note that each module makes a single change to source code at a time. Given the perturbation modules M, our program corruption procedure (named DrPerturb) samples 1-5 modules from M (with replacement) and applies them to an input program sequentially. We sample each module with probability 0.3, 0.5, 0.15, 0.05, respectively, motivated by the distribution of errors found in our analysis <ref type="table">(Table 1)</ref>.</p><p>We will show in our experiments that DrPerturb is significantly more effective than baseline corruption procedures such as randomly deleting tokens.</p><p>Data preparation details. As the program domain in our applications (DeepFix, SPoC) is C/C++ implementation of introductory algorithms, we turn to programs available on codeforces.com, which contains C++ code submitted by programming contest participants. We collect accepted programs and filter out outliers (e.g. those longer than 100 lines), following the procedure in <ref type="bibr" target="#b19">Kulal et al. (2019)</ref>. This yields 310K C++ programs that compile successfully, which is roughly 10 times the size of the original training data available in our applications <ref type="bibr">(37,</ref><ref type="bibr">415 programs in DeepFix,</ref><ref type="bibr">14,</ref><ref type="bibr">784 in SPoC)</ref>. For each program, we then create roughly 50 corrupted versions by applying DrPerturb and keeping ones that fail to compile. This yields ∼1.5M extra training examples of broken code x, feedback f , correct code y , which we use to pre-train our program repair model.</p><p>Note that the collected program data share the same source with SPoC (codeforces.com), 3 but not exactly with Deep-Fix, which is C programming assignments. Nevertheless, we find that the collected data is highly effective in both tasks, which we elaborate on in §4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>We conduct an extensive evaluation of our approach via two applications: DeepFix 4 <ref type="bibr" target="#b10">(Gupta et al., 2017)</ref> and SPoC 5 <ref type="bibr" target="#b19">(Kulal et al., 2019)</ref>, which are recent benchmarks for program repair and program synthesis, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental setup</head><p>We summarize the setup of DeepFix and SPoC, and describe how we apply our program repair model to those tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1.">DeepFix</head><p>Task. The DeepFix dataset contains C programs submitted by students in an introductory programming course, of which 37,415 are correct (compile) and 6,971 are broken (do not compile). The average program length is 25 lines. The broken programs are called raw test set and may contain multiple errors. The task is to repair them into ones that compile (full repair; evaluation metric is full repair rate).</p><p>Data processing. To generate training/dev data for repair models, we corrupt the correct programs in DeepFix using DrPerturb. We call this the synthetic data, as apposed to the raw test set. We also call this the original train/dev data to distinguish it from the extra data prepared for pre-training, which is not exactly in the same domain as DeepFix.</p><p>How to apply the repair model. At test time, as the broken programs may contain errors in multiple lines, we apply the repair model iteratively until the program compiles or we reach the attempt limit of 5, as in <ref type="bibr" target="#b10">Gupta et al. (2017)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2.">SPoC</head><p>Task. The SPoC dataset consists of 18,356 C++ programs (avg. length 15 lines) collected from codeforces.com. For each program t = t 1:L (with L lines), every line of code is annotated with natural language pseudocode, s 1:L . The task is to synthesize the target program t from pseudocode DeepFix <ref type="bibr" target="#b10">(Gupta et al., 2017)</ref> --27.0 * RLAssist <ref type="bibr" target="#b12">(Gupta et al., 2019b)</ref> --26.6 * SampleFix <ref type="bibr" target="#b13">(Hajipour et al., 2019)</ref>   </p><formula xml:id="formula_4">t = concat L i=1 t ici , p(t) = L i=1 p ici ,<label>(6)</label></formula><p>where c i is to be searched for each line i. <ref type="bibr" target="#b19">Kulal et al. (2019)</ref> then considers various search algorithms (e.g. best first search using the score) to efficiently find the correct program t from this space of candidates.</p><p>Why &amp; how to apply the repair model. As <ref type="bibr" target="#b19">Kulal et al. (2019)</ref> observed, the top candidates produced by this scoring metric exhibited syntactic or semantic incoherence (e.g. conflicting types) and fail to compile, because each candidate score p ici is calculated by line-level translation of pseudocode, ignoring the global context. To address this issue, <ref type="bibr" target="#b19">Kulal et al. (2019)</ref> combined best first search with error localization; here we propose a search algorithm that also follows best first search, but attempts to repair the current candidate program with our repair model if it does not compile, and adds the repaired code piece t ic i into the pool of candidate code pieces C i , with an updated score p ic i .</p><p>Data processing. We follow the data splits in <ref type="bibr" target="#b19">Kulal et al. (2019)</ref>, which consists of Train, Dev, TestP, and TestW. We use TestP / TestW for the final evaluation of program synthesis, and use Train/Dev to train or validate our repair model. To prepare train/dev data for the repair model, for  <ref type="bibr" target="#b19">(Kulal et al., 2019)</ref> 28  each program y = y 1:L in SPoC, we sample an error line index k and substitute line y k with a candidate c kj ∈ C k generated from pseudocode line s k . We then collect any modified program y that produces a compiler error f . We call this original train/dev data, to distinguish with the extra data prepared for pre-training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Hyperparameters &amp; training details</head><p>We set the dimension of input token embeddings and position embeddings to be 200 and 100. The LSTMs and graph attention networks have a state size of 200. We use 3, 2, 1 and 2 layers for LSTM (1) , graph attention net, LSTM <ref type="bibr">(2)</ref> and LSTM (3) , respectively, with dropout rate 0.3 applied to each layer <ref type="bibr" target="#b30">(Srivastava et al., 2014)</ref>. The parameters of the models are optimized by Adam <ref type="bibr" target="#b17">(Kingma &amp; Ba, 2015)</ref>, with batch size 25, learning rate 0.0001, and gradient clipping 1.0 <ref type="bibr" target="#b24">(Pascanu et al., 2012)</ref>, on a GPU (GTX Titan X).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Results</head><p>We describe our main results on DeepFix and SPoC here. We use "base" to denote the version of our model that replaces graph attention with line-level LSTM layers (a pure sequence model), and "base + graph" the one with graph attention. We train these models on the original data (from DeepFix/SPoC) only. "base+graph+pre-train" denotes a "base+graph" model that is pre-trained with self-supervision on the extra data and fine-tuned on the original data.</p><p>DeepFix. <ref type="table" target="#tab_7">Table 3</ref> describes the performance of our re-  <ref type="table">Table 6</ref>. Effect of different program corruption procedures. We train repair models using different program corruption methods (our DrPerturb, <ref type="bibr" target="#b10">Gupta et al. (2017)</ref>'s, and random token dropout), and evaluate the trained models on the DeepFix raw test set (full repair rate %). Bold score indicates the best corruption algorithm.</p><p>pair model along with prior work. "Single Repair" column shows the accuracy of repairing a single line (single step) on the synthetic dev set, and "Full Repair" column shows the full repair acc. on the raw test set, where our repair model is run iteratively ( §4.1.1). First, we observe that our base model ("our base" row) achieves 62.5% full repair acc., which outperforms prior works (those above the dashed line) by 15% absolute. We hypothesize that this is because our model uses compiler messages as input, but prior works do not (they consider direct mapping of broken code into its fix). To understand the importance of using compiler messages for program repair, we experimented with a version of our model that does not use compiler messages ("our base, no compiler message"). We find that while it attains comparable scores to "our base" on the synthetic dev, the performance drops a lot on the raw test set: 34.0% acc., similar to the prior work (30-40% acc.). This suggests that diagnostic feedback offered by compiler messages plays a crucial role in learning program repair, and without it, the model tends to learn superficial patterns present in the synthetic train/dev data (hence the high scores on dev).</p><p>Next, we find that our program-feedback graph ("base + graph") provides a 3% boost over "base" in full repair rate, and self-supervised pre-training ("base + graph + pre-train") provides a further improvement of 2%, suggesting that both the program-feedback graph and self-supervision provide complementary improvements. Consequently, with the use of compiler messages, graph and pre-training, our full system DrRepair ("base + graph + pre-train") improves on the prior best (SampleFix) by 22.9% in total, achieving a state-of-the-art result of 68.2% full repair rate.</p><p>SPoC. Similar to DeepFix, we measure the single step repair accuracy on the SPoC dev set <ref type="table" target="#tab_8">(Table 4</ref>). The use of graph and pre-training both improve the repair performance (4.4% and 3.2% respectively; first three rows). As the SPoC task contains pseudocode, we also experimented with a version of our repair model that takes in pseudocode as input in addition to the broken code and compiler message. This provides a further boost in performance, achieving 68% single repair acc. on SPoC dev set (bottom row).</p><p>We then apply our repair model to the program synthesis setting (TestP, TestW), as described in §4.1.2. As seen in <ref type="table" target="#tab_11">Table 5</ref>, our synthesis method equipped with DrRepair (bottom row) improves on the best first search significantly (e.g. +6% on TestP/TestW budget 100), suggesting that our repair model is useful for program synthesis as well.</p><p>We note that a concurrent work <ref type="bibr" target="#b41">(Zhong et al., 2020)</ref> uses semantic constraints of programs to improve the search and achieves state-of-the-art results (46.1% / 62.8% on TestP / TestW). In contrast, our method only requires blackbox access to a compiler or executor. We believe the two approaches are complementary and it would be interesting to combine the approaches.</p><p>Example &amp; Visualization. <ref type="figure" target="#fig_0">Figure 1</ref> gives a real example of the output of "base+graph", as well as visualization of graph attention, where the pink highlighting in the source code shows the computed attention weights w.r.t. the 'a' in the compiler message (the darker, the higher). It indicates that the model attends not only to the line reported by compiler (line 9), but also to the line that declared 'a', which is the source of the error. This way, we can interpret the reasoning performed by our repair model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Analysis</head><p>We aim to understand 1) the effect of different program corruption procedures and 2) graph representation methods, and 3) when self-supervision or graph is useful.</p><p>Different program corruption procedures. We compare DrPerturb ( §3.2) with alternative program corruption procedures: Gupta+17, the original DeepFix work that corrupts delimiters or drops variable declarations only (so a subset of our Syntax and ID-typo module), and Random, a baseline that randomly drops tokens. We apply DrPerturb, Gupta+17, Random on the DeepFix data to create corresponding training sets (containing 156, 113, 170 types of compiler errors respectively). We then evaluate repair models trained on each of those training sets on the DeepFix raw test set <ref type="table">(Table  6</ref>). We find that models trained by DrPerturb significantly outperform Gupta+17 (+10% repair rate), suggesting that the diverse set of errors covered by DrPerturb is useful. Additionally, while Random produces more distinct types of compiler errors than DrPerturb in terms of the number (170 vs 156), models trained by DrPerturb outperform Random by more than 10%, suggesting that DrPerturb generates a more useful distribution of errors than the Random baseline. from ``base''. Those compiler errors typically require analyses of multiple lines of code, suggesting the usefulness of program-feedback graph in fixing such errors.</p><p>A bolded score in the ``+graph +pretrain'' column indicates a particularly big improvement from ``+graph''. We observe that those compiler errors were relatively rare in the original training data of SPoC and self-supervised pre-training is especially helpful in those cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Compiler message type</head><p>Frequency in original train data <ref type="bibr">(SPoC)</ref> Repair acc. <ref type="bibr">(SPoC dev)</ref>   Bold score indicates a particularly big improvement from "base" to "+ graph" or from "+ graph" to "+ graph + pretrain".</p><p>Different graph representations. <ref type="table">Table 7</ref> shows an ablation study for the architecture of program-feedback graph. We find that the edges connecting symbols in source code ("edges among code only" row), and the edges spanning across source code and a compiler message ("edges across code-feedback only" row) are equally important, and the final program-feedback graph ("final" row) is the most effective. We also experimented with a version of our model that uses self-attention (i.e. we consider the complete graph), which we find comparable or slightly less effective ("selfattention" row). This suggests that the most important edges in the graph are those in our program-feedback graph, which connect symbols with semantic correspondence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>When is graph &amp; self-supervision useful?</head><p>We study what kinds of compiler errors a program-feedback graph or self-supervised pre-training is most useful for fixing. <ref type="table" target="#tab_15">Table  8</ref> shows the breakdown of major compiler errors seen in the SPoC dev set (left), and the repair accuracy of our model variants for each error type (right). We used the SPoC data as it exhibited more diverse errors than DeepFix.</p><p>We observe that the use of program-feedback graph is particularly helpful for compiler errors such as "@@@ was not declared" and "request for member @@@..." (those with bold scores in the "+graph" column), which typically require analyses of multiple lines of code (recall our example in <ref type="figure" target="#fig_0">Fig. 1</ref>). This suggests that a program-feedback graph indeed allows better information flow across source code lines and compiler messages, compared to the baseline sequence model ("base"). Additionally, we observe that self-supervised pre-training improves repair accuracy across most of the error types, but is noticeably helpful for errors that were relatively rare in the original training data (e.g. the bottom two), for which the use of a program-feedback graph only helped a little. This suggests that the extra training examples created in our self-supervision method help mitigate such data scarcity issues in original training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Related work and discussion</head><p>Graph neural networks. Graph neural nets (GNN), such as graph attention net <ref type="bibr" target="#b34">(Velikovi et al., 2018)</ref>, graph convolutional net <ref type="bibr" target="#b18">(Kipf &amp; Welling, 2017)</ref>, graph isomorphism net <ref type="bibr" target="#b37">(Xu et al., 2019)</ref> have been shown to be effective for modeling graph-based data. Several works use GNNs to model the structure of text <ref type="bibr" target="#b38">(Yasunaga et al., 2017;</ref><ref type="bibr" target="#b39">Zhang et al., 2018)</ref> and more recently, source code <ref type="bibr" target="#b1">(Allamanis et al., 2018;</ref><ref type="bibr" target="#b3">Brockschmidt et al., 2019)</ref>. <ref type="bibr" target="#b1">Allamanis et al. (2018)</ref> present program graph that augments AST with data flow edges across variables, which is passed to GNNs to solve the task of variable name prediction. <ref type="bibr" target="#b3">Brockschmidt et al. (2019)</ref> build on it and design a graph-based generative model for source code. <ref type="bibr" target="#b11">Gupta et al. (2019a)</ref> propose a tree convolution model to encode ASTs. Distinct from the above works, we focus on the problem of program repair, and design the program-feedback graph to represent the dependencies between source code and diagnostic feedback.</p><p>Our results show that GNNs can fruitfully represent these program-feedback dependencies for program repair.</p><p>Self-supervised pre-training. The idea of using unlabeled data to pre-train neural networks has been shown effective across many fields, including computer vision <ref type="bibr" target="#b35">(Vincent et al., 2008;</ref><ref type="bibr" target="#b7">Erhan et al., 2010)</ref>, NLP <ref type="bibr" target="#b25">(Peters et al., 2018;</ref><ref type="bibr" target="#b5">Devlin et al., 2019)</ref>, graphs <ref type="bibr" target="#b15">(Hu et al., 2020)</ref>, and programming languages <ref type="bibr" target="#b8">(Feng et al., 2020)</ref>. Typically, the self-supervised pre-training objective is different from the target task: For instance, in image recognition, <ref type="bibr" target="#b35">Vincent et al. (2008)</ref> pretrain networks via a denoising autoencoder; in NLP, <ref type="bibr" target="#b5">Devlin et al. (2019)</ref> pre-train networks via masked language modeling and then fine-tune on a target task such as question answering. In contrast, our pre-training task is the program repair task (our target task), as we prepare the pre-training data by corrupting unlabeled programs and obtaining diagnostic feedback to synthesize program repair examples. Additionally, our pre-training task is conditioned on diagnostic feedback, which is a new type of structure from a pre-training perspective and provides better generalization at the test time as we show in §4.3.</p><p>Learning program repair. There is increasing interest in automatic correction of introductory programming assignments <ref type="bibr" target="#b27">(Pu et al., 2016;</ref><ref type="bibr" target="#b23">Parihar et al., 2017;</ref><ref type="bibr" target="#b0">Ahmed et al., 2018)</ref>. DeepFix <ref type="bibr" target="#b10">(Gupta et al., 2017)</ref> is an early work that uses a seq2seq model to translate a broken code into fixed one. RLAssist <ref type="bibr" target="#b12">(Gupta et al., 2019b)</ref>, SampleFix <ref type="bibr" target="#b13">(Hajipour et al., 2019)</ref> improve on it by introducing reinforcement learning or better sampling methods. While these works purely use sequence models, we propose to use a graph representation of source code and diagnostic feedback to capture long-range dependencies of symbols across them.</p><p>Another line of work learns from labeled datasets of how programmers edit code (e.g. error resolution records) <ref type="bibr" target="#b16">(Just et al., 2014;</ref><ref type="bibr" target="#b4">Chen et al., 2019)</ref>. <ref type="bibr" target="#b21">Mesbah et al. (2019)</ref> model a Java build error resolution record using seq2seq. <ref type="bibr" target="#b31">Tarlow et al. (2019)</ref> generalize it to more diverse error types, and propose a repair model that uses the graph structure of AST. <ref type="bibr" target="#b2">Bader et al. (2019)</ref> present a hierarchical clustering algorithm to learn program repair patterns. While these works rely purely on labeled datasets of program repair, we propose a self-supervised learning paradigm that leverages a large amount of unlabeled data to create extra training examples for program repair.</p><p>Finally, several works focus on repairing specific types of bugs, e.g., variable misuse <ref type="bibr" target="#b32">(Vasic et al., 2019)</ref>, name-based bugs <ref type="bibr" target="#b26">(Pradel &amp; Sen, 2018)</ref> and Javascript bugs <ref type="bibr" target="#b6">(Dinella et al., 2020)</ref>. Other works focus on modeling program execution <ref type="bibr" target="#b36">(Wang et al., 2018)</ref> or edits <ref type="bibr" target="#b40">(Zhao et al., 2019)</ref>. We refer readers to <ref type="bibr" target="#b22">Monperrus (2018)</ref> for a more comprehensive review of automated program repair.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>This paper makes two contributions to program repair from diagnostic feedback. First, we proposed the programfeedback graph to model the reasoning process in program repair. We find this particularly useful when the repair requires analyzing multiple lines of code. Second, we introduced a self-supervised learning paradigm that creates extra program repair examples by corrupting unlabeled programs and obtaining feedback from an evaluator (compiler). We find this effective for overcoming the scarcity of labeled data for program repair.</p><p>While we primarily focus on program repair in this paper, we note that our framework of learning to edit based on feedback is a potentially powerful and more general paradigm with many applications, from learning to edit essays based on written feedback, to learning from users in interactive dialogue, etc. <ref type="bibr" target="#b20">(Liu et al., 2018)</ref>. The key is that rather than using a single number reward (e.g. compile or not) as in reinforcement learning, obtaining high bandwidth feedback via diagnostic feedback can be much more informative if we incorporate it effectively, for instance through the use of graph neural networks as we presented in this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reproducibility</head><p>All code and data are available at https://github.com/ michiyasunaga/DrRepair. Experiments are available at https://worksheets.codalab.org/worksheets/ 0x01838644724a433c932bef4cb5c42fbd.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Given a broken program and diagnostic feedback (compiler error message), our goal is to localize an erroneous line and generate a repaired line.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Illustration of program-feedback graph, corresponding to the example in Fig. 1. The graph captures long-range dependencies of symbols to help model the reasoning process of program repair.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>DrRepair model. It takes in a program x = (x1, ..., xL) and diagnostic feedback from a compiler f = (ierr, merr) as inputs (bottom), encodes them via LSTM and graph attention layers, and decodes the error line index k and repaired code y k (top). The right-hand side illustrates the graph attention mechanism. Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>} → return 0; } } cout &lt;&lt; "YES"; → cout &lt;&lt; YES; min(s.size(), n) → min(s.size()), n) tmp = *a; → tmp = &amp;aID-type (deletion, insertion, replacement of type)for (int i=0; i&lt;n;) → for (i=0; i&lt;n;) k = k + 1; → int k = k + 1; string tmp; → char tmp;ID-typo (deletion, insertion, replacement of IDentifier)int a, b=0, m, n; → int a, m, n; string x,y,z; → string x,y,z,z; for (i=0; i&lt;n;) → for (j=0; i&lt;n;)Keyword (deletion, insertion, replacement of keyword/call)if (n &gt;= 0) → while (n &gt;= 0) l = s.length(); → l = s.;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Stanford University, Stanford, CA. Correspondence to: Michihiro Yasunaga &lt;myasu@cs.stanford.edu&gt;. Proceedings of the 37 th International Conference on Machine Learning, Vienna, Austria, PMLR 119, 2020. Copyright 2020 by the author(s).</figDesc><table><row><cell></cell><cell>LSTM</cell><cell></cell><cell></cell><cell></cell></row><row><cell>LSTM</cell><cell>LSTM</cell><cell></cell><cell></cell><cell></cell><cell>Evaluator (compiler)</cell></row><row><cell>LSTM</cell><cell>LSTM</cell><cell></cell><cell cols="3">(`char` should be `string` instead in line 5) 1 #include &lt;bits/stdc++.h&gt;</cell><cell>Feedback</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">2 #include &lt;string&gt;</cell></row><row><cell>LSTM</cell><cell>LSTM LSTM</cell><cell></cell><cell cols="3">3 using namespace std; 4 int main() { 5 char tmp, a , b; 6 map&lt;string,int&gt; mp; 7 cin &gt;&gt; a &gt;&gt; b; 8 int i, j;</cell><cell>line 9:error: request for member 'size' in 'a', which is of non-class type 'char'</cell><cell>Sourc 4 in 5 c</cell></row><row><cell></cell><cell></cell><cell></cell><cell>9</cell><cell></cell><cell>for (i = 0; i &lt; a .size(); i++){</cell><cell>6 m</cell></row><row><cell></cell><cell>LSTM</cell><cell></cell><cell>10 11</cell><cell></cell><cell>tmp.push_back( a [i]); string tmp1 = tmp;</cell><cell>7 c</cell></row><row><cell></cell><cell></cell><cell></cell><cell>12</cell><cell></cell><cell>for (j = 0; j &lt; b.size(); j++){</cell><cell>8 i</cell></row><row><cell></cell><cell></cell><cell></cell><cell>13 14 15 16 17</cell><cell></cell><cell>tmp1.push_back(b[j]); mp[tmp1] = 1; map&lt;string,int&gt;::iterator it; } }</cell><cell>Dr Repair (our model) 1. Error localized line 5</cell><cell>9 f 10 11</cell></row><row><cell>1. Localize error: line 5 Goal</cell><cell></cell><cell></cell><cell cols="2">18 19 20 }</cell><cell>it = mp.begin(); cout &lt;&lt; it.first &lt;&lt; endl;</cell><cell>→ string tmp, a, b; char tmp, a, b; 2. Repair</cell><cell>.</cell></row><row><cell>2. Edit</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>char tmp, a, b;</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Example taken from SPoC dataset</cell></row><row><cell cols="2">→ string tmp, a, b;</cell><cell></cell><cell></cell><cell></cell><cell>( 909A-45398788.cpp )</cell></row><row><cell></cell><cell></cell><cell cols="4">1 #include &lt;bits/stdc++.h&gt;</cell></row><row><cell></cell><cell></cell><cell cols="4">2 #include &lt;string&gt;</cell></row><row><cell></cell><cell></cell><cell cols="4">3 using namespace std;</cell></row><row><cell></cell><cell></cell><cell cols="4">4 int main() {</cell></row><row><cell></cell><cell></cell><cell>5</cell><cell cols="3">char tmp, a , b;</cell></row><row><cell></cell><cell></cell><cell>6</cell><cell cols="3">map&lt;string,int&gt; mp;</cell></row><row><cell></cell><cell></cell><cell>7</cell><cell cols="3">cin &gt;&gt; a &gt;&gt; b;</cell></row><row><cell></cell><cell></cell><cell>8</cell><cell cols="2">int i, j;</cell></row><row><cell></cell><cell></cell><cell>9</cell><cell cols="3">for (i = 0; i &lt; a .size(); i++){</cell></row><row><cell></cell><cell></cell><cell>10</cell><cell cols="3">tmp.push_back( a [i]);</cell></row><row><cell></cell><cell></cell><cell>11</cell><cell cols="3">string tmp1 = tmp;</cell></row><row><cell></cell><cell></cell><cell>12</cell><cell cols="3">for (j = 0; j &lt; b.size(); j++){</cell></row><row><cell></cell><cell></cell><cell>13</cell><cell cols="3">tmp1.push_back(b[j]);</cell></row><row><cell></cell><cell></cell><cell>14</cell><cell cols="3">mp[tmp1] = 1;</cell></row><row><cell></cell><cell></cell><cell>15</cell><cell>}</cell><cell></cell></row><row><cell></cell><cell></cell><cell>16</cell><cell>}</cell><cell></cell></row><row><cell></cell><cell></cell><cell>17</cell><cell cols="3">map&lt;string,int&gt;::iterator it;</cell></row><row><cell></cell><cell></cell><cell>18</cell><cell cols="3">it = mp.begin();</cell></row><row><cell></cell><cell></cell><cell>19</cell><cell cols="3">cout &lt;&lt; it.first &lt;&lt; endl;</cell></row><row><cell></cell><cell></cell><cell>20 }</cell><cell></cell><cell></cell></row><row><cell>Error type</cell><cell>Common compiler messages</cell><cell cols="2">Statistics DeepDelta DeepFix SPoC</cell><cell cols="2">Avg.</cell><cell>Relevant auto-corruption module (our proposal)</cell></row><row><cell cols="2">redeclaration/conflicting declaration @@@</cell><cell></cell><cell></cell><cell></cell></row></table><note>1Expected ...• operator/punctuator• primary expression expected @@@ (e.g. expected ';' before..., expected '}' at end of input, expected primary-expression before...) missing @@@ (e.g. terminating " character) 9% 48%• 37%• 11% 35%• 29%• 6% 30%• 23%• 7% Syntax (deletion, insertion, replacement of op/punc) ID-typo (deletion, insertion of IDentifier)</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>→ string tmp, a, b; Source code</head><label></label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Source code</cell><cell>Feedba (compiler m</cell></row><row><cell cols="3">4 int main() { 5 char tmp, a, b; a char b 6 map&lt;string,int&gt; mp; 7 cin &gt;&gt; a &gt;&gt; b; a b</cell><cell></cell><cell cols="2">Compiler message request for member 'size ' in 'a', which is of 'a' size</cell><cell>Source code</cell></row><row><cell cols="4">8 int i, j; 9 for (i = 0; i &lt; a .size () ... 10 tmp.push_back(a [i]); 11 string tmp1 = tmp; ... a a size</cell><cell cols="2">non-class type 'Char ' char</cell><cell>8 int i, j; 4 int main() { 5 char tmp, a, b; a char b 6 map&lt;string,int&gt; mp; 7 cin &gt;&gt; a &gt;&gt; b; a b</cell><cell>non-class type Compiler message request for member 'size ' in 'a', which is of 'a' size</cell></row><row><cell></cell><cell></cell><cell cols="3">Program-Feedback Graph</cell><cell>9 for (i = 0; i &lt; a .size () ... a size</cell><cell>'Char ' char</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>10 tmp.push_back(a [i]); a</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>11 string tmp1 = tmp;</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>...</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Program-Feedback Graph</cell></row><row><cell></cell><cell cols="2">Source code</cell><cell></cell><cell></cell><cell>Compiler message</cell></row><row><cell></cell><cell cols="2">4 int main() {</cell><cell></cell><cell></cell><cell>request for</cell></row><row><cell></cell><cell cols="3">5 char tmp, a, b;</cell><cell></cell><cell>member 'size' in</cell></row><row><cell></cell><cell cols="3">6 map&lt;string,int&gt; mp;</cell><cell></cell><cell>'a', which is of</cell></row><row><cell></cell><cell cols="3">7 cin &gt;&gt; a &gt;&gt; b;</cell><cell></cell><cell>non-class type</cell></row><row><cell></cell><cell cols="2">8 int i, j;</cell><cell></cell><cell></cell><cell>'char'</cell></row><row><cell></cell><cell cols="4">9 for (i = 0; i &lt; a.size() ...</cell></row><row><cell></cell><cell>10</cell><cell cols="3">tmp.push_back(a[i]);</cell></row><row><cell></cell><cell>11</cell><cell cols="2">string tmp1 = tmp;</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">Program-Feedback Graph</cell></row><row><cell>Program with errors</cell><cell></cell><cell cols="3">Evaluator (compiler)</cell></row><row><cell cols="2">hould be `string` instead in line 5)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>ude &lt;bits/stdc++.h&gt;</cell><cell></cell><cell cols="2">Feedback</cell><cell></cell></row><row><cell>ude &lt;string&gt; namespace std; ain() { r tmp, a , b; &lt;string,int&gt; mp;</cell><cell></cell><cell cols="3">line 9:error: request for member 'size' in 'a', which is of non-class type 'char'</cell></row><row><cell>&gt;&gt; a &gt;&gt; b;</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>i, j;</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">(i = 0; i &lt; a .size(); i++){</cell><cell></cell><cell></cell><cell></cell></row><row><cell>mp.push_back( a [i]);</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>tring tmp1 = tmp;</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">or (j = 0; j &lt; b.size(); j++){</cell><cell></cell><cell></cell><cell></cell></row><row><cell>tmp1.push_back(b[j]);</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>mp[tmp1] = 1;</cell><cell></cell><cell cols="3">Dr Repair (our model)</cell></row><row><cell></cell><cell></cell><cell cols="3">1. Error localized line 5</cell></row><row><cell cols="2">&lt;string,int&gt;::iterator it;</cell><cell cols="2">2. Repair</cell><cell></cell></row><row><cell>= mp.begin();</cell><cell></cell><cell></cell><cell cols="2">char tmp, a, b;</cell></row><row><cell>t &lt;&lt; it.first &lt;&lt; endl;</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">Example taken from SPoC dataset</cell><cell></cell><cell></cell></row><row><cell cols="2">(909A-45398788.cpp)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>ssage type</cell><cell cols="2">Frequency in original train data (SPoC)</cell><cell>base</cell><cell cols="2">Repair acc. (SPoC dev) + graph + graph + pretrain</cell></row><row><cell></cell><cell cols="2">35.2 %</cell><cell>50.2</cell><cell>58.9</cell><cell>65.0</cell></row><row><cell></cell><cell cols="2">8.9 %</cell><cell>40.7</cell><cell>43.0</cell><cell>49.1</cell></row><row><cell></cell><cell cols="2">3.2 %</cell><cell>67.6</cell><cell>70.7</cell><cell>86.1</cell></row><row><cell>efore ...</cell><cell cols="2">3.0 %</cell><cell>47.4</cell><cell>47.4</cell><cell>49.1</cell></row><row><cell>@@@', ... (e.g. Figure 1)</cell><cell cols="2">2.9 %</cell><cell>37.9</cell><cell>56.9</cell><cell>48.4</cell></row><row><cell>@@@'</cell><cell cols="2">2.1 %</cell><cell>48.8</cell><cell>51.1</cell><cell>93.0</cell></row><row><cell>'</cell><cell cols="2">1.3 %</cell><cell>37.0</cell><cell>39.7</cell><cell>44.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Gold code Y1 Y2 Y3 k Error line idx LSTM code (3) Line 3 Source code Line idx Msg content Feedback (compiler message) Line 2 Line 1 Line 1 Line 2 Line 3 Message content</head><label></label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell>MLP</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Pointer-Generator</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">+ softmax</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Decoder</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>hx11 hx12 hx13 ...</cell></row><row><cell cols="3">LSTM code (2)</cell><cell cols="3">LSTM code (2)</cell><cell cols="3">LSTM code (2)</cell><cell></cell><cell cols="3">LSTM msg (2)</cell><cell>hm1 '</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Aggregate</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">Graph Attention</cell><cell></cell><cell></cell><cell></cell><cell>hx21 hx22 hx23 ...</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>hm 1 hm 2</cell><cell>hm 3 ..</cell></row><row><cell cols="3">LSTM code (1)</cell><cell cols="3">LSTM code (1)</cell><cell cols="3">LSTM code (1)</cell><cell></cell><cell cols="3">LSTM msg (1)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>hx31 hx32 hx33 ...</cell></row><row><cell>x11</cell><cell>x12</cell><cell>x13</cell><cell>x11</cell><cell>x12</cell><cell>x13</cell><cell>x11</cell><cell>x12</cell><cell>x13</cell><cell>ierr</cell><cell>m1</cell><cell>m2</cell><cell>m3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Graph-based, Self-Supervised Program Repair from Diagnostic Feedback primary expression expected @@@ (e.g. expected ';' before..., expected '}' at end of input, expected primary-expression before...) missing @@@ (e.g. terminating " character)</figDesc><table><row><cell>Error type</cell><cell></cell><cell cols="2">Common compiler messages</cell><cell cols="3">Statistics DeepDelta DeepFix SPoC</cell><cell>Avg.</cell><cell>Relevant auto-corruption module (our proposal)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>48%</cell><cell>35%</cell><cell>30%</cell><cell>Syntax (deletion, insertion, replacement of</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>9%</cell><cell>• 37%</cell><cell>• 29%</cell><cell>• 23%</cell><cell>op/punc)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>• 11%</cell><cell>• 6%</cell><cell>• 7%</cell><cell>ID-typo (deletion, insertion of IDentifier)</cell></row><row><cell></cell><cell cols="3">redeclaration/conflicting declaration @@@</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Identifier type/declaration conflict</cell><cell cols="3">invalid conversion from &lt;type&gt; to &lt;type&gt; no match for 'operator @@@' (operand</cell><cell>9%</cell><cell>5%</cell><cell>18%</cell><cell>11%</cell><cell>ID-type (deletion, insertion, replacement of type)</cell></row><row><cell></cell><cell cols="2">types are @@@)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Identifier undeclared</cell><cell cols="2">@@@ was not declared</cell><cell></cell><cell>62%</cell><cell>33%</cell><cell>31%</cell><cell>42%</cell><cell>ID-typo (deletion, replacement of IDentifier)</cell></row><row><cell></cell><cell cols="3">'else' without a previous 'if'</cell><cell></cell><cell></cell><cell></cell><cell>Keyword (deletion, insertion, replacement)</cell></row><row><cell>Others</cell><cell cols="3">no matching function for call to...</cell><cell>20%</cell><cell>14%</cell><cell>16%</cell><cell>17%</cell><cell>Above modules (e.g. Syntax , ID-type , ID-typo )</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>can also cause errors clustered here</cell></row><row><cell cols="2">Our auto-corruption module</cell><cell></cell><cell>Example</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">return 0; } → return 0; } }</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Syntax (deletion, insertion, replacement of operator/ punctuator ,.;(){}'"++, etc.)</cell><cell cols="3">cout &lt;&lt; "YES"; → cout &lt;&lt; YES; min(s.size(), n) → min(s.size()), n) tmp = *a; → tmp = &amp;a</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="3">for (int i=0; i&lt;n;) → for (i=0; i&lt;n;)</cell><cell></cell><cell></cell></row><row><cell cols="2">ID-type (deletion, insertion, replacement of type)</cell><cell cols="2">k = k + 1; → int k = k + 1; string tmp; → char tmp;</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">int a, b=0, m, n; → int a, m, n;</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">ID-typo (deletion, insertion, replacement of IDentifier)</cell><cell cols="3">string x,y,z; → string x,y,z,z; for (i=0; i&lt;n;) → for (j=0; i&lt;n;)</cell><cell></cell><cell></cell></row><row><cell cols="2">Keyword (deletion, insertion,</cell><cell cols="2">if (n &gt;= 0) → while (n &gt;= 0)</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">replacement of keyword/call)</cell><cell cols="2">l = s.length(); → l = s.;</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Evaluator (compiler)</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="4">(`char` should be `string` instead in line 5)</cell></row><row><cell></cell><cell></cell><cell cols="4">1 #include &lt;bits/stdc++.h&gt;</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="3">2 #include &lt;string&gt;</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="3">3 using namespace std;</cell><cell></cell><cell></cell><cell>line 9:error: request for</cell></row><row><cell></cell><cell></cell><cell cols="3">4 int main() { 5 char tmp, a , b; 6 map&lt;string,int&gt; mp;</cell><cell></cell><cell></cell><cell>member 'size' in 'a', which is of non-class type 'char'</cell></row><row><cell></cell><cell></cell><cell>7</cell><cell cols="2">cin &gt;&gt; a &gt;&gt; b;</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>8</cell><cell>int i, j;</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>9</cell><cell cols="4">for (i = 0; i &lt; a .size(); i++){</cell></row><row><cell></cell><cell></cell><cell>10</cell><cell cols="3">tmp.push_back( a [i]);</cell><cell></cell></row><row><cell></cell><cell></cell><cell>11</cell><cell cols="2">string tmp1 = tmp;</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>12</cell><cell cols="4">for (j = 0; j &lt; b.size(); j++){</cell></row><row><cell></cell><cell></cell><cell>13</cell><cell cols="3">tmp1.push_back(b[j]);</cell><cell></cell></row><row><cell></cell><cell></cell><cell>14</cell><cell cols="2">mp[tmp1] = 1;</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>15</cell><cell>}</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>16</cell><cell>}</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>17</cell><cell cols="4">map&lt;string,int&gt;::iterator it;</cell></row><row><cell></cell><cell></cell><cell>18</cell><cell cols="2">it = mp.begin();</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>19</cell><cell cols="3">cout &lt;&lt; it.first &lt;&lt; endl;</cell><cell></cell></row></table><note>Expected ...• operator/punctuator•Feedback Dr Repair (our model)1. Error localized line 5 2. Repair char tmp, a, b;</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>primary expression expected @@@ (e.g. expected ';' before..., expected '}' at end of input, expected primary-expression before...) missing @@@ (e.g. terminating " character)</figDesc><table><row><cell>Error type</cell><cell cols="2">Common compiler messages</cell><cell cols="3">Statistics DeepDelta DeepFix SPoC</cell><cell>Avg.</cell><cell>Relevant auto-corruption module (our proposal)</cell></row><row><cell>Expected ...</cell><cell></cell><cell></cell><cell></cell><cell>48%</cell><cell>35%</cell><cell>30%</cell><cell>Syntax (deletion, insertion, replacement of</cell></row><row><cell></cell><cell></cell><cell></cell><cell>9%</cell><cell>• 37%</cell><cell>• 29%</cell><cell>• 23%</cell><cell>op/punc)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>• 11%</cell><cell>• 6%</cell><cell>• 7%</cell><cell>ID-typo (deletion, insertion of IDentifier)</cell></row><row><cell></cell><cell cols="2">redeclaration/conflicting declaration @@@</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Identifier type/declaration conflict</cell><cell cols="2">invalid conversion from &lt;type&gt; to &lt;type&gt; no match for 'operator @@@' (operand</cell><cell>9%</cell><cell>5%</cell><cell>18%</cell><cell>11%</cell><cell>ID-type (deletion, insertion, replacement of type)</cell></row><row><cell></cell><cell>types are @@@)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Identifier undeclared</cell><cell>@@@ was not declared</cell><cell></cell><cell>62%</cell><cell>33%</cell><cell>31%</cell><cell>42%</cell><cell>ID-typo (deletion, replacement of IDentifier)</cell></row><row><cell></cell><cell cols="2">'else' without a previous 'if'</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Keyword (deletion, insertion, replacement)</cell></row><row><cell>Others</cell><cell cols="2">no matching function for call to...</cell><cell>20%</cell><cell>14%</cell><cell>16%</cell><cell>17%</cell><cell>Above modules (e.g. Syntax , ID-type , ID-typo )</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>can also cause errors clustered here</cell></row><row><cell cols="2">Our auto-corruption module</cell><cell>Example</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>;</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Evaluator (compiler)</cell></row><row><cell></cell><cell cols="5">(`char` should be `string` instead in line 5)</cell><cell></cell></row><row><cell></cell><cell cols="4">1 #include &lt;bits/stdc++.h&gt;</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="3">2 #include &lt;string&gt;</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="3">3 using namespace std;</cell><cell></cell><cell></cell><cell></cell><cell>line 9:error: request for</cell></row><row><cell></cell><cell cols="3">4 int main() { 5 char tmp, a , b; 6 map&lt;string,int&gt; mp;</cell><cell></cell><cell></cell><cell></cell><cell>member 'size' in 'a', which is of non-class type 'char'</cell></row><row><cell></cell><cell>7</cell><cell cols="2">cin &gt;&gt; a &gt;&gt; b;</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>8</cell><cell>int i, j;</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>9</cell><cell cols="4">for (i = 0; i &lt; a .size(); i++){</cell><cell></cell></row><row><cell></cell><cell>10</cell><cell cols="3">tmp.push_back( a [i]);</cell><cell></cell><cell></cell></row><row><cell></cell><cell>11</cell><cell cols="2">string tmp1 = tmp;</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>12</cell><cell cols="4">for (j = 0; j &lt; b.size(); j++){</cell><cell></cell></row><row><cell></cell><cell>13</cell><cell cols="3">tmp1.push_back(b[j]);</cell><cell></cell><cell></cell></row><row><cell></cell><cell>14</cell><cell cols="2">mp[tmp1] = 1;</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>15</cell><cell>}</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>16</cell><cell>}</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>17</cell><cell cols="4">map&lt;string,int&gt;::iterator it;</cell><cell></cell></row><row><cell></cell><cell>18</cell><cell cols="2">it = mp.begin();</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>19</cell><cell cols="3">cout &lt;&lt; it.first &lt;&lt; endl;</cell><cell></cell><cell></cell></row><row><cell></cell><cell>20 }</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>• operator/punctuator•Syntax (deletion, insertion, replacement of operator/ punctuator ,.;(){}'"++, etc.) return 0; } → return 0; } } cout &lt;&lt; "YES"; → cout &lt;&lt; YES; min(s.size(), n) → min(s.size()), n) tmp = *a; → tmp = &amp;a ID-type (deletion, insertion, replacement of type) for (int i=0; i&lt;n;) → for (i=0; i&lt;n;) k = k + 1; → int k = k + 1; string tmp; → char tmp; ID-typo (deletion, insertion, replacement of IDentifier) int a, b=0, m, n; → int a, m, n; string x,y,z; → string x,y,z,z; for (i=0; i&lt;n;) → for (j=0; i&lt;n;) Keyword (deletion, insertion, replacement of keyword/call) if (n &gt;= 0) → while (n &gt;= 0) l = s.length(); → l = s.Feedback Dr Repair (our model)1. Error localized line 5 2. Repair char tmp, a, b; → string tmp, a, b;</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 .</head><label>2</label><figDesc>Proposed program perturbation modules for generating self-supervised data.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 3 .</head><label>3</label><figDesc>Performance of our repair model and prior work on DeepFix data. We report the single step error localization / repair accuracy (%) on our synthetic dev set (column 2-3), and the full repair success rate (%) on DeepFix raw test set (column 4). "DrRepair" refers to our full model, which outperforms prior work by significant margins. (*) compiler messages not used.</figDesc><table><row><cell>-</cell><cell>-</cell><cell>45.3  *</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4 .</head><label>4</label><figDesc>Performance of our repair model on SPoC data. We measure the single step error localization / repair accuracy (%) on the SPoC Dev set. "DrRepair" refers to our full model.</figDesc><table /><note>s within a budget of B attempts (search iterations). Prior work (Kulal et al., 2019) uses a seq2seq translation system to map each pseudocode line s i into a set of 100 candidate code pieces C i = {t ici | c i ∈ [100]}, where candidate piece t ici has probability p ici . A full candidate program t is a concatenation of candidate code pieces, and has score p(t):</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 5 .</head><label>5</label><figDesc>Program synthesis success rate (%) at search budgets B on the SPoC Test sets. Our search method equipped with DrRepair consistently outperforms the previous best in all settings.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head></head><label></label><figDesc>Table 7. Comparison of different graph architectures. We evaluate the models on the Deepfix raw test set (full repair rate %).</figDesc><table><row><cell>Repair Model</cell><cell>Full Repair</cell></row><row><cell>Our base</cell><cell>62.5</cell></row><row><cell>Our base + graph (edges among code only)</cell><cell>64.8</cell></row><row><cell>Our base + graph (edges across code-feedback only)</cell><cell>64.9</cell></row><row><cell>Our base + graph (final)</cell><cell>66.4</cell></row><row><cell>Our base + self-attention</cell><cell>66.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 8 .</head><label>8</label><figDesc>Breakdown of major compiler errors seen in SPoC dev (left), and the corresponding repair accuracy by our model variants (right).</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Note that here we are defining a module that repairs a single line of code in a program. We describe how we apply this repair module to programs with multiple errors in §4. We also explain the application-dependent evaluation metrics in §4.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://github.com/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">We made sure that the programs collected for pre-training do not overlap with the exact programs in SPoC test sets. 4 https://bitbucket.org/iiscseal/deepfix 5 https://sumith1896.github.io/spoc</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank John Hewitt, Mina Lee, Sumith Kulal, Pang Wei Koh, Robin Jia, Ananya Kumar, Ruiqi Zhong, and anonymous reviewers for insightful feedback and discussions. This work was supported in part by NSF CAREER Award IIS-1552635, a PECASE Award, and an Amazon Research Award.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Compilation error repair: for the student programs, from the student programs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">Z</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karkare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gulwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICSE</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning to represent programs with graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Allamanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brockschmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Khademi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning to fix bugs automatically</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pradel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Getafix</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OOPSLA</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Generative code modeling with graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brockschmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Allamanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gaunt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Sequencer: Sequence-to-sequence learning for end-to-end program repair</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Kommrusch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tufano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-N</forename><surname>Pouchet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Poshyvanyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Monperrus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Software Engineering</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning graph transformations to detect and fix bugs in programs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dinella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hoppity</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Why does unsupervised pretraining help deep learning?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-A</forename><surname>Manzagol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Journal of MachineLearning Research</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Codebert: A pre-trained model for programming and natural languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Debugging: finding, fixing and flailing, a multi-institutional study of novice debuggers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lewandowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mccauley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Science Education</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deepfix: Fixing common c language errors by deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shevade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Neural attribution for semantic bug-localization in student programs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shevade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Self-Supervised Program Repair from Diagnostic Feedback</title>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>Graph-based</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep reinforcement learning for programming language correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shevade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Learning to correct programs by sampling diverse fixes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hajipour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Samplefix</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.10502</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Pre-training graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pande</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Defects4j: A database of existing faults to enable controlled testing studies for java programs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Just</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jalali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Ernst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISSTA</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Search-based pseudocode to code</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kulal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Padon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Aiken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Spoc</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Dialogue learning with human teaching and feedback in end-to-end trainable task-oriented dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hakkani-Tr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Heck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In NAACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning to repair compilation errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mesbah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Johnston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Glorioso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aftandilian</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ESEC/FSE</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">The living review on automated program repair</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Monperrus</surname></persName>
		</author>
		<idno>hal-01956501. HAL/archives- ouvertes.fr.</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Automatic grading and feedback using program repair for introductory programming courses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Parihar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dadachanji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Praveen Kumar Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karkare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bhattacharya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Conference on Innovation and Technology in Computer Science Education</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">On the difficulty of training recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1211.5063</idno>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deep contextualized word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deepbugs: a learning approach to name-based bug detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pradel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OOPSLA</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">sk p: a neural program corrector for moocs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Solar-Lezama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPLASH Companion</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Get to the point: Summarization with pointer-generator networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>See</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Programmers&apos; build errors: A case study at google</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sadowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Elbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Aftandilian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bowdidge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICSE</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Learning to fix build errors with graph2diff neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tarlow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-A</forename><surname>Manzagol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aftandilian</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1911.01205</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Neural program repair by jointly learning to localize and repair</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Maniatis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bieber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Graph attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Velikovi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Extracting and composing robust features with denoising autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-A</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Dynamic neural program embeddings for program repair</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">How powerful are graph neural networks? In ICLR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Graph-based neural multi-document summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Meelu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pareek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Radev</surname></persName>
		</author>
		<editor>CoNLL</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Graph convolution over pruned dependency trees improves relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Neural networks for modeling source code edits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bieber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tarlow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.02818</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Semantic scaffolds for pseudocode-to-code generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.05927</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
