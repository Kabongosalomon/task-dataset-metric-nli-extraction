<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Explain Yourself! Leveraging Language Models for Commonsense Reasoning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nazneen</forename><forename type="middle">Fatema</forename><surname>Rajani</surname></persName>
							<email>nazneen.rajani@salesforce.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Salesforce Research Palo Alto</orgName>
								<address>
									<postCode>94301</postCode>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Mccann</surname></persName>
							<email>bmccann@salesforce.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Salesforce Research Palo Alto</orgName>
								<address>
									<postCode>94301</postCode>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
							<email>cxiong@salesforce.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Salesforce Research Palo Alto</orgName>
								<address>
									<postCode>94301</postCode>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
							<email>rsocher@salesforce.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Salesforce Research Palo Alto</orgName>
								<address>
									<postCode>94301</postCode>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Explain Yourself! Leveraging Language Models for Commonsense Reasoning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T15:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep learning models perform poorly on tasks that require commonsense reasoning, which often necessitates some form of worldknowledge or reasoning over information not immediately present in the input. We collect human explanations for commonsense reasoning in the form of natural language sequences and highlighted annotations in a new dataset called Common Sense Explanations (CoS-E). We use CoS-E to train language models to automatically generate explanations that can be used during training and inference in a novel Commonsense Auto-Generated Explanation (CAGE) framework. CAGE improves the state-of-the-art by 10% on the challenging CommonsenseQA task. We further study commonsense reasoning in DNNs using both human and auto-generated explanations including transfer to out-of-domain tasks. Empirical results indicate that we can effectively leverage language models for commonsense reasoning.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Commonsense reasoning is a challenging task for modern machine learning methods <ref type="bibr" target="#b28">(Zhong et al., 2018;</ref><ref type="bibr" target="#b22">Talmor et al., 2019)</ref>. Explanations are a way to verbalize the reasoning that the models learn during training. Common sense Question Answering (CQA) is a multiple-choice question answering dataset proposed for developing natural language processing (NLP) models with commonssense reasoning capabilities <ref type="bibr" target="#b22">(Talmor et al., 2019)</ref>. Although these efforts have led to progress, it is still unclear how these models perform reasoning and to what extent that reasoning is based on world knowledge. We collect human explanations for commonsense reasoning built on top of CQA and introduce them as Common Sense Explanations (CoS-E) <ref type="bibr">1</ref>   the form of both open-ended natural language explanations as well as highlighted span annotations that represent words selected by humans as important for predicting the right answer (see <ref type="table" target="#tab_1">Table 1</ref>). <ref type="bibr" target="#b22">Talmor et al. (2019)</ref> show that using Google search to extract context from top 100 result snippets for each of the question and answer choices does not help much in improving the accuracy on CQA trained using even the state-of-the-art reading comprehension model BiDAF++ <ref type="bibr" target="#b21">(Seo et al., 2017)</ref> augmented with a self-attention layer and ELMo representations <ref type="bibr" target="#b17">(Peters et al., 2018)</ref>.</p><p>In contrast, we leverage a pretrained language model to generate explanations that are useful for commonsense reasoning. We propose Commonsense Auto-Generated Explanations (CAGE) as a framework for generating explanations for CQA. We break down the task of commonsense reasoning into two phases. In the first phase, we provide a CQA example alongside the corresponding CoS-E explanation to a language model. The language model conditions on the question and answer choices from the example and is trained to generate the CoS-E explanation.</p><p>In the second phase, we use the language model arXiv:1906.02361v1 [cs.CL] 6 Jun 2019 … (a) One time-step of training a CAGE language model to generate explanations from CoS-E. It is conditioned on the question tokens Q concatenated with the answer choice tokens A1, A2, A3 and previously generated tokens E1, . . . , Ei−1. It is trained to generate token Ei.  to generate explanations for each example in the training and validation sets of CQA. These CAGE explanations are provided to a second commonsense reasoning model by concatenating it to the end of the original question, answer choices, and output of the language model. The two-phase CAGE framework obtains state-of-the-art results outperforming the best reported baseline by 10% and also produces explanations to justify its predictions. <ref type="figure" target="#fig_1">Figure 1</ref> shows an overview of our proposed approach.</p><p>In summary, we introduce a new Common Sense Explanations (CoS-E) dataset to study neural commonsense reasoning and provide a new method, CAGE for automatically generating explanations that achieve a state-of-the-art accuracy of approximately 65% on CQA v1.0. We demonstrate explanation transfer on two out-of-domain datasets. Note that before our final submission, the organizers released a more challenging v1.11 of CQA with 5 answer choices instead of 3 and so we also included the new version in our results and discussions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background and Related Work</head><p>Commonsense reasoning Datasets that require models to learn to predict relations between situations or events in natural language have been introduced in the recent past. The Story Cloze (also referred to as ROC Stories) involves predicting the correct story ending from a set of plausible endings <ref type="bibr" target="#b14">(Mostafazadeh et al., 2016)</ref> while the Situations with Adversarial Generations (SWAG) involves predicting the next scene based on an initial event <ref type="bibr" target="#b27">(Zellers et al., 2018)</ref>. Language Modeling based techniques such as the GPT and BERT models get human-level performance on these datasets <ref type="bibr" target="#b18">(Radford et al., 2018;</ref><ref type="bibr" target="#b5">Devlin et al., 2019)</ref>. They have been less successful on tasks that require clear understanding of how pronouns resolve be-tween sentences and how that interacts with world knowledge. For example, the Winograd Schemas <ref type="bibr" target="#b26">(Winograd, 1972)</ref> and challenges derived from that format <ref type="bibr" target="#b9">(Levesque et al., 2012;</ref><ref type="bibr" target="#b12">McCann et al., 2018;</ref> have proven difficult for even the most modern machine learning methods <ref type="bibr" target="#b23">(Trinh and Le, 2018)</ref> to achieve near-human performance, but the emphasis on pronoun resolution in those challenges leaves room for exploration of other kinds of commonsense reasoning. CQA is a new dataset that consists of 9500 questions with one correct answer and two distractor answers <ref type="bibr" target="#b22">(Talmor et al., 2019)</ref>. The authors claim that because all the answer choices are drawn from the same source concept, the dataset requires models to actually infer from the question rather than take advantage of distributional biases. We, however, observed that the current state of this dataset has gender disparity with higher proportion of feminine pronouns used in negative context.</p><p>The authors show that the state-of-the-art language models perform very poorly compared to human participants on their dataset. Although, CQA introduces a benchmark for evaluating commonsense reasoning capabilities of models, it is still unclear how and to what extent do models actually do common-sense reasoning. CoS-E builds on top of their benchmark, on the other hand, provides data in the form of explanations that can be used to study and analyze as well as evaluate a model's reasoning capabilities. <ref type="bibr" target="#b8">Lei et al. (2016)</ref> proposed an approach for rationale generation for sentiment analysis by highlighting complete phrases in the input text that by itself is sufficient to predict the desired output. Humangenerated natural language explanations for classification data have been used in the past to train a semantic parser that in turn generates more noisy labeled data which can used to train a classifier <ref type="bibr" target="#b6">(Hancock et al., 2018)</ref>. <ref type="bibr" target="#b2">Camburu et al. (2018)</ref> generate explanations and predictions for the natural language inference problem <ref type="bibr" target="#b2">(Camburu et al., 2018)</ref>. However, the authors report that interpretability comes at the cost of loss in performance on the popular Stanford Natural Language Inference <ref type="bibr" target="#b1">(Bowman et al., 2015)</ref> dataset. We find that, unlike for e-SNLI, explanations for CQA lead to improved performance in what <ref type="bibr" target="#b2">Camburu et al. (2018)</ref> would call the explain-predict setting. In the multi-modal setting, Rajani and Mooney (2018) showed that visual explanations can be leveraged to improve performance of VQA <ref type="bibr" target="#b0">(Antol et al., 2015)</ref> and that an ensemble explanation is significantly better than individual explanations using both automated and human evaluations (Rajani and Mooney, 2017).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Natural language explanations</head><p>Knowledge Transfer in NLP Natural language processing has often relied on the transfer of world-knowledge through pretrained word vectors like Word2Vec <ref type="bibr" target="#b13">(Mikolov et al., 2013)</ref> and GloVe <ref type="bibr" target="#b16">(Pennington et al., 2014)</ref>. Contextualized word vectors <ref type="bibr" target="#b11">(McCann et al., 2017;</ref><ref type="bibr" target="#b17">Peters et al., 2018)</ref> refined these representations for particular inputs by using different forms of general encoding. Language models trained from scratch on large amounts of data have made groundbreaking success in this direction by carefully finetuning for specific tasks <ref type="bibr" target="#b4">(Dai and Le, 2015;</ref><ref type="bibr" target="#b18">Radford et al., 2018;</ref><ref type="bibr" target="#b7">Howard and Ruder, 2018;</ref><ref type="bibr" target="#b5">Devlin et al., 2019)</ref>. These models have the advantage that only a few parameters need to be learned from scratch and thus perform surprisingly well even on small amounts of supervised data. Fine-tuned language models do not however work as well for directly predicting answers for CQA <ref type="bibr" target="#b22">(Talmor et al., 2019)</ref>. In our work, we show how these finetuned language models are more effective when leveraged to generate explanations and empirically prove that they also linguistically capture common sense.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Common Sense Explanations (CoS-E)</head><p>We used Amazon Mechanical Turk (MTurk) to collect explanations for our Common Sense Explanations (CoS-E) dataset. The CQA dataset consists of two splits -the question token split and the random split. Our CoS-E dataset and all our experiments use the more difficult random split, which is the main evaluation split according to Tal- mor et al. <ref type="bibr">(2019)</ref>. We also release CoS-E for CQA v1.11. Human participants are given the question and answer choices along with the ground-truth answer choice. Turkers are prompted with the following question: "Why is the predicted output the most appropriate answer?" Annotators were instructed to highlight relevant words in the question that justifies the ground-truth answer choice and to provide a brief open-ended explanation based on the highlighted justification could serve as the commonsense reasoning behind the question. We collected these explanations for the CQA trainrandom-split and dev-random-split, which have a size of 7610 and 950 for v1.0 and 9741 and 1221 for v1.11 respectively. <ref type="table" target="#tab_1">Table 1</ref> shows a random sample of examples from our CoS-E dataset with both free-form explanations and highlighted text. From here on, we refer to the highlighted words as CoS-E-selected and the free-form explanation as</p><formula xml:id="formula_0">CoS-E-open-ended.</formula><p>In MTurk, it is difficult to control the quality of open-ended annotations. So, we do some inbrowser checks to avoid obviously bad explanations. Annotators cannot move forward if they do not highlight any relevant words in the question or if the length of explanations is less than 4 words. We also check that the explanation is not a substring of the question or the answer choices without any other extra words. We collect these explanations from only one annotator per example, so we also perform some post-collection checks to catch examples that are not caught by our previous filters. We filter out explanations that could be classified as a template. For example, explanations of the form "&lt;answer&gt; is the only option that is [correct|obvious]" are deleted and then reannotated. <ref type="figure" target="#fig_2">Figure 2</ref> shows the distribution of explanations collected in the CoS-E v1.0 dataset. 58% of expla-nations from CoS-E contain the ground truth, but the effectiveness of CoS-E is not constrained only to those examples. Our model obtains state-of-theart results by using CoS-E only during training. Empirical results show that even when using only those explanations that do not have any word overlap with any of the answer choices, performance exceeds that of baselines that do not use CoS-E at all. We also observed that a significant proportion of the distractor choices are also present in the CoS-E dataset and on further analysis we found that for those examples, annotators resorted to explaining by eliminating the wrong choices. This indicates that it is difficult even for humans to reason about many of the examples in CQA. Because CoS-E uses crowd-sourcing, it also adds diversity of perspective and in particular diverse reasoning on world knowledge to the CQA dataset. Even though many explanations remain noisy after quality-control checks, we find that they are of sufficient quality to train a language model that generates commonsense reasoning. We refer to Section 5 for more details on empirical results and ablation analysis on CoS-E.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Algorithm</head><p>We present Commonsense Auto-Generated Explanations (CAGE) and apply it to the CQA task. CAGE are generated by a language model and are used aas supplementary inputs to a classification model. Each example in CQA consists of a question, q, three answer choices, c0, c1, c2, and a labeled answer a. Our CoS-E dataset adds a human explanation e h for why a is the most appropriate choice. The output of CAGE is a language model generated explanation e that is trained to be close to e h .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Commonsense Auto-Generated</head><p>Explanations (CAGE) In order to supply CAGE to a classification model, we fine-tune a language model (LM) to generate explanations from our CoS-E dataset. Our LM is the large, pre-trained OpenAI GPT <ref type="bibr" target="#b18">(Radford et al., 2018)</ref> which is a multi-layer, transformer <ref type="bibr" target="#b24">(Vaswani et al., 2017)</ref> decoder. GPT is fine-tuned on the combination of CQA and CoS-E datasets, as shown in the left half of <ref type="figure" target="#fig_1">Figure 1</ref>. We explore explanation generation in two settings -1) explain-and-then-predict (reasoning) <ref type="figure" target="#fig_1">(Figure 1)</ref> and 2) predict-and-then-explain (rationalization).</p><p>Reasoning This is our main approach and in this the LM is fine-tuned conditioned on the question, answer choices and the human generated explanation and not the actual predicted label. So, the input context during training is defined as follows: C RE = "q, c0, c1, or c2? commonsense says " The model is trained to generate explanations e according to a conditional language modeling objective. The objective is to maximize:</p><formula xml:id="formula_1">i log P (e i |e i−k , . . . , e i−1 , C RE ; Θ)</formula><p>where k is the size of the context window (in our case k is always greater than the length of e so that the entire explanation is within the context). The conditional probability P is modeled by a neural network with parameters Θ conditioned on C RE and previous explanation tokens. We call this kind of explanation reasoning because they can be automatically generated during inference to provide additional context for commonsense question answering. In Section 5, we show that this approach outperforms the reported state-of-the-art on CQA by 10%. For the sake of completeness, we also experimented with the reverse of this approach wherein the model first makes the predictions and then generates explanations based on those labels, which we call rationalization and is discussed below.</p><p>Rationalization In rationalization, the LM model conditions on the predicted labels along with the input to generate post-hoc rationalizations. So, during the fine-tuning step, the input context contains the output label and is constructed as follows:</p><p>C RA = " q, c0, c1, or c2? a because " The training objective for the LM in rationalization is similar to that in reasoning except that in this case, the model has access to the ground truth labels to the input questions during training. Because the language model is conditioned on the predicted label, the explanations cannot be considered as common sense reasoning. Instead, they offer a rationalization that makes the model more accessible and interpretable. We find that this approach outperforms the current best model by 6% and also produces interestingly good quality explanations as discussed in Section 5.</p><p>For CAGE, we generate sequences of maximum length 20, use a batch size of 36, train for a maximum of 10 epochs, selecting the best model based on validation BLEU and perplexity scores. Learning rate was set to 1e −6 , warmed up linearly with proportion 0.002 and weight decay 0.01.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Commonsense Predictions with</head><p>Explanations Given either a human explanation from CoS-E or reasoning from a language model, we can then learn to perform predictions on the CQA task. For the classification module of our proposed approach, we adopt the widely popular BERT model <ref type="bibr" target="#b5">(Devlin et al., 2019)</ref> which we refer to as just BERT. BERT can be fine-tuned for multiple choice question answering by adding a simple binary classifier that takes as input the final state corresponding to the the special [CLS] token placed at the start of all inputs to BERT models <ref type="bibr" target="#b5">(Devlin et al., 2019)</ref>. We apply this same approach to the CQA task. For each example in the dataset, we construct three input sequences for fine-tuning BERT. Each sequence is the concatenation of the question, a separator token <ref type="bibr">[SEP]</ref>, and one of the answer choices. If the approach requires explanation from either CoS-E or automatically generated as in the CAGE, we concatenate the question, [SEP], the explanation, <ref type="bibr">[SEP]</ref>, and an answer choice. For BERT, the explanations share the same input representation as that of the questions. We also experimented with the explanation sharing the same representation as that of the answer choice but found that the performance decreased slightly.</p><p>When explanations are used only during training, the explanation variable is optional and the answer choices directly follow the question during evaluation. For all our experiments we used a train batch size of 24, test batch size of 12, 10 training epochs and maximum sequence length of 50 for the baseline and 175 for all experiments involving explanations. The right part of <ref type="figure" target="#fig_1">Figure 1</ref> gives an overview of the classification module of our proposed approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Transfer to out-of-domain datasets</head><p>Transfer without fine-tuning to out-of-domain NLP datasets is known to exhibit poor performance. For example, for the comparatively easier natural langauge inference task with fixed labels, Bowman et al. <ref type="bibr">(2015)</ref> show that the accuracy dropped by 25% when training on SNLI and evaluating on SICK-E <ref type="bibr" target="#b10">(Marelli et al., 2014)</ref>. We study transfer of natural language explanations from the CQA to SWAG <ref type="bibr" target="#b27">(Zellers et al., 2018)</ref> and Story Cloze Test <ref type="bibr" target="#b14">(Mostafazadeh et al., 2016)</ref>. Both the datasets are multiple-choice like CQA and the authors publicize them as commonsense reasoning and inference tasks.</p><p>We use the GPT language model fine-tuned on CQA train and dev sets to generate explanations on the SWAG train and val sets (with 73546 and 20006 instances respectively) and the Story Cloze Spring 2016 val and test sets (with 1870 instances each). We then train a BERT classifier using the input instances and generated explanations and evaluate on the SWAG and Story Cloze test sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Results</head><p>We present results on the CQA dataset using variations of our proposed Commonsense Auto-Generated Explanations (CAGE). All our models are based on BERT, which also serves as our baseline without any CoS-E or CAGE. All our ablation analysis is conducted on the CQA dev-randomsplit. We also show results for key models on the final test split. 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Accuracy <ref type="formula">(</ref>   <ref type="table" target="#tab_3">Table 2</ref> shows results that compare a BERT baseline that uses only the CQA inputs and the same architecture but trained using inputs that contain explanations from CoS-E during training. The BERT baseline model reaches 64% accuracy and adding open-ended human explanations (CoS-E-open-ended) alongside the questions during training results in a 2% boost in accuracy. By generating explanations as described in Section 4.1, we can give the commonsense question answering model access to an explanation that is not conditioned on the ground truth. These explanations (CAGE-reasoning) can be provided during both training and validation and increases the accuracy to 72%. <ref type="table" target="#tab_5">Table 3</ref> shows the results obtained on the CQA test split. We report our two best models that represent using human explanations (CoS-E-openended) for training only and using language model explanations (CAGE-reasoning) during both train and test. We compare our approaches to the best reported models for the CQA task <ref type="bibr">(Talmor et</ref>     <ref type="formula">(2019)</ref> experimented with using Google search of "question + answer choice" for each example in the dataset and collected 100 top snippets per answer choice to be used as context for their Reading Comprehension (RC) model. They found that providing such extra data does not improve accuracy. On the other hand, using CAGE-reasoning resulted in a gain of 10% accuracy over the previous state-of-the-art. This suggests that our CoS-E-open-ended and CAGEreasoning explanations provide far more useful information than what can be achieved through simple heuristics like using Google search to find relevant snippets. We observed that our models' performance on test is lower than those on validation and this trend was confirmed by the organizers of the task.</p><p>To establish an oracle upper-bound on the performance, we also explored an experimental setting in which human-generated explanations from CoS-E are provided during both training and validation. These results are summarized in <ref type="table" target="#tab_6">Table 4</ref>. We note that this is an unfair setting because the human that provided the explanation had access to the ground truth answer; these results merely serve as an oracle for how much potential benefit can come from using CoS-E-open-ended. If the openended human explanations (CoS-E-open-ended) are provided at inference time, performance jumps to approximately 90%. These results also motivate an attempt to automatically generate explanations that establish the world knowledge needed to solve CQA. CAGE-reasoning is our attempt towards this goal. <ref type="table" target="#tab_6">Table 4</ref> also contains results that use only the explanation and exclude the original question from CQA denoted by 'w/o question'. These variants also use explanation during both train and validation. For these experiments we give the explanation in place of the question followed by the answer choices as input to the model. When the explanation consists of words humans selected as justification for the answer <ref type="figure">(CoS-E-selected</ref>  We experimented with one final setting in which we only used open-ended explanations that did not contain any word from any answer choices (23%. In this setting, we call these "CoS-E-limited-openended" explanations because these explanations are limited in the choice of words allowed. We observe that even using these limited kind of explanations improves over the BERT baseline in Table 4, which suggests that the explanations are providing useful information beyond just mentioning the correct or incorrect answers.</p><p>We also evaluated our key models -CoS-Eopen-ended used during training only and the CAGE reasoning on the v1.11 of CQA that was released before the final submission. <ref type="table" target="#tab_8">Table 5</ref> shows the results obtained on the more challenging CQA v1.11. <ref type="bibr" target="#b2">Camburu et al. (2018)</ref> empirically show that transferring explanations on the natural language inference (NLI) problem from SNLI to MultiNLI performs very poorly and is still an open challenging problem. We study transfer of explanations on commonsense reasoning tasks. The NLI problem has a small fixed set of pre-defined labels unlike the commonsense reasoning tasks such as CQA, SWAG and Story Cloze. <ref type="table" target="#tab_10">Table 6</ref> shows the results obtained by the BERT baseline without explanations and using our transferred explanations from CQA to SWAG and Story Cloze. We observed that adding explanations led to a very small decrease (&lt; 0.6%) in the performance compared to the baseline for both tasks.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Analysis and Discussion</head><p>In We measure quality of CAGE using human evaluation and automated metrics. One of the metrics is the BLEU score <ref type="bibr" target="#b15">(Papineni et al., 2002)</ref>, which measures syntactical precision by n-gram overlap. We also report perplexity, which provides a token-level measure of how well the language models predict the next word. We obtained a peak BLEU score of 4.1 between CAGEreasoning and CoS-E-open-ended and perplexity of 32. Language models that are not fine-tuned achieve BLEU score of only 0.8. Though it is clearly beneficial to fine-tune the LM and empirical results suggested that CAGE increased performance, these scores suggest that humans and LMs have widely varying ways of providing useful explanations.</p><p>Error analysis on the baseline BERT model that does not use any explanations indicates that the model performs poorly on questions that are longer on an average and are more compositional. The average length of such questions is 14 words as opposed to the average length of 13 words for questions that the model using CAGE predicts in-  <ref type="table">Table 7</ref>: Random sample of explanations generated by humans from CoS-E and our CAGE framework's reasoning and rationalization approaches. Boldface indicates gold label. All the typos and grammatical errors are as they appear in the actual output sequence.</p><p>correctly. Therefore, we can conclude that explanations help elucidate the longer and more complicated compositional questions. <ref type="table">Table 7</ref> shows a collection of examples from CQA, CoS-E, and CAGE samples. We observe that CAGE-reasoning typically employs a much simpler construction than CoS-E-openended. Nonetheless, this simple declarative mode can sometimes be more informative than CoS-Eopen-ended. CAGE achieves this by either providing more explicit guidance (as in the final example of <ref type="table">Table 7</ref>) or by adding meaningful context (as in the third example by introducing the word 'friends'). We observe that CAGE-reasoning contains at least one of the answer choices 43% of the time, out of which it contains the model's actual predicted answer choice 21% of the time. This suggests that there is more to the effectiveness of CAGE-reasoning than directly pointing to the answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question:</head><p>What is the main purpose of having a bath? Choices:</p><p>cleanness, use water, exfoliation, hygiene, wetness Explanation: the only purpose of having a bath is to clean yourself.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question:</head><p>Where can you store you spare linens near your socks? Choices:</p><p>cabinet, chest, hospital, dresser drawers, home Explanation: dresser drawer is the only place that you can store linens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question:</head><p>Where do you find the most amount of leafs?, Choices:</p><p>forrest, floral arrangement, compost pile, field, ground Explanation: the most likely place to find leafs is in a garden. <ref type="table">Table 8</ref>: Random sample of incorrectly predicted instances by CAGE-reasoning on CQA v1.11 dev-set. Bold indicated ground-truth and underline indicates our CAGE's prediction.</p><p>We also carried out human evaluations to compare 400 examples of CoS-E and CAGEreasoning. We asked human participants on Mechanical Turk to guess the most appropriate answer choice based on only the explanation without the question. This tests whether the explanation by itself is sufficient for a human to arrive at the same answer as the neural network. We found that Turkers were able to arrive at the same answer as the model based on CAGE-reasoning 42% of the time. This initially seemed low, but Turkers could only arrive at the same answer as humans using only CoS-E-open-ended 52% of the time From <ref type="table">Table 7</ref>, we observed that CAGErationalization and CAGE-reasoning were often identical or differed only in word ordering or by replacing one of the answer choices with another. Humans could predict the answer based on just CAGE-rationalization 42% of the time, same as CAGE-reasoning. Although CAGErationalizations seem to be better than CAGEreasoning, we find that it does not drastically improve the model's language generating behavior which is what humans judge while trying to guess the right answer without the actual question.</p><p>Even though CoS-E and CAGE are noisy, they empirically perform well when used by downstream models for CQA, but this is not the case for misleading explanations. If we manually changed a random sample of 50 examples to have adversarial misleading explanations, performance dropped from 60% to 30%, well below the baseline of 50% validation accuracy. For example, we changed the explanation from "being able to use" to "buying more will alleviate stress" for the question "If a couple is having financial issues, buying products can lead to what" with answer choices "economic boom", "disagreements", "being able to use". Of the 70% of the errors made by a model trained on misleading explanations, 57% of them were instead correctly answered by our model trained with true CoS-E explanations. This demonstrates the effectiveness of having well-informing explanations. <ref type="bibr" target="#b2">Camburu et al. (2018)</ref> use human explanations to train a neural network model on the SNLI dataset <ref type="bibr" target="#b1">(Bowman et al., 2015)</ref>. However, they obtain explanations at the cost of accuracy. The authors use the InferSent <ref type="bibr" target="#b3">(Conneau et al., 2017)</ref> model for classification and add a one-layer LSTM as the explanation decoder. They report a slight drop in performance (&lt; 1%) when training on human explanations and testing by first predicting an answer and then generating explanations. There is a further drop of approximately 2% accuracy when their model generates explanations prior to predicting an answer based only on that explanations. However, they also show that a bidirectional encoder with MLP-classifier obtains 96.83% accuracy when given only human explanations. CQA experiences a lift from explanations when e-SNLI performance appears to degrade with explanations. For CQA, humans are able to predict the right answer only about 52% of the time using only human explanations from CoS-E.</p><p>On the more challenging CQA v1.11, we observed that our CoS-E model trained on human explanations but evaluated without explanations obtains state-of-the-art performance, beating the BERT baseline by 1.5%. Surprisingly, we found that our CAGE-reasoning model performs slightly worse than the baseline. However, during error analysis we found that the language model explanations do not exhibit any obvious problems. Table 8 shows some samples that CAGE predicts incorrectly. We observed that many of the incorrectly predicted instances had the correct answer in the generated explanation, such as "dresser drawer" and "cleanness" in the first two examples, but this information is not properly used by the BERT classifier. A more explicit method of guiding attention towards the relevant information in the explanations might be necessary for such cases. The model also frequently errs when the choices seem semantically close such as "forest" and "compost pile" in the third example. In these cases, the classifier often predicts the incorrect choice on v1.11, but was able to predict the correct choice on v1.0 when only 3 choices were presented. This suggests that simply concatenating explanations is unable to make sufficiently clear the more difficult cases of the newer version of CQA.</p><p>Transferring the language model used to generate commonsense explanations to out-of-domain datasets, SWAG and Story Cloze, led to slight decrease in performance. Upon inspection, the generated explanations exhibited little grammatical or syntactical errors and often contained apparently relevant information. <ref type="table" target="#tab_13">Table 9</ref> shows examples from both datasets and the corresponding gen-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SWAG</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question:</head><p>Men are standing on motorbikes getting ready for a motocross competition. Choices: man places the ladders onto a fence and winds up a marching wall, high with hammer and a stone., man is talking to the camera and standing on a podium., man stands outside in the field going at arms of people and leading a long jumping calf in front., man drops the javelin to the ground and jumps it very high. Explanation:</p><p>man is talking to the camera and not the crowd.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question:</head><p>The man examines the instrument in his hand.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Choices:</head><p>The person studies a picture of the man playing the violin., The person holds up the violin to his chin and gets ready., The person stops to speak to the camera again., The person puts his arm around the man and backs away. Explanation:</p><p>the person is holding the instrument in his hand.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question:</head><p>The woman is seated facing the camera while another woman styles her hair. Choices:</p><p>The woman in purple is wearing a blue dress and blue headband, using the pits to style her hair., The woman begins to cut the hair with her hair then serves it and begins brushing her hair and styling it., The woman puts some right braids on his., The woman continues to have her hair styled while turned away from the camera. Explanation:</p><p>the woman is using the braids to trim her hair.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Story Cloze (ROCStories)</head><p>Question: My friends all love to go to the club to dance. They think it's a lot of fun and always invite. I finally decided to tag along last Saturday. I danced terribly and broke a friend's toe. Choices:</p><p>My friends decided to keep inviting me out as I am so much fun., The next weekend, I was asked to please stay home. Explanation: the next weekend, i would be asked to stay home Question: Ari spends $20 a day on pickles. He decides to make his own to save money. He puts the pickles in brine. Ari waits 2 weeks for his pickles to get sour. Choices:</p><p>Ari opens the jar to find perfect pickles., Ari's pickles are sweet. Explanation:</p><p>pickles are the only thing that can be found in a jar.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question:</head><p>Gina sat on her grandpa's bed staring outside. It was winter and his garden was dead until spring. Her grandpa had passed away so there would be no one to tend it. The weeds would take over and strangle the flowers. Choices:</p><p>Gina asked her grandpa what kind of flowers he liked best., Gina decided to go outside and pick some of the weeds. Explanation: the weeds would take over and strangle the flowers. erated explanations. In the SWAG dataset, each question is a video caption from activity recognition videos with choices about what might happen next and the correct answer is the video caption of the next scene. Generated explanations for SWAG appear to be grounded in the given images even though the language model was not at all trained on SWAG. Similarly, we found that for the Story Cloze dataset, the explanations had information pointing to the correct ending. Nonetheless, the classifier was unable to make use of this information to improve performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and Future Work</head><p>We introduced the Common Sense Explanations (CoS-E) dataset built on top of the existing Com-monsenseQA dataset. We also proposed the novel Commonsense Auto-Generated Explanations (CAGE) framework that trains a language model to generate useful explanations when finetuned on the problem input and human explanations These explanations can then be used by a classifier model to make predictions. We empirically show that such an approach not only results in state-of-the-art performance on a difficult commonsense reasoning task, but also opens further avenues for studying explanation as it relates to interpretable commonsense reasoning. We also performed comprehensive error analyses of lan-guage model explanations and evaluated explanation transfer to out-of-domain datasets. While CAGE focuses on generating explanations prior to predicting an answer, language models for explanation might also be jointly trained to predict the answer. They might also be extended to a broader set of tasks. With a sufficient dataset of explanations (analogous to CoS-E) for many tasks, it might be possible to fine-tune a more general explanatory language model that generates more useful explanations for unseen tasks.</p><p>With deferral of explanation to neural models, it will be crucial in the future to study the ethical implications of biases that are accumulated during pretraining or fine-tuning. Explanations must be carefully monitored to ensure that they do not reinforce negative or otherwise harmful reasoning that might then propagate into downstream models. For example, in CQA we observed significant gender disparity and bias with higher proportion of female pronouns used in negative contexts. This kind of bias has inevitably propagated into CoS-E and advise these datasets and trained models be used with that in mind.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>A trained CAGE language model is used to generate explanations for a downstream commonsense reasoning model (CSRM), which itself predicts one of the answer choices.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>An overview of CAGE trained on CoS-E and CQA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Analysis of the CoS-E v1.0 dataset. Percent of the dataset that contains the answer, a distractor, either, at least one bigram from the question, and at least one trigram from the question.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>. CoS-E contains human explanations in 1 https://github.com/nazneenrajani/CoS-E People usually do something relaxing, such as taking trips,when they don't need to work.</figDesc><table><row><cell cols="2">Question: While eating a hamburger with friends,</cell></row><row><cell></cell><cell>what are people trying to do?</cell></row><row><cell>Choices:</cell><cell>have fun, tasty, or indigestion</cell></row><row><cell>CoS-E:</cell><cell>Usually a hamburger with friends indicates</cell></row><row><cell></cell><cell>a good time.</cell></row><row><cell cols="2">Question: After getting drunk people couldn't</cell></row><row><cell></cell><cell>understand him,it was because of his what?</cell></row><row><cell>Choices:</cell><cell>lower standards,slurred speech,</cell></row><row><cell></cell><cell>or falling down</cell></row><row><cell>CoS-E:</cell><cell>People who are drunk have difficulty speaking.</cell></row><row><cell cols="2">Question: People do what during their time off</cell></row><row><cell></cell><cell>from work?</cell></row><row><cell>Choices:</cell><cell>take trips, brow shorter, or become hysterical</cell></row><row><cell>CoS-E:</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Examples from our CoS-E dataset.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>Results on CQA dev-random-split with CoS-E used during training.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>al.,</figDesc><table><row><cell>Method</cell><cell>Accuracy (%)</cell></row><row><cell>RC (Talmor et al., 2019)</cell><cell>47.7</cell></row><row><cell>GPT (Talmor et al., 2019)</cell><cell>54.8</cell></row><row><cell>CoS-E-open-ended</cell><cell>60.2</cell></row><row><cell>CAGE-reasoning</cell><cell>64.7</cell></row><row><cell>Human (Talmor et al., 2019)</cell><cell>95.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell cols="2">: Test accuracy on CQA v1.0. The addition</cell></row><row><cell cols="2">of CoS-E-open-ended during training dramatically im-</cell></row><row><cell cols="2">proves performance. Replacing CoS-E during training</cell></row><row><cell cols="2">with CAGE reasoning during both training and infer-</cell></row><row><cell cols="2">ence leads to an absolute gain of 10% over the previous</cell></row><row><cell>state-of-the-art.</cell><cell></cell></row><row><cell>Method</cell><cell>Accuracy (%)</cell></row><row><cell>CoS-E-selected w/o ques</cell><cell>53.0</cell></row><row><cell>CoS-E-limited-open-ended</cell><cell>67.6</cell></row><row><cell>CoS-E-selected</cell><cell>70.0</cell></row><row><cell>CoS-E-open-ended w/o ques</cell><cell>84.5</cell></row><row><cell>CoS-E-open-ended*</cell><cell>89.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table /><note>Oracle results on CQA dev-random-split using different variants of CoS-E for both training and valida- tion. * indicates CoS-E-open-ended used during both training and validation to contrast with CoS-E-open- ended used only during training in Table 2.2019). We observe that using CoS-E-open-ended during training improves the state-of-the-art by ap- proximately 6%. Talmor et al.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>), the model was able to obtain 53% in contrast to the 85% achieved by the open-ended human explanations (CoS-E-open-ended). Adding the question boosts performance for CoS-E-selected to 70%, again falling short of almost 90% achieved by CoS-E-open-ended. We conclude then that our full, open-ended CoS-E thus supply a significant source of information beyond simply directing the model towards the most useful information already in the question.</figDesc><table><row><cell>Method</cell><cell>Accuracy (%)</cell></row><row><cell>CAGE-reasoning</cell><cell>55.7</cell></row><row><cell>BERT baseline</cell><cell>56.7</cell></row><row><cell>CoS-E-open-ended</cell><cell>58.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>Test results on CQA v1.11.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table /><note>Results for explanation transfer from CQA to out-of-domain SWAG and Sotry Cloze tasks.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>, using CAGE-reasoning at both train</cell></row><row><cell>and validation resulted in an accuracy of 72%,</cell></row><row><cell>but Table 4 shows that if CAGE-reasoning truly</cell></row><row><cell>captured all information provided in CoS-E-open-</cell></row><row><cell>ended, performance would be 90%. This gap be-</cell></row><row><cell>tween CAGE and CoS-E prompted further analy-</cell></row><row><cell>sis.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head></head><label></label><figDesc>What could people do that involves talking? Choices: confession, carnival, state park CoS-E: confession is the only vocal action. Reason people talk to each other Rationale: people talk to people Question: A child wants to play, what would they likely want? Choices: play tag, breathe, fall down CoS-E: A child to play tag Reason Children want to play tag, and they want to play tag with their friends.</figDesc><table><row><cell>Rationale: Children want to play tag, what would they want to do?</cell></row><row><cell>Question: They were getting ready for a really long hike, he put the food</cell></row><row><cell>in his what?</cell></row><row><cell>Choices: recycling center, house, backpack</cell></row><row><cell>CoS-E: Backpacks are used on hikes</cell></row><row><cell>Reason a backpack is a place to store food and supplies.</cell></row><row><cell>Rationale: a backpack is used to carry food and supplies</cell></row><row><cell>Question: You can do knitting to get the feeling of what?</cell></row><row><cell>Choices: relaxation, your, arthritis</cell></row><row><cell>CoS-E: Your are focusing on a repetitive task.</cell></row><row><cell>Reason knitting is the only thing that is relaxing.</cell></row><row><cell>Rationale: you can do knitting to get the feeling of what?</cell></row></table><note>Question:</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 9 :</head><label>9</label><figDesc>Random sample of explanations generated by the language model fine-tuned on CQA and transferred without further training to SWAG and Story Cloze. Bold indicates ground-truth.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://www.tau-nlp.org/csqa-leaderboard</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank Melvin Gruesbeck for the illustration of CAGE in <ref type="figure">Figure 1</ref>. We also thank the anonymous reviewers for their feedback.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">VQA: Visual Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislaw</forename><surname>Antol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aishwarya</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiasen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A large annotated corpus for learning natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Samuel R Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP2015)</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP2015)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="632" to="642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">e-SNLI: Natural Language Inference with Natural Language Explanations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oana-Maria</forename><surname>Camburu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rocktäschel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Lukasiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS2018)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="9560" to="9572" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Supervised learning of universal sentence representations from natural language inference data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Loïc</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP2017)</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP2017)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="670" to="680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Semi-supervised sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Neural Information Processing Systems (NIPS2015)</title>
		<meeting>the 28th International Conference on Neural Information Processing Systems (NIPS2015)</meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3079" to="3087" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Long and Short Papers</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Training classifiers with natural language explanations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Braden</forename><surname>Hancock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paroma</forename><surname>Varma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephanie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Bringmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Ré</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (ACL2018)</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (ACL2018)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1884" to="1895" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Universal language model fine-tuning for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (ACL2018)</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (ACL2018)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="328" to="339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Rationalizing neural predictions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommi</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP2016)</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP2016)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="107" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The winograd schema challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hector</forename><surname>Levesque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ernest</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leora</forename><surname>Morgenstern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirteenth International Conference on the Principles of Knowledge Representation and Reasoning</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A SICK cure for the evaluation of compositional distributional semantic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Marelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Menini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luisa</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raffaella</forename><surname>Bernardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Zamparelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC&apos;14)</title>
		<meeting>the Ninth International Conference on Language Resources and Evaluation (LREC&apos;14)<address><addrLine>Reykjavik, Iceland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="216" to="223" />
		</imprint>
	</monogr>
	<note>European Language Resources Association (ELRA</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learned in translation: Contextualized word vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6294" to="6305" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The natural language decathlon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Shirish Keskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.08730</idno>
	</analytic>
	<monogr>
		<title level="m">Multitask learning as question answering</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A corpus and cloze evaluation for deeper understanding of commonsense stories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nasrin</forename><surname>Mostafazadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucy</forename><surname>Vanderwende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Allen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL2016)</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL2016)<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="839" to="849" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual meeting on Association for Computational Linguistics (ACL2002)</title>
		<meeting>the 40th Annual meeting on Association for Computational Linguistics (ACL2002)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP2014)</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (EMNLP2014)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.05365</idno>
		<title level="m">Deep contextualized word representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Tim Salimans, and Ilya Sutskever</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Improving language understanding by generative pre-training</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Stacking with auxiliary features for visual question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fatema</forename><surname>Nazneen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><surname>Rajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2217" to="2226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Ensembling visual explanations for vqa</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fatema</forename><surname>Nazneen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Rajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NIPS 2017 workshop on Visually-Grounded Interaction and Language (ViGIL)</title>
		<meeting>the NIPS 2017 workshop on Visually-Grounded Interaction and Language (ViGIL)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Bidirectional attention flow for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min Joon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aniruddha</forename><surname>Kembhavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno>abs/1611.01603</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">CommonsenseQA: A question answering challenge targeting commonsense knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Lourie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Long and Short Papers</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4149" to="4158" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">A simple method for commonsense reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Trieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Trinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.02847</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS2017)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amapreet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel R</forename><surname>Bowman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.07461</idno>
		<title level="m">Glue: A multi-task benchmark and analysis platform for natural language understanding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Understanding natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Winograd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive psychology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="191" />
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Swag: A large-scale adversarial dataset for grounded commonsense inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rowan</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP2018)</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing (EMNLP2018)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="93" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Improving question answering by commonsense-based pre-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanjun</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiahai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Yin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.03568</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
