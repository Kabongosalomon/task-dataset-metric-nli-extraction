<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Train Sparsely, Generate Densely: Memory-efficient Unsupervised Training of High-resolution Temporal GAN</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masaki</forename><surname>Saito</surname></persName>
							<email>msaito@preferred.jp</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shunta</forename><surname>Saito</surname></persName>
							<email>shunta@preferred.jp</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masanori</forename><surname>Koyama</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sosuke</forename><surname>Kobayashi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masaki</forename><surname>Saito</surname></persName>
							<email>masomatics@preferred.jp</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shunta</forename><surname>Saito</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masanori</forename><surname>Koyama</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sosuke</forename><surname>Kobayashi</surname></persName>
						</author>
						<title level="a" type="main">Train Sparsely, Generate Densely: Memory-efficient Unsupervised Training of High-resolution Temporal GAN</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Generative Adversarial Network · Video generation · Subsampling layer</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Training of Generative Adversarial Network (GAN) on a video dataset is a challenge because of the sheer size of the dataset and the complexity of each observation. In general, the computational cost of training GAN scales exponentially with the resolution. In this study, we present a novel memory efficient method of unsupervised learning of high-resolution video dataset whose computational cost scales only linearly with the resolution. We achieve this by designing the generator model as a stack of small sub-generators and training the model in a specific way. We train each sub-generator with its own specific discriminator. At the time of the training, we introduce between each pair of consecutive sub-generators an auxiliary subsampling layer that reduces the frame-rate by a certain ratio. This procedure can allow each sub-generator to learn the distribution of the video at different levels of resolution. We also need only a few GPUs to train a highly complex generator that far outperforms the predecessor in terms of inception scores. The source code is available at https://github.com/pfnet-research/tgan2.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Generative Adversarial Network (GAN) is a powerful family of unsupervised learning, and various versions of GANs have been developed to date for different types of datasets, including image and audio dataset. GANs have been particularly successful for its application to image dataset <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b5">6]</ref>.</p><p>In this study, we present a novel method of unsupervised learning for video dataset, an important type of dataset with numerous applications such as autonomous vehicles, creative tasks, video compression, and frame interpolation.</p><p>There are two major challenges in training a generative model for video dataset. The first challenge comes from the sheer complexity of each observation. Video has a time dimension in addition to width and height, and the correlation between each pair of time frames are usually governed by complex dynamics underlying the system. Also, many applications of video generation methods-including those pertaining to industrial projects-require every frame of the generated video to be photo-realistic. This is a challenging problem on its own because photo-realistic image generation has been made possible only recently with the invention of techniques to stabilize the training of GANs on large dataset <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b32">33]</ref>. One must not only prepare a model that is sophisticated enough to produce a photo-realistic video but also to come up with an appropriate strategy to train the model stably within a reasonable time frame and computational resource.</p><p>The second challenge is the size of the dataset to be used in the training process. Unsupervised learning of generative model usually requires large dataset to guarantee high generalization ability. This can be a particular problem for the learners of video dataset because each observation is large on its own. Moreover, the required computational resource grows exponentially with the resolution. A naive approach is bound to fail because one must reserve massive resource for both high-resolution dataset and the set of model parameters.</p><p>Most previous studies have only focused on improving the photo-realism of the output <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b48">49]</ref> while using the dataset of low-resolution videos in the range of 64 × 64 for the training.</p><p>In general, batch-size is limited by the memory capacity of GPU, and under a situation where the number of usable GPU is limited, it is unrealistic in practice to use a sufficiently large batch size for the training of currently available models on 256 × 256 resolution videos with few GPUs. These challenges warrant a clever mechanism to train a massive model fast in a memory-efficient manner.</p><p>We resolve these two problems by introducing a separate architecture into the model at the time of the training. Our generator is a stack of multiple subgenerators, in which each sub-generator takes a video of intermediate feature maps as an input and outputs a video of more complex intermediate features with the same number of frames <ref type="figure">(Figure 1)</ref>. At the training process, we introduce a subsampling layer between each sub-generator and force the intermediate features from each sub-generator to make a detour to a subsampling layer that reduces its frame-rate by a certain ratio. For example, if the video of intermediate features at k − 1th layer has m frames, the sub-generator at k-th level will receive a sparse, subsampled version of the video with m/s t frames at the time of the training, where s t ≥ 1 denotes the subsampling rate. This way, the sub-generators at low level are made to receive highframe-rate, low-resolution videos of abstract and global information, and the sub-generators at a high level are made to receive low-frame-rate, high-resolution videos of local information. This procedure can significantly reduce the computational cost and the memory requirement during the training process. Also, by preparing a separate discriminator for each sub-generator, we evaluate the fidelity of the generated video at various levels of resolution.</p><p>Because local information tends to be slow in changing (low frame-rate), our design of the division of roles allows us to produce high-resolution videos with high fidelity while keeping the memory consumption low. Our method can efficiently train a generator that can generate videos with significantly higher inception score (∼ 26) than all predecessors.           <ref type="figure">Fig. 1</ref> The generator using multiple subsampling layers.</p><formula xml:id="formula_0">F b Q I n j A B V I t B O / s t 3 Q Q W B m t N A m P O X o i v 3 7 h w d p 7 V L m Q S n B z e 3 F X k t e 1 R v X r n g 5 8 V x V t U P F z h c V t a B O 0 z Y D O u M G m R P L A I A Z H r x S N g c D z I W k + v 3 B g P 4 Z R m 2 Q h q j W l u c G F u i a d U O i 1 G H W X P 6 D 5 i w 0 Z l h k I 2 R x 6 r P W d l 7 4 O G 0 6 / v Q K / h W G W A 2 + D d y 7 C g 0 4 b Z 7 5 D E w p u W p C z G X 2 v E X / E 8 L Z b 2 F A 4 c L p x X t e B q O d 7 T T g 9 7 v x 3 k 5 3 6 w 3 y m D w h T 0 l K X p A 9 8 o Y c k C F h x J C v 5 B v 5 H h 1 G H 6 N P 0 e d z a d T r / j w i a x V 9 + Q V q H O U C &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " o V x F G F o e l d 3 2 h E 0 i H v T p i E I F v + Q = " &gt; A A A C 0 n i c f V H L a h R B F K 1 p X 3 F 8 J b p 0 U 9 g M i E j o D g F d B i L o R o y Y m Q S m J 8 P t m t s 9 x d S j q a o O G Y t e i F s / w K 1 + g P / j 3 1 g 9 a d F J o h c K D u e e u v d w b l 4 J b l 2 S / O x F 1 6 7 f u H l r 4 3 b / z t 1 7 9 x 9 s b j 0 c W V 0 b h k O m h T b H O V g U X O H Q c S f w u D I I M h d 4 l C / 2 2 / 7 R K R r L t T p 0 y w o n E k r F C 8 7 A B e r E Z w w E / d C c v J 7 6 t J l u x s l 2 s i p 6 G a Q d i E l X B 9 O t 3 o 9 s p l k t U T k m w N p x m l R u 4 s E 4 z g Q 2 / a y 2 W A F b Q I n j A B V I t B O / s t 3 Q Q W B m t N A m P O X o i v 3 7 h w d p 7 V L m Q S n B z e 3 F X k t e 1 R v X r n g 5 8 V x V t U P F z h c V t a B O 0 z Y D O u M G m R P L A I A Z H r x S N g c D z I W k + v 3 B g P 4 Z R m 2 Q h q j W l u c G F u i a d U O i 1 G H W X P 6 D 5 i w 0 Z l h k I 2 R x 6 r P W d l 7 4 O G 0 6 / v Q K / h W G W A 2 + D d y 7 C g 0 4 b Z 7 5 D E w p u W p C z G X 2 v E X / E 8 L Z b 2 F A 4 c L p x X t e B q O d 7 T T g 9 7 v x 3 k 5 3 6 w 3 y m D w h T 0 l K X p A 9 8 o Y c k C F h x J C v 5 B v 5 H h 1 G H 6 N P 0 e d z a d T r / j w i a x V 9 + Q V q H O U C &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " o V x F G F o e l d 3 2 h E 0 i H v T p i E I F v + Q = " &gt; A A A C 0 n i c f V H L a h R B F K 1 p X 3 F 8 J b p 0 U 9 g M i E j o D g F d B i L o R o y Y m Q S m J 8 P t m t s 9 x d S j q a o O G Y t e i F s / w K 1 + g P / j 3 1 g 9 a d F J o h c K D u e e u v d w b l 4 J b l 2 S / O x F 1 6 7 f u H l r 4 3 b / z t 1 7 9 x 9 s b j 0 c W V 0 b h k O m h T b H O V g U X O H Q c S f w u D I I M h d 4 l C / 2 2 / 7 R K R r L t T p 0 y w o n E k r F C 8 7 A B e r E Z w w E / d C c v J 7 6 t J l u x s l 2 s i p 6 G a Q d i E l X B 9 O t 3 o 9 s p l k t U T k m w N p x m l R u 4 s E 4 z g Q 2 / a y 2 W A F b Q I n j A B V I t B O / s t 3 Q Q W B m t N A m P O X o i v 3 7 h w d p 7 V L m Q S n B z e 3 F X k t e 1 R v X r n g 5 8 V x V t U P F z h c V t a B O 0 z Y D O u M G m R P L A I A Z H r x S N g c D z I W k + v 3 B g P 4 Z R m 2 Q h q j W l u c G F u i a d U O i 1 G H W X P 6 D 5 i w 0 Z l h k I 2 R x 6 r P W d l 7 4 O G 0 6 / v Q K / h W G W A 2 + D d y 7 C g 0 4 b Z 7 5 D E w p u W p C z G X 2 v E X / E 8 L Z b 2 F A 4 c L p x X t e B q O d 7 T T g 9 7 v x 3 k 5 3 6 w 3 y m D w h T 0 l K X p A 9 8 o Y c k C F h x J C v 5 B v 5 H h 1 G H 6 N P 0 e d z a d T r / j w i a x V 9 + Q V q H O U C &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " o V x F G F o e l d 3 2 h E 0 i H v T p i E I F v + Q = " &gt; A A A C 0 n i c f V H L a h R B F K 1 p X 3 F 8 J b p 0 U 9 g M i E j o D g F d B i L o R o y Y m Q S m J 8 P t m t s 9 x d S j q a o O G Y t e i F s / w K 1 + g P / j 3 1 g 9 a d F J o h c K D u e e u v d w b l 4 J b l 2 S / O x F 1 6 7 f u H l r 4 3 b / z t 1 7 9 x 9 s b j 0 c W V 0 b h k O m h T b H O V g U X O H Q c S f w u D I I M h d 4 l C / 2 2 / 7 R K R r L t T p 0 y w o n E k r F C 8 7 A B e r E Z w w E / d C c v J 7 6 t J l u x s l 2 s i p 6 G a Q d i E l X B 9 O t 3 o 9 s p l k t U T k m w N p x m l R u 4 s E 4 z g Q 2 / a y 2 W A F b Q I n j A B V I t B O / s t 3 Q Q W B m t N A m P O X o i v 3 7 h w d p 7 V L m Q S n B z e 3 F X k t e 1 R v X r n g 5 8 V x V t U P F z h c V t a B O 0 z Y D O u M G m R P L A I A Z H r x S N g c D z I W k + v 3 B g P 4 Z R m 2 Q h q j W l u c G F u i a d U O i 1 G H W X P 6 D 5 i w 0 Z l h k I 2 R x 6 r P W d l 7 4 O G 0 6 / v Q K / h W G W A 2 + D d y 7 C g 0 4 b Z 7 5 D E w p u W p C z G X 2 v E X / E 8 L Z b 2 F A 4 c L p x X t e B q O</formula><formula xml:id="formula_1">v b V P r y R g B 1 F X W q m z I E i G E = " &gt; A A A C y X i c f V F d a 9 R A F J 1 N / a j r V 6 u P v g y G B R E p S S n o Y 0 U f C i J W c L e F z b r c z N 5 k h 5 3 J x J l J 6 R r y 5 A / w t f 0 T / h / / j T f b i G 5 b v T B w O P f c j z k 3 L Z V 0 P o p + 9 o K N G z d v 3 d 6 8 0 7 9 7 7 / 6 D h 1 v b j 0 b O V F b g U B h l 7 H E K D p U s c O i l V 3 h c W g S d K j x K F 2 / a / N</formula><formula xml:id="formula_2">v b V P r y R g B 1 F X W q m z I E i G E = " &gt; A A A C y X i c f V F d a 9 R A F J 1 N / a j r V 6 u P v g y G B R E p S S n o Y 0 U f C i J W c L e F z b r c z N 5 k h 5 3 J x J l J 6 R r y 5 A / w t f 0 T / h / / j T f b i G 5 b v T B w O P f c j z k 3 L Z V 0 P o p + 9 o K N G z d v 3 d 6 8 0 7 9 7 7 / 6 D h 1 v b j 0 b O V F b g U B h l 7 H E K D p U s c O i l V 3 h c W g S d K j x K F 2 / a / N</formula><formula xml:id="formula_3">v b V P r y R g B 1 F X W q m z I E i G E = " &gt; A A A C y X i c f V F d a 9 R A F J 1 N / a j r V 6 u P v g y G B R E p S S n o Y 0 U f C i J W c L e F z b r c z N 5 k h 5 3 J x J l J 6 R r y 5 A / w t f 0 T / h / / j T f b i G 5 b v T B w O P f c j z k 3 L Z V 0 P o p + 9 o K N G z d v 3 d 6 8 0 7 9 7 7 / 6 D h 1 v b j 0 b O V F b g U B h l 7 H E K D p U s c O i l V 3 h c W g S d K j x K F 2 / a / N</formula><formula xml:id="formula_4">v b V P r y R g B 1 F X W q m z I E i G E = " &gt; A A A C y X i c f V F d a 9 R A F J 1 N / a j r V 6 u P v g y G B R E p S S n o Y 0 U f C i J W c L e F z b r c z N 5 k h 5 3 J x J l J 6 R r y 5 A / w t f 0 T / h / / j T f b i G 5 b v T B w O P f c j z k 3 L Z V 0 P o p + 9 o K N G z d v 3 d 6 8 0 7 9 7 7 / 6 D h 1 v b j 0 b O V F b g U B h l 7 H E K D p U s c O i l V 3 h c W g S d K j x K F 2 / a / N</formula><formula xml:id="formula_5">x E k B u Z a Z F O C J G u a f X k 3 f T j f D a C d a B b 8 M 4 g 6 E r I v D 6 V b v R z I z o i p Q e 6 H A u X E c l X 5 S g / V S K G z 6 S e W w B L G A H M c E N R T o J v V q 2 4 Y P i J n x z F h 6 2 v M V + 3 d F D Y V z y y I l Z Q F + 7 i 7 m W v K q 3 L j y 2 c t J L X V Z e d T i f F B W K</formula><formula xml:id="formula_6">x E k B u Z a Z F O C J G u a f X k 3 f T j f D a C d a B b 8 M 4 g 6 E r I v D 6 V b v R z I z o i p Q e 6 H A u X E c l X 5 S g / V S K G z 6 S e W w B L G A H M c E N R T o J v V q 2 4 Y P i J n x z F h 6 2 v M V + 3 d F D Y V z y y I l Z Q F + 7 i 7 m W v K q 3 L j y 2 c t J L X V Z e d T i f F B W K</formula><formula xml:id="formula_7">x E k B u Z a Z F O C J G u a f X k 3 f T j f D a C d a B b 8 M 4 g 6 E r I v D 6 V b v R z I z o i p Q e 6 H A u X E c l X 5 S g / V S K G z 6 S e W w B L G A H M c E N R T o J v V q 2 4 Y P i J n x z F h 6 2 v M V + 3 d F D Y V z y y I l Z Q F + 7 i 7 m W v K q 3 L j y 2 c t J L X V Z e d T i f F B W K</formula><formula xml:id="formula_8">x E k B u Z a Z F O C J G u a f X k 3 f T j f D a C d a B b 8 M 4 g 6 E r I v D 6 V b v R z I z o i p Q e 6 H A u X E c l X 5 S g / V S K G z 6 S e W w B L G A H M c E N R T o J v V q 2 4 Y P i J n x z F h 6 2 v M V + 3 d F D Y V z y y I l Z Q F + 7 i 7 m W v K q 3 L j y 2 c t J L X V Z e d T i f F B W K</formula><p>2 Related work</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Image generation</head><p>Many applications of the Generative Adversarial Network <ref type="bibr" target="#b13">[14]</ref> mainly focus on the image generation problem; this is primarily because that the Deep Convolutional Generative Adversarial Networks (DCGAN) <ref type="bibr" target="#b38">[39]</ref> demonstrated that the GAN is quite effective in image generation. After that, the DCGAN was extended to a network called Self-Attention Generative Adversarial Networks (SAGAN) <ref type="bibr" target="#b55">[56]</ref> that includes spectral normalization <ref type="bibr" target="#b33">[34]</ref> and self-attention blocks <ref type="bibr" target="#b53">[54]</ref>. BigGANs <ref type="bibr" target="#b5">[6]</ref> succeeded in generating high fidelity images by introducing several tricks such as orthogonal regularization that stabilizes the training with large batch size. In the image-to-image translation problem, which transfers an input image from its domain to another domain, there exist many studies for transforming a high-resolution image to another high-resolution image. <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b19">20]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Video-to-video translation</head><p>Recently, several studies have succeeded in converting high-resolution videos into other ones in a different domain. RecycleGAN <ref type="bibr" target="#b3">[4]</ref> extends a concept of CycleGAN <ref type="bibr" target="#b60">[61]</ref>, and solves a video retargeting problem with two video datasets for which correspondences are not given. Vid2Vid <ref type="bibr" target="#b51">[52]</ref> learns a model that maps a source domain into an output one from a pair of videos and generates high-resolution videos. Contrary to these models that can be trained well with a small batch size (e.g., one or two), image and video generation GAN requires a large batch size for the training, which makes the training of GAN models for video generation more difficult.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Multi-scale GANs</head><p>Our approach is related to methods in which a generator produces multi-scale images. LAPGAN <ref type="bibr" target="#b8">[9]</ref> first generates a coarse image and updates it by using a difference of an initial image. StackGAN <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b56">57]</ref> and HDGAN <ref type="bibr" target="#b58">[59]</ref> directly generates multi-scale images, and the corresponding discriminator returns a score from each image. Although our approach itself is similar to StackGAN and HDGAN, the most significant difference lies in the existence of sampling layers; it is useful for problems where the number of dimensions in a sample is quite large. ProgressiveGAN <ref type="bibr" target="#b23">[24]</ref> is another model that uses multiresolution images and generates high-resolution images by growing both the generator and the discriminator gradually. Although the ProgressiveGAN also saves computational cost by using low-resolution images in the early stages of the training, our method has two advantages compared to ProgressiveGAN. The first advantage is that our method does not require hyperparameters to grow the network according to the number of iterations dynamically. It also means that it does not need to dynamically change the batch size according to the number of iterations. The second is that our method can generate a large sample from the beginning regardless of the number of iterations. It is useful for evaluating inception score <ref type="bibr" target="#b42">[43]</ref> using a pre-trained model accepting only a sample with a fixed shape.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Video prediction</head><p>Video prediction, which estimates subsequent images from a given few frames, is one of the major problems in computer vision. Although there is no unified view on how to model the domain of video, many studies dealing with video prediction problem directly predict the next frame with recurrent networks such as LSTM <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b25">26]</ref>. Another well-known approach is to predict intermediate features of videos such as optical flow <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b26">27]</ref>. Some studies introduce adversarial training to avoid generating a blurred image caused by the image reconstruction loss <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b25">26</ref>].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Video generation</head><p>There are two major approaches in the field of video generation using GANs. One is a study for generating videos by incorporating dataset specific prior knowledge into the method (e.g., limiting the problem to human action generation and giving the number of parts as prior knowledge) <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b54">55]</ref>, and the other is a study that can handle any datasets without such restriction <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b0">1]</ref>. Our study is related to the latter.</p><p>We describe several models for video generation in the following. To the best of our knowledge, VGAN <ref type="bibr" target="#b50">[51]</ref> is the first model to generate videos using GANs and consists of a 2D network to generate a still background and 3D convolutional networks to generate foreground videos. After that, Saito et al. <ref type="bibr" target="#b41">[42]</ref> found that it is better to separate a spatiotemporal generator into time-series and space models to generate videos and proposed TGAN that first generates a set of latent vectors corresponding to each frame and then transforms them into actual images. MoCoGAN <ref type="bibr" target="#b48">[49]</ref> was proposed to produce videos more efficiently by decomposing the latent space into the motion and the content subspaces. Unlike TGAN where the discriminator consists of a stack of 3D convolutional layers, MoCoGAN uses two different sub-discriminators to improve the quality of videos; the first is a three-dimensional discriminator that aims to extract global motion in the video, and another is two-dimensional one that identifies from a still frame in the video.</p><p>Although these models illustrate that models using GAN are also useful in video generation, they have a problem of requiring an enormous computational cost and GPU memory. It is particularly problematic when dealing with high-resolution video. Our proposed model aims to solve it. Besides, our model can be regarded as a further extension of the MoCoGAN, where the discriminator uses two different discriminators. Although our model also uses multiple discriminators, its computational cost and memory consumption are quite lower than MoCoGAN, which directly takes the generated video as an input. It is due to the multiple subsampling layers described later.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>In this section, we first describe the conventional design of GANs for video dataset. We will describe the challenges posed by these models, and explain how our models can resolve them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">GAN models for video generation</head><p>Generative Adversarial Network is a framework of unsupervised learning in which a generator model strives to mimic the target distribution while a discriminator model strives to distinguish the samples from the target distribution from the samples synthesized by the generator. The generator synthesizes an artificial sample z   <ref type="figure" target="#fig_5">Fig. 2</ref> The overview of relationship between a temporal generator and an image generator used in conventional temporal GANs. To produce a set of T latent vectors, the temporal generator typically is a recurrent network. For the proposed method, we used a convolutional LSTM for this part as detailed in Section 4.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " S L U 7 L y 6 D B W g H D h E H Z l 6 / 5 A z E O t s = " &gt; A A A C y 3 i c f V H L a t t A F B 2 r r 9 R 9 J e 2 y m 6 H C U E o J U g i 0 y 0 C 7 6 C Y 0 h d o O W C Z c j a / k w T M j M T M y d V Q t + w H Z p v / Q / 8 n f 5 M p R a Z 2 k v T B w O P f c x 5 y b l k o 6 H 0 U X v e D O 3 X v 3 H 2 w 9 7 D 9 6 / O T p s + 2 d 5 y N X V F b g U B S q s M c p O F T S 4 N B L r / C 4 t A g 6 V T h O F x / a / H i J 1 s n C f P W r E q c a c i M z K c A T N U 6 W K O r T 5 m Q 7 j H a j d f C b I O 5 A y L o 4 O t n p / U p m h a g 0 G i 8 U O D e J o 9 J P a 7 B e C o V N P 6 k c l i A W k O O E o A G N b l q v 9 2 3 4 g J g Z z w p L z 3 i + Z v + u q E E 7 t 9 I p K T X 4 u b u e a 8 n b c p P K Z + + n t T R l 5 d G I q 0 F Z p b g v e P t 5 P p M W h V c r A i C s p F 2 5 m I M F 4 c m i f n 8 w 4 H + a c U d S 8 m h j e G p h g b 7 Z X E j l B f W a 6 3 / Q U l B i h l k y Q h H G d d K u n W Z 1 G D c d v 7 y F / 4 h k q 8 V D 4 j 6 X a M E X 9 k 2 d g M 2 1 N A 3 Z n C d v W / Q / I X z 7 L S R E F 4 6 v 3 / M m G O 3 t x o S / 7 I c H + 9 2 t t 9 h L 9 o q 9 Z j F 7 x w 7 Y J 3 b E h k y w B T t j 5 + x n c B i 4 4 D T 4 f i U N e l 3 N C 7 Y R w Y 9 L T V P i p g = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " S L U 7 L y 6 D B W g H D h E H Z l 6 / 5 A z E O t s = " &gt; A A A C y 3 i c f V H L a t t A F B 2 r r 9 R 9 J e 2 y m 6 H C U E o J U g i 0 y 0 C 7 6 C Y 0 h d o O W C Z c j a / k w T M j M T M y d V Q t + w H Z p v / Q / 8 n f 5 M p R a Z 2 k v T B w O P f c x 5 y b l k o 6 H 0 U X v e D O 3 X v 3 H 2 w 9 7 D 9 6 / O T p s + 2 d 5 y N X V F b g U B S q s M c p O F T S 4 N B L r / C 4 t A g 6 V T h O F x / a / H i J 1 s n C f P W r E q c a c i M z K c A T N U 6 W K O r T 5 m Q 7 j H a j d f C b I O 5 A y L o 4 O t n p / U p m h a g 0 G i 8 U O D e J o 9 J P a 7 B e C o V N P 6 k c l i A W k O O E o A G N b l q v 9 2 3 4 g J g Z z w p L z 3 i + Z v + u q E E 7 t 9 I p K T X 4 u b u e a 8 n b c p P K Z + + n t T R l 5 d G I q 0 F Z p b g v e P t 5 P p M W h V c r A i C s p F 2 5 m I M F 4 c m i f n 8 w 4 H + a c U d S 8 m h j e G p h g b 7 Z X E j l B f W a 6 3 / Q U l B i h l k y Q h H G d d K u n W Z 1 G D c d v 7 y F / 4 h k q 8 V D 4 j 6 X a M E X 9 k 2 d g M 2 1 N A 3 Z n C d v W / Q / I X z 7 L S R E F 4 6 v 3 / M m G O 3 t x o S / 7 I c H + 9 2 t t 9 h L 9 o q 9 Z j F 7 x w 7 Y J 3 b E h k y w B T t j 5 + x n c B i 4 4 D T 4 f i U N e l 3 N C 7 Y R w Y 9 L T V P i p g = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " S L U 7 L y 6 D B W g H D h E H Z l 6 / 5 A z E O t s = " &gt; A A A C y 3 i c f V H L a t t A F B 2 r r 9 R 9 J e 2 y m 6 H C U E o J U g i 0 y 0 C 7 6 C Y 0 h d o O W C Z c j a / k w T M j M T M y d V Q t + w H Z p v / Q / 8 n f 5 M p R a Z 2 k v T B w O P f c x 5 y b l k o 6 H 0 U X v e D O 3 X v 3 H 2 w 9 7 D 9 6 / O T p s + 2 d 5 y N X V F b g U B S q s M c p O F T S 4 N B L r / C 4 t A g 6 V T h O F x / a / H i J 1 s n C f P W r E q c a c i M z K c A T N U 6 W K O r T 5 m Q 7 j H a j d f C b I O 5 A y L o 4 O t n p / U p m h a g 0 G i 8 U O D e J o 9 J P a 7 B e C o V N P 6 k c l i A W k O O E o A G N b l q v 9 2 3 4 g J g Z z w p L z 3 i + Z v + u q E E 7 t 9 I p K T X 4 u b u e a 8 n b c p P K Z + + n t T R l 5 d G I q 0 F Z p b g v e P t 5 P p M W h V c r A i C s p F 2 5 m I M F 4 c m i f n 8 w 4 H + a c U d S 8 m h j e G p h g b 7 Z X E j l B f W a 6 3 / Q U l B i h l k y Q h H G d d K u n W Z 1 G D c d v 7 y F / 4 h k q 8 V D 4 j 6 X a M E X 9 k 2 d g M 2 1 N A 3 Z n C d v W / Q / I X z 7 L S R E F 4 6 v 3 / M m G O 3 t x o S / 7 I c H + 9 2 t t 9 h L 9 o q 9 Z j F 7 x w 7 Y J 3 b E h k y w B T t j 5 + x n c B i 4 4 D T 4 f i U N e l 3 N C 7 Y R w Y 9 L T V P i p g = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " S L U 7 L y 6 D B W g H D h E H Z l 6 / 5 A z E O t s = " &gt; A A A C y 3 i c f V H L a t t A F B 2 r r 9 R 9 J e 2 y m 6 H C U E o J U g i 0 y 0 C 7 6 C Y 0 h d o O W C Z c j a / k w T M j M T M y d V Q t + w H Z p v / Q / 8 n f 5 M p R a Z 2 k v T B w O P f c x 5 y b l k o 6 H 0 U X v e D O 3 X v 3 H 2 w 9 7 D 9 6 / O T p s + 2 d 5 y N X V F b g U B S q s M c p O F T S 4 N B L r / C 4 t A g 6 V T h O F x / a / H i J 1 s n C f P W r E q c a c i M z K c A T N U 6 W K O r T 5 m Q 7 j H a j d f C b I O 5 A y L o 4 O t n p / U p m h a g 0 G i 8 U O D e J o 9 J P a 7 B e C o V N P 6 k c l i A W k O O E o A G N b l q v 9 2 3 4 g J g Z z w p L z 3 i + Z v + u q E E 7 t 9 I p K T X 4 u b u e a 8 n b c p P K Z + + n t T R l 5 d G I q 0 F Z p b g v e P t 5 P p M W h V c r A i C s p F 2 5 m I M F 4 c m i f n 8 w 4 H + a c U d S 8 m h j e G p h g b 7 Z X E j l B f W a 6 3 / Q U l B i h l k y Q h H G d d K u n W Z 1 G D c d v 7 y F / 4 h k q 8 V D 4 j 6 X a M E X 9 k 2 d g M 2 1 N A 3 Z n C d v W / Q / I X z 7 L S R E F 4 6 v 3 / M m G O 3 t x o S / 7 I c H + 9 2 t t 9 h L 9 o q 9 Z j F 7 x w 7 Y J 3 b E h k y w B T t j 5 + x n c B i 4 4 D T 4 f i U N e l 3 N C 7 Y R w Y 9 L T V P i p g = = &lt; / l a t e x i t &gt; h 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " w Y 4 9 P T b + D o E l z r h R b Y 8 4 J s u E s S U = " &gt; A A A B 8 H i c b V D L S g N B E O z 1 G e M r 6 t H L Y B A 8 h d 0 o 6 D H g x W M E 8 5 A k h N n J b D J k Z n a Z 6 R X C k q / w 4 k E R r 3 6 O N / / G S b I H T S x o K K q 6 6 e 4 K E y k s + v 6 3 t 7 a + s b m 1 X d g p 7 u 7 t H x y W j o 6 b N k 4 N 4 w 0 W y 9 i 0 Q 2 q 5 F J o 3 U K D k 7 c R w q k L J W + H 4 d u a 3 n r i x I t Y P O E l 4 T 9 G h F p F g F J 3 0 m H X D i I y m / a B f K v s V f w 6 y S o K c l C F H v V / 6 6 g 5 i l i q u k U l q b S f w E + x l 1 K B g k k + L 3 d T y h L I x H f K O o 5 o q b n v Z / O A p O X f K g E S x c a W R z N X f E x l V 1 k 5 U 6 D o V x Z F d 9 m b i f 1 4 n x e i m l w m d p M g 1 W y y K U k k w J r P v y U A Y z l B O H K H M C H c r Y S N q K E O X U d G F E C y / v E q a 1 U p w W a n e X 5 V r 1 T y O A p z C G V x A A N d Q g z u o Q w M Y K H i G V 3 j z j P f i v X s f i 9 Y 1 L 5 8 5 g T / w P n 8 A P R C P / A = = &lt; / l a t e x i t &gt; z 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " F N Z g r N k Y 9 Q 3 V x D n w T k y p s t K l k L w = " &gt; A A A B 8 H i c b V B N S w M x E J 3 U r 1 q / q h 6 9 B I v g q e x W Q Y 8 F L x 4 r 2 A 9 p l 5 J N s 2 1 o k l 2 S r F C X / g o v H h T x 6 s / x 5 r 8 x b f e g r Q 8 G H u / N M D M v T A Q 3 1 v O + U W F t f W N z q 7 h d 2 t n d 2 z 8 o H x 6 1 T J x q y p o 0 F r H u h M Q w w R V r W m 4 F 6 y S a E R k K 1 g 7 H N z O / / c i 0 4 b G 6 t 5 O E B Z I M F Y 8 4 J d Z J D 1 k v j P D T t O / 3 y x W v 6 s 2 B V 4 m f k w r k a P T L X 7 1 B T F P J l K W C G N P 1 v c Q G G d G W U 8 G m p V 5 q W E L o m A x Z 1 1 F F J D N B N j 9 4 i s + c M s B R r F 0 p i + f q 7 4 m M S G M m M n S d k t i R W f Z m 4 n 9 e N 7 X R d Z B x l a S W K b p Y F K U C 2 x j P v s c D r h m 1 Y u I I o Z q 7 W z E d E U 2 o d R m V X A j + 8 s u r p F W r + h f V 2 t 1 l p V 7 L 4 y j C C Z z C O f h w B X W 4 h Q Y 0 g Y K E Z 3 i F N 6 T R C 3 p H H 4 v W</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>y f K v 3 R S F s a J o i G Z L / I T j l S E Z n m g I R O U K D 7 V g I l g + q + I j L H A R O n U K j o E e / H k v 9 B p 1 O 2 z e u P m v N p s F H G U 4 R C O o A Y 2 X E A T r q E F b S D w A E / w A q / G o / F s v</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " H x A y 7 o F h s j z k / L M G 5 Q O m V T p I G K 0 = " &gt; A A A C A H i c b Z D L S s N A F I Z P 6 q 3 W W 9 S F C z e D R a g g J a m C L g t u X F a w F 2 h L m E w n 7 d D J J M x M h B q y 8 V X c u F D E r Y / h z r d x 2 m a h r T 8 M f P z n H M 6 c 3 4 8 5 U 9 p x v q 3 C y u r a + k Z x s 7 S 1 v b O 7 Z + 8 f t F S U S E K b J O K R 7 P h Y U c 4 E b W q m O e 3 E k u L Q 5 7 T t j 2 + m 9 f Y D l Y p F 4 l 5 P Y t o P 8 V C w g B G s j e X Z R 0 P P r a Q 9 P 0 C P 2 T n K w X P P P L v s V J 2 Z 0 D K 4 O Z Q h V 8 O z v 3 q D i C Q h F Z p w r F T X d W L d T 7 H U j H C a l X q J o j E m Y z y k X Y M C h 1 T 1 0 9 k B G T o 1 z g A F k T R P a D R z f 0 + k O F R q E v q m M 8 R 6 p B Z r U / O / W j f R w X U / Z S J O N B V k v i h I O N I R m q a B B k x S o v n E A C a S m b 8 i M s I S E 2 0 y K 5 k Q 3 M W T l 6 F V q 7 o X 1 d r d Z b l e y + M o w j G c Q A V c u I I 6 3 E I D m k A g g 2 d 4 h T f r y X q x 3 q 2 P e W v B y m c O 4 Y + s z x + e f Z U V &lt; / l a t e x i t &gt;</head><p>by applying a network function G to a sample from an user-specified prior distribution p z . The discriminator network D classifies an input as real or synthetic. Let us denote a sample from p z by z, and denote a sample from p d (target distribution) by x. The training of these networks is performed by alternately maximizing and minimizing the following objective:</p><formula xml:id="formula_9">E x∼p d [ln D(x)] + E z∼pz [ln(1 − D(G(z)))],<label>(1)</label></formula><p>Conventional temporal GAN (i.e., TGAN and MoCo-GAN) uses a generator consisting of two sub-networks: temporal generator g 0 and image generator g 1 . For the generation of a T -frame video, temporal generator generates a size-T set of latent vectors (or a T -frame video in the latent space) {z 1 , . . . , z T } from noise vector z, and image generator transforms the video of latent vectors and the noise vector into the video of images as shown in <ref type="figure" target="#fig_5">Figure 2</ref>. The synthesized video is then classified as synthetic or real by a discriminator network consisting of three-dimensional convolutional layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Subsampling layer</head><p>As mentioned in the introduction, the conventional architecture introduced above is memory inefficient. A memory that must be reserved for the three dimensional convolutional layer in the discriminator is especially heavy, and the number of parameters in the model can be literally on order 100 million. Because GPU must reserve a large space for massive G and D, currently available lines of GPU cannot process a sufficient batch when a video is larger than 64 × 64 pixels with 16 frames.</p><p>In order to resolve this resource shortage, we introduce an architecture called subsampling layer s at the time of training.</p><p>For simplicity, we first describe the training of GAN with a single subsampling layer. Suppose a generator that outputs video x from noise vector z and consists of two blocks: abstract block g A and rendering block g R . The abstract block computes the latent feature map (we call it an abstract map) from noise vector, and the rendering block transforms it into a video. In inference time, the generation process of samples by this generator is equivalent to that of the generator in the conventional GAN; that is, G(z) can be represented by</p><formula xml:id="formula_10">x = G(z) = g R • g A (z).</formula><p>(2)</p><p>The discriminator in conventional temporal GANs computes a score from a high-frame rate video of original resolution. This can be especially costly when the original resolution is high. To cope with this problem, in the training stage, we modify G into G as follows by introducing between g R and g A a subsampling layer S G that reduces the frame rate of the abstract map produced from g A .</p><p>With G , the subsampled video x is produced by applying g R to S G (g A (z)). That is,</p><formula xml:id="formula_11">x = G (z) = g R • S G • g A (z).<label>(3)</label></formula><p>The discriminator D then evaluates the score for x .</p><p>In the training process of D, one must also prepare a set of real data to compare against the synthetic data. We prepare this by applying S D to the real videos, an architecture that downscales the resolution and reduces the frame-rate so that the dimension of the output tensor matches the output of G .</p><p>In other words, in the training stage of our method, the objective of Equation (1) can be rewritten by</p><formula xml:id="formula_12">E x∼p d [ln D (S D (x))] + E z∼pz [ln(1 − D (G (z)))]. (4)</formula><p>This way, we can significantly reduce the burden on the discriminator. The computational cost for D is much smaller than the original D.</p><p>Indeed, this benefit comes at the cost of making the domain of the video at the inference-time differ from that of the video at the training time. We introduce two tricks to deal with this problem. The first trick is to statically change the position of the first frame (that is, we sample video at times ts t + b t with random b t ; cf. Equation (9)) so that there will be no frames that are not sampled. The second trick is to use multiple subsampling layers that drop the frame rate by different scales. We describe the detail of this method in the next subsection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Multiple subsampling layers</head><p>Unfortunately, however, we experimentally observed that the scores of the samples generated by the architecture in the previous section are significantly lower than those generated by the naive implementation without the subsampling layer. By using a model made of multiple sub-generators and multiple subsampling layers, however, we can drastically reduce the overall computational cost without compromising the quality of the video. In fact, the quality of the video generated by our stacked sub-generator is significantly better than that of the video generated by the conventional architecture. Below we elaborate the construction of the model <ref type="figure">(Figure 1)</ref>. We describe the model consisting of L sub-generators, or L abstract blocks. At the time of the training, this architecture is trained with L corresponding rendering blocks and L − 1 subsampling layers.</p><p>Let us denote the abstract block, rendering block, and the subsampling layer at level l by g A l , g R l , and S G l respectively. In the inference time, x can be evaluated simply by sequentially applying abstract blocks and rendering with a single g R L , i.e.,</p><formula xml:id="formula_13">x = g R L • g A L • g A L−1 • · · · • g A 1 (z).<label>(5)</label></formula><p>Here and also in the following explanation, g A 1 includes the temporal generator g 0 , but we abuse the notation g A 1 as g A 1 • g 0 for simplicity (see <ref type="figure">Figure 1</ref>). Note that the noise vector is concatenated with each latent vector from the temporal generator only when it is input to the first image generator g A 1 . In the training time, we use L-set of sub-generators consisting of G l (z), each of which recursively applies g A m and S G m (m = 1, . . . , l − 1) to abstract maps and converting the output of the final abstract block g A l to the video by g R l :</p><formula xml:id="formula_14">G 1 = g R 1 • g A 1 G 2 = g R 2 • g A 2 • S G 1 • g A 1 .</formula><p>. .</p><formula xml:id="formula_15">G L = g R L • g A L • S G L−1 • g A L−1 • · · · • S G 1 • g A 1 .<label>(6)</label></formula><p>Note that in our implementation, all rendering blocks (g R i (i = 1, . . . , L)) do not have any shared parameters, i.e., every block has its own parameters. G 1 is a model that generates a video of lowest resolution and highestframe-rate. It applies g A 1 to the high-frame-rate video of latent vectors and applies g R 1 to the result to produce a high-frame-rate video of low-resolution images x 1 . G 2 on the other hand reduces the frame-rate of the video output of g A 1 with S G 1 , feed the subsampled video to g A 2 , and converts the output of g A 2 to a video of higher resolution image x 2 by g R 2 . Defined recursively, G L generates a video of highest resolution and lowest-framerate. Because the increase in the resolution is countered by the decrease in frame-rate, the computational cost for G L does not increase exponentially with the resolution of the video.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Multiple discriminators</head><p>In order to train the above generator consisting of multiple sub-generators G 1 , . . . , G L , we need a discriminator that evaluates a score for the set of videos produced by them. Our discriminator consists of multiple subdiscriminators. Let D l be the l-th sub-discriminator that takes a sample x l from l-th sub-generator G l and returns a scalar value. Our discriminator D evaluates a score for a set of x l s by the following formula:</p><formula xml:id="formula_16">D (x 1 , . . . , x L ) = σ L l=1 D l (x l ) ,<label>(7)</label></formula><p>where σ(·) is a sigmoid function. To take a sample from the raw dataset and evaluate a score for it, we apply S D l to each raw video, which downscales the resolution and reduces the frame-rate, so that the output will match the synthetic video produced by G l .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Role of each discriminator</head><p>The essence of our method is the division of roles; instead of feeding the dense raw dataset of a single massive model, we train each sub-generator with select parts of the dataset that can help the sub-generator improve at playing the given role. The role of the sub-generator with low indices is to mimic the original video dataset at an abstract level; that is, to produce a low-resolution video that flows naturally with time. The discriminators with low indices are responsible for evaluating the quality of highframe-rate videos of low resolution. This allows the generators with low indices to capture global motion in the video that is independent from high resolution details.</p><p>On the other hand, the role of the sub-generator with high indices is to mimic the original video dataset in visual quality. That is, they only require a low framerate video of high resolution to train. The discriminator with the highest index in our model may in fact be designed to evaluate the fidelity of the still image (one frame).</p><p>Our model can also be regarded as an extension of MoCoGAN, a model that uses two different discriminators.</p><p>Our method also aims to reduce both computational cost and memory consumption simultaneously. We will further discuss this topic in Section 4.3.</p><p>4 Network architecture</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Generator</head><p>We describe our design of a generator consisting of four sub-generators that synthesizes a video with T frames and W × H pixels. As with the TGAN <ref type="bibr" target="#b41">[42]</ref> and MoCo-GAN <ref type="bibr" target="#b48">[49]</ref>, our generator first produces T latent feature maps from a noise vector and then transforms each map into a corresponding frame (see <ref type="figure" target="#fig_5">Figure 2</ref>). The specific network structure is shown in <ref type="figure">Figure 3</ref> and <ref type="figure">Figure 4</ref>.</p><p>We first describe the flow of the inference. Given d-dimensional noise vector z randomly drawn from the uniform distribution within a range of [−1, 1], the generator converts it into a feature map of (W/64)×(H/64) pixel resolution through a fully-connected layer. A recurrent block consisting of a Convolutional LSTM <ref type="bibr" target="#b43">[44]</ref> (CLSTM) receives this feature map as an input, and then returns another feature map with the same shape. Note that at t = 0 the CLSTM receives the feature map derived from z as input, but at t ≥ 1 it always receives a feature map derived from a zero vector (i.e., z is used to initialize the state of the CLSTM). After that, each feature map is transformed into another feature map with W × H pixels by six upsampling blocks, and a rendering block renders it into the frame (As we mentioned before, all g R i (i = 1, . . . , L) do not share any parameters and have their own parameters). That is, the upsampling block is a function that outputs a feature map whose resolution is double that of the input feature map, and the rendering block converts it to the image while maintaining the resolution.</p><p>In the training phase, the generator progressively reduces the size of abstract maps with the three subsampling layers placed between each g A i . Each layer is given the role of reducing the number of frames.</p><p>Consider for example an abstract map h with C h channels, T h frames, width W h and height H h . We represent each element of this tensor by h c,t,h,w . The subsampling layer with reduction rate s t reduces the shape of h to (C h × T h /s t × H h × W h ); The output h produced from subsampling layer is the following probabilistic mixture of subsampled versions of h c,t,h,w :</p><formula xml:id="formula_17">h c,τ,h,w = t B(τ, n, t)h c,t,h,w ,<label>(8)</label></formula><p>where B is a Boolean function given by</p><formula xml:id="formula_18">B(τ, n, t) = 1 if τ = ts t + b t 0 otherwise (9)</formula><p>with b t being a sample from discrete uniform distribution U{0, min(s t , T h ) − 1}. Using the slicing notation of NumPy <ref type="bibr" target="#b37">[38]</ref>, the above equation can be evaluated easily by invoking hd = h[:, bt::st]. In experiments, we set s t to the same value for all subsampling layers. The advantage of this strategy is that it can prevent the memory consumption of the discriminator from growing exponentially with the resolution.</p><p>For this example model, the amount of GPU memory required by the discriminator will be constant regardless of the resolution if s t ≥ 4 and T is sufficiently large.</p><p>At the same time, if s t is too large relative to T , the number of frames will reduce to 1 at a block close to the input layer, and there will be no computational gain from the subsampling layer from that point onward. The number of original frames required to guarantee the constant-order computational cost at every block grows exponentially with s t . It is therefore important to choose the appropriate pair of s t and the number of blocks that suits the purpose and the memory capacity of GPU.</p><p>In Section 5 we will investigate the effect of the choice of s t on the quality of the generated video.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Discriminator</head><p>As we described in Section 3.3, our discriminator consists of several sub-discriminators. In our implementation, we used four 3D ResNet models, each containing several spatiotemporal three-dimensional residual blocks <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18]</ref> and one fully-connected layer. The network configuration of each 3D ResNet was almost the same as the discriminator used in Miyato et al. <ref type="bibr" target="#b33">[34]</ref> except that the kernel of all convolutional layers was replaced with (3 × 3) to (3 × 3 × 3). For more details, see <ref type="figure">Figure 4</ref>. As for the initializers, we used the Gloro-tUniform initializer <ref type="bibr" target="#b12">[13]</ref> with a scale √ 2 in the residual paths of both the "Up(C)" and the "Down(C)", and the normal GlorotUniform initializer in the shortcut paths.</p><p>We shall emphasize that, even though all sub-discriminators are given the same network structure, they all play different roles in the model as a whole. The sub-discriminator with the lowest index evaluates the fidelity of the global flow of a given video, and the subdiscriminator with the highest index evaluates the photorealism of randomly selected several frames.  <ref type="figure">Fig. 3</ref> Network configuration of our model. "CLSTM(C)" represents the convolutional LSTM with C channels and 3 × 3 kernel. "Up(C)" means the upsampling block that returns a feature map with C channels and twice the resolution of the input. <ref type="figure">Fig. 4</ref> Details of the blocks used in the main paper. "Conv(C, k)" denotes a 2D convolutional layer with C channels and (k × k) kernel. "Conv3D(C, k)" denotes a 3D convolutional layer with C channels and (k × k × k) kernel. "UnPool" denotes a 2D unpooling layer with (2 × 2) kernel and stride 2. "AvgPool2D" denotes a 2D average pooling layer along the spatial dimensions with (2 × 2) kernel and stride 2. Note that it does not perform pooling operation along the temporal dimension. "DownSample" means the downsampling operator. If the size of each dimension of the input 3D feature maps is larger than one, this operator performs the average pooling along its axis (if the size is odd when performing the average pooling, the padding of the target axis is set to one). Otherwise, average pooling is not performed for that axis. (·) in "Up(C)" means that the blocks in the bracket are not inserted if the number of input channels is equivalent to that of output channels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Computational cost and Memory</head><p>The computational cost and the memory consumption of the generator differ in nature from those of the discriminator (see <ref type="figure" target="#fig_13">Figure 5</ref> and <ref type="table" target="#tab_0">Table 1</ref>.)</p><p>While the computational cost of the generator is almost constant for each block, the cost of the discriminator increases exponentially with the level of the block. On the other hand, the memory consumption of both generator and discriminator grows exponentially with the level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method GFlops Ratio Memory Ratio</head><p>Gen (naive impl.) <ref type="bibr" target="#b44">45</ref>   <ref type="figure">Figure 3</ref> and the corresponding rendering block. Each block of the discriminator corresponds to each sub discriminator. The number of frames used for generation is 16, and the batch size is 1.</p><p>This is problematic because the computational cost and the memory consumption of 3D ResNet are particularly high for the discriminator.</p><p>As shown in <ref type="table" target="#tab_0">Table 1</ref>, the computational cost for the discriminator tends to be significantly heavier than that of the generator even when using a single 3D discriminator in the setting of ordinary GAN. This is also true when using a discriminator similar to the one used in MoCoGAN ("3D + 2D dis" in <ref type="table" target="#tab_0">Table  1</ref>. See Section 5.3 for details.) The computational cost for the discriminator grows exponentially with the dimension of the video, and some countermeasure must be taken if one wishes to conduct unsupervised learning of high-resolution video with limited number of GPUs.</p><p>By successively reducing the frame-rate of the video with the aforementioned subsampling layer, however, we can prevent the computational cost from growing exponentially.</p><p>When the number of frames reduced by the subsampling layer is half of the original (i.e., s t = 2), we can improve the total memory usage and computational cost of the model four∼five times over the vanilla model without subsampling layers.</p><p>Meanwhile, this mechanism does not improve the computational cost of the generator as much. However, most part of the overall computational cost comes from the discriminator, and this mechanism alone can reduce the overall computational cost to a reasonable level.</p><p>In general, the computational gain increases with the size of s t . When the original number of frames is sufficiently large and s t ≥ 4, the computational cost for each sub-generator will be roughly kept constant because at each block, the number of frame decreases by the rate of 4 while the height and the width doubles.</p><p>The computational gain is not as high in our implementation because the number of original frames used in our experiments was just 16. For example, <ref type="figure" target="#fig_13">Figure 5</ref> shows that the actual memory consumption at the level 4 in the generator is larger than that of the level 3 because the number of frames handled by the level 3 is one since the number of original frames is 16.</p><p>Even still, the memory consumption of our model with s t = 4 was about 60% better than that of s t = 2.</p><p>Thus, the computational gain from subsampling layer tends to increase with the size of s t .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Dataset</head><p>We use three subsampling functions to make four subsampled videos from one example video in the dataset. For the sample to be used for the sub-discriminator with index= 1, we only apply one resize function to lower the resolution of the video by one eighth. Meanwhile, the last sub-discriminator receives a video that was produced by applying three subsampling layers defined in Equation <ref type="formula" target="#formula_17">(8)</ref> to the input example. This transformation reduces the number of frames to 1/s 3 t while maintaining the resolution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Regularizer</head><p>To improve the performance of the generator, we augmented the loss of the discriminator at level l with a zero-centered gradient penalty evaluated over the target data distribution <ref type="bibr" target="#b32">[33]</ref>, given by</p><formula xml:id="formula_19">R 1 = λ L l=1 n l i=1 ∇D l (x l ) 2 ,<label>(10)</label></formula><p>where λ is a weight and n l represents the batch size at level l.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Conditional model</head><p>In the previous discussion, we only focus on the problem where the generator can only accept a noise vector as an input. However, as with the field of the image generation (c.f., BigGAN <ref type="bibr" target="#b5">[6]</ref>), we can extend the proposed method to accept not only the noise vector but also a discrete integer label representing a category of the dataset. Giving such information as an argument of the generator and the discriminator, we can further improve the quality of the generated videos. Specifically, we extend the generator and the discriminator according to the following. In the generator, we first transform the discrete label into one-hot vector l, concatenate it with noise vector z to obtain another vector represented by <ref type="bibr">[l, z]</ref>. Using this vector as the input of of the FC layer in <ref type="figure">Figure 3</ref>, the discrete label information can be propagated to the ConvLSTM. Regarding the extension of the image generator (i.e., the upsampling blocks after the ConvLSTM), we adopted the technique performed by Miyato et al. <ref type="bibr" target="#b33">[34]</ref>; that is, we replace all the batch normalization layers with conditional batch normalization layers to ensure that all the blocks receive discrete label information. In the discriminator, we add a perturbation vector for the label to the final layer of each sub-discriminator according to a method of projection discriminator <ref type="bibr" target="#b34">[35]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets</head><p>We used the following two datasets in the experiments. UCF101 UCF101 is a common video dataset that contains 13,320 videos with 320 × 240 pixels and 101 different sport categories such as Baseball Pitch <ref type="bibr" target="#b44">[45]</ref>. In the experiments, we randomly extracted 16 frames from the training dataset, cropped a rectangle with 240 × 240 pixels from the center, resized it to 192 × 192 pixels, and used it for training. The values of all the samples are normalized to <ref type="bibr">[−1, 1]</ref>. To amplify the samples we randomly flipped video during the training.</p><p>FaceForensics Following to Wang et al. <ref type="bibr" target="#b51">[52]</ref>, we created the facial videos from FaceForensics <ref type="bibr" target="#b40">[41]</ref> containing 854 news videos with different reporters. Specifically, we first identified the position of the face with a mask video in the dataset, cropped only the area of the face, and resized it to 256 × 256 pixels. In training, we randomly extracted 16 frames from them and sent these frames to the discriminator. As with UCF101, all the values are normalized to [−1, 1].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Hyperparameters</head><p>We used the Adam <ref type="bibr" target="#b24">[25]</ref> optimizer with the learning rate of 1.0 × 10 −4 , decayed linearly to 0 over 100K iterations. We also employed β 1 = 0.0 and β 2 = 0.9 in the Adam optimizer. The local batch size of each GPU was selected so it fills the GPU memory of NVIDIA Tesla P100 (12Gb). The total batch size used for experiments depends on the experiments. The number of updates of the discriminator for each iteration was set to one. The number of dimensions of z was set to 256, and λ in Equation (10) was 0.5. We implemented all models using Chainer <ref type="bibr" target="#b46">[47]</ref> and ChainerMN <ref type="bibr" target="#b1">[2]</ref>. The total number of parameters in our model is about 2.0 × 10 8 , which is larger than the number of parameters used in BigGAN (1.6 × 10 8 ) <ref type="bibr" target="#b5">[6]</ref>.</p><p>We manually confirmed that the training time is approximately proportional to GFlops shown in <ref type="table" target="#tab_0">Table 1</ref> under the same number of GPUs. The whole training time including snapshot and computation of the inception score was about 61 hours under the environment of four GPUs, batch size 32, and s t = 2. The training for each model used in the experiments ended within two to four days.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Baseline models</head><p>To confirm the effectiveness of our model, we introduced two baseline models that generate high-resolution videos. One is a high-resolution model consisting of a single generator and a single discriminator. Specifically, the network architecture of the generator in this model is almost identical to that of the proposed model, but it does not contain three rendering blocks that output low-resolution videos (that is, the generator only outputs a single high-resolution video during training). The network of the discriminator is the same as the sub-discriminator used in our method. Since the number of parameters of the generator is almost the same as that of our model, we can see the difference of performance between the simple high-resolution model and our multi-scale model.</p><p>The other is a baseline model where the discriminator uses two different sub-discriminators similar to MoCoGAN. Specifically, although the network of the generator is the same as that of the model mentioned above, this discriminator consists of the 2D sub-discriminator in addition to the above 3D ones. The configuration of the 2D sub-discriminator is equivalent to the model of Miyato et al. <ref type="bibr" target="#b33">[34]</ref> used for image generation.</p><p>The 3D sub-discriminator discriminates real videos from generated videos by directly classifying videos, while the 2D sub-discriminator only discriminates a randomly selected frame in videos. Using this baseline model, we can see the performance of simply inserting the subsampling layer only in the final layer instead of a middle layer.</p><p>To improve the quality of baseline models, we performed a grid search to find the optimal λ in Equation <ref type="bibr" target="#b9">(10)</ref>. We finally set λ = 10.0 for all experiments using these baseline models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Qualitative comparison of generated videos</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.1">FaceForensics</head><p>To confirm the quality of the video generated by our model, we trained our models and two baselines using the two datasets described above. First, we trained these models using the FaceForensics <ref type="bibr" target="#b40">[41]</ref> dataset. In order to check the effect of s t in the subsampling layer, we trained the model with two values s t = 2, 4. In the proposed model, the generator has four sub-generators and each of which generates videos at different resolution and different number of frames depending on the setting of subsampling layers (the value of s t ). Here, we denote the series of numbers of frames of those videos from different sub-generators as a tuple of the number of frames such as <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b1">2]</ref>. Therefore, in the case of s t = 2, the number of video frames produced by the generator is <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b1">2]</ref>. On the other hand, in the case of s t = 4, the number of video frames is <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b0">1]</ref> according to the definition of Equation <ref type="bibr" target="#b8">(9)</ref>. The batch size was set to 32 for both. Eight GPUs were used in this experiment.</p><p>The videos generated by our model are shown in <ref type="figure" target="#fig_14">Figure 6</ref>. We confirmed that at s t = 2, our model generated high-resolution videos without collapsing the parts in a face. Specifically, we observed that our model was able to generate high-fidelity images as a single still image, and facial parts such as eyes and mouth move smoothly. To show clearly that our generated video is not just a sequence that continues a single still image, we also placed an enlarged view of the eyes and mouth in <ref type="figure" target="#fig_14">Figure 6</ref>.</p><p>In addition to this, we also confirmed that the proposed method could generate videos of various faces without causing mode collapse. To show this diversity, we show several samples generated by our model in <ref type="figure">Figure 7</ref>.</p><p>As for the facial video, MoCoGAN also shows similar qualitative results using a similar facial video dataset, but its resolution is relatively small (64×64 pixels). We confirmed that even though our model handles samples that consume 16 times more memory than the conventional small samples, it can be efficiently trained while saving memory and computational cost with the subsampling layer. As mentioned in Sections 1 and 4.3, if one tries to use MoCoGAN that does not exploit the subsampling layer to generate high resolution videos, there is a problem that the amount of consumed GPU memory is enormous (for example, MoCoGAN requires about 10Gb of memory to generate videos with 64 × 64 px even if batch size is 8). The result of <ref type="figure" target="#fig_14">Figure 6</ref> shows that our model can be properly trained even at such a high resolution without extremely increasing the amount of memory consumed by the discriminator.</p><p>On the other hand, videos generated by the model of s t = 4 tended to be inconsistent in the first few frames (note that we confirmed that both s t = 2 and s t = 4 generate stable videos for the remaining frames). This example is shown in <ref type="figure">Figure 8</ref>. We considered it is because that the increase in the number of subsampled frames leads to instability in the first few frames. We also confirmed that this behavior depends on the dataset. Specifically, the instability of s t = 4 has been mitigated when trained with UCF101 dataset, and we observed that in the quantitative evaluation, the model with s t = 4 outperformed the model with s t = 2. We describe the detail in Sections 5.4.2 and 5.10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.2">UCF101</head><p>Next, we performed a similar experiment using UCF101, which is more challenging to generate videos that look more natural than FaceForensics. Unlike FaceForensics with 256×256 pixels, the resolution of the UCF101 used in experiments is 192 × 192 pixels; this is because the resolution of the original video is 320 × 240 pixels. Four GPUs were used to train models. Similar to the experiment in the FaceForensics, we trained two models of s t = 2 and s t = 4 with the UCF101 dataset. The total batch size was set to 32, which is identical to the experiment in the FaceForensics. To confirm the differences in qualitative results when using a conditional model, we also trained conditional models with discrete labels in UCF101. These hyperparameters are identical to those without conditions.</p><p>Although the metrics such as Inception Score and Fréchet Inception Distance used in this quantitative experiment have been applied in the field of video generation <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b49">50]</ref>, it is difficult to know how much improvement in these values leads to qualitative improvement. To confirm this difference, we compared qualitatively with videos generated by five models. One is a TGAN <ref type="bibr" target="#b41">[42]</ref> trained with UCF101. The second and  third are our proposed models with s t = 2 and s t = 4. The rest are the two baseline models described in Section 5.3. For the MoCoGAN <ref type="bibr" target="#b48">[49]</ref>, we could not use it for the qualitative experiment because the pre-trained model was not available and there is no figure representing the generated result in the paper. However, we considered that TGAN can also be used to compare the qualitative quality of the current state-of-the-art methods because the TGAN achieves similar inception score to MoCoGAN. <ref type="figure" target="#fig_16">Figure 9</ref> shows the videos generated by the baseline and our two models. We confirmed that our proposed two models generated videos that are easier to interpret the content than the two baseline models. Specifically, the videos generated by our models tend to have some abstract motions such as moving shadows that look like a human, but its outline is relatively clear, and the background is more distinguishable (e.g., indoor, sea, grassland, and stadium) than baseline models. In particular, when the background of the video is static such as soccer or basketball in a distant view, our model generated more detailed videos than other conventional models.</p><p>The baseline models trained with UCF101 tended to produce the same meaningless videos since they often caused mode collapse. On the other hand, we did not find such a tendency in the proposed models. In order to show this behavior, we list the still images extracted from the generated videos in <ref type="figure">Figure 10</ref>. The inception scores and Fréchet inception distance measured by these models are much better than those observed by the baseline models. It suggests that both metrics have a certain degree of correlation with the quality of videos perceived by humans even in UCF101. For reference, we also put a list of frames extracted from the videos generated by TGAN <ref type="bibr" target="#b41">[42]</ref>. We also confirmed that the TGAN tends to generate noisy videos and blurry backgrounds, whereas our model tends to produce a video with a relatively clear background and sharp shadows.</p><p>As for videos generated by the condtional model, we observed that it tends to yield a relatively stable video than the unconditional one. This was especially noticeable when the content of the video was a distant view. We have also confirmed through quantitative experiments described later that the quality of the videos by the conditional model tends to exceed that of the unconditional one. Because the quality of the video in which a person moves well is still comparable to the unconditional model, we inferred that such quantitative improvement of the quality was mainly because of the improvement of distant view videos.</p><p>Unlike the experiment of FaceForensics with s t = 4, in the experiment of UCF101 with s t = 4 we did not see such steep instability but observed gradual changes in the video, i.e., the category of the video does not change but topography changes gradually. The example is shown in <ref type="figure" target="#fig_17">Figure 11</ref>. We considered that it was due to differences in the domain of the dataset. If videos in the dataset are not very diverse as in FaceForensics, the transition of the domain of the first frames caused by the subsampling layer tends to occur. Contrarily, if the dataset is diverse as in UCF101, we considered that such steep transition would be less likely to occur since such transitions are easily identified by the discriminator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Linear interpolation of the noise vector</head><p>We also generated a new sample with a intermediate vector between the two noise vectors to ensure that the trained network was not a model that memorized the dataset. The model trained with s t = 2 and the Face-Forensics dataset was used for the experiment.</p><p>The result is shown in <ref type="figure" target="#fig_5">Figure 12</ref>. The content of the video changed smoothly by moving z linearly. It means that our model is not just a "memorized" model of the original dataset. Changing z often tended to change the speaker itself, but on the other hand, there were several videos where the speaker did not change, but other attributes such as the orientation of the speaker's face changed smoothly. We inferred that it was mainly because that the input of the discriminator was a sequence clipped at 16 frames randomly from a video in the dataset. Example of videos by the three models (our two unconditional models (s t = 2, 4) and baseline ("3D + 2D discriminators")) trained with UCF101. Images excluding the intermediate three frames are shown to make it easy to identify the motion.</p><p>TGAN <ref type="bibr" target="#b41">[42]</ref> Single 3D discriminator Our model (s t = 4, unconditional) Our model (s t = 4, conditional) <ref type="figure">Fig. 10</ref> A list of still images extracted from videos generated by our models (s t = 4), TGAN, and baseline model. The UCF101 dataset was used for the training. "unconditional" means a generator trained with videos only, whereas "conditional" is a conditional one trained with videos and corresponding labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Consistency of generated samples</head><p>To check whether each rendering block generates the same content under the same z, we visualized the result of each rendering block. The example is shown in <ref type="figure">Figure 13</ref>. We observed that every rendering block in our method tends to generate the same content without a color-consistency regularization introduced in Stack-GAN++ <ref type="bibr" target="#b56">[57]</ref>.</p><p>Next, making use of the property that all blocks tend to output the same content, we observed which level of blocks the instability of the first frames at s t = 4 resulted from. To check the results of the videos generated by all rendering blocks, we disabled every sub-  sampling layer to make the rendering block of each level output a video with 16 frames. The results for each level at s t = 2, 4 are shown in <ref type="figure">Figure 14</ref>. In contrast to the result of s t = 2, where every rendering block generated a video with almost identical content, the first frames of the model of s t = 4 tended to become unstable as the level increased. It indicates that the cause of instability is that the subsequent rendering blocks no longer output the same content.</p><p>To quantitatively confirm that this instability depends on the dataset, we calculated PSNR (Peak Signalto-Noise Ratio) and SSIM (structural similarity) between the frame in a video generated by the rendering block of level 1 and the frame of level 4. We resized the videos in level 1 so that the resolutions of the two videos match. One thousand samples were used for evaluation. These quantitative results are shown in <ref type="figure" target="#fig_13">Figure 15</ref>. It indicates that the first frames at level 4 become unstable when trained with the FaceForensics dataset, while later it outputs almost identical content as level 1. However, the identity of s t = 4 was worse than s t = 2 even if enough time had passed. While such a rapid initial instability was not observed with UCF101, its identity after a sufficient period of time was slightly worse for both SSIM and PSNR than for FaceForensics. It means that the identity of the video generated by each block changes depending on the difficulty level of the dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.7">Comparison with other existing methods</head><p>We confirmed that the quality of samples generated by the proposed model is superior to other existing models with Inception Score (IS) <ref type="bibr" target="#b42">[43]</ref> and Fréchet Inception Distance (FID) <ref type="bibr" target="#b18">[19]</ref>, which measure the quality of generated samples. We describe the details of the experimental environment used for measuring IS and FID in the following. See <ref type="bibr" target="#b4">[5]</ref> for details of IS and FID.</p><p>As with other comparable methods <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b0">1]</ref>, we employed the UCF101 dataset <ref type="bibr" target="#b44">[45]</ref> for the quantitative experiments. Regarding the classifier used for comput- ing IS and FID, we used a pre-trained model of Convolutional 3D (C3D) network <ref type="bibr" target="#b47">[48]</ref>, which was first trained with Sports-1M dataset <ref type="bibr" target="#b22">[23]</ref> and then fine-tuned on the UCF101 dataset 1 . Note that we used this pre-trained model as is, and did not update any parameters in the classifier. As the resolution and the number of frames in a video used in the classifier are 128 × 128 pixels and 16 frames, we resized the generated video with 192 × 192 pixels to 128 × 128 pixels and regarded it as the input of the classifier. To calculate the IS and FID with the C3D model, we need a fourth-order tensor (C × T × H × W ) that represents the average for all the clips in the UCF101. We used the same average tensor used in TGAN.</p><p>In all experiments, we computed FID and IS according to the following procedure. First, we set the maximum number of iterations to 100,000 and took snapshots every 2,000 iterations. For each snapshot, we computed the IS and FID with 2,048 samples. The best snapshot with the largest IS was used for quantitative evaluation. We calculated the mean and standard deviation by performing the same procedure ten times for this snapshot. It took about four hours to compute IS and FID of one snapshot.</p><p>The resolutions of generated videos by all the existing methods are 64 × 64 pixels except for Progres-siveGAN (128 × 128 pixels). These scores shown in the quantitative experiments in these models can be compared with the IS calculated by our method because their models also compute the IS by resizing the generated videos to 128 × 128 pixels. However, even if the IS of our method exceeds the existing method, this increase may be due to simply increasing the resolution (in other words, the IS may be an indicator with a vulnerability that can be easily increased by increasing resolution). To confirm this, we measured IS and FID of two baseline models with a similar network structure as the existing method (c.f., Section 5.3), and observed the change of both scores in the case of high resolution.  The difference between our model and the existing ones is roughly divided into the two: multi-scale model and subsampling layer. To clarify the contribution of each factor to the IS and FID, we also defined a model without all subsampling layers as "naive implementation", and measured its IS and FID. Four GPUs were used in all the experiments of this subsection. We set the maximum batch size within the memory of the GPU for each model. This means that the batch size of the two proposed methods was 32, whereas that of two baseline models was 8. The model without subsampling layers consumes much memory due to the resolution; therefore, we had to set the entire batch size to 4 even if we can use four GPUs.</p><p>The quantitative results are shown in <ref type="table" target="#tab_2">Table 2</ref>. The inception scores of two baseline models are slightly lower than those of other existing methods. It indicates that it is difficult to improve scores by simply increasing the resolution of the samples from the generator. Although it may be possible that the baseline models could not allocate a sufficient mini-batch due to the high resolution, we will show in Section 5.9 that these scores do not increase dramatically even if the batch size is sufficiently large. The IS and FID of the baseline model with two sub-discriminators are almost the same as those of the baseline with a single 3D discriminator. It implies that it is difficult to improve the quality of the generated  videos dramatically with the conventional approach of simply introducing multiple discriminators into the input layer. The IS and FID of the model without subsampling layers are much lower than those of our proposed model. It indicates that the subsampling layer contributes to the improvement of the quality in an environment of four GPUs. The inception scores of our two models (s t = 2, 4) are significantly higher than those of the other existing models. In other words, in the environment of four GPUs, it means that the quality of our proposed models exceeds the existing method. It is interesting to see that IS and FID computed by the model of s t = 4 are better than those of s t = 2. Thus, by increasing the number of frames to be reduced, our method can not only save the computational cost and the GPU memory more efficiency but also slightly improve the quality of the generated videos. As discussed in Sections 5.4.1 and 5.4.2, increasing s t may contribute to instability of first few frames in some datasets; however, the increase of IS by setting s t = 2 instead of not using subsampling layers is much higher than the increase of IS by setting s t = 4 instead of s t = 2. Based on these quantitative results, we concluded that an approach of setting s t = 2 at the beginning and then gradually increasing would be appropriate when training with an unknown dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.8">Quantitative results under a single GPU</head><p>Although our proposed model outperforms the other existing methods in the environment of 4 GPUs, this improvement may be due to the advantageous setting where we used multiple GPUs. To confirm whether the IS and FID of our method exceed those of the existing method under the almost same environment, we measured IS and FID of the two baselines and the proposed models when training with a single GPU.</p><p>The results are shown in <ref type="table" target="#tab_4">Table 3</ref>. IS and FID of the model without subsampling layers are much worse than those of the existing models. It is because that the video is a high resolution and the batch size is only one. It also illustrates the difficulty of training high resolution models in a limited resource. Even if we can use only  one GPU, the IS of our model is significantly higher than those of the other existing models. In particular, the fact that inception scores of our models are higher than that of ProgressiveGAN, which also outputs highresolution videos, demonstrates the effectiveness of our model under constrained computational resources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.9">Quantitative results under the same batch size</head><p>It can be seen that our models outperformed the other existing and baseline models under the environment of one or four GPUs. However, if we can increase the batch size without such limitations, i.e., if we can set the same batch size as our model by simply increasing the number of GPUs, baseline models may outperform the proposed method. Therefore, we measured IS and FID of the three baseline models under the same batch size. The batch size was set to 32. It means that the model without the subsampling layers consumed 32 GPUs, whereas the two baseline models used 16 GPUs and our method used only four GPUs. <ref type="table" target="#tab_6">Table 4</ref> shows the results. Even if there is no limit on the number of GPUs, our proposed model outperformed all the baseline models. We can claim the following two from these results. First, the low IS and the high FID in the baseline models shown in the previous experiments are not mainly due to the small batch size. That is, it is hard to improve both scores dramatically with a simple model that introduces a single discriminator only to the input layer. Second, the reason why both scores of our models are much better than those of the existing methods is not a simple reason like the number of parameters is larger than others. Even in an environment where a sufficient number of GPUs can be used, the IS of the model without introducing the subsampling layer was similar to the other existing methods. It implies that such high scores are because of the introduction of multiple subsampling layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.10">Effectiveness of frame sub-sampling layers</head><p>IS and FID highly depend on batch size. We confirmed that activating the subsampling layer improved IS and  FID of our model over the other existing methods, and the scores of the model of s t = 4 are slightly better than those of s t = 2. However, it is not clear whether these trends are the same even if the batch size is increased (for example, the score of the naive model may catch up with that of the model with subsampling layers). To see the effectiveness of the subsampling layer for batch size, we measured the change of the inception score when the subsampling layers were activated under the condition of the same batch size. In this subsection we performed three types of experiments; one is an experiment when all subsampling layers are disabled, and the remaining two are experiments when the subsampling layers are enabled with s t = 2 and 4. Training these models with different batch sizes, we measured the change of IS and FID. For economic reasons, we did not measure scores of batch size 64 and 128 when disabling the subsampling layer.</p><p>The results are shown in Tables 5 and 6. In any batch size, IS and FID of the model with subsampling layers are significantly better than the model without them. It indicates that the subsampling layers are effective for improving the quality of the generated videos regardless of the batch size. As the discriminator at the later stage has to determine the authenticity of the video with a lower frame rate, it needs to judge the authenticity from the global motion and the quality of a still image instead of the difference of the fine movement. We considered that the subsampling layer played a role like regularization, resulting in improvement of IS and FID.  <ref type="table">Table 7</ref> Changes in the inception score when updating to a conditional model. "pure" denotes an unconditional model, whereas "conditional" is a conditional one described in Section 4.6. "BS" means a batch size.  We also confirmed that IS and FID at s t = 4 were significantly higher than those at s t = 2 in almost all batch sizes. In particular, when the batch size is 128 and s t = 4, the inception score of our model (28.87) dramatically exceeds the existing state-of-the-art method <ref type="bibr">(14.56)</ref>. It shows the superiority of our model over other existing methods. Note that our IS also exceeds all the scores of the existing methods when using one GPU only instead of such relatively large computational resources (c.f., Section 5.8).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.11</head><p>Quantitative results of the conditional model As we described in Section 4.6, the quality of our generated video can be improved with a conditional model. To see the changes of quantitative scores when using the conditional model, we measured the changes in IS and FID for each batch size. The experiment was performed under two conditions: s t = 2 and s t = 4. Three batch sizes of 16, 32, and 64 were used in the experiment.</p><p>The results are shown in Tables 7 and 8. They show that the scores improved significantly by extending to the conditional model regardless of the batch size and hyperparameters. In particular, the inception score (54.93) of the conditional model for s t = 2 and the batch size of 64 is significantly higher than any previously reported scores. However, an increase in batch size did not lead to a significant increase in FID, but was sometimes worsened. When the batch size was 32, the FID of the conditional model was improved over all scores in <ref type="table" target="#tab_8">Table 6</ref>, but its improvement is not as dramatic as that of IS. It is more intuitive when looking at the actual generated videos (see <ref type="figure">Figure 10</ref>).  <ref type="table">Table 9</ref> Change in Inception Score and Fréchet Inception Distance when each subsampling layer is gradually enabled (batchsize=16, s t = 2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.12">Effectiveness of each subsampling layer</head><p>In previous experiments, we enabled multiple subsampling layers simultaneously. To confirm whether all of the subsampling layers introduced by our method actually contribute to the improvement of the quality, we measured the change of IS and FID when multiple subsampling layers were gradually activated.</p><p>The concrete procedure is as follows. First, according to the notation in <ref type="figure">Figure 1</ref> we defined the three subsampling layers introduced in our method as S 1 , S 2 , and S 3 . Next, we observed the change of IS and FID when these layers were activated sequentially from S 1 . Enabling S i affects the number of video frames received by all subsequent discriminators in our method. Therefore, to investigate whether S i contributes to the improvement of both scores in all cases, it is necessary to measure the change of the scores for every state of S j except S i . Although strictly speaking, measuring the effect on the strategy to sequentially activate the subsampling layers does not fully illustrate the effectiveness of S i , we can see whether all subsampling layers are effective, at least in the general situation of activating them gradually.</p><p>We also confirmed the effectiveness of each subsampling layer for changes in hyperparameters by setting s t to 2 and 4. The batch size for these experiments was set to 16. From the definition of b t , the number of frames of four generated videos in the case of s t = 4 is [16, 4, 1, 1], that is, enabling both S 1 and S 2 is the same as enabling all subsampling layers. To see the effectiveness of S 3 in s t = 4, instead, we observed the change of IS and FID when S 3 was activated in the situation where S 1 was enabled.</p><p>The result of s t = 2 is shown in <ref type="table">Table 9</ref>. By gradually activating S i , both IS and FID significantly improved. We considered this is because that each subdiscriminator plays different roles in improving the quality by enabling the subsampling layers, and IS and FID gradually increased. Regarding the change in scores at each step, it can be seen that IS and FID improved most when enabling S 1 . It means that S 1 contributed Changes in the Inception Score when applying a single frame subsampling layer to two baseline models. "Naive impl." means a model without any subsampling layers.</p><p>most to the improvement of the quality of videos in our method.</p><p>We also show the result of s t = 4 in <ref type="table" target="#tab_0">Table 10</ref>. As with the result of s t = 2, IS and FID increased significantly by enabling S i gradually. In particular, the improvement of IS and FID when enabling S 1 represents the importance of S 1 in our method. IS and FID did not improve when the number of frames of four generated videos was changed from <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b3">4]</ref> to <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b0">1]</ref>, whereas both scores improved significantly when changing from <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b3">4]</ref> to <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b0">1]</ref>. This implies that enabling S 2 is more important than S 3 for s t = 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.13">Frame subsampling in baseline models</head><p>Although we show that the subsampling layer in our model has the effect of improving the quality of videos, it is still unclear whether the subsampling layer is also effective in the conventional methods, that is, the essential contribution of our method may be only in the subsampling layer. To clarify that the contribution of this study is the combination of multi-scale model and subsampling layers, we measured the change of IS and FID when the subsampling layer was applied to the above two baseline models.</p><p>We describe the detail. Unlike our proposed model that outputs multiple videos for training, the generator in the baseline model generates only a single video. Thus, from the network architecture of the baseline model, it is clear that enabling S 2 or S 3 is equivalent to enabling only S 1 . In this experiment, we focused on S 1 and measured only the change of both scores when S 1 was activated. As in the previous experiment, we used the two hyperparameters (s t = 2, 4) for the subsampling layer. The batch size was 16.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Naive impl. s t = 2 s t = 4</p><p>3D dis. only 8358 ± 81 11764 ± 54 13938 ± 26 3D + 2D dis. 8304 ± 70 11301 ± 26 11386 ± 12 <ref type="table" target="#tab_0">Table 12</ref> Changes in the Fréchet Inception Distance when applying a single frame subsampling layer to two baseline models.</p><p>The results are shown in <ref type="table" target="#tab_0">Tables 11 and 12</ref>. Both IS and FID when activating the subsampling layer are significantly worse than those of the naive implementation. In particular, when the subsampling layer of s t = 4 was applied, we observed that the training did not work at all for both models. While the introduction of the subsampling layer saves computational cost and memory consumption, the discriminator can identify the videos with reduced frame rates more easily than the original ones. We considered that it led to a decrease in the IS and an increase in FID. This result is in contrast to the result of our model, which improved both computational cost and quality by enabling the subsampling layer, and illustrates that our contribution is a combination of a multiscale model and subsampling layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>In this section, we summarize the empirical findings obtained through a series of experiments.</p><p>What contributed most to the improvement of the quality is the combination of the subsampling layer and the multiscale model (the quality cannot be dramatically improved by either the multiscale model or the subsampling layer). The score can be improved by simply increasing the number of GPUs without the subsampling layers, but its improvement is small. The score improved significantly by enabling the subsampling layers. However, this significant improvement does not occur in other models, but only in our multiscale model. That is, in order to improve the score in the task of video generation, it is important not to introduce either one but to combine both.</p><p>The introduction of the subsampling layer leads not only to the improvement of the quality but also to significantly saving the computational cost and memory consumption of the GPU (c.f., <ref type="table" target="#tab_0">Table 1</ref>). Even in situations where only a single GPU can be used due to budget constraints, our method can efficiently solve highresolution video generation problems that could not be solved with naive models, and its inception score is significantly higher than those of the existing methods. We have confirmed that this dramatic increase in scores cannot be achieved by only increasing the resolution with two baseline models.</p><p>Similar to the findings of BigGAN <ref type="bibr" target="#b5">[6]</ref>, the quality of the video can also be improved by increasing the batch size in our model. We confirmed that an increase in s t leads to an improvement in the quality regardless of the batch size. However, on the other hand, the generation of the first frames may be unstable depending on the dataset. Since no such instability was observed in the case of s t = 2, we consider that it would be appropriate to train the model with s t = 2 at an early stage, gradually increase the value, and observe the change of IS and FID.</p><p>In our proposed method using multiple subsampling layers, enabling the first subsampling layer (S 1 ) contributes the most to improving the score. However, in our experiments, we did not see any decrease in scores even when the subsequent subsampling layers were enabled. As there is no increase in computational cost and memory consumption by enabling the subsampling layer, we consider that it would be better to enable all subsampling layers first, and then to fine-tune by gradually activating the subsampling layers if there are enough computing resources and time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Trials and their results</head><p>We share a process of trial and error that led up to the development of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.1">CLSTM layers</head><p>We tried stacked Convolutional LSTM layers but observed that a single CLSTM with many channels worked better. We also tried a dilated CLSTM layer, but the plain CLSTM was better. As with the above, we observed that simply increasing the number of channels in the single CLSTM contributed the most improvement in the score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.2">Generation of longer videos</head><p>We observed that our model sometimes succeeded to stably generate longer videos than the number of frames used for training (i.e., 16 frames) but sometimes generated broken videos. Although this behavior depends on the hyperparameters and the dataset, it is unclear under what conditions our model can generate stably 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.3">Spectral normalization</head><p>We tried to insert the Spectral Normalization <ref type="bibr" target="#b33">[34]</ref> into the 3D convolutional layers in the discriminator, but its performance decreased significantly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.4">Gradient penalty</head><p>Although we initially used a gradient penalty based on WGAN-GP <ref type="bibr" target="#b14">[15]</ref> as a regularizer, but for simplicity we later adopted a simpler zero-centered gradient penalty. Through the grid search, we finally confirmed that λ = 0.5 is the best but also observed that the training itself could be performed normally without the gradient penalty. It may indicate that the method using multiple discriminators contributed to the stabilization of training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.5">Batch normalization</head><p>Mescheder et al. <ref type="bibr" target="#b32">[33]</ref>, the authors of the zero-centered gradient penalty, reported that they succeeded in generating high fidelity images without Batch Normalization layers in the generator, but in our experiments without Batch Normalization layers, the performance significantly decreased.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.6">3D discriminator</head><p>The inception score when using a simple discriminator consisting of several 3D convolutional layers without any residual blocks is lower than the 3D ResNet discriminator, but the computational speed is faster. We used this simple discriminator temporarily for making the trial-and-error loops for searching a good model faster and adopted the 3D ResNet for the final evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper we introduced the method of efficiently training the high-resolution model for video generation with GAN. The main idea is to generate videos in different ways during training and inference. During the training, the generator outputs multiple "sparse" samples useful for the training at low computational cost instead of directly generating high-resolution video. For inference, the generator outputs high-resolution "dense" videos over time. Using this method we can not only train our multi-scale model for video generation while saving computational cost and memory consumption, but the quality of our trained model is significantly superior to the baseline models and the existing ones. In both qualitative and quantitative experiments, we confirmed that our method could output high-resolution videos with higher quality the conventional ones, and the subsampling layers actually contribute to the improvement of the quality.</p><p>Our core idea may may not only to other fields that exploit videos such as video prediction but also to other domains with time series including audio generation. We are planning to find more practical applications by exploring these possibilities.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>g A 1 &lt;A 2 &lt; 1 &lt; 2 &lt; 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 =</head><label>1212114114</label><figDesc>l a t e x i t s h a 1 _ b a s e 6 4 = " e e L M o C v b V P r y R g B 1 F X W q m z I E i G E = " &gt; A A A C y X i c f V F d a 9 R A F J 1 N / a j r V 6 u P v g y G B R E p S S n o Y 0 U f C i J W c L e F z b r c z N 5 k h 5 3 J x J l J 6 R r y 5 A / w t f 0 T / h / / j T f b i G 5 b v T B w O P f c j z k 3 L Z V 0 P o p + 9 o K N G z d v 3 d 6 8 0 7 9 7 7 / 6 D h 1 v b j 0 b O V F b g U B h l 7 H E K D p U s c O i l V 3 h c W g S d K j x K F 2 / a / N E J W i d N 8 c k v S 5 x o y A u Z S Q G e q G H + + f U 0 n m 6 F 0 U 6 0 C n 4 V x B 0 I W R e H 0 + 3 e j 2 R m R K W x 8 E K B c + M 4 K v 2 k B u u l U N j 0 k 8 p h C W I B O Y 4 J F q D R T e r V t g 0 f E D P j m b H 0 C s 9 X 7 N 8 V N W j n l j o l p Q Y / d 5 d z L X l d b l z 5 7 N W k l k V Z e S z E x a C s U t w b 3 n 6 d z 6 R F 4 d W S A A g r a V c u 5 m B B e D K o 3 x 8 M + J 9 m 3 J G U H F o b n l p Y o G / W F 1 K 5 o V 5 z / Q 9 a C k r M M E t G K M K 4 T t q 1 0 6 w O 4 6 b j T 6 7 h 3 y L Z a v E 9 c R 9 K t O C N f V 4 n Y H M t i 4 Z s z p M X L f q f E E 5 / C w n R h e P L 9 7 w K R r s 7 M e G P e + H + X n f r T f a E P W X P W M x e s n 1 2 w A 7 Z k A k m 2 X d 2 x s 6 D d 8 G X 4 D T 4 e i E N e l 3 N Y 7 Y W w b d f g s H h H A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " e e L M o C v b V P r y R g B 1 F X W q m z I E i G E = " &gt; A A A C y X i c f V F d a 9 R A F J 1 N / a j r V 6 u P v g y G B R E p S S n o Y 0 U f C i J W c L e F z b r c z N 5 k h 5 3 J x J l J 6 R r y 5 A / w t f 0 T / h / / j T f b i G 5 b v T B w O P f c j z k 3 L Z V 0 P o p + 9 o K N G z d v 3 d 6 8 0 7 9 7 7 / 6 D h 1 v b j 0 b O V F b g U B h l 7 H E K D p U s c O i l V 3 h c W g S d K j x K F 2 / a / N E J W i d N 8 c k v S 5 x o y A u Z S Q G e q G H + + f U 0 n m 6 F 0 U 6 0 C n 4 V x B 0 I W R e H 0 + 3 e j 2 R m R K W x 8 E K B c + M 4 K v 2 k B u u l U N j 0 k 8 p h C W I B O Y 4 J F q D R T e r V t g 0 f E D P j m b H 0 C s 9 X 7 N 8 V N W j n l j o l p Q Y / d 5 d z L X l d b l z 5 7 N W k l k V Z e S z E x a C s U t w b 3 n 6 d z 6 R F 4 d W S A A g r a V c u 5 m B B e D K o 3 x 8 M + J 9 m 3 J G U H F o b n l p Y o G / W F 1 K 5 o V 5 z / Q 9 a C k r M M E t G K M K 4 T t q 1 0 6 w O 4 6 b j T 6 7 h 3 y L Z a v E 9 c R 9 K t O C N f V 4 n Y H M t i 4 Z s z p M X L f q f E E 5 / C w n R h e P L 9 7 w K R r s 7 M e G P e + H + X n f r T f a E P W X P W M x e s n 1 2 w A 7 Z k A k m 2 X d 2 x s 6 D d 8 G X 4 D T 4 e i E N e l 3 N Y 7 Y W w b d f g s H h H A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " e e L M o C v b V P r y R g B 1 F X W q m z I E i G E = " &gt; A A A C y X i c f V F d a 9 R A F J 1 N / a j r V 6 u P v g y G B R E p S S n o Y 0 U f C i J W c L e F z b r c z N 5 k h 5 3 J x J l J 6 R r y 5 A / w t f 0 T / h / / j T f b i G 5 b v T B w O P f c j z k 3 L Z V 0 P o p + 9 o K N G z d v 3 d 6 8 0 7 9 7 7 / 6 D h 1 v b j 0 b O V F b g U B h l 7 H E K D p U s c O i l V 3 h c W g S d K j x K F 2 / a / N E J W i d N 8 c k v S 5 x o y A u Z S Q G e q G H + + f U 0 n m 6 F 0 U 6 0 C n 4 V x B 0 I W R e H 0 + 3 e j 2 R m R K W x 8 E K B c + M 4 K v 2 k B u u l U N j 0 k 8 p h C W I B O Y 4 J F q D R T e r V t g 0 f E D P j m b H 0 C s 9 X 7 N 8 V N W j n l j o l p Q Y / d 5 d z L X l d b l z 5 7 N W k l k V Z e S z E x a C s U t w b 3 n 6 d z 6 R F 4 d W S A A g r a V c u 5 m B B e D K o 3 x 8 M + J 9 m 3 J G U H F o b n l p Y o G / W F 1 K 5 o V 5 z / Q 9 a C k r M M E t G K M K 4 T t q 1 0 6 w O 4 6 b j T 6 7 h 3 y L Z a v E 9 c R 9 K t O C N f V 4 n Y H M t i 4 Z s z p M X L f q f E E 5 / C w n R h e P L 9 7 w K R r s 7 M e G P e + H + X n f r T f a E P W X P W M x e s n 1 2 w A 7 Z k A k m 2 X d 2 x s 6 D d 8 G X 4 D T 4 e i E N e l 3 N Y 7 Y W w b d f g s H h H A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " e e L M o C v b V P r y R g B 1 F X W q m z I E i G E = " &gt; A A A C y X i c f V F d a 9 R A F J 1 N / a j r V 6 u P v g y G B R E p S S n o Y 0 U f C i J W c L e F z b r c z N 5 k h 5 3 J x J l J 6 R r y 5 A / w t f 0 T / h / / j T f b i G 5 b v T B w O P f c j z k 3 L Z V 0 P o p + 9 o K N G z d v 3 d 6 8 0 7 9 7 7 / 6 D h 1 v b j 0 b O V F b g U B h l 7 H E K D p U s c O i l V 3 h c W g S d K j x K F 2 / a / N E J W i d N 8 c k v S 5 x o y A u Z S Q G e q G H + + f U 0 n m 6 F 0 U 6 0 C n 4 V x B 0 I W R e H 0 + 3 e j 2 R m R K W x 8 E K B c + M 4 K v 2 k B u u l U N j 0 k 8 p h C W I B O Y 4 J F q D R T e r V t g 0 f E D P j m b H 0 C s 9 X 7 N 8 V N W j n l j o l p Q Y / d 5 d z L X l d b l z 5 7 N W k l k V Z e S z E x a C s U t w b 3 n 6 d z 6 R F 4 d W S A A g r a V c u 5 m B B e D K o 3 x 8 M + J 9 m 3 J G U H F o b n l p Y o G / W F 1 K 5 o V 5 z / Q 9 a C k r M M E t G K M K 4 T t q 1 0 6 w O 4 6 b j T 6 7 h 3 y L Z a v E 9 c R 9 K t O C N f V 4 n Y H M t i 4 Z s z p M X L f q f E E 5 / C w n R h e P L 9 7 w K R r s 7 M e G P e + H + X n f r T f a E P W X P W M x e s n 1 2 w A 7 Z k A k m 2 X d 2 x s 6 D d 8 G X 4 D T 4 e i E N e l 3 N Y 7 Y W w b d f g s H h H A = = &lt; / l a t e x i t &gt; … g l a t e x i t s h a 1 _ b a s e 6 4 = " 2 4 a + V d 2 W Z 2 E A r E r H J N 8 R V 3 w Z r g g = " &gt; A A A C y X i c f V F d a 9 R A F J 1 N / a j r V 6 u P v g y G B R E p S S n o Y 0 U f C i J W c L e F z b r c z N 5 k h 5 3 M x J l J 6 R r y 5 A / w t f 0 T / h / / j T f b i G 5 b v T B w O P f c j z k 3 L Z V 0 P o p + 9 o K N G z d v 3 d 6 8 0 7 9 7 7 / 6 D h 1 v b j 0 b O V F b g U B h l 7 H E K D p X U O P T S K z w u L U K R K j x K F 2 / a / N E J W i e N / u S X J U 4 K y L X M p A B P 1 D D / / H q 6 O 9 0 K o 5 1 o F f w q i D s Q s i 4 O p 9 u 9 H 8 n M i K p A 7 Y U C 5 8 Z x V P p J D d Z L o b D p J 5 X D E s Q C c h w T 1 F C g m 9 S r b R s + I G b G M 2 P p a c 9 X 7 N 8 V N R T O L Y u U l A X 4 u b u c a 8 n r c u P K Z 6 8 m t d R l 5 V G L i 0 F Z p b g 3 v P 0 6 n 0 m L w q s l A R B W 0 q 5 c z M G C 8 G R Q v z 8 Y 8 D / N u C M p O b Q 2 P L W w Q N + s L 6 R y Q 7 3 m x T 9 o K S g x w y w Z o Q j j O m n X T r M 6 j J u O P 7 m G f 4 t k q 8 X 3 x H 0 o 0 Y I 3 9 n m d g M 0 L q R u y O U 9 e t O h / Q j j 9 L S R E F 4 4 v 3 / M q G O 3 u x I Q / 7 o X 7 e 9 2 t N 9 k T 9 p Q 9 Y z F 7 y f b Z A T t k Q y a Y Z N / Z G T s P 3 g V f g t P g 6 4 U 0 6 H U 1 j 9 l a B N 9 + A Y U i 4 R 0 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 2 4 a + V d 2 W Z 2 E A r E r H J N 8 R V 3 w Z r g g = " &gt; A A A C y X i c f V F d a 9 R A F J 1 N / a j r V 6 u P v g y G B R E p S S n o Y 0 U f C i J W c L e F z b r c z N 5 k h 5 3 M x J l J 6 R r y 5 A / w t f 0 T / h / / j T f b i G 5 b v T B w O P f c j z k 3 L Z V 0 P o p + 9 o K N G z d v 3 d 6 8 0 7 9 7 7 / 6 D h 1 v b j 0 b O V F b g U B h l 7 H E K D p X U O P T S K z w u L U K R K j x K F 2 / a / N E J W i e N / u S X J U 4 K y L X M p A B P 1 D D / / H q 6 O 9 0 K o 5 1 o F f w q i D s Q s i 4 O p 9 u 9 H 8 n M i K p A 7 Y U C 5 8 Z x V P p J D d Z L o b D p J 5 X D E s Q C c h w T 1 F C g m 9 S r b R s + I G b G M 2 P p a c 9 X 7 N 8 V N R T O L Y u U l A X 4 u b u c a 8 n r c u P K Z 6 8 m t d R l 5 V G L i 0 F Z p b g 3 v P 0 6 n 0 m L w q s l A R B W 0 q 5 c z M G C 8 G R Q v z 8 Y 8 D / N u C M p O b Q 2 P L W w Q N + s L 6 R y Q 7 3 m x T 9 o K S g x w y w Z o Q j j O m n X T r M 6 j J u O P 7 m G f 4 t k q 8 X 3 x H 0 o 0 Y I 3 9 n m d g M 0 L q R u y O U 9 e t O h / Q j j 9 L S R E F 4 4 v 3 / M q G O 3 u x I Q / 7 o X 7 e 9 2 t N 9 k T 9 p Q 9 Y z F 7 y f b Z A T t k Q y a Y Z N / Z G T s P 3 g V f g t P g 6 4 U 0 6 H U 1 j 9 l a B N 9 + A Y U i 4 R 0 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 2 4 a + V d 2 W Z 2 E A r E r H J N 8 R V 3 w Z r g g = " &gt; A A A C y X i c f V F d a 9 R A F J 1 N / a j r V 6 u P v g y G B R E p S S n o Y 0 U f C i J W c L e F z b r c z N 5 k h 5 3 M x J l J 6 R r y 5 A / w t f 0 T / h / / j T f b i G 5 b v T B w O P f c j z k 3 L Z V 0 P o p + 9 o K N G z d v 3 d 6 8 0 7 9 7 7 / 6 D h 1 v b j 0 b O V F b g U B h l 7 H E K D p X U O P T S K z w u L U K R K j x K F 2 / a / N E J W i e N / u S X J U 4 K y L X M p A B P 1 D D / / H q 6 O 9 0 K o 5 1 o F f w q i D s Q s i 4 O p 9 u 9 H 8 n M i K p A 7 Y U C 5 8 Z x V P p J D d Z L o b D p J 5 X D E s Q C c h w T 1 F C g m 9 S r b R s + I G b G M 2 P p a c 9 X 7 N 8 V N R T O L Y u U l A X 4 u b u c a 8 n r c u P K Z 6 8 m t d R l 5 V G L i 0 F Z p b g 3 v P 0 6 n 0 m L w q s l A R B W 0 q 5 c z M G C 8 G R Q v z 8 Y 8 D / N u C M p O b Q 2 P L W w Q N + s L 6 R y Q 7 3 m x T 9 o K S g x w y w Z o Q j j O m n X T r M 6 j J u O P 7 m G f 4 t k q 8 X 3 x H 0 o 0 Y I 3 9 n m d g M 0 L q R u y O U 9 e t O h / Q j j 9 L S R E F 4 4 v 3 / M q G O 3 u x I Q / 7 o X 7 e 9 2 t N 9 k T 9 p Q 9 Y z F 7 y f b Z A T t k Q y a Y Z N / Z G T s P 3 g V f g t P g 6 4 U 0 6 H U 1 j 9 l a B N 9 + A Y U i 4 R 0 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 2 4 a + V d 2 W Z 2 E A r E r H J N 8 R V 3 w Z r g g = " &gt; A A A C y X i c f V F d a 9 R A F J 1 N / a j r V 6 u P v g y G B R E p S S n o Y 0 U f C i J W c L e F z b r c z N 5 k h 5 3 M x J l J 6 R r y 5 A / w t f 0 T / h / / j T f b i G 5 b v T B w O P f c j z k 3 L Z V 0 P o p + 9 o K N G z d v 3 d 6 8 0 7 9 7 7 / 6 D h 1 v b j 0 b O V F b g U B h l 7 H E K D p X U O P T S K z w u L U K R K j x K F 2 / a / N E J W i e N / u S X J U 4 K y L X M p A B P 1 D D / / H q 6 O 9 0 K o 5 1 o F f w q i D s Q s i 4 O p 9 u 9 H 8 n M i K p A 7 Y U C 5 8 Z x V P p J D d Z L o b D p J 5 X D E s Q C c h w T 1 F C g m 9 S r b R s + I G b G M 2 P p a c 9 X 7 N 8 V N R T O L Y u U l A X 4 u b u c a 8 n r c u P K Z 6 8 m t d R l 5 V G L i 0 F Z p b g 3 v P 0 6 n 0 m L w q s l A R B W 0 q 5 c z M G C 8 G R Q v z 8 Y 8 D / N u C M p O b Q 2 P L W w Q N + s L 6 R y Q 7 3 m x T 9 o K S g x w y w Z o Q j j O m n X T r M 6 j J u O P 7 m G f 4 t k q 8 X 3 x H 0 o 0 Y I 3 9 n m d g M 0 L q R u y O U 9 e t O h / Q j j 9 L S R E F 4 4 v 3 / M q G O 3 u x I Q / 7 o X 7 e 9 2 t N 9 k T 9 p Q 9 Y z F 7 y f b Z A T t k Q y a Y Z N / Z G T s P 3 g V f g t P g 6 4 U 0 6 H U 1 j 9 l a B N 9 + A Y U i 4 R 0 = &lt; / l a t e x i t &gt; g A L &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " j 9 P q w 7 v 5 A g J c G w A B X q 6 D g 4 t / M B Y = " &gt; A A A C y X i c f V F d a 9 R A F J 2 N X 3 X 9 a u u j L 4 N h Q U R K I g V 9 r N i H g o o V 3 G 1 h s y 4 3 s z f Z Y S c z c W Z S u o Y 8 9 Q f 4 q n / C / + O / 8 W Y b 0 W 2 r F w Y O 5 5 7 7 M e e m p Z L O R 9 H P X n D t + o 2 b t z Z u 9 + / c v X f / w e b W 9 s i Z y g o c C q O M P U 7 B o Z I a h 1 5 6 h c e l R S h S h U f p 4 n W b P z p B 6 6 T R H / 2 y x E k B u Z a Z F O C J G u a f X k 3 f T j f D a C d a B b 8 M 4 g 6 E r I v D 6 V b v R z I z o i p Q e 6 H A u X E c l X 5 S g / V S K G z 6 S e W w B L G A H M c E N R T o J v V q 2 4 Y P i J n x z F h 6 2 v M V + 3 d F D Y V z y y I l Z Q F + 7 i 7 m W v K q 3 L j y 2 c t J L X V Z e d T i f F B W K e 4 N b 7 / O Z 9 K i 8 G p J A I S V t C s X c 7 A g P B n U 7 w 8 G / E 8 z 7 k h K D q 0 N T y 0 s 0 D f r C 6 n c U K 9 5 8 Q 9 a C k r M M E t G K M K 4 T t q 1 0 6 w O 4 6 b j T 6 7 g 9 5 F s t f i O u P c l W v D G P q 0 T s H k h d U M 2 5 8 m z F v 1 P C K e / h Y T o w v H F e 1 4 G o + c 7 M e E P u + H e b n f r D f a I P W Z P W M x e s D 1 2 w A 7 Z k A k m 2 V f 2 j X 0 P 3 g S f g 9 P g y 7 k 0 6 H U 1 D 9 l a B G e / A M L 8 4 T c = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " j 9 P q w 7 v 5 A g J c G w A B X q 6 D g 4 t / M B Y = " &gt; A A A C y X i c f V F d a 9 R A F J 2 N X 3 X 9 a u u j L 4 N h Q U R K I g V 9 r N i H g o o V 3 G 1 h s y 4 3 s z f Z Y S c z c W Z S u o Y 8 9 Q f 4 q n / C / + O / 8 W Y b 0 W 2 r F w Y O 5 5 7 7 M e e m p Z L O R 9 H P X n D t + o 2 b t z Z u 9 + / c v X f / w e b W 9 s i Z y g o c C q O M P U 7 B o Z I a h 1 5 6 h c e l R S h S h U f p 4 n W b P z p B 6 6 T R H / 2 y x E k B u Z a Z F O C J G u a f X k 3 f T j f D a C d a B b 8 M 4 g 6 E r I v D 6 V b v R z I z o i p Q e 6 H A u X E c l X 5 S g / V S K G z 6 S e W w B L G A H M c E N R T o J v V q 2 4 Y P i J n x z F h 6 2 v M V + 3 d F D Y V z y y I l Z Q F + 7 i 7 m W v K q 3 L j y 2 c t J L X V Z e d T i f F B W K e 4 N b 7 / O Z 9 K i 8 G p J A I S V t C s X c 7 A g P B n U 7 w 8 G / E 8 z 7 k h K D q 0 N T y 0 s 0 D f r C 6 n c U K 9 5 8 Q 9 a C k r M M E t G K M K 4 T t q 1 0 6 w O 4 6 b j T 6 7 g 9 5 F s t f i O u P c l W v D G P q 0 T s H k h d U M 2 5 8 m z F v 1 P C K e / h Y T o w v H F e 1 4 G o + c 7 M e E P u + H e b n f r D f a I P W Z P W M x e s D 1 2 w A 7 Z k A k m 2 V f 2 j X 0 P 3 g S f g 9 P g y 7 k 0 6 H U 1 D 9 l a B G e / A M L 8 4 T c = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " j 9 P q w 7 v 5 A g J c G w A B X q 6 D g 4 t / M B Y = " &gt; A A A C y X i c f V F d a 9 R A F J 2 N X 3 X 9 a u u j L 4 N h Q U R K I g V 9 r N i H g o o V 3 G 1 h s y 4 3 s z f Z Y S c z c W Z S u o Y 8 9 Q f 4 q n / C / + O / 8 W Y b 0 W 2 r F w Y O 5 5 7 7 M e e m p Z L O R 9 H P X n D t + o 2 b t z Z u 9 + / c v X f / w e b W 9 s i Z y g o c C q O M P U 7 B o Z I a h 1 5 6 h c e l R S h S h U f p 4 n W b P z p B 6 6 T R H / 2 y x E k B u Z a Z F O C J G u a f X k 3 f T j f D a C d a B b 8 M 4 g 6 E r I v D 6 V b v R z I z o i p Q e 6 H A u X E c l X 5 S g / V S K G z 6 S e W w B L G A H M c E N R T o J v V q 2 4 Y P i J n x z F h 6 2 v M V + 3 d F D Y V z y y I l Z Q F + 7 i 7 m W v K q 3 L j y 2 c t J L X V Z e d T i f F B W K e 4 N b 7 / O Z 9 K i 8 G p J A I S V t C s X c 7 A g P B n U 7 w 8 G / E 8 z 7 k h K D q 0 N T y 0 s 0 D f r C 6 n c U K 9 5 8 Q 9 a C k r M M E t G K M K 4 T t q 1 0 6 w O 4 6 b j T 6 7 g 9 5 F s t f i O u P c l W v D G P q 0 T s H k h d U M 2 5 8 m z F v 1 P C K e / h Y T o w v H F e 1 4 G o + c 7 M e E P u + H e b n f r D f a I P W Z P W M x e s D 1 2 w A 7 Z k A k m 2 V f 2 j X 0 P 3 g S f g 9 P g y 7 k 0 6 H U 1 D 9 l a B G e / A M L 8 4 T c = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " j 9 P q w 7 v 5 A g J c G w A B X q 6 D g 4 t / M B Y = " &gt; A A A C y X i c f V F d a 9 R A F J 2 N X 3 X 9 a u u j L 4 N h Q U R K I g V 9 r N i H g o o V 3 G 1 h s y 4 3 s z f Z Y S c z c W Z S u o Y 8 9 Q f 4 q n / C / + O / 8 W Y b 0 W 2 r F w Y O 5 5 7 7 M e e m p Z L O R 9 H P X n D t + o 2 b t z Z u 9 + / c v X f / w e b W 9 s i Z y g o c C q O M P U 7 B o Z I a h 1 5 6 h c e l R S h S h U f p 4 n W b P z p B 6 6 T R H / 2 y x E k B u Z a Z F O C J G u a f X k 3 f T j f D a C d a B b 8 M 4 g 6 E r I v D 6 V b v R z I z o i p Q e 6 H A u X E c l X 5 S g / V S K G z 6 S e W w B L G A H M c E N R T o J v V q 2 4 Y P i J n x z F h 6 2 v M V + 3 d F D Y V z y y I l Z Q F + 7 i 7 m W v K q 3 L j y 2 c t J L X V Z e d T i f F B W K e 4 N b 7 / O Z 9 K i 8 G p J A I S V t C s X c 7 A g P B n U 7 w 8 G / E 8 z 7 k h K D q 0 N T y 0 s 0 D f r C 6 n c U K 9 5 8 Q 9 a C k r M M E t G K M K 4 T t q 1 0 6 w O 4 6 b j T 6 7 g 9 5 F s t f i O u P c l W v D G P q 0 T s H k h d U M 2 5 8 m z F v 1 P C K e / h Y T o w v H F e 1 4 G o + c 7 M e E P u + H e b n f r D f a I P W Z P W M x e s D 1 2 w A 7 Z k A k m 2 V f 2 j X 0 P 3 g S f g 9 P g y 7 k 0 6 H U 1 D 9 l a B G e / A M L 8 4 T c = &lt; / l a t e x i t &gt; z &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " S L U 7 L y 6 D B W g H D h E H Z l 6 / 5 A z E O t s = " &gt; A A A C y 3 i c f V H L a t t A F B 2 r r 9 R 9 J e 2 y m 6 H C U E o J U g i 0 y 0 C 7 6 C Y 0 h d o O W C Z c j a / k w T M j M T M y d V Q t + w H Z p v / Q / 8 n f 5 M p R a Z 2 k v T B w O P f c x 5 y b l k o 6 H 0 U X v e D O 3 X v 3 H 2 w 9 7 D 9 6 / O T p s + 2 d 5 y N X V F b g U B S q s M c p O F T S 4 N B L r / C 4 t A g 6 V T h O F x / a / H i J 1 s n C f P W r E q c a c i M z K c A T N U 6 W K O r T 5 m Q 7 j H a j d f C b I O 5 A y L o 4 O t n p / U p m h a g 0 G i 8 U O D e J o 9 J P a 7 B e C o V N P 6 k c l i A W k O O E o A G N b l q v 9 2 3 4 g J g Z z w p L z 3 i + Z v + u q E E 7 t 9 I p K T X 4 u b u e a 8 n b c p P K Z + + n t T R l 5 d G I q 0 F Z p b g v e P t 5 P p M W h V c r A i C s p F 2 5 m I M F 4 c m i f n 8 w 4 H + a c U d S 8 m h j e G p h g b 7 Z X E j l B f W a 6 3 / Q U l B i h l k y Q h H G d d K u n W Z 1 G D c d v 7 y F / 4 h k q 8 V D 4 j 6 X a M E X 9 k 2 d g M 2 1 N A 3 Z n C d v W / Q / I X z 7 L S R E F 4 6 v 3 / M m G O 3 t x o S / 7 I c H + 9 2 t t 9 h L 9 o q 9 Z j F 7 x w 7 Y J 3 b E h k y w B T t j 5 + x n c B i 4 4 D T 4 f i U N e l 3 N C 7 Y R w Y 9 L T V P i p g = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " S L U 7 L y 6 D B W g H D h E H Z l 6 / 5 A z E O t s = " &gt; A A A C y 3 i c f V H L a t t A F B 2 r r 9 R 9 J e 2 y m 6 H C U E o J U g i 0 y 0 C 7 6 C Y 0 h d o O W C Z c j a / k w T M j M T M y d V Q t + w H Z p v / Q / 8 n f 5 M p R a Z 2 k v T B w O P f c x 5 y b l k o 6 H 0 U X v e D O 3 X v 3 H 2 w 9 7 D 9 6 / O T p s + 2 d 5 y N X V F b g U B S q s M c p O F T S 4 N B L r / C 4 t A g 6 V T h O F x / a / H i J 1 s n C f P W r E q c a c i M z K c A T N U 6 W K O r T 5 m Q 7 j H a j d f C b I O 5 A y L o 4 O t n p / U p m h a g 0 G i 8 U O D e J o 9 J P a 7 B e C o V N P 6 k c l i A W k O O E o A G N b l q v 9 2 3 4 g J g Z z w p L z 3 i + Z v + u q E E 7 t 9 I p K T X 4 u b u e a 8 n b c p P K Z + + n t T R l 5 d G I q 0 F Z p b g v e P t 5 P p M W h V c r A i C s p F 2 5 m I M F 4 c m i f n 8 w 4 H + a c U d S 8 m h j e G p h g b 7 Z X E j l B f W a 6 3 / Q U l B i h l k y Q h H G d d K u n W Z 1 G D c d v 7 y F / 4 h k q 8 V D 4 j 6 X a M E X 9 k 2 d g M 2 1 N A 3 Z n C d v W / Q / I X z 7 L S R E F 4 6 v 3 / M m G O 3 t x o S / 7 I c H + 9 2 t t 9 h L 9 o q 9 Z j F 7 x w 7 Y J 3 b E h k y w B T t j 5 + x n c B i 4 4 D T 4 f i U N e l 3 N C 7 Y R w Y 9 L T V P i p g = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " S L U 7 L y 6 D B W g H D h E H Z l 6 / 5 A z E O t s = " &gt; A A A C y 3 i c f V H L a t t A F B 2 r r 9 R 9 J e 2 y m 6 H C U E o J U g i 0 y 0 C 7 6 C Y 0 h d o O W C Z c j a / k w T M j M T M y d V Q t + w H Z p v / Q / 8 n f 5 M p R a Z 2 k v T B w O P f c x 5 y b l k o 6 H 0 U X v e D O 3 X v 3 H 2 w 9 7 D 9 6 / O T p s + 2 d 5 y N X V F b g U B S q s M c p O F T S 4 N B L r / C 4 t A g 6 V T h O F x / a / H i J 1 s n C f P W r E q c a c i M z K c A T N U 6 W K O r T 5 m Q 7 j H a j d f C b I O 5 A y L o 4 O t n p / U p m h a g 0 G i 8 U O D e J o 9 J P a 7 B e C o V N P 6 k c l i A W k O O E o A G N b l q v 9 2 3 4 g J g Z z w p L z 3 i + Z v + u q E E 7 t 9 I p K T X 4 u b u e a 8 n b c p P K Z + + n t T R l 5 d G I q 0 F Z p b g v e P t 5 P p M W h V c r A i C s p F 2 5 m I M F 4 c m i f n 8 w 4 H + a c U d S 8 m h j e G p h g b 7 Z X E j l B f W a 6 3 / Q U l B i h l k y Q h H G d d K u n W Z 1 G D c d v 7 y F / 4 h k q 8 V D 4 j 6 X a M E X 9 k 2 d g M 2 1 N A 3 Z n C d v W / Q / I X z 7 L S R E F 4 6 v 3 / M m G O 3 t x o S / 7 I c H + 9 2 t t 9 h L 9 o q 9 Z j F 7 x w 7 Y J 3 b E h k y w B T t j 5 + x n c B i 4 4 D T 4 f i U N e l 3 N C 7 Y R w Y 9 L T V P i p g = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " S L U 7 L y 6 D B W g H D h E H Z l 6 / 5 A z E O t s = " &gt; A A A C y 3 i c f V H L a t t A F B 2 r r 9 R 9 J e 2 y m 6 H C U E o J U g i 0 y 0 C 7 6 C Y 0 h d o O W C Z c j a / k w T M j M T M y d V Q t + w H Z p v / Q / 8 n f 5 M p R a Z 2 k v T B w O P f c x 5 y b l k o 6 H 0 U X v e D O 3 X v 3 H 2 w 9 7 D 9 6 / O T p s + 2 d 5 y N X V F b g U B S q s M c p O F T S 4 N B L r / C 4 t A g 6 V T h O F x / a / H i J 1 s n C f P W r E q c a c i M z K c A T N U 6 W K O r T 5 m Q 7 j H a j d f C b I O 5 A y L o 4 O t n p / U p m h a g 0 G i 8 U O D e J o 9 J P a 7 B e C o V N P 6 k c l i A W k O O E o A G N b l q v 9 2 3 4 g J g Z z w p L z 3 i + Z v + u q E E 7 t 9 I p K T X 4 u b u e a 8 n b c p P K Z + + n t T R l 5 d G I q 0 F Z p b g v e P t 5 P p M W h V c r A i C s p F 2 5 m I M F 4 c m i f n 8 w 4 H + a c U d S 8 m h j e G p h g b 7 Z X E j l B f W a 6 3 / Q U l B i h l k y Q h H G d d K u n W Z 1 G D c d v 7 y F / 4 h k q 8 V D 4 j 6 X a M E X 9 k 2 d g M 2 1 N A 3 Z n C d v W / Q / I X z 7 L S R E F 4 6 v 3 / M m G O 3 t x o S / 7 I c H + 9 2 t t 9 h L 9 o q 9 Z j F 7 x w 7 Y J 3 b E h k y w B T t j 5 + x n c B i 4 4 D T 4 f i U N e l 3 N C 7 Y R w Y 9 L T V P i p g = = &lt; / l a t e x i t &gt; z &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " S L U 7 L y 6 D B W g H D h E H Z l 6 / 5 A z E O t s = " &gt; A A A C y 3 i c f V H L a t t A F B 2 r r 9 R 9 J e 2 y m 6 H C U E o J U g i 0 y 0 C 7 6 C Y 0 h d o O W C Z c j a / k w T M j M T M y d V Q t + w H Z p v / Q / 8 n f 5 M p R a Z 2 k v T B w O P f c x 5 y b l k o 6 H 0 U X v e D O 3 X v 3 H 2 w 9 7 D 9 6 / O T p s + 2 d 5 y N X V F b g U B S q s M c p O F T S 4 N B L r / C 4 t A g 6 V T h O F x / a / H i J 1 s n C f P W r E q c a c i M z K c A T N U 6 W K O r T 5 m Q 7 j H a j d f C b I O 5 A y L o 4 O t n p / U p m h a g 0 G i 8 U O D e J o 9 J P a 7 B e C o V N P 6 k c l i A W k O O E o A G N b l q v 9 2 3 4 g J g Z z w p L z 3 i + Z v + u q E E 7 t 9 I p K T X 4 u b u e a 8 n b c p P K Z + + n t T R l 5 d G I q 0 F Z p b g v e P t 5 P p M W h V c r A i C s p F 2 5 m I M F 4 c m i f n 8 w 4 H + a c U d S 8 m h j e G p h g b 7 Z X E j l B f W a 6 3 / Q U l B i h l k y Q h H G d d K u n W Z 1 G D c d v 7 y F / 4 h k q 8 V D 4 j 6 X a M E X 9 k 2 d g M 2 1 N A 3 Z n C d v W / Q / I X z 7 L S R E F 4 6 v 3 / M m G O 3 t x o S / 7 I c H + 9 2 t t 9 h L 9 o q 9 Z j F 7 x w 7 Y J 3 b E h k y w B T t j 5 + x n c B i 4 4 D T 4 f i U N e l 3 N C 7 Y R w Y 9 L T V P i p g = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " S L U 7 L y 6 D B W g H D h E H Z l 6 / 5 A z E O t s = " &gt; A A A C y 3 i c f V H L a t t A F B 2 r r 9 R 9 J e 2 y m 6 H C U E o J U g i 0 y 0 C 7 6 C Y 0 h d o O W C Z c j a / k w T M j M T M y d V Q t + w H Z p v / Q / 8 n f 5 M p R a Z 2 k v T B w O P f c x 5 y b l k o 6 H 0 U X v e D O 3 X v 3 H 2 w 9 7 D 9 6 / O T p s + 2 d 5 y N X V F b g U B S q s M c p O F T S 4 N B L r / C 4 t A g 6 V T h O F x / a / H i J 1 s n C f P W r E q c a c i M z K c A T N U 6 W K O r T 5 m Q 7 j H a j d f C b I O 5 A y L o 4 O t n p / U p m h a g 0 G i 8 U O D e J o 9 J P a 7 B e C o V N P 6 k c l i A W k O O E o A G N b l q v 9 2 3 4 g J g Z z w p L z 3 i + Z v + u q E E 7 t 9 I p K T X 4 u b u e a 8 n b c p P K Z + + n t T R l 5 d G I q 0 F Z p b g v e P t 5 P p M W h V c r A i C s p F 2 5 m I M F 4 c m i f n 8 w 4 H + a c U d S 8 m h j e G p h g b 7 Z X E j l B f W a 6 3 / Q U l B i h l k y Q h H G d d K u n W Z 1 G D c d v 7 y F / 4 h k q 8 V D 4 j 6 X a M E X 9 k 2 d g M 2 1 N A 3 Z n C d v W / Q / I X z 7 L S R E F 4 6 v 3 / M m G O 3 t x o S / 7 I c H + 9 2 t t 9 h L 9 o q 9 Z j F 7 x w 7 Y J 3 b E h k y w B T t j 5 + x n c B i 4 4 D T 4 f i U N e l 3 N C 7 Y R w Y 9 L T V P i p g = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " S L U 7 L y 6 D B W g H D h E H Z l 6 / 5 A z E O t s = " &gt; A A A C y 3 i c f V H L a t t A F B 2 r r 9 R 9 J e 2 y m 6 H C U E o J U g i 0 y 0 C 7 6 C Y 0 h d o O W C Z c j a / k w T M j M T M y d V Q t + w H Z p v / Q / 8 n f 5 M p R a Z 2 k v T B w O P f c x 5 y b l k o 6 H 0 U X v e D O 3 X v 3 H 2 w 9 7 D 9 6 / O T p s + 2 d 5 y N X V F b g U B S q s M c p O F T S 4 N B L r / C 4 t A g 6 V T h O F x / a / H i J 1 s n C f P W r E q c a c i M z K c A T N U 6 W K O r T 5 m Q 7 j H a j d f C b I O 5 A y L o 4 O t n p / U p m h a g 0 G i 8 U O D e J o 9 J P a 7 B e C o V N P 6 k c l i A W k O O E o A G N b l q v 9 2 3 4 g J g Z z w p L z 3 i + Z v + u q E E 7 t 9 I p K T X 4 u b u e a 8 n b c p P K Z + + n t T R l 5 d G I q 0 F Z p b g v e P t 5 P p M W h V c r A i C s p F 2 5 m I M F 4 c m i f n 8 w 4 H + a c U d S 8 m h j e G p h g b 7 Z X E j l B f W a 6 3 / Q U l B i h l k y Q h H G d d K u n W Z 1 G D c d v 7 y F / 4 h k q 8 V D 4 j 6 X a M E X 9 k 2 d g M 2 1 N A 3 Z n C d v W / Q / I X z 7 L S R E F 4 6 v 3 / M m G O 3 t x o S / 7 I c H + 9 2 t t 9 h L 9 o q 9 Z j F 7 x w 7 Y J 3 b E h k y w B T t j 5 + x n c B i 4 4 D T 4 f i U N e l 3 N C 7 Y R w Y 9 L T V P i p g = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " S L U 7 L y 6 D B W g H D h E H Z l 6 / 5 A z E O t s = " &gt; A A A C y 3 i c f V H L a t t A F B 2 r r 9 R 9 J e 2 y m 6 H C U E o J U g i 0 y 0 C 7 6 C Y 0 h d o O W C Z c j a / k w T M j M T M y d V Q t + w H Z p v / Q / 8 n f 5 M p R a Z 2 k v T B w O P f c x 5 y b l k o 6 H 0 U X v e D O 3 X v 3 H 2 w 9 7 D 9 6 / O T p s + 2 d 5 y N X V F b g U B S q s M c p O F T S 4 N B L r / C 4 t A g 6 V T h O F x / a / H i J 1 s n C f P W r E q c a c i M z K c A T N U 6 W K O r T 5 m Q 7 j H a j d f C b I O 5 A y L o 4 O t n p / U p m h a g 0 G i 8 U O D e J o 9 J P a 7 B e C o V N P 6 k c l i A W k O O E o A G N b l q v 9 2 3 4 g J g Z z w p L z 3 i + Z v + u q E E 7 t 9 I p K T X 4 u b u e a 8 n b c p P K Z + + n t T R l 5 d G I q 0 F Z p b g v e P t 5 P p M W h V c r A i C s p F 2 5 m I M F 4 c m i f n 8 w 4 H + a c U d S 8 m h j e G p h g b 7 Z X E j l B f W a 6 3 / Q U l B i h l k y Q h H G d d K u n W Z 1 G D c d v 7 y F / 4 h k q 8 V D 4 j 6 X a M E X 9 k 2 d g M 2 1 N A 3 Z n C d v W / Q / I X z 7 L S R E F 4 6 v 3 / M m G O 3 t x o S / 7 I c H + 9 2 t t 9 h L 9 o q 9 Z j F 7 x w 7 Y J 3 b E h k y w B T t j 5 + x n c B i 4 4 D T 4 f i U N e l 3 N C 7 Y R w Y 9 L T V P i p g = = &lt; / l a t e x i t &gt; g R l a t e x i t s h a 1 _ b a s e 6 4 = " F i G p D e d T 0 a f V g x h K w G M L + 5 A F Q d o = " &gt; A A A C y X i c f V F d a 9 R A F J 1 N / a j r V 6 u P v g y G B R E p S S n o Y 0 E f h C J W c b e F z b r c z N 5 k h 5 3 J x J l J 6 R r y 5 A / w t f 0 T / h / / j T f b i G 5 b v T B w O P f c j z k 3 L Z V 0 P o p + 9 o K N G z d v 3 d 6 8 0 7 9 7 7 / 6 D h 1 v b j 0 b O V F b g U B h l 7 H E K D p U s c O i l V 3 h c W g S d K j x K F 6 / b / N E J W i d N 8 c k v S 5 x o y A u Z S Q G e q G E + j T 9 / n G 6 F 0 U 6 0 C n 4 V x B 0 I W R e H 0 + 3 e j 2 R m R K W x 8 E K B c + M 4 K v 2 k B u u l U N j 0 k 8 p h C W I B O Y 4 J F q D R T e r V t g 0 f E D P j m b H 0 C s 9 X 7 N 8 V N W j n l j o l p Q Y / d 5 d z L X l d b l z 5 7 N W k l k V Z e S z E x a C s U t w b 3 n 6 d z 6 R F 4 d W S A A g r a V c u 5 m B B e D K o 3 x 8 M + J 9 m 3 J G U H F o b n l p Y o G / W F 1 K 5 o V 5 z / Q 9 a C k r M M E t G K M K 4 T t q 1 0 6 w O 4 6 b j T 6 7 h 3 y D Z a v E d c e 9 L t O C N f V 4 n Y H M t i 4 Z s z p M X L f q f E E 5 / C w n R h e P L 9 7 w K R r s 7 M e E P e + H + X n f r T f a E P W X P W M x e s n 3 2 l h 2 y I R N M s u / s j J 0 H B 8 G X 4 D T 4 e i E N e l 3 N Y 7 Y W w b d f q x T h L Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " F i G p D e d T 0 a f V g x h K w G M L + 5 A F Q d o = " &gt; A A A C y X i c f V F d a 9 R A F J 1 N / a j r V 6 u P v g y G B R E p S S n o Y 0 E f h C J W c b e F z b r c z N 5 k h 5 3 J x J l J 6 R r y 5 A / w t f 0 T / h / / j T f b i G 5 b v T B w O P f c j z k 3 L Z V 0 P o p + 9 o K N G z d v 3 d 6 8 0 7 9 7 7 / 6 D h 1 v b j 0 b O V F b g U B h l 7 H E K D p U s c O i l V 3 h c W g S d K j x K F 6 / b / N E J W i d N 8 c k v S 5 x o y A u Z S Q G e q G E + j T 9 / n G 6 F 0 U 6 0 C n 4 V x B 0 I W R e H 0 + 3 e j 2 R m R K W x 8 E K B c + M 4 K v 2 k B u u l U N j 0 k 8 p h C W I B O Y 4 J F q D R T e r V t g 0 f E D P j m b H 0 C s 9 X 7 N 8 V N W j n l j o l p Q Y / d 5 d z L X l d b l z 5 7 N W k l k V Z e S z E x a C s U t w b 3 n 6 d z 6 R F 4 d W S A A g r a V c u 5 m B B e D K o 3 x 8 M + J 9 m 3 J G U H F o b n l p Y o G / W F 1 K 5 o V 5 z / Q 9 a C k r M M E t G K M K 4 T t q 1 0 6 w O 4 6 b j T 6 7 h 3 y D Z a v E d c e 9 L t O C N f V 4 n Y H M t i 4 Z s z p M X L f q f E E 5 / C w n R h e P L 9 7 w K R r s 7 M e E P e + H + X n f r T f a E P W X P W M x e s n 3 2 l h 2 y I R N M s u / s j J 0 H B 8 G X 4 D T 4 e i E N e l 3 N Y 7 Y W w b d f q x T h L Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " F i G p D e d T 0 a f V g x h K w G M L + 5 A F Q d o = " &gt; A A A C y X i c f V F d a 9 R A F J 1 N / a j r V 6 u P v g y G B R E p S S n o Y 0 E f h C J W c b e F z b r c z N 5 k h 5 3 J x J l J 6 R r y 5 A / w t f 0 T / h / / j T f b i G 5 b v T B w O P f c j z k 3 L Z V 0 P o p + 9 o K N G z d v 3 d 6 8 0 7 9 7 7 / 6 D h 1 v b j 0 b O V F b g U B h l 7 H E K D p U s c O i l V 3 h c W g S d K j x K F 6 / b / N E J W i d N 8 c k v S 5 x o y A u Z S Q G e q G E + j T 9 / n G 6 F 0 U 6 0 C n 4 V x B 0 I W R e H 0 + 3 e j 2 R m R K W x 8 E K B c + M 4 K v 2 k B u u l U N j 0 k 8 p h C W I B O Y 4 J F q D R T e r V t g 0 f E D P j m b H 0 C s 9 X 7 N 8 V N W j n l j o l p Q Y / d 5 d z L X l d b l z 5 7 N W k l k V Z e S z E x a C s U t w b 3 n 6 d z 6 R F 4 d W S A A g r a V c u 5 m B B e D K o 3 x 8 M + J 9 m 3 J G U H F o b n l p Y o G / W F 1 K 5 o V 5 z / Q 9 a C k r M M E t G K M K 4 T t q 1 0 6 w O 4 6 b j T 6 7 h 3 y D Z a v E d c e 9 L t O C N f V 4 n Y H M t i 4 Z s z p M X L f q f E E 5 / C w n R h e P L 9 7 w K R r s 7 M e E P e + H + X n f r T f a E P W X P W M x e s n 3 2 l h 2 y I R N M s u / s j J 0 H B 8 G X 4 D T 4 e i E N e l 3 N Y 7 Y W w b d f q x T h L Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " F i G p D e d T 0 a f V g x h K w G M L + 5 A F Q d o = " &gt; A A A C y X i c f V F d a 9 R A F J 1 N / a j r V 6 u P v g y G B R E p S S n o Y 0 E f h C J W c b e F z b r c z N 5 k h 5 3 J x J l J 6 R r y 5 A / w t f 0 T / h / / j T f b i G 5 b v T B w O P f c j z k 3 L Z V 0 P o p + 9 o K N G z d v 3 d 6 8 0 7 9 7 7 / 6 D h 1 v b j 0 b O V F b g U B h l 7 H E K D p U s c O i l V 3 h c W g S d K j x K F 6 / b / N E J W i d N 8 c k v S 5 x o y A u Z S Q G e q G E + j T 9 / n G 6 F 0 U 6 0 C n 4 V x B 0 I W R e H 0 + 3 e j 2 R m R K W x 8 E K B c + M 4 K v 2 k B u u l U N j 0 k 8 p h C W I B O Y 4 J F q D R T e r V t g 0 f E D P j m b H 0 C s 9 X 7 N 8 V N W j n l j o l p Q Y / d 5 d z L X l d b l z 5 7 N W k l k V Z e S z E x a C s U t w b 3 n 6 d z 6 R F 4 d W S A A g r a V c u 5 m B B e D K o 3 x 8 M + J 9 m 3 J G U H F o b n l p Y o G / W F 1 K 5 o V 5 z / Q 9 a C k r M M E t G K M K 4 T t q 1 0 6 w O 4 6 b j T 6 7 h 3 y D Z a v E d c e 9 L t O C N f V 4 n Y H M t i 4 Z s z p M X L f q f E E 5 / C w n R h e P L 9 7 w K R r s 7 M e E P e + H + X n f r T f a E P W X P W M x e s n 3 2 l h 2 y I R N M s u / s j J 0 H B 8 G X 4 D T 4 e i E N e l 3 N Y 7 Y W w b d f q x T h L Q = = &lt; / l a t e x i t &gt; g R l a t e x i t s h a 1 _ b a s e 6 4 = " 6 r j k 4 i F k 2 z f b F 5 n p Q n e 6 b Q 0 b t Q w = " &gt; A A A C y X i c f V F d a 9 R A F J 1 N / a j r V 6 u P v g y G B R E p S S n o Y 0 E f h C J W c b e F z b r c z N 5 k h 5 3 M x J l J 6 R r y 5 A / w t f 0 T / h / / j T f b i G 5 b v T B w O P f c j z k 3 L Z V 0 P o p + 9 o K N G z d v 3 d 6 8 0 7 9 7 7 / 6 D h 1 v b j 0 b O V F b g U B h l 7 H E K D p X U O P T S K z w u L U K R K j x K F 6 / b / N E J W i e N / u S X J U 4 K y L X M p A B P 1 D C f 7 n 7 + O N 0 K o 5 1 o F f w q i D s Q s i 4 O p 9 u 9 H 8 n M i K p A 7 Y U C 5 8 Z x V P p J D d Z L o b D p J 5 X D E s Q C c h w T 1 F C g m 9 S r b R s + I G b G M 2 P p a c 9 X 7 N 8 V N R T O L Y u U l A X 4 u b u c a 8 n r c u P K Z 6 8 m t d R l 5 V G L i 0 F Z p b g 3 v P 0 6 n 0 m L w q s l A R B W 0 q 5 c z M G C 8 G R Q v z 8 Y 8 D / N u C M p O b Q 2 P L W w Q N + s L 6 R y Q 7 3 m x T 9 o K S g x w y w Z o Q j j O m n X T r M 6 j J u O P 7 m G f 4 N k q 8 V 3 x L 0 v 0 Y I 3 9 n m d g M 0 L q R u y O U 9 e t O h / Q j j 9 L S R E F 4 4 v 3 / M q G O 3 u x I Q / 7 I X 7 e 9 2 t N 9 k T 9 p Q 9 Y z F 7 y f b Z W 3 b I h k w w y b 6 z M 3 Y e H A R f g t P g 6 4 U 0 6 H U 1 j 9 l a B N 9 + A a 1 3 4 S 4 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 6 r j k 4 i F k 2 z f b F 5 n p Q n e 6 b Q 0 b t Q w = " &gt; A A A C y X i c f V F d a 9 R A F J 1 N / a j r V 6 u P v g y G B R E p S S n o Y 0 E f h C J W c b e F z b r c z N 5 k h 5 3 M x J l J 6 R r y 5 A / w t f 0 T / h / / j T f b i G 5 b v T B w O P f c j z k 3 L Z V 0 P o p + 9 o K N G z d v 3 d 6 8 0 7 9 7 7 / 6 D h 1 v b j 0 b O V F b g U B h l 7 H E K D p X U O P T S K z w u L U K R K j x K F 6 / b / N E J W i e N / u S X J U 4 K y L X M p A B P 1 D C f 7 n 7 + O N 0 K o 5 1 o F f w q i D s Q s i 4 O p 9 u 9 H 8 n M i K p A 7 Y U C 5 8 Z x V P p J D d Z L o b D p J 5 X D E s Q C c h w T 1 F C g m 9 S r b R s + I G b G M 2 P p a c 9 X 7 N 8 V N R T O L Y u U l A X 4 u b u c a 8 n r c u P K Z 6 8 m t d R l 5 V G L i 0 F Z p b g 3 v P 0 6 n 0 m L w q s l A R B W 0 q 5 c z M G C 8 G R Q v z 8 Y 8 D / N u C M p O b Q 2 P L W w Q N + s L 6 R y Q 7 3 m x T 9 o K S g x w y w Z o Q j j O m n X T r M 6 j J u O P 7 m G f 4 N k q 8 V 3 x L 0 v 0 Y I 3 9 n m d g M 0 L q R u y O U 9 e t O h / Q j j 9 L S R E F 4 4 v 3 / M q G O 3 u x I Q / 7 I X 7 e 9 2 t N 9 k T 9 p Q 9 Y z F 7 y f b Z W 3 b I h k w w y b 6 z M 3 Y e H A R f g t P g 6 4 U 0 6 H U 1 j 9 l a B N 9 + A a 1 3 4 S 4 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 6 r j k 4 i F k 2 z f b F 5 n p Q n e 6 b Q 0 b t Q w = " &gt; A A A C y X i c f V F d a 9 R A F J 1 N / a j r V 6 u P v g y G B R E p S S n o Y 0 E f h C J W c b e F z b r c z N 5 k h 5 3 M x J l J 6 R r y 5 A / w t f 0 T / h / / j T f b i G 5 b v T B w O P f c j z k 3 L Z V 0 P o p + 9 o K N G z d v 3 d 6 8 0 7 9 7 7 / 6 D h 1 v b j 0 b O V F b g U B h l 7 H E K D p X U O P T S K z w u L U K R K j x K F 6 / b / N E J W i e N / u S X J U 4 K y L X M p A B P 1 D C f 7 n 7 + O N 0 K o 5 1 o F f w q i D s Q s i 4 O p 9 u 9 H 8 n M i K p A 7 Y U C 5 8 Z x V P p J D d Z L o b D p J 5 X D E s Q C c h w T 1 F C g m 9 S r b R s + I G b G M 2 P p a c 9 X 7 N 8 V N R T O L Y u U l A X 4 u b u c a 8 n r c u P K Z 6 8 m t d R l 5 V G L i 0 F Z p b g 3 v P 0 6 n 0 m L w q s l A R B W 0 q 5 c z M G C 8 G R Q v z 8 Y 8 D / N u C M p O b Q 2 P L W w Q N + s L 6 R y Q 7 3 m x T 9 o K S g x w y w Z o Q j j O m n X T r M 6 j J u O P 7 m G f 4 N k q 8 V 3 x L 0 v 0 Y I 3 9 n m d g M 0 L q R u y O U 9 e t O h / Q j j 9 L S R E F 4 4 v 3 / M q G O 3 u x I Q / 7 I X 7 e 9 2 t N 9 k T 9 p Q 9 Y z F 7 y f b Z W 3 b I h k w w y b 6 z M 3 Y e H A R f g t P g 6 4 U 0 6 H U 1 j 9 l a B N 9 + A a 1 3 4 S 4 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 6 r j k 4 i F k 2 z f b F 5 n p Q n e 6 b Q 0 b t Q w = " &gt; A A A C y X i c f V F d a 9 R A F J 1 N / a j r V 6 u P v g y G B R E p S S n o Y 0 E f h C J W c b e F z b r c z N 5 k h 5 3 M x J l J 6 R r y 5 A / w t f 0 T / h / / j T f b i G 5 b v T B w O P f c j z k 3 L Z V 0 P o p + 9 o K N G z d v 3 d 6 8 0 7 9 7 7 / 6 D h 1 v b j 0 b O V F b g U B h l 7 H E K D p X U O P T S K z w u L U K R K j x K F 6 / b / N E J W i e N / u S X J U 4 K y L X M p A B P 1 D C f 7 n 7 + O N 0 K o 5 1 o F f w q i D s Q s i 4 O p 9 u 9 H 8 n M i K p A 7 Y U C 5 8 Z x V P p J D d Z L o b D p J 5 X D E s Q C c h w T 1 F C g m 9 S r b R s + I G b G M 2 P p a c 9 X 7 N 8 V N R T O L Y u U l A X 4 u b u c a 8 n r c u P K Z 6 8 m t d R l 5 V G L i 0 F Z p b g 3 v P 0 6 n 0 m L w q s l A R B W 0 q 5 c z M G C 8 G R Q v z 8 Y 8 D / N u C M p O b Q 2 P L W w Q N + s L 6 R y Q 7 3 m x T 9 o K S g x w y w Z o Q j j O m n X T r M 6 j J u O P 7 m G f 4 N k q 8 V 3 x L 0 v 0 Y I 3 9 n m d g M 0 L q R u y O U 9 e t O h / Q j j 9 L S R E F 4 4 v 3 / M q G O 3 u x I Q / 7 I X 7 e 9 2 t N 9 k T 9 p Q 9 Y z F 7 y f b Z W 3 b I h k w w y b 6 z M 3 Y e H A R f g t P g 6 4 U 0 6 H U 1 j 9 l a B N 9 + A a 1 3 4 S 4 = &lt; / l a t e x i t &gt; x &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " t z D d g d g z u R z o 1 B D J o S J 5 V a M E v 7 8 = " &gt; A A A C y 3 i c f V H L a t t A F B 0 r f a T u K 4 9 l N k O F o Z Q S p B B o l 4 F 2 k U 1 I A r U d s E y 4 G l / J g + c h Z k Y m r q p l P i D b 9 B / 6 P / 2 b j h y F 1 E n a C w O H c 8 9 9 z L l p I b h 1 U f S 7 E 6 w 9 e f r s + f q L 7 s t X r 9 + 8 3 d j c G l h d G o Z 9 p o U 2 Z y l Y F F x h 3 3 E n 8 K w w C D I V O E x n X 5 r 8 c I 7 G c q 2 + u U W B Y w m 5 4 h l n 4 D w 1 T O b I q o v 6 f C O M d q N l 0 I c g b k F I 2 j g 5 3 + z 8 S i a a l R K V Y w K s H c V R 4 c Y V G M e Z w L q b l B Y L Y D P I c e S h A o l 2 X C 3 3 r W n P M x O a a e O f c n T J / l 1 R g b R 2 I V O v l O C m 9 n 6 u I R / L j U q X f R 5 X X B W l Q 8 V u B m W l o E 7 T 5 v N 0 w g 0 y J x Y e A D P c 7 0 r Z F A w w 5 y 3 q d n s 9 e t e M W i / 1 H q 0 M T w 3 M 0 N W r C 4 l c + 1 5 T + Q + a M 5 + Y Y J Y M k I V x l T R r p 1 k V x n X L z x / h v 6 K 3 1 e C R 5 4 4 L N O C 0 + V A l Y H L J V e 1 t z p O P D f q f E C 5 u h b C 8 c H z / n g / B Y G 8 3 9 v h 0 P z z Y b 2 + 9 T n b I O / K e x O Q T O S C H 5 I T 0 C S M z c k W u y c / g K L D B 9 + D H j T T o t D X b Z C W C y z 9 I j + K k &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " t z D d g d g z u R z o 1 B D J o S J 5 V a M E v 7 8 = " &gt; A A A C y 3 i c f V H L a t t A F B 0 r f a T u K 4 9 l N k O F o Z Q S p B B o l 4 F 2 k U 1 I A r U d s E y 4 G l / J g + c h Z k Y m r q p l P i D b 9 B / 6 P / 2 b j h y F 1 E n a C w O H c 8 9 9 z L l p I b h 1 U f S 7 E 6 w 9 e f r s + f q L 7 s t X r 9 + 8 3 d j c G l h d G o Z 9 p o U 2 Z y l Y F F x h 3 3 E n 8 K w w C D I V O E x n X 5 r 8 c I 7 G c q 2 + u U W B Y w m 5 4 h l n 4 D w 1 T O b I q o v 6 f C O M d q N l 0 I c g b k F I 2 j g 5 3 + z 8 S i a a l R K V Y w K s H c V R 4 c Y V G M e Z w L q b l B Y L Y D P I c e S h A o l 2 X C 3 3 r W n P M x O a a e O f c n T J / l 1 R g b R 2 I V O v l O C m 9 n 6 u I R / L j U q X f R 5 X X B W l Q 8 V u B m W l o E 7 T 5 v N 0 w g 0 y J x Y e A D P c 7 0 r Z F A w w 5 y 3 q d n s 9 e t e M W i / 1 H q 0 M T w 3 M 0 N W r C 4 l c + 1 5 T + Q + a M 5 + Y Y J Y M k I V x l T R r p 1 k V x n X L z x / h v 6 K 3 1 e C R 5 4 4 L N O C 0 + V A l Y H L J V e 1 t z p O P D f q f E C 5 u h b C 8 c H z / n g / B Y G 8 3 9 v h 0 P z z Y b 2 + 9 T n b I O / K e x O Q T O S C H 5 I T 0 C S M z c k W u y c / g K L D B 9 + D H j T T o t D X b Z C W C y z 9 I j + K k &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " t z D d g d g z u R z o 1 B D J o S J 5 V a M E v 7 8 = " &gt; A A A C y 3 i c f V H L a t t A F B 0 r f a T u K 4 9 l N k O F o Z Q S p B B o l 4 F 2 k U 1 I A r U d s E y 4 G l / J g + c h Z k Y m r q p l P i D b 9 B / 6 P / 2 b j h y F 1 E n a C w O H c 8 9 9 z L l p I b h 1 U f S 7 E 6 w 9 e f r s + f q L 7 s t X r 9 + 8 3 d j c G l h d G o Z 9 p o U 2 Z y l Y F F x h 3 3 E n 8 K w w C D I V O E x n X 5 r 8 c I 7 G c q 2 + u U W B Y w m 5 4 h l n 4 D w 1 T O b I q o v 6 f C O M d q N l 0 I c g b k F I 2 j g 5 3 + z 8 S i a a l R K V Y w K s H c V R 4 c Y V G M e Z w L q b l B Y L Y D P I c e S h A o l 2 X C 3 3 r W n P M x O a a e O f c n T J / l 1 R g b R 2 I V O v l O C m 9 n 6 u I R / L j U q X f R 5 X X B W l Q 8 V u B m W l o E 7 T 5 v N 0 w g 0 y J x Y e A D P c 7 0 r Z F A w w 5 y 3 q d n s 9 e t e M W i / 1 H q 0 M T w 3 M 0 N W r C 4 l c + 1 5 T + Q + a M 5 + Y Y J Y M k I V x l T R r p 1 k V x n X L z x / h v 6 K 3 1 e C R 5 4 4 L N O C 0 + V A l Y H L J V e 1 t z p O P D f q f E C 5 u h b C 8 c H z / n g / B Y G 8 3 9 v h 0 P z z Y b 2 + 9 T n b I O / K e x O Q T O S C H 5 I T 0 C S M z c k W u y c / g K L D B 9 + D H j T T o t D X b Z C W C y z 9 I j + K k &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " t z D d g d g z u R z o 1 B D J o S J 5 V a M E v 7 8 = " &gt; A A A C y 3 i c f V H L a t t A F B 0 r f a T u K 4 9 l N k O F o Z Q S p B B o l 4 F 2 k U 1 I A r U d s E y 4 G l / J g + c h Z k Y m r q p l P i D b 9 B / 6 P / 2 b j h y F 1 E n a C w O H c 8 9 9 z L l p I b h 1 U f S 7 E 6 w 9 e f r s + f q L 7 s t X r 9 + 8 3 d j c G l h d G o Z 9 p o U 2 Z y l Y F F x h 3 3 E n 8 K w w C D I V O E x n X 5 r 8 c I 7 G c q 2 + u U W B Y w m 5 4 h l n 4 D w 1 T O b I q o v 6 f C O M d q N l 0 I c g b k F I 2 j g 5 3 + z 8 S i a a l R K V Y w K s H c V R 4 c Y V G M e Z w L q b l B Y L Y D P I c e S h A o l 2 X C 3 3 r W n P M x O a a e O f c n T J / l 1 R g b R 2 I V O v l O C m 9 n 6 u I R / L j U q X f R 5 X X B W l Q 8 V u B m W l o E 7 T 5 v N 0 w g 0 y J x Y e A D P c 7 0 r Z F A w w 5 y 3 q d n s 9 e t e M W i / 1 H q 0 M T w 3 M 0 N W r C 4 l c + 1 5 T + Q + a M 5 + Y Y J Y M k I V x l T R r p 1 k V x n X L z x / h v 6 K 3 1 e C R 5 4 4 L N O C 0 + V A l Y H L J V e 1 t z p O P D f q f E C 5 u h b C 8 c H z / n g / B Y G 8 3 9 v h 0 P z z Y b 2 + 9 T n b I O / K e x O Q T O S C H 5 I T 0 C S M z c k W u y c / g K L D B 9 + D H j T T o t D X b Z C W C y z 9 I j + K k &lt; / l a t e x i t &gt; " r L Q O b k F J Q 6 r k b k t d U D 4 B Y X B E b K Q = " &gt; A A A C 1 n i c f V F d a x N B F J 1 s / a j x o 2 l 9 9 G V w C Y h o 2 S 2 C P h Y s 1 A f F i i Y N Z G O 4 O 7 m 7 G T I f y 8 x s M C z r m / j q D / B V H / 0 / / h t n 0 x V N W 7 0 w c D j 3 z L 2 H c 9 N C c O u i 6 G c n 2 L p y 9 d r 1 7 R v d m 7 d u 3 9 n p 7 e 4 N r S 4 N w w H T Q p t R C h Y F V z h w 3 A k c F Q Z B p g J P 0 8 X z p n + 6 R G O 5 V u / c q s C J h F z x j D N w n p r 2 e l X C Q N C 3 9 f v j a f X y c V x P e 2 G 0 H 6 2 L X g R x C 0 L S 1 s l 0 t / M j m W l W S l S O C b B 2 H E e F m 1 R g H G c C 6 2 5 S W i y A L S D H s Y c K J N p J t b Z e 0 7 5 n Z j T T x j / l 6 J r 9 + 0 c F 0 t q V T L 1 S g p v b 8 7 2 G v K w 3 L l 3 2 b F J x V Z Q O F T t b l J W C O k 2 b H O i M G 2 R O r D w A Z r j 3 S t k c D D D n 0 + p 2 + 3 3 6 Z x i 1 X u r j 2 l i e G l i g q z c N i V z 7 W X P 5 D 5 o z 3 5 h h l g y R h X G V N L b T r A r j u u W X l / B H 6 G M 1 + M p z r w s 0 4 L R 5 W C V g c s l V 7 W P O k 0 c N + p 8 Q P v w W e u Q v H J + / 5 0 U w P N i P P X 7 z J D w 8 a G + 9 T e 6 R + + Q B i c l T c k h e k B M y I I w s y V f y j X w P R s H H 4 F P w + U w a d N o / d 8 l G B V 9 + A X K M 5 c A = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " r L Q O b k F J Q 6 r k b k t d U D 4 B Y X B E b K Q = " &gt; A A A C 1 n i c f V F d a x N B F J 1 s / a j x o 2 l 9 9 G V w C Y h o 2 S 2 C P h Y s 1 A f F i i Y N Z G O 4 O 7 m 7 G T I f y 8 x s M C z r m / j q D / B V H / 0 / / h t n 0 x V N W 7 0 w c D j 3 z L 2 H c 9 N C c O u i 6 G c n 2 L p y 9 d r 1 7 R v d m 7 d u 3 9 n p 7 e 4 N r S 4 N w w H T Q p t R C h Y F V z h w 3 A k c F Q Z B p g J P 0 8 X z p n + 6 R G O 5 V u / c q s C J h F z x j D N w n p r 2 e l X C Q N C 3 9 f v j a f X y c V x P e 2 G 0 H 6 2 L X g R x C 0 L S 1 s l 0 t / M j m W l W S l S O C b B 2 H E e F m 1 R g H G c C 6 2 5 S W i y A L S D H s Y c K J N p J t b Z e 0 7 5 n Z j T T x j / l 6 J r 9 + 0 c F 0 t q V T L 1 S g p v b 8 7 2 G v K w 3 L l 3 2 b F J x V Z Q O F T t b l J W C O k 2 b H O i M G 2 R O r D w A Z r j 3 S t k c D D D n 0 + p 2 + 3 3 6 Z x i 1 X u r j 2 l i e G l i g q z c N i V z 7 W X P 5 D 5 o z 3 5 h h l g y R h X G V N L b T r A r j u u W X l / B H 6 G M 1 + M p z r w s 0 4 L R 5 W C V g c s l V 7 W P O k 0 c N + p 8 Q P v w W e u Q v H J + / 5 0 U w P N i P P X 7 z J D w 8 a G + 9 T e 6 R + + Q B i c l T c k h e k B M y I I w s y V f y j X w P R s H H 4 F P w + U w a d N o / d 8 l G B V 9 + A X K M 5 c A = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " r L Q O b k F J Q 6 r k b k t d U D 4 B Y X B E b K Q = " &gt; A A A C 1 n i c f V F d a x N B F J 1 s / a j x o 2 l 9 9 G V w C Y h o 2 S 2 C P h Y s 1 A f F i i Y N Z G O 4 O 7 m 7 G T I f y 8 x s M C z r m / j q D / B V H / 0 / / h t n 0 x V N W 7 0 w c D j 3 z L 2 H c 9 N C c O u i 6 G c n 2 L p y 9 d r 1 7 R v d m 7 d u 3 9 n p 7 e 4 N r S 4 N w w H T Q p t R C h Y F V z h w 3 A k c F Q Z B p g J P 0 8 X z p n + 6 R G O 5 V u / c q s C J h F z x j D N w n p r 2 e l X C Q N C 3 9 f v j a f X y c V x P e 2 G 0 H 6 2 L X g R x C 0 L S 1 s l 0 t / M j m W l W S l S O C b B 2 H E e F m 1 R g H G c C 6 2 5 S W i y A L S D H s Y c K J N p J t b Z e 0 7 5 n Z j T T x j / l 6 J r 9 + 0 c F 0 t q V T L 1 S g p v b 8 7 2 G v K w 3 L l 3 2 b F J x V Z Q O F T t b l J W C O k 2 b H O i M G 2 R O r D w A Z r j 3 S t k c D D D n 0 + p 2 + 3 3 6 Z x i 1 X u r j 2 l i e G l i g q z c N i V z 7 W X P 5 D 5 o z 3 5 h h l g y R h X G V N L b T r A r j u u W X l / B H 6 G M 1 + M p z r w s 0 4 L R 5 W C V g c s l V 7 W P O k 0 c N + p 8 Q P v w W e u Q v H J + / 5 0 U w P N i P P X 7 z J D w 8 a G + 9 T e 6 R + + Q B i c l T c k h e k B M y I I w s y V f y j X w P R s H H 4 F P w + U w a d N o / d 8 l G B V 9 + A X K M 5 c A = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " r L Q O b k F J Q 6 r k b k t d U D 4 B Y X B E b K Q = " &gt; A A A C 1 n i c f V F d a x N B F J 1 s / a j x o 2 l 9 9 G V w C Y h o 2 S 2 C P h Y s 1 A f F i i Y N Z G O 4 O 7 m 7 G T I f y 8 x s M C z r m / j q D / B V H / 0 / / h t n 0 x V N W 7 0 w c D j 3 z L 2 H c 9 N C c O u i 6 G c n 2 L p y 9 d r 1 7 R v d m 7 d u 3 9 n p 7 e 4 N r S 4 N w w H T Q p t R C h Y F V z h w 3 A k c F Q Z B p g J P 0 8 X z p n + 6 R G O 5 V u / c q s C J h F z x j D N w n p r 2 e l X C Q N C 3 9 f v j a f X y c V x P e 2 G 0 H 6 2 L X g R x C 0 L S 1 s l 0 t / M j m W l W S l S O C b B 2 H E e F m 1 R g H G c C 6 2 5 S W i y A L S D H s Y c K J N p J t b Z e 0 7 5 n Z j T T x j / l 6 J r 9 + 0 c F 0 t q V T L 1 S g p v b 8 7 2 G v K w 3 L l 3 2 b F J x V Z Q O F T t b l J W C O k 2 b H O i M G 2 R O r D w A Z r j 3 S t k c D D D n 0 + p 2 + 3 3 6 Z x i 1 X u r j 2 l i e G l i g q z c N i V z 7 W X P 5 D 5 o z 3 5 h h l g y R h X G V N L b T r A r j u u W X l / B H 6 G M 1 + M p z r w s 0 4 L R 5 W C V g c s l V 7 W P O k 0 c N + p 8 Q P v w W e u Q v H J + / 5 0 U w P N i P P X 7 z J D w 8 a G + 9 T e 6 R + + Q B i c l T c k h e k B M y I I w s y V f y j X w P R s H H 4 F P w + U w a d N o / d 8 l G B V 9 + A X K M 5 c A = &lt; / l a t e x i t &gt; S G " o V x F G F o e l d 3 2 h E 0 i H v T p i E I F v + Q = " &gt; A A A C 0 n i c f V H L a h R B F K 1 p X 3 F 8 J b p 0 U 9 g M i E j o D g F d B i L o R o y Y m Q S m J 8 P t m t s 9 x d S j q a o O G Y t e i F s / w K 1 + g P / j 3 1 g 9 a d F J o h c K D u e e u v d w b l 4 J b l 2 S / O x F 1 6 7 f u H l r 4 3 b / z t 1 7 9 x 9 s b j 0 c W V 0 b h k O m h T b H O V g U X O H Q c S f w u D I I M h d 4 l C / 2 2 / 7 R K R r L t T p 0 y w o n E k r F C 8 7 A B e r E Z w w E / d C c v J 7 6 t J l u x s l 2 s i p 6 G a Q d i E l X B 9 O t 3 o 9 s p l k t U T k m w N p x m l R u 4 s E 4 z g Q 2 / a y 2 W A</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>d 7 TA 1 &lt;</head><label>71</label><figDesc>T g 9 7 v x 3 k 5 3 6 w 3 y m D w h T 0 l K X p A 9 8 o Y c k C F h x J C v 5 B v 5 H h 1 G H 6 N P 0 e d z a d T r / j w i a x V 9 + Q V q H O U C &lt; / l a t e x i t &gt; g R L &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " m 1 I U 2 L e I z 3 4 P B A 2 t w j u N G 7 Q S k F s = " &gt; A A A C y X i c f V F d a 9 R A F J 2 N X 3 X 9 a u u j L 4 N h Q U R K I g V 9 L O h D o Y p V 3 G 1 h s y 4 3 s z f Z Y W c m c W Z S u o Y 8 9 Q f 4 q n / C / + O / 8 W Y b 0 W 2 r F w Y O 5 5 7 7 M e e m p Z L O R 9 H P X n D t + o 2 b t z Z u 9 + / c v X f / w e b W 9 s g V l R U 4 F I U q 7 H E K D p U 0 O P T S K z w u L Y J O F R 6 l i 1 d t / u g E r Z O F + e i X J U 4 0 5 E Z m U o A n a p h / + j B 9 M 9 0 M o 5 1 o F f w y i D s Q s i 4 O p 1 u 9 H 8 m s E J V G 4 4 U C 5 8 Z x V P p J D d Z L o b D p J 5 X D E s Q C c h w T N K D R T e r V t g 0 f E D P j W W H p G c 9 X 7 N 8 V N W j n l j o l p Q Y / d x d z L X l V b l z 5 7 O W k l q a s P B p x P i i r F P c F b 7 / O Z 9 K i 8 G p J A I S V t C s X c 7 A g P B n U 7 w 8 G / E 8 z 7 k h K D q 0 N T y 0 s 0 D f r C 6 m 8 o F 5 z / Q 9 a C k r M M E t G K M K 4 T t q 1 0 6 w O 4 6 b j T 6 7 g X y P Z a v E t c e 9 K t O A L + 7 R O w O Z a m o Z s z p N n L f q f E E 5 / C w n R h e O L 9 7 w M R s 9 3 Y s L v d 8 O 9 3 e 7 W G + w R e 8 y e s J i 9 Y H t s n x 2 y I R N M s q / s G / s e H A S f g 9 P g y 7 k 0 6 H U 1 D 9 l a B G e / A O u P 4 U g = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " m 1 I U 2 L e I z 3 4 P B A 2 t w j u N G 7 Q S k F s = " &gt; A A A C y X i c f V F d a 9 R A F J 2 N X 3 X 9 a u u j L 4 N h Q U R K I g V 9 L O h D o Y p V 3 G 1 h s y 4 3 s z f Z Y W c m c W Z S u o Y 8 9 Q f 4 q n / C / + O / 8 W Y b 0 W 2 r F w Y O 5 5 7 7 M e e m p Z L O R 9 H P X n D t + o 2 b t z Z u 9 + / c v X f / w e b W 9 s g V l R U 4 F I U q 7 H E K D p U 0 O P T S K z w u L Y J O F R 6 l i 1 d t / u g E r Z O F + e i X J U 4 0 5 E Z m U o A n a p h / + j B 9 M 9 0 M o 5 1 o F f w y i D s Q s i 4 O p 1 u 9 H 8 m s E J V G 4 4 U C 5 8 Z x V P p J D d Z L o b D p J 5 X D E s Q C c h w T N K D R T e r V t g 0 f E D P j W W H p G c 9 X 7 N 8 V N W j n l j o l p Q Y / d x d z L X l V b l z 5 7 O W k l q a s P B p x P i i r F P c F b 7 / O Z 9 K i 8 G p J A I S V t C s X c 7 A g P B n U 7 w 8 G / E 8 z 7 k h K D q 0 N T y 0 s 0 D f r C 6 m 8 o F 5 z / Q 9 a C k r M M E t G K M K 4 T t q 1 0 6 w O 4 6 b j T 6 7 g X y P Z a v E t c e 9 K t O A L + 7 R O w O Z a m o Z s z p N n L f q f E E 5 / C w n R h e O L 9 7 w M R s 9 3 Y s L v d 8 O 9 3 e 7 W G + w R e 8 y e s J i 9 Y H t s n x 2 y I R N M s q / s G / s e H A S f g 9 P g y 7 k 0 6 H U 1 D 9 l a B G e / A O u P 4 U g = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " m 1 I U 2 L e I z 3 4 P B A 2 t w j u N G 7 Q S k F s = " &gt; A A A C y X i c f V F d a 9 R A F J 2 N X 3 X 9 a u u j L 4 N h Q U R K I g V 9 L O h D o Y p V 3 G 1 h s y 4 3 s z f Z Y W c m c W Z S u o Y 8 9 Q f 4 q n / C / + O / 8 W Y b 0 W 2 r F w Y O 5 5 7 7 M e e m p Z L O R 9 H P X n D t + o 2 b t z Z u 9 + / c v X f / w e b W 9 s g V l R U 4 F I U q 7 H E K D p U 0 O P T S K z w u L Y J O F R 6 l i 1 d t / u g E r Z O F + e i X J U 4 0 5 E Z m U o A n a p h / + j B 9 M 9 0 M o 5 1 o F f w y i D s Q s i 4 O p 1 u 9 H 8 m s E J V G 4 4 U C 5 8 Z x V P p J D d Z L o b D p J 5 X D E s Q C c h w T N K D R T e r V t g 0 f E D P j W W H p G c 9 X 7 N 8 V N W j n l j o l p Q Y / d x d z L X l V b l z 5 7 O W k l q a s P B p x P i i r F P c F b 7 / O Z 9 K i 8 G p J A I S V t C s X c 7 A g P B n U 7 w 8 G / E 8 z 7 k h K D q 0 N T y 0 s 0 D f r C 6 m 8 o F 5 z / Q 9 a C k r M M E t G K M K 4 T t q 1 0 6 w O 4 6 b j T 6 7 g X y P Z a v E t c e 9 K t O A L + 7 R O w O Z a m o Z s z p N n L f q f E E 5 / C w n R h e O L 9 7 w M R s 9 3 Y s L v d 8 O 9 3 e 7 W G + w R e 8 y e s J i 9 Y H t s n x 2 y I R N M s q / s G / s e H A S f g 9 P g y 7 k 0 6 H U 1 D 9 l a B G e / A O u P 4 U g = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " m 1 I U 2 L e I z 3 4 P B A 2 t w j u N G 7 Q S k F s = " &gt; A A A C y X i c f V F d a 9 R A F J 2 N X 3 X 9 a u u j L 4 N h Q U R K I g V 9 L O h D o Y p V 3 G 1 h s y 4 3 s z f Z Y W c m c W Z S u o Y 8 9 Q f 4 q n / C / + O / 8 W Y b 0 W 2 r F w Y O 5 5 7 7 M e e m p Z L O R 9 H P X n D t + o 2 b t z Z u 9 + / c v X f / w e b W 9 s g V l R U 4 F I U q 7 H E K D p U 0 O P T S K z w u L Y J O F R 6 l i 1 d t / u g E r Z O F + e i X J U 4 0 5 E Z m U o A n a p h / + j B 9 M 9 0 M o 5 1 o F f w y i D s Q s i 4 O p 1 u 9 H 8 m s E J V G 4 4 U C 5 8 Z x V P p J D d Z L o b D p J 5 X D E s Q C c h w T N K D R T e r V t g 0 f E D P j W W H p G c 9 X 7 N 8 V N W j n l j o l p Q Y / d x d z L X l V b l z 5 7 O W k l q a s P B p x P i i r F P c F b 7 / O Z 9 K i 8 G p J A I S V t C s X c 7 A g P B n U 7 w 8 G / E 8 z 7 k h K D q 0 N T y 0 s 0 D f r C 6 m 8 o F 5 z / Q 9 a C k r M M E t G K M K 4 T t q 1 0 6 w O 4 6 b j T 6 7 g X y P Z a v E t c e 9 K t O A L + 7 R O w O Z a m o Z s z p N n L f q f E E 5 / C w n R h e O L 9 7 w M R s 9 3 Y s L v d 8 O 9 3 e 7 W G + w R e 8 y e s J i 9 Y H t s n x 2 y I R N M s q / s G / s e H A S f g 9 P g y 7 k 0 6 H U 1 D 9 l a B G e / A O u P 4 U g = &lt; / l a t e x i t &gt; g R L &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " m 1 I U 2 L e I z 3 4 P B A 2 t w j u N G 7 Q S k F s = " &gt; A A A C y X i c f V F d a 9 R A F J 2 N X 3 X 9 a u u j L 4 N h Q U R K I g V 9 L O h D o Y p V 3 G 1 h s y 4 3 s z f Z Y W c m c W Z S u o Y 8 9 Q f 4 q n / C / + O / 8 W Y b 0 W 2 r F w Y O 5 5 7 7 M e e m p Z L O R 9 H P X n D t + o 2 b t z Z u 9 + / c v X f / w e b W 9 s g V l R U 4 F I U q 7 H E K D p U 0 O P T S K z w u L Y J O F R 6 l i 1 d t / u g E r Z O F + e i X J U 4 0 5 E Z m U o A n a p h / + j B 9 M 9 0 M o 5 1 o F f w y i D s Q s i 4 O p 1 u 9 H 8 m s E J V G 4 4 U C 5 8 Z x V P p J D d Z L o b D p J 5 X D E s Q C c h w T N K D R T e r V t g 0 f E D P j W W H p G c 9 X 7 N 8 V N W j n l j o l p Q Y / d x d z L X l V b l z 5 7 O W k l q a s P B p x P i i r F P c F b 7 / O Z 9 K i 8 G p J A I S V t C s X c 7 A g P B n U 7 w 8 G / E 8 z 7 k h K D q 0 N T y 0 s 0 D f r C 6 m 8 o F 5 z / Q 9 a C k r M M E t G K M K 4 T t q 1 0 6 w O 4 6 b j T 6 7 g X y P Z a v E t c e 9 K t O A L + 7 R O w O Z a m o Z s z p N n L f q f E E 5 / C w n R h e O L 9 7 w M R s 9 3 Y s L v d 8 O 9 3 e 7 W G + w R e 8 y e s J i 9 Y H t s n x 2 y I R N M s q / s G / s e H A S f g 9 P g y 7 k 0 6 H U 1 D 9 l a B G e / A O u P 4 U g = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " m 1 I U 2 L e I z 3 4 P B A 2 t w j u N G 7 Q S k F s = " &gt; A A A C y X i c f V F d a 9 R A F J 2 N X 3 X 9 a u u j L 4 N h Q U R K I g V 9 L O h D o Y p V 3 G 1 h s y 4 3 s z f Z Y W c m c W Z S u o Y 8 9 Q f 4 q n / C / + O / 8 W Y b 0 W 2 r F w Y O 5 5 7 7 M e e m p Z L O R 9 H P X n D t + o 2 b t z Z u 9 + / c v X f / w e b W 9 s g V l R U 4 F I U q 7 H E K D p U 0 O P T S K z w u L Y J O F R 6 l i 1 d t / u g E r Z O F + e i X J U 4 0 5 E Z m U o A n a p h / + j B 9 M 9 0 M o 5 1 o F f w y i D s Q s i 4 O p 1 u 9 H 8 m s E J V G 4 4 U C 5 8 Z x V P p J D d Z L o b D p J 5 X D E s Q C c h w T N K D R T e r V t g 0 f E D P j W W H p G c 9 X 7 N 8 V N W j n l j o l p Q Y / d x d z L X l V b l z 5 7 O W k l q a s P B p x P i i r F P c F b 7 / O Z 9 K i 8 G p J A I S V t C s X c 7 A g P B n U 7 w 8 G / E 8 z 7 k h K D q 0 N T y 0 s 0 D f r C 6 m 8 o F 5 z / Q 9 a C k r M M E t G K M K 4 T t q 1 0 6 w O 4 6 b j T 6 7 g X y P Z a v E t c e 9 K t O A L + 7 R O w O Z a m o Z s z p N n L f q f E E 5 / C w n R h e O L 9 7 w M R s 9 3 Y s L v d 8 O 9 3 e 7 W G + w R e 8 y e s J i 9 Y H t s n x 2 y I R N M s q / s G / s e H A S f g 9 P g y 7 k 0 6 H U 1 D 9 l a B G e / A O u P 4 U g = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " m 1 I U 2 L e I z 3 4 P B A 2 t w j u N G 7 Q S k F s = " &gt; A A A C y X i c f V F d a 9 R A F J 2 N X 3 X 9 a u u j L 4 N h Q U R K I g V 9 L O h D o Y p V 3 G 1 h s y 4 3 s z f Z Y W c m c W Z S u o Y 8 9 Q f 4 q n / C / + O / 8 W Y b 0 W 2 r F w Y O 5 5 7 7 M e e m p Z L O R 9 H P X n D t + o 2 b t z Z u 9 + / c v X f / w e b W 9 s g V l R U 4 F I U q 7 H E K D p U 0 O P T S K z w u L Y J O F R 6 l i 1 d t / u g E r Z O F + e i X J U 4 0 5 E Z m U o A n a p h / + j B 9 M 9 0 M o 5 1 o F f w y i D s Q s i 4 O p 1 u 9 H 8 m s E J V G 4 4 U C 5 8 Z x V P p J D d Z L o b D p J 5 X D E s Q C c h w T N K D R T e r V t g 0 f E D P j W W H p G c 9 X 7 N 8 V N W j n l j o l p Q Y / d x d z L X l V b l z 5 7 O W k l q a s P B p x P i i r F P c F b 7 / O Z 9 K i 8 G p J A I S V t C s X c 7 A g P B n U 7 w 8 G / E 8 z 7 k h K D q 0 N T y 0 s 0 D f r C 6 m 8 o F 5 z / Q 9 a C k r M M E t G K M K 4 T t q 1 0 6 w O 4 6 b j T 6 7 g X y P Z a v E t c e 9 K t O A L + 7 R O w O Z a m o Z s z p N n L f q f E E 5 / C w n R h e O L 9 7 w M R s 9 3 Y s L v d 8 O 9 3 e 7 W G + w R e 8 y e s J i 9 Y H t s n x 2 y I R N M s q / s G / s e H A S f g 9 P g y 7 k 0 6 H U 1 D 9 l a B G e / A O u P 4 U g = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " m 1 I U 2 L e I z 3 4 P B A 2 t w j u N G 7 Q S k F s = " &gt; A A A C y X i c f V F d a 9 R A F J 2 N X 3 X 9 a u u j L 4 N h Q U R K I g V 9 L O h D o Y p V 3 G 1 h s y 4 3 s z f Z Y W c m c W Z S u o Y 8 9 Q f 4 q n / C / + O / 8 W Y b 0 W 2 r F w Y O 5 5 7 7 M e e m p Z L O R 9 H P X n D t + o 2 b t z Z u 9 + / c v X f / w e b W 9 s g V l R U 4 F I U q 7 H E K D p U 0 O P T S K z w u L Y J O F R 6 l i 1 d t / u g E r Z O F + e i X J U 4 0 5 E Z m U o A n a p h / + j B 9 M 9 0 M o 5 1 o F f w y i D s Q s i 4 O p 1 u 9 H 8 m s E J V G 4 4 U C 5 8 Z x V P p J D d Z L o b D p J 5 X D E s Q C c h w T N K D R T e r V t g 0 f E D P j W W H p G c 9 X 7 N 8 V N W j n l j o l p Q Y / d x d z L X l V b l z 5 7 O W k l q a s P B p x P i i r F P c F b 7 / O Z 9 K i 8 G p J A I S V t C s X c 7 A g P B n U 7 w 8 G / E 8 z 7 k h K D q 0 N T y 0 s 0 D f r C 6 m 8 o F 5 z / Q 9 a C k r M M E t G K M K 4 T t q 1 0 6 w O 4 6 b j T 6 7 g X y P Z a v E t c e 9 K t O A L + 7 R O w O Z a m o Z s z p N n L f q f E E 5 / C w n R h e O L 9 7 w M R s 9 3 Y s L v d 8 O 9 3 e 7 W G + w R e 8 y e s J i 9 Y H t s n x 2 y I R N M s q / s G / s e H A S f g 9 P g y 7 k 0 6 H U 1 D 9 l a B G e / A O u P 4 U g = &lt; / l a t e x i t &gt; Inference Training g l a t e x i t s h a 1 _ b a s e 6 4 = " e e L M o C</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>E J W i d N 8 c k v S 5 x o y A u Z S Q G e q G H + + f U 0 n m 6 F 0 U 6 0 C n 4 V x B 0 I W R e H 0 + 3 e j 2 R m R K W x 8 E K B c + M 4 K v 2 k B u u l U N j 0 k 8 p h C W I B O Y 4 J F q D R T e r V t g 0 f E D P j m b H 0 C s 9 X 7 N 8 V N W j n l j o l p Q Y / d 5 d z L X l d b l z 5 7 N W k l k V Z e S z E x a C s U t w b 3 n 6 d z 6 R F 4 d W S A A g r a V c u 5 m B B e D K o 3 x 8 M + J 9 m 3 J G U H F o b n l p Y o G / W F 1 K 5 o V 5 z / Q 9 a C k r M M E t G K M K 4 T t q 1 0 6 w O 4 6 b j T 6 7 h 3 y L Z a v E 9 c R 9 K t O C N f V 4 n Y H M t i 4 Z s z p M X L f q f E E 5 / C w n R h e P L 9 7 w K R r s 7 M e G P e + H + X n f r T f a E P W X P W M x e s n 1 2 w A 7 Z k A k m 2 X d 2 x s 6 D d 8 G X 4 D T 4 e i E N e l 3 N Y 7 Y W w b d f g s H h H A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " e e L M o C</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>E J W i d N 8 c k v S 5 x o y A u Z S Q G e q G H + + f U 0 n m 6 F 0 U 6 0 C n 4 V x B 0 I W R e H 0 + 3 e j 2 R m R K W x 8 E K B c + M 4 K v 2 k B u u l U N j 0 k 8 p h C W I B O Y 4 J F q D R T e r V t g 0 f E D P j m b H 0 C s 9 X 7 N 8 V N W j n l j o l p Q Y / d 5 d z L X l d b l z 5 7 N W k l k V Z e S z E x a C s U t w b 3 n 6 d z 6 R F 4 d W S A A g r a V c u 5 m B B e D K o 3 x 8 M + J 9 m 3 J G U H F o b n l p Y o G / W F 1 K 5 o V 5 z / Q 9 a C k r M M E t G K M K 4 T t q 1 0 6 w O 4 6 b j T 6 7 h 3 y L Z a v E 9 c R 9 K t O C N f V 4 n Y H M t i 4 Z s z p M X L f q f E E 5 / C w n R h e P L 9 7 w K R r s 7 M e G P e + H + X n f r T f a E P W X P W M x e s n 1 2 w A 7 Z k A k m 2 X d 2 x s 6 D d 8 G X 4 D T 4 e i E N e l 3 N Y 7 Y W w b d f g s H h H A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " e e L M o C</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>E J W i d N 8 c k v S 5 x o y A u Z S Q G e q G H + + f U 0 n m 6 F 0 U 6 0 C n 4 V x B 0 I W R e H 0 + 3 e j 2 R m R K W x 8 E K B c + M 4 K v 2 k B u u l U N j 0 k 8 p h C W I B O Y 4 J F q D R T e r V t g 0 f E D P j m b H 0 C s 9 X 7 N 8 V N W j n l j o l p Q Y / d 5 d z L X l d b l z 5 7 N W k l k V Z e S z E x a C s U t w b 3 n 6 d z 6 R F 4 d W S A A g r a V c u 5 m B B e D K o 3 x 8 M + J 9 m 3 J G U H F o b n l p Y o G / W F 1 K 5 o V 5 z / Q 9 a C k r M M E t G K M K 4 T t q 1 0 6 w O 4 6 b j T 6 7 h 3 y L Z a v E 9 c R 9 K t O C N f V 4 n Y H M t i 4 Z s z p M X L f q f E E 5 / C w n R h e P L 9 7 w K R r s 7 M e G P e + H + X n f r T f a E P W X P W M x e s n 1 2 w A 7 Z k A k m 2 X d 2 x s 6 D d 8 G X 4 D T 4 e i E N e l 3 N Y 7 Y W w b d f g s H h H A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " e e L M o C</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>2 &lt;</head><label>2</label><figDesc>E J W i d N 8 c k v S 5 x o y A u Z S Q G e q G H + + f U 0 n m 6 F 0 U 6 0 C n 4 V x B 0 I W R e H 0 + 3 e j 2 R m R K W x 8 E K B c + M 4 K v 2 k B u u l U N j 0 k 8 p h C W I B O Y 4 J F q D R T e r V t g 0 f E D P j m b H 0 C s 9 X 7 N 8 V N W j n l j o l p Q Y / d 5 d z L X l d b l z 5 7 N W k l k V Z e S z E x a C s U t w b 3 n 6 d z 6 R F 4 d W S A A g r a V c u 5 m B B e D K o 3 x 8 M + J 9 m 3 J G U H F o b n l p Y o G / W F 1 K 5 o V 5 z / Q 9 a C k r M M E t G K M K 4 T t q 1 0 6 w O 4 6 b j T 6 7 h 3 y L Z a v E 9 c R 9 K t O C N f V 4 n Y H M t i 4 Z s z p M X L f q f E E 5 / C w n R h e P L 9 7 w K R r s 7 M e G P e + H + X n f r T f a E P W X P W M x e s n 1 2 w A 7 Z k A k m 2 X d 2 x s 6 D d 8 G X 4 D T 4 e i E N e l 3 N Y 7 Y W w b d f g s H h H A = = &lt; / l a t e x i t &gt; g A l a t e x i t s h a 1 _ b a s e 6 4 = " 2 4 a + V d 2 W Z 2 E A r E r H J N 8 R V 3 w Z r g g = " &gt; A A A C y X i c f V F d a 9 R A F J 1 N / a j r V 6 u P v g y G B R E p S S n o Y 0 U f C i J W c L e F z b r c z N 5 k h 5 3 M x J l J 6 R r y 5 A / w t f 0 T / h / / j T f b i G 5 b v T B w O P f c j z k 3 L Z V 0 P o p + 9 o K N G z d v 3 d 6 8 0 7 9 7 7 / 6 D h 1 v b j 0 b O V F b g U B h l 7 H E K D p X U O P T S K z w u L U K R K j x K F 2 / a / N E J W i e N / u S X J U 4 K y L X M p A B P 1 D D / / H q 6 O 9 0 K o 5 1 o F f w q i D s Q s i 4 O p 9 u 9 H 8 n M i K p A 7 Y U C 5 8 Z x V P p J D d Z L o b D p J 5 X D E s Q C c h w T 1 F C g m 9 S r b R s + I G b G M 2 P p a c 9 X 7 N 8 V N R T O L Y u U l A X 4 u b u c a 8 n r c u P K Z 6 8 m t d R l 5 V G L i 0 F Z p b g 3 v P 0 6 n 0 m L w q s l A R B W 0 q 5 c z M G C 8 G R Q v z 8 Y 8 D / N u C M p O b Q 2 P L W w Q N + s L 6 R y Q 7 3 m x T 9 o K S g x w y w Z o Q j j O m n X T r M 6 j J u O P 7 m G f 4 t k q 8 X 3 x H 0 o 0 Y I 3 9 n m d g M 0 L q R u y O U 9 e t O h / Q j j 9 L S R E F 4 4 v 3 / M q G O 3 u x I Q / 7 o X 7 e 9 2 t N 9 k T 9 p Q 9 Y z F 7 y f b Z A T t k Q y a Y Z N / Z G T s P 3 g V f g t P g 6 4 U 0 6 H U 1 j 9 l a B N 9 + A Y U i 4 R 0 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 2 4 a +V d 2 W Z 2 E A r E r H J N 8 R V 3 w Z r g g = " &gt; A A A C y X i c f V F d a 9 R A F J 1 N / a j r V 6 u P v g y G B R E p S S n o Y 0 U f C i J W c L e F z b r c z N 5 k h 5 3 M x J l J 6 R r y 5 A / w t f 0 T / h / / j T f b i G 5 b v T B w O P f c j z k 3 L Z V 0 P o p + 9 o K N G z d v 3 d 6 8 0 7 9 7 7 / 6 D h 1 v b j 0 b O V F b g U B h l 7 H E K D p X U O P T S K z w u L U K R K j x K F 2 / a / NE J W i e N / u S X J U 4 K y L X M p A B P 1 D D / / H q 6 O 9 0 K o 5 1 o F f w q i D s Q s i 4 O p 9 u 9 H 8 n M i K p A 7 Y U C 5 8 Z x V P p J D d Z L o b D p J 5 X D E s Q C c h w T 1 F C g m 9 S r b R s + I G b G M 2 P p a c 9 X 7 N 8 V N R T O L Y u U l A X 4 u b u c a 8 n r c u P K Z 6 8 m t d R l 5 V G L i 0 F Z p b g 3 v P 0 6 n 0 m L w q s l A R B W 0 q 5 c z M G C 8 G R Q v z 8 Y 8 D / N u C M p O b Q 2 P L W w Q N + s L 6 R y Q 7 3 m x T 9 o K S g x w y w Z o Q j j O m n X T r M 6 j J u O P 7 m G f 4 t k q 8 X 3 x H 0 o 0 Y I 3 9 n m d g M 0 L q R u y O U 9 e t O h / Q j j 9 L S R E F 4 4 v 3 / M q G O 3 u x I Q / 7 o X 7 e 9 2 t N 9 k T 9 p Q 9 Y z F 7 y f b Z A T t k Q y a Y Z N / Z G T s P 3 g V f g t P g 6 4 U 0 6 H U 1 j 9 l a B N 9 + A Y U i 4 R 0 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 2 4 a + V d 2 W Z 2 E A r E r H J N 8 R V 3 w Z r g g = " &gt; A A A C y X i c f V F d a 9 R A F J 1 N / a j r V 6 u P v g y G B R E p S S n o Y 0 U f C i J W c L e F z b r c z N 5 k h 5 3 M x J l J 6 R r y 5 A / w t f 0 T / h / / j T f b i G 5 b v T B w O P f c j z k 3 L Z V 0 P o p + 9 o K N G z d v 3 d 6 8 0 7 9 7 7 / 6 D h 1 v b j 0 b O V F b g U B h l 7 H E K D p X U O P T S K z w u L U K R K j x K F 2 / a / N E J W i e N / u S X J U 4 K y L X M p A B P 1 D D / / H q 6 O 9 0 K o 5 1 o F f w q i D s Q s i 4 O p 9 u 9 H 8 n M i K p A 7 Y U C 5 8 Z x V P p J D d Z L o b D p J 5 X D E s Q C c h w T 1 F C g m 9 S r b R s + I G b G M 2 P p a c 9 X 7 N 8 V N R T O L Y u U l A X 4 u b u c a 8 n r c u P K Z 6 8 m t d R l 5 V G L i 0 F Z p b g 3 v P 0 6 n 0 m L w q s l A R B W 0 q 5 c z M G C 8 G R Q v z 8 Y 8 D / N u C M p O b Q 2 P L W w Q N + s L 6 R y Q 7 3 m x T 9 o K S g x w y w Z o Q j j O m n X T r M 6 j J u O P 7 m G f 4 t k q 8 X 3 x H 0 o 0 Y I 3 9 n m d g M 0 L q R u y O U 9 e t O h / Q j j 9 L S R E F 4 4 v 3 / M q G O 3 u x I Q / 7 o X 7 e 9 2 t N 9 k T 9 p Q 9 Y z F 7 y f b Z A T t k Q y a Y Z N / Z G T s P 3 g V f g t P g 6 4 U 0 6 H U 1 j 9 l a B N 9 + A Y U i 4 R 0 = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 2 4 a + V d 2 W Z 2 E A r E r H J N 8 R V 3 w Z r g g = " &gt; A A A C y X i c f V F d a 9 R A F J 1 N / a j r V 6 u P v g y G B R E p S S n o Y 0 U f C i J W c L e F z b r c z N 5 k h 5 3 M x J l J 6 R r y 5 A / w t f 0 T / h / / j T f b i G 5 b v T B w O P f c j z k 3 L Z V 0 P o p + 9 o K N G z d v 3 d 6 8 0 7 9 7 7 / 6 D h 1 v b j 0 b O V F b g U B h l 7 H E K D p X U O P T S K z w u L U K R K j x K F 2 / a / N E J W i e N / u S X J U 4 K y L X M p A B P 1 D D / / H q 6 O 9 0 K o 5 1 o F f w q i D s Q s i 4 O p 9 u 9 H 8 n M i K p A 7 Y U C 5 8 Z x V P p J D d Z L o b D p J 5 X D E s Q C c h w T 1 F C g m 9 S r b R s + I G b G M 2 P p a c 9 X 7 N 8 V N R T O L Y u U l A X 4 u b u c a 8 n r c u P K Z 6 8 m t d R l 5 V G L i 0 F Z p b g 3 v P 0 6 n 0 m L w q s l A R B W 0 q 5 c z M G C 8 G R Q v z 8 Y 8 D / N u C M p O b Q 2 P L W w Q N + s L 6 R y Q 7 3 m x T 9 o K S g x w y w Z o Q j j O m n X T r M 6 j J u O P 7 m G f 4 t k q 8 X 3 x H 0 o 0 Y I 3 9 n m d g M 0 L q R u y O U 9 e t O h / Q j j 9 L S R E F 4 4 v 3 / M q G O 3 u x I Q / 7 o X 7 e 9 2 t N 9 k T 9 p Q 9 Y z F 7 y f b Z A T t k Q y a Y Z N / Z G T s P 3 g V f g t P g 6 4 U 0 6 H U 1 j 9 l a B N 9 + A Y U i 4 R 0 = &lt; / l a t e x i t &gt; g A L &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " j 9 P q w 7 v 5 A g J c G w A B X q 6 D g 4 t / M B Y = " &gt; A A A C y X i c f V F d a 9 R A F J 2 N X 3 X 9 a u u j L 4 N h Q U R K I g V 9 r N i H g o o V 3 G 1 h s y 4 3 s z f Z Y S c z c W Z S u o Y 8 9 Q f 4 q n / C / + O / 8 W Y b 0 W 2 r F w Y O 5 5 7 7 M e e m p Z L O R 9 H P X n D t + o 2 b t z Z u 9 + / c v X f / w e b W 9 s i Z y g o c C q O M P U 7 B o Z I a h 1 5 6 h c e l R S h S h U f p 4 n W b P z p B 6 6 T R H / 2 y</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>e 4 N b 7 / O Z 9 K i 8 G p J A I S V t C s X c 7 A g P B n U 7 w 8 G / E 8 z 7 k h K D q 0 N T y 0 s 0 D f r C 6 n c U K 9 5 8 Q 9 a C k r M M E t G K M K 4 T t q 1 0 6 w O 4 6 b j T 6 7 g 9 5 F s t f i O u P c l W v D G P q 0 T s H k h d U M 2 5 8 m z F v 1 P C K e / h Y T o w v H F e 1 4 G o + c 7 M e E P u + H e b n f r D f a I P W Z P W M x e s D 1 2 w A 7 Z k A k m 2 V f 2 j X 0 P 3 g S f g 9 P g y 7 k 0 6 H U 1 D 9 l a B G e / A M L 8 4 T c = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " j 9 P q w 7 v 5 A g J c G w A B X q 6 D g 4 t / M B Y = " &gt; A A A C y X i c f V F d a 9 R A F J 2 N X 3 X 9 a u u j L 4 N h Q U R K I g V 9 r N i H g o o V 3 G 1 h s y 4 3 s z f Z Y S c z c W Z S u o Y 8 9 Q f 4 q n / C / + O / 8 W Y b 0 W 2 r F w Y O 5 5 7 7 M e e m p Z L O R 9 H P X n D t + o 2 b t z Z u 9 + / c v X f / w e b W 9 s i Z y g o c C q O M P U 7 B o Z I a h 1 5 6 h c e l R S h S h U f p 4 n W b P z p B 6 6 T R H / 2 y</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>e 4 N b 7 / O Z 9 K i 8 G p J A I S V t C s X c 7 A g P B n U 7 w 8 G / E 8 z 7 k h K D q 0 N T y 0 s 0 D f r C 6 n c U K 9 5 8 Q 9 a C k r M M E t G K M K 4 T t q 1 0 6 w O 4 6 b j T 6 7 g 9 5 F s t f i O u P c l W v D G P q 0 T s H k h d U M 2 5 8 m z F v 1 P C K e / h Y T o w v H F e 1 4 G o + c 7 M e E P u + H e b n f r D f a I P W Z P W M x e s D 1 2 w A 7 Z k A k m 2 V f 2 j X 0 P 3 g S f g 9 P g y 7 k 0 6 H U 1 D 9 l a B G e / A M L 8 4 T c = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " j 9 P q w 7 v 5 A g J c G w A B X q 6 D g 4 t / M B Y = " &gt; A A A C y X i c f V F d a 9 R A F J 2 N X 3 X 9 a u u j L 4 N h Q U R K I g V 9 r N i H g o o V 3 G 1 h s y 4 3 s z f Z Y S c z c W Z S u o Y 8 9 Q f 4 q n / C / + O / 8 W Y b 0 W 2 r F w Y O 5 5 7 7 M e e m p Z L O R 9 H P X n D t + o 2 b t z Z u 9 + / c v X f / w e b W 9 s i Z y g o c C q O M P U 7 B o Z I a h 1 5 6 h c e l R S h S h U f p 4 n W b P z p B 6 6 T R H / 2 y</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>e 4 N b 7 / O Z 9 K i 8 G p J A I S V t C s X c 7 A g P B n U 7 w 8 G / E 8 z 7 k h K D q 0 N T y 0 s 0 D f r C 6 n c U K 9 5 8 Q 9 a C k r M M E t G K M K 4 T t q 1 0 6 w O 4 6 b j T 6 7 g 9 5 F s t f i O u P c l W v D G P q 0 T s H k h d U M 2 5 8 m z F v 1 P C K e / h Y T o w v H F e 1 4 G o + c 7 M e E P u + H e b n f r D f a I P W Z P W M x e s D 1 2 w A 7 Z k A k m 2 V f 2 j X 0 P 3 g S f g 9 P g y 7 k 0 6 H U 1 D 9 l a B G e / A M L 8 4 T c = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " j 9 P q w 7 v 5 A g J c G w A B X q 6 D g 4 t / M B Y = " &gt; A A A C y X i c f V F d a 9 R A F J 2 N X 3 X 9 a u u j L 4 N h Q U R K I g V 9 r N i H g o o V 3 G 1 h s y 4 3 s z f Z Y S c z c W Z S u o Y 8 9 Q f 4 q n / C / + O / 8 W Y b 0 W 2 r F w Y O 5 5 7 7 M e e m p Z L O R 9 H P X n D t + o 2 b t z Z u 9 + / c v X f / w e b W 9 s i Z y g o c C q O M P U 7 B o Z I a h 1 5 6 h c e l R S h S h U f p 4 n W b P z p B 6 6 T R H / 2 y</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>1 &lt; 2 &lt; 0 L</head><label>120</label><figDesc>e 4 N b 7 / O Z 9 K i 8 G p J A I S V t C s X c 7 A g P B n U 7 w 8 G / E 8 z 7 k h K D q 0 N T y 0 s 0 D f r C 6 n c U K 9 5 8 Q 9 a C k r M M E t G K M K 4 T t q 1 0 6 w O 4 6 b j T 6 7 g 9 5 F s t f i O u P c l W v D G P q 0 T s H k h d U M 2 5 8 m z F v 1 P C K e / h Y T o w v H F e 1 4 G o + c 7 M e E P u + H e b n f r D f a I P W Z P W M x e s D 1 2 w A 7 Z k A k m 2 V f 2 j X 0 P 3 g S f g 9 P g y 7 k 0 6 H U 1 D 9 l a B G e / A M L 8 4 T c = &lt; / l a t e x i t &gt; x 0 l a t e x i t s h a 1 _ b a s e 6 4 = " T t X l H j W h 4 4 H H d R l m L 0 1 C T B 5 O w 4 4 = " &gt; A A A C 5 X i c h V J N T 9 R Q F D 3 U D x A / G H B j w o Y 4 Q V 1 N b g k J x h U J G 5 Z 8 D R C B T N r H m / G F T t u 0 b x q g m T 9 g w o 7 o w i j B x I X x Z 7 D h D 7 h g 7 c q 4 x M S N C 8 9 0 a o w S 8 D V 9 9 9 5 z 7 7 n v 3 L 7 6 c W B S K 3 I 2 4 F y 7 f u P m 4 N C t 4 d t 3 7 t 4 b q Y y O r a Z R J 1 G 6 r q I g S t Z 9 L 9 W B C X X d G h v o 9 T j R X t s P 9 J q / M 9 f L r 2 U 6 S U 0 U r t i 9 W G + 1 v V Z o m k Z 5 l t D z z U y r f L f 7 u O E 2 K l W p S b E m L j p u 6 V R R r o W o 8 g W b 2 E Y E h Q 7 a 0 A h h 6 Q f w k P L Z g A t B T G w L O b G E n i n y G l 0 M k 9 t h l W a F R 3 S H e 4 v R R o m G j H s 9 0 4 K t e E r A N y F z A p P y W T 7 K u Z z K J / k q P y / t l R c 9 e l r 2 a P 0 + V 8 e N k Z c P l n / 8 l 9 W m t X j x h 3 W l Z o s m n h Z a D b X H B d K b Q v X 5 2 f 7 r 8 + V n S 5 P 5 I 3 k v 3 6 j / W M 7 k h B O E 2 X f 1 Y V E v v b l C j 0 8 t l 3 + x n J h h J u R u s V t W b j P T p M 1 o F a q 8 i 5 z R 7 5 l 8 5 v I C 7 a L L i 3 f / v e a L z u p U z Z W a u z h d n Z 0 u f 4 E h j O M h n r D L D G Y x j w X U e V a I Q 7 z F O 6 f l H D i H z q t + q T N Q c u 7 j r + U c / Q K p y 6 Z + &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " T t X l H j W h 4 4 H H d R l m L 0 1 C T B 5 O w 4 4 = " &gt; A A A C 5 X i c h V J N T 9 R Q F D 3 U D x A / G H B j w o Y 4 Q V 1 N b g k J x h U J G 5 Z 8 D R C B T N r H m / G F T t u 0 b x q g m T 9 g w o 7 o w i j B x I X x Z 7 D h D 7 h g 7 c q 4 x M S N C 8 9 0 a o w S 8 D V 9 9 9 5 z 7 7 n v 3 L 7 6 c W B S K 3 I 2 4 F y 7 f u P m 4 N C t 4 d t 3 7 t 4 b q Y y O r a Z R J 1 G 6 r q I g S t Z 9 L 9 W B C X X d G h v o 9 T j R X t s P 9 J q / M 9 f L r 2 U 6 S U 0 U r t i 9 W G + 1 v V Z o m k Z 5 l t D z z U y r f L f 7 u O E 2 K l W p S b E m L j p u 6 V R R r o W o 8 g W b 2 E Y E h Q 7 a 0 A h h 6 Q f w k P L Z g A t B T G w L O b G E n i n y G l 0 M k 9 t h l W a F R 3 S H e 4 v R R o m G j H s 9 0 4 K t e E r A N y F z A p P y W T 7 K u Z z K J / k q P y / t l R c 9 e l r 2 a P 0 + V 8 e N k Z c P l n / 8 l 9 W m t X j x h 3 W l Z o s m n h Z a D b X H B d K b Q v X 5 2 f 7 r 8 + V n S 5 P 5 I 3 k v 3 6 j / W M 7 k h B O E 2 X f 1 Y V E v v b l C j 0 8 t l 3 + x n J h h J u R u s V t W b j P T p M 1 o F a q 8 i 5 z R 7 5 l 8 5 v I C 7 a L L i 3 f / v e a L z u p U z Z W a u z h d n Z 0 u f 4 E h j O M h n r D L D G Y x j w X U e V a I Q 7 z F O 6 f l H D i H z q t + q T N Q c u 7 j r + U c / Q K p y 6 Z + &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " T t X l H j W h 4 4 H H d R l m L 0 1 C T B 5 O w 4 4 = " &gt; A A A C 5 X i c h V J N T 9 R Q F D 3 U D x A / G H B j w o Y 4 Q V 1 N b g k J x h U J G 5 Z 8 D R C B T N r H m / G F T t u 0 b x q g m T 9 g w o 7 o w i j B x I X x Z 7 D h D 7 h g 7 c q 4 x M S N C 8 9 0 a o w S 8 D V 9 9 9 5 z 7 7 n v 3 L 7 6 c W B S K 3 I 2 4 F y 7 f u P m 4 N C t 4 d t 3 7 t 4 b q Y y O r a Z R J 1 G 6 r q I g S t Z 9 L 9 W B C X X d G h v o 9 T j R X t s P 9 J q / M 9 f L r 2 U 6 S U 0 U r t i 9 W G + 1 v V Z o m k Z 5 l t D z z U y r f L f 7 u O E 2 K l W p S b E m L j p u 6 V R R r o W o 8 g W b 2 E Y E h Q 7 a 0 A h h 6 Q f w k P L Z g A t B T G w L O b G E n i n y G l 0 M k 9 t h l W a F R 3 S H e 4 v R R o m G j H s 9 0 4 K t e E r A N y F z A p P y W T 7 K u Z z K J / k q P y / t l R c 9 e l r 2 a P 0 + V 8 e N k Z c P l n / 8 l 9 W m t X j x h 3 W l Z o s m n h Z a D b X H B d K b Q v X 5 2 f 7 r 8 + V n S 5 P 5 I 3 k v 3 6 j / W M 7 k h B O E 2 X f 1 Y V E v v b l C j 0 8 t l 3 + x n J h h J u R u s V t W b j P T p M 1 o F a q 8 i 5 z R 7 5 l 8 5 v I C 7 a L L i 3 f / v e a L z u p U z Z W a u z h d n Z 0 u f 4 E h j O M h n r D L D G Y x j w X U e V a I Q 7 z F O 6 f l H D i H z q t + q T N Q c u 7 j r + U c / Q K p y 6 Z + &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " T t X l H j W h 4 4 H H d R l m L 0 1 C T B 5 O w 4 4 = " &gt; A A A C 5 X i c h V J N T 9 R Q F D 3 U D x A / G H B j w o Y 4 Q V 1 N b g k J x h U J G 5 Z 8 D R C B T N r H m / G F T t u 0 b x q g m T 9 g w o 7 o w i j B x I X x Z 7 D h D 7 h g 7 c q 4 x M S N C 8 9 0 a o w S 8 D V 9 9 9 5 z 7 7 n v 3 L 7 6 c W B S K 3 I 2 4 F y 7 f u P m 4 N C t 4 d t 3 7 t 4 b q Y y O r a Z R J 1 G 6 r q I g S t Z 9 L 9 W B C X X d G h v o 9 T j R X t s P 9 J q / M 9 f L r 2 U 6 S U 0 U r t i 9 WG + 1 v V Z o m k Z 5 l t D z z U y r f L f 7 u O E 2 K l W p S b E m L j p u 6 V R R r o W o 8 g W b 2 E Y E h Q 7 a 0 A h h 6 Q f w k P L Z g A t B T G w L O b G E n i n y G l 0 M k 9 t h l W a F R3 S H e 4 v R R o m G j H s 9 0 4 K t e E r A N y F z A p P y W T 7 K u Z z K J / k q P y / t l R c 9 e l r 2 a P 0 + V 8 e N k Z c P l n / 8 l 9 W m t X j x h 3 W l Z o s m n h Z a D b X H B d K b Q v X 5 2 f 7 r 8 + V n S 5 P 5 I 3 k v 3 6 j / W M 7 k h B O E 2 X f 1 Y V E v v b l C j 0 8 t l 3 + x n J h h J u R u s V t W b j P T p M 1 o F a q 8 i 5 z R 7 5 l 8 5 v I C 7 a L L i 3 f / v e a L z u p U z Z W a u z h d n Z 0 u f 4 E h j O M h n r D L D G Y x j w X U e V a I Q 7 z F O 6 f l H D i H z q t + q T N Q c u 7 j r + U c / Q K p y 6 Z + &lt; / l a t e x i t &gt; x 0 l a t e x i t s h a 1 _ b a s e 6 4 = " D D 4 j / X h n R T 1 o A O u k b X e Y p 1 r l+ 8 k = " &gt; A A A C 5 X i c h V J N T 9 R Q F D 1 U V M Q P B t m Y u C F O U F e T W 0 I i Y U X i h i U f D h A + M m k f b 8 Y X O m 3 T v m m A Z v 6 A C T s C C 6 J G E x f G n + H G P 8 C C t S v j E h I 3 L j z T q T F K w N f 0 3 X v P v e e + c / v q x 4 F J r c j p g H N t 8 P q N m 0 O 3 h m / f u X t v p D J 6 f z m N O o n S d R U F U b L q e 6 k O T K j r 1 t h A r 8 a J 9 t p + o F f 8 7 e e 9 / E q m k 9 R E 4 Q u 7 G + v N t t c K T d M o z x J a 2 8 i 0 y n e 6 T x q T j U p V a l K s 8 Y u O W z p V l G s + q n z F B r Y Q Q a G D N j R C W P o B P K R 8 1 u F C E B P b R E 4 s o W e K v E Y X w + R 2 W K V Z 4 R H d5 t 5 i t F 6 i I e N e z 7 R g K 5 4 S 8 E 3 I H M e E n M h H O Z M v 8 k m + y c 9 L e + V F j 5 6 W X V q / z 9 V x Y + T V g 6 U f / 2 W 1 a S 1 e / m F d q d m i i e l C q 6 H 2 u E B 6 U 6 g + P 9 s 7 O l u a W Z z I H 8 t 7 + U 7 9 7 + R U P n O C M D t X H x b 0 4 v E V e n x q u f y L 5 c Q M M y F 3 i 5 2 y c o u Z J m 1 G q 1 D l X e S M f s / k M 5 c X a B d d X r z 7 7 z V f d J Y n a 6 7 U 3 I W p 6 u x U + Q s M 4 S E e 4 S m 7 P M M s 5 j C P O s 8 K c Y D X e O O 0 n H 3 n w D n s l z o D J W c M f y 3 n 7 S + s Q 6 Z / &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " D D 4 j / X h n R T 1 o A O u k b X e Y p 1 r l + 8k = " &gt; A A A C 5 X i c h V J N T 9 R Q F D 1 U V M Q P B t m Y u C F O U F e T W 0 I i Y U X i h i U f D h A + M m k f b 8 Y X O m 3 T v m m A Z v 6 A C T s C C 6 J G E x f G n + H G P 8 C C t S v j E h I 3 L j z T q T F K w N f 0 3 X v P ve e + c / v q x 4 F J r c j p g H N t 8 P q N m 0 O 3 h m / f u X t v p D J 6 f z m N O o n S d R U F U b L q e 6 k O T K j r 1 t h A r 8 a J 9 t p + o F f 8 7 e e 9 / E q m k 9 R E 4 Q u 7 G + v N t t c K T d M o z x J a 2 8 i 0 y n e 6 T x q T j U p V a l K s 8 Y u O W z p V l G s + q n z F B r Y Q Q a G D N j R C W P o B P K R 8 1 u F C E B P b R E 4 s o W e K v E Y X w + R 2 W K V Z 4 R H d 5 t 5 i t F 6 i I e N e z 7 R g K 5 4 S 8 E 3 I H M e E n M h H O Z M v 8 k m + y c 9 L e + V F j 5 6 W X V q / z 9 V x Y + T V g 6 U f / 2 W 1 a S 1 e / m F d q d m i i e l C q 6 H 2 u E B 6 U 6 g + P 9 s 7 O l u a W Z z I H 8 t 7 + U 7 9 7 + R U P n O C M D t X H x b 0 4 v E V e n x q u f y L 5 c Q M M y F 3 i 5 2 y c o u Z J m 1 G q 1 D l X e S M f s / k M 5 c X a B d d X r z 7 7 z V f d J Y n a 6 7 U 3 I W p 6 u x U + Q s M 4 S E e 4 S m 7 P M M s 5 j C P O s 8 K c Y D X e O O 0 n H 3 n w D n s l z o D J W c M f y 3 n 7 S + s Q 6 Z / &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " D D 4 j / X h n R T 1 o A O u k b X e Y p 1 r l + 8 k = " &gt; A A A C 5 X i c h V J N T 9 R Q F D 1 U V M Q P B t m Y u C F O U F e T W 0 I i Y U X i h i U f D h A + M m k f b 8 Y X O m 3 T v m m A Z v 6 A C T s C C 6 J G E x f G n + H G P 8 C C t S v j E h I 3 L j z T q T F K w N f 0 3 X v P v e e + c / v q x 4 F J r c j p g H N t 8 P q N m 0 O 3 h m / f u X t v p D J 6 f z m N O o n S d R U F U b L q e 6 k O T K j r 1 t h A r 8 a J 9 t p + o F f 8 7 e e 9 / E q m k 9 R E 4 Q u 7 G + v N t t c K T d M o z x J a 2 8 i 0 y n e 6 T x q T j U p V a l K s 8 Y u O W z p V l G s + q n z F B r Y Q Q a G D N j R C W P o B P K R 8 1 u F C E B P b R E 4 s o W e K v E Y X w + R 2 W K V Z 4 R H d 5 t 5 i t F 6 i I e N e z 7 R g K 5 4 S 8 E 3 I H M e E n M h H O Z M v 8 k m + y c 9 L e + V F j 5 6 W X V q / z 9 V x Y + T V g 6 U f / 2 W 1 a S 1 e / m F d q d m i i e l C q 6 H 2 u E B 6 U 6 g + P 9 s 7 O l u a W Z z I H 8 t 7 + U 7 9 7 + R U P n O C M D t X H x b 0 4 v E V e n x q u f y L 5 c Q M M y F 3 i 5 2 y c o u Z J m 1 G q 1 D l X e S M f s / k M 5 c X a B d d X r z 7 7 z V f d J Y n a 6 7 U 3 I W p 6 u x U + Q s M 4 S E e 4 S m 7 P M M s 5 j C P O s 8 K c Y D X e O O 0 n H 3 n w D n s l z o D J W c M f y 3 n 7 S + s Q 6 Z / &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " D D 4 j / X h n R T 1 o A O u k b X e Y p 1 r l + 8 k = " &gt; A A A C 5 X i c h V J N T 9 R Q F D 1 U V M Q P B t m Y u C F O U F e T W 0 I i Y U X i h i U f D h A + M m k f b 8 Y X O m 3 T v m m A Z v 6 A C T s C C 6 J G E x f G n + H G P 8 C C t S v j E h I 3 L j z T q T F K w N f 0 3 X v P v e e + c / v q x 4 F J r c j p g H N t 8 P q N m 0 O 3 h m / f u X t v p D J 6 f z m N O o n S d R U F U b L q e 6 k O T K j r 1 t h A r 8 a J 9 t p + o F f 8 7 e e 9 / E q m k 9 R E 4 Q u 7 G + v N t t c K T d M o z x J a 2 8 i 0 y n e 6 T x q T j U p V a l K s 8 Y u O W z p V l G s + q n z F B r Y Q Q a G D N j R C W P o B P K R 8 1 u F C E B P b R E 4 s o W e K v E Y X w + R 2 W K V Z 4 R H d 5 t 5 i t F 6 i I e N e z 7 R g K 5 4 S 8 E 3 I H M e E n M h H O Z M v 8 k m + y c 9 L e + V F j 5 6 W X V q / z 9 V x Y + T V g 6 U f / 2 W 1 a S 1 e / m F d q d m i i e l C q 6 H 2 u E B 6 U 6 g + P 9 s 7 O l u a W Z z I H 8 t 7 + U 7 9 7 + R U P n O C M D t X H x b 0 4 v E V e n x q u f y L 5 c Q M M y F 3 i 5 2 y c o u Z J m 1 G q 1 D l X e S M f s / k M 5 c X a B d d X r z 7 7 z V f d J Y n a 6 7 U 3 I W p 6 u x U + Q s M 4 S E e 4 S m 7 P M M s 5 j C P O s 8 K c Y D X e O O 0 n H 3 n w D n s l z o D J W c M f y 3 n 7 S + s Q 6 Z / &lt; / l a t e x i t &gt; x &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " y K B o Z u z W g 7 J a Z C w R v x U r r O j 4 h E I = " &gt; A A A C 5 X i c h V J N T 9 R Q F D 1 U F M Q P B t m Q u C F O U F e T W 0 M i Y U X i x g U L v g a I Q C b t 4 8 3 4 Q q d t 2 j c N 2 M w f M G F H c G H Q a O L C 8 D P Y + A d c s H Z l X G L i x o V n O j V G C f i a v n v v u f f c d 2 5 f / T g w q R U 5 H X C u D F 6 9 N j R 8 f e T G z V u 3 R y t j d 1 b T q J M o X V d R E C X r v p f q w I S 6 b o 0 N 9 H q c a K / t B 3 r N 3 3 n S y 6 9 l O k l N F K 7 Y v V h v t b 1 W a J p G e Z b Q s 8 1 M q 3 y 3 + 6 A x 3 6 h U p S b F m j z v u K V T R b k W o s o X b G I b E R Q 6 a E M j h K U f w E P K Z w M u B D G x L e T E E n q m y G t 0 M U J u h 1 W a F R 7 R H e 4 t R h s l G j L u 9 U w L t u I p A d + E z E l M y W f 5 K G f y S Y 7 l q / y 8 s F d e 9 O h p 2 a P 1 + 1 w d N 0 Z f T i z / + C + r T W v x / A / r U s 0 W T c w U W g 2 1 x w X S m 0 L 1 + d m L V 2 f L s 0 t T + X 1 5 L 9 + o / 5 2 c y g k n C L P v 6 s O i X n p 9 i R 6 f W i 7 + Y j k x w 0 z I 3 W K 3 r N x m p k m b 0 S p U e R c 5 o 9 8 z + c z l B d p F l x f v / n v N 5 5 3 V R z V X a u 7 i d H V u u v w F h n E X 9 / C Q X R 5 j D k + x g D r P C n G A I 7 x x W s 6 + c + A c 9 k u d g Z I z j r + W 8 / Y X 7 H O m m Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " y K B o Z u z W g 7 J a Z C w R v x U r r O j 4 h E I = " &gt; A A A C 5 X i c h V J N T 9 R Q F D 1 U F M Q P B t m Q u C F O U F e T W 0 M i Y U X i x g U L v g a I Q C b t 4 8 3 4 Q q d t 2 j c N 2 M w f M G F H c G H Q a O L C 8 D P Y + A d c s H Z l X G L i x o V n O j V G C f i a v n v v u f f c d 2 5 f / T g w q R U 5 H X C u D F 6 9 N j R 8 f e T G z V u 3 R y t j d 1 b T q J M o X V d R E C X r v p f q w I S 6 b o 0 N 9 H q c a K / t B 3 r N 3 3 n S y 6 9 l O k l N F K 7 Y v V h v t b 1 W a J p G e Z b Q s 8 1 M q 3 y 3 + 6 A x 3 6 h U p S b F m j z v u K V T R b k W o s o X b G I b E R Q 6 a E M j h K U f w E P K Z w M u B D G x L e T E E n q m y G t 0 M U J u h 1 W a F R 7 R H e 4 t R h s l G j L u 9 U w L t u I p A d + E z E l M y W f 5 K G f y S Y 7 l q / y 8 s F d e 9 O h p 2 a P 1 + 1 w d N 0 Z f T i z / + C + r T W v x / A / r U s 0 W T c w U W g 2 1 x w X S m 0 L 1 + d m L V 2 f L s 0 t T + X 1 5 L 9 + o / 5 2 c y g k n C L P v 6 s O i X n p 9 i R 6 f W i 7 + Y j k x w 0 z I 3 W K 3 r N x m p k m b 0 S p U e R c 5 o 9 8 z + c z l B d p F l x f v / n v N 5 5 3 V R z V X a u 7 i d H V u u v w F h n E X 9 / C Q X R 5 j D k + x g D r P C n G A I 7 x x W s 6 + c + A c 9 k u d g Z I z j r + W 8 / Y X 7 H O m m Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " y K B o Z u z W g 7 J a Z C w R v x U r r O j 4 h E I = " &gt; A A A C 5 X i c h V J N T 9 R Q F D 1 U F M Q P B t m Q u C F O U F e T W 0 M i Y U X i x g U L v g a I Q C b t 4 8 3 4 Q q d t 2 j c N 2 M w f M G F H c G H Q a O L C 8 D P Y + A d c s H Z l X G L i x o V n O j V G C f i a v n v v u f f c d 2 5 f / T g w q R U 5 H X C u D F 6 9 N j R 8 f e T G z V u 3 R y t j d 1 b T q J M o X V d R E C X r v p f q w I S 6 b o 0 N 9 H q c a K / t B 3 r N 3 3 n S y 6 9 l O k l N F K 7 Y v V h v t b 1 W a J p G e Z b Q s 8 1 M q 3 y 3 + 6 A x 3 6 h U p S b F m j z v u K V T R b k W o s o X b G I b E R Q 6 a E M j h K U f w E P K Z w M u B D G x L e T E E n q m y G t 0 M U J u h 1 W a F R 7 R H e 4 t R h s l G j L u 9 U w L t u I p A d + E z E l M y W f 5 K G f y S Y 7 l q / y 8 s F d e 9 O h p 2 a P 1 + 1 w d N 0 Z f T i z / + C + r T W v x / A / r U s 0 W T c w U W g 2 1 x w X S m 0 L 1 + d m L V 2 f L s 0 t T + X 1 5 L 9 + o / 5 2 c y g k n C L P v 6 s O i X n p 9 i R 6 f W i 7 + Y j k x w 0 z I 3 W K 3 r N x m p k m b 0 S p U e R c 5 o 9 8 z + c z l B d p F l x f v / n v N 5 5 3 V R z V X a u 7 i d H V u u v w F h n E X 9 / C Q X R 5 j D k + x g D r P C n G A I 7 x x W s 6 + c + A c 9 k u d g Z I z j r + W 8 / Y X 7 H O m m Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " y K B o Z u z W g 7 J a Z C w R v x U r r O j 4 h E I = " &gt; A A A C 5 X i c h V J N T 9 R Q F D 1 U F M Q P B t m Q u C F O U F e T W 0 M i Y U X i x g U L v g a I Q C b t 4 8 3 4 Q q d t 2 j c N 2 M w f M G F H c G H Q a O L C 8 D P Y + A d c s H Z l X G L i x o V n O j V G C f i a v n v v u f f c d 2 5 f / T g w q R U 5 H X C u D F 6 9 N j R 8 f e T G z V u 3 R y t j d 1 b T q J M o X V d R E C X r v p f q w I S 6 b o 0 N 9 H q c a K / t B 3 r N 3 3 n S y 6 9 l O k l N F K 7 Y v V h v t b 1 W a J p G e Z b Q s 8 1 M q 3 y 3 + 6 A x 3 6 h U p S b F m j z v u K V T R b k W o s o X b G I b E R Q 6 a E M j h K U f w E P K Z w M u B D G x L e T E E n q m y G t 0 M U J u h 1 W a F R 7 R H e 4 t R h s l G j L u 9 U w L t u I p A d + E z E l M y W f 5 K G f y S Y 7 l q / y 8 s F d e 9 O h p 2 a P 1 + 1 w d N 0 Z f T i z / + C + r T W v x / A / r U s 0 W T c w U W g 2 1 x w X S m 0 L 1 + d m L V 2 f L s 0 t T + X 1 5 L 9 + o / 5 2 c y g k n C L P v 6 s O i X n p 9 i R 6 f W i 7 + Y j k x w 0 z I 3 W K 3 r N x m p k m b 0 S p U e R c 5 o 9 8 z + c z l B d p F l x f v / n v N 5 5 3 V R z V X a u 7 i d H V u u v w F h n E X 9 / C Q X R 5 j D k + x g D r P C n G A I 7 x x W s 6 + c + A c 9 k u d g Z I z j r + W 8 / Y X 7 H O m m Q = = &lt; / l a t e x i t &gt; g 0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " u S u S H w L 6 J t U 7 U 1 2 T k z 2 7 q m v n I D o = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k V 9 F j w 4 r G i / Y A 2 l M 1 2 k y 7 d b M L u R C i h P 8 G L B 0 W 8 + o u 8 + W / c t j l o 6 4 O B x 3 s z z M w L U i k M u u 6 3 s 7 a + s b m 1 X d o p 7 + 7 t H x x W j o 7 b J s k 0 4 y 2 W y E R 3 A 2 q 4 F I q 3 U K D k 3 V R z G g e S d 4 L x 7 c z v P H F t R K I e c Z J y P 6 a R E q F g F K 3 0 E A 3 c Q a X q 1 t w 5 y C r x C l K F A s 1 B 5 a s / T F g W c 4 V M U m N 6 n p u i n 1 O N g k k + L f c z w 1 P K x j T i P U s V j b n x 8 / m p U 3 J u l S E J E 2 1 L I Z m r v y d y G h s z i Q P b G V M c m W V v J v 7 n 9 T I M b / x c q D R D r t h i U Z h J g g m Z / U 2 G Q n O G c m I J Z V r Y W w k b U U 0 Z 2 n T K N g R v + e V V 0 q 7 X v M t a / f 6 q 2 q g X c Z T g F M 7 g A j y 4 h g b c Q R N a w C C C Z 3 i F N 0 c 6 L 8 6 7 8 7 F o X X O K m R P 4 A + f z B + y 1 j Y I = &lt; / l a t e x i t &gt; g 0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " u S u S H w L 6 J t U 7 U 1 2 T k z 2 7 q m v n I D o = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k V 9 F j w 4 r G i / Y A 2 l M 1 2 k y 7 d b M L u R C i h P 8 G L B 0 W 8 + o u 8 + W / c t j l o 6 4 O B x 3 s z z M w L U i k M u u 6 3 s 7 a + s b m 1 X d o p 7 + 7 t H x x W j o 7 b J s k 0 4 y 2 W y E R 3 A 2 q 4 F I q 3 U K D k 3 V R z G g e S d 4 L x 7 c z v P H F t R K I e c Z J y P 6 a R E q F g F K 3 0 E A 3 c Q a X q 1 t w 5 y C r x C l K F A s 1 B 5 a s / T F g W c 4 V M U m N 6 n p u i n 1 O N g k k + L f c z w 1 P K x j T i P U s V j b n x 8 / m p U 3 J u l S E J E 2 1 L I Z m r v y d y G h s z i Q P b G V M c m W V v J v 7 n 9 T I M b / x c q D R D r t h i U Z h J g g m Z / U 2 G Q n O G c m I J Z V r Y W w k b U U 0 Z 2 n T K N g R v + e V V 0 q 7 X v M t a / f 6 q 2 q g X c Z T g F M 7 g A j y 4 h g b c Q R N a w C C C Z 3 i F N 0 c 6 L 8 6 7 8 7 F o X X O K m R P 4 A + f z B + y 1 j Y I = &lt; / l a t e x i t &gt;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>2 &lt; 2 &lt; 1 &lt;</head><label>221</label><figDesc>A s p n j u E P 0 O c P W I 6 Q D g = = &lt; / l a t e x i t &gt; 0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " U y Y 0 l H S J H Y S Y v 3 h b b H R M Q p c 5 v F g = " &gt; A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m q o M e C F 4 8 V 7 A e 0 o W y 2 m 3 b p Z h N 2 J 0 I J + R F e P C j i 1 d / j z X / j t s 1 B W x 8 M P N 6 b Y W Z e k E h h 0 H W / n d L G 5 t b 2 T n m 3 s r d / c H h U P T 7 p m D j V j L d Z L G P d C 6 j h U i j e R o G S 9 x L N a R R I 3 g 2 m d 3 O / + 8 S 1 E b F 6 x F n C / Y i O l Q g F o 2 i l b j Y I Q u L m w 2 r N r b s L k H X i F a Q G B V r D 6 t d g F L M 0 4 g q Z p M b 0 P T d B P 6 M a B Z M 8 r w x S w x P K p n TM + 5 Y q G n H j Z 4 t z c 3 J h l R E J Y 2 1 L I V m o v y c y G h k z i w L b G V G c m F V v L v 7 n 9 V M M b / 1 M q C R F r t h y U Z h K g j G Z / 0 5 G Q n O G c m Y J Z V r Y W w m b U E 0 Z 2 o Q q N g R v 9 e V 1 0 m n U v a t 6 4 + G 6 1 m w U c Z T h D M 7 h E j y 4 g S b c Q w v a w G A K z / A K b 0 7 i v D j v zs e y t e Q U M 6 f w B 8 7 n D 7 4 R j y A = &lt; / l a t e x i t &gt; z l a t e x i t s h a 1 _ b a s e 6 4 = " 1 e X i A e K U m j K o r 7 a n i n w 6 v J T Y Y u s = " &gt; A A A B 8 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m i o M e C F 4 8 V 7 I e 0 o W y 2 m 3 b p 7 i b s b o Q a + i u 8 e F D E q z / H m / / G T Z u D t j 4 Y e L w 3 w 8 y 8 M O F M G 9 f 9 d k p r 6 x u b W + X t y s 7 u 3 v 5 B 9 f C o r e N U E d o i M Y 9 V N 8 S a c i Z p y z D D a T d R F I u Q 0 0 4 4 u c n 9 z i N V m s X y 3 k w T G g g 8 k i x i B B s r P W T 9 M E J P s 4 E / q N b c u j s H W i V e Q W p Q o D m o f v W H M U k F l Y Z w r H X P c x M T Z F g Z R j i d V f q p p g k m E z y i P U s l F l Q H 2 f z g G T q z y h B F s b I l D Z q r v y c y L L S e i t B 2 C m z G e t n L x f + 8 X m q i 6 yB j M k k N l W S x K E o 5 M j H K v 0 d D p i g x f G o J J o r Z W x E Z Y 4 W J s R l V b A j e 8 s u r p O 3 X v Y u 6 f 3 d Z a / h F H G U 4 g V M 4 B w + u o A G 3 0 I Q W E B D w D K / w 5 i j n x X l 3 P h a t J a e Y O Y Y / c D 5 / A F o S k A 8 = &lt; / l a t e x i t &gt;h l a t e x i t s h a 1 _ b a s e 6 4 = " E S L Y v E d S D z M I N L j g J g u V N N 7 0 0 W s = " &gt; A A A B 8 H i c b V B N S w M x E J 3 4 W e t X 1 a O X Y B E 8 l d 1 V 0 G P B i 8 c K 9 k P a p W T T b B u a Z J c k K 5 S l v 8 K L B 0 W 8 + n O 8 + W 9 M 2 z 1 o 6 4 O B x 3 s z z M y L U s G N 9 b x v t L a + s b m 1 X d o p 7 + 7 t H x x W j o 5 b J s k 0 Z U 2 a i E R 3 I m K Y 4 I o 1 L b e C d V L N i I w E a 0 f j 2 5 n f f m L a 8 E Q 9 2 E n K Q k m G i s e c E u u k x 7 w X x X g 0 7 Q f 9 S t W r e X P g V e I X p A o F G v 3 K V 2 + Q 0 E w y Z a k g x n R 9 L 7 V h T r T l V L B p u Z c Z l h I 6 J k P W d V Q R y U y Y z w + e 4 n O n D H C c a F f K 4 r n 6 e y I n 0 p i J j F y n J H Z k l r 2 Z + J / X z W x 8 E + Z c p Z l l i i 4 W x Z n A N s G z 7 / G A a 0 a t m D h C q O b u V k x H R B N q X U Z l F 4 K / / P I q a Q U 1 / 7 I W 3 F 9 V 6 0 E R R w l O 4 Q w u w I d r q M M d N K A J F C Q 8 w y u 8 I Y 1 e 0 D v 6 W L S u o W L m B P 4 A f f 4 A P p S P / Q = = &lt; / l a t e x i t &gt; 0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " U y Y 0 l H S J H Y S Y v 3 h b b H R M Q p c 5 v F g = " &gt; A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m q o M e C F 4 8 V 7 A e 0 o W y 2 m 3 b p Z h N 2 J 0 I J + R F e P C j i 1 d / j z X / j t s 1 B W x 8 M P N 6 b Y W Z e k E h h 0 H W / n d L G 5 t b 2 T n m 3 s r d / c H h U P T 7 p m D j V j L d Z L G P d C 6 j h U i j e R o G S 9 x L N a R R I 3 g 2 m d 3 O / + 8 S 1 E b F 6 x F n C / Y i O l Q g F o 2 i l b j Y I Q u L m w 2 r N r b s L k H X i F a Q G B V r D 6 t d g F L M 0 4 g q Z p M b 0 P T d B P 6 M a B Z M 8 r w x S w x P K p n T M + 5 Y q G n H j Z 4 t z c 3 J h l R E J Y 2 1 L I V m o v y c y G h k z i w L b G V G c m F V v L v 7 n 9 V M M b / 1 M q C R F r t h y U Z h K g j G Z / 0 5 G Q n O G c m Y J Z V r Y W w m b U E 0 Z 2 o Q q N g R v 9 e V 1 0 m n U v a t 6 4 + G 6 1 m w U c Z T h D M 7 h E j y 4 g S b c Q w v a w G A K z / A K b 0 7 i v D j v z s e y t e Q U M 6 f w B 8 7 n D 7 4 R j y A = &lt; / l a t e x i t &gt; z T &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " c O r B i 5 w O I / 9 A L e 7 C c n V Q d 2 q G x 7 o = " &gt; A A A B 8 H i c b V B N S w M x E J 3 4 W e t X 1 a O X Y B E 8 l d 0 q 6 L H g x W O F f k m 7 l G y a b U O T 7 J J k h b r 0 V 3 j x o I h X f 4 4 3 / 4 1 p u w d t f T D w e G + G m X l h I r i x n v e N 1 t Y 3 N r e 2 C z v F 3 b 3 9 g 8 P S 0 X H L x K m m r E l j E e t O S A w T X L G m 5 V a w T q I Z k a F g 7 X B 8 O / P b j 0 w b H q u G n S Q s k G S o e M Q p s U 5 6 y H p h h J + m / U a / V P Y q 3 h x 4 l f g 5 K U O O e r / 0 1 R v E N J V M W S q I M V 3 f S 2 y Q E W 0 5 F W x a 7 K W G J Y S O y Z B 1 H V V E M h N k 8 4 O n + N w p A x z F 2 p W y e K 7 + n s i I N G Y i Q 9 c p i R 2 Z Z W 8 m / u d 1 U x v d B B l X S W q Z o o t F U S q w j f H s e z z g m l E r J o 4 Q q r m 7 F d M R 0 Y R a l 1 H R h e A v v 7 x K W t W K f 1 m p 3 l + V a 9 U 8 j g K c w h l c g A / X U I M 7 q E M T K E h 4 h l d 4 Q x q 9 o H f 0 s W h d Q / n M C f w B + v w B j Z q Q M Q = = &lt; / l a t e x i t &gt; h T l a t e x i t s h a 1 _ b a s e 6 4 = " U n M I u u w 4 F 5 C s C + T Y R s / P E k 6 f z q c = " &gt; A A A B 9 H i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C R b B i 2 W 3 C n o s e P F Y o V / Q L i W b Z t v Q J L s m 2 U J Z 9 n d 4 8 a C I V 3 + M N / + N a b s H b X 0 w 8 H h v h p l 5 Q c y Z N q 7 7 7 R Q 2 N r e 2 d 4 q 7 p b 3 9 g 8 O j 8 v F J W 0 e J I r R F I h 6 p b o A 1 5 U z S l m G G 0 2 6 s K B Y B p 5 1 g c j / 3 O 1 O q N I t k 0 8 x i 6 g s 8 k i x k B B s r + W k / C N E 4 G 6 T N K y 8 b l C t u 1 V 0 A r R M v J x X I 0 R i U v / r D i C S C S k M 4 1 r r n u b H x U 6 w M I 5 x m p X 6 i a Y z J B I 9 o z 1 K J B d V + u j g 6 Q x d W G a I w U r a k Q Q v 1 9 0 S K h d Y z E d h O g c 1 Y r 3 p z 8 T + v l 5 j w z k + Z j B N D J V k u C h O O T I T m C a A h U 5 Q Y P r M E E 8 X s r Y i M s c L E 2 J x K N g R v 9 e V 1 0 q 5 V v e t q 7 f G m U q / l c R T h D M 7 h E j y 4 h T o 8 Q A N a Q O A J n u E V 3 p y p 8 + K 8 O x / L 1 o K T z 5 z C H z i f P x v 8 k Z 0 = &lt; / l a t e x i t &gt; g 0 (z, h 0 ) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " p p O K Z c f W C h W Y I P R f B V b Z y N x i / b 8 = " &gt; A A A C A n i c b Z D L S s N A F I Z P 6 q 3 W W 9 S V u B k s Q g U p S R V 0 W X D j s o K 9 Q B v C Z D p p h 0 4 u z E y E G o I b X 8 W N C 0 X c + h T u f B u n a R Z a / W H g 4 z / n c O b 8 X s y Z V J b 1 Z Z S W l l d W 1 8 r r l Y 3 N r e 0 d c 3 e v I 6 N E E N o m E Y 9 E z 8 O S c h b S t m K K 0 1 4 s K A 4 8 T r v e 5 G p W 7 9 5 R I V k U 3 q p p T J 0 A j 0 L m M 4 K V t l z z Y O S m V l Z L B 5 6 P 7 r N T l M M 4 c 6 0 T 1 6 x a d S s X + g t 2 A V U o 1 H L N z 8 E w I k l A Q 0 U 4 l r J v W 7 F y U i w U I 5 x m l U E i a Y z J B I 9 o X 2 O I A y q d N D 8 h Q 8 f a G S I / E v q F C u X u z 4 k U B 1 J O A 0 9 3 B l i N 5 W J t Z v 5 X 6</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>B n v 8 9 a S U c z s w y 8 Z H 9 9 Y Q J Y N &lt; / l a t e x i t &gt; g 0 (0, h 1 ) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " A L M H y i 1 i 2 p z V b z s M j / p n Z A a G / V k = " &gt; A A A C A n i c b Z D L S s N A F I Z P 6 q 3 W W 9 S V u B k s Q g U p S R V 0 W X D j s o K 9 Q B v C Z D p p h 0 4 u z E y E E o I b X 8 W N C 0 X c + h T u f B u n a R b a + s P A x 3 / O 4 c z 5 v Z g z q S z r 2 y i t r K 6 t b 5 Q 3 K 1 v b O 7 t 7 5 v 5 B R 0 a J I L R N I h 6 J n o c l 5 S y k b c U U p 7 1 Y U B x 4 n H a 9 y c 2 s 3 n 2 g Q r I o v F f T m D o B H o X M Z w Q r b b n m 0 c h N r a y W D j w f W d k 5 y m G c u f a Z a 1 a t u p U L L Y N d Q B U K t V z z a z C M S B L Q U B G O p e z b V q y c F A v F C K d Z Z Z B I G m M y w S P a 1 x j i g E o n z U / I 0 K l 2 h s i P h H 6 h Q r n 7 e y L F g Z T T w N O d A V Z j u V i b m f / V + o n y r 5 2 U h X G i a E j m i / y E I x W h W R 5 o y A Q l i k 8 1 Y C K Y / i s i Y y w w U T q 1 i g 7 B X j x 5 G T q N u n 1 R b 9 x d V p u N I o 4 y H M M J 1 M C G K 2 j C L b S g D Q Q e 4 R l e 4 c 1 4 M l 6 M d + N j 3 l o y i p l D + C P j 8 w f l z J X E &lt; / l a t e x i t &gt; g 0 (0, h T 1 ) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " a 1 d n P u 1 G R I a 6 2 g U 8 K / E 6 F 2 l / n t s = " &gt; A A A C B n i c b Z D L S s N A F I Z P 6 q 3 W W 9 S l C I N F q K A l q Y I u C 2 5 c V u g N 2 h A m 0 0 k 7 d H J h Z i K U k J U b X 8 W N C 0 X c + g z u f B u n a R f a + s P A x 3 / O 4 c z 5 v Z g z q S z r 2 y i s r K 6 t b x Q 3 S 1 v b O 7 t 7 5 v 5 B W 0 a J I L R F I h 6 J r o c l 5 S y k L c U U p 9 1 Y U B x 4 n H a 8 8 e 2 0 3 n m g Q r I o b K p J T J 0 A D 0 P m M 4 K V t l z z e O i m V l Z J + 5 6 P r O w c 5 T D K 3 L R 5 Y W d n r l m 2 q l Y u t A z 2 H M o w V 8 M 1 v / q D i C Q B D R X h W M q e b c X K S b F Q j H C a l f q J p D E m Y z y k P Y 0 h D q h 0 0 v y M D J 1 q Z 4 D 8 S O g X K p S 7 v y d S H E g 5 C T z d G W A 1 k o u 1 q f l f r Z c o / 8 Z J W R g n i o Z k t s h P O F I R m m a C B k x Q o v h E A y a C 6 b 8 i M s I C E 6 W T K + k Q 7 M W T l 6 F d q 9 q X 1 d r 9 V b l e m 8 d R h C M 4 g Q r Y c A 1 1 u I M G t I D A I z z D K 7 w Z T 8 a L 8 W 5 8 z F o L x n z m E P 7 I + P w B 2 m W X Z Q = = &lt; / l a t e x i t &gt; g 1 (z, z T ) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " C w V x D g J R y x C W 6 Q y O V Y 7 N z u G q I 3 o = " &gt; A A A C A H i c b Z D L S s N A F I Z P v N Z 6 i 7 p w 4 W a w C B W k J F X Q Z c G N y w q 9 Q R v C Z D p p h 0 4 m Y W Y i 1 N C N r + L G h S J u f Q x 3 v o 3 T N g t t / W H g 4 z / n c O b 8 Q c K Z 0 o 7 z b a 2 s r q 1 v b B a 2 i t s 7 u 3 v 7 9 s F h S 8 W p J L R J Y h 7 L T o A V 5 U z Q p m a a 0 0 4 i K Y 4 C T t v B 6 H Z a b z 9 Q q V g s G n q c U C / C A 8 F C R r A 2 l m 8 f D 3 y 3 n P W C E D 1 O L l A O f u P c t 0 t O x Z k J L Y O b Q w l y 1 X 3 7 q 9 e P S R p R o Q n H S n V d J 9 F e h q V m h N N J s Z c q m m A y w g P a N S h w R J W X z Q 6 Y o D P j 9 F E Y S / O E R j P 3 9 0 S G I 6 X G U W A 6 I 6 y H a r E 2 N f + r d V M d 3 n g Z E 0 m q q S D z R W H K k Y 7 R N A 3 U Z 5 I S z c c G M J H M / B W R I Z a Y a J N Z 0 Y T g L p 6 8 D K 1 q x b 2 s V O + v S r V q H k c B T u A U y u D C N d T g D u r Q B A I T e I Z X e L O e r B f r 3 f q Y t 6 5 Y + c w R / J H 1 + Q P T r J U 4 &lt; / l a t e x i t &gt; g 1 (z, z 2 ) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " b q h E r C i I 9 j J M g z m k i D m Z S r w B c A 0 = " &gt; A A A C A H i c b Z D L S s N A F I Z P 6 q 3 W W 9 S F C z e D R a g g J Y m C L g t u X F a w F 2 h D m E w n 7 d D J h Z m J U E M 2 v o o b F 4 q 4 9 T H c + T Z O 2 y y 0 9 Y e B j / + c w 5 n z + w l n U l n W t 1 F a W V 1 b 3 y h v V r a 2 d 3 b 3 z P 2 D t o x T Q W i L x D w W X R 9 L y l l E W 4 o p T r u J o D j 0 O e 3 4 4 5 t p v f N A h W R x d K 8 m C X V D P I x Y w A h W 2 v L M o 6 F n 1 7 K + H 6 D H / B w V 4 D l n n l m 1 6 t Z M a B n s A q p Q q O m Z X / 1 B T N K Q R o p w L G X P t h L l Z l g o R j j N K / 1 U 0 g S T M R 7 S n s Y I h 1 S 6 2 e y A H J 1 q Z 4 C C W O g X K T R z f 0 9 k O J R y E v q 6 M 8 R q J B d r U / O / W i 9 V w b W b s S h J F Y 3 I f F G Q c q R i N E 0 D D Z i g R P G J B k w E 0 3 9 F Z I Q F J k p n V t E h 2 I s n L 0 P b q d s X d e f u s t p w i j j K c A w n U A M b r q A B t 9 C E F h D I 4 R l e 4 c 1 4 M l 6 M d + N j 3 l o y i p l D + C P j 8 w e g A p U W &lt; / l a t e x i t &gt; g 1 (z, z 1 )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>t e x i t s h a 1 _ b a s e 6 4 = " S L U 7 L y 6 D B W g H D h E H Z l 6 / 5 A z E O t s = " &gt; A A A C y 3 i c f V H L a t t A F B 2 r r 9 R 9 J e 2 y m 6 H C U E o J U g i 0 y 0 C 7 6 C Y 0 h d o O W C Z c j a / k w T M j M T M y d V Q t + w H Z p v / Q / 8 n f 5 M p R a Z 2 k v T B w O P f c x 5 y b l k o 6 H 0 U X v e D O 3 X v 3 H 2 w 9 7 D 9 6 / O T p s + 2 d 5 y N X V F b g U B S q s M c p O F T S 4 N B L r / C 4 t A g 6 V T h O F x / a / H i J 1 s n C f P W r E q c a c i M z K c A T N U 6 W K O r T 5 m Q 7 j H a j d f C b I O 5 A y L o 4 O t n p / U p m h a g 0 G i 8 U O D e J o 9 J P a 7 B e C o V N P 6 k c l i A W k O O E o A G N b l q v 9 2 3 4 g J g Z z w p L z 3 i + Z v + u q E E 7 t 9 I p K T X 4 u b u e a 8 n b c p P K Z + + n t T R l 5 d G I q 0 F Z p b g v e P t 5 P p M W h V c r A i C s p F 2 5 m I M F 4 c m i f n 8 w 4 H + a c U d S 8 m h j e G p h g b 7 Z X E j l B f W a 6 3 / Q U l B i h l k y Q h H G d d K u n W Z 1 G D c d v 7 y F / 4 h k q 8 V D 4 j 6 X a M E X 9 k 2 d g M 2 1 N A 3 Z n C d v W / Q / I X z 7 L S R E F 4 6 v 3 / M m G O 3 t x o S / 7 I c H + 9 2 t t 9 h L 9 o q 9 Z j F 7 x w 7 Y J 3 b E h k y w B T t j 5 + x n c B i 4 4 D T 4 f i U N e l 3 N C 7 Y R w Y 9 L T V P i p g = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " S L U 7 L y 6 D B W g H D h E H Z l 6 / 5 A z E O t s = " &gt; A A A C y 3 i c f V H L a t t A F B 2 r r 9 R 9 J e 2 y m 6 H C U E o J U g i 0 y 0 C 7 6 C Y 0 h d o O W C Z c j a / k w T M j M T M y d V Q t + w H Z p v / Q / 8 n f 5 M p R a Z 2 k v T B w O P f c x 5 y b l k o 6 H 0 U X v e D O 3 X v 3 H 2 w 9 7 D 9 6 / O T p s + 2 d 5 y N X V F b g U B S q s M c p O F T S 4 N B L r / C 4 t A g 6 V T h O F x / a / H i J 1 s n C f P W r E q c a c i M z K c A T N U 6 W K O r T 5 m Q 7 j H a j d f C b I O 5 A y L o 4 O t n p / U p m h a g 0 G i 8 U O D e J o 9 J P a 7 B e C o V N P 6 k c l i A W k O O E o A G N b l q v 9 2 3 4 g J g Z z w p L z 3 i + Z v + u q E E 7 t 9 I p K T X 4 u b u e a 8 n b c p P K Z + + n t T R l 5 d G I q 0 F Z p b g v e P t 5 P p M W h V c r A i C s p F 2 5 m I M F 4 c m i f n 8 w 4 H + a c U d S 8 m h j e G p h g b 7 Z X E j l B f W a 6 3 / Q U l B i h l k y Q h H G d d K u n W Z 1 G D c d v 7 y F / 4 h k q 8 V D 4 j 6 X a M E X 9 k 2 d g M 2 1 N A 3 Z n C d v W / Q / I X z 7 L S R E F 4 6 v 3 / M m G O 3 t x o S / 7 I c H + 9 2 t t 9 h L 9 o q 9 Z j F 7 x w 7 Y J 3 b E h k y w B T t j 5 + x n c B i 4 4 D T 4 f i U N e l 3 N C 7 Y R w Y 9 L T V P i p g = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " S L U 7 L y 6 D B W g H D h E H Z l 6 / 5 A z E O t s = " &gt; A A A C y 3 i c f V H L a t t A F B 2 r r 9 R 9 J e 2 y m 6 H C U E o J U g i 0 y 0 C 7 6 C Y 0 h d o O W C Z c j a / k w T M j M T M y d V Q t + w H Z p v / Q / 8 n f 5 M p R a Z 2 k v T B w O P f c x 5 y b l k o 6 H 0 U X v e D O 3 X v 3 H 2 w 9 7 D 9 6 / O T p s + 2 d 5 y N X V F b g U B S q s M c p O F T S 4 N B L r / C 4 t A g 6 V T h O F x / a / H i J 1 s n C f P W r E q c a c i M z K c A T N U 6 W K O r T 5 m Q 7 j H a j d f C b I O 5 A y L o 4 O t n p / U p m h a g 0 G i 8 U O D e J o 9 J P a 7 B e C o V N P 6 k c l i A W k O O E o A G N b l q v 9 2 3 4 g J g Z z w p L z 3 i + Z v + u q E E 7 t 9 I p K T X 4 u b u e a 8 n b c p P K Z + + n t T R l 5 d G I q 0 F Z p b g v e P t 5 P p M W h V c r A i C s p F 2 5 m I M F 4 c m i f n 8 w 4 H + a c U d S 8 m h j e G p h g b 7 Z X E j l B f W a 6 3 / Q U l B i h l k y Q h H G d d K u n W Z 1 G D c d v 7 y F / 4 h k q 8 V D 4 j 6 X a M E X 9 k 2 d g M 2 1 N A 3 Z n C d v W / Q / I X z 7 L S R E F 4 6 v 3 / M m G O 3 t x o S / 7 I c H + 9 2 t t 9 h L 9 o q 9 Z j F 7 x w 7 Y J 3 b E h k y w B T t j 5 + x n c B i 4 4 D T 4 f i U N e l 3 N C 7 Y R w Y 9 L T V P i p g = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " S L U 7 L y 6 D B W g H D h E H Z l 6 / 5 A z E O t s = " &gt; A A A C y 3 i c f V H L a t t A F B 2 r r 9 R 9 J e 2 y m 6 H C U E o J U g i 0 y 0 C 7 6 C Y 0 h d o O W C Z c j a / k w T M j M T M y d V Q t + w H Z p v / Q / 8 n f 5 M p R a Z 2 k v T B w O P f c x 5 y b l k o 6 H 0 U X v e D O 3 X v 3 H 2 w 9 7 D 9 6 / O T p s + 2 d 5 y N X V F b g U B S q s M c p O F T S 4 N B L r / C 4 t A g 6 V T h O F x / a / H i J 1 s n C f P W r E q c a c i M z K c A T N U 6 W K O r T 5 m Q 7 j H a j d f C b I O 5 A y L o 4 O t n p / U p m h a g 0 G i 8 U O D e J o 9 J P a 7 B e C o V N P 6 k c l i A W k O O E o A G N b l q v 9 2 3 4 g J g Z z w p L z 3 i + Z v + u q E E 7 t 9 I p K T X 4 u b u e a 8 n b c p P K Z + + n t T R l 5 d G I q 0 F Z p b g v e P t 5 P p M W h V c r A i C s p F 2 5 m I M F 4 c m i f n 8 w 4 H + a c U d S 8 m h j e G p h g b 7 Z X E j l B f W a 6 3 / Q U l B i h l k y Q h H G d d K u n W Z 1 G D c d v 7 y F / 4 h k q 8 V D 4 j 6 X a M E X 9 k 2 d g M 2 1 N A 3 Z n C d v W / Q / I X z 7 L S R E F 4 6 v 3 / M m G O 3 t x o S / 7 I c H + 9 2 t t 9 h L 9 o q 9 Z j F 7 x w 7 Y J 3 b E h k y w B T t j 5 + x n c B i 4 4 D T 4 f i U N e l 3 N C 7 Y R w Y 9 L T V P i p g = = &lt; / l a t e x i t &gt; t e x i t s h a 1 _ b a s e 6 4 = " t z D d g d g z u R z o 1 B D J o S J 5 V a M E v 7 8 = " &gt; A A A C y 3 i c f V H L a t t A F B 0 r f a T u K 4 9 l N k O F o Z Q S p B B o l 4 F 2 k U 1 I A r U d s E y 4 G l / J g + c h Z k Y m r q p l P i D b 9 B / 6 P / 2 b j h y F 1 E n a C w O H c 8 9 9 z L l p I b h 1 U f S 7 E 6 w 9 e f r s + f q L 7 s t X r 9 + 8 3 d j c G l h d G o Z 9 p o U 2 Z y l Y F F x h 3 3 E n 8 K w w C D I V O E x n X 5 r 8 c I 7 G c q 2 + u U W B Y w m 5 4 h l n 4 D w 1 T O b I q o v 6 f C O M d q N l 0 I c g b k F I 2 j g 5 3 + z 8 S i a a l R K V Y w K s H c V R 4 c Y V G M e Z w L q b l B Y L Y D P I c e S h A o l 2 X C 3 3 r W n P M x O a a e O f c n T J / l 1 R g b R 2 I V O v l O C m 9 n 6 u I R / L j U q X f R 5 X X B W l Q 8 V u B m W l o E 7 T 5 v N 0 w g 0 y J x Y e A D P c 7 0 r Z F A w w 5 y 3 q d n s 9 e t e M W i / 1 H q 0 M T w 3 M 0 N W r C 4 l c + 1 5 T + Q + a M 5 + Y Y J Y M k I V x l T R r p 1 k V x n X L z x / h v 6 K 3 1 e C R 5 4 4 L N O C 0 + V A l Y H L J V e 1 t z p O P D f q f E C 5 u h b C 8 c H z / n g / B Y G 8 3 9 v h 0 P z z Y b 2 + 9 T n b I O / K e x O Q T O S C H 5 I T 0 C S M z c k W u y c / g K L D B 9 + D H j T T o t D X b Z C W C y z 9 I j + K k &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " t z D d g d g z u R z o 1 B D J o S J 5 V a M E v 7 8 = " &gt; A A A C y 3 i c f V H L a t t A F B 0 r f a T u K 4 9 l N k O F o Z Q S p B B o l 4 F 2 k U 1 I A r U d s E y 4 G l / J g + c h Z k Y m r q p l P i D b 9 B / 6 P / 2 b j h y F 1 E n a C w O H c 8 9 9 z L l p I b h 1 U f S 7 E 6 w 9 e f r s + f q L 7 s t X r 9 + 8 3 d j c G l h d G o Z 9 p o U 2 Z y l Y F F x h 3 3 E n 8 K w w C D I V O E x n X 5 r 8 c I 7 G c q 2 + u U W B Y w m 5 4 h l n 4 D w 1 T O b I q o v 6 f C O M d q N l 0 I c g b k F I 2 j g 5 3 + z 8 S i a a l R K V Y w K s H c V R 4 c Y V G M e Z w L q b l B Y L Y D P I c e S h A o l 2 X C 3 3 r W n P M x O a a e O f c n T J / l 1 R g b R 2 I V O v l O C m 9 n 6 u I R / L j U q X f R 5 X X B W l Q 8 V u B m W l o E 7 T 5 v N 0 w g 0 y J x Y e A D P c 7 0 r Z F A w w 5 y 3 q d n s 9 e t e M W i / 1 H q 0 M T w 3 M 0 N W r C 4 l c + 1 5 T + Q + a M 5 + Y Y J Y M k I V x l T R r p 1 k V x n X L z x / h v 6 K 3 1 e C R 5 4 4 L N O C 0 + V A l Y H L J V e 1 t z p O P D f q f E C 5 u h b C 8 c H z / n g / B Y G 8 3 9 v h 0 P z z Y b 2 + 9 T n b I O / K e x O Q T O S C H 5 I T 0 C S M z c k W u y c / g K L D B 9 + D H j T T o t D X b Z C W C y z 9 I j + K k &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " t z D d g d g z u R z o 1 B D J o S J 5 V a M E v 7 8 = " &gt; A A A C y 3 i c f V H L a t t A F B 0 r f a T u K 4 9 l N k O F o Z Q S p B B o l 4 F 2 k U 1 I A r U d s E y 4 G l / J g + c h Z k Y m r q p l P i D b 9 B / 6 P / 2 b j h y F 1 E n a C w O H c 8 9 9 z L l p I b h 1 U f S 7 E 6 w 9 e f r s + f q L 7 s t X r 9 + 8 3 d j c G l h d G o Z 9 p o U 2 Z y l Y F F x h 3 3 E n 8 K w w C D I V O E x n X 5 r 8 c I 7 G c q 2 + u U W B Y w m 5 4 h l n 4 D w 1 T O b I q o v 6 f C O M d q N l 0 I c g b k F I 2 j g 5 3 + z 8 S i a a l R K V Y w K s H c V R 4 c Y V G M e Z w L q b l B Y L Y D P I c e S h A o l 2 X C 3 3 r W n P M x O a a e O f c n T J / l 1 R g b R 2 I V O v l O C m 9 n 6 u I R / L j U q X f R 5 X X B W l Q 8 V u B m W l o E 7 T 5 v N 0 w g 0 y J x Y e A D P c 7 0 r Z F A w w 5 y 3 q d n s 9 e t e M W i / 1 H q 0 M T w 3 M 0 N W r C 4 l c + 1 5 T + Q + a M 5 + Y Y J Y M k I V x l T R r p 1 k V x n X L z x / h v 6 K 3 1 e C R 5 4 4 L N O C 0 + V A l Y H L J V e 1 t z p O P D f q f E C 5 u h b C 8 c H z / n g / B Y G 8 3 9 v h 0 P z z Y b 2 + 9 T n b I O / K e x O Q T O S C H 5 I T 0 C S M z c k W u y c / g K L D B 9 + D H j T T o t D X b Z C W C y z 9 I j + K k &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " t z D d g d g z u R z o 1 B D J o S J 5 V a M E v 7 8 = " &gt; A A A C y 3 i c f V H L a t t A F B 0 r f a T u K 4 9 l N k O F o Z Q S p B B o l 4 F 2 k U 1 I A r U d s E y 4 G l / J g + c h Z k Y m r q p l P i D b 9 B / 6 P / 2 b j h y F 1 E n a C w O H c 8 9 9 z L l p I b h 1 U f S 7 E 6 w 9 e f r s + f q L 7 s t X r 9 + 8 3 d j c G l h d G o Z 9 p o U 2 Z y l Y F F x h 3 3 E n 8 K w w C D I V O E x n X 5 r 8 c I 7 G c q 2 + u U W B Y w m 5 4 h l n 4 D w 1 T O b I q o v 6 f C O M d q N l 0 I c g b k F I 2 j g 5 3 + z 8 S i a a l R K V Y w K s H c V R 4 c Y V G M e Z w L q b l B Y L Y D P I c e S h A o l 2 X C 3 3 r W n P M x O a a e O f c n T J / l 1 R g b R 2 I V O v l O C m 9 n 6 u I R / L j U q X f R 5 X X B W l Q 8 V u B m W l o E 7 T 5 v N 0 w g 0 y J x Y e A D P c 7 0 r Z F A w w 5 y 3 q d n s 9 e t e M W i / 1 H q 0 M T w 3 M 0 N W r C 4 l c + 1 5 T + Q + a M 5 + Y Y J Y M k I V x l T R r p 1 k V x n X L z x / h v 6 K 3 1 e C R 5 4 4 L N O C 0 + V A l Y H L J V e 1 t z p O P D f q f E C 5 u h b C 8 c H z / n g / B Y G 8 3 9 v h 0 P z z Y b 2 + 9 T n b I O / K e x O Q T O S C H 5 I T 0 C S M z c k W u y c / g K L D B 9 + D H j T T o t D X b Z C W C y z 9 I j + K k &lt; / l a t e x i t &gt;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 5</head><label>5</label><figDesc>Graphs representing the cost savings by enabling multiple subsampling layers. The left figures show the theoretical computational cost of each block of the network, and the right figures denote the amount of intermediate memory in each block consumed by generated samples and hidden variables. The horizontal axis of all graphs represents the level of the block. Each block of the generator used to compute the cost contains layers inside the blue area in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 6</head><label>6</label><figDesc>An example of videos generated by our model (s t = 2) trained with FaceForensics dataset. Every four frames out of 16 frames is shown in a row for the ease of identifing the motion in the video. The top row represents the frames of the whole video. The bottom row shows a magnified view of the area of the white box in the top row.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 7 AFig. 8</head><label>78</label><figDesc>list of still images extracted from videos generated by our model (s t = 2). The FaceForensics dataset was used for the trainingComparison of instability of first frames trained with FaceForensics. Only the initial six frames are shown.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 9</head><label>9</label><figDesc>3D + 2D discriminators (ii) Our model (s t = 2, uncond.) (iii) Our model (s t = 4, uncond.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Fig. 11</head><label>11</label><figDesc>Comparison of instability of first frames trained with UCF101. Only the initial six frames are shown.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Fig. 12</head><label>12</label><figDesc>Example of linear interpolation of noise vectors. The first and last rows represent images sampled from the two noise vectors, and the middle row means an image generated from an intermediate vector between them. Only the result of the eight frame is shown for simplicity. The model trained with s t = 2 was used.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Fig. 13 s t = 4 Fig. 14</head><label>13414</label><figDesc>FaceForensics (s t = 2) (ii) UCF101 (s t = 4) Example of videos generated at different levels. The leftmost image represents the frame of the video generated by the initial rendering block, and the rightmost one denotes the final generated image. The difference of the video which each rendering block outputs. The row represents levels of rendering blocks and time, and the column means time.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Fig. 15</head><label>15</label><figDesc>Quantitative differences of the videos generated by different rendering blocks. The row indicates the difference between the two frames generated by rendering block at level 1 and 4. The column means time. Error bars at the 95% confidence interval.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>The total computational cost and intermediate memory consumption in megabytes when enabling frame and batch reductions. The number of frames used for generation is 16, and the batch size is 1.</figDesc><table><row><cell></cell><cell>.07</cell><cell></cell><cell>1019</cell><cell></cell></row><row><cell>Subsampling (s t = 2)</cell><cell>28.91</cell><cell>1.56x</cell><cell>271</cell><cell>3.76x</cell></row><row><cell>Subsampling (s t = 4)</cell><cell>26.20</cell><cell>1.72x</cell><cell>169</cell><cell>6.03x</cell></row><row><cell>Dis (naive impl.)</cell><cell>215.74</cell><cell></cell><cell>1130</cell><cell></cell></row><row><cell>Subsampling (s t = 2)</cell><cell>53.41</cell><cell>4.04x</cell><cell>217</cell><cell>5.22x</cell></row><row><cell>Subsampling (s t = 4)</cell><cell>38.40</cell><cell>5.62x</cell><cell>135</cell><cell>8.37x</cell></row><row><cell>3D discriminator</cell><cell>162.38</cell><cell></cell><cell>851</cell><cell></cell></row><row><cell>3D + 2D dis.</cell><cell>168.20</cell><cell></cell><cell>921</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>The pre-trained model itself can be downloaded from http://vlg.cs.dartmouth.edu/c3d/</figDesc><table><row><cell>Method</cell><cell>IS</cell><cell>FID</cell></row><row><cell>VGAN [51]</cell><cell>8.31 ± .09</cell><cell></cell></row><row><cell>TGAN [42]</cell><cell>11.85 ± .07</cell><cell></cell></row><row><cell>MoCoGAN [49]</cell><cell>12.42 ± .03</cell><cell></cell></row><row><cell>ProgressiveVGAN [1]</cell><cell>13.59 ± .07</cell><cell></cell></row><row><cell cols="2">ProgressiveVGAN w/ SWL [1] 14.56 ± .05</cell><cell></cell></row><row><cell>Single 3D discriminator only</cell><cell cols="2">11.10 ± .16 8358 ± 81</cell></row><row><cell>3D + 2D discriminators</cell><cell cols="2">10.47 ± .12 8304 ± 70</cell></row><row><cell>Naive implementation</cell><cell cols="2">13.29 ± .15 5401 ± 31</cell></row><row><cell>Our model (s t = 2)</cell><cell cols="2">23.87 ± .28 3797 ± 20</cell></row><row><cell>Our model (s t = 4)</cell><cell cols="2">26.60 ± .47 3431 ± 19</cell></row></table><note>1</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc>Inception Score and Fréchet Inception Distance on UCF101 dataset.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3</head><label>3</label><figDesc>Inception Score and Fréchet Inception Distance when using a single GPU.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Method IS FID Single 3D discriminator only 11.72 ± .20 7754 ± 47 3D + 2D discriminators 13.38 ± .22 6993 ± 25 Naive implementation 14.44 ± .20 7613 ± 29 Our model (s t = 2) 23.87 ± .28 3797 ± 20 Our model (s t = 4) 26.60 ± .47 3431 ± 19</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4</head><label>4</label><figDesc>Inception Score and Fréchet Inception Distance when setting 32 for batch size.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5</head><label>5</label><figDesc>Batchsize Naive impl. s t = 2 s t = 4 4 13.29 ± .15 14.64 ± .25 17.12 ± .26 8 11.26 ± .19 20.61 ± .28 21.45 ± .29 16 12.79 ± .10 22.81 ± .52 22.69 ± .47 32 14.44 ± .20 23.87 ± .28 26.60 ± .47 64 N/A 24.39 ± .50 26.89 ± .40 128 N/A 25.65 ± .34 28.87 ± .67 Changes in the inception score when sub-sampling layers are enabled.</figDesc><table><row><cell cols="2">Batchsize Naive impl.</cell><cell>s t = 2</cell><cell>s t = 4</cell></row><row><cell>4</cell><cell>5401 ± 31</cell><cell cols="2">5148 ± 33 4449 ± 14</cell></row><row><cell>8</cell><cell>7364 ± 51</cell><cell cols="2">3930 ± 25 3877 ± 15</cell></row><row><cell>16</cell><cell>7822 ± 27</cell><cell cols="2">3639 ± 15 3715 ± 19</cell></row><row><cell>32</cell><cell>7613 ± 29</cell><cell cols="2">3797 ± 20 3431 ± 19</cell></row><row><cell>64</cell><cell>N/A</cell><cell cols="2">4242 ± 32 3334 ± 26</cell></row><row><cell>128</cell><cell>N/A</cell><cell cols="2">3573 ± 28 3497 ± 26</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6</head><label>6</label><figDesc>Changes in the Fréchet Inception Distance when sub-sampling layers are enabled.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>± .52 40.59 ± .94 22.69 ± .47 39.61 ± .94 32 23.87 ± .28 48.00 ± 1.0 26.60 ± .47 49.30 ± .56 64 24.39 ± .50 54.93 ± .68 26.89 ± .40 51.21 ± .49</figDesc><table><row><cell></cell><cell></cell><cell>s t = 2</cell><cell></cell><cell>s t = 4</cell></row><row><cell>BS</cell><cell>pure</cell><cell>conditional</cell><cell>pure</cell><cell>conditional</cell></row><row><cell>16</cell><cell>22.81</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 8</head><label>8</label><figDesc>Changes in the Fréchet Inception Distance when updating to a conditional model.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head></head><label></label><figDesc>Method S 1 S 2 S 3 IS FID Naive impl. 12.79 ± .10 7822 ± 27 19.99 ± .33 4502 ± 37 21.38 ± .38 4192 ± 45 Full 22.81 ± .52 3639 ± 15</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 11</head><label>11</label><figDesc>Method S 1 S 2 S 3 IS FID Naive impl. 12.79 ± .10 7822 ± 27 20.95 ± .12 4433 ± 26 19.37 ± .43 4628 ± 20 Full 22.69 ± .47 3715 ± 19 Table 10 Change in Inception Score and Fréchet Inception Distance when each subsampling layer is gradually enabled (batchsize=16, s t = 4). 3D dis. only 11.10 ± .16 4.30 ± .06 1.73 ± .01 3D + 2D dis. 10.47 ± .12 4.97 ± .04 3.78 ± .02</figDesc><table><row><cell>Method</cell><cell>Naive impl.</cell><cell>s t = 2</cell><cell>s t = 4</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Note that we mention videos after 16 frames. Up to 16 frames, our model generates stable videos regardless of the dataset.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to acknowledge Takeru Miyato and Shoichiro Yamaguchi for helpful discussions. We would like to acknowledge Daichi Suzuo for providing a tool to calculate the cost of computation and the amount of memory consumed. We also would like to thank the developers of Chainer <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b1">2]</ref>.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Towards High Resolution Video Generation with Progressive Growing of Sliced Wasserstein GANs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Acharya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Paudel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V</forename><surname>Gool</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.02419</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">Arxiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">ChainerMN: Scalable Distributed Deep Learning Framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Akiba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fukuda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Suzuki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Workshop on ML Systems in NIPS</title>
		<meeting>Workshop on ML Systems in NIPS</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Stochastic Variational Video Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Babaeizadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Recycle-GAN: Unsupervised Video Retargeting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sheikh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Pros and Cons of GAN Evaluation Measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Borji</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.03446</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">Arxiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Large Scale GAN Training for High Fidelity Natural Image Synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.11096</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">Arxiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">ContextVP: Fully Context-Aware Video Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Byeon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koumoutsakos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Deep Video Generation, Prediction and Completion of Human Action Sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Tang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Deep Generative Image Models Using a Laplacian Pyramid of Adversarial Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Denton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>NIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Stochastic Video Generation with a Learned Prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Denton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.07687</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">Arxiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Self-Supervised Visual Planning with Temporal Skip Connections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">X</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Robot Learning (CoRL)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Unsupervised Learning for Physical Interaction through Video Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>NIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Understanding the Difficulty of Training Deep Feedforward Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AIS-TATS</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Generative Adversarial Nets</title>
		<imprint>
			<date type="published" when="2014" />
			<publisher>NIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Improved Training of Wasserstein GANs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Controllable Video Generation with Sparse Trajectories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kataoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Satoh</surname></persName>
		</author>
		<title level="m">Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet? In: CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Deep Residual Learning for Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Heusel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ramsauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Nessler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Multimodal Unsupervised Image-to-Image Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Image-to-Image Translation with Conditional Adversarial Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.00527</idno>
		<title level="m">Video Pixel Networks. In: arxiv preprint</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Large-scale Video Classification with Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shetty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Toderici</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sukthankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Progressive Growing of GANs for Improved Quality, Stability, and Variation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lehtinen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Stochastic Adversarial Video Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">X</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.01523</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">Arxiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Flow-Grounded Spatial-Temporal Video Prediction from Still Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Dual Motion GAN for Future-Flow Embedded Video Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Unsupervised Image-to-Image Translation Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Breuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Video Frame Synthesis using Deep Voxel Flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Agarwala</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lotter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kreiman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cox</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Deep Multi-Scale Video Prediction beyond Mean Square Error</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Couprie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mescheder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
		<title level="m">Which Training Methods for GANs do actually Converge? In: ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Spectral Normalization for Generative Adversarial Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kataoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yoshida</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">cGANs with Projection Discriminator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Koyama</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Action-Conditional Video Prediction using Deep Networks in Atari Games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>NIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Hierarchical Video Generation from Orthogonal Information: Optical Flow and Texture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ohnishi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ushiku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Harada</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Guide to NumPy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">E</forename><surname>Oliphant</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CreateSpace Independent Publishing Platform</publisher>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
	<note>2nd edn</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6604</idno>
		<title level="m">Video (Language) Modeling: A Baseline for Generative Models of Natural Videos</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">FaceForensics: A Large-scale Video Dataset for Forgery Detection in Human Faces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rössler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cozzolino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Verdoliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Riess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Thies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nießner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.09179</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">Arxiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Temporal Generative Adversarial Nets with Singular Value Clipping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Matsumoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Saito</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Improved Techniques for Training GANs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>NIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">Y</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">K</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">C</forename><surname>Woo</surname></persName>
		</author>
		<title level="m">Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting</title>
		<imprint>
			<publisher>NIPS</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Soomro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1212.0402</idno>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Unsupervised Learning of Video Representations using LSTMs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Mansimov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICML</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Chainer: a Next-Generation Open Source Framework for Deep Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tokui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Oono</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hido</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Clayton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Workshop on Machine Learning Systems in NIPS</title>
		<meeting>Workshop on Machine Learning Systems in NIPS</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Torresani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Paluri</surname></persName>
		</author>
		<title level="m">Learning Spatiotemporal Features with 3D Convolutional Networks</title>
		<imprint>
			<publisher>ICCV</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">MoCoGAN: Decomposing Motion and Content for Video Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tulyakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Van Steenkiste</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kurach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Marinier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Michalski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gelly</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.01717</idno>
		<title level="m">Towards Accurate Generative Models of Video: A New Metric &amp; Challenges. In: Arxiv preprint</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Generating Videos with Scene Dynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Vondrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pirsiavash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>NIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Video-to-Video Synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Catanzaro</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.06601</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">Arxiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Catanzaro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Non-local Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Pose Guided Human Video Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Self-Attention Generative Adversarial Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Metaxas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Odena</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.08318</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">Arxiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Metaxas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10916</idno>
		<title level="m">StackGAN++: Realistic Image Synthesis with Stacked Generative Adversarial Networks. In: arXiv preprint</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Metaxas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Photographic Text-to-Image Synthesis with a Hierarchically-nested Adversarial Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Learning to Forecast and Refine Residual Motion for Image-to-Video Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kapadia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Metaxas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
