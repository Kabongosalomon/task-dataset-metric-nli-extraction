<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Enhancing VAEs for Collaborative Filtering: Flexible Priors &amp; Gating Mechanisms</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daeryong</forename><surname>Kim</surname></persName>
							<email>daeryong@snu.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="institution">Human Centered Computing Lab Seoul National University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bongwon</forename><surname>Suh</surname></persName>
							<email>bongwon@snu.ac.kr</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Human Centered Computing Lab Seoul National University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Enhancing VAEs for Collaborative Filtering: Flexible Priors &amp; Gating Mechanisms</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3298689.3347015</idno>
					<note>ACM Reference format: Daeryong Kim and Bongwon Suh. 2019. Enhancing VAEs for Collabora-tive Filtering: Flexible Priors &amp; Gating Mechanisms. In Thirteenth ACM Conference on Recommender Systems (RecSys &apos;19), September 16-20, 2019, Copenhagen, Denmark. ACM, New York, NY, USA, 5 pages.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T08:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CCS CONCEPTS • Information systems → Recommender systems</term>
					<term>• Computing methodologies → Neural networks</term>
					<term>KEYWORDS Recommender Systems</term>
					<term>Neural Collaborative Filtering</term>
					<term>Variational Autoencoders</term>
					<term>Deep Generative Models</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Neural network based models for collaborative filtering have started to gain attention recently. One branch of research is based on using deep generative models to model user preferences where variational autoencoders were shown to produce state-of-the-art results. However, there are some potentially problematic characteristics of the current variational autoencoder for CF. The first is the too simplistic prior that VAEs incorporate for learning the latent representations of user preference. The other is the model's inability to learn deeper representations with more than one hidden layer for each network. Our goal is to incorporate appropriate techniques to mitigate the aforementioned problems of variational autoencoder CF and further improve the recommendation performance. Our work is the first to apply flexible priors to collaborative filtering and show that simple priors (in original VAEs) may be too restrictive to fully model user preferences and setting a more flexible prior gives significant gains. We experiment with the VampPrior, originally proposed for image generation, to examine the effect of flexible priors in CF. We also show that VampPriors coupled with gating mechanisms outperform SOTA results including the Variational Autoencoder for Collaborative Filtering by meaningful margins on 2 popular benchmark datasets (MovieLens &amp; Netflix).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Today, the immense size and diversity of Web-based services make it nearly impossible for individual users to effectively search and find online content without the help of recommender systems.</p><p>There have been various kinds of recent studies incorporating deep learning into recommender systems. We focus on the branch of research using autoencoders and generative models which model latent variables of user preference <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b23">23,</ref><ref type="bibr" target="#b31">30]</ref>. Recommendation can be done by using the latent variables of a given user to reconstruct the users' history for recommendation. There has been work using vanilla autoencoders <ref type="bibr" target="#b23">[23]</ref>, denoising autoencoders <ref type="bibr" target="#b31">[30]</ref>, and most recently Variational Autoencoders (VAEs) <ref type="bibr" target="#b14">[15]</ref> to model user preference for collaborative filtering. To the best of our knowledge, Variational Autoencoders for Collaborative Filtering currently gives state-of-the-art results in the context of collaborative filtering.</p><p>However, while many new variations of VAEs are being proposed in the domain of image and audio generation, there has not yet been much research that has yielded further success in the collaborative filtering task for recommender systems.</p><p>In this work we aim to overcome some potentially problematic characteristics of VAEs in the task of collaborative filtering and appropriately tailor VAEs to further improve model performance and make high quality recommendations.</p><p>Two main motivations led our research. 1) The current prior distribution used in VAEs may be too restrictive for the collaborative filtering task, hindering the models from learning richer latent variables of user preference which is crucial to model performance. 2) Learning from user-item interaction history has its own characteristics and may have more effective architectures to learn deeper latent representations.</p><p>We implement hierarchical variational autoencoders with VampPrior (variational mixture of posteriors prior) <ref type="bibr" target="#b25">[25]</ref> to learn richer latent representations of user preferences from interaction history. Another variation we adopted is that we used Gated Linear Units (GLUs) <ref type="bibr" target="#b3">[4]</ref> to effectively control information flow of our networks by learning when each item or feature contribute to certain units. Coupling the gating mechanism with the aforementioned VampPrior significantly boosted the performance of the variational autoencoding CF framework and outperformed current state-of-the-art collaborative filtering algorithms.</p><p>We carried out rigorous experiments on two popular benchmark datasets: MovieLens-20M and Netflix. Our proposed method was compared to baseline models including state-of-the-art matrix factorization and autoencoder based methods and showed significant improvements in NDCG and recall.</p><p>The key contributions of our work are as follows: *This is a preprint version of the paper published at ACM RecSys <ref type="bibr">'19</ref> Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. RecSys <ref type="bibr">'19, September 16-20, 2019</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>There have been various studies incorporating deep learning into collaborative filtering recommender systems. Research extending the traditional matrix factorization framework to non-linear matrix factorization using neural networks <ref type="bibr" target="#b8">[9]</ref>, session-based recommenddation using recurrent neural networks (RNNs) <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b20">20,</ref><ref type="bibr" target="#b30">29]</ref>, recommendation with autoencoders and generative models <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b23">23,</ref><ref type="bibr" target="#b28">28,</ref><ref type="bibr" target="#b31">30]</ref>, and many others including hybrid methods using extraction of high-level content features through deep learning <ref type="bibr" target="#b26">[26,</ref><ref type="bibr" target="#b27">27]</ref>. The autoencoder based recommendation algorithm was first proposed as AutoRec <ref type="bibr" target="#b23">[23]</ref>. It is the algorithm of using vanilla autoencoders for collaborative filtering and showed to give superior results compared to linear MF methods. Further research was made using denoising autoencoders to present CDAE <ref type="bibr" target="#b31">[30]</ref>.</p><p>The most recent advancement of autoencoder based CF was made by using Variational Autoencoders for Collaborative Filtering <ref type="bibr" target="#b14">[15]</ref>. The Variational Autoencoder (VAE) is a probabilistic generative model in the form of autoencoders which models the data distribution P(X) using amortized variational inference. In VAE-CF <ref type="bibr" target="#b14">[15]</ref> the latent variables are stochastic, and their probability distributions are learned for each datapoint. Additionally modeling per-data-point variation led to more robust representations and yielded SOTA recommendation performance beating other autoencoder and neural network based methods such as CDAE <ref type="bibr" target="#b31">[30]</ref> and Neural Collaborative Filtering (NCF) <ref type="bibr" target="#b8">[9]</ref>.</p><p>On the other hand, in the domain of computer vision there have been further advances for VAEs proposing new models with more flexible priors to enrich the generative capabilities. A Dirichlet process prior with a stick-breaking process was proposed in <ref type="bibr" target="#b18">[18]</ref>, and in <ref type="bibr" target="#b7">[8]</ref> a nested Chinese Restaurant Process was used. Also, a Gaussian mixture prior was used for <ref type="bibr" target="#b5">[6]</ref>. The VampPrior <ref type="bibr" target="#b25">[25]</ref> was proposed recently, it consists of a mixture distribution of variational posteriors on pseudo-inputs substituting the original standard normal prior to a very flexible multimodal distribution. The VampPrior showed impressive results for image generation and was a major motivation of our work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PRELIMINARIES</head><p>Our work is an extension of the VAEs for CF <ref type="bibr" target="#b14">[15]</ref> framework incorporating appropriate ideas to further enhance the recommendation performance in collaborative filtering. In this section we describe our problem formulation and the original VAE-CF framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem Formulation</head><p>We attempt to model user preferences based on a given users' interaction history of the item set. We shall use the following shared notations throughout the paper. We will use u ∈ {1, … , N} to index users and i ∈ {1, … , M} to index items. We consider implicit feedback with binary input: the dataset = { 1 , … , } with each ∈ the interaction history of user . And ∈ ℝ the latent variable of user preference for user .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">VAE for Collaborative Filtering</head><p>The baseline model of our research is the Multi-VAE in <ref type="bibr" target="#b14">[15]</ref>. The generative process of the model is as follows. For every user a latent variable ∈ ℝ is sampled from the standard normal prior distribution. The latent representation is then transformed through a neural network generative model to produce the probability distribution over the user's item consumption history , a bag-ofwords vector indicating whether the user has consumed each item, assuming a multinomial distribution:</p><formula xml:id="formula_0">~ (0, ), ( ) ∝ exp{ ( )} ~ ( , ( ))<label>(1)</label></formula><p>Once the generative process is configured, it follows the typical Variational Autoencoder <ref type="bibr" target="#b13">[14]</ref> framework and attempts to maximize the marginal data likelihood P( ) = ∫ ( | ) ( ) . Since a Neural Network is used for the non-linear mapping (•), P( ) becomes intractable and the optimization becomes difficult.</p><p>The problem is solved by using amortized variational inference and optimizing per-datapoint the following Evidence Lower Bound (ELBO) <ref type="bibr" target="#b13">[14]</ref>:</p><formula xml:id="formula_1">log ( ; ) ≥ ( | ) [log ( | )] − KL ( ( | )|| ( )) ≡ ( ; , )<label>(2)</label></formula><p>with ( | ) a generative model (decoder) which is a neural network parameterized by , a prior distribution of latent variables ( ), and an approximation to the unknown posterior ( | ) with a recognition model (encoder) ( | ) also with neural networks. The Multi-VAE for CF <ref type="bibr" target="#b14">[15]</ref> additionally introduces a parameter ∈ [0,1] to scale the KL term similar to -VAE <ref type="bibr" target="#b2">[3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">ENHANCING VAES FOR CF</head><p>Variational Autoencoders have been extensively researched in the fields such as image generation and new advances have been proposed since its first appearance <ref type="bibr" target="#b13">[14]</ref>. One line of research analyzes the prior distribution of VAEs, suggesting that regular standard Gaussian priors can restrict the modeling performance <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b16">16]</ref>. However, the restrictive prior problem has not been researched in the field of recommender systems and our work is the first to apply flexible priors to variational autoencoders for collaborative filtering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Flexible Priors for Modeling User Preference</head><p>As in <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b16">16,</ref><ref type="bibr" target="#b25">25]</ref>, the ELBO objective can be further analyzed to be rewritten as the following:</p><formula xml:id="formula_2">( , , ) =~( ) [ ( | ) [log ( | )]] +~( ) [ℍ[ ( | )]] −~( ) [− log ( )]<label>(3)</label></formula><p>The first term is the negative reconstruction error while the second term is the expected entropy of the variational posterior, and the last component is the cross-entropy between the aggregated posterior ( ) = 1 ∑ ( | ) =1 and the prior.</p><p>We can see that the cross-entropy term pulls the distribution of the latent variables towards the prior, which is in the case of regular VAEs a standard Gaussian distribution chosen in advance. This can result in an unintended strong regularization effect due to the simple unimodal nature of the standard Gaussian distribution.</p><p>While the encoder tries to shape the aggregated posterior to match the prior distribution, there is no guarantee that a simple unimodal distribution will be a good match. Since modeling human preference is a complicated issue, we considered it plausible to relax the restrictive prior to investigate possible increase of recommendation quality in the context of collaborative filtering.</p><p>VampPrior. We experiment with a recently proposed flexible prior called the VampPrior (variational mixture of posteriors prior) <ref type="bibr" target="#b25">[25]</ref>. Revisiting equation <ref type="formula" target="#formula_2">(3)</ref>, we can see that only the cross-entropy term is associated with the prior ( ). If we find the optimal prior maximizing the ELBO by solving the Lagrange function it simply gives us the aggregated posterior * ( ) = 1 ∑ ( | ) <ref type="bibr">=1</ref> .</p><p>VampPrior <ref type="bibr" target="#b25">[25]</ref> is an approximation to this optimal prior using a mixture distribution of variational posteriors conditioned on K learnable pseudo-inputs:</p><formula xml:id="formula_3">( ) = 1 ∑ ( | ) =1<label>(4)</label></formula><p>where K(≪ N) is the number of M-dimensional pseudo-inputs . The pseudo-inputs are learned through backpropagation and can be thought of hyperparameters of the prior. Hierarchical Stochastic Units. We also adopt hierarchical stochastic units to learn even richer latent representations as in the original work of VampPriors <ref type="bibr" target="#b25">[25]</ref>. Hierarchical VAEs have been explored in different literatures <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b25">25]</ref> but have not been explored for collaborative filtering.</p><p>The original stochastic latent variable is replaced by a stacked hierarchical structure of 1 and 2 . The full Hierarchical Vamp-Prior VAE model is given as the follows. The variational part:</p><formula xml:id="formula_4">( 1 | , 2 ) ( 2 | )<label>(5)</label></formula><p>and the generative part:</p><formula xml:id="formula_5">( | 1 , 2 ) ( 1 | 2 ) ( 2 )<label>(6)</label></formula><p>where ( 2 ) is given as a VampPrior</p><formula xml:id="formula_6">( 2 ) = 1 ∑ ( 2 | ) =1</formula><p>and other conditional distributions are each modeled by neural networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Gating Mechanism</head><p>Preceding research using autoencoders for collaborative filtering make use of relatively shallow networks. Models in <ref type="bibr" target="#b23">[23,</ref><ref type="bibr" target="#b31">30]</ref> use encoder networks with no hidden layers. The encoder for Multi-VAE <ref type="bibr" target="#b14">[15]</ref> use 1 hidden layer and does not achieve additional performance gain by adding more layers. We anticipate two possible reasons for this; (1) the nature of the data, where we have to extract prefere-nce from sparse consumption history and (2) the relatively easily deepening autoencoder structure due to the encoder and decoder. Gated Linear Units. As the structure of Neural Networks get deeper and deeper, non-recurrent neural nets also have the problem of being unable to properly propagate information from the bottom layer to the top. We experiment with a non-recurrent gating mechanism proposed in Gated CNNs <ref type="bibr" target="#b3">[4]</ref> which was suggested to help information propagation in deeper networks: ℎ ( ) = ( * + ) ⊗ ( * + )</p><p>⊗ is the element-wise product with the input of the layer and , , , learned parameters, and the sigmoid function. As we can see from the formula, the gates attend to the past layer and react depending on the current input. This can also be interpreted as potentially increasing the network's modeling capacity to allow higher level interactions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>Experiments were conducted to evaluate the effect of flexible priors, hierarchical stochastic units and gating mechanisms in the context of collaborative filtering. Our proposed models are compar-ed to other state-of-the-art collaborative filtering models. The source code is available on GitHub (http://github.com/psywaves/EVCF).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Setup</head><p>Datasets. The Experiments were made on the MovieLens-20M and Netflix Prize dataset. Since we consider implicit feedback, we binarize both datasets by keeping only ratings of four or higher. Also, for both datasets we keep only users who have watched at least five movies.</p><p>Metrics. We evaluate performance based on two ranking-based metrics: Recall@K and truncated normalized discounted cumulative gain (NDCG@K). Recall@K considers all items ranked within the first K to be equally important, while NDCG@K uses a monotonically increasing discount to emphasize the importance of higher ranks versus lower ones <ref type="bibr" target="#b14">[15]</ref>.</p><p>Experimental settings. Models are evaluated under the strong generalization setting following <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b17">17]</ref>. All users are split into training/validation/test sets. The models are trained using the entire click history of the training set. During evaluation, we sample 80% of the click history from each user in the validation (or test) dataset as the "fold-in" set to calculate the necessary user-level representations and predict the remaining 20% of the click history.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Models</head><p>We use popular matrix factorization and state-of-the-art autoencoder models as baselines for comparison. WMF <ref type="bibr" target="#b12">[13]</ref>, SLIM <ref type="bibr" target="#b19">[19]</ref>, CDAE <ref type="bibr" target="#b31">[30]</ref> and Multi-VAE <ref type="bibr" target="#b14">[15]</ref> are chosen as baselines.</p><p>Our models to evaluate the effect of flexible priors, HVAE and gating are the following.</p><p>Vamp: Variational autoencoder with a VampPrior <ref type="bibr" target="#b25">[25]</ref> as the prior distribution instead of the original standard normal prior. We can compare with Multi-VAE <ref type="bibr" target="#b14">[15]</ref> to evaluate the effect of using flexible priors.</p><p>H + Vamp: Hierarchical VAE <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b25">25]</ref> with the VampPrior, the difference to the Vamp model is that it has hierarchical stochastic units to model the latent representation. All models are fully tuned by choosing hyperparameters with grid search on possible candidate values 1 . The number of components for the VampPrior was set to 1000. Also, while it was suggested in <ref type="bibr" target="#b14">[15]</ref> that multinomial likelihoods perform better for CF than binary cross-entropy, we found it was not always the case and used the better of the two for each model/dataset. Results of WMF <ref type="bibr" target="#b12">[13]</ref>, SLIM <ref type="bibr" target="#b19">[19]</ref> and CDAE <ref type="bibr" target="#b31">[30]</ref> were taken from <ref type="bibr" target="#b14">[15]</ref>. Note that our datasets and setup are consistent with <ref type="bibr" target="#b14">[15]</ref> for fair comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MovieLens 20M Netflix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Results</head><p>In this session, we first compare the performance results of our proposed models with the various baselines. We then further examine the effect of gating mechanisms by comparing performance of gated and ungated models of increasing depth.</p><p>Model performance. Quantitative results comparing performance are presented in <ref type="table">Table 1</ref>. Multi-VAE <ref type="bibr" target="#b14">[15]</ref> is the strongest baseline while Vamp, H+Vamp, H+Vamp (Gated) shows sequentially improving performance. Vamp shows significantly better performance compared to Multi-VAE, indicating the benefit of changing the restrictive standard normal prior to a flexible VampPrior. Our final model H + Vamp (Gated) shows the best performance and significantly outperforms the strongest baseline Multi-VAE <ref type="bibr" target="#b14">[15]</ref> for both datasets on all metrics. The final model shows up to 6.87% relative increase in recall@20 for the Netflix dataset producing new state-of-the-art results.</p><p>Effect of gating. We also conducted experiments to further study the effect of using gates. We present the results in ndcg@100 for the Netflix dataset in <ref type="table" target="#tab_3">Table 2</ref>. In this experiment the number of hidden units in each layer is fixed to 600 2 . A two layer model means that there are two hidden layers in each of the encoder and decoder.</p><p>We can see in <ref type="table" target="#tab_3">Table 2</ref> that for models with no gates, increasing the depth does not bring performance gain while for gated models it does. This can be interpreted that gating does help the network to propagate information through deeper models. However, we can also see large performance gains in simply adding the gates without additional layers. This tells us that the higher-level interactions the self-attentive gates allow are also very helpful themselves for modeling user preferences. One may point out that the gated model has more parameters, but note that ungated models cannot achieve similar performance by merely adding more units.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this paper, we extend the VAE for collaborative filtering to adopt flexible priors and gating mechanisms. We show empirically that standard Gaussian priors may limit the model capacity and introducing a more flexible prior can learn better representations of the user preference. We also show that gating mechanisms are suitable for user-item interaction data. Gates provide valuable modeling capacity as well as helping information propagate through deeper networks. Our final model incorporating Hierarchical VampPrior VAEs with GLUs produces new state-of-the-art results in the collaborative filtering literature.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 : Comparison of performance between Gated and Un- Gated for models of different depth 3 . The model with better performance (1 Layer vs 2 Layers) is marked in bold.</head><label>2</label><figDesc></figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Hyperparameters were selected using the validation set.<ref type="bibr" target="#b1">2</ref> All other hyperparameters except the number of layers were fixed as well.<ref type="bibr" target="#b2">3</ref> There was no additional performance gain for adding more hidden layers than two.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>Part of this work was done during internship at Kakao corporation, Republic of Korea.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Alemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">V</forename><surname>Dillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.00410</idno>
		<title level="m">Deep variational information bottleneck</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Fixing a Broken ELBO</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Saurous</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018-07" />
			<biblScope unit="page" from="159" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">P</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Matthey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Watters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Desjardins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerchner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.03599</idno>
		<title level="m">Understanding disentangling in $\beta $-VAE</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Language modeling with gated convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Grangier</surname></persName>
		</author>
		<ptr target="JMLR.org" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017-08" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="933" to="941" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Dieng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.04863</idno>
		<title level="m">Avoiding latent variable collapse with generative skip models</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dilokthanakul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Mediano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Garnelo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Salimbeni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Arulkumaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shanahan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.02648</idno>
		<title level="m">Deep unsupervised clustering with gaussian mixture variational autoencoders</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Nonparametric variational auto-encoders for hierarchical representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5094" to="5102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Neural collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on World Wide Web</title>
		<meeting>the 26th International Conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2017-04" />
			<biblScope unit="page" from="173" to="182" />
		</imprint>
	</monogr>
	<note>International World Wide Web Conferences Steering Committee</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hidasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karatzoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Baltrunas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tikk</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06939</idno>
		<title level="m">Session-based recommendations with recurrent neural networks</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Elbo surgery: yet another way to carve up the variational evidence lower bound</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop in Advances in Approximate Bayesian Inference, NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Unsupervised learning of disentangled and interpretable representations from sequential data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">N</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Glass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1878" to="1889" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Collaborative Filtering for Implicit Feedback Datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
		<imprint>
			<date type="published" when="2008-12" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="263" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<title level="m">Auto-encoding variational bayes</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Variational autoencoders for collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jebara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the</title>
		<meeting>the</meeting>
		<imprint>
			<date type="published" when="2018-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<title level="m">International World Wide Web Conferences Steering Committee</title>
		<imprint>
			<biblScope unit="page" from="689" to="698" />
		</imprint>
	</monogr>
	<note>World Wide Web Conference on World Wide Web</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Makhzani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Frey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.05644</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">Adversarial autoencoders. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Collaborative filtering: A machine learning perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Marlin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="2239" to="2239" />
			<pubPlace>Toronto</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Toronto</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Stick-breaking variational autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Nalisnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Smyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Slim: Sparse linear methods for topn recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Karypis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2011 IEEE 11th International Conference on Data Mining</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011-12" />
			<biblScope unit="page" from="497" to="506" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Personalizing session-based recommendations with hierarchical recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Quadrana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karatzoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hidasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cremonesi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh ACM Conference on Recommender Systems</title>
		<meeting>the Eleventh ACM Conference on Recommender Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017-08" />
			<biblScope unit="page" from="130" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Linked variational autoencoders for inferring substitutable and supplementary items</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Rakesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining</title>
		<meeting>the Twelfth ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019-01" />
			<biblScope unit="page" from="438" to="446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Sequential Variational Autoencoders for Collaborative Filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sachdeva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Manco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ritacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pudi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining</title>
		<meeting>the Twelfth ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019-01" />
			<biblScope unit="page" from="600" to="608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Autorec: Autoencoders meet collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sedhain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sanner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on World Wide Web</title>
		<meeting>the 24th International Conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015-05" />
			<biblScope unit="page" from="111" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Ladder variational autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Raiko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Maaløe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Winther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3738" to="3746" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">VAE with a VampPrior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tomczak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2018-03" />
			<biblScope unit="page" from="1214" to="1223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deep content-based music recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schrauwen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2643" to="2651" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Collaborative deep learning for recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">Y</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining</title>
		<meeting>the 21th ACM SIGKDD international conference on knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015-08" />
			<biblScope unit="page" from="1235" to="1244" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Irgan: A minimax game for unifying generative and discriminative information retrieval models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th International ACM SIGIR conference on Research and Development in Information Retrieval</title>
		<meeting>the 40th International ACM SIGIR conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017-08" />
			<biblScope unit="page" from="515" to="524" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Recurrent recommender networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Beutel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the tenth ACM international conference on web search and data mining</title>
		<meeting>the tenth ACM international conference on web search and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017-02" />
			<biblScope unit="page" from="495" to="503" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Collaborative denoising auto-encoders for top-n recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dubois</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">X</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth ACM International Conference on Web Search and Data Mining</title>
		<meeting>the Ninth ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016-02" />
			<biblScope unit="page" from="153" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Deep learning based recommender system: A survey and new perspectives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
