<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">An application of cascaded 3D fully convolutional networks for medical image segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2018-03-20">20 Mar 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><forename type="middle">R</forename><surname>Roth</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Nagoya University</orgName>
								<address>
									<addrLine>Furo-cho, Chikusa-ku</addrLine>
									<settlement>Nagoya</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hirohisa</forename><surname>Oda</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Nagoya University</orgName>
								<address>
									<addrLine>Furo-cho, Chikusa-ku</addrLine>
									<settlement>Nagoya</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangrong</forename><surname>Zhou</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Gifu University</orgName>
								<address>
									<settlement>Yanagido, Gifu</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natsuki</forename><surname>Shimizu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Nagoya University</orgName>
								<address>
									<addrLine>Furo-cho, Chikusa-ku</addrLine>
									<settlement>Nagoya</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Nagoya University</orgName>
								<address>
									<addrLine>Furo-cho, Chikusa-ku</addrLine>
									<settlement>Nagoya</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuichiro</forename><surname>Hayashi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Nagoya University</orgName>
								<address>
									<addrLine>Furo-cho, Chikusa-ku</addrLine>
									<settlement>Nagoya</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masahiro</forename><surname>Oda</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Nagoya University</orgName>
								<address>
									<addrLine>Furo-cho, Chikusa-ku</addrLine>
									<settlement>Nagoya</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michitaka</forename><surname>Fujiwara</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Nagoya University Graduate School of Medicine</orgName>
								<address>
									<settlement>Nagoya</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazunari</forename><surname>Misawa</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Aichi Cancer Center</orgName>
								<address>
									<addrLine>Chikusa-ku</addrLine>
									<settlement>Kanokoden, Nagoya</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kensaku</forename><surname>Mori</surname></persName>
							<email>kensaku@is.nagoya-u.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">Nagoya University</orgName>
								<address>
									<addrLine>Furo-cho, Chikusa-ku</addrLine>
									<settlement>Nagoya</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">An application of cascaded 3D fully convolutional networks for medical image segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2018-03-20">20 Mar 2018</date>
						</imprint>
					</monogr>
					<note type="submission">Preprint submitted to Computerized Medical Imaging and Graphics March 21, 2018</note>
					<note>$ 2018. This manuscript version is made available under the CC-BY-NC-ND 4.0 license http://creativecommons. org/licenses/by-nc-nd/4.0/ 1 Our code and trained models are available for download: github.com/holgerroth/3Dunet_abdomen_cascade</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T05:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>fully convolutional networks</term>
					<term>deep learning</term>
					<term>medical imaging</term>
					<term>computed tomography</term>
					<term>multi-organ segmentation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent advances in 3D fully convolutional networks (FCN) have made it feasible to produce dense voxel-wise predictions of volumetric images. In this work, we show that a multi-class 3D FCN trained on manually labeled CT scans of several anatomical structures (ranging from the large organs to thin vessels) can achieve competitive segmentation results, while avoiding the need for handcrafting features or training class-specific models.</p><p>To this end, we propose a two-stage, coarse-to-fine approach that will first use a 3D FCN to roughly define a candidate region, which will then be used as input to a second 3D FCN. This reduces the number of voxels the second FCN has to classify to ∼10% and allows it to focus on more detailed segmentation of the organs and vessels.</p><p>We utilize training and validation sets consisting of 331 clinical CT images and test our models on a completely unseen data collection acquired at a different hospital that includes 150 CT scans, targeting three anatomical organs (liver, spleen, and pancreas). In challenging organs such as the pancreas, our cascaded approach improves the mean Dice score from 68.5 to 82.2%, achieving the highest reported average score on this dataset. We compare with a 2D FCN method on a separate dataset of 240 CT scans with 18 classes and achieve a significantly higher performance in small organs and vessels. Furthermore, we explore fine-tuning our models to different datasets.</p><p>Our experiments illustrate the promise and robustness of current 3D FCN based semantic segmentation of medical images, achieving state-of-the-art results. 1 .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Recent advances in fully convolutional networks (FCN) have made it feasible to train models for pixel-wise segmentation in an end-to-end fashion <ref type="bibr" target="#b18">(Long et al., 2015)</ref>. Efficient implementations of 3D convolution and growing GPU memory have made it possible to extent these methods to 3D medical imaging and train networks on large amounts of annotated volumes. One such example is the recently proposed 3D U-Net <ref type="bibr">(Ç içek et al., 2016)</ref>, which applies a 3D FCN with skip connections to sparsely annotated biomedical images. Alternative architectures for processing volumetric images have also been successfully applied to 3D medical image segmentation <ref type="bibr" target="#b19">(Milletari et al., 2016;</ref><ref type="bibr" target="#b2">Chen et al., 2016;</ref><ref type="bibr" target="#b6">Dou et al., 2017)</ref>. In this work, we show that a 3D FCN, like 3D U-Net, trained on manually labeled data of several anatomical structures (ranging from the large organs to thin vessels) can also achieve competitive segmentation results on clinical CT images, very different from the original application of 3D U-Net using confocal microscopy images. We furthermore compare our approach to 2D FCNs applied to the same images.</p><p>Our approach applies 3D FCN architectures to problems of multi-organ and vessel segmentation in a cascaded fashion. A FCN can be trained on whole 3D CT scans. However, because of the high imbalance between background and foreground voxels (organs, vessels, etc.) the network will concentrate on differentiating the foreground from the background voxels in order to minimize the loss function used for training. While this enables the FCN to roughly segment the organs, it causes particularly smaller organs (like the pancreas or gallbladder) and vessels to suffer from inaccuracies around their boundaries.</p><p>To overcome this limitation, we learn a second-stage FCN in a cascaded manner that focuses more on the boundary regions. This is a coarse-to-fine approach in which the first-stage FCN sees around 40% of the voxels using only a simple automatically generated mask of the patient's body. In the second stage, the amount of the image's voxels is further reduced to around 10%. In effect, this step narrows down and simplifies the search space for the FCN to decide which voxels belong to the background or any of the foreground classes; this strategy has been successful in many computer vision problems <ref type="bibr" target="#b33">(Viola and Jones, 2004;</ref><ref type="bibr" target="#b16">Li et al., 2016)</ref>. Our approach is illustrated on a training example in <ref type="figure">Fig. 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Related work</head><p>Multi-organ segmentation has attracted considerable interest over the years. Classical approaches include statistical shape models <ref type="bibr" target="#b1">(Cerrolaza et al., 2015;</ref><ref type="bibr" target="#b21">Okada et al., 2015)</ref>, and/or employ techniques based on image registration. So called multi-atlas label fusion <ref type="bibr" target="#b24">(Rohlfing et al., 2004;</ref><ref type="bibr" target="#b34">Wang et al., 2013;</ref><ref type="bibr" target="#b9">Iglesias and Sabuncu, 2015)</ref> has found wide application in clinical research and practice. Approaches that combine techniques from multi-atlas registration and machine learning are also common place and have been successfully applied to multi-organ segmentation in abdominal imaging <ref type="bibr" target="#b32">(Tong et al., 2015;</ref><ref type="bibr" target="#b20">Oda et al., 2016)</ref>. However, a fundamental disadvantage of image registration based methods is there extensive computational cost <ref type="bibr" target="#b9">(Iglesias and Sabuncu, 2015)</ref>. Typical methods need hours of computation time in order to complete on single desktop machines <ref type="bibr" target="#b36">(Wolz et al., 2013)</ref>.</p><p>The recent success of deep learning based classification and segmentation methods are now transitioning to applications of multi-class segmentation in medical imaging. Recent examples of deep learning applied to organ segmentation include <ref type="bibr" target="#b30">(Roth et al., 2017;</ref><ref type="bibr" target="#b39">Zhou et al., 2016b;</ref><ref type="bibr" target="#b3">Christ et al., 2016;</ref><ref type="bibr" target="#b37">Zhou et al., 2016a)</ref>. Many methods focus on the segmentation of single organs like prostate <ref type="bibr" target="#b19">(Milletari et al., 2016)</ref>, liver <ref type="bibr" target="#b3">(Christ et al., 2016)</ref>, or pancreas <ref type="bibr" target="#b28">(Roth et al., 2015</ref><ref type="bibr" target="#b29">(Roth et al., , 2016b</ref>.</p><p>Multi-organ segmentation in abdominal CT has also been approached by works like <ref type="bibr" target="#b7">Gibson et al., 2017)</ref>. Most methods are based on variants of FCNs <ref type="bibr" target="#b18">(Long et al., 2015)</ref> that either employ 2D convolutional layers in a slice-by-slice fashion <ref type="bibr" target="#b29">Roth et al. (2016b)</ref>; <ref type="bibr" target="#b39">Zhou et al. (2016b)</ref>; <ref type="bibr" target="#b3">Christ et al. (2016)</ref>; <ref type="bibr" target="#b37">Zhou et al. (2016a)</ref>, 2D convolutions on orthogonal (2.5D) cross-sections <ref type="bibr" target="#b28">(Roth et al., 2015;</ref><ref type="bibr" target="#b23">Prasoon et al., 2013)</ref>, and 3D convolutional layers <ref type="bibr" target="#b19">(Milletari et al., 2016;</ref><ref type="bibr" target="#b2">Chen et al., 2016;</ref><ref type="bibr" target="#b6">Dou et al., 2017;</ref><ref type="bibr" target="#b13">Kamnitsas et al., 2017)</ref>. A common feature of these novel segmentation methods is that they are able to extract the features useful for image segmentation directly from the training imaging data, which is crucial for the success of deep learning <ref type="bibr" target="#b15">(LeCun et al., 2015)</ref>. This avoids the need for hand-crafting features that are suitable for detection of individual organs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Contributions</head><p>Due to the automatic learning of image feature and in contrast to previous approaches of multiorgan segmentation where separate models have to be created for each organ <ref type="bibr" target="#b20">(Oda et al., 2016;</ref><ref type="bibr" target="#b32">Tong et al., 2015)</ref>, our proposed method allows us to use the same model to segment very different anatomical structures such as large abdominal organs (liver, spleen), but also vessels like arteries and veins. Furthermore, other recent FCN-based methods that applied in medical imaging in cascaded/iterative fashion were often constrained to using rectangular bounding boxes around single organs <ref type="bibr" target="#b30">(Roth et al., 2017;</ref><ref type="bibr" target="#b39">Zhou et al., 2016b)</ref> and/or performing slice-wise processing in 2D <ref type="bibr" target="#b3">(Christ et al., 2016;</ref><ref type="bibr" target="#b37">Zhou et al., 2016a)</ref>.</p><p>Figure 1: Cascaded 3D fully convolutional networks in a coarse-to-fine approach: the first stage (left) learns the generation of a candidate region for training a second-stage FCN (right) for finer prediction. Outlined red area shows candidate region C 1 used in first stage and C 2 used in second stage. Colored regions denote ground truth annotations for training (best viewed in color).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Methods</head><p>Convolutional neural networks have the ability to solve challenging classification tasks in a datadriven manner. Given a training set of images and labels S = {(I n , L n ), n = 1, . . . , N }, I n denotes the raw CT images and L n denotes the ground truth label images. Each L n contains K class labels consisting of the manual segmentations of the foreground anatomy (e.g. artery, portal vein, lungs, liver, spleen, stomach, gallbladder, and pancreas) and the background for each voxel in the CT image. Our employed network architecture is the 3D extension by Ç içek et al. (2016) of the U-Net proposed by <ref type="bibr" target="#b25">Ronneberger et al. (2015)</ref>. U-Net, which is a type of fully convolutional network (FCN) <ref type="bibr" target="#b18">(Long et al., 2015)</ref> was originally proposed for bio-medical image applications, utilizes deconvolution <ref type="bibr" target="#b18">(Long et al., 2015)</ref> (or sometimes called up-convolutions <ref type="bibr">(Ç içek et al., 2016)</ref>) to remap the lower resolution feature maps within the network to the denser space of the input images. This operation allows for denser voxel-to-voxel predictions in contrast to previously proposed sliding-window CNN methods where each voxel under the window is classified independently making such architecture inefficient for processing large 3D volumes. In 3D U-Net, operations such as 2D convolution, 2D max-pooling, and 2D deconvolution are replaced by their 3D counterparts <ref type="bibr">(Ç içek et al., 2016)</ref>. We use the open-source implementation of 3D U-Net 2 based on the Caffe deep learning library <ref type="bibr" target="#b11">(Jia et al., 2014)</ref>. The 3D U-Net architecture consists of analysis and synthesis paths with four resolution levels each. Each resolution level in the analysis path contains two 3 × 3 × 3 convolutional layers, each followed by rectified linear units (ReLU) and a 2 × 2 × 2 max pooling with strides of two in each dimension. In the synthesis path, the convolutional layers are replaced by deconvolutions of 2 × 2 × 2 with strides of two in each dimension. These are followed by two 3 × 3 × 3 convolutions, each of which has a ReLU. Furthermore, 3D U-Net employs shortcut (or skip) connections from layers of equal resolution in the analysis path to provide higher-resolution features to the synthesis path <ref type="bibr">(Ç içek et al., 2016)</ref>. The last layer contains a 1 × 1 × 1 convolution that reduces the number of output channels to the number of class labels K. This architecture has over 19 million learnable parameters and can be trained to minimize a weighted voxel-wise cross-entropy loss <ref type="bibr">(Ç içek et al., 2016)</ref>. A schematic illustration of 3D U-Net is shown in <ref type="figure" target="#fig_0">Fig. 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Loss function: adjustments for multi-organ segmentation</head><p>The voxel-wise cross-entropy loss is defined as</p><formula xml:id="formula_0">L = −1 N K k=1   x∈S k log (p k (x))   ,<label>(1)</label></formula><p>wherep k are the softmax class probabilitieŝ</p><formula xml:id="formula_1">p k (x) = exp(x k (x)) K k =1 exp(x k (x)) ,<label>(2)</label></formula><p>N are the total number of voxels x, S k is the set of voxels within one class in L n , and k ∈ [1, 2, . . . , K] indicates the ground truth class label. The input to this loss function is real valued output predictions x ∈ [−∞, +∞] from the last convolutional layer. However, in most cases minimizing this loss will instantly make the network converge to classifying every voxel as background. This is because of the large dominance of the background class in the images. In order to combat this large data imbalance between foreground/background voxels and differently sized organs and vessels, we apply a voxel-wise weight λ k to this loss function (Eq. 1). In this work, we choose λ i such that  This results in a smaller output size than input size and requires cropping of when mapping lower level feature maps of the analysis path to the synthesis path of the network via concatenation (Concat). Max-pooling (Max pool) is used to reduce the resolution of feature maps, while up-convolutions (Up-conv ) are used for up-sampling the feature maps back to higher resolutions. The number of extracted feature maps is noted above each layer. We show the input and output size of feature maps at each level of the network. These parameters are kept constant for all experiments performed in this study. Batch normalization (BatchNorm) is used throughout the network for improved convergence <ref type="bibr" target="#b10">(Ioffe and Szegedy, 2015)</ref>.</p><formula xml:id="formula_2">K k=1 λ k = 1, with λ k = 1 − N k /N C K − 1 ,<label>(3)</label></formula><p>where N k is the number of voxels in each class S k , and N C is the number of voxels within a candidate region C 1 or C 2 . The weights λ i help to balance the common voxels (i.e., background) with respect to such smaller organs as vessels or the pancreas by giving more weight to the latter. Now, the weighted cross-entropy loss can be written as:</p><formula xml:id="formula_3">L = −1 N K k=1 λ k   x∈S k log (p k (x))   ,<label>(4)</label></formula><p>We use the loss formulation in Eq. 4 for all experiments in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Coarse-to-fine prediction</head><p>In our experiments, the input to the network is fixed to a given size N x × N y × N z , mainly influenced by considerations of available memory size on the GPU. In training, sub-volumes of that given size are randomly sampled from the candidate regions within the training CT images, as described below. To increase the field of view presented to the CNN and reduce informative redundancy among neighboring voxels, each image is downsampled by a factor of 2. The resulting prediction maps are then resampled back to the original resolution using nearest neighbor interpolation (or linear interpolation in case of the probability maps).</p><p>1 st Stage. In the first stage, we apply simple thresholding in combination with morphological operations (hole filling and largest component selection) to get a mask of the patient's body. This mask can be utilized as candidate region C 1 to reduce the number of voxels necessary to compute the network's loss function and reduce the amount of input 3D regions shown to the CNN during training to about 40%.</p><p>2 nd Stage. After training the first-stage FCN, it is applied to each image to generate candidate regions C 2 for training the second-stage FCN (see <ref type="figure">Fig. 1</ref>). We define the predicted organ labels in the testing phase using the argmax of the class probability maps. All foreground labels are then dilated in 3D using a voxel radius of r in order to compute C 2 , resulting in a binary candidate map.</p><p>When comparing the recall and false-positive rates of the first-stage FCN with respect to r for both the training and validation sets, r = 3 gives good trade-off between high recall (&gt;99%) and low false-positive rates (∼10%) for each organ on our training and validation sets (see <ref type="figure" target="#fig_4">Fig. 6</ref>).</p><p>Our overall multi-stage training scheme is illustrated in <ref type="figure" target="#fig_1">Fig. 3</ref> Images,  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Training</head><p>The network iteratively adjusts its parameters by stochastic gradient descent. Batch normalization is used throughout the network for improved convergence and we utilize random elastic deformations in 3D during training to artificially increase the amount of available data samples and increase robustness, similar to <ref type="bibr">(Ç içek et al., 2016)</ref>. Hence, we randomly sample deformation fields from a uniform distribution with a maximum displacement of ±4 and a grid spacing of 32 voxels (see <ref type="figure" target="#fig_2">Fig. 4</ref>). Furthermore, we applied random rotations between −5 • and +5 • , and translations of -20 to 20 voxels in each direction at each iteration in order to generate plausible deformations during training. Each training sub-volume is randomly extracted from C 1 or C 2 in both stages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Testing</head><p>The CT image is processed by the 3D FCN using a tiling strategy (sliding-window) <ref type="bibr">(Ç içek et al., 2016)</ref> as illustrated in <ref type="figure" target="#fig_3">Fig. 5</ref>. For greater speed, we use non-overlapping tiles in the first stage and investigate the use of non-overlapping and overlapping tiles in the second. When using overlapping tiles (with a 4× higher sampling rate of each voxel x), the resulting probabilities for the overlapping voxels are averaged:  </p><formula xml:id="formula_4">p(x) = 1 R R r=1 pr(x).<label>(5)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiments &amp; Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Training and validation</head><p>Our dataset includes 331 contrast-enhanced abdominal clinical CT images in the portal venous phase used for pre-operative planning in gastric surgery. Each CT volume consists of 460 − 1177 slices of 512 × 512 pixels. The voxel dimensions are [0.59-0.98, 0.59-0.98, 0.5-1.0] mm. A random split of 281/50 patients is used for training and validating the network, i.e., determining when to stop training to avoid overfitting. In order to generate plausible deformations during training, we sample from a normal distribution with a standard derivation of 4 and a grid spacing of 32 voxels, and apply random rotations between −5 • and +5 • to the training images. No deformations were applied during testing. We trained 200,000 iterations in the first stage and 115,000 in the second. <ref type="table" target="#tab_2">Table 1</ref> summarizes the Dice similarity scores for each organ labeled in the 50 validation cases. On average, we achieved a 7.5% improvement in Dice scores per organ. Small, thin organs such as arteries especially benefit from our two-stage cascaded approach. For example, the mean Dice score for arteries improved from 59.0 to 79.6% and from 54.8 to 63.1% for the pancreas. The effect is less pronounced for large organs, like the liver, the spleen, and the stomach. <ref type="figure" target="#fig_5">Fig. 7</ref> shows an example result from the validation set and illustrates the tiling approach. The 3D U-Net separates the foreground organs well from the background tissue of the images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Testing</head><p>Our test set is different from our training and validation data. It originates from a different hospital, scanners, and research study with gastric cancer patients. 150 abdominal CT scans were acquired in the portal venous phase. Each CT volume consists of 263 − 1061 slices of 512 × 512 pixels. Voxel dimensions are [0.55-0.82, 0.55-0.82, 0.4-0.80] mm. The pancreas, liver, and spleen  were semi-automatically delineated by three trained researchers and confirmed by a clinician. <ref type="figure" target="#fig_6">Figure  8</ref> shows surface renderings for comparison of the different stages of the algorithm. A typical testing case in the first and second stages is shown using non-overlapping and overlapping tiles. Dice similarity scores are listed in <ref type="table" target="#tab_3">Table 2</ref>. The second stage achieves the highest reported average score for pancreas in this dataset with 82.2% ±10.2%. Previous state of the art on this dataset was at 75.1% ±15.4% while using leave-one-out-validation <ref type="bibr" target="#b20">(Oda et al., 2016)</ref>. The testing dataset provides slightly higher image quality than our training/validation dataset. Furthermore, its field of view is more constrained to the upper abdomen. This likely explains the improved performance for liver and pancreas compared to the validation set in <ref type="table" target="#tab_2">Table 1</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Comparison to other methods</head><p>Even though direct comparison is difficult due to the differences in datasets, training/testing evaluation schemes, and segmented organs, we try to indicate how well our model performed with respect to recent state-of-the-art methods in <ref type="table">Table 3</ref>. In particualar, we provide a comparison to recent methods on two different datasets: (1) our own in-house dataset for pancreas segmentation, acquired at Nagoya University Hospital, Japan, and consisting of 150 CT images; and (2) the publicly available TCIA Pancreas-CT dataset of 82 patient images 3 <ref type="bibr" target="#b26">(Roth et al., 2016a)</ref>. For comparison with (2), we use the same 4-fold cross-validation (CV) split as in <ref type="bibr" target="#b28">(Roth et al., 2015</ref><ref type="bibr" target="#b30">(Roth et al., , 2017</ref>.</p><p>Our results on dataset (1) achieves the highest reported performance in testing. On the other hand, our results on the public dataset (2) are comparable to other recent works that developed methods especially targeting this dataset and focusing on pancreas segmentation alone <ref type="bibr" target="#b30">(Roth et al., 2017;</ref><ref type="bibr" target="#b39">Zhou et al., 2016b)</ref>. <ref type="table">Table 3</ref>: Comparison to other methods. We list other recent segmentation work performed on the same/similar datasets and organs and based on atlas-based segmentation propagation using global affine <ref type="bibr" target="#b35">(Wang et al., 2014)</ref>, local non-rigid registration methods <ref type="bibr" target="#b36">(Wolz et al., 2013)</ref> and in combination with machine learning (ML) <ref type="bibr" target="#b32">(Tong et al., 2015)</ref>. We also list a method using regression forest (RF) and graph cut (GC) <ref type="bibr" target="#b20">(Oda et al., 2016)</ref>, and two other methods utilizing 2D FCNs <ref type="bibr" target="#b30">(Roth et al., 2017;</ref><ref type="bibr" target="#b39">Zhou et al., 2016b)</ref>. Validation of other methods was performed using either leave-one-out-validation (LOOV) or cross-validation(CV). Best performance is shown in bold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Subjects </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Direct comparison to 2D FCN networks</head><p>Furthermore, we implement the method of Zhou et al. <ref type="bibr" target="#b37">(Zhou et al., 2016a</ref><ref type="bibr" target="#b38">(Zhou et al., , 2017</ref> and apply it to the same dataset. This method employs a combination of three 2D FCNs trained on the orthogonal planes of the images. The results of each model are then fused by majority voting. This dataset consists of 240 3D CT scans with 18 manually annotated organs. A split of 228/12 cases was used for our training/testing as in <ref type="bibr" target="#b37">(Zhou et al., 2016a</ref><ref type="bibr" target="#b38">(Zhou et al., , 2017</ref>. A direct comparison can be seen in <ref type="table">Table 4</ref>. It can be observed that our 3D FCN approach has a clear advantage for the smaller, thinner organs (like aorta, esophagus, gallbladder, inferior vena cava, portal vein, and prostate) but only performs comparable to the 2D FCNs when aiming at the larger organs (like lungs, liver, kidneys). Furthermore, a slightly higher overall performance can be observed for the average of all organ/vessel predictions when using the proposed cascaded 3D FCN approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Computation</head><p>Training on 281 cases can take 2-3 days for 200-k iterations on a NVIDIA GeForce GTX TITAN X with 12 GB memory. However, in testing, the processing time for each volume was 1.4-3.3 minutes for each stage, depending on the size of the candidate regions; and 1.6-4.4 minutes using overlapping tiles in the second stage. In order to achieve optimal GPU memory usage in training, we keep the input subvolume size at N x × N y × N z = 132 × 132 × 116, resulting in an output size of 44 × 44 × 28 for each class output channel as in <ref type="bibr">(Ç içek et al., 2016)</ref>. <ref type="table">Table 4</ref>: Direct comparison of the proposed cascaded 3D FCN approach against a 2D FCN approach using a majority voting scheme as in <ref type="bibr" target="#b37">(Zhou et al., 2016a</ref><ref type="bibr" target="#b38">(Zhou et al., , 2017</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Fine-tuning to other datasets</head><p>One advantage of deep learning based models is their ability to transfer learned features across dataset domains <ref type="bibr" target="#b31">(Shin et al., 2016)</ref>. To this end, we trained a general FCN model employing the 3D U-Net architecture <ref type="bibr">(Ç içek et al., 2016)</ref> on the large dataset of CT scans including the major abdominal organ labels of Section 3.1. This model can then be fine-tuned to other (smaller) datasets aiming at more detailed classification tasks or different field of views. For this purpose, we utilize separate training, fine-tuning, and testing datasets. As mentioned above, the general training set consists of 280 clinical CT images with seven abdominal structures <ref type="bibr">(artery, vein, liver, spleen, stomach, gallbladder, and pancreas)</ref> labeled.</p><p>We then fine-tune on a much smaller dataset consisting only of 20 contrast enhanced CT images from the Visceral Challenge dataset 4 (Jimenez-del <ref type="bibr" target="#b12">Toro et al., 2016)</ref>, but with substantially more anatomical structures labeled in each image (20 in total). This fine-tuning process across different datasets is illustrated in <ref type="figure">Fig. 9</ref> with some ground truth label examples used for pre-training and fine-tuning. In fine-tuning, we use a 10 times smaller learning rate. We furthermore test our models on a completely unseen data collection of 10 torso CT images with 8 labels, including organs that were not labeled in the original abdominal dataset, e.g. the kidneys and lungs. A probabilistic output for kidney (not in the pre-training dataset) from our model is shown in <ref type="figure">Fig. 10</ref>.</p><p>Transfer learning <ref type="bibr">(a)</ref> (b) <ref type="figure">Figure 9</ref>: We fine-tune our model via transfer learning from 8 anatomical structures in the abdomen (a) to 20 anatomical structures in the whole torso (b). We show some typical ground truth labels that are used for training on both datasets. <ref type="figure">Figure 10</ref>: Automated probability map for left kidney after transfer learning. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Fine-tuning results</head><p>In testing, we deploy our fine-tuned model using a non-overlapping tiling approach as in previous sections. An automated segmentation result on the unseen test dataset by our fine-tuned model is shown in <ref type="figure" target="#fig_7">Fig. 11</ref>. Our fine-tuned approach provides a Dice score of right lung, left lung, liver, gall bladder, spleen, right kidney, left kidney, and pancreas are 0.96, 0.97, 0.95, 0.77, 0.90, 0.90, 0.88, and 0.36, respectively (summarized in <ref type="table" target="#tab_6">Table 5</ref>). The relatively lower score for pancreas is due to several outlier cases on this dataset. These outliers are likely caused by variations of contrast enhancement across the datasets and the higher variability of the pancreas shape and intensity profile compared to other organs across different patients.</p><p>Our approach and results, however, illustrate the generalizability and robustness of our models across different datasets. Fine-tuning can be useful when the amount of training examples for some target organs are limited. In this case, transfer learning achieves slight improvements over learning from scratch, especially in the kidneys (see <ref type="table" target="#tab_6">Table 5</ref>). It should be noted that for this particular application, data augmentation already gives a good performance when learning models from scratch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Discussion</head><p>The cascaded coarse-to-fine approach presented in this paper provides a simple yet effective method for employing 3D FCNs in medical imaging settings. No post-processing was applied to any of the FCN outputs. The improved performance stemming from our cascaded approach is especially visible in smaller, thinner organs, such as arteries and veins, particularly when compared to other recent FCN approaches using 2D FCNs <ref type="bibr" target="#b37">(Zhou et al., 2016a)</ref>. Our results and recent literature indicate that 2D FCNs and especially the combination of orthogonally applied 2D FCNs <ref type="bibr" target="#b37">(Zhou et al., 2016a;</ref><ref type="bibr" target="#b30">Roth et al., 2017;</ref><ref type="bibr" target="#b39">Zhou et al., 2016b)</ref> might be sufficient for larger and midsized organs. In fact, the combination of 2D FCNs even slightly outperforms our 3D approach for some organs. On the other hand 3D convolutional kernels are important for distinguishing the thin (vessel-like) and small organs as can be seen in the improved performance of our approach. When compared to other cascaded approaches using 2D FCNs that focus on single organs <ref type="bibr" target="#b30">(Roth et al., 2017;</ref><ref type="bibr" target="#b39">Zhou et al., 2016b)</ref>, we perform similar to the state of the art. Our findings are also consistent with <ref type="bibr" target="#b30">(Roth et al., 2017;</ref><ref type="bibr" target="#b39">Zhou et al., 2016b</ref>) that show that cascaded approaches are useful for applying deep learning methods to medical image segmentation. Note that we used different datasets (from different hospitals and scanners) for separate training/validation and testing. These experiments illustrate our method's generalizability and robustness to differences in image quality and populations. Running the algorithms at half resolution allows efficient training on a single GPU. In contrast, using the same field of view for each subvolume with the original resolution would require 8× more memory with the current architecture and would force us to reduce the amount of context visible to the 3D FCNs. In this work, we utilized 3D U-Net for the segmentation of CT scans. However, the proposed cascaded approach in principle should also work well for other 3D CNN/FCN architectures and 3D image modalities. Exploration of other loss functions such as the Dice score <ref type="bibr" target="#b19">(Milletari et al., 2016;</ref><ref type="bibr" target="#b17">Li et al., 2017)</ref> could help further in dealing with the class imbalance issue. We used Caffe's stochastic gradient descent solver <ref type="bibr" target="#b11">(Jia et al., 2014)</ref> for all experiments in this work. Alternative optimizers could further improve training performance <ref type="bibr" target="#b14">(Kingma and Ba, 2014)</ref>.</p><p>In the future, prediction results from different models could be combined in order to achieve the best overall performance. Furthermore, additional anatomical constraints could be included in order to guarantee topologically correct segmentation results <ref type="bibr" target="#b0">(BenTaieb and Hamarneh, 2016;</ref><ref type="bibr" target="#b22">Oktay et al., 2017)</ref>. With growing amounts of available GPU memory, the need for computing overlapping sub-volume predictions as in this work will be reduced as it will be come possible to reshape the network to accept arbitrary 3D input image sizes <ref type="bibr" target="#b18">(Long et al., 2015)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In conclusion, we showed that a cascaded deployment of volumetric fully convolutional networks (3D U-Net) can produce competitive results for medical image segmentation on a clinical CT dataset while being efficiently deployed on a single GPU. An overlapping tiles approach during testing produces better results with only moderate additional computational cost. The proposed method compares favorably to recent state-of-the-art work on a completely unseen dataset. Our results indicate that 3D convolutional features are advantageous for detecting smaller organs and vessel. A promising future direction might be hybrid approaches that combine 2D and 3D FCN-type architectures at multiple scales. We have made our code, pre-trained models, and fine-tuned models available for download 5 in order to allow further applications and fine-tuning to different datasets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>The architecture of 3D U-Net (Ç içek et al., 2016), a type of fully convolutional network. It applies an end-to-end architecture using only valid convolutions (Conv ) with no padding and kernel sizes of 3 × 3 × 3. Rectified Linear units (ReLU ) are used as activation functions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Flowchart of our multi-stage cascaded training scheme.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Axial cross-section through the same patient CT image at various examples of plausible random deformation during training. A deformed grid pattern is overlaid in order to better illustrate the applied deformation. At each iteration, the random deformation is computed on the fly.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>The non-overlapping tiling approach on second stage candidate region C 2 . Note that the grid shows the output tiles of size 44 × 44 × 28 (x, y, z-directions). Each predicted tile is based on a larger input of 132 × 132 × 116 that the network processes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Sensitivity and false-positive-rate (FPR) as a function of dilating prediction maps of first stage in training (a) and validation (b). We observe good trade-off between high sensitivity (&gt;99% on average) and low false-positiverate (∼10% on average) at dilation radius of r = 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Example of the validation set with (a) ground truth and (b) the corresponding non-overlapping (N/OL) segmentation result. The posterior to anterior view is shown to visualize the inner organs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Surface renderings: (a) ground truth segmentation, (b) result of proposed method in first stage, secondstage results using (c) non-overlapping (N/OL), and (d) overlapping (OL) tiles strategy. The posterior to anterior view is shown for better visualization of the pancreas.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 11 :</head><label>11</label><figDesc>Multi-organ segmentation result. Each color represents an organ region on the unseen whole torso test set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Validation set: Dice similarity score [%] of different stages of FCN processing</figDesc><table><row><cell cols="3">Stage 1: Non-overlapping</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Dice</cell><cell>artery</cell><cell>vein</cell><cell>liver</cell><cell>spleen</cell><cell>stomach</cell><cell>gallbladder</cell><cell>pancreas</cell><cell>Mean</cell></row><row><cell>Mean</cell><cell>59.0</cell><cell>64.7</cell><cell>89.6</cell><cell>84.1</cell><cell>80.0</cell><cell>69.6</cell><cell>54.8</cell><cell>71.7</cell></row><row><cell>Std</cell><cell>7.8</cell><cell>8.6</cell><cell>1.7</cell><cell>4.7</cell><cell>18.3</cell><cell>14.1</cell><cell>11.0</cell><cell>9.5</cell></row><row><cell>Median</cell><cell>59.8</cell><cell>67.3</cell><cell>90.0</cell><cell>85.2</cell><cell>87.5</cell><cell>73.2</cell><cell>57.2</cell><cell>74.3</cell></row><row><cell>Min</cell><cell>41.0</cell><cell>34.5</cell><cell>84.4</cell><cell>70.9</cell><cell>8.4</cell><cell>13.8</cell><cell>23.5</cell><cell>39.5</cell></row><row><cell>Max</cell><cell>75.7</cell><cell>76.0</cell><cell>92.6</cell><cell>91.4</cell><cell>94.8</cell><cell>86.8</cell><cell>72.0</cell><cell>84.2</cell></row><row><cell cols="3">Stage 2: Non-overlapping</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Dice</cell><cell>artery</cell><cell>vein</cell><cell>liver</cell><cell>spleen</cell><cell>stomach</cell><cell>gallbladder</cell><cell>pancreas</cell><cell>Mean</cell></row><row><cell>Mean</cell><cell>79.6</cell><cell>73.1</cell><cell>93.2</cell><cell>90.6</cell><cell>84.3</cell><cell>70.6</cell><cell>63.1</cell><cell>79.2</cell></row><row><cell>Std</cell><cell>6.5</cell><cell>7.9</cell><cell>1.5</cell><cell>2.8</cell><cell>17.3</cell><cell>15.9</cell><cell>10.7</cell><cell>8.9</cell></row><row><cell>Median</cell><cell>82.3</cell><cell>74.6</cell><cell>93.5</cell><cell>91.2</cell><cell>90.9</cell><cell>77.3</cell><cell>64.5</cell><cell>82.1</cell></row><row><cell>Min</cell><cell>62.9</cell><cell>33.3</cell><cell>88.9</cell><cell>82.3</cell><cell>10.9</cell><cell>13.0</cell><cell>32.4</cell><cell>46.2</cell></row><row><cell>Max</cell><cell>87.0</cell><cell>83.2</cell><cell>95.6</cell><cell>95.1</cell><cell>96.3</cell><cell>89.4</cell><cell>81.8</cell><cell>89.8</cell></row><row><cell cols="2">Stage2 vs Stage1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Dice</cell><cell>artery</cell><cell>vein</cell><cell>liver</cell><cell>spleen</cell><cell>stomach</cell><cell>gallbladder</cell><cell>pancreas</cell><cell>Mean</cell></row><row><cell>Mean</cell><cell>20.61</cell><cell>8.41</cell><cell>3.60</cell><cell>6.42</cell><cell>4.22</cell><cell>0.93</cell><cell>8.26</cell><cell>7.49</cell></row><row><cell>Std</cell><cell>-1.24</cell><cell>-0.68</cell><cell>-0.18</cell><cell>-1.97</cell><cell>-0.97</cell><cell>1.78</cell><cell>-0.35</cell><cell>-0.52</cell></row><row><cell>Median</cell><cell>22.57</cell><cell>7.34</cell><cell>3.42</cell><cell>6.00</cell><cell>3.44</cell><cell>4.15</cell><cell>7.31</cell><cell>7.75</cell></row><row><cell>Min</cell><cell>21.83</cell><cell>-1.20</cell><cell>4.47</cell><cell>11.35</cell><cell>2.44</cell><cell>-0.75</cell><cell>8.85</cell><cell>6.71</cell></row><row><cell>Max</cell><cell>11.28</cell><cell>7.21</cell><cell>3.06</cell><cell>3.70</cell><cell>1.52</cell><cell>2.67</cell><cell>9.74</cell><cell>5.60</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Testing on unseen dataset: Dice similarity score [%] of different stages of FCN processing.</figDesc><table><row><cell></cell><cell cols="3">Stage 1: Non-overlapping</cell><cell cols="3">Stage 2: non-overlapping</cell><cell cols="3">Stage 2: Overlapping</cell></row><row><cell>Dice</cell><cell cols="2">liver spleen</cell><cell>pancreas</cell><cell cols="2">liver spleen</cell><cell>pancreas</cell><cell cols="3">liver spleen pancreas</cell></row><row><cell>Mean</cell><cell>93.6</cell><cell>89.7</cell><cell>68.5</cell><cell>94.9</cell><cell>91.4</cell><cell>81.2</cell><cell>95.4</cell><cell>92.8</cell><cell>82.2</cell></row><row><cell>Std</cell><cell>2.5</cell><cell>8.2</cell><cell>8.2</cell><cell>2.1</cell><cell>8.9</cell><cell>10.2</cell><cell>2.0</cell><cell>8.0</cell><cell>10.2</cell></row><row><cell>Median</cell><cell>94.2</cell><cell>91.8</cell><cell>70.3</cell><cell>95.4</cell><cell>94.2</cell><cell>83.1</cell><cell>96.0</cell><cell>95.4</cell><cell>84.5</cell></row><row><cell>Min</cell><cell>78.2</cell><cell>20.6</cell><cell>32.0</cell><cell>80.4</cell><cell>22.3</cell><cell>1.9</cell><cell>80.9</cell><cell>21.7</cell><cell>1.8</cell></row><row><cell>Max</cell><cell>96.8</cell><cell>95.7</cell><cell>82.3</cell><cell>97.3</cell><cell>97.4</cell><cell>91.3</cell><cell>97.7</cell><cell>98.1</cell><cell>92.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>). 18 different anatomical structures are compared using the Dice similarity score [%]. Significantly better performance is shown in bold (p &lt; 0.05, Wilcoxon signed-rank test).</figDesc><table><row><cell>Label (Dice)</cell><cell>2D (Zhou et al., 2016a)</cell><cell>3D (stage1)</cell><cell>3D (stage2)</cell><cell>p-value</cell></row><row><cell>right lung</cell><cell>94.6 ± 2.8</cell><cell>90.1 ± 4.0</cell><cell>91.9 ± 3.6</cell><cell>0.028</cell></row><row><cell>left lung</cell><cell>92.8 ± 3.8</cell><cell>87.8 ± 5.3</cell><cell>93.2 ± 4.0</cell><cell>0.959</cell></row><row><cell>heart</cell><cell>91.2 ± 4.0</cell><cell>70.9 ± 11.8</cell><cell>86.2 ± 5.6</cell><cell>0.016</cell></row><row><cell>aorta</cell><cell>76.0 ± 11.8</cell><cell>50.7 ± 5.4</cell><cell>82.3 ± 5.9</cell><cell>0.038</cell></row><row><cell>esophagus</cell><cell>24.6 ± 16.7</cell><cell>0.0 ± 0.0</cell><cell>51.9 ± 5.3</cell><cell>0.011</cell></row><row><cell>liver</cell><cell>94.3 ± 3.3</cell><cell>90.2 ± 3.5</cell><cell>93.6 ± 2.7</cell><cell>0.049</cell></row><row><cell>gallbladder</cell><cell>47.5 ± 39.9</cell><cell>9.1 ± 11.6</cell><cell>58.4 ± 33.2</cell><cell>0.011</cell></row><row><cell>stomach and duodenal</cell><cell>68.0 ± 19.1</cell><cell>58.2 ± 15.2</cell><cell>61.9 ± 13.4</cell><cell>0.070</cell></row><row><cell>stomach and duodenal (air)</cell><cell>64.0 ± 32.2</cell><cell>52.4 ± 27.4</cell><cell>48.8 ± 26.6</cell><cell>0.001</cell></row><row><cell>stomach and duodenal (not air)</cell><cell>8.5 ± 15.6</cell><cell>1.1 ± 1.7</cell><cell>20.7 ± 20.0</cell><cell>0.000</cell></row><row><cell>spleen</cell><cell>86.7 ± 14.5</cell><cell>81.2 ± 12.1</cell><cell>86.6 ± 6.6</cell><cell>0.326</cell></row><row><cell>right kidney</cell><cell>92.2 ± 2.1</cell><cell>80.9 ± 10.6</cell><cell>90.8 ± 6.7</cell><cell>0.918</cell></row><row><cell>left kidney</cell><cell>90.2 ± 4.0</cell><cell>82.8 ± 8.3</cell><cell>86.1 ± 11.1</cell><cell>0.179</cell></row><row><cell>inferior vena cava</cell><cell>63.6 ± 19.1</cell><cell>59.8 ± 15.2</cell><cell>70.6 ± 17.5</cell><cell>0.007</cell></row><row><cell>portal vein</cell><cell>33.6 ± 29.5</cell><cell>30.0 ± 21.3</cell><cell>56.0 ± 16.6</cell><cell>0.002</cell></row><row><cell>pancreas</cell><cell>55.4 ± 19.3</cell><cell>47.5 ± 16.3</cell><cell>71.0 ± 13.9</cell><cell>0.001</cell></row><row><cell>prostate</cell><cell>1.2 ± 2.3</cell><cell>0.0 ± 0.0</cell><cell>38.0 ± 29.3</cell><cell>0.008</cell></row><row><cell>bladder</cell><cell>78.8 ± 13.9</cell><cell>57.2 ± 14.0</cell><cell>71.6 ± 20.8</cell><cell>0.213</cell></row><row><cell>Mean</cell><cell>65.0</cell><cell>52.8</cell><cell>69.3</cell><cell>0.004</cell></row><row><cell>Std</cell><cell>33.4</cell><cell>32.2</cell><cell>26.1</cell><cell></cell></row><row><cell>Min</cell><cell>0.0</cell><cell>0.0</cell><cell>1.1</cell><cell></cell></row><row><cell>Max</cell><cell>97.7</cell><cell>90.2</cell><cell>97.3</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Testing on unseen whole torso dataset: Dice scores [%] for each segmented organ.</figDesc><table><row><cell>Dice</cell><cell>r. lung</cell><cell>l. lung</cell><cell>liver</cell><cell cols="3">gall spleen r. kidney</cell><cell>l. kidney</cell><cell cols="2">pancreas Avg.</cell></row><row><cell>scratch</cell><cell>96.2</cell><cell>96.3</cell><cell cols="2">94.0 74.9</cell><cell>91.0</cell><cell>87.6</cell><cell>84.1</cell><cell>32.0</cell><cell>82.0</cell></row><row><cell>fine-tuned</cell><cell>96.4</cell><cell>96.6</cell><cell cols="2">94.9 76.3</cell><cell>90.1</cell><cell>90.5</cell><cell>88.5</cell><cell>33.0</cell><cell>83.3</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">http://lmb.informatik.uni-freiburg.de/resources/opensource/unet.en.html</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://wiki.cancerimagingarchive.net/display/Public/Pancreas-CT<ref type="bibr" target="#b26">(Roth et al., 2016a)</ref> hosted by TCIA<ref type="bibr" target="#b5">(Clark et al., 2013)</ref>.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">http://www.visceral.eu/benchmarks/anatomy3-open/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">https://github.com/holgerroth/3Dunet_abdomen_cascade</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments This paper was supported by MEXT KAKENHI (26108006, 26560255, 25242047,  17H00867, 15H01116)  and the JPSP International Bilateral Collaboration Grant.</p><p>Conflict of interest statement: The authors declare that they have no conflict of interest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Topology aware fully convolutional networks for histology gland segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bentaieb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hamarneh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="460" to="468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Automatic multi-resolution shape modeling of multi-organ structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Cerrolaza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Reyes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Summers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Á</forename><surname>González-Ballester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Linguraru</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical image analysis</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="11" to="21" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-A</forename><surname>Heng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.05895</idno>
		<title level="m">Voxresnet: Deep voxelwise residual networks for volumetric brain segmentation</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Automatic liver and lesion segmentation in ct using cascaded fully convolutional neural networks and 3D conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">F</forename><surname>Christ</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E A</forename><surname>Elshaer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ettlinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tatavarty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bilic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rempfler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Armbruster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Danastasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">H</forename><surname>Sommer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-A</forename><surname>Ahmadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">H</forename><surname>Menze</surname></persName>
		</author>
		<editor>MICCAI. Springer</editor>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="415" to="423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">3D U-Net: learning dense volumetric segmentation from sparse annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ö</forename><surname>Ç Içek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Abdulkadir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Lienkamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>MICCAI. Springer</publisher>
			<biblScope unit="page" from="424" to="432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The cancer imaging archive (tcia): maintaining and operating a public information repository</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Vendt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Freymann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kirby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maffitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pringle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tarbox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Prior</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of digital imaging</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1045" to="1057" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">3d deeply supervised network for automated segmentation of volumetric medical images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-A</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Image Analysis</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Towards image-guided pancreas and biliary endoscopy: Automatic multi-organ segmentation on abdominal ct with dense dilated networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gibson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Giganti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bonmati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bandula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gurusamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Clarkson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Barratt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="728" to="736" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Automatic abdominal multi-organ segmentation using deep convolutional neural network and time-implicit level sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer assisted radiology and surgery</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="399" to="411" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multi-atlas segmentation of biomedical images: a survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Iglesias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Sabuncu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical image analysis</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="205" to="219" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03167</idno>
		<title level="m">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Caffe: Convolutional architecture for fast feature embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Karayev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM international conference on Multimedia</title>
		<meeting>the 22nd ACM international conference on Multimedia</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="675" to="678" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Cloud-based evaluation of anatomical structure segmentation and landmark detection algorithms: Visceral anatomy benchmarks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimenez-Del</forename><surname>Toro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Krenn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gruenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Taha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Winterstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eggel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Foncubierta-Rodríguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Goksel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Jakab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kontokotsios</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Langs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Menze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Salas Fernandez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schaer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Walleyo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dicente Cid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Heinrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Kahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Kechichian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Spanier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wyeth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on medical imaging</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2459" to="2475" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Efficient multi-scale 3d cnn with fully connected crf for accurate brain lesion segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kamnitsas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ledig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">F</forename><surname>Newcombe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Kane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical image analysis</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="61" to="78" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Iterative instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3659" to="3667" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">On the compactness, efficiency, and representation of 3d convolutional networks: Brain parcellation as a pretext task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fidon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ourselin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Cardoso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Vercauteren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Information Processing in Medical Imaging</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="348" to="360" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3431" to="3440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">V-net: Fully convolutional neural networks for volumetric medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Milletari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Navab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-A</forename><surname>Ahmadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3D Vision (3DV). IEEE</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="565" to="571" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Regression forest-based atlas localization and direction specific atlas generation for pancreas segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Oda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shimizu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Karasawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Nimura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kitasaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Misawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fujiwara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mori</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>MICCAI. Springer</publisher>
			<biblScope unit="page" from="556" to="563" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Abdominal multi-organ segmentation from ct images using conditional shape-location and unsupervised intensity priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Okada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Linguraru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Summers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tomiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical image analysis</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Oktay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ferrante</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kamnitsas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Heinrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Guerrero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>De Marvao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>O&amp;apos;regan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kainz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.08302</idno>
		<title level="m">Anatomically constrained neural networks (acnn): Application to cardiac image enhancement and segmentation</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep feature learning for knee cartilage segmentation using a triplanar convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Prasoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Igel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lauze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nielsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on medical image computing and computer-assisted intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="246" to="253" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Evaluation of atlas selection strategies for atlas-based image segmentation with application to confocal microscopy images of bee brains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rohlfing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Brandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Menzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Maurer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1428" to="1442" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>MICCAI. Springer</publisher>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Data citation: Data from pancreas-ct. the cancer imaging archive</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Turkbey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Summers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title/>
		<idno type="DOI">10.7937/K9/TCIA.2016.tNB1kqBUAccessed</idno>
		<ptr target="http://doi.org/10.7937/K9/TCIA.2016.tNB1kqBUAccessed" />
		<imprint>
			<date type="published" when="2018-03-21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deeporgan: Multi-level deep convolutional networks for automated pancreas segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-C</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Turkbey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Summers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="556" to="564" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Spatial aggregation of holisticallynested networks for automated pancreas segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Summers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="451" to="459" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Summers</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.00045</idno>
		<title level="m">Spatial aggregation of holistically-nested convolutional neural networks for automated pancreas localization and segmentation</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Deep convolutional neural networks for computer-aided detection: Cnn architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-C</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Nogues</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mollura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Summers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>dataset characteristics and transfer learning</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Discriminative dictionary learning for abdominal multi-organ segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wolz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Misawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fujiwara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">V</forename><surname>Hajnal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Image Analysis</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="92" to="104" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Robust real-time face detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="137" to="154" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Multi-atlas segmentation with robust label transfer and label fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pouch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Takabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Jackson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gorman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gorman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Yushkevich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information processing in medical imaging: proceedings of the... conference</title>
		<imprint>
			<publisher>NIH Public Access</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page">548</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Geodesic patch-based segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">K</forename><surname>Bhatia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Marvao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dawes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Misawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="666" to="673" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Automated abdominal multi-organ segmentation with subject-specific atlas generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wolz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Misawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fujiwara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1723" to="1730" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Three-dimensional ct image segmentation by combining 2D fully convolutional network with 3D majority voting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Takayama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fujita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LABELS workshop</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="111" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Deep learning of the sectional appearances of 3d ct images for anatomical structure segmentation based on an fcn voting method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Takayama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fujita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Physics</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Pancreas segmentation in abdominal ct scan: A coarse-to-fine approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Fishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.08230</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
