<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CheXclusion: Fairness gaps in deep chest X-ray classifiers</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laleh</forename><surname>Seyyed-Kalantari</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science</orgName>
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<settlement>Toronto</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Vector Institute</orgName>
								<address>
									<settlement>Toronto</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guanxiong</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science</orgName>
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<settlement>Toronto</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Vector Institute</orgName>
								<address>
									<settlement>Toronto</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Mcdermott</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Electrical Engineering and Computer Science</orgName>
								<orgName type="institution">Massachusetts Institute of Technology</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irene</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Electrical Engineering and Computer Science</orgName>
								<orgName type="institution">Massachusetts Institute of Technology</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maryzeh</forename><surname>Ghassemi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science</orgName>
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<settlement>Toronto</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Vector Institute</orgName>
								<address>
									<settlement>Toronto</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">CheXclusion: Fairness gaps in deep chest X-ray classifiers</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T14:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>fairness</term>
					<term>medical imaging</term>
					<term>chest x-ray classifier</term>
					<term>computer vision</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Machine learning systems have received much attention recently for their ability to achieve expert-level performance on clinical tasks, particularly in medical imaging. Here, we examine the extent to which state-of-the-art deep learning classifiers trained to yield diagnostic labels from X-ray images are biased with respect to protected attributes. We train convolution neural networks to predict 14 diagnostic labels in 3 prominent public chest X-ray datasets: MIMIC-CXR, Chest-Xray8, CheXpert, as well as a multi-site aggregation of all those datasets. We evaluate the TPR disparity -the difference in true positive rates (TPR) -among different protected attributes such as patient sex, age, race, and insurance type as a proxy for socioeconomic status. We demonstrate that TPR disparities exist in the stateof-the-art classifiers in all datasets, for all clinical tasks, and all subgroups. A multi-source dataset corresponds to the smallest disparities, suggesting one way to reduce bias. We find that TPR disparities are not significantly correlated with a subgroup's proportional disease burden. As clinical models move from papers to products, we encourage clinical decision makers to carefully audit for algorithmic disparities prior to deployment. Our code can be found at, https://github.com/LalehSeyyed/CheXclusion.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Chest X-ray imaging is an important screening and diagnostic tool for several life-threatening diseases, but due to the shortage of radiologists, this screening tool cannot be used to treat all patients. <ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b1">2</ref> Deep-learning-based medical image classifiers are one potential solution, with significant prior work targeting chest X-rays specifically, <ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4</ref> leveraging large-scale publicly available datasets, <ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6</ref> and demonstrating radiologist-level accuracy in diagnostic classification. <ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref> Despite the seemingly clear case for implementing AI-enabled diagnostic tools, 9 moving such methods from paper to practice require careful thought. <ref type="bibr" target="#b9">10</ref> Models may exhibit disparities in performance across protected subgroups, and this could lead to different subgroups receiving different treatment. <ref type="bibr" target="#b10">11</ref> During evaluation, machine learning algorithms usually optimize for, and report performance on, the general population rather than balancing accuracy on different subgroups. While some variance in performance is unavoidable, mitigating any systematic bias against protected subgroups may be desired or required in a deployable model.</p><p>In this paper, we examine whether state-of-the-art (SOTA) deep neural classifiers trained on large public medical imaging datasets are fair across different subgroups of protected attributes. We train classifiers on 3 large, public chest X-ray datasets: MIMIC-CXR, <ref type="bibr" target="#b4">5</ref> CheXpert, <ref type="bibr" target="#b5">6</ref> Chest-Xray8, <ref type="bibr" target="#b2">3</ref> as well as an additional datasets formed of the aggregation of those three datasets on their shared labels. In each case, we implement chest X-ray pathology classifiers via a deep convolutional neural network (CNN) chest X-ray images as inputs, and optimize the multi-label probability of 14 diagnostic labels simultaneously. Because researchers have observed health disparities with respect to race, <ref type="bibr" target="#b11">12</ref> sex, <ref type="bibr" target="#b12">13</ref> age, <ref type="bibr" target="#b13">14</ref> and socioeconomic status, <ref type="bibr" target="#b11">12</ref> we extract structural data on race, sex, and age; we also use insurance type as an imperfect proxy <ref type="bibr" target="#b10">11</ref> for socioeconomic status. To our knowledge, we are the first to examine whether SOTA chest X-ray pathology classifiers display systematic bias across race, age, and insurance type.</p><p>We analyze equality of opportunity <ref type="bibr" target="#b14">15</ref> as our fairness metric based on the needs of the clinical diagnostic setting. In particular, we examine the differences in true positive rate (TPR) across different subgroups per attributes. A high TPR disparity indicates that sick members of a protected subgroup would not be given correct diagnoses-e.g., true positives-at the same rate as the general population, even in an algorithm with high overall accuracy.</p><p>We find three major findings: First, that there are indeed extensive patterns of bias in SOTA classifiers, shown in TPR disparities across datasets. Secondly, the disparity rate for most attributes/ datasets pairs is not significantly correlated with the subgroups' proportional disease membership. These findings suggest that underrepresented subgroups could be vulnerable to mistreatment in a systematic deployment, and that such vulnerability may not be addressable simply through increasing subgroup patient count. Lastly, we find that using the multi-source dataset which combines all the other datasets yields the lowest TPR disparities, suggesting using multi-source datasets may combat bias in the data collection process. As researchers increasingly apply artificial intelligence and machine learning to precision medicine, we hope that our work demonstrates how predictive models trained on large, well-balanced datasets can still yield disparate impact.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background and Related Work</head><p>Fairness and Debiasing. Fairness in machine learning models is a topic of increasing attention, spanning sex bias in occupation classifiers, <ref type="bibr" target="#b15">16</ref> racial bias in criminal defendant risk assessments algorithms, <ref type="bibr" target="#b16">17</ref> and intersectional sex-racial bias in automated facial analysis. <ref type="bibr" target="#b17">18</ref> Sources of bias arise in many different places along the classical machine learning pipeline. For example, input data may be biased, leaving supervised models vulnerable to labeling and cohort bias. <ref type="bibr" target="#b17">18</ref> Minority groups may also be under-sampled, or the features collected may not be indicative of their trends. <ref type="bibr" target="#b18">19</ref> There are several conflicting definitions of fairness, many of which are not simultaneously achievable. <ref type="bibr" target="#b19">20</ref> The appropriate choice of a disparity metric is generally task dependent, but balancing error rates between different subgroups is a common consideration, <ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b16">17</ref> with equal accuracy across subgroups being a popular choice in medical set-tings. <ref type="bibr" target="#b20">21</ref> In this work, we consider the equality of opportunity notion of fairness and evaluate the rate of correct diagnosis in patients across several protected attribute groups.</p><p>Ethical Algorithms in Health. Using machine learning algorithms to make decisions raises serious ethical concerns about risk of patient harm. <ref type="bibr" target="#b21">22</ref> Notably, biases have already been demonstrated in several settings, including racial bias in the commercial risk score algorithms used in hospitals, <ref type="bibr" target="#b22">23</ref> or an increased risk of electronic health record (EHR) miss-classification in patients with low socioeconomic status. <ref type="bibr" target="#b23">24</ref> It is crucial that we actively consider fairness metrics when building models in systems that include human and structural biases.</p><p>Chest X-Ray Classification. With the releases of large public datasets like Chest-Xray8, <ref type="bibr" target="#b2">3</ref> CheXpert, 6 and MIMIC-CXR, 5 many researchers have begun to train large deep neural network models for chest X-ray diagnosis. <ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b24">25</ref> Prior work 8 demonstrates a diagnostic classifier trained on Chest-Xray8 can achieve radiologist-level performance. Other work on CheXpert 6 reports high performance for five of their diagnostic labels. To our knowledge, however, no works have yet been published which examined whether any of these algorithms display systematic bias over age, race and insurance type (as a proxy of socialeconomic status).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Data</head><p>We use three public chest X-ray radiography datasets described in <ref type="table">Table 1</ref>: MIMIC-CXR (CXR), 5 CheXpert (CXP), <ref type="bibr" target="#b5">6</ref> Chest-Xray8 (NIH). <ref type="bibr" target="#b2">3</ref> Images in CXR, CXP, and NIH are associated with 14 diagnostic labels (see <ref type="table" target="#tab_1">Table 2</ref>). We combine all non-positive labels within CXR and CXP (including "negative", "not mentioned", or "uncertain") into an aggregate "negative" label for simplicity, equivalent to "U-zero" study of 'NaN' label in CXP. In CXR and CXP, one of the 14 labels is "No Finding", meaning no disease has been diagnosed for the image and all the other 13 labels are 0. Of the 14 total disease labels, only 8 are shared amongst all 3 datasets. Using these 8 labels, we define a multi-site dataset (ALL) that consists of the aggregation of all images in CXR, CXP, and NIH defined over this restricted label schema.</p><p>These datasets contain protected subgroup attributes, the full list of which includes sex (Male and Female), age (0-20, 20-40, 40-60, 60-80, and 80-), race (White, Black, Other, Asian, Hispanic, and Native) and insurance type (Medicare, Medicaid, and Other). These values are taken from the structured patient attributes. NIH, CXP, and ALL only have the patient sex and age, while CXR also has race and insurance type data (excluding around 100,000 images).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Methods</head><p>We implement CNN-based models to classify chest X-ray images into 14 diagnostic labels. We train separate models for CXR, 5 CXP, 6 NIH 3 and ALL and explore their fairness with respect to patient sex and age for all 4 datasets as well as race and insurance type for CXR. <ref type="table">Table 1</ref>. Description of chest X-ray datasets, MIMIC-CXR (CXR), 5 CheXpert (CXP), <ref type="bibr" target="#b5">6</ref> Chest-Xray8 (NIH). <ref type="bibr" target="#b2">3</ref> and their aggregation on 8 shared labels (ALL). Here, the number of images, patients, view types, and the proportion of patients per subgroups of sex, age, race, and insurance type are presented. 'Frontal' and 'Latral' abbreviate frontal and lateral view, respectively. Native, Hispanic, and Black denote self-reported American Indian/Alaska Native, Hispanic/Latino, and Black/African American race respectively. split with no patient shared across splits. We resize all images to 256 × 256 and normalize via the mean and standard deviation of the ImageNet dataset. <ref type="bibr" target="#b26">27</ref> We apply center crop, random horizontal flip and random rotation, as some of the images maybe flipped or rotated within the dataset. The initial degree of random rotation is chosen by hyperparameter tuning. We use Adam 28 optimization with default parameters, and decrease the learning rate (LR) by a factor of 2 if the validation loss does not improve over three epochs; we stop learning if validation loss does not improve over 10 epochs. Thus the ultimate number of epochs for training each model is varied based on the early stop condition. For NIH, CXP and CXR we first tune models to get the highest average area under the receiver operating characteristic curve (AUC) over 14 labels by fine tuning the LR. For the best achieved model, we fine tune the degree of random rotation data augmentation from the set of 7, 10 and 15 and select the best model. Following this, best initial LR is 0.0005 for CXR and NIH where it is achieved as 0.0001 for CXP. Also, best initial degree for random rotation data augmentation is 10 for NIH and 15 for the CXR and CXP. For training on ALL, we use the majority vote of the best hyperparameters per individual dataset (e.g. 0.0005 initial LR and 15 degree random rotation). We then, fix the hyperparameters of the best model and train four extra models with the same hyperparameters but different random seeds between 0 to 100, per dataset. We report all the metrics based on the mean and 95% confidence intervals (CI) achieved over five studies per dataset. We choose batch size of 48 to use the maximum memory capacity of the GPU, for all datasets except NIH where we choose 32 similar to prior work. <ref type="bibr" target="#b7">8</ref> The output of the network is an array of 14 numbers between 0 and 1 indicating the probability of each disease label. The binary prediction threshold per disease is chosen to maximize the F1 score measure on the validation dataset. We train models using a single NVIDIA GPU with 16G of memory in approximately 9, 20, 40, and 90 hours for NIH, CXP, CXR, and ALL, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Subgroup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Classifier Disparity Evaluation</head><p>Our primary measurement of bias is TPR disparity. For example, given a binary subgroup attribute such as sex (which in our data we classify as either 'male' or 'female'), we mimic prior work <ref type="bibr" target="#b15">16</ref> and define the TPR disparity per diagnostic label i as simply the TPR of label i restricted to female patients minus that for male patients. More formally, letting g be the binary subgroup attribute, we define TPR g,i = P [Ŷ i = y i |G = g, Y i = y i ], and the TPR disparity as, Gap g,i = TPR g,i − TPR ¬g,i . For non-binary attributes S 1 , . . . , S N , we use the difference between a subgroup's TPR and the median of all TPRs to define TPR disparity of the jth subgroup for the ith label as, Gap Sj,i = TPR Sj,i −Median(TPR S1,i , .., TPR Sk,i ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>First, we demonstrate that the classifiers we train on all datasets reach near-SOTA level performance. This motivates using them to study fairness implications, as we can be confident any problematic disparities are not simply reflective of poor overall performance. Next, we explicitly test these classifiers for their implications on fairness. We target two investigations:</p><p>(1) TPR disparity: We quantify the TPR disparity per subgroup/disease for sex and age across all 4 datasets, and due to data availability for race and insurance type on CXR. (2) TPR disparity in proportion to membership: We investigate the distribution of the positive patient proportion per subgroup S j and label y i (which is given by P [S = S j |Y = y i ]) and the effect on TPR disparities. Prior work on chest X-ray diagnosis prediction has suggested data imbalance can explain sex TPR disparities 29 while work in other domains illustrates that disparities in small or vulnerable subgroups could be propagated if put into practice, <ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b29">30</ref> and these experiments are meant to probe that hypothesis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Results</head><p>One potential reason that a model may be biased is because of poor performance, but we demonstrate that our models achieve near-SOTA classification performance. <ref type="table" target="#tab_1">Table 2</ref> shows overall performance numbers across all tasks and datasets. Though results have non-trivial  </p><formula xml:id="formula_0">- - 0.897 ± 0.002 - Enlarged Card (EC) 0.757 ± 0.003 0.668 ± 0.005 - - Fibrosis - - 0.788 ± 0.007 - Fracture (Fr) 0.718 ± 0.007 0.790 ± 0.006 - - Hernia (H) - - 0.978 ± 0.004 - Infiltration (In) - - 0.717 ± 0.004 - Lung Lesion (LL) 0.772 ± 0.006 0.780 ± 0.005 - - Mas (M) - - 0.829 ± 0.006 - Nodule (N) - - 0.779 ± 0.006 - No Finding (NF) 0.868 ± 0.001 0.885 ± 0.001 - 0.890 ± 0.000 Pleural Thickening (PT) - - 0.813 ± 0.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">TPR Disparities</head><p>We calculate and identify TPR disparities and 95% CI across all labels, datasets and attributes. We see many instances of positive and negative disparities, which can denote bias for or against of a subgroup, here referred to favorable and unfavorable subgroups. As an illustrative example <ref type="figure" target="#fig_0">Fig. 1</ref> shows the race TPR disparities distribution sorted by the the gap between least and most favorable subgroups per label. In a fair setting, all subgroups would have no appreciable TPR disparities, yielding a gap between least and most favorable subgroups within a label at '0'. <ref type="table">Table 3</ref> shows the summary of the disparities in all attributes and datasets. We note that the most frequent unfavorable subgroups are those with social disparities in the healthcare  <ref type="table">Table 3</ref>. Disparities overview over attributes and datasets. We average per label gaps between the least and most favorable subgroup's TPR disparities per attributes/datasets to obtain the average cross-label gap. The labels (full names on <ref type="table" target="#tab_1">Table 2</ref>) that obtained the smallest and largest gaps are shown next to the average cross-label gap column, along with their gaps. We summarize and label in columns the most frequent "Unfavorable" and "Favorable" subgroups count, which are the ones that experience TPRs disparities below or above the zero gap line. See Section 6.1 for more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Attribute Dataset Average Cross-Label Gap Unfavorable Favorable Gap</head><p>Lowest Greatest system, e.g., women and minorities, but no disease is consistently at the highest or lowest disparity. We show the average cross-label gap between and the labels of the least and most favorable subgroups per dataset and attributes. We count the number of time each subgroups experience negative disparities (unfavorable) and zero or positive disparities (favorable) across disease labels and report the most frequent unfavorable and favorable subgroups by count in <ref type="table">Table 3</ref>. For CXP and CXR, we exclude "No Finding" label in the count (counts are out of 13) as we want to check negative bias in disease labels. Notably, the model trained on ALL has the smallest average cross-label gap between least/most favorable groups for sex and age.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">TPR Disparity Correlation with Membership Proportion</head><p>We measure the Pearson correlation coefficients (r) between the TPR disparities and patients proportion per label across all subgroups/datasets. As we test multiple (33) hypotheses, (33 total comparisons amongst all protected attributes considered) with a desired significance level (p &lt; 0.05), then based on Bonferroni correction, 31 the statistical significance level for each hypothesis is p &lt; 0.0015 (0.05/33). The majority of correlation coefficients listed are positive, but the only statistically significant correlations are: race Other (r: 0.782, p: 0.0009) &amp; age subgroups, 20-40 (r: 0.766, p: 0.0013), 60-80 (r: 0.787, p: 0.0008) and 80-(r:0.858 , p: 0.0000) in CXR, age group 60-80 (r: 0.853, p: 0.0001) in CXP, and age group 60-80 (r: 0.936, p: 0.0006) in ALL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Summary and Discussion</head><p>We present a range of findings on the potential biases of deployed SOTA X-ray image classifiers over the sex, age, race and insurance type attributes on models trained on NIH, CXP and CXR. We focus on TPR disparities similar to prior work, <ref type="bibr" target="#b15">16</ref> checking if the sick members of the different subgroups are given correct diagnosis at similar rates. Our results demonstrate several main takeaways. First, all datasets and tasks display nontrivial TPR disparities. These disparities could pose serious barriers to effective deployment of these models and invite additional changes in either dataset design and/or modeling techniques to ensure more equitable models. Second, using a multi-source dataset leads to smaller TPR disparities, potentially due to removing bias in the data collection process. Third, while there is occasionally a proportionality between protected subgroup membership per label and TPR disparity, this relationship is not uniformly true across datasets and subgroups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.">Extensive Patterns of Bias</head><p>We find that all datasets and tasks contain meaningful patterns of bias although no diseases are consistently at the highest or lowest disparity rates across all attributes and datasets. These disparities are present with respect to age and sex in all settings, with consistent subgroups (female, 0-20) showing consistently unfavorable outcomes. Note that in the case of the sex disparities, "female" patients are universally the least favored subgroup despite the fact that the proportion of female patients is only slightly less than male patients in all 4 datasets.</p><p>We also observe TPR disparities with respect to the patient race and insurance type in the CXR dataset. White patients, the majority, are the most favorable subgroup, where Hispanic patients are the most unfavorable. Additionally, bias exists against patients with Medicaid insurance, who are the minority population and are often from lower socioeconomic status. They are the most unfavorable subgroup with the model often providing incorrect diagnoses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.">Bias Reduction Through Multi-source Data</head><p>Of the four datasets, the multi-source dataset led to the smallest disparities with respect to age and sex. Based on notions of generalizability in healthcare, <ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b31">32</ref> we hypothesize that this improvement stems from the combination of large datasets reducing data collection bias.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.">Correlation Between TPR Disparities and Membership Proportion</head><p>Although prior work has raised data imbalance as a potential cause of sex bias, <ref type="bibr" target="#b28">29</ref> we observe TPR disparities are not often significantly correlated with disease membership. While we observe positive correlation between subgroups membership and TPR disparities, only 6 of 33 subgroups showed statistically significant correlation. By inspection, we identify diseases with the same patient proportion of a subgroup and completely different TPR disparities (e.g. 'Consolidation', 'Nodule' and 'Pneumothorax' in NIH have 45% Female, but the TPR disparities are in diverse range, -0.155, -0.079 and 0.047, respectively). Thus, having the same portion of images within all labels may not guarantee lack of bias.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4.">Discussion</head><p>We identify subgroups that may experience more bias through the exploration of variance in TPR and FPR. Based on the equality of opportunity notion of fairness, a fair network should exhibit the same TPR on average among all subgroups regardless of how likely a subgroup may have a disease. Such an improvement would allow two patients with the same condition, but in different subgroups, to be diagnosed correctly and receive the same level of care. While we focused on some of the more obvious protected attributes, it is important to note that there are several other factors, subgroups, and attributes that we have not considered.</p><p>Identifying and eliminating disparities is particularly important as large datasets begin to be used by high-capacity neural models, but are based on highly skewed population, e.g., kidney injury prediction in a population that is 93.6% male. <ref type="bibr" target="#b32">33</ref> While chest X-ray images datasets are not sex-skewed, we note that the age, race and insurance type attributes are highly unbalanced, e.g., 67.6% of patients are White, and only 8.98% are under Medicaid insurance. Subgroups with chronic underdiagnosis are those who experience more negative social determinants of health, specifically, women, minorities, and those of low socioeconomic status. Such patients may use healthcare services less than others. In some groups, such a dataset skew can increase the risk of miss-classification. <ref type="bibr" target="#b23">24</ref> Although "de-biasing" techniques <ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b34">35</ref> may reduce disparities, we should not ignore the important biases inherent in existent large public datasets. There are a number of reasons why dataset may induce disparities in algorithms, from imbalanced datasets to differences in statistical noise in each group (e.g. unmeasured predictive features) to differences in access to healthcare for patients of different groups. <ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b18">19</ref> For instance, an algorithm that can classify skin cancer <ref type="bibr" target="#b35">36</ref> with high accuracy will not be able to generalize on different skin color if similar samples have not been represented enough in the trained dataset. <ref type="bibr" target="#b17">18</ref> Intentionally adjusting the datasets to reduce disparities in to protect minorities and the subgroups with high disparities is one potential option in dataset creation, though our analyses suggest that dataset membership cannot always ameliorate bias.</p><p>With the great promise of advanced models for clinical care, we caution that advanced SOTA models must be carefully checked for such biases as those we have identified. Disparities in small or vulnerable subgroups could be propagated 30 within the development of machine learning models. This raises serious ethical concerns 22 about the equal accessibility to the required medical treatment. Usually the SOTA classifiers are trained to provides high AUC or accuracy on the general population. However we suggest additionally applying rigorous fairness analyses before deployment. Clear disclaimers about the dataset collection process and potential resulting algorithmic bias could improve model assessment for clinical use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Limitations and Future Work</head><p>As SOTA deep learning diagnosis algorithms become more promising for medical screening, model bias investigation is essential. This work is a first step in quantifying these biases so that approaches for amelioration can be developed. However, important future work remains.</p><p>First, we note that across these models, our source of diagnostic labels for these images must be considered at best "silver" labels, as all currently existing public chest X-ray datasets use automatically deteremined labels based on natural language processing (NLP) techniques to extract labels from the radiology reports. These silver labels may be incorrect, in ways that could compound with observe biases or model errors, a risk that warrants further investigation. Additionally, we must consider the quality of the imaging devices themselves, the region of data collection, and the patient demographics at each hospital collection site. For instance, NIH was gathered from a hospital that covers more complicated cases, CXP contains more tertiary cases, and CXR was gathered from an emergency department, and prior literature has already shown that models are fully capable of taking advantage of such confounders. <ref type="bibr" target="#b31">32</ref> These challenges may affect both the label quality, <ref type="bibr" target="#b36">37</ref> and any patterns of bias in the labels, thereby affecting the resulting fairness metrics. Finally, exploration of existing de-biasing techniques, however limited, should also be undertaken over this modality to see if any of the problems we identified here can be resolved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">Conclusion</head><p>While the development and deployment of machine learning models in a clinical setting poses exciting opportunities, great care must be taken to understand how existing biases may be exacerbated and propagated. We show the TPR disparity of SOTA chest X-ray pathology classifiers trained on 4 datasets, (MIMIC-CXR, ChestX-ray8, CheXpert, and aggregation of those three on shared labels) across 14 diagnostic labels. We quantify the TPR disparity across datasets along sex, age, race and insurance type. Our results indicate that high-capacity models trained on large datasets do not provide equality of opportunity naturally, leading instead to potential disparities in care if deployed without modification.</p><p>Here we present the distribution of TPR disparities per subgroups/disease labels for all attributes. In a fair setting all subgroups TPRs per disease are the same and disparity is '0'. Conversely, negative and positive disparities denotes bias against and in favor of a subgroup, respectively. The subgroup with largest (positive) and smallest (negative) TPR disparities per disease label are the most favorable and unfavorable subgroups, respectively. In <ref type="figure" target="#fig_0">Fig. A1</ref> to <ref type="figure" target="#fig_7">Fig. A9</ref>, we sort disease labels based on the gap between the least and most favorable subgroups per disease, so that ones with smaller variance in disparity appear on the left side. We quantify TPR disparity across different subgroups similar to prior work <ref type="bibr" target="#b15">16</ref> for sex attributes, as the TPR of the subgroup of interest minus the TPR of the other subgroup (e.g. Disparity F emale,Edema = TPR F emale,Edema − TPR M ale,Edema ). For age, race, and insurance type we quantify disparities using the difference between a subgroup's TPR and the TPRs median. We present the count of negative disparities per subgroup across all labels, excluding the 'No Finding' ('NF') label in order to consider disease labels only. The counts are based on the TPR disparities mean over five run. For <ref type="figure" target="#fig_0">Fig. A1</ref> to <ref type="figure" target="#fig_7">Fig. A9</ref> the label with the smallest and largest gap (distance) between the least/most favorable subgroups, the average cross labels gaps (between the the least/most favorable subgroups), and the count of the most frequent 'Unfavorable' and 'Favorable' subgroups, are summarized in <ref type="table">Table.</ref> 3 and presented in the figure captions.    <ref type="table" target="#tab_1">Table  2</ref> refer to the same disease. The scatter plot's circle area is proportional to the patients percentages per subgroup. The TPR disparities are averaged over five run ±95% CI. The 95% CI are shown with arrows around the TPR disparities mean scatter plot. Count of 'Female' and 'Male' patients with negative disparities in disease labels are 7/13 and 6/13. Here, 'Edema' ('Ed') is the label with the smallest gap (0.000) between the least/most favorable subgroups, where 'Consolidation' ('Co') has the largest gap (0.139). The average cross labels gap between the the least/most favorable subgroups are 0.062.    <ref type="table" target="#tab_1">Table 2</ref> refer to the same disease. The scatter plot's circle area is proportional to the percentage of patients in each subgroup. The TPR disparities are averaged over five run ±95% CI. The 95% CI are shown with arrows around the mean of TPRs scatter plot. Count of patients in age subgroups '40-60', '60-80', '20-40','80-' and '0-20' with negative gap in disease labels are 4/13, 3/13, 7/13, 4/13 and 7/13. Thus, patients 0-20 and 20-40 are the most favorable subgroups where patient 60-80 with 10/13 positive disparities are the most favorable subgroup. Here, 'Support Devices' is the label with the smallest gap (0.091) between the least/most favorable subgroups, where 'Cardiomegaly' has the largest gap (0.440). The average cross labels gap between the the least/most favorable subgroups are 0.245. <ref type="figure">Fig. A7</ref>. The sorted distribution of the TPR age disparity in CheXpert dataset per disease. The x-axis labels are the disease labels. Here, the label Lung Opacity and Airspace Opacity label in <ref type="table" target="#tab_1">Table  2</ref> refer to the same disease. The scatter plot's circle area is proportional to the percentage of patients in each subgroup. The TPR disparities are averaged over five run ±95% CI (CI are shown with arrows around the mean). Count of patients in age subgroups '40-60', '60-80', '20-40','80-' and '0-20' with negative gap in disease labels are 5/13, 6/13, 7/13, 7/13 and 7/13. Here, 'Support Devices' ('SD') is the label with the smallest gap (0.082) between the least/most favorable subgroups, where 'No Finding' ('NF') has the largest gap (0.604). The average cross labels gap between the the least/most favorable subgroups are 0.270. <ref type="figure">Fig. A8</ref>. The sorted distribution of the TPR age disparity in ChestXray8 dataset per disease. The x-axis labels are the disease labels. The scatter plot's circle area is proportional to the patients membership. The TPR disparities are averaged over five run ±95%CI (the CI are shown with arrows around the mean). Count of patients in age subgroups '40-60', '60-80', '20-40','80-' and '0-20' with negative gap in disease labels are 6/14, 7/14, 4/14, 6/14 and 6/14. Here, 'Infiltration' ('In') is the label with the smallest gap (0.188) between the least/most favorable subgroups, where 'Emphysema' ('Em') has the largest gap (1.00). The average cross labels gap between the the least/most favorable subgroups are 0.413.  <ref type="table" target="#tab_1">Table 2</ref> refer to the same disease. The scatter plot's circle area is proportional to the patients membership. The TPR disparities are averaged over five run ±95%CI (the CI are shown with arrows around the mean). Count of patients in insurance subgroups 'Other', 'Medicare', and 'Medicaid' with negative gap in disease labels are 3/13, 6/13, and 10/13. The patients with 'Medicaid' insurance are the most unfavorable subgroup where 'Other' are the most favorable subgroup with 10/13 positive disparity count. Here, 'Support Devices' is the label with the smallest gap (0.021) between the least/most favorable subgroups, where 'Pleural Other' has the largest gap (0.190). The average cross labels gap between the the least/most favorable subgroups are 0.100.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>The sorted distribution of TPR race disparity of CXR (y-axis) with label (x-axis). The scatter plot's circle area is proportional to group size. TPR disparities are averaged over five runs ±95%CI ( shown with arrows). Hispanic patients are most unfavorable (highest count of negative TPR disparities, 9/13) whereas White patients are most favorable subgroup (9/13 zero or positive disparities). Labels 'No Finding' ('NF') and 'Pneumonia' ('Pa') have smallest (0.119) and largest (0.440) gap between least/most favorable subgroups. The average cross 14 labels gap is 0.226.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. A1 .</head><label>A1</label><figDesc>The sorted distribution of the TPR sex disparity in ALL dataset per disease. The x-axis labels are the disease names. The scatter plot's circle area is proportional to the patients percentages per subgroup. The TPR disparities are averaged over five run ±95% CI. The 95% CI are shown with arrows around the TPR disparities mean scatter plot. The average cross labels gaps between the the least/most favorable subgroups is 0.045. Female are the most unfavorable subgroups with 4/7 count of negative disparities in disease labels where 'Male' are the most favorable subgroups. Here, 'Effusion' is the label with the smallest gap (0.001) between the least/most favorable subgroups, where 'Pneumonia' has the largest gap (0.105).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. A2 .</head><label>A2</label><figDesc>The sorted distribution of the TPR sex disparity in MIMIC-CXR dataset per disease. The x-axis labels are the abbreviation of the disease names. Here Lung Opacity and Airspace Opacity label inTable 2refer to the same disease. The scatter plot's circle area is proportional to the patients percentages per subgroup. The TPR disparities are averaged over five run ±95% CI. The 95% CI are shown with arrows around the TPR disparities mean scatter plot. Count of 'Female' and 'Male' patients with negative disparities in disease labels (excluding 'No Finding') are 10/13 and 3/13. Thus Female are the most unfavorable subgroup. Here, 'Edema' is the label with the smallest gap (0.011) between the least/most favorable subgroups, where 'Enlarged Cardiomediastinum' has the largest gap (0.151). The average cross labels gap between the the least/most favorable subgroups are 0.072.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. A3 .</head><label>A3</label><figDesc>The sorted distribution of the TPR sex disparity in CheXpert dataset per disease. The x-axis labels are the disease labels. Here, the label Lung Opacity and Airspace Opacity label in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. A4 .</head><label>A4</label><figDesc>The sorted distribution of the TPR sex disparity in ChestXray8 dataset per disease. The x-axis labels are the disease names. The scatter plot's circle area is proportional to the patients percentages per subgroup. The TPR disparities are averaged over five run ±95% CI. The 95% CI are shown with arrows around the TPR disparities mean scatter plot. Count of 'Female' and 'Male' patients with negative disparities in disease labels are 8/14 and 6/14. Here, 'Mass' ('M') is the label with the smallest gap (0.001) between the least/most favorable subgroups, where 'Cardiomegaly' ('Cd') has the largest gap (0.393). The average cross labels gap between the the least/most favorable subgroups are 0.190.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. A5 .</head><label>A5</label><figDesc>The sorted distribution of the TPR age disparity in ALL dataset per disease. The x-axis labels are the disease names. The scatter plot's circle area is proportional to the percentage of patients in each subgroup. The TPR disparities are averaged over five run ±95% CI. The 95% CI are shown with arrows around the mean of TPRs scatter plot. The count of patients in age subgroups '40-60', '60-80', '20-40','80-' and '0-20' with negative gap in disease labels are 2/7, 2/7, 4/7, 4/7 and 5/7. Thus ypung patients 0-20 are the most unfavorable subgroups where patients 40-60 and 60-80 are the most favorable subgroups with 5/7 count of positive gaps over disease labels. The average cross labels gaps between the the least/most favorable subgroups is 0.215. Here, 'Effusion' is the label with the smallest gap (0.115) between the least/most favorable subgroups, where 'No Finding' has the largest gap (0.444).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. A6 .</head><label>A6</label><figDesc>The sorted distribution of the TPR age disparity in MIMIC-CXR dataset per disease. The x-axis labels are the disease labels. Here, the label Lung Opacity and Airspace Opacity label in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. A9 .</head><label>A9</label><figDesc>The sorted distribution of the TPR insurance type disparity in MIMIC-CXR dataset per disease.The x-axis labels are the disease names. Here, the label Lung Opacity and Airspace Opacity label in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>The AUC for chest X-ray classifiers trained on CXP, CXR, NIH, and ALL averaged over 5 runs ±95%CI, where all runs have same hyperparameters but different random seed. ('Airspace Opacity' 5 and 'Lung Opacity' 6 denote the same label.)</figDesc><table><row><cell>Label (Abbr.)</cell><cell>CXR</cell><cell>CXP</cell><cell>NIH</cell><cell>ALL</cell></row><row><cell>Airspace Opacity (AO)</cell><cell cols="2">0.782 ± 0.002 0.747 ± 0.001</cell><cell>-</cell><cell>-</cell></row><row><cell>Atelectasis (A)</cell><cell cols="3">0.837 ± 0.001 0.717 ± 0.002 0.814 ± 0.004</cell><cell>0.808 ± 0.001</cell></row><row><cell>Cardiomegaly (Cd)</cell><cell cols="3">0.828 ± 0.002 0.855 ± 0.003 0.915 ± 0.002</cell><cell>0.856 ± 0.001</cell></row><row><cell>Consolidation (Co)</cell><cell cols="3">0.844 ± 0.001 0.734 ± 0.004 0.801 ± 0.005</cell><cell>0.805 ± 0.001</cell></row><row><cell>Edema (Ed)</cell><cell cols="3">0.904 ± 0.002 0.849 ± 0.001 0.915 ± 0.003</cell><cell>0.898 ± 0.001</cell></row><row><cell>Effusion (Ef)</cell><cell cols="3">0.933 ± 0.001 0.885 ± 0.001 0.875 ± 0.002</cell><cell>0.922 ± 0.001</cell></row><row><cell>Emphysema (Em)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>± 0.001 0.805±0.001 0.840 ± 0.001 0.859 ± 0.001 variability, we show similar performance to the published SOTA of NIH, 8 the only dataset for which a published SOTA comparison exists for all labels. Note that the published results for CXP 6 are on a private, unreleased dataset of only 200 images and 5 labels. Our results for CXP are on a randomly sub-sampled test set of size 22,274 images, so the numbers for this dataset are not comparable to the published results there.</figDesc><table><row><cell></cell><cell></cell><cell>006</cell><cell>-</cell></row><row><cell>Pleural Other (PO)</cell><cell>0.848 ± 0.003 0.795 ± 0.004</cell><cell>-</cell><cell>-</cell></row><row><cell>Pneumonia (Pa)</cell><cell cols="2">0.748 ± 0.005 0.777 ± 0.003 0.759 ± 0.012</cell><cell>0.784 ± 0.001</cell></row><row><cell>Pneumothorax (Px)</cell><cell cols="2">0.903 ± 0.002 0.893 ± 0.002 0.879 ± 0.005</cell><cell>0.904 ± 0.002</cell></row><row><cell>Support Devices (SD)</cell><cell>0.927 ± 0.001 0.898 ± 0.001</cell><cell>-</cell><cell>-</cell></row><row><cell>Average</cell><cell>0.834</cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>We acknowledge the support of the Natural Sciences and Engineering Research Council of Canada (NSERC, funding number PDF-516984), Microsoft Research, CIFAR, NSERC Discovery Grant, and high performance computing platforms of Vector Institute. We also thank Dr. Alistair Johnson, Dr. Errol Colak and Grey Kuling for productive discussions.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A. Distribution of TPR Disparity per Attributes, Subgroups and Labels</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Radiologist shortage leaves patient care at risk, warns royal college</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rimmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMJ</title>
		<imprint>
			<biblScope unit="volume">359</biblScope>
			<biblScope unit="page">4683</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Diagnostic radiology in liberia: a country report</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Harrington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kenned</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hussain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Global Radiology</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bagheri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Summers</surname></persName>
		</author>
		<title level="m">ChestX-ray8: Hospital-Scale Chest X-Ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">2097</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Poblenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dagunts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Covington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bernard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lyman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10501</idno>
		<title level="m">Learning to diagnose from scratch by exploiting dependencies among labels</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E W</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Pollard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Berkowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">R</forename><surname>Greenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">P</forename><surname>Lungren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Horng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.07042</idno>
		<title level="m">MIMIC-CXR: A large publicly available database of labeled chest radiographs</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Irvin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ciurea-Ilcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chute</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Marklund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Haghgoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ball</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shpanskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Seekins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Mong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Halabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Sandberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">P</forename><surname>Langlotz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">N</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">P</forename><surname>Lungren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.07031</idno>
		<title level="m">CheXpert: A Large Chest Radiograph Dataset with Uncertainty Labels and Expert Comparison</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Irvin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bagul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Langlotz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shpanskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lungren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
		<title level="m">Chexnet: Radiologist-level pneumonia detection on chest x-rays with deep learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Irvin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Ball</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bagul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">P</forename><surname>Langlotz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">N</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">W</forename><surname>Yeom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shpanskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">G</forename><surname>Blankenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Seekins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Amrhein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Mong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Halabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Zucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">P</forename><surname>Lungren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Deep learning for chest radiograph diagnosis: A retrospective comparison of the CheXNeXt algorithm to practicing radiologists</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">1002686</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Thousands of images at the Radiologist&apos;s fingertips seeing the invisible</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Institute</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Practical guidance on artificial intelligence for health-care data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghassemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Naumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Schulam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Beam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ranganath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Lancet Digital Health</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">157</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Can ai help reduce disparities in general medical and mental health care?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghassemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AMA journal of ethics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page">167</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Health disparities by race and class: why both matter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kawachi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Daniels</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Robinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Health Affairs</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page">343</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The girl who cried pain: a bias against women in the treatment of pain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Tarzian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Law</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page">13</biblScope>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
	<note>Medicine &amp; Ethics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">age matters&quot;-german claims data indicate disparities in lung cancer care between elderly and young patients</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Walter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tufman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Holle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Schwarzkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">217434</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Equality of Opportunity in Supervised Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srebro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">3323</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Bias in bios: a case study of semantic representation bias in a high-stakes setting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>De-Arteaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Romanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chayes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Borgs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chouldechova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Geyik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kenthapadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">T</forename><surname>Kalai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<pubPlace>Atlanta, GA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Fair prediction with disparate impact: A study of bias in recidivism prediction instruments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chouldechova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Big data</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">153</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Buolamwini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gebru</surname></persName>
		</author>
		<title level="m">Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">D</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sontag</surname></persName>
		</author>
		<title level="m">Why Is My Classifier Discriminatory?, in NIPS&apos;31</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3539" to="3550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mullainathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Raghavan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.05807</idno>
		<title level="m">Inherent Trade-Offs in the Fair Determination of Risk Scores</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Mathematical notions vs. human perception of fairness: a descriptive approach to fairness for machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Heidari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krause</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.04783</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Implementing machine learning in health careaddressing ethical challenges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Char</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">H</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Magnus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New England Journal of Medicine</title>
		<imprint>
			<biblScope unit="volume">378</biblScope>
			<biblScope unit="page">981</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Dissecting racial bias in an algorithm that guides health decisions for 70 million peoples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Obermeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mullainathan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">89</biblScope>
			<pubPlace>Atlanta, GA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Potential biases in machine learning algorithms using electronic health record data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Gianfrancesco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tamang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yazdany</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Schmajuk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAMA internal medicine</title>
		<imprint>
			<biblScope unit="volume">178</biblScope>
			<biblScope unit="page">1544</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Akbarian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Seyyed-Kalantari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Khalvati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dolatabadi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.13574</idno>
		<title level="m">Evaluating knowledge transfer in neural network for medical images</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V D</forename><surname>Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>Densely Connected Convolutional Networks</publisher>
			<biblScope unit="page">2261</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ImageNet: A Large-Scale Hierarchical Image Database</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980v9</idno>
		<title level="m">Adam: A method for stochastic optimization</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Gender imbalance in medical imaging datasets produces biased classifiers for computer-aided diagnosis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Larrazabal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nieto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Milone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ferrante</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page">12592</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">B</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Namkoong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.08010</idno>
		<title level="m">Fairness Without Demographics in Repeated Loss Minimization</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G J</forename><surname>Miller</surname></persName>
		</author>
		<title level="m">Simultaneous Statistical Inference</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Confounding variables can degrade generalization performance of radiological deep learning models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Zech</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Badgeley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Titano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">K</forename><surname>Oermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS Medicine</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">1002683</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A clinically applicable approach to continuous prediction of future acute kidney injury</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tomašev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Rae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zielinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Askham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saraiva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mottram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Protsyuk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">572</biblScope>
			<biblScope unit="page">116</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Uncovering and Mitigating Algorithmic Bias through Learned Latent Structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Amini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Soleimany</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Schwarting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">N</forename><surname>Bhatia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society -AIES &apos;19</title>
		<meeting>the 2019 AAAI/ACM Conference on AI, Ethics, and Society -AIES &apos;19<address><addrLine>Honolulu, HI, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lemoine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mitchell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.07593</idno>
		<title level="m">Mitigating Unwanted Biases with Adversarial Learning</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Dermatologistlevel classification of skin cancer with deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Esteva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kuprel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Novoa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Swetter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">M</forename><surname>Blau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">542</biblScope>
			<biblScope unit="page">115</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Half a million x-rays! First impressions of the Stanford and MIT chest x-ray datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">˜</forename><surname>Lukeoakdenrayner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
