<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Laplacian Regularized Few-Shot Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Imtiaz</forename><surname>Masud</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziko</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Dolz</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Granger</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ismail</forename><forename type="middle">Ben</forename><surname>Ayed</surname></persName>
						</author>
						<title level="a" type="main">Laplacian Regularized Few-Shot Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose a transductive Laplacian-regularized inference for few-shot tasks. Given any feature embedding learned from the base classes, we minimize a quadratic binary-assignment function containing two terms: (1) a unary term assigning query samples to the nearest class prototype, and (2) a pairwise Laplacian term encouraging nearby query samples to have consistent label assignments. Our transductive inference does not re-train the base model, and can be viewed as a graph clustering of the query set, subject to supervision constraints from the support set. We derive a computationally efficient bound optimizer of a relaxation of our function, which computes independent (parallel) updates for each query sample, while guaranteeing convergence. Following a simple cross-entropy training on the base classes, and without complex meta-learning strategies, we conducted comprehensive experiments over five fewshot learning benchmarks. Our LaplacianShot consistently outperforms state-of-the-art methods by significant margins across different models, settings, and data sets. Furthermore, our transductive inference is very fast, with computational times that are close to inductive inference, and can be used for large-scale few-shot tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Deep learning models have achieved human-level performances in various tasks. The success of these models rely considerably on exhaustive learning from large-scale labeled data sets. Nevertheless, they still have difficulty generalizing to novel classes unseen during training, given only a few labeled instances for these new classes. In contrast, humans can learn new tasks easily from a handful of examples, by leveraging prior experience and related context. <ref type="bibr">1É</ref> TS Montreal, Canada. Correspondence to: Imtiaz Masud Ziko &lt;imtiaz-masud.ziko.1@etsmtl.ca&gt;.</p><p>Proceedings of the 37 th International Conference on Machine Learning, Vienna, Austria, PMLR 119, 2020. Copyright 2020 by the author(s).</p><p>Few-shot learning <ref type="bibr" target="#b3">(Fei-Fei et al., 2006;</ref><ref type="bibr" target="#b18">Miller et al., 2000;</ref><ref type="bibr" target="#b37">Vinyals et al., 2016)</ref> has emerged as an appealing paradigm to bridge this gap. Under standard few-shot learning scenarios, a model is first trained on substantial labeled data over an initial set of classes, often referred to as the base classes. Then, supervision for novel classes, which are unseen during base training, is limited to just one or few labeled examples per class. The model is evaluated over few-shot tasks, each one supervised by a few labeled examples per novel class (the support set) and containing unlabeled samples for evaluation (the query set).</p><p>The problem has recently received substantial research interests, with a large body of work based on complex metalearning and episodic-training strategies. The meta-learning setting uses the base training data to create a set of few-shot tasks (or episodes), with support and query samples that simulate generalization difficulties during test times, and train the model to generalize well on these artificial tasks. For example, <ref type="bibr" target="#b37">(Vinyals et al., 2016)</ref> introduced matching network, which employs an attention mechanism to predict the unknown query samples as a linear combination of the support labels, while using episodic training and memory architectures. Prototypical networks <ref type="bibr" target="#b30">(Snell et al., 2017</ref>) maintain a single prototype representation for each class in the embedding space, and minimize the negative log-probability of the query features with episodic training. <ref type="bibr" target="#b25">Ravi &amp; Larochelle (2017)</ref> viewed optimization as a model for few-shot learning, and used an LSTM meta-learner to update classifier parameters. <ref type="bibr" target="#b4">Finn et al. (2017)</ref> proposed MAML, a meta-learning strategy that attempts to make a model "easy" to fine-tune. These widely adopted works were recently followed by an abundant meta-learning literature, for instance, <ref type="bibr" target="#b32">(Sung et al., 2018;</ref><ref type="bibr" target="#b22">Oreshkin et al., 2018;</ref><ref type="bibr" target="#b19">Mishra et al., 2018;</ref><ref type="bibr" target="#b28">Rusu et al., 2019;</ref><ref type="bibr" target="#b17">Liu et al., 2019b;</ref><ref type="bibr" target="#b8">Hou et al., 2019;</ref><ref type="bibr">Ye et al., 2020)</ref>, among many others.</p><p>Several recent studies explored transductive inference for few-shot tasks, e.g., <ref type="bibr" target="#b17">(Liu et al., 2019b;</ref><ref type="bibr" target="#b8">Hou et al., 2019;</ref><ref type="bibr">Dhillon et al., 2020;</ref><ref type="bibr">Hu et al., 2020;</ref><ref type="bibr" target="#b13">Kim et al., 2019;</ref><ref type="bibr" target="#b23">Qiao et al., 2019)</ref>, among others. Given a few-shot task at test time, transductive inference performs class predictions jointly for all the unlabeled query samples of the task, rather than one sample at a time as in inductive inference. For instance, TPN <ref type="bibr" target="#b17">(Liu et al., 2019b)</ref> used label propagation <ref type="bibr" target="#b50">(Zhou et al., 2004)</ref> along with episodic training and a arXiv: <ref type="bibr">2006.15486v3 [cs.</ref>LG] 28 Apr 2021 specific network architecture, so as to learn how to propagate labels from labeled to unlabeled samples. <ref type="bibr">CAN-T (Hou et al., 2019)</ref> is another meta-learning based transductive method, which uses attention mechanisms to propagate labels to unlabeled query samples. The transductive finetuning method by <ref type="bibr">(Dhillon et al., 2020)</ref> re-train the network by minimizing an additional entropy loss, which encourages peaked (confident) class predictions at unlabeled query points, in conjunction with a standard cross-entropy loss defined on the labeled support set.</p><p>Transductive few-shot methods typically perform better than their inductive counterparts. However, this may come at the price of a much heavier computational complexity during inference. For example, the entropy fine-tuning in <ref type="bibr">(Dhillon et al., 2020)</ref> re-trains the network, performing gradient updates over all the parameters during inference. Also, the label propagation in <ref type="bibr" target="#b17">(Liu et al., 2019b</ref>) requires a matrix inversion, which has a computational overhead that is cubic with respect to the number of query samples. This may be an impediment for deployment for large-scale few-shot tasks.</p><p>We propose a transductive Laplacian-regularized inference for few-shot tasks. Given any feature embedding learned from the base data, our method minimizes a quadratic binary-assignment function integrating two types of potentials: (1) unary potentials assigning query samples to the nearest class prototype, and (2) pairwise potentials favoring consistent label assignments for nearby query samples. Our transductive inference can be viewed as a graph clustering of the query set, subject to supervision constraints from the support set, and does not re-train the base model. Following a relaxation of our function, we derive a computationally efficient bound optimizer, which computes independent (parallel) label-assignment updates for each query point, with guaranteed convergence. We conducted comprehensive experiments on five few-shot learning benchmarks, with different levels of difficulties. Using a simple crossentropy training on the base classes, and without complex meta-learning strategies, our LaplacianShot outperforms state-of-the-art methods by significant margins, consistently providing improvements across different settings, data sets, and training models. Furthermore, our transductive inference is very fast, with computational times that are close to inductive inference, and can be used for large-scale tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Laplacian Regularized Few-Shot Learning</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Proposed Formulation</head><p>In the few-shot setting, we are given a labeled support set X s = C c=1 X c s with C test classes, where each novel class c has |X c s | labeled examples, for instance, |X c s | = 1 for 1-shot and |X c s | = 5 for 5-shot. The objective of few-shot learn-ing is, therefore, to accurately classify unlabeled unseen query sample set X q = C c=1 X c q from these C test classes. This setting is referred to as the |X c s |-shot C-way few-shot learning.</p><p>Let f θ denotes the embedding function of a deep convolutional neural network, with parameters θ and x q = f θ (z q ) ∈ R M encoding the features of a given data point z q . Embedding f θ is learned from a labeled training set X base , with base classes that are different from the few-shot classes of X s and X q . In our work, parameters θ are learned through a basic network training with the standard cross-entropy loss defined over X base , without resorting to any complex episodic-training or meta-learning strategy. For each query feature point x q in a few-shot task, we define a latent binary assignment vector y q = [y q,1 , . . . , y q,C ] t ∈ {0, 1} C , which is within the C-dimensional probability simplex ∇ C = {y ∈ [0, 1] C | 1 t y = 1}: binary y q,c is equal to 1 if x q belongs to class c, and equal to 0 otherwise. t is used as the transpose operator. Let Y denotes the N × C matrix whose rows are formed by y q , where N is the number of query points in X q . We propose a transductive fewshot inference, which minimizes a Laplacian-regularization objective for few-shot tasks w.r.t assignment variables Y, subject to simplex and integer constraints y q ∈ ∇ C and y q ∈ {0, 1} C , ∀q:</p><formula xml:id="formula_0">E(Y) = N (Y) + λ 2 L(Y) (1) N (Y) = N q=1 C c=1 y q,c d(x q − m c ) L(Y) = 1 2 q,p w(x q , x p ) y q − y p 2</formula><p>In (1), the first term N (Y) is minimized globally when each query point is assigned to the class of the nearest prototype m c from the support set, using a distance metric d(x q , m c ), such as the Euclidean distance. In the 1-shot setting, prototype m c is the support example of class c, whereas in multi-shot, m c can be the mean of the support examples. In fact, m c can be further rectified by integrating information from the query features, as we will detail later in our experiments.</p><p>The second term L(Y) is the well-known Laplacian regularizer, which can be equivalently written as tr(Y t LY), where L is the Laplacian matrix 1 corresponding to affinity matrix W = [w(x q , x p )], and tr denotes the trace operator. Pairwise potential w(x q , x p ) evaluates the similarity between feature vectors x q and x p , and can be computed using some kernel function. The Laplacian term encourages nearby Algorithm 1 Proposed Algorithm for LaplacianShot Input: X s , X q , λ, f θ Output: Labels ∈ {1, .., C} N for X q Get prototypes m c . Compute a q using (8a) ∀x q ∈ X q . Initialize i = 1.</p><formula xml:id="formula_1">Initialize y i q = exp(−aq) 1 t exp(−aq) . repeat Compute y i+1 q using (12) y i q ← y i+1 q . Y = [y i q ]; ∀q. i = i + 1. until B i (Y) in (7) does not change l q = arg max c y q ; ∀y q ∈ Y. Labels = {l q } N q=1</formula><p>points (x q , x p ) in the feature space to have the same latent label assignment, thereby regularizing predictions at query samples for few-shot tasks. As we will show later in our comprehensive experiments, the pairwise Laplacian term complements the unary potentials in N (Y), substantially increasing the predictive performance of few-shot learning across different networks, and various benchmark datasets with different levels of difficulty.</p><p>More generally, Laplacian regularization is widely used in the contexts of graph clustering (Von <ref type="bibr" target="#b38">Luxburg, 2007;</ref><ref type="bibr" target="#b29">Shi &amp; Malik, 2000;</ref><ref type="bibr" target="#b51">Ziko et al., 2018;</ref><ref type="bibr" target="#b40">Wang &amp; Carreira-Perpinán, 2014</ref>) and semi-supervised learning <ref type="bibr" target="#b43">(Weston et al., 2012;</ref><ref type="bibr" target="#b0">Belkin et al., 2006)</ref>. For instance, popular spectral graph clustering techniques (Von <ref type="bibr" target="#b38">Luxburg, 2007;</ref><ref type="bibr" target="#b29">Shi &amp; Malik, 2000)</ref> optimize the Laplacian term subject to partitionbalance constraints. In this connection, our transductive inference can be viewed as a graph clustering of the query set, subject to supervision constraints from the support set.</p><p>Regularization parameter λ controls the trade-off between the two terms. It is worth noting that the recent nearestprototype classification in  corresponds to the particular case of λ = 0 of our model in (1). It assigns a query sample x q to the label of the closest support prototype in the feature space, thereby minimizing N (Y):</p><formula xml:id="formula_2">y q,c * = 1 if c * = arg min c∈{1,...,C} d(x q , m c )<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Optimization</head><p>In this section, we propose an efficient bound-optimization technique for solving a relaxed version of our objective in (1), which guarantees convergence, while computing independent closed-form updates for each query sample in few-shot tasks. It is well known that minimizing pairwise functions over binary variables is NP-hard <ref type="bibr" target="#b34">(Tian et al., 2014)</ref>, and a standard approach in the context of clustering algorithms is to relax the integer constraints, for instance, using a convex <ref type="bibr" target="#b40">(Wang &amp; Carreira-Perpinán, 2014)</ref> or a concave relaxation <ref type="bibr" target="#b51">(Ziko et al., 2018)</ref>. In fact, by relaxing integer constraints y q ∈ {0, 1} C , our objective in (1) becomes a convex quadratic problem. However, this would require solving for the N × C assignment variables all together, with additional projections steps for handling the simplex constraints. In this work, we use a concave relaxation of the Laplacian-regularized objective in <ref type="formula">(1)</ref>, which, as we will later show, yields fast independent and closed-form updates for each assignment variable, with convergence guarantee. Furthermore, it enables us to draw interesting connections between Laplacian regularization and attention mechanisms in few-shot learning <ref type="bibr" target="#b37">(Vinyals et al., 2016)</ref>.</p><p>It is easy to verify that, for binary (integer) simplex variables, the Laplacian term in (1) can be written as follows, after some simple manipulations:</p><formula xml:id="formula_3">L(Y) = q D q − q,p w(x q , x p )y t q y p<label>(3)</label></formula><p>where D q = p w(x q , x p ) denotes the degree of query sample x q . By relaxing integer constraints y q ∈ {0, 1} C , the expression in Eq. (3) can be viewed as a concave relaxation 2 for Laplacian term L(Y) when symmetric affinity matrix W = [w(x q , x p )] is positive semi-definite. As we will see in the next paragraph, concavity is important to derive an efficient bound optimizer for our model, with independent and closed-form updates for each query sample. Notice that the first term in relaxation (3) is a constant independent of the soft (relaxed) assignment variables.</p><p>We further augment relaxation (3) with a convex negativeentropy barrier function y t q log y q , which avoids expensive projection steps and Lagrangian-dual inner iterations for the simplex constraints of each query point. Such a barrier 3 removes the need for extra dual variables for constraints y q ≥ 0 by restricting the domain of each assignment variable to non-negative values, and yields closed-form updates for the dual variables of constraints 1 t y q = 1. Notice that this barrier function is null at the vertices of the simplex. Putting all together, and omitting the additive constant q D q in (3), we minimize the following concave-convex relaxation of our objective in (1) w.r.t soft assignment variables Y, subject to simplex constraints y q ∈ ∇ C , ∀q:</p><formula xml:id="formula_4">R(Y) = Y t log Y + N (Y) + λ 2L (Y)<label>(4)</label></formula><p>whereL(Y) = − q,p w(x q , x p )y t q y p . Bound optimization: In the following, we detail an iterative bound-optimization solution for relaxation (4). Bound optimization, often referred to as MM (Majorize-Minimization) framework <ref type="bibr" target="#b14">(Lange et al., 2000;</ref><ref type="bibr" target="#b49">Zhang et al., 2007)</ref>, is a general optimization principle 4 . At each iteration, it updates the variable as the minimum of a surrogate function, i.e., an upper bound on the original objective, which is tight at the current iteration. This guarantees that the original objective does not increase at each iteration.</p><p>Re-arranging the soft assignment matrix Y in vector form Y = [y q ] ∈ R N C , relaxationL(Y) can be written conveniently in the following form:</p><formula xml:id="formula_5">L(Y) = − q,p w(x q , x p )y t q y p = Y t ΨY<label>(5)</label></formula><p>with Ψ = −W ⊗ I, where ⊗ denotes the Kronecker product and I is the N × N identity matrix. Note that Ψ is negative semi-definite for a positive semi-definite W. Therefore, Y t ΨY is a concave function, and the first-order approximation of (5) at a current solution Y i (i is the iteration index) gives the following tight upper bound onL(Y):</p><formula xml:id="formula_6">L(Y) = Y t ΨY ≤ (Y i ) t ΨY i + 2 (ΨY i ) t (Y − Y i ) (6)</formula><p>Therefore, using unary potentials N (Y) and the negative entropy barrier in conjunction with the upper bound in <ref type="formula">(6)</ref>, we obtain the following surrogate function</p><formula xml:id="formula_7">B i (Y) for relax- ation R(Y) at current solution Y i : R(Y) ≤ B i (Y) c = N q=1 y t q (log(y q ) + a q − λb i q ) (7)</formula><p>where c = means equality up to an additive constant 5 that is independent of variable Y, and a q and b i q are the following C-dimensional vectors:</p><formula xml:id="formula_8">a q = [a q,1 , . . . , a q,C ] t ; a q,c = d(x q , m c ) (8a) b i q = [b i q,1 , . . . , b i q,C ] t ; b i q,c = p w(x q , x p )y i p,c<label>(8b)</label></formula><p>It is straightforward to verify that upper bound</p><formula xml:id="formula_9">B i (Y) is tight at the current iteration, i.e., B i (Y i ) = R(Y i ). This 4</formula><p>The general MM principle is widely used in machine learning in various problems as it enables to replace a difficult optimization problem with a sequence of easier sub-problems <ref type="bibr" target="#b49">(Zhang et al., 2007)</ref>. Examples of well-known bound optimizers include expectation-maximization (EM) algorithms, the concave-convex procedure (CCCP) <ref type="bibr" target="#b46">(Yuille &amp; Rangarajan, 2001</ref>) and submodularsupermodular procedures (SSP) <ref type="bibr" target="#b21">(Narasimhan &amp; Bilmes, 2005)</ref>, among many others. <ref type="bibr">5</ref> The additive constant in Bi(Y) is a term that depends only on Y i . This term comes from the Laplacian upper bound in <ref type="formula">(6).</ref> can be seen easily from the first-order approximation in (6). We iteratively optimize the surrogate function at each iteration i: <ref type="formula">(9)</ref>, it is easy to verify that updates (9) guarantee that relaxation R(Y) does not increase at each iteration:</p><formula xml:id="formula_10">Y i+1 = arg min Y B i (Y) (9) Because of upper-bound condition R(Y) ≤ B i (Y), ∀Y, tightness condition B i (Y i ) = R(Y i ) at the current solu- tion, and the fact that B i (Y i+1 ) ≤ B i (Y i ) due to minimiza- tion</formula><formula xml:id="formula_11">R(Y i+1 ) ≤ B i (Y i+1 ) ≤ B i (Y i ) = R(Y i )</formula><p>Closed-form solutions of the surrogate functions: Notice that B i (Y) is a sum of independent functions of each assignment variable. Therefore, we can solve (9) for each y q independently, while satisfying the simplex constraint:</p><formula xml:id="formula_12">min yq∈∇ C y t q (log(y q ) + a q − λb i q ), ∀q<label>(10)</label></formula><p>The negative entropy barrier term y t q log y q in (10) restricts y q to be non-negative, removing the need of extra dual variables for the constraints y q &gt; 0. Also, simplex constraint 1 t y q = 1 is affine. Thus, the solution of the following Karush-Kuhn-Tucker (KKT) condition provide the minimum of (10):</p><formula xml:id="formula_13">log y q + a q − λb i q + β1 = 0<label>(11)</label></formula><p>with β the Lagrange multiplier for the simplex constraint. This provides, for each q, closed-form solutions for both the primal and dual variables, yielding the following independent updates of the assignment variables:</p><formula xml:id="formula_14">y i+1 q = exp(−a i q + λb i q ) 1 t exp(−a i q + λb i q ) ∀ q<label>(12)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Proposed Algorithm</head><p>The overall proposed algorithm is simplified in Algorithm 1. Once the network function f θ is learned using the base dataset X base , our algorithm proceeds with the extracted features x q . Before the iterative bound updates, each soft assignment y 1 q is initialized as a softmax probability of a q , which is based on the distances to prototypes m c . The iterative bound optimization is guaranteed to converge, typically less than 15 iterations in our experiments <ref type="figure">(Figure 2</ref>). Also the independent point-wise bound updates yield a parallel structure of the algorithm, which makes it very efficient (and convenient for large-scale few-shot tasks). We refer to our method as LaplacianShot in the experiments.</p><p>Link to attention mechanisms: Our Laplacian-regularized model has interesting connection to the popular attention mechanism in <ref type="bibr" target="#b36">(Vaswani et al., 2017)</ref>. In fact, MatchingNet  <ref type="bibr" target="#b4">(Finn et al., 2017)</ref> ResNet-18 49.61 ± 0.92 65.72 ± 0.77 --Chen  ResNet-18 51.87 ± 0.77 75.68 ± 0.63 --RelationNet <ref type="bibr" target="#b32">(Sung et al., 2018)</ref> ResNet-18 52.48 ± 0.86 69.83 ± 0.68 --MatchingNet <ref type="bibr" target="#b37">(Vinyals et al., 2016)</ref> ResNet-18 52.91 ± 0.88 68.88 ± 0.69 --ProtoNet <ref type="bibr" target="#b30">(Snell et al., 2017)</ref> ResNet-18 54.16 ± 0.82 73.68 ± 0.65 --Gidaris <ref type="bibr" target="#b5">(Gidaris &amp; Komodakis, 2018)</ref> ResNet-15 55.45 ± 0.89 70.13 ± 0.68 --SNAIL <ref type="bibr" target="#b19">(Mishra et al., 2018)</ref> ResNet-15 55.71 ± 0.99 68.88 ± 0.92 --AdaCNN <ref type="bibr" target="#b20">(Munkhdalai et al., 2018)</ref> ResNet-15 56.88 ± 0.62 71.94 ± 0.57 --TADAM <ref type="bibr" target="#b22">(Oreshkin et al., 2018)</ref> ResNet-15 58.50 ± 0.30 76.70 ± 0.30 --CAML <ref type="bibr" target="#b12">(Jiang et al., 2019)</ref> ResNet-12 59.23 ± 0.99 72.35 ± 0.71 --TPN <ref type="bibr" target="#b17">(Liu et al., 2019b)</ref> ResNet-12 59.46 75.64 --TEAM <ref type="bibr" target="#b23">(Qiao et al., 2019)</ref> ResNet-18 60.07 75.90 --MTL <ref type="bibr" target="#b31">(Sun et al., 2019)</ref> ResNet-18 61.20 ± 1.80 75.50 ± 0.80 --VariationalFSL <ref type="bibr" target="#b48">(Zhang et al., 2019)</ref> ResNet-18 61.23 ± 0.26 77.69 ± 0.17 --Transductive tuning <ref type="bibr">(Dhillon et al., 2020)</ref>   <ref type="bibr" target="#b37">(Vinyals et al., 2016)</ref> predicted the labels of the query samples x q as a linear combination of the support labels. The expression of b i q,c that we obtained in (8b), which stems from our bound optimizer and the concave relaxation of the Laplacian, also takes the form of a combination of labels at each iteration i in our model: b i q,c = p w(x q , x p )y i p,c . However, there are important differences with <ref type="bibr" target="#b37">(Vinyals et al., 2016)</ref>: First, the attention in our formulation is non-parametric as it considers only the feature relationships among the query samples in X q , not the support examples. Second, unlike our approach, the attention mechanism in <ref type="bibr" target="#b37">(Vinyals et al., 2016)</ref> is employed during training for learning embedding function f θ with a meta-learning approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiments</head><p>In this section, we describe our experimental setup. An implementation of our LaplacianShot is publicly available 6 . 6 https://github.com/imtiazziko/LaplacianShot</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Datasets</head><p>We used five benchmarks for few-shot classification: miniImageNet, tieredImageNet, CUB, cross-domain CUB (with base training on miniImageNet) and iNat.</p><p>The miniImageNet benchmark is a subset of the larger ILSVRC-12 dataset <ref type="bibr" target="#b27">(Russakovsky et al., 2015)</ref>. It has a total of 60,000 color images with 100 classes, where each class has 600 images of size 84 × 84, following <ref type="bibr" target="#b37">(Vinyals et al., 2016)</ref>. We use the standard split of 64 base, 16 validation and 20 test classes <ref type="bibr" target="#b25">(Ravi &amp; Larochelle, 2017;</ref><ref type="bibr" target="#b41">Wang et al., 2019)</ref>. The tieredImageNet benchmark <ref type="bibr" target="#b26">(Ren et al., 2018)</ref> is also a subset of ILSVRC-12 dataset but with 608 classes instead. We follow standard splits with 351 base, 97 validation and 160 test classes for the experiments. The images are also resized to 84 × 84 pixels. CUB-200-2011 <ref type="bibr" target="#b39">(Wah et al., 2011</ref>) is a fine-grained image classification dataset. We follow  for few-shot classification on CUB, which splits into 100 base, 50 validation and 50 test classes for the experiments. The images are also resized to 84 × 84 pixels, as in miniImageNet. The iNat benchmark, introduced recently for few-shot classification in <ref type="bibr" target="#b42">(Wertheimer &amp; Hariharan, 2019)</ref>, contains images of 1,135 animal species. It introduces a more challenging fewshot scenario, with different numbers of support examples per class, which simulates more realistic class-imbalance scenarios, and with semantically related classes that are not easily separable. Following <ref type="bibr" target="#b42">(Wertheimer &amp; Hariharan, 2019)</ref>, the dataset is split into 908 base classes and 227 test classes, with images of size 84 × 84.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Evaluation Protocol</head><p>In the case of miniImageNet, CUB and tieredImageNet, we evaluate 10,000 five-way 1-shot and five-way 5-shot classification tasks, randomly sampled from the test classes, following standard few-shot evaluation settings <ref type="bibr" target="#b28">Rusu et al., 2019)</ref>. This means that, for each of the five-way few-shot tasks, C = 5 classes are randomly selected, with |X c s | = 1 (1-shot) and |X c s | = 5 (5-shot) examples selected per class, to serve as support set X s . Query set X q contains 15 images per class. Therefore, the evaluation is performed over N = 75 query images per task. The average accuracy of these 10,000 few shot tasks are reported along with the 95% confidence interval. For the iNat benchmark, the number of support examples |X c s | per class varies. We performed 227-way multi-shot evaluation, and report the top-1 accuracy averaged over the test images per class (Per Class in <ref type="table">Table 3</ref>), as well as the average over all test images (Mean in <ref type="table">Table 3</ref>), following the same procedure as in <ref type="bibr" target="#b42">(Wertheimer &amp; Hariharan, 2019;</ref><ref type="bibr" target="#b41">Wang et al., 2019)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Network Models</head><p>We evaluate LaplacianShot on four different backbone network models to learn feature extractor f θ :</p><p>ResNet-18/50 is based on the deep residual network architecture <ref type="bibr" target="#b7">(He et al., 2016)</ref>, where the first two down-sampling layers are removed, setting the stride to 1 in the first convolutional layer and removing the first max-pool layer. The first convolutional layer is used with a kernel of size 3×3 instead of 7 × 7. ResNet-18 has 8 basic residual blocks, and ResNet-50 has 16 bottleneck blocks. For all the networks, the dimension of the extracted features is 512. MobileNet <ref type="bibr" target="#b9">(Howard et al., 2017)</ref> was initially proposed as a light-weight convolutional network for mobile-vision applications. In our setting, we remove the first two down-sampling operations, which results in a feature embedding of size 1024. WRN <ref type="bibr" target="#b47">(Zagoruyko &amp; Komodakis, 2016)</ref> widens the residual blocks by adding more convolutional layers and feature planes. In our case, we used 28 convolutional layers, with a widening factor of 10 and an extracted-feature dimension of 640. Finally, we used the standard 121-layer DenseNet <ref type="bibr" target="#b11">(Huang et al., 2017)</ref>, omitting the first two down-sampling layers and setting the stride to 1. We changed the kernel size of the first convolutional layer to 3 × 3. The extracted feature vector is of dimension 1024. <ref type="figure">Figure 1</ref>. We tune regularization parameter λ over values ranging from 0.1 to 1.5. In the above plots, we show the impact of choosing λ on both validation and test accuracies. The values of λ based on the best validation accuracies correspond to good accuracies in the test classes. The results are shown for different networks on miniImageNet dataset, for both 1-shot (top row) and 5-shot (bottom row).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2.</head><p>Convergence of Algorithm 1: Bounds Bi(Y) vs. iteration numbers for features from different networks. Here, the plots are produced by setting λ = 1.0, for a single 5-way 5 shot task from the miniImageNet test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Implementation Details</head><p>Network model training: We trained the network models using the standard cross-entropy loss on the base classes, with a label-smoothing <ref type="bibr" target="#b33">(Szegedy et al., 2016)</ref> parameter set to 0.1. Note that the base training did not involve any metalearning or episodic-training strategy. We used the SGD optimizer to train the models, with mini-batch size set to 256 for all the networks, except for WRN and DenseNet, where we used mini-batch sizes of 128 and 100, respectively. We used two 16GB P100 GPUs for network training with base classes. For miniImageNet, CUB and tieredImageNet, we used early stopping by evaluating the the nearest-prototype classification accuracy on the validation classes, with L2 normalized features.</p><p>Prototype estimation and feature transformation: Dur-ing the inference on test classes, SimpleShot  performs the following feature transformations: L2 normalization, x q := x q / x q 2 and CL2, which computes the mean of the base class featuresx = 1 |Xbase| x∈Xbase x and centers the extracted features as x q := x q −x, which is followed by an L2 normalization. We report the results in <ref type="table" target="#tab_0">Table 1</ref> and 2 with CL2 normalized features. In <ref type="table">Table 3</ref> for the iNat dataset, we provide the results with both normalized and unnormalized (UN) features for a comparative analysis. We reproduced the results of SimpleShot with our trained network models. In the 1-shot setting, prototype m c is just the support example x q ∈ X c s of class c, whereas in multi-shot, m c is the simple mean of the support examples of class c. Another option is to use rectified prototypes, i.e., a weighted combination of features from both the support examples in X c s and query samples in X c q , which are initially predicted as belonging to class c using Eq. <ref type="formula" target="#formula_2">(2)</ref>:</p><formula xml:id="formula_15">m c = 1 |X c s | + |X c q | xp∈{X c s ,X c q } exp(cos(x p , m c )) C c=1 exp(cos(x p , m c )) x p ,</formula><p>where cos denotes the cosine similarity. And, for a given few-shot task, we compute the cross-domain shift ∆ as the difference between the mean of features within the support set and the mean of features within the query set:</p><formula xml:id="formula_16">∆ = 1 |Xs| xp∈Xs x p − 1 |Xq| xq∈Xq x q .</formula><p>Then, we rectify each query point x p ∈ X q in the few-shot task as follows:</p><p>x p = x p + ∆. This shift correction is similar to the prototype rectification in <ref type="bibr" target="#b16">(Liu et al., 2019a)</ref>. Note that our LaplacianShot model in Eq. (1) is agnostic to the way of estimating the prototypes: It can be used either with the standard prototypes (m c ) or with the rectified ones (m c ). We report the results of LaplacianShot with the rectified prototypes in <ref type="table" target="#tab_0">Table 1</ref> and 2, for miniImagenet, tieredImagenet and CUB. We do not report the results with the rectified prototypes in <ref type="table">Table 3</ref> for iNat, as rectification drastically worsen the performance.</p><p>For W, we used the k-nearest neighbor affinities as follows: w(x q , x p ) = 1 if x p is within the k nearest neighbor of x q , and w(x q , x p ) = 0 otherwise. In our experiments, k is simply chosen from three typical values (3, 5 or 10) tuned over 500 few-shot tasks from the base training classes (i.e., we did not use test data for choosing k). We used k = 3 for miniImageNet, CUB and tieredImageNet and k = 10 for iNat benchmark. Regularization parameter λ is chosen based on the validation class accuracy for miniImageNet, CUB and tieredImageNet. This will be discussed in more details in section 3.6. For the iNat experiments, we simply fix λ = 1.0, as there is no validation set for this benchmark.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Results</head><p>We evaluated LaplacianShot over five different benchmarks, with different scenarios and difficulties: Generic image classification, fine-grained image classification, crossdomain adaptation, and imbalanced class distributions. We report the results of LaplacianShot for miniImageNet, tieredImageNet, CUB and iNat datasets, in <ref type="table" target="#tab_0">Tables 1, 2</ref> and 3, along with comparisons with state-of-the-art methods. <ref type="table" target="#tab_0">Table 1</ref> reports the results of generic image classification for the standard miniImageNet and tieredImageNet few-shot benchmarks. We can clearly observe that LaplacianShot outperforms state-of-the-art methods by large margins, with gains that are consistent across different settings and network models. It is worth mentioning that, for challenging scenarios, e.g., 1-shot with low-capacity models, LaplacianShot outperforms complex meta-learning methods by more than 9%. For instance, compared to well-known MAML <ref type="bibr" target="#b4">(Finn et al., 2017)</ref> and ProtoNet <ref type="bibr" target="#b30">(Snell et al., 2017)</ref>, and to the recent MetaoptNet <ref type="bibr" target="#b15">(Lee et al., 2019)</ref>, LaplacianShot brings improvements of nearly 22%, 17%, and 9%, respectively, under the same evaluation conditions. Furthermore, it outperforms the very recent transductive approaches in <ref type="bibr">(Dhillon et al., 2020;</ref><ref type="bibr" target="#b16">Liu et al., 2019a;</ref> by significant margins. With better learned features with WRN and DenseNet, LaplacianShot brings significant performance boosts, yielding state-of-the art results in few-shot classification, without meta-learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generic image classification:</head><p>Fine-grained image classification: <ref type="table" target="#tab_2">Table 2</ref> reports the results of fine-grained few-shot classification on CUB, with Resnet-18 network. LaplacianShot outperforms the best performing method in this setting by a 7% margin.</p><p>Cross-domain (mini-ImageNet → CUB): We perform the very interesting few-shot experiment, with a cross-domain scenario, following the setting in . We used the ResNet-18 model trained on the miniImagenet base classes, while evaluation is performed on CUB few-shot tasks, with 50 test classes. Table 2 (rightmost column) reports the results. In this cross-domain setting, and consistently with the standard settings, LaplacianShot outperforms complex meta-learning methods by substantial margins. <ref type="table">Table 3</ref> reports the results for the more challenging, class-imbalanced iNat benchmark, with different numbers of support examples per class and, also, with high visual similarities between the different classes, making class separation difficult. To our knowledge, only <ref type="bibr" target="#b42">(Wertheimer &amp; Hariharan, 2019;</ref><ref type="bibr" target="#b41">Wang et al., 2019)</ref> report performances on this benchmark, and SimpleShot  represents the state-of-the-art. We compared with SimpleShot using unnormalized extracted features (UN), L2 and CL2 normalized features. Our Laplacian regularization yields significant improvements, regardless of the network model and feature normalization. However, unlike SimpleShot, our method reaches its best performance with the unnormalized features. Note that, for iNat, we did not use the rectified prototypes. These results clearly highlight the benefit Laplacian regularization brings in challenging class-imbalance scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Imbalanced class distribution:</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Ablation Study</head><p>Choosing the Value of λ: In LaplacianShot, we need to choose the value of regularization parameter λ, which controls the trade-off between the nearest-prototype classifier term a q and Laplacian regularizer b i q . We tuned this parameter using the validation classes by sampling 500 few-shot tasks. LaplacianShot is used in each few-shot task with the following values of λ: [0.1, 0.3, 0.5, 0.7, 0.8, 1.0, 1.2, 1.5]. The best λ corresponding to the best average 1-shot and 5-shot accuracy over validation classes/data is selected for inference over the test classes/data. To examine experimentally whether the chosen values of λ based on the best validation accuracies correspond to good accuracies in the </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods inference time</head><p>SimpleShot  0.009 Transductive tuning <ref type="bibr">(Dhillon et al., 2020)</ref> 20.7 LaplacianShot (ours) 0.012 test classes, we plotted both the validation and test class accuracies vs. different values of λ for miniImageNet ( <ref type="figure">Figure  1)</ref>. The results are intuitive, with a consistent trend in both 1-shot and 5-shot settings. Particularly, for 1-shot tasks, λ = 0.7 provides the best results in both validation and test accuracies. In 5-shot tasks, the best test results are obtained mostly with λ = 0.1, while the best validation accuracies were reached with higher values of λ. Nevertheless, we report the results of LaplacianShot with the values of λ chosen based on the best validation accuracies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effects of Laplacian regularization:</head><p>We conducted an ablation study on the effect of each term in our model, i.e., nearest-prototype classifier N (Y) and Laplacian regularizer L(Y). We also examined the effect of using prototype rectification, i.e.,m c instead of m c . <ref type="table" target="#tab_3">Table 4</ref> reports the results, using the ResNet-18 network. The first row corresponds to the prediction of the nearest neighbor classifier (λ = 0), and the second shows the effect of adding Laplacian regularization. In the 1-shot case, the latter boosts the performances by at least 3%. Prototype rectification (third and fourth rows) also boosts the performances. Again, in this case, the improvement that the Laplacian term brings is significant, particularly in the 1-shot case (2 to 3%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Convergence of transductive LaplacianShot inference:</head><p>The proposed algorithm belongs to the family of bound optimizers or MM algorithms. In fact, the MM principle can be viewed as a generalization of expectation-maximization (EM). Therefore, in general, MM algorithms inherit the monotonicity and convergence properties of EM algorithms <ref type="bibr" target="#b35">(Vaida, 2005)</ref>, which are well-studied in the literature. In fact, Theorem 3 in <ref type="bibr" target="#b35">(Vaida, 2005)</ref> states a simple condition for convergence of the general MM procedure, which is almost always satisfied in practice: The surrogate function has a unique global minimum. In <ref type="figure">Fig. 2</ref>, we plotted surrogates B i (Y), up to a constant, i.e., Eq. <ref type="formula">(7)</ref>, as functions of the iter-ation numbers, for different networks. One can see that the value of B i (Y) decreases monotonically at each iteration, and converges, typically, within less than 15 iterations.</p><p>Inference time: We computed the average inference time required for each 5-shot task. <ref type="table">Table 5</ref> reports these inference times for miniImageNet with the WRN network. The purpose of this is to check whether there exist a significant computational overhead added by our Laplacian-regularized transductive inference, in comparison to inductive inference. Note that the computational complexity of the proposed inference is O(N kC) for a few-shot task, where k is the neighborhood size for affinity matrix W. The inference time per few-shot task for LaplacianShot is close to inductive SimpleShot run-time (LaplacianShot is only 1-order of magnitude slower), and is 3-order-of-magnitude faster than the transductive fine-tuning in <ref type="bibr">(Dhillon et al., 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>Without meta-learning, we provide state-of-the-art results, outperforming significantly a large number of sophisticated few-shot learning methods, in all benchmarks. Our transductive inference is a simple constrained graph clustering of the query features. It can be used in conjunction with any base-class training model, consistently yielding improvements. Our results are in line with several recent baselines <ref type="bibr">(Dhillon et al., 2020;</ref><ref type="bibr" target="#b1">Chen et al., 2019;</ref><ref type="bibr" target="#b41">Wang et al., 2019)</ref> that reported competitive performances, without resorting to complex meta-learning strategies. This recent line of simple methods emphasizes the limitations of current few-shot benchmarks, and questions the viability of a large body of convoluted few-shot learning techniques in the recent literature. As pointed out in <ref type="figure">Fig. 1</ref> in <ref type="bibr">(Dhillon et al., 2020)</ref>, the progress made by an abundant recent few-shot literature, mostly based on meta-learning, may be illusory. Classical and simple regularizers, such as the entropy in <ref type="bibr">(Dhillon et al., 2020)</ref> or our Laplacian term, well-established in semisupervised learning and clustering, achieve outstanding performances. We do not claim to hold the ultimate solution for few-shot learning, but we believe that our model-agnostic transductive inference should be used as a strong baseline for future few-shot learning research.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Average accuracy (in %) in miniImageNet and tieredImageNet. The best results are reported in bold font.</figDesc><table><row><cell>miniImageNet</cell><cell>tieredImageNet</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Results for CUB and cross-domain results on miniImagenet → CUB.</figDesc><table><row><cell>Methods</cell><cell></cell><cell></cell><cell cols="2">Network</cell><cell cols="4">CUB 1-shot 5-shot 1-shot miniImagenet → CUB 5-shot</cell></row><row><cell cols="5">MatchingNet (Vinyals et al., 2016) ResNet-18</cell><cell>73.49</cell><cell>84.45</cell><cell>-</cell><cell>53.07</cell></row><row><cell cols="2">MAML (Finn et al., 2017)</cell><cell></cell><cell cols="2">ResNet-18</cell><cell>68.42</cell><cell>83.47</cell><cell>-</cell><cell>51.34</cell></row><row><cell cols="2">ProtoNet (Snell et al., 2017)</cell><cell></cell><cell cols="2">ResNet-18</cell><cell>72.99</cell><cell>86.64</cell><cell>-</cell><cell>62.02</cell></row><row><cell cols="3">RelationNet (Sung et al., 2018)</cell><cell cols="2">ResNet-18</cell><cell>68.58</cell><cell>84.05</cell><cell>-</cell><cell>57.71</cell></row><row><cell cols="2">Chen (Chen et al., 2019)</cell><cell></cell><cell cols="2">ResNet-18</cell><cell>67.02</cell><cell>83.58</cell><cell>-</cell><cell>65.57</cell></row><row><cell cols="3">SimpleShot (Wang et al., 2019)</cell><cell cols="2">ResNet-18</cell><cell>70.28</cell><cell>86.37</cell><cell>48.56</cell><cell>65.63</cell></row><row><cell cols="2">LaplacianShot(ours)</cell><cell></cell><cell cols="2">ResNet-18</cell><cell>80.96</cell><cell>88.68</cell><cell>55.46</cell><cell>66.33</cell></row><row><cell cols="9">Table 3. Average accuracy (in %) in iNat benchmark for SimpleShot (Wang et al., 2019) and the proposed LaplacianShot. The best results</cell></row><row><cell cols="9">are reported in bold font. Note that, for iNat, we do not utilize the rectified prototypes. [The best reported result of (Wertheimer &amp;</cell></row><row><cell cols="6">Hariharan, 2019) with ResNet50 is: Per Class: 46.04%, Mean: 51.25%.]</cell><cell></cell><cell></cell></row><row><cell>Methods</cell><cell>Network</cell><cell cols="7">UN Per Class Mean Per Class Mean Per Class Mean L2 CL2</cell></row><row><cell>SimpleShot</cell><cell>ResNet-18</cell><cell></cell><cell>55.80</cell><cell>58.56</cell><cell>57.15</cell><cell cols="2">59.56</cell><cell>56.35</cell><cell>58.63</cell></row><row><cell cols="2">LaplacianShot ResNet-18</cell><cell></cell><cell>62.80</cell><cell>66.40</cell><cell>58.72</cell><cell cols="2">61.14</cell><cell>58.49</cell><cell>60.81</cell></row><row><cell>SimpleShot</cell><cell>ResNet-50</cell><cell></cell><cell>58.45</cell><cell>61.07</cell><cell>59.68</cell><cell cols="2">61.99</cell><cell>58.83</cell><cell>60.98</cell></row><row><cell cols="2">LaplacianShot ResNet-50</cell><cell></cell><cell>65.96</cell><cell>69.13</cell><cell>61.40</cell><cell cols="2">63.66</cell><cell>61.08</cell><cell>63.18</cell></row><row><cell>SimpleShot</cell><cell>WRN</cell><cell></cell><cell>62.44</cell><cell>65.08</cell><cell>64.26</cell><cell cols="2">66.25</cell><cell>63.03</cell><cell>65.17</cell></row><row><cell>LaplacianShot</cell><cell>WRN</cell><cell></cell><cell>71.55</cell><cell>74.97</cell><cell>65.78</cell><cell cols="2">67.82</cell><cell>65.32</cell><cell>67.43</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>Ablation study on the effect of each term corresponding to nearest prototype N (Y), Laplacian L(Y) and rectified prototypemc. Results are reported with ResNet-18 network. Note that, the Laplacian regularization L(Y) improve the results consistently.</figDesc><table><row><cell cols="4">mini-ImageNet tiered-ImageNet</cell><cell>CUB</cell></row><row><cell cols="3">N (Y) L(Y)mc 1-shot 5-shot 1-shot</cell><cell>5-shot</cell><cell>1shot 5-shot</cell></row><row><cell>63.10</cell><cell>79.92</cell><cell>69.68</cell><cell>84.56</cell><cell>70.28 86.37</cell></row><row><cell>66.20</cell><cell>80.75</cell><cell>72.89</cell><cell>85.25</cell><cell>74.46 86.86</cell></row><row><cell>69.74</cell><cell>82.01</cell><cell>76.73</cell><cell>85.74</cell><cell>78.76 88.55</cell></row><row><cell>72.11</cell><cell>82.31</cell><cell>78.98</cell><cell>86.39</cell><cell>80.96 88.68</cell></row><row><cell cols="2">Table 5. Average inference time (in seconds) for the 5-shot tasks</cell><cell></cell><cell></cell><cell></cell></row><row><cell>in miniImagenet dataset.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The Laplacian matrix corresponding to affinity matrix W = [w(xq, xp)] is L = D − W, with D the diagonal matrix whose diagonal elements are given by: Dq = p w(xq, xp).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Equality (3) holds in for points on the vertices of the simplex, i.e., yq ∈ {0, 1} C , but is an approximation for points within the simplex (soft assignments), i.e., yq ∈]0, 1[ C .3 Note that entropy-like barriers are known in the context of Bregman-proximal optimization<ref type="bibr" target="#b45">(Yuan et al., 2017)</ref>, and have well-known computational benefits when dealing with simplex constraints.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Manifold regularization: A geometric framework for learning from labeled and unlabeled examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Niyogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sindhwani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="2399" to="2434" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A closer look at few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><forename type="middle">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-B</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A baseline for few-shot image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chaudhari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">One-shot learning of object categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="594" to="611" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Model-agnostic metalearning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Dynamic few-shot visual learning without forgetting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Boosting few-shot visual learning with selfsupervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bursuc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pérez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cord</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Cross attention network for few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bingpeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Weyand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andreetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mobilenets</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.04861</idno>
		<title level="m">Efficient convolutional neural networks for mobile vision applications</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">Preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Empirical bayes transductive meta-learning with synthetic gradients</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">G</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Obozinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Damianou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning to learn with conditional class dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Havaei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Varno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chartrand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chapados</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Matwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Edge-labeling graph neural network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Optimization transfer using surrogate objective functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lange</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of computational and graphical statistics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Metalearning with differentiable convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Prototype rectification for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.10713</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">Preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning to propagate labels: Transductive propagation network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning from one example through shared densities on transforms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Matsakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Viola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A simple neural attentive meta-learner</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohaninejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Rapid adaptation with conditionally shifted neurons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munkhdalai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mehri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Trischler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A submodular-supermodular procedure with applications to discriminative structure learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bilmes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Uncertainty in Artificial Intelligence (UAI)</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Task dependent adaptive metric for improved few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Oreshkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">R</forename><surname>López</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lacoste</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tadam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Transductive episodic-wise adaptive metric for fewshot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Few-shot image recognition by predicting parameters from activations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuille</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Optimization as a model for fewshot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Metalearning for semi-supervised few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">ImageNet Large Scale Visual Recognition Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Meta-learning with latent embedding optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sygnowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Normalized cuts and image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="888" to="905" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Meta-transfer learning for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning to compare: Relation network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning deep representations for graph clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Parameter convergence for em and mm algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Vaida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistica Sinica</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="831" to="840" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">P</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A tutorial on spectral clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Von</forename><surname>Luxburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics and computing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="395" to="416" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">The caltech-ucsd birds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">The laplacian k-modes algorithm for clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Carreira-Perpinán</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.3895</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">Preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Simpleshot: Revisiting nearestneighbor classification for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-L</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.04623</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">Preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Few-shot learning with localization in realistic settings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wertheimer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Deep learning via semi-supervised embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ratle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mobahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural networks: Tricks of the trade</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="639" to="655" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Few-shot learning via embedding adaptation with set-to-set functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-C</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sha</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Bregmanproximal augmented lagrangian approach to multiphase image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Scale Space and Variational Methods in Computer Vision (SSVM)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">The concave-convex procedure (CCCP)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rangarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Wide residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference (BMVC)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Variational few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Surrogate maximization/minimization algorithms and extensions. Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-Y</forename><surname>Yeung</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="1" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Learning with local and global consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Lal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Scalable laplacian k-modes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Ziko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Granger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Ayed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
