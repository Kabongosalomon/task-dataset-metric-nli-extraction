<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">aNMM: Ranking Short Answer Texts with Attention-Based Neural Matching Model</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liu</forename><surname>Yang</surname></persName>
							<email>lyang@cs.umass.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Center for Intelligent Information Retrieval</orgName>
								<orgName type="institution">University of Massachusetts Amherst</orgName>
								<address>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyao</forename><surname>Ai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Intelligent Information Retrieval</orgName>
								<orgName type="institution">University of Massachusetts Amherst</orgName>
								<address>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
							<email>guojiafeng@ict.ac.cn</email>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">CAS Key Lab of Network Data Science and Technology</orgName>
								<orgName type="department" key="dep2">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
							<email>croft@cs.umass.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Center for Intelligent Information Retrieval</orgName>
								<orgName type="institution">University of Massachusetts Amherst</orgName>
								<address>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">aNMM: Ranking Short Answer Texts with Attention-Based Neural Matching Model</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/2983323.2983818</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CCS Concepts •Information systems → Retrieval models and ranking</term>
					<term>Ques- tion answering</term>
					<term>Keywords Question Answering</term>
					<term>Deep Learning</term>
					<term>Value-shared Weights</term>
					<term>Term Importance Learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>As an alternative to question answering methods based on feature engineering, deep learning approaches such as convolutional neural networks (CNNs) and Long Short-Term Memory Models (LSTMs) have recently been proposed for semantic matching of questions and answers. To achieve good results, however, these models have been combined with additional features such as word overlap or BM25 scores. Without this combination, these models perform significantly worse than methods based on linguistic feature engineering. In this paper, we propose an attention based neural matching model for ranking short answer text. We adopt value-shared weighting scheme instead of position-shared weighting scheme for combining different matching signals and incorporate question term importance learning using question attention network. Using the popular benchmark TREC QA data, we show that the relatively simple aNMM model can significantly outperform other neural network models that have been used for the question answering task, and is competitive with models that are combined with additional features. When aNMM is combined with additional features, it outperforms all baselines.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Question answering (QA), which returns exact answers as either short facts or long passages to natural language questions issued by users, is a challenging task and plays a central role in the next generation of advanced web search <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b22">21]</ref>. Many of current QA systems use a learning to rank approach that encodes question/answer pairs with complex linguistic features including lexical, syntactic and semantic features <ref type="bibr" target="#b19">[18,</ref><ref type="bibr" target="#b23">22]</ref>. For instance, Surdeanu et al. <ref type="bibr">[22,</ref> Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.</p><p>CIKM <ref type="bibr">'16 , October 24-28, 2016</ref>  <ref type="bibr" target="#b24">23</ref>] investigated a wide range of feature types including similarity features, translation features, density/frequency features and web correlation features for learning to rank answers and show improvements in accuracy. However, such methods rely on manual feature engineering, which is often time-consuming and requires domain dependent expertise and experience. Moreover, they may need additional NLP parsers or external knowledge sources that may not be available for some languages.</p><p>Recently, researchers have been studying deep learning approaches to automatically learn semantic match between questions and answers. Such methods are built on the top of neural network models such as convolutional neural networks (CNNs) <ref type="bibr" target="#b35">[34,</ref><ref type="bibr" target="#b19">18,</ref><ref type="bibr" target="#b17">16]</ref> and Long Short-Term Memory Models (LSTMs) <ref type="bibr" target="#b26">[25]</ref>. The proposed models have the benefit of not requiring hand-crafted linguistic features and external resources. Some of them <ref type="bibr" target="#b19">[18]</ref> achieve state-ofthe art performance for the answer sentence selection task benchmarked by the TREC QA track. However, the weakness of the existing studies is that the proposed deep models, either based on CNNs or LSTMs, need to be combined with additional features such as word overlap features and BM25 to perform well. Without combining these additional features, their performance is significantly worse than the results obtained by the state-of-the-art methods based on linguistic feature engineering <ref type="bibr" target="#b33">[32]</ref>. This led us to propose the following research questions:</p><p>RQ1 Without combining additional features, could we build deep learning models that can achieve comparable or even better performance than methods using feature engineering ?</p><p>RQ2 By combining additional features, could our model outperform state-of-the-art models for question answering ?</p><p>To address these research questions, we analyze the existing current deep learning architectures for answer ranking and make the following two key observations:</p><p>1. Architectures not specifically designed for question/answer matching: Some methods employ CNNs for question/answer matching. However, CNNs are originally designed for computer vision (CV), which uses position-shared weights with local perceptive filters, to learn spatial regularities in many CV tasks. However, such spatial regularities may not exist in semantic matching between questions and answers, since important similarity signals between question and answer terms could appear in any position due to the complex linguistic property of natural languages. Meanwhile, models based on LSTMs view the question/answer matching problem in a sequential way. Without direct interactions between question and answer terms, the model may not be able to capture sufficiently detailed matching signals between them.</p><p>ranking the answers correctly . For example, given a question like "Where was the first burger king restaurant opened ?", it is critical for the answer to talk about "burger", "king", "open", etc. Most existing text matching models do not explicitly model question focus. For example, models based on CNNs treat all the question terms as equally important when matching to answer terms. Models based on LSTMs usually model question terms closer to the end to be more important.</p><p>To handle these issues in the existing deep learning architectures for ranking answers, we propose an attention based neural matching model (aNMM). The novel properties of the proposed model and our contributions can be summarized as follows:</p><p>1. Deep neural network with value-shared weights: We introduce a novel value-shared weighting scheme in deep neural networks as a counterpart of the position-shared weighting scheme in CNNs, based on the idea that semantic matching between a question and answer is mainly about the (semantic similarity) value regularities rather than spatial regularities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Incorporate attention scheme over question terms:</head><p>We incorporate the attention scheme over the question terms using a gating function, so that we can explicitly discriminate the question term importance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Extensive experimental evaluation and promising results.</head><p>We perform a thorough experimental study based on the TREC QA dataset from TREC QA tracks 8-13, which appears to be one of the most widely used benchmarks for answer reranking. Unlike previous methods using CNNs <ref type="bibr" target="#b35">[34,</ref><ref type="bibr" target="#b19">18]</ref> and LSTMs <ref type="bibr" target="#b26">[25]</ref>, which showed inferior results without combining additional features, our model can achieve better performance than a state-of-art method using linguistic feature engineering and comparable performance with previous deep learning models with combined additional features. If we combine our model with a simple additional feature like QL, our method can achieve the state-of-the-art performance among current existing methods for ranking answers under multiple metrics.</p><p>Roadmap. The rest of our paper is organized as follows. We will review related work in Section 2. In Section 3, we will present the proposed aNMM model with two components: value-shared weights and question attention network with gating functions. Two different architectures will be presented and analyzed. Section 4 is a systematic experimental analysis using the TREC QA benchmark dataset. Finally, we conclude our paper and discuss future work in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>Our work is related to several research areas, including deep learning models for text matching, factoid question answering, answer ranking in CQA and answer passage / sentence retrieval.</p><p>Deep Learning Models for Text Matching. Recently there have been many deep learning models proposed for text matching and ranking. Such deep learning models include DSSM <ref type="bibr" target="#b8">[7]</ref>, CDSSM <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b20">19]</ref>, ARC-I/ARC-II <ref type="bibr" target="#b6">[6]</ref> , DCNN <ref type="bibr" target="#b11">[10]</ref>, DeepMatch <ref type="bibr" target="#b14">[13]</ref>, MultiGranCNN <ref type="bibr" target="#b34">[33]</ref> and MatchPyramid <ref type="bibr" target="#b16">[15]</ref>. DSSM performs a non-linear projection to map the query and the documents to a common semantic space. The neural network models are trained using clickthrough data such that the conditional likelihood of the clicked document given the query is maximized. DeepMatch uses a topic model to construct the interactions between two texts and then makes different levels of abstractions with a deep architecture to model the relationships between topics. ARC-I and ARC-II are two different architectures proposed by Hu et. al. <ref type="bibr" target="#b6">[6]</ref> for matching natural language sentences. ARC-I firstly finds the representation of each sentence and then compares the representations of the two sentences with a multi-layer perceptron (MLP). The drawback of ARC-I is that it defers the interaction between two sentences until their individual representation matures in the convolution model, and therefore has the risk of losing details, which could be important for the matching task. On the other hand, ARC-II is built directly on the interaction space between two sentences. Thus ARC-II makes two sentences meet before their own high-level representations mature, while still retaining the space for individual development of abstraction of each sentence. Our aNMM architecture adopts a similar design with ARC-II in the QA matching matrix where we build neural networks directly on the interaction of sentence term pairs. However, we adopt value-shared weights instead of position-shared weights as in the CNN used by ARC-II. We also add attention scheme to learn question term importance.</p><p>Factoid Question Answering. There have been many previous studies on factoid question answering, most of which use the benchmark data from TREC QA track <ref type="bibr" target="#b33">[32,</ref><ref type="bibr" target="#b26">25,</ref><ref type="bibr" target="#b32">31,</ref><ref type="bibr" target="#b35">34,</ref><ref type="bibr" target="#b19">18]</ref>. Yih et. al. <ref type="bibr" target="#b33">[32]</ref> formulated answer sentence selection as a semantic matching problem with a latent word-alignment structure and conducted a series of experimental studies on leveraging proposed lexical semantic models. Iyyer et. al. <ref type="bibr" target="#b9">[8]</ref> introduced a recursive neural network (RNN) model that can reason over text that contains very few individual words by modeling textual compositionality. Yu et al. <ref type="bibr" target="#b35">[34]</ref> proposed an approach for answer sentence selection via distributed representations, and learned to match questions with answers by considering their semantic encoding. They combined the learning results of their model with word overlap features by training a logistic regression classifier. Wang and Nyberg <ref type="bibr" target="#b26">[25]</ref> proposed a method which uses a stacked bidirectional Long-Short Term Memory (BLSTM) network to sequentially read words from question and answer sentences, and then output their relevance scores. Their system needs to combine the stacked BLSTM relevance model with a BM25 score to achieve good performance. Severyn and Moschitti <ref type="bibr" target="#b19">[18]</ref> presented a convolutional neural network architecture for re-ranking pairs of short texts, where they learned the optimal representation of text pairs and a similarity function to relate them in a supervised way from the available training data. They also need to combine additional features into their model to outperform previous methods. Unlike the previous research, our method can outperform previous methods using feature engineering without combining any additional features. With an additional simple feature like QL, our model is significantly better than the previous state-of-the-art methods including deep learning methods.</p><p>Answer Ranking in CQA. There is also previous research on ranking answers from community question answering (CQA) sites. Surdeanu et al. <ref type="bibr" target="#b23">[22,</ref><ref type="bibr" target="#b24">23]</ref> investigated a wide range of feature types such as similarity features, translation features, density / frequency features for ranking answers to non-factoid questions in Yahoo! Answers. Jansen et al. <ref type="bibr" target="#b10">[9]</ref> presented an answer re-ranking model for non-factoid questions that integrate lexical semantics with discourse information driven by two representations of discourse. Xue et al. <ref type="bibr" target="#b30">[29]</ref> proposed a retrieval model that combines a translationbased language model for the question part with a query likelihood approach for the answer part. Questions from CQA sites are mostly non-factoid questions. Our research is closer to factoid questions such as questions in TREC QA data.  Answer Passage / Sentence Retrieval. Our work is also related to previous research on answer passage / sentence retrieval. Tymoshenko and Moschitti <ref type="bibr" target="#b25">[24]</ref> studied the use of syntactic and semantic structures obtained with shallow and deeper syntactic parsers in the answer passage re-ranking task. Keikha et al. <ref type="bibr" target="#b13">[12,</ref><ref type="bibr" target="#b12">11]</ref> developed an annotated data set for non-factoid answer finding using TREC GOV2 collections and topics. They annotated passage-level answers, revisited several passage retrieval models with this data, and came to the conclusion that the current methods are not effective for this task. Yang et al. <ref type="bibr" target="#b31">[30]</ref> developed effective methods for answer sentence retrieval using this annotated data by combining semantic features, context features and basic text matching features with a learning to rank approach. Our model is built on attentionbased neural matching model with value-shared weighting schema. Unlike learning to rank approaches with feature engineering, our model can achieve good performance for ranking answers without any additional manual feature engineering, preprocessing of NLP parsers and external resources like knowledge bases.</p><formula xml:id="formula_0">! " ! $ ! % ! &amp; ! ' ! ( ! ) ! * + " + $ + % + &amp; + ' + ( + ) + * X Q A ! " ! $ ! % ! &amp; ! ' ! ( ! ) ! * + " + $ + % + &amp; + ' + ( + ) + * Question Attention Network {-./ } {1 2 } 3 4 5 4.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Word</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">ATTENTION-BASED NEURAL MATCH-ING MODEL</head><p>In this section we present the proposed model referred as aNMM (attention-based Neural Matching Model), which is shown in <ref type="figure">Figure</ref> 1. Before we introduce our model, we firstly define some terminologies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Terminology</head><p>Short Answer Text: We use Short Answer Text to refer to a short fact, answer sentences or answer passages that can address users' information needs in the issued questions. This is the ranking object in this paper and includes answers in various lengths. In the experiments of this paper, we mainly focus on ranking answer sentences that contain correct answer facts as in TREC QA data. QA Matching Matrix: We use QA Matching Matrix to refer to a matrix which represents the semantic matching information of term pairs from a question and answer pair. Given a question q with length M and an answer a with length N , a QA matching matrix is an M by N matrix P, where Pj,i denote the semantic similarity between term qj and term ai measured by the cosine similarity of the corresponding word embeddings of terms. If qj and ai are the same term, we assign Pj,i as 1. QA Matching Vector: We use QA Matching Vector to refer to a row in the QA matching matrix. As presented before, the j-th row of the QA matching matrix P contains the semantic similarity between qj and all terms in answer a .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Model Overview</head><p>Our method contains three steps as follows:</p><p>1. We construct QA matching matrix for each question and answer pair with pre-trained word embeddings.</p><p>2. We then employ a deep neural network with value-shared weighting scheme in the first layer, and fully connected layers in the rest to learn hierarchical abstraction of the semantic matching between question and answer terms.</p><p>3. Finally, we employ a question attention network to learn question term importance and produce the final ranking score.</p><p>We propose two neural matching model architectures and compare the effectivenesses of them. We firstly describe a basic version of the architecture, which is referred to as aNMM-1.</p><p>In the following sections, we will explain in detail the two major designs of aNMM-1, i.e., value-shared weights and question attention network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Value-shared Weighting</head><p>We first train word embeddings with the Word2Vec tool by Mikolov et al. <ref type="bibr" target="#b15">[14]</ref> with the English Wikipedia dump to construct QA matching matrices. Given a question sentence and an answer sentence, we compute the dot product of the normalized word embeddings of all term pairs to construct the QA matching matrix P as defined in Section 3.1. A major problem with the QA matching matrix is the variable size due to the different lengths of answers for a given question. To solve this problem, one can use CNN with <ref type="figure">Figure 2</ref>: The comparison of position-shared weight in CNN and value-shared weight in aNMM. In CNN, the weight associated with a node only depends on its position or relative location as specified by the filters. In aNMM, the weight associated with a node depends on its value. pooling strategy to handle the variable size. However, as we have mentioned before, CNNs basically use position-shared weighting scheme which may not fit semantic matching between questions and answers. Important question terms and semantically similar answer words could appear anywhere in questions/answers due to the complex linguistic property of natural languages. Thus we adopt the following method to handle the various length problem:</p><p>Value-shared Weights: For this method, the assumption is that matching signals in different ranges play different roles in deciding the final ranking score. Thus we introduce the value-shared weighting scheme to learn the importance of different levels of matching signals. The comparison between the position-shared weight and value-shared weight is shown in <ref type="figure">Figure 2</ref>. We can see that for position-shared weights, the weight associated with a node only depends on its position or relative location as specified by the filters in CNN. However in our model, the weight associated with a node depends on its value. The value of a node denotes the strength of the matching signal between term pairs of questions and answers from the QA matching matrix, as explained in Section 3.1. Such a setting enables us to use the learned weights to encode how to combine different levels of matching signals. After this step, the size of the hidden representation becomes fixed and we can use normal fully connected layers to learn higher level representations. We use the term bin to denote a specific range of matching signals. since Pj,i ∈ [−1, 1], if we set the size of bins as 0.1, then we have 21 bins where there is a separate bin for Pj,i = 1 to denote exact match of terms.</p><p>Specifically, value-shared weights are adopted in the forward propagation prediction process from the input layer to the hidden layer over each question term in aNMM-1 as follows:</p><p>Input Layer to Hidden Layer. Let w denote a K + 1 dimensional model parameter from input layer to hidden layer. x jk denotes the sum of all matching signals within the k-th value range or bin. For each QA matching vector of a given query q, the combined score after the activation function of the j-th node in hidden layer is defined as</p><formula xml:id="formula_1">hj = δ( K k=0 w k · x jk )<label>(1)</label></formula><p>where j is the index of question words in q. We use the sigmoid function as the activation function, which is commonly adopted in many neural network architectures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Question Attention Network</head><p>In addition to value-shared weighting, another model component of aNMM-1 is the question attention network. In a committee of neural networks which consists of multiple networks, we need to combine the output of these networks to output a final decision vector. The question attention network uses the gating function <ref type="bibr" target="#b21">[20]</ref> to control the output of each network in this process. Specifically, in aNMM-1 we use the softmax gate function to combine the output of multiple networks where each network corresponds to a question term as shown in <ref type="figure" target="#fig_0">Figure 1</ref>. We feed the dot product of query word embedding and model parameter to the softmax function to represent the query term importance. In this setting, we can directly compare the relative term importance of query words within the same query with softmax function. We also tried sigmoid gate function, but this did not perform as well as softmax gate function.</p><p>Softmax gate function is used in the forward propagation process from the hidden layer to the output layer as follows:</p><p>Hidden Layer to Output Layer. From the hidden layer to the output layer, we add a softmax gate function to learn question attention. Let v denote a P dimensional vector which is a model parameter. We feed the dot product of query word embedding qj and v to the softmax function to represent the query term importance as shown in Equation 2. Note that we normalize the query word embedding before computing the dot product.</p><formula xml:id="formula_2">y = M j=1 gj · hj = M j=1 exp(v · qj) L l=1 exp(v · q l ) · δ( K k=0 w k · x jk ) (2)</formula><p>Unlike previous models like CNNs <ref type="bibr" target="#b19">[18]</ref> and BLSTM <ref type="bibr" target="#b26">[25]</ref>, which learn the semantic match score between questions and answers through representation learning from matching matrix or question / answer pair sequences, aNMM achieves this by combining semantic matching signals of term pairs in questions and answers weighted by the output of question attention network, where softmax gate functions help discriminate the term importance or attention on different question terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Model Training</head><p>For aNMM-1, the model parameters contain two sets: 1) The value-shared weights w k for combining matching signals from the input layer to the hidden layer. 2) The parameters vp in the gating function from the hidden layer to the output layer.</p><p>To learn the model parameters from the training data, we adopt a pair-wise learning strategy with a large margin objective. Firstly we construct triples (q, a + , a − ) from the training data, with q matched with a + better than with a − . We have the ranking-based loss as the objective function as following:</p><formula xml:id="formula_3">e(q, a + , a − ; w, v) = max(0, 1 − S(q, a + ) + S(q, a − )) (3)</formula><p>where S(q, a) denote the predicted matching score for QA pair (q, a). During training stage, we will scan all the triples in training data. Given a triple (q, a + , a − ), we will compute ∆S = 1 − S(q, a + ) + S(q, a − ). If ∆S ≤ 0, we will skip this triple. Otherwise, we need to update model parameters with back propagation algorithm to minimize the objective function.</p><p>Under softmax gate function setting, the gradients of e w.r.t. v from hidden layer to the output layer is shown in Equation 4</p><formula xml:id="formula_4">∂e ∂vp = M j=1 ∂gj ∂vp · (−δ(u + ) + δ(u − ))<label>(4)</label></formula><p>where</p><formula xml:id="formula_5">u + = K k=0 w k · x + jk , u − = K k=0 w k · x − jk ∂g j ∂vp can be derived as exp(v · qj ) · qjp M l=1 exp(v · q l ) − exp(v · qj ) M l=1 exp(v · q l ) · q lp ( M l=1 exp(v · q l )) 2</formula><p>The gradient of e w.r.t. w from input layer to hidden layer is shown in <ref type="bibr">Equation 5</ref>.</p><formula xml:id="formula_6">∂e w k = M j=1 exp(v · qj) L l=1 exp(v · q l ) · (−δ(u + )(1 − δ(u + ))x + jk +δ(u − )(1 − δ(u − ))x − jk )<label>(5)</label></formula><p>With the formulas of gradients, we can perform stochastic gradient descent to learn model parameters. We use mini-batch gradient descent to achieve more robust performance on the ranking task. For the learning rate, we adopt adaptive learning rate: η = η0(1 − ), where will approach 1 with more iterations. Such a setting has better guarantee for convergence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Extension to Deep Neural Networks with Multiple Sets of Value-shared Weights</head><p>In aNMM-1, we can only use one set of value-shared weights for each QA matching vector. We further propose a more flexible neural network architecture which could enable us to use multiple sets of value-shared weights for each QA matching vector, leading to multiple intermediate nodes in the first hidden layer, as shown in <ref type="figure" target="#fig_0">Figure 1</ref> by the yellow color. We refer to this extended model as aNMM-2. The model architecture shown in <ref type="figure" target="#fig_0">Figure 1</ref> is corresponding to aNMM-2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.1">Forward Propagation Prediction</head><p>For aNMM-2, we add a hidden layer in the neural network where we learn multiple combined scores from the input layer. With this hidden layer, we define multiple weight vectors as w. Thus w becomes a two dimensional matrix. The formula for the forward propagation prediction is as follows:</p><formula xml:id="formula_7">y = M j=1 τ (v · qj) · δ( T t=0 rt · δ( K k=0 w kt x jk ))<label>(6)</label></formula><p>where τ (v · qj) = exp(v·q j ) L l=1 exp(v·q l ) and τ denote the softmax gate function. T is the number of nodes in hidden layer 1. rt is the model parameter from hidden layer 1 to hidden layer 2, where we feed the linear combination of outputs of nodes in hidden layer 1 to an extra activation function comparing with Equation 2. Then from hidden layer 2 to output layer, we sum over all outputs of nodes in hidden layer 2 weighted by the outputs of softmax gate functions, which also form the question attention network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.2">Back Propagation for Model Training</head><p>For aNMM-2, we have three sets of model parameters: 1) w kt from input layer to hidden layer 1; 2) rt from hidden layer 1 to hidden layer 2; 3) vp from hidden layer 2 to output layer. All three sets of parameters are updated through back propagation. The definition of the objective function is the same as Equation 3. The back propagation process for model parameter learning is described as follows:</p><p>From hidden layer 2 to output layer. The gradients of the objective function w.r.t. v is as following:</p><formula xml:id="formula_8">∂e ∂vp = M j=1 ∂gj ∂vp · (−h + j + h − j )<label>(7)</label></formula><p>Where</p><formula xml:id="formula_9">h + j = δ( T t=0 rt · δ( K k=0 w kt x + jk )) h − j = δ( T t=0 rt · δ( K k=0 w kt x − jk )</formula><p>) From hidden layer 1 to hidden layer 2. The gradients of the objective function w.r.t. r is as following:</p><formula xml:id="formula_10">∂e ∂rt = M j=1 τ (v · qj)(−h + j )(1 − h + j )s + t + h − j (1 − h − j )s − t ) Where s + t = δ( K k=0 w kt x + jk ) s − t = δ( K k=0 w kt x − jk )</formula><p>. From input layer to hidden layer 1. The gradients of the objective function w.r.t. w is as following:</p><formula xml:id="formula_11">∂e ∂w kt = M j=1 τ (v · qj)(− ∂y + u + j · rt · δ(u + t )(1 − δ(u + t )) · x + jk + ∂y − u − j · rt · δ(u − t )(1 − δ(u − t )) · x − jk )<label>(8)</label></formula><p>Where</p><formula xml:id="formula_12">u + j = T t=0 rt · δ( K k=0 w kt x + jk ) u − j = T t=0 rt · δ( K k=0 w kt x − jk )</formula><p>Initially we will randomly give the values of model parameters. Then we will use back propagation to update the model parameters. When the learning process converge, we use the learned model parameters for prediction to rank short answer texts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Set and Experiment Settings</head><p>We use the TREC QA data set 1 created by Wang et. al. <ref type="bibr" target="#b28">[27]</ref> from TREC QA track 8-13 data, with candidate answers automatically selected from each question's document pool using a combination of overlapping non-stop word counts and pattern matching. This data set is one of the most widely used benchmarks for answer   <ref type="bibr" target="#b15">[14]</ref> with the English Wikipedia dump. We use the skip-gram model with window size 5 and filter words with frequency less than 5 following the common practice in many neural embedding models. For the word vector dimension, we tune it as a hyper-parameter on the validation data starting from 200 to 1000. Embeddings for words not present are randomly initialized with sampled numbers from uniform distribution U[-0.25,0.25], which follows the same setting as <ref type="bibr" target="#b19">[18]</ref>.</p><p>Model Hyper-parameters. For the setting of hyper-parameters, we set the number of bins as 600, word embedding dimension as 700 for aNNM-1, the number of bins as 200, word embedding dimension as 700 for aNNM-2 after we tune hyper-parameters on the provided DEV set of TREC QA data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation and Metrics</head><p>For evaluation, we rank answer sentences with the predicted score of each method and compare the rank list with the ground truth to compute metrics. We choose Mean Average Precision (MAP) and Mean Reciprocal Rank (MRR), which are commonly used in information retrieval and question answering, as the metric to evaluate our model.</p><p>The definition of MRR is as follows:</p><formula xml:id="formula_13">M RR = 1 |Q| q∈Q 1 rank(f a)</formula><p>where rank(f a) is the position of the first correct answer in the rank list for the question q. Thus MRR is only based on the rank of the first correct answer. It is more suitable for the cases where the rank of the first correct answer is emphasized or each question only have one correct answer. On the other hand, MAP looks at the ranks of all correct answers. It is computed as following:</p><formula xml:id="formula_14">M AP = 1 |Q| q∈Q AP (q) where AP (q)</formula><p>is the average precision for each query q ∈ Q. Thus MAP is the average performance on all correct answers. We use the official trec_eval 2 scripts for computing these metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Model Learning Results</head><p>In this section, we give some qualitative analysis and visualization of our model learning results. Specifically, we analyze the learned value-shard weights and question term importance by aNMM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Value-shared Weight</head><p>We take the learned value-shared weights of aNMM-1 as the example. <ref type="figure" target="#fig_1">Figure 3</ref> shows the learned value-shared weights by aNMM-1. In aNMM-1, for each QA matching vector, there is only one bin node. Thus the learned value-shared weights for aNMM-1 is a one dimension vector. For aNMM-1, we set the number of bins as 600 as presented in Section 4.1. Note that the x-axis is the index of bin range and the y-axis is the value-shared weights corresponding to each bin range. The range of match signals is [-1,1] from the left to the right. We make the following observations: (1) The exact match signal which is corresponding to 1 in the last bin is tied with a very large weight, which shows that exact match information is very important. (2) For positive matching score from (0, 1), which is corresponding to bin index (300, 600), the learned value-shared weights are different for matching score range (0.5, 1) (bin index (450, 600)) and matching score range (0, 0.5) (bin index (300, 450)) . We can observe many positive value-shared weights for matching score range(0.5, 1) and negative value-shared weights for matching score range(0, 0.5). This makes sense since high semantic matching scores are positive indicators on answer correctness, whereas low semantic matching scores indicate that the candidate answer sentences contain irrelevant terms. (3) For negative   matching scores from (−1, 0), we can see there is not a lot of differences between value-shared weights for different ranges. A major reason is that most similarity scores based on word embeddings are positive. Therefore, we can remove bins corresponding to negative matching scores to reduce the dimension of value-shared weight vectors, which can help improve the efficiency of the model training process. We will show more quantitative results on the comparison between value-shared weights and position-shared weights in CNN in Section 4.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Question Term Importance</head><p>Next we analyze the learned question term importance of our model. Due to the space limit, we also use the learned question term importance of aNMM-1 as an example. <ref type="table" target="#tab_3">Table 2</ref> shows the examples of learned question term importance by aNMM-1. We also visualize the question term importance in <ref type="figure" target="#fig_2">Figure 4</ref>. Based on the results in the table and the figure, we can clearly see that aNMM-1 learns reasonable term importance. For instance, with the question attention network, aNMM-1 discovers important terms like "khmer", "rouge", "power" as for the question "When did the khmer rouge come into power ?". Terms like "age", "rossinin", "stop", "writing","opera" are highlighted for the question "At what age did rossini stop writing opera ? ". For the question "Where was the first burger king restaurant opened ?" mentioned in Section 1, "burger", "king", "opened" are treated as important question terms.</p><p>An interesting question is how the learned term importance compare with traditional IR term weighting methods such as IDF. We design an experiment to compare aNMM-1/aNMM-2 with aNMM-IDF, which is a degenerate version of our model where we use IDF to directly replace the output of question attention network. In this case, τ (v · qj) in Equation 6 is replaced by the IDF of the j-th question term. <ref type="table" target="#tab_4">Table 3</ref> shows the results. We find that if we replace the output of question attention network of aNMM with IDF, it will decrease the answer ranking performance, especially on TRAIN data. Thus, we can see that with the optimization process in the back propagation training process, aNMM can learn better question term weighting score than heuristic term weighting functions like IDF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Experimental Results for Ranking Answers</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Learning without Combining Additional Features</head><p>Our first experimental setting is ranking answer sentences directly by the predicted score from aNMM without combining any additional features. This will enable us to answer RQ1 proposed in Section 1. <ref type="table" target="#tab_5">Table 4</ref> shows the results of TREC QA on TRAIN and TRAIN-ALL without combining additional features. In this table, we compare the results of aNMM with other previous deep learning methods including CNN <ref type="bibr" target="#b35">[34,</ref><ref type="bibr" target="#b19">18]</ref> and LSTM <ref type="bibr" target="#b26">[25]</ref>. We summarize our observations as follows: (1) Both aNMM-1 and aNMM-2 show significant improvements for MAP and MRR on TRAIN and TRAIN-ALL data sets comparing with previous deep learning methods. Specifically, if we compare the results of aNMM-1 with the strongest deep learning baseline method by Severyn et al. <ref type="bibr" target="#b19">[18]</ref> based on CNN, we can see aNMM-1 outperform CNN for 14.67% in MAP on TRAIN, 9.15% in MAP on TRAIN-ALL. For MRR, we can also observe similar significant improvements of aNMM-1. These results show that with the value-shared weight scheme instead of the position-shared weight scheme in CNN and term importance learning with question attention network, aNMM can predict ranking scores with much higher accuracy comparing with previous deep learning models for ranking answers. (2) If we compare the results of aNMM-1 and aNMM-2, we can see their results are very close. aNMM-1 has slightly better performance than aNMM-2. This result indicates that adding one more hidden layer to incorporate multiple bin nodes does not necessarily increase the performance for answer ranking in TREC QA data. From the perspective of model efficiency, aNMM-1 could be a better choice since it can   <ref type="bibr" target="#b28">[27]</ref> 0.6029 0.6852 Heilman and Smith (2010) <ref type="bibr" target="#b4">[5]</ref> 0.6091 0.6917 <ref type="bibr" target="#b27">Wang and Manning (2010)</ref>  <ref type="bibr" target="#b27">[26]</ref> 0.5951 0.6951 <ref type="bibr" target="#b32">Yao et al. (2013)</ref>  <ref type="bibr" target="#b32">[31]</ref> 0.6307 0.7477 <ref type="bibr" target="#b18">Severyn et al. (2013)</ref>  <ref type="bibr" target="#b18">[17]</ref> 0.6781 0.7358 <ref type="bibr" target="#b33">Yih et al. (2013)</ref>  <ref type="bibr" target="#b33">[32]</ref> 0.7092 0.7700 aNMM-2 0.7407 0.7969 aNMM-1 0.7385 0.7995 be trained much faster with good prediction accuracy. However, for larger training data sets than TREC QA data, aNMM-2 could have better performance since it has more model parameters and is suitable for fitting larger training data set. We leave the study of impact of the number of hidden layers in aNMM to future work. <ref type="table" target="#tab_6">Table 5</ref> shows the comparison between aNMM with previous methods using feature engineering on TRAIN-ALL without combining additional features. We find that both aNMM-1 and aNMM-2 achieve better performance comparing with other methods using feature engineering. Specifically, comparing the results of aNMM-1 with the strongest baseline by Yih et al. <ref type="bibr" target="#b33">[32]</ref> based on enhanced lexical semantic models, aNMM-1 achieves 4.13% gain for MAP and 3.83% gain for MRR. These results show that it is possible to build a uniform deep learning model such that it can achieve better performance than methods using feature engineering. To the best of our knowledge, aNMM is the first deep learning model that can achieve good performance comparing with previous methods either based on deep learning models or feature engineering for ranking answers without any additional features, syntactic parsers and external resources except for pre-trained word embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Learning with Combining Additional Features</head><p>Our second experimental setting is to address RQ2 proposed in Section 1, where we ask whether our model can outperform the state-of-the-art performance achieved by CNN <ref type="bibr" target="#b35">[34,</ref><ref type="bibr" target="#b19">18]</ref> and LSTM <ref type="bibr" target="#b26">[25]</ref> for answer ranking when combining additional features. We combine the predicted score from aNMM-1 and aNMM-2 with the Query Likelihood (QL) <ref type="bibr" target="#b0">[1]</ref> score using LambdaMART <ref type="bibr" target="#b29">[28]</ref> following a similar approach to <ref type="bibr" target="#b26">[25]</ref>. We use the implementation of LambdaMART in jforests <ref type="bibr" target="#b2">3</ref> We compare the results with previous deep learning models with additional features. <ref type="table" target="#tab_7">Table 6</ref> shows the results on TRAIN and TRAIN-ALL when combining additional features. We can see that with combined features, both aNMM-1 and aNMM-2 have better performance. aNMM-1 also outperforms 3 https://github.com/yasserg/jforests <ref type="bibr" target="#b2">[3]</ref>.   <ref type="bibr" target="#b19">[18]</ref> which is the current state-of-the-art method for ranking answers in terms of both MAP and MRR on TRAIN and TRAIN-ALL. We also tried to combine aNMM score with other additional features such as word overlap features, IDF weighted word overlap features and BM25 as in previous research <ref type="bibr" target="#b35">[34,</ref><ref type="bibr" target="#b19">18,</ref><ref type="bibr" target="#b26">25]</ref>. The results were either similar or worse than combining aNMM score with QL. For aNMM, the gains after combining additional features are not as large as neural network models like CNN in <ref type="bibr" target="#b19">[18]</ref> and LSTM in <ref type="bibr" target="#b26">[25]</ref>. We think the reasons for this are two-fold: (1) The QA matching matrix in aNMM model can capture exact match information by assigning 1 to matrix elements if the corresponding answer term and question term are the same. This exact match information includes match between numbers and proper nouns, which are highlighted in previous research work <ref type="bibr" target="#b19">[18]</ref> as especially important for factoid questions answering, where most of the questions are of type what, when , who that are looking for answers containing numbers or proper nouns. Within aNMM architecture, this problem has already been handled with QA matching matrix. Thus incorporating word overlap features will not help much for improving the performance of aNMM. (2) In addition to exact match information, aNMM could also learn question term importance like IDF information through question attention network. Instead of empirically designing heuristic functions like IDF, aNMM can get learning based question term importance score. As analyzed in Section 4.3.2, with the optimization process in the back propagation training process, aNMM can learn similar or even better term weighting score than IDF. Thus combining aNMM score with features like IDF weighted word overlap features and BM25 may not increase the performance of aNMM by a large margin as the case in related research works <ref type="bibr" target="#b35">[34,</ref><ref type="bibr" target="#b19">18,</ref><ref type="bibr" target="#b26">25</ref>].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.3">Results Summary</head><p>Finally we summarize the results of previously published systems on the QA answer ranking task in <ref type="table" target="#tab_8">Table 7</ref>. We can see aNMM  trained with TRAIN-ALL set beats all the previous state-of-the art systems including both methods using feature engineering and deep learning models. These results are very promising since aNMM requires no manual feature engineering, no expensive processing by various NLP parsers and no external results like large scale knowledge base except for pre-trained word embeddings. Furthermore, even without combining additional features, aNMM still performs well for answer ranking, showing significant improvements over previous deep learning model with no additional features and linguistic feature engineering methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Parameter Sensitivity Analysis</head><p>We perform parameter sensitivity analysis of our proposed model aNMM. We focus on aNMM-1 as the example due to the space limitation. For aNMM-1, we fix the number of bins as 600 and change the dimension of word vectors. Similarly, we fix the dimension of word vectors as 700 and vary the number of bins. <ref type="figure" target="#fig_4">Figure 5</ref> shows the change of MAP and MRR on the validation data as we vary the hyper-parameters. We summarize our observations as follows: (1) For word vector dimension, the range (300, 700) is a good choice as much lower or higher word vector dimensions will hurt the performance. The choice of word vector dimension also depends on the size of training corpus. Larger corpus requires higher dimension of word vectors to embed terms in vocabulary. (2) For the number of bins, we can see that MAP and MRR will decrease as the bin number increase. Too many bins will increase the model complexity, which leads aNMM to be more likely to overfit the training data. Thus choosing suitable number of bins by optimizing hyperparameter on validation data can help improve the performance of aNMM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSIONS AND FUTURE WORK</head><p>In this paper, we propose an attention based neural matching model for ranking short answer text. We adopt value-shared weighting scheme instead of position-shared weighting scheme for combing different matching signals and incorporate question term importance learning using a question attention network. We perform a thorough experimental study with the TREC QA dataset from TREC QA tracks 8-13 and show promising results. Unlike previous methods including CNN as in <ref type="bibr" target="#b35">[34,</ref><ref type="bibr" target="#b19">18]</ref> and LSTM as in <ref type="bibr" target="#b26">[25]</ref>, which only show inferior results without combining additional features, our model can achieve better performance than the state-of-art method using linguistic feature engineering without additional features. With a simple additional feature, our method can achieve the new state-of-the-art performance among current existing methods. For further work, we will study other deep learning architectures for answer ranking and extend our work to include nonfactoid question answering data sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">ACKNOWLEDGMENTS</head><p>This work was supported in part by the Center for Intelligent Information Retrieval, in part by NSF IIS-1160894, and in part by NSF grant #IIS-1419693. Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect those of the sponsor.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>The proposed architecture of attention-based neural matching model (aNMM-2) for ranking answers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Visualization of learned value-shared weigths of aNMM-1. The x-axis is index of bin ranges and the y-axis is the value-shared weights corresponding to each bin range. The range of match signals is [-1,1] from the left to the right.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Visualization of learned question term importance by aNMM-1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Tune bin number on validation data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Tune hyper-parameters on validation data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>, Indianapolis, IN, USA c 2016 ACM. ISBN 978-1-4503-4073-1/16/10. . . $15.00 DOI: http://dx.doi.org/10.1145/2983323.2983818</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>The statistics of the TREC QA data set. This data set is more noisy, however it provides many more QA pairs for model training. There is a DEV set for hyper-parameter optimization and TEST set for model testing. We use the same train/dev/test partition in our experiments to directly compare our results with previous works. For data preprocess, we perform tokenization without stemming. We maintain stop words during the model training stage.Word Embeddings. We obtain pre-trained word embeddings with the Word2Vec tool by Mikolov et al.</figDesc><table><row><cell>Data</cell><cell cols="5">#Questions #QA pairs %Correct #Answers/Q Judgement</cell></row><row><cell cols="2">TRAIN-ALL 1,229</cell><cell>53,417</cell><cell>12.00%</cell><cell>43.46</cell><cell>automatic</cell></row><row><cell>TRAIN</cell><cell>94</cell><cell>4,718</cell><cell>7.40%</cell><cell>50.19</cell><cell>manual</cell></row><row><cell>DEV</cell><cell>82</cell><cell>1,148</cell><cell>19.30%</cell><cell>14.00</cell><cell>manual</cell></row><row><cell>TEST</cell><cell>100</cell><cell>1,517</cell><cell>18.70%</cell><cell>15.17</cell><cell>manual</cell></row></table><note>re-ranking. Table 1 shows the statistics of this data set. The dataset contains a set of factoid questions with candidate answers which are limited to a single sentence. There are two training data sets: TRAIN and TRAIN-ALL. Answers in TRAIN have manual judg- ments for the answer correctness. The manual judgment of candi- date answer sentences is provided for the entire TREC 13 set and for a part of questions from TREC 8-12. TRAIN-ALL is another training set with much larger number of questions. The correct- ness of candidate answer sentences in TRAIN-ALL is identified by matching answer sentences with answer pattern regular expressions provided by TREC.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Examples of learned question term importance by aNMM-1. 06E-02 2.54E-03 6.17E-02 2.68E-03 3.89E-01 4.28E-01 9.29E-03 5.64E-02</figDesc><table><row><cell>test_14</cell><cell>when</cell><cell>did</cell><cell>the</cell><cell>khmer</cell><cell>rouge</cell><cell>come</cell><cell>into</cell><cell>power</cell></row><row><cell cols="9">Term Importance 4.91E-03 7.18E-04 8.97E-04 5.67E-01 2.13E-01 1.81E-02 6.59E-03 1.89E-01</cell></row><row><cell>test_66</cell><cell>where</cell><cell>was</cell><cell>the</cell><cell>first</cell><cell>burger</cell><cell>king</cell><cell cols="2">restaurant opened</cell></row><row><cell cols="9">Term Importance 2.16E-04 5.67E-04 1.96E-04 2.57E-03 3.43E-01 4.39E-01 5.35E-03 2.08E-01</cell></row><row><cell>train_84</cell><cell>at</cell><cell>what</cell><cell>age</cell><cell>did</cell><cell>rossini</cell><cell>stop</cell><cell>writing</cell><cell>opera</cell></row><row><cell cols="2">Term Importance 5.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>The comparision of aNMM-1/aNMM-2 with aNMM-IDF which is a degenerate version of our model where we use IDF to directly replace the output of question attention network.</figDesc><table><row><cell>Training Data</cell><cell cols="2">TRAIN</cell><cell cols="2">TRAIN-ALL</cell></row><row><cell>Method</cell><cell>MAP</cell><cell>MRR</cell><cell>MAP</cell><cell>MRR</cell></row><row><cell>aNMM-IDF</cell><cell cols="4">0.6624 0.7376 0.7225 0.7873</cell></row><row><cell>aNMM-2</cell><cell cols="2">0.7191 0.7974</cell><cell cols="2">0.7407 0.7969</cell></row><row><cell>aNMM-1</cell><cell cols="4">0.7334 0.8020 0.7385 0.7995</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Results of TREC QA on TRAIN and TRAIN-ALL without combining additional features (Compare with deep learning methods).</figDesc><table><row><cell>Training Data</cell><cell cols="2">TRAIN</cell><cell cols="2">TRAIN-ALL</cell></row><row><cell>Method</cell><cell>MAP</cell><cell>MRR</cell><cell>MAP</cell><cell>MRR</cell></row><row><cell>Yu et al. (2014) [34]</cell><cell cols="4">0.5476 0.6437 0.5693 0.6613</cell></row><row><cell>Wang et al.(2015) [25]</cell><cell>/</cell><cell>/</cell><cell cols="2">0.5928 0.6721</cell></row><row><cell cols="5">Severyn et al. (2015) [18] 0.6258 0.6591 0.6709 0.7280</cell></row><row><cell>aNMM-2</cell><cell cols="4">0.7191 0.7974 0.7407 0.7969</cell></row><row><cell>aNMM-1</cell><cell cols="4">0.7334 0.8020 0.7385 0.7995</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5</head><label>5</label><figDesc></figDesc><table><row><cell cols="3">: Results of TREC QA on TRAIN-ALL without combining</cell></row><row><cell cols="3">additional features (Compare with methods using feature engineer-</cell></row><row><cell>ing).</cell><cell></cell><cell></cell></row><row><cell>Method</cell><cell>MAP</cell><cell>MRR</cell></row><row><cell>Wang et al. (2007)</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 :</head><label>6</label><figDesc>Results of TREC QA on TRAIN and TRAIN-ALL with combining additional features.</figDesc><table><row><cell>Training Data</cell><cell cols="2">TRAIN</cell><cell cols="2">TRAIN-ALL</cell></row><row><cell>Method</cell><cell>MAP</cell><cell>MRR</cell><cell>MAP</cell><cell>MRR</cell></row><row><cell>Yu et al. (2014) [34]</cell><cell cols="4">0.7058 0.7800 0.7113 0.7846</cell></row><row><cell>Wang et al. (2015) [25]</cell><cell>/</cell><cell>/</cell><cell cols="2">0.7134 0.7913</cell></row><row><cell cols="5">Severyn et al. (2015) [18] 0.7329 0.7962 0.7459 0.8078</cell></row><row><cell>aNMM-2</cell><cell cols="4">0.7306 0.7968 0.7484 0.8013</cell></row><row><cell>aNMM-1</cell><cell cols="2">0.7417 0.8102</cell><cell cols="2">0.7495 0.8109</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7 :</head><label>7</label><figDesc>Overview of previously published systems on the QA answer ranking task. All reported results are from the best setting of each model trained on TRAIN-ALL data.</figDesc><table><row><cell>Method</cell><cell>MAP</cell><cell>MRR</cell></row><row><cell>Wang et al. (2007) [27]</cell><cell cols="2">0.6029 0.6852</cell></row><row><cell>Heilman and Smith (2010) [5]</cell><cell cols="2">0.6091 0.6917</cell></row><row><cell cols="3">Wang and Manning (2010) [26] 0.5951 0.6951</cell></row><row><cell>Yao et al. (2013) [31]</cell><cell cols="2">0.6307 0.7477</cell></row><row><cell>Severyn et al. (2013) [17]</cell><cell cols="2">0.6781 0.7358</cell></row><row><cell>Yih et al. (2013) [32]</cell><cell cols="2">0.7092 0.7700</cell></row><row><cell>Yu et al. (2014) [34]</cell><cell cols="2">0.7113 0.7846</cell></row><row><cell>Wang et al. (2015) [25]</cell><cell cols="2">0.7134 0.7913</cell></row><row><cell>Severyn et al. (2015) [18]</cell><cell cols="2">0.7459 0.8078</cell></row><row><cell>aNMM</cell><cell cols="2">0.7495 0.8109</cell></row></table><note>CNN by Severyn et al.</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/aseveryn/deep-qa</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">http://trec.nist.gov/trec_eval/</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Search Engines: Information Retrieval in Practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Strohman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Addison-Wesley Publishing Company</publisher>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
	<note>1st edition</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Search needs a shake-up</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">476</biblScope>
			<biblScope unit="issue">7358</biblScope>
			<biblScope unit="page" from="25" to="26" />
			<date type="published" when="2011-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Bagging gradient-boosted trees for high precision, low variance ranking models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganjisaffar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lopes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR &apos;11</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="85" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Modeling interestingness with deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pantel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gamon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-10-25" />
			<biblScope unit="page" from="2" to="13" />
		</imprint>
	</monogr>
	<note>A meeting of SIGDAT, a Special Interest Group of the ACL</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Tree edit models for recognizing textual entailments, paraphrases, and answers to questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Heilman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies: The</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<title level="m">Annual Conference of the North American Chapter of the Association for Computational Linguistics, HLT &apos;10</title>
		<meeting><address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1011" to="1019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Convolutional neural network architectures for matching natural language sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<editor>Z. Ghahramani, M. Welling, C. Cortes, N. D</editor>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weinberger</surname></persName>
		</author>
		<title level="m">Advances in Neural Information Processing Systems 27</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2042" to="2050" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning deep structured semantic models for web search using clickthrough data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Acero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Heck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM International Conference on Information &amp; Knowledge Management, CIKM &apos;13</title>
		<meeting>the 22nd ACM International Conference on Information &amp; Knowledge Management, CIKM &apos;13<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2333" to="2338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A neural network for factoid question answering over paragraphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Claudino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Daumé</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP &apos;14</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Discourse Complements Lexical Semantics for Non-factoid Answer Reranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL&apos;14</title>
		<meeting>ACL&apos;14</meeting>
		<imprint>
			<biblScope unit="page" from="977" to="986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A convolutional neural network for modelling sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2014-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Evaluating Answer Passages Using Summarization Measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Keikha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGIR&apos;14</title>
		<meeting>SIGIR&apos;14</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Retrieving Passages and Finding Answers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Keikha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ADCS&apos;14</title>
		<meeting>ADCS&apos;14</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="81" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A deep architecture for matching short texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1367" to="1375" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Text matching as image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence</title>
		<meeting>the Thirtieth AAAI Conference on Artificial Intelligence<address><addrLine>Phoenix, Arizona, USA.</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2793" to="2799" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Convolutional neural tensor network architecture for community-based question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fourth International Joint Conference on Artificial Intelligence, IJCAI 2015</title>
		<meeting>the Twenty-Fourth International Joint Conference on Artificial Intelligence, IJCAI 2015<address><addrLine>Buenos Aires, Argentina</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1305" to="1311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Automatic feature engineering for answer selection and extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Severyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP &apos;13</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="458" to="467" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning to rank short text pairs with convolutional deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Severyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;15</title>
		<meeting>the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;15<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="373" to="382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A latent semantic model with convolutional-pooling structure for information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Mesnil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management, CIKM 2014</title>
		<meeting>the 23rd ACM International Conference on Conference on Information and Knowledge Management, CIKM 2014<address><addrLine>Shanghai, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="101" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Gating improves neural network performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Basu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. IJCNN &apos;01. International Joint Conference on</title>
		<meeting>IJCNN &apos;01. International Joint Conference on</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="2159" to="2164" />
		</imprint>
	</monogr>
	<note>Neural Networks</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Open domain question answering via semantic enrichment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-T</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on World Wide Web, WWW &apos;15</title>
		<meeting>the 24th International Conference on World Wide Web, WWW &apos;15<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1045" to="1055" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning to rank answers on large online QA collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ciaramita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zaragoza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL &apos;08</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="719" to="727" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning to rank answers to non-factoid questions from web collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ciaramita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zaragoza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Linguist</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="351" to="383" />
			<date type="published" when="2011-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Assessing the impact of syntactic and semantic structures for answer passages reranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tymoshenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM &apos;15</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1451" to="1460" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A long short-term memory model for answer sentence selection in question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Nyberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL &apos;15</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="707" to="712" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Probabilistic tree-edit models with structured latent variables for textual entailment and question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics, COLING &apos;10</title>
		<meeting>the 23rd International Conference on Computational Linguistics, COLING &apos;10<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1164" to="1172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">What is the Jeopardy model? a quasi-synchronous grammar for QA</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mitamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the EMNLP-CoNLL</title>
		<meeting>the EMNLP-CoNLL<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="22" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Adapting boosting for information retrieval measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Svore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inf. Retr</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="254" to="270" />
			<date type="published" when="2010-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Retrieval Models for Question and Answer Archives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jeon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGIR&apos;08</title>
		<meeting>SIGIR&apos;08</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="475" to="482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Beyond factoid QA: effective methods for non-factoid answer sentence retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Spina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Scholer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Information Retrieval -38th European Conference on IR Research</title>
		<meeting><address><addrLine>Padua, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-03-20" />
			<biblScope unit="page" from="115" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Answer extraction as sequence tagging with tree edit distance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">V</forename><surname>Durme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies: Conference of the North American Chapter of the Association of Computational Linguistics, Proceedings</title>
		<meeting><address><addrLine>Westin Peachtree Plaza Hotel, Atlanta, Georgia, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="858" to="867" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Question answering using enhanced lexical semantic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Meek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pastusiak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL &apos;13</title>
		<meeting><address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-08" />
			<biblScope unit="page" from="1744" to="1753" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Multigrancnn: An architecture for general matching of text chunks on multiple levels of granularity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schütze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL &apos;15</title>
		<meeting><address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015-07" />
			<biblScope unit="page" from="63" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deep Learning for Answer Sentence Selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pulman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Deep Learning Workshop</title>
		<imprint>
			<date type="published" when="2014-12" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
