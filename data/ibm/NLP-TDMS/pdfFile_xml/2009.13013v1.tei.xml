<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SPARTA: Efficient Open-Domain Question Answering via Sparse Transformer Matching Retrieval</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiancheng</forename><surname>Zhao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaopeng</forename><surname>Lu</surname></persName>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyusong</forename><surname>Lee</surname></persName>
							<email>kyusongl@soco.ai</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">SOCO Inc</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Language Technologies Institute</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">SPARTA: Efficient Open-Domain Question Answering via Sparse Transformer Matching Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We introduce SPARTA, a novel neural retrieval method that shows great promise in performance, generalization, and interpretability for open-domain question answering. Unlike many neural ranking methods that use dense vector nearest neighbor search, SPARTA learns a sparse representation that can be efficiently implemented as an Inverted Index. The resulting representation enables scalable neural retrieval that does not require expensive approximate vector search and leads to better performance than its dense counterpart. We validated our approaches on 4 opendomain question answering (OpenQA) tasks and 11 retrieval question answering (ReQA) tasks. SPARTA achieves new state-of-the-art results across a variety of open-domain question answering tasks in both English and Chinese datasets, including open SQuAD, Natural Question, CMRC and etc. Analysis also confirms that the proposed method creates human interpretable representation and allows flexible control over the trade-off between performance and efficiency. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Open-domain Question Answering (OpenQA) is the task of answering a question based on a knowledge source. One promising approach to solve OpenQA is Machine Reading at Scale (MRS) <ref type="bibr" target="#b6">(Chen et al., 2017)</ref>. MRS leverages an information retrieval (IR) system to narrow down to a list of relevant passages and then uses a machine reading comprehension reader to extract the final answer span. This approach, however, is bounded by its pipeline nature since the first stage retriever is not trainable and may return no passage that contains the correct answer.</p><p>To address this problem, prior work has focused on replacing the first stage retriever with a train-1 Work done during Lu's internship at SOCO. able ranker <ref type="bibr" target="#b7">(Chidambaram et al., 2018;</ref>. End-to-end systems have also been proposed to combine passage retrieval and machine reading by directly retrieving answer span . Despite of their differences, the above approaches are all built on top of the dual-encoder architecture, where query and answer are encoded into fixed-size dense vectors, and their relevance score is computed via dot products. Approximate nearest neighbor (ANN) search is then used to enable realtime retrieval for large dataset <ref type="bibr" target="#b45">(Shrivastava and Li, 2014)</ref>.</p><p>In this paper, we argue that the dual-encoder structure is far from ideal for open-domain QA retrieval. Recent research shows its limitations and suggests the importance of modeling complex queries to answer interactions for strong QA performance.  shows that their best performing system underperforms the state-of-theart due to query-agnostic answer encoding and its over-simplified matching function. <ref type="bibr" target="#b20">Humeau et al. (2019)</ref> shows the trade-off between performance and speed when moving from expressive crossattention in BERT <ref type="bibr" target="#b11">(Devlin et al., 2018)</ref> to simple inner product interaction for dialog response retrieval. Therefore, our key research goal is to develop new a method that can simultaneously achieve expressive query to answer interaction and fast inference for ranking.</p><p>We introduce SPARTA (Sparse Transformer Matching), a novel neural ranking model. Unlike existing work that relies on a sequence-level inner product, SPARTA uses token-level interaction between every query and answer token pair, leading to superior retrieval performance. Concretely, SPARTA learns sparse answer representations that model the potential interaction between every query term with the answer. The learned sparse answer representation can be efficiently saved in an Inverted <ref type="bibr">Index, e.g., Lucene (McCandless et al., 2010)</ref>, so that one can query a SPARTA index with almost the same speed as a standard search engine and enjoy the more reliable ranking performance without depending on GPU or ANN search.</p><p>Experiments are conducted on two settings: OpenQA <ref type="bibr" target="#b6">(Chen et al., 2017)</ref> that requires phraselevel answers and retrieval QA (ReQA) that requires sentence-level answers <ref type="bibr" target="#b0">(Ahmad et al., 2019)</ref>. Our proposed SpartaQA system achieves new stateof-the-art results across 15 different domains and 2 languages with significant performance gain, including OpenSQuAD, Open Natural Questions, OpenCMRC and etc.</p><p>Moreover, model analysis shows that SPARTA exhibits several desirable properties. First SPARTA shows strong domain generalization ability and achieves the best performance compared to both classic IR method and other learning methods in low-resources domains. Second, SPARTA is simple and efficient and achieves better performance than many more sophisticated methods. Lastly, it provides a human-readable representation that is easy to interpret. In short, the contributions of this work include:</p><p>• A novel ranking model SPARTA that offers token-level query-to-answer interaction and enables efficient large-scale ranking.</p><p>• New state-of-the-art experiment results on 11 ReQA tasks and 4 OpenQA tasks in 2 languages.</p><p>• Detailed analyses that reveal insights about the proposed methods, including generalization and computation efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The classical approach for OpenQA depends on knowledge bases (KB)s that are manually or automatically curated, e.g., Freebase KB <ref type="bibr" target="#b4">(Bollacker et al., 2008)</ref>, NELL <ref type="bibr" target="#b14">(Fader et al., 2014)</ref> etc. Semantic parsing is used to understand the query and computes the final answer <ref type="bibr" target="#b2">(Berant et al., 2013;</ref><ref type="bibr" target="#b3">Berant and Liang, 2014)</ref>. However, KB-based systems are often limited due to incompleteness in the KB and inflexibility to changes in schema <ref type="bibr" target="#b15">(Ferrucci et al., 2010)</ref>. A more recent approach is to use text data directly as a knowledge base. Dr.QA uses a search engine to filter to relevant documents and then applies machine readers to extract the final answer <ref type="bibr" target="#b6">(Chen et al., 2017)</ref>. It needs two stages because all existing machine readers, for example, BERT-based models <ref type="bibr" target="#b11">(Devlin et al., 2018)</ref>, are prohibitively slow (BERT only processes a few thousands of words per second with GPU acceleration). Many attempts have been made to improve the first-stage retrieval performance <ref type="bibr" target="#b7">(Chidambaram et al., 2018;</ref><ref type="bibr" target="#b18">Henderson et al., 2019;</ref><ref type="bibr" target="#b23">Karpukhin et al., 2020;</ref><ref type="bibr" target="#b5">Chang et al., 2020</ref>). Yet, the information retrieval (IR) community has shown that simple word embedding matching do not perform well for ad-hoc document search compared to classic methods <ref type="bibr" target="#b17">(Guo et al., 2016;</ref><ref type="bibr" target="#b51">Xiong et al., 2017)</ref>.</p><p>To increase the expressiveness of dual encoders, <ref type="bibr" target="#b51">Xiong et al. (2017)</ref> develops kernel function to learn soft matching score at token-level instead of sequence-level. <ref type="bibr" target="#b20">Humeau et al. (2019)</ref> proposes Poly-Encoders to enable more complex interactions between the query and the answer by letting one encoder output multiple vectors instead of one vector. <ref type="bibr" target="#b12">Dhingra et al. (2020)</ref> incorporates entity vectors and multi-hop reasoning to teach systems to answer more complex questions. <ref type="bibr" target="#b28">(Lee et al., 2020)</ref> augments the dense answer representation with learned n-gram sparse feature from contextualized word embeddings, achieving significant improvement compared to the dense-only baseline. <ref type="bibr" target="#b5">Chang et al. (2020)</ref> explores various unsupervised pretraining objectives to improve dual-encoders' QA performance in the low-resources setting.</p><p>Unlike most of the existing work based-on dualencoders, we explore a different path where we focus on learning sparse representation and emphasizes token-level interaction models instead of sequence-level. This paper is perhaps the most related to the sparse representations from <ref type="bibr" target="#b28">(Lee et al., 2020)</ref>. However, the proposed approach is categorically different in the following ways. (1) it is stand-alone and does not need augmentation with dense vectors while keeping superior performance (2) our proposed model is architecturally simpler and is generative so that it will understand words that not appear in the answer document, whereas the one developed at <ref type="bibr" target="#b28">(Lee et al., 2020)</ref> only models n-grams appear in the document.</p><p>3 Proposed Method</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem Formulation</head><p>First, we formally define the problem of answer ranking for question answering. Let q be the input <ref type="figure">Figure 1</ref>: SPARTA Neural Ranker computes token-level matching score via dot product. Each query terms' contribution is first obtained via max-pooling and then pass through ReLU and log. The final score is the summation of each query term contribution. question, and A = {(a, c)} be a set of candidate answers. Each candidate answer is a tuple (a, c) where a is the answer text and c is context information about a. The objective is to find model parameter θ that rank the correct answer as high as possible, .i.e:</p><formula xml:id="formula_0">θ = argmax θ∈Θ E[p θ ((a * , c * )|q)]<label>(1)</label></formula><p>This formulation is general and can cover many tasks. For example, typical passage-level retrieval systems sets the a to be the passage and leaves c empty <ref type="bibr" target="#b6">(Chen et al., 2017;</ref><ref type="bibr" target="#b52">Yang et al., 2019a)</ref>. The sentence-level retrieval task proposed at sets a to be each sentence in a text knowledge base and c to be the surrounding text <ref type="bibr" target="#b0">(Ahmad et al., 2019)</ref>. Lastly, the phrase-level QA system sets a to be all valid phrases from a corpus and c to be the surrounding text . This work focuses on the same sentence-level retrieval task <ref type="bibr" target="#b0">(Ahmad et al., 2019)</ref> since it provides a good balance between precision and memory footprint. Yet note that our methods can be easily applied to the other two settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">SPARTA Neural Ranker</head><p>In order to achieve both high accuracy and efficiency (scale to millions of candidate answers with real-time response), the proposed SPARTA index is built on top of two high-level intuitions.</p><p>• Accuracy: retrieve answer with expressive embedding interaction between the query and answer, i.e., token-level contextual interaction.</p><p>• Efficiency: create query agnostic answer representation so that they can be pre-computed at indexing time. Since it is an offline operation, we can use the most powerful model for indexing and simplify the computation needed at inference.</p><p>As shown in <ref type="figure">Figure 1</ref>, a query is represented as a sequence of tokens q = [t 1 , ...t |q| ] and each answer is also a sequence of tokens (a, c) = [c 1 , ..a 1 , ..a |a| , c a+1 , ...c |c| ]. We use a noncontextualized embedding to encode the query tokens to e i , and a contextualized transformer model to encode the answer and obtain contextualized token-level embedding s j :</p><formula xml:id="formula_1">E(q) = [e 1 , .</formula><p>..e |q| ] Query Embedding <ref type="formula">(2)</ref> H(a, c) = [s 1 , ...s |c| ] Answer Embedding <ref type="formula">(3)</ref> Then the matching score f between a query and an answer is computed by:</p><formula xml:id="formula_2">y i = max j∈[1,|c|] (e T i s j ) Term Matching (4) φ(y i ) = ReLU(y i + b) Sparse Feature (5) f (q, (a, c)) = |q| i=0 log(φ(y i ) + 1) Final Score (6)</formula><p>where b is a trainable bias. The final score between the query and answer is the summation of all individual scores between each query token and the answer. The logarithm operations normalize each individual score and weaken the overwhelmingly large term score. Additionally, there are two key design choices worth of elaboration.</p><p>Token-level Interaction SPARTA scoring uses token-level interaction between the query and the answer. Motivated by bidirectional-attention flow <ref type="bibr" target="#b42">(Seo et al., 2016)</ref>, relevance between every query and answer token pair is computed via dot product and max pooling in Eq. 4. Whereas in a typical dual-encoder approach, only sequence-level interaction is computed via dot product. Results in our experiment section show that fine-grained interaction is crucial to obtain significant accuracy improvement. Additionally, s j is obtained from powerful bidirectional transformer encoders, e.g. BERT and only needs to be computed at the indexing time. On the other hand, the query embedding is non-contextual, a trade-off needed to enable realtime inference, which is explained in Section 3.4</p><p>Sparsity Control Another key feature to enable efficient inference and memory foot print is sparsity. This is achieved via the combination of log, ReLU and b in Eq. 5. The bias term is used as a threshold for y i . The ReLU layer forces that only query terms with y i &gt; 0 have impact to the final score, achieving sparse activation. The log operation is proven to be useful via experiments for regularizing individual term scores and leads to better performance and more generalized representation.</p><p>Implementation In terms of implementation, we use a pretrained 12-layer, 768 hidden size bertbase-uncased as the answer encoder to encode the answer and their context <ref type="bibr" target="#b11">(Devlin et al., 2018)</ref>. To encode the difference between the answer sequence and its surrounding context, we utilized the segment embedding from BERT, i.e. the answer tokens have segment id = 1 and the context tokens havesegment id = 0. Moreover, the query tokens are embedded via the word embedding from the bert-base-uncased with dimension 768.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Learning to Rank</head><p>The training of SPARTA uses cross entropy learning-to-rank loss and maximizes Eq. 7. The objective tries to distinguish between the true relevant answer (a + , c + )and irrelevant/random answers K − for each training query q:</p><formula xml:id="formula_3">J = f (q, (a + , c + )) − log k∈K − e f (q,(a k ,c k )) (7)</formula><p>The choice of negative samples K − are crucial for effective learning. Our study uses two types of negative samples: 50% of the negative samples are randomly chosen from the entire answer candidate set, and the rest 50% are chosen from sentences that are nearby to the ground truth answer a. The second case requires the model to learn the fine-grained difference between each sentence candidate instead of only rely on the context information. The parameters to learn include both the query encoder E and the answer encoder H. Parameters are optimized using back propagation (BP) through the neural network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Indexing and Inference</head><p>One major novelty of SPARTA is how one can use it for real-time inference. That is for a testing query q = [t 0 , ...t |q| ], the ranking score between q and an answer is:</p><formula xml:id="formula_4">LOOKUP(t, (a, c)) = log(Eq. 5) t ∈ V (8) f (q, (a, c)) = |q| i=1 LOOKUP(t i , (a, c))<label>(9)</label></formula><p>Since the query term embedding is non-contextual, we can compute the rank feature φ(t, (a, c)) for every possible term t in the vocabulary V with every answer candidate. The result score is cached in the indexing time as shown in Eq. 8. At inference time, the final ranking score can be computed via O(1) look up plus a simple summation as shown in Eq. 9. More importantly, the above computation can be efficiently implemented via a Inverted Index <ref type="bibr" target="#b34">(Manning et al., 2008)</ref>, which is the underlying data structure for modern search engines, e.g. Lucene <ref type="bibr" target="#b35">(McCandless et al., 2010)</ref> as shown in <ref type="figure">Figure 1(b)</ref>. This property makes it easy to apply SPARTA to real-world applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Relation to Classic IR and Generative Models</head><p>It is not hard to see the relationship between SPARTA and classic BM25 based methods. In the classic IR method, only the tokens that appeared in the answer are saved to the Inverted Index. Each term's score is a combination of Term Frequency and Inverted Document Frequency via heuristics <ref type="bibr" target="#b34">(Manning et al., 2008)</ref>. On the other hand, SPARTA learns which term in the vocabulary should be inserted into the index, and predicts the ranking score directly rather than heuristic calculation. This enables the system to find relevant answers, even when none of the query words appeared in the answer text. For example, if the answer sentence is "Bill Gates founded Microsoft", a SPARTA index will not only contain the tokens in the answer, but also include relevant terms, e.g. who, founder, entrepreneur and etc. SPARTA is also related to generative QA. The scoring between (a, c) and every word in the vocabulary V can be understood as the un-normalized probability of log p(q|a) = |q| i log p(t i |a) with term independence assumption. Past work such as <ref type="bibr" target="#b32">Lewis and Fan (2018)</ref>; <ref type="bibr" target="#b38">Nogueira et al. (2019)</ref> trains a question generator to score the answer via likelihood. However, both approaches focus on auto-regressive models and the quality of question generation and do not provide an end-to-end solution that enables stand-alone answer retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">OpenQA Experiments</head><p>We consider an Open-domain Question Answering (OpenQA) task to evaluate the performance of SPARTA ranker. Following previous work on OpenQA <ref type="bibr" target="#b6">(Chen et al., 2017;</ref><ref type="bibr" target="#b50">Xie et al., 2020)</ref>, we experiment with two English datasets: SQuAD <ref type="bibr" target="#b39">(Rajpurkar et al., 2016)</ref>, Natural Questions (NQ) ; and two Chinese datasets: CMRC <ref type="bibr" target="#b10">(Cui et al., 2018)</ref>, DRCD <ref type="bibr" target="#b44">(Shao et al., 2018)</ref>. For each dataset, we used the version of Wikipedia where the data was collected from. Preliminary results show that it is crucial to use the right version of Wikipedia to reproduce the results from baselines. We compare the results with previous best models.</p><p>System-wise we follow the 2-stage ranker-reader structure used in <ref type="bibr" target="#b6">(Chen et al., 2017)</ref>.</p><p>Ranker: We split all documents into sentences. Each sentence is treated as a candidate answer a. We keep the surrounding context words of each candidate answer as its context c. We encode at most 512 word piece tokens and truncate the context surrounding the answer sentence with equal window size. For model training, bert-base-uncased is used as the answer encoder for English, and chinesebert-wwm is used for Chinese. We reuse the word embedding from corresponding BERT model as the term embedding. Adam (Kingma and Ba, 2014) is used as the optimizer for fine-tuning with a learning rate 3e-5. The model is fine-tuned for at most 10K steps and the best model is picked based on validation performance.</p><p>Reader: We deploy a machine reading comprehension (MRC) reader to extract phrase-level answers from the top-K retrieved contexts. For English tasks, we fine-tune on span-bert <ref type="bibr" target="#b21">(Joshi et al., 2020)</ref>. For Chinese tasks, we fine-tune on chinesebert-wwm <ref type="bibr" target="#b9">(Cui et al., 2020)</ref>. Two additional proven techniques are used to improve performance. First, we use global normalization <ref type="bibr" target="#b8">(Clark and Gardner, 2017)</ref> to normalize span scores among multiple passages and make them comparable among each other. Second, distant supervision is used. Concretely, we first use the ranker to find top-10 passages for all training data from Wikipedia corpus. Then every mention of the oracle answers in these contexts are treated as training examples. This can ensure the MRC reader to adapt to the ranker and make the training distribution closer to the test distribution <ref type="bibr" target="#b50">(Xie et al., 2020)</ref>.</p><p>Lastly, evaluation metrics include the standard MRC metric: EM and F1-score.</p><p>• Exact Match (EM): if the top-1 answer span matches with the ground truth exactly.</p><p>• F1 Score: we compute word overlapping between the returned span and the ground truth answer at token level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">OpenQA Results</head><p>OpenSQuAD Model F1 EM Dr.QA <ref type="bibr" target="#b6">(Chen et al., 2017)</ref> -29.8 R 3  37.5 29.1 Par. ranker  -30.2 MINIMAL <ref type="bibr" target="#b37">(Min et al., 2018)</ref> 42.5 32.7 DenSPI-hybrid  44.4 36.2 BERTserini <ref type="bibr" target="#b52">(Yang et al., 2019a)</ref> 46.1 38.6 RE 3 <ref type="bibr" target="#b19">(Hu et al., 2019)</ref> 50.2 41.9 Multi-passage  60.9 53.0 Graph-retriever <ref type="bibr" target="#b1">(Asai et al., 2019)</ref>   <ref type="bibr" target="#b36">(Min et al., 2019)</ref> 28.8 28.1 ORQA  31.3 33.3 Graph-retriever <ref type="bibr" target="#b1">(Asai et al., 2019)</ref>   <ref type="bibr" target="#b50">(Xie et al., 2020)</ref> 60.9 44.5 BERTserini+DS <ref type="bibr" target="#b50">(Xie et al., 2020)</ref> 64.6 48.6 SPARTA 79.9 62.9 OpenDRCD Model F1 EM BERTserini <ref type="bibr" target="#b50">(Xie et al., 2020)</ref> 65.0 50.7 BERTserini+DS <ref type="bibr" target="#b50">(Xie et al., 2020)</ref>    <ref type="bibr" target="#b50">(Xie et al., 2020)</ref>. Notably, the previous best system on Open-SQuAD and OpenNQ depends on sophisticated graph reasoning <ref type="bibr" target="#b1">(Asai et al., 2019)</ref>, whereas the proposed SPARTA system only uses single-hop ranker and require much less computation power. This suggests that for tasks that requires only singlehop reasoning, there is still big improvement room for better ranker-reader QA systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Retrieval QA Experiments</head><p>We also consider Retrieval QA (ReQA), a sentencelevel question answering task <ref type="bibr" target="#b0">(Ahmad et al., 2019)</ref>. The candidate answer set contains every possible sentence from a text corpus and the system is expected to return a ranking of sentences given a query. The original ReQA only contains SQuAD and NQ. In this study, we extend ReQA to 11 different domains adapted from <ref type="bibr" target="#b16">(Fisch et al., 2019)</ref> to evaluate both in-domain performance and out-ofdomain generalization. The details of the 11 ReQA domains are in <ref type="table" target="#tab_4">Table 3</ref> and Appendix.</p><p>The in-domain scenarios look at domains that have enough training data (see <ref type="table" target="#tab_4">Table 3</ref>). The models are trained on the training data and the evaluation is done on the test data. On the other hand, the out-of-domain scenarios evaluate systems' performance on test data from domains not included in the training, making it a zero-shot learning problem. There are two out-of-domain settings: (1) training data only contain SQuAD (2) training data contain only SQuAD and NQ. Evaluation is carried on all the domains to test systems' ability to generalize to unseen data distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Domain</head><p>Data Source Has training data SQuAD <ref type="bibr" target="#b39">(Rajpurkar et al., 2016)</ref> Wikipedia News <ref type="bibr" target="#b46">(Trischler et al., 2016)</ref> News Trivia <ref type="bibr" target="#b22">(Joshi et al., 2017)</ref> Web NQ  Google Search Hotpot  Wikipedia Has no training data BioASQ <ref type="bibr" target="#b47">(Tsatsaronis et al., 2015)</ref> PubMed Documents DROP <ref type="bibr" target="#b13">(Dua et al., 2019)</ref> Wikipedia DuoRC <ref type="bibr" target="#b41">(Saha et al., 2018)</ref> Wikipedia+IMDB RACE <ref type="bibr" target="#b27">(Lai et al., 2017)</ref> English Exam RE <ref type="bibr" target="#b31">(Levy et al., 2017)</ref> Wikipedia Textbook <ref type="bibr" target="#b24">(Kembhavi et al., 2017)</ref> K12 Textbook For evaluation metrics, we use Mean Reciprocal Rank (MRR) as the criteria. The competing baselines include:</p><p>BM25: a strong classic IR baseline that is difficult to beat <ref type="bibr" target="#b40">(Robertson et al., 2009)</ref>.</p><p>USE-QA 2 : universal sentence encoder trained for QA task by Google <ref type="bibr" target="#b53">(Yang et al., 2019b)</ref>. USE-QA uses the dual-encoder architecture and it is trained on more than 900 million mined questionanswer pairs with 16 different languages.</p><p>Poly-Encoder (Poly-Enc): Poly Encoders improves the expressiveness of dual-encoders with two-level interaction <ref type="bibr" target="#b20">(Humeau et al., 2019)</ref>. We adapted the original dialog model for QA retrieval: two bert-base-uncased models are used as the question and answer encoders. The answer encoder has 4 vector outputs. <ref type="table" target="#tab_6">Table 4</ref> shows the MRR results on the five datasets with in-domain training. SPARTA can achieve the best performance across all domains with a large main. In terms of average MRR across the five domains, SPARTA is 114.3% better than BM25, 50.6% better than USE-QA and 26.5% better than Poly-Encoders.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">In-domain Performance</head><p>Two additional insights can be drawn from the results. First, BM-25 is a strong baseline and does not require training. It performs particularly well in domains that have a high-rate of word-overlapping between the answer and the questions. For example,  SQuAD's questions are generated by crowd workers who look at the ground truth answer, while question data from NQ/News are generated by question makers who do not see the correct answer. BM25 works particularly well in SQuAD while performing the poorest in other datasets. Similar observations are also found in prior research <ref type="bibr" target="#b0">(Ahmad et al., 2019)</ref>. Second, the results in <ref type="table" target="#tab_6">Table 4</ref> confirms our hypothesis on the importance of rich interaction between the answer and the questions. Both USE-QA and Poly Encoder use powerful transformers to encode the whole question and model word-order information in the queries. However, their performance is bounded by the simple dot-product interaction between the query and the answer. On the other hand, despite the fact that SPARTA does not model word-order information in the query, it is able to achieve a big performance gain compared to the baselines, confirming the effectiveness of the proposed token-level interaction method in Eq. 4. <ref type="table" target="#tab_8">Table 5</ref> summarized the results for out-of-domain performance comparison. SPARTA trained only on SQuAD outperforms the baselines, achieving 54.1% gain compared to BM25, 26.7% gain compared to USE-QA and 25.3% gain compared to Poly-Encoders in terms of average MRR across 11 different datasets. When SPARTA is trained on SQuAD+NQ, an additional 1.7 MRR improvement is gained compared to SPARTA-SQuAD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Out-of-domain Generalization</head><p>We can observe that Poly-Encoder is able to achieve similar in-domain performance for the domains that are included in the training. However, its performance decreases significantly in new domains, a 25.0% drop compared to its full performance for Poly-Encoder that is trained on SQuAD and 29.2% drop when it's trained on SQuAD+NQ.</p><p>Meanwhile, SPARTA generalizes its knowledge from the training data much better to new domains. When trained on SQuAD, its performance on News, Trivia, NQ, and HotPot is only 19.2% lower than the full performance and 18.3% drop when it's trained on SQuAD+NQ. Also, we note that SPARTA's zero-shot performance on News (MRR=41.2) and Trivia (MRR=45.8) is even better than the full performance of Poly-Encoder (News MRR=28.3 and Trivia MRR=39.5).</p><p>6 Model Analysis</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Interpreting Sparse Representations</head><p>One common limitation of deep neural network models is poor interpretability. Take dense distributed vector representation for example, one cannot directly make sense of each dimension and has to use dimension reduction and visualization methods, e.g. <ref type="bibr">TSNE (Maaten and Hinton, 2008)</ref>. On the contrary, the resulting SPARTA index is straightforward to interpret due to its sparse nature. Specifically, we can understand a SPARTA vector by reading the top K words with non-zero f <ref type="figure">(t, (a, c)</ref>), since these terms have the greatest impact to the final ranking score. <ref type="table">Table 6</ref> shows some example outputs. It is not hard to note that the generated terms for each answer sentence is highly relevant to both a and c, and contains not keywords that appeared in the answer, but also include terms that are potentially in the query but never appear in the answer itself. Two experts manually inspect the outputs for 500 (a, c) data points from Wikipedia, and we summarize the following four major categories of terms that are predicted by SPARTA.</p><p>Conversational search understanding: the third row is an example. "Who" appears to the top term, showing it learns Bill Gates is a person so that it's likely to match with "Who" questions.</p><p>Keyword identification: terms such as "gates, google, magnate, yellowstone" have high scores in the generated vector, showing that SPARTA learns which words are important in the answer.</p><p>Synonyms and Common Sense: "benefactor, investors" are examples of synonyms. Also even though "Utah" does not appear in the answer, it is predicted as an important term, showing that SPARTA leverages the world-knowledge from a pretrained language model and knows Yellowstone is related to Utah.  Question answering (QA) is a computer science discipline within the fields of information retrieval and natural language processing (NLP).</p><p>answering, question, q, computer, information,, retrieval,language, natural, human, nl, science, ... <ref type="table">Table 6</ref>: Top-k terms predicted by SPARTA. The text in bold is the answer sentence and the text surrounded it is encoded as its context. Each answer sentence has around 1600 terms with non-zero scores.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Sparsity vs. Performance</head><p>Sparsity not only provides interpretability, but also offers flexibility to balance the trade-off of memory footprint vs. performance. When there are memory constraints on the vector size, the SPARTA vector can be easily reduced by only keeping the top-K important terms. <ref type="table" target="#tab_10">Table 7</ref> shows performance on SQuAD and NQ with varying K. The resulting sparse vector representation is very robust to smaller K. When only keeping the top 50 terms in each answer vector, SPARTA achieves 69.5 MRR, a better score than all baselines with only 1.6% memory footprint compared to Poly-Encoders (768 x 4 dimension). NQ dataset is more challenging and requires more terms. SPARTA achieves a close to the best performance with top-500 terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In short, we propose SPARTA, a novel ranking method, that learns sparse representation for better open-domain QA. Experiments show that the proposed framework achieves the state-of-the-art performance for 4 different open-domain QA tasks in 2 languages and 11 retrieval QA tasks. This confirm our hypothesis that token-level interaction is superior to sequence-level interaction for better evidence ranking. Analyses also show the advantages of sparse representation, including interpretability, generalization and efficiency. Our findings also suggest promising future research directions. The proposed method does not support multi-hop reasoning, an important attribute that enables QA systems to answer more complex questions that require collecting multiple evidence passages. Also, current method only uses a bag-ofword features for the query. We expect further performance gain by incorporating more word-order information.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Results on Chinese Open CMRC and DRCD</figDesc><table><row><cell>datasets. For OpenSQuAD and OpenNQ, SPARTA</cell></row><row><cell>outperforms the previous best system (Asai et al.,</cell></row><row><cell>2019) by 2.7 absolute F1 points and 5.1 absolute</cell></row><row><cell>EM points respectively. For OpenCMRC and Open-</cell></row><row><cell>DRCD, SPARTA achieves a 15.3 and 6.7 absolute</cell></row><row><cell>F1 points improvement over the previous best sys-</cell></row><row><cell>tem</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell>: 11 corpora included in MultiReQA and their</cell></row><row><cell>document sources. The top 5 domains contain training</cell></row><row><cell>data and the bottom 6 domains only have test sets.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>MRR comparison for the in-domain settings.</figDesc><table><row><cell>The proposed SPARTA consistently outperform all the</cell></row><row><cell>baseline models with large margin. BM25 and USE-</cell></row><row><cell>QA are unsupervised and pre-trained respectively.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>MRR comparison in the out-of-domain settings. The proposed SPARTA is able to achieve the best performance across all tasks, the only learning-based method that is able to consistently outperform BM25 with larger margin in new domains. Results with * are in-domain performance.September 1998 by Larry Page and Sergey Brin while they were Ph.D. students at Stanford University in California. google, when, founded, page, stanford, sergey, larry, founding, established, did, 1998, was, year, formed ... Yellowstone National Park is an American national park located in the western United States, with parts in Wyoming, Montana and Idaho. montana, yellowstone, wyoming, idaho, park, where, national, western, american, us, utah ... William Henry Gates is an American business magnate, software developer, investor, and philanthropist. He is best known as the co-founder of Microsoft Corporation. who, gates, investors, magnate, developer, microsoft, philanthropist, benefactor, investors, ...</figDesc><table><row><cell>Answer (a, c)</cell><cell>Top terms</cell></row><row><cell>Google was founded in</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 7 :</head><label>7</label><figDesc>Performance on ReQA task with varying sparsity. SPARTA outperforms all baselines with top-50 terms on SQuAD, and with top-500 terms on NQ.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://tfhub.dev/google/ universal-sentence-encoder-multilingual-qa</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendices</head><p>Size details of multi-domain ReQA task.  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Reqa: An evaluation for endto-end answer retrieval models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amin</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinfei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.04780</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akari</forename><surname>Asai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuma</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.10470</idno>
		<title level="m">Learning to retrieve reasoning paths over wikipedia graph for question answering</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Semantic parsing on freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 conference on empirical methods in natural language processing</title>
		<meeting>the 2013 conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1533" to="1544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Semantic parsing via paraphrasing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1415" to="1425" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Freebase: a collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 ACM SIGMOD international conference on Management of data</title>
		<meeting>the 2008 ACM SIGMOD international conference on Management of data</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1247" to="1250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Pretraining tasks for embedding-based large-scale retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Cheng</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Felix</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin-Wen</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjiv</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.03932</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Reading Wikipedia to answer opendomain questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics (ACL)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muthuraman</forename><surname>Chidambaram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinfei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Hsuan</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Strope</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ray</forename><surname>Kurzweil</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.12836</idno>
		<title level="m">Learning cross-lingual sentence representations via a multi-task dual-encoder model</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Simple and effective multi-paragraph reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10723</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Revisiting pretrained models for chinese natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shijin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoping</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of EMNLP. Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">A span-extraction dataset for chinese machine reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhipeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wentao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shijin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoping</forename><surname>Hu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.07366</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhuwan</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vidhisha</forename><surname>Balachandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.10640</idno>
		<title level="m">Differentiable reasoning over a virtual knowledge base</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dheeru</forename><surname>Dua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pradeep</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Stanovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.00161</idno>
		<title level="m">Drop: A reading comprehension benchmark requiring discrete reasoning over paragraphs</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Open question answering over curated and extracted knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1156" to="1165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Building watson: An overview of the deepqa project</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Ferrucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Chu-Carroll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Gondek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><forename type="middle">A</forename><surname>Kalyanpur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lally</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Murdock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Nyberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Prager</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI magazine</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="59" to="79" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.09753</idno>
		<title level="m">Mrqa 2019 shared task: Evaluating generalization in reading comprehension</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A deep relevance matching model for ad-hoc retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixing</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyao</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM International on Conference on Information and Knowledge Management</title>
		<meeting>the 25th ACM International on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="55" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iñigo</forename><surname>Casanueva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Mrkšić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vulić</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.03688</idno>
		<title level="m">Convert: Efficient and accurate conversational representations from transformers</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Retrieve, read, rerank: Towards end-to-end multi-document reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghao</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxing</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongsheng</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.04618</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Poly-encoders: Transformer architectures and pre-training strategies for fast and accurate multi-sentence scoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Humeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Anne</forename><surname>Lachaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno>abs/1905.01969</idno>
	</analytic>
	<monogr>
		<title level="m">External Links: Link Cited by</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2" to="2" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Spanbert: Improving pre-training by representing and predicting spans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Levy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="64" to="77" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.03551</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Dense passage retrieval for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barlas</forename><surname>Oguz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ledell</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wentau</forename><surname>Yih</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.04906</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Are you smarter than a sixth grader? textbook question answering for multimodal machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aniruddha</forename><surname>Kembhavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dustin</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonghyun</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4999" to="5007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Natural questions: a benchmark for question answering research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennimaria</forename><surname>Palomaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivia</forename><surname>Redfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danielle</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="453" to="466" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guokun</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.04683</idno>
		<title level="m">Race: Large-scale reading comprehension dataset from examinations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Contextualized sparse representations for real-time open-domain question answering. arXiv: Computation and Language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinhyuk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaewoo</forename><surname>Kang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Ranking paragraphs for improving answer recall in open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinhyuk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seongjun</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunjae</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miyoung</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaewoo</forename><surname>Kang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.00494</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Latent retrieval for weakly supervised open domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.00300</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Zero-shot relation extraction via reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.04115</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<title level="m">Generative question answering: Learning to answer the whole question</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Introduction to information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prabhakar</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schütze</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mccandless</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Hatcher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Otis</forename><surname>Gospodnetić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Gospodnetić</surname></persName>
		</author>
		<title level="m">Lucene in action</title>
		<meeting><address><addrLine>Manning Greenwich</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">A discrete hard em approach for weakly supervised question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.04849</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Efficient and robust question answering from minimal context over documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.08092</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">From doc2query to doctttttquery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">I</forename><surname>Epistemic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Squad: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.05250</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The probabilistic relevance framework: Bm25 and beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Zaragoza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends R in Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="333" to="389" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Duorc: Towards complex language understanding with paraphrased reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amrita</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Aralikatte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mitesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Khapra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sankaranarayanan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.07927</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Bidirectional attention flow for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aniruddha</forename><surname>Kembhavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01603</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Real-time open-domain question answering with dense-sparse phrase index</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinhyuk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4430" to="4441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih Chieh</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trois</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuting</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiying</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Tsai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.00920</idno>
		<title level="m">Drcd: a chinese machine reading comprehension dataset</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Asymmetric lsh (alsh) for sublinear time maximum inner product search (mips)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anshumali</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2321" to="2329" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Newsqa: A machine comprehension dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">(</forename><surname>Xingdi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><forename type="middle">D</forename><surname>Eric) Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaheer</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Suleman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">An overview of the bioasq large-scale biomedical semantic indexing and question answering competition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Tsatsaronis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Balikas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prodromos</forename><surname>Malakasiotis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Partalas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Zschunke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Michael R Alvers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anastasia</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergios</forename><surname>Krithara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Petridis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Polychronopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC bioinformatics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">138</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">R 3: Reinforced ranker-reader for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Klinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerry</forename><surname>Tesauro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Ramesh Nallapati, and Bing Xiang</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofei</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.08167</idno>
	</analytic>
	<monogr>
		<title level="m">Multi-passage bert: A globally normalized bert model for open-domain question answering</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Distant supervision for multistage fine-tuning in retrieval-based question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luchen</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><forename type="middle">Jing</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoxing</forename><surname>Huai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Web Conference 2020</title>
		<meeting>The Web Conference 2020</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2934" to="2940" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">End-to-end neural ad-hoc ranking with kernel pooling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuyun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russell</forename><surname>Power</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th International ACM SIGIR conference on research and development in information retrieval</title>
		<meeting>the 40th International ACM SIGIR conference on research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="55" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aileen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luchen</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.01718</idno>
		<title level="m">End-to-end open-domain question answering with bertserini</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Multilingual universal sentence encoder for semantic retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinfei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amin</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandy</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jax</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustavo</forename><surname>Hernandez Abrego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Tar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Hsuan</forename><surname>Sung</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.04307</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saizheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.09600</idno>
		<title level="m">Hotpotqa: A dataset for diverse, explainable multi-hop question answering</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
