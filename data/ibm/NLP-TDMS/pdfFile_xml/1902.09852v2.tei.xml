<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Associatively Segmenting Instances and Semantics in Point Clouds</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlong</forename><surname>Wang</surname></persName>
							<email>wangxinlon@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Adelaide</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Youtu Lab</orgName>
								<address>
									<region>Tencent</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyong</forename><surname>Shen</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Youtu Lab</orgName>
								<address>
									<region>Tencent</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
							<email>chunhua.shen@adelaide.edu.au</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Adelaide</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Youtu Lab</orgName>
								<address>
									<region>Tencent</region>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Associatively Segmenting Instances and Semantics in Point Clouds</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T19:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A 3D point cloud describes the real scene precisely and intuitively. To date how to segment diversified elements in such an informative 3D scene is rarely discussed. In this paper, we first introduce a simple and flexible framework to segment instances and semantics in point clouds simultaneously. Then, we propose two approaches which make the two tasks take advantage of each other, leading to a win-win situation. Specifically, we make instance segmentation benefit from semantic segmentation through learning semantic-aware point-level instance embedding. Meanwhile, semantic features of the points belonging to the same instance are fused together to make more accurate per-point semantic predictions. Our method largely outperforms the state-of-the-art method in 3D instance segmentation along with a significant improvement in 3D semantic segmentation. Code has been made available at: https</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Both instance segmentation and semantic segmentation aim to detect specific informative region represented by sets of smallest units in the scenes. For example, a point cloud can be parsed into groups of points, where each group corresponds to a class of stuff or an individual instance. The two tasks are related and both have wide applications in real scenarios, e.g., autonomous driving and augmented reality. Though great progress has been made in recent years <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b34">34,</ref><ref type="bibr" target="#b15">16]</ref> for each single task, no prior method tackles these two tasks associatively.</p><p>In fact, instance segmentation and semantic segmentation conflict with each other in some respects. The former one distinguishes different instances of the same class clearly, while the latter one wants them to have the same label. However, the two tasks could cooperate with each other through seeking common grounds. Semantic segmentation distinguishes points of different classes, which is also one  <ref type="figure">Figure 1</ref>: Instance segmentation and semantic segmentation results using ASIS. Our method takes raw point clouds as inputs and outputs instance labels and semantic labels for each point. of the purposes of instance segmentation, as points of different classes must belong to different instances. Furthermore, instance segmentation assigns the same label to points belonging to the same instance, which is also consistent with semantic segmentation, as points of the same instance must belong to the same category. This observation makes one wonder how the two tasks could be associated together to lead to a win-win solution?</p><p>There may be two straightforward approaches. The first one is that, given the semantic labels, we could run instance segmentation independently on every semantic class to better distinguish individual instances. Thus, different class instances are separated simply but naively.</p><p>However, the instance segmentation would greatly depend on performance of semantic segmentation as incorrect semantic predictions would inevitably result in incorrect instance predictions. Otherwise, given the instance labels, one could classify each instance and assign the predicted class label to each point of this instance. Thus, the problem is transformed to an easier instance recognition problem. However, inaccurate instance predictions would deeply confuse the downstream object classifiers. Both these two approaches are in step-wise paradigm, which can be sub-optimal and inefficient. In this work, we integrate the two tasks altogether into an end-to-end parallel training framework, which shares the same benefits in a soft and learnable fashion.</p><p>We first introduce a simple baseline to segment instances and semantics simultaneously. It is similar to the method in <ref type="bibr" target="#b5">[6]</ref> for 2D images, but we tailor it for 3D point cloud. The network of the baseline has two parallel branches: one for per-point semantic predictions; the other outputs pointlevel instance embeddings, where the embeddings of points belonging to the same instance stay close while those of different instances are apart. Our baseline method can already achieve better performance than the recent state-of-the-art method, SGPN <ref type="bibr" target="#b35">[35]</ref>, as well as faster training and inference. Based on this flexible baseline, a novel technique is further proposed to associate instance segmentation and semantic segmentation closely together, termed ASIS (Associatively Segmenting Instances and Semantics).</p><p>With the proposed ASIS method, we are able to learn semantic-aware instance embeddings, where the embeddings of points belonging to different semantic classes are further separated automatically through feature fusion. As shown in <ref type="figure">Figure 2</ref>, the boundaries between different class points are clearer (chair &amp; table, window &amp; wall). Moreover, the semantic features of points belonging to the same instance are exploited and fused together to make more accurate per-point semantic predictions. The intuition behind it is that during semantic segmentation a point being assigned to one of the categories is because the instance containing that point belongs to that category. Thus, the two tasks can take advantage of each other to further boost their performance. Our method is demonstrated to be effective and general on different backbone networks, e.g., the Point-Net <ref type="bibr" target="#b26">[26]</ref> and hierarchical architecture PointNet++ <ref type="bibr" target="#b28">[28]</ref>. The method can also be used to tackle the panoptic segmentation <ref type="bibr" target="#b13">[14]</ref> task, which unifies the semantic and instance segmentation. To summarize, our main contributions are as follows.</p><p>• We propose a fast and efficient simple baseline for simultaneous instance segmentation and semantic segmentation on 3D point clouds. • We propose a new framework, termed ASIS, to associate instance segmentation and semantic segmentation closely together. Specifically, two types of partnerships are proposed-semantics awareness for instance segmentation and instance fusion for semantic segmentation-to make these two tasks cooperate with each other. • With the proposed ASIS, the model containing semantics-aware instance segmentation and instancefused semantic segmentation are trained end-to-end, which outperforms state-of-the-art 3D instance segmentation methods on the S3DIS dataset <ref type="bibr" target="#b0">[1]</ref> along with a significant improvement on the 3D semantic  <ref type="bibr" target="#b21">[22]</ref> technique is used to visualize the learned instance embeddings for the points on S3DIS test data. Three closeup pairs are shown. Of each pair the left patch is from our baseline method, while the right one is from ASIS. Differences in color shade represent distances in instance embedding space. segmentation task. Furthermore, our experiments on the ShapeNet dataset <ref type="bibr" target="#b39">[39]</ref> show that ASIS is also beneficial for the task of part segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Instance Segmentation. 2D instance segmentation has attracted much research attention recently, leading to various top-performing methods. Inspired by the effectiveness of region-based CNN (R-CNN) <ref type="bibr" target="#b7">[8]</ref> in object detection problem, <ref type="bibr" target="#b25">[25,</ref><ref type="bibr" target="#b3">4]</ref> learn to segment instances by proposing segment candidates. The mask proposals are further classified to obtain the final instance masks. Dai et al. <ref type="bibr" target="#b4">[5]</ref> predict segment proposals based on bounding box proposals. He et al. <ref type="bibr" target="#b9">[10]</ref> propose the simpler and flexible Mask R-CNN which predicts masks and class labels simultaneously. Different from the top-down detector-based approaches above, bottom-up methods learn to associate per-pixel predictions to object instances. Newell et al. <ref type="bibr" target="#b24">[24]</ref> group pixels into instances using the learned associative embedding. Brabandere et al. <ref type="bibr" target="#b5">[6]</ref> propose a discriminative loss function which enables to learn pixel-level instance embedding efficiently. Liu et al. <ref type="bibr" target="#b19">[20]</ref> decompose the instance segmentation problem into a sequence of sub-grouping problems. However, 3D instance segmentation is rarely researched. Wang et al. <ref type="bibr" target="#b35">[35]</ref> learn the similarity matrix of a point cloud to get instance proposals. In this work, we introduce a simple and flexible method that learns effective point-level instance embedding with the help of semantic features in 3D point clouds.</p><p>Semantic Segmentation. With the recent development of convolutional neural networks (CNNs) <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b32">32]</ref>, tremendous progress has been made in semantic segmentation. Approaches <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b18">19]</ref> based on fully convolutional networks (FCN) <ref type="bibr" target="#b20">[21]</ref> dominate the semantic segmentation on 2D images. As for 3D segmentation, Huang et al. <ref type="bibr" target="#b10">[11]</ref> propose 3D-FCNN which predict coarse voxel-level semantic label. PointNet <ref type="bibr" target="#b26">[26]</ref> and following works <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b38">38]</ref> use multilayer perceptron (MLP) to produce fine-grained point-level segmentation. Very recently, Landrieu et al. <ref type="bibr" target="#b15">[16]</ref> introduce superpoint graph (SPG) to segment large-scale point clouds.</p><p>In fact, few of previous works segment semantics taking advantages of the instance embedding, either in 2D images or 3D point clouds.</p><p>Deep Learning on Point Clouds. To take advantage of the strong representation capability of classic CNNs, a 3D point cloud is first projected into multiview rendering images in <ref type="bibr" target="#b33">[33,</ref><ref type="bibr" target="#b31">31,</ref><ref type="bibr" target="#b27">27,</ref><ref type="bibr" target="#b8">9]</ref>, on which the well-designed CNNs for 2D images can be applied. But part of contextual information in point cloud is left behind during the projection process. Another popular representation for point cloud data is voxelized volumes. The works of <ref type="bibr" target="#b37">[37,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b30">30]</ref> convert point cloud data into regular volumetric occupancy grids, then train 3D CNNs or the varieties to perform voxellevel predictions. A drawback of volumetric representations is being both computationally and memory intensive, due to the sparsity of point clouds and the heavy computation of 3D convolutions. Therefore those methods are limited to deal with large-scale 3D scenes. To process raw point cloud directly, PointNet <ref type="bibr" target="#b26">[26]</ref> is proposed to yield point-level predictions, achieving strong performance on 3D classification and segmentation tasks. The following works Point-Net++ <ref type="bibr" target="#b28">[28]</ref>, RSNet <ref type="bibr" target="#b12">[13]</ref>, DGCNN <ref type="bibr" target="#b36">[36]</ref> and PointCNN <ref type="bibr" target="#b16">[17]</ref> further focus on exploring the local context and hierarchical learning architectures. In this work, we build a novel framework to associatively segment instances and semantics in point clouds, and demonstrate that it is effective and general on different backbone networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Our Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">A Simple Baseline</head><p>Here we introduce a simple yet effective framework. It is composed of a shared encoder and two parallel decoders. One of the decoders is for point-level semantic predictions, while the other one aims to handle the instance segmentation problem. Specifically, a point cloud of size N p is first extracted and encoded into a feature matrix through the feature encoder (e.g., stacked PointNet layers). This shared feature matrix refers to the concatenation of local features and global features in PointNet architecture, or the output of the last set abstraction module for the PointNet++ architecture. The two parallel branches then fetch the feature matrix and proceed with their following predictions separately. The semantic segmentation branch decodes the shared feature matrix into N P × N F shaped semantic feature matrix F SEM , and then outputs the semantic predictions P SEM with shape of N P × N C where N C is the number of semantic categories. The instance segmentation branch has the same architecture except the last output layer. The N P × N F instance feature matrix F INS is used to predict per-point instance embedding E INS with shape of N P × N E where N E is the dimension of the embedding. The embeddings of a point cloud represent the the instance relationship between points in it: the points belonging to the same instance are close to each other in embedding space, while those points of different instances are apart.</p><p>At training time, the semantic segmentation branch is supervised by the classical cross entropy loss. As for the instance segmentation, the discriminative loss function for 2D image in <ref type="bibr" target="#b5">[6]</ref> is adopted to supervise the instance embedding learning. We modify it and make it suitable for point clouds. The loss used in <ref type="bibr" target="#b5">[6]</ref> is class-specific: the instance embeddings of different semantic class are learned separately, which means the semantic class should be given first. This step-wise paradigm is highly dependent on the quality of semantic prediction, as incorrect semantic prediction would inevitably result in incorrect instance recognition. Thus, we adopt the class-agnostic instance embedding learning strategy, where embeddings are in charge of distinguishing different instances and are blind to their categories. The loss function is formulated as follows:</p><formula xml:id="formula_0">L = L var + L dist + α · L reg ,<label>(1)</label></formula><p>where L var aims to pull embeddings towards the mean embedding of the instance, i.e. the instance center, L dist make instances repel each other, and L reg is a regularization term to keep the embedding values bounded. α is set to 0.001 in our experiments. Specifically, each term can be written as follows:</p><formula xml:id="formula_1">L var = 1 I I i=1 1 N i Ni j=1 µ i − e j 1 − δ v 2 + ,<label>(2)</label></formula><formula xml:id="formula_2">L dist = 1 I(I − 1) I i A =1 I i B =1 i A =i B [2δ d − µ i A − µ i B 1 ] 2 + , (3) L reg = 1 I I i=1 µ i 1 ,<label>(4)</label></formula><p>where I is the number of ground-truth instances; N i is the number of points in instance i; µ i is the mean embedding of instance i; · 1 is the 1 distance; e j is an embedding of a point; δ v and δ d are margins; [x] + = max(0, x) means the hinge.</p><p>During the test, final instance labels are obtained using mean-shift clustering <ref type="bibr" target="#b2">[3]</ref> on instance embeddings. We assign the mode of the semantic labels of the points within the same instance as its final category. The pipeline is illustrated in <ref type="figure" target="#fig_3">Figure 3</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Mutual Aid</head><p>As depicted in <ref type="figure" target="#fig_3">Figure 3</ref>(b), benefiting from the simple and flexible framework described above, we are able to build upon it the novel ASIS module and achieve semanticaware instance segmentation and instance-fused semantic segmentation.</p><p>Semantic-aware Instance Segmentation. Semantic features of a point cloud construct a new and high-level feature space, where points are naturally positioned according to their categories. In that space, points of the same semantic class lie close together while different classes are separated. We abstract the semantic awareness (SA) from semantic features and integrate it into the instance features, producing semantic-aware instance features. Firstly, the semantic feature matrix F SEM is adapted to instance feature space as F SEM through a point independent fully connected layer (FC) with batch normalization and ReLU activation function. F SEM has the same shape with F SEM . Then, We add the adapted semantic feature matrix F SEM to instance feature matrix F INS element-wise, producing semantic-aware instance feature matrix F SINS . The procedure can be formulated as:</p><formula xml:id="formula_3">F SINS = F INS + F C(F SEM ).<label>(5)</label></formula><p>In this soft and learnable way, points belonging to different category instances are further repelled in instance feature space, whereas same category instances are rarely affected. The feature matrix F SINS is used to generate final instance embeddings.</p><p>Instance-fused Semantic Segmentation. Given the instance embeddings, we use K nearest neighbor (kNN) search to find a fixed number of neighboring points for each point (including itself) in instance embedding space.</p><p>To make sure the K sampled points belonging to the same instance, we filter the outliers according to the margin δ v used in Equation 2. As described in Section 3.1, the hinged loss term L var supervises the instance embedding learning through drawing each point embedding close to the the mean embedding within a distance of δ v . The output of the kNN search is an index matrix with shape of N P × K. According to the index matrix, the semantic features (F SEM ) of those points are grouped to a N P ×K ×N F shaped feature tensor, which is groups of semantic feature matrix where each group corresponds to a local region in instance embedding space neighboring its centroid point. Inspired by the effectiveness of channel-wise max aggregation in <ref type="bibr" target="#b26">[26,</ref><ref type="bibr" target="#b36">36,</ref><ref type="bibr" target="#b38">38]</ref>, semantic features of each group are fused together through a channel-wise max aggregation operation, as the refined semantic feature of the centroid point. The instance fusion (IF) can be formulated as below. For the N P × N F shaped semantic feature matrix F SEM = {x 1 , ..., x N P } ⊆ R N F , instance-fused semantic features are calculated as:</p><formula xml:id="formula_4">x i = Max(x i1 , x i2 , ..., x ik ),<label>(6)</label></formula><p>where {x i1 , ..., x ik } represent the semantic features of K neighboring points centered point i in instance embedding space, and Max is an element-wise maximum operator which takes K vectors as input and output a new vector. After the instance fusion, the output is a N P × N F feature matrix F ISEM , the final semantic features to be fed into the last semantic classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experiment Settings</head><p>Datasets. We carry out experiments on two public datasets: Stanford 3D Indoor Semantics Dataset (S3DIS) <ref type="bibr" target="#b0">[1]</ref> and ShapeNet <ref type="bibr" target="#b39">[39]</ref>. S3DIS contains 3D scans from Matterport Scanners in 6 areas that in total have 272 rooms. Each point in the scene point cloud is associated with an instance label and one of the semantic labels from 13 categories. Besides the large real scene benchmark S3DIS, we also evaluate our methods on the ShapeNet part dataset. This dataset contains 16, 881 3D shapes from 16 categories. Each point sampled from the shapes is assigned with one of the 50 different parts. The instance annotations from <ref type="bibr" target="#b35">[35]</ref> are used as the instance ground-truth labels.</p><p>Evaluation Metrics. Our experiments involved S3DIS are conducted following the same k-fold cross validation with micro-averaging as in <ref type="bibr" target="#b26">[26]</ref>. We also report the performance on the fifth fold following <ref type="bibr" target="#b34">[34]</ref>, as Area 5 is not present in other folds. For evaluation of semantic segmentation, overall accuracy (oAcc), mean accuracy (mAcc) and mean IoU (mIoU) across all the categories are calculated along with the detailed scores of per class IoU. As for instance segmentation, (weighted) coverage (Cov, WCov) <ref type="bibr" target="#b29">[29,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b40">40</ref>] are adopted. Cov is the average instance-wise IoU of prediction matched with ground-truth. The score is further weighted by the size of the ground-truth instances to get WCov. For ground-truth regions G and predicted regions O, these values are defined as</p><formula xml:id="formula_5">Cov(G, O) = |G| i=1 1 |G| max j IoU(r G i , r O j ),<label>(7)</label></formula><formula xml:id="formula_6">WCov(G, O) = |G| i=1 w i max j IoU(r G i , r O j ),<label>(8)</label></formula><formula xml:id="formula_7">w i = |r G i | k |r G k | ,<label>(9)</label></formula><p>where |r G i | is the number of points in ground-truth region i. Besides, the classical metrics mean precision (mPrec) and mean recall (mRec) with IoU threshold 0.5 are also reported.</p><p>Training and Inference Details. For the S3DIS dataset, each point is represented by a 9-dim feature vector (XYZ, RGB and normalized coordinates as to the room). During training, we follow the procedure in <ref type="bibr" target="#b26">[26]</ref> and split the rooms into 1m×1m overlapped blocks on the ground plane, each containing 4096 points. For the instance segmentation branch, we train the network with σ v = 0.5, σ d = 1.5, and 5 output embedding dimensions. For the kNN search in instance fusion, K is set to 30. We train the network for 50 epochs and 100 epochs for PointNet and PointNet++ respectively, with batch size 24, base learning rate set to 0.001 and divided by 2 every 300k iterations. The Adam solver is adopted to optimize the network on a single GPU. Momentum is set to 0.9. At test time, bandwidth is set to 0.6 for mean-shift clustering. BlockMerging algorithm <ref type="bibr" target="#b35">[35]</ref> is used to merge instances from different blocks. For ShapeNet dataset, each shape is represented by a point cloud with 2048 points, as in <ref type="bibr" target="#b26">[26]</ref>. Each point is represented by a 3dim vector (XY Z).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">S3DIS Results</head><p>We conduct experiments on S3DIS dataset using Point-Net and PointNet++ (single-scale grouping) as our backbone networks. If no extra notes, our main analyses are based on PointNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Baseline Method</head><p>We report instance segmentation results of our baseline method in <ref type="table" target="#tab_0">Table 1</ref>. Based on PointNet backbone, our method achieves 46.3 mWCov when evaluate by 6-fold cross validation, which shows an absolute 5.5-point improvement over the state-of-the-art method SGPN 1 . The superiority is consistent across the four evaluation metrics. Semantic segmentation results are shown in <ref type="table" target="#tab_1">Table 2</ref>. The mIoU of training without instance segmentation branch is 48.9, which can be regarded as the result of pure backbone PointNet. Equipped with instance segmentation training, our semantic segmentation baseline result achieves 49.5 mIoU, which is slightly better. It indicates that the supervision of instance segmentation helps learn more general shared feature representation. As for the training time, SGPN needs 16 ∼ 17 hours (excluding pre-training) to converge, while it only takes 4 ∼ 5 hours for our method to train from scratch, both on a single GPU. More computation time comparisons can be referred to <ref type="table" target="#tab_6">Table 5</ref>. Our baseline method is demonstrated to be effective and efficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">ASIS</head><p>Semantic Segmentation. In <ref type="table" target="#tab_0">Table 1</ref>, we report the results of ASIS on instance segmentation task. ASIS yields 48.2 mWCov, which outperforms our baseline by 1.9-point. In terms of another metric mean precision, a larger 2.6-point gain is observed. When evaluated on Area 5, the improvements are more significant: 2.7 mWCov and 2.2 mPrec. Through visualizations in <ref type="figure" target="#fig_4">Figure 4</ref>, our baseline method tends to group two nearby different class instances together into one instance (e.g., board &amp; wall). With ASIS, they are well distinguished as semantic awareness helps repel them in instance embedding space. Per class performance changes are in accordance with our observations. Shown in <ref type="table" target="#tab_5">Table 4</ref>, ASIS yields 5.0 WCov and 2.4 WCov gains on class "board" and class "wall" on instance segmentation.</p><p>Instance Segmentation. <ref type="table" target="#tab_1">Table 2</ref> reports the results of ASIS on semantic segmentation task. ASIS improves the mIoU by 1.6-point. We obseve more significant improvements of 2.8 mAcc and 1.7 mIoU when evaluating on Area 5. In <ref type="figure" target="#fig_5">Figure 5</ref> we show some comparison examples on semantic segmentation. ASIS performs better on complicated categories (e.g., bookcase) and is aware of instance integrity (e.g., table, window) as instance fusion aggregates points belonging to the same instance to produce more accurate predictions. <ref type="table" target="#tab_5">Table 4</ref> shows that ASIS outperforms the baseline by 3.5 IoU and 2.2 IoU on class "table" and class "bookcase", which are in line with our analysis.  <ref type="table">Table 3</ref>: Ablation study on the S3DIS dataset. IF refers to instance fusion; SA refers to semantic awareness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Real Scene</head><p>Baseline ASIS Ground Truth  Stronger Backbone. Both the two tasks benefit largely from our novel method. When adopt the stronger architecture PointNet++ as our backbone network, we observe consistent improvements: 2.1 mWCov and 2.6 mIoU gains on Area 5; 1.7 mWCov and 1.1 mIoU gains for 6-fold cross validation. The results on PointNet++ indicate that our ASIS is a general framework and can be built upon different backbone networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Analysis</head><p>Ablative Analysis. Equipped with only instance fusion for semantic segmentation, our method achieves 50.0 mIoU and 47.0 mWCov. Compared to the baseline, there is a 0.5point gain on mIoU. Furthermore, better semantic predictions assign more correct class labels to instances, improv-  ing the instance segmentation performance. When adopt semantic awareness alone, we achieve an improvement of 1.1 mWCov (from 46.3 to 47.4). The improvement of one task also helps the other one, as better shared features are learned. Applying instance fusion and semantic awareness together, the performance boost is larger than using only one of them. On the basis of instance fusion, semantic awareness could bring additional 1.1 mIoU and 1.2 mWCov gains. The semantic awareness strengthens the instance segmentation, as well as improving the semantic segmentation. It is because that the improved instance embedding predictions could amplify the improvements brought by instance fusion, thus leading to a further 1.1 mIoU gain. The similar results can also be observed when add instance fusion on semantic awareness. To conclude, the two components not only perform their own duty well, but also enlarge the function of the other one.</p><p>Category-based Analysis. We show how the performance of each category changes in <ref type="figure" target="#fig_8">Figure 7</ref>. Interestingly the categories being helped by ASIS module are different for instance segmentation and semantic segmentation. On instance segmentation, our ASIS module largely helps the categories in which instances often surround with instances of other classes (e.g., beam, board and window). For example, board is hung on the wall. The board is easily being ignored during instance segmentation, as the body of the board has similar color and shape with the wall. Our semantic awareness in ASIS module shows great superiority on these cases: 5.0 WCov and 2.4 WCov improvements on class "board"   <ref type="figure" target="#fig_4">Figure 4</ref>. On semantic segmentation, ASIS module significantly boosts the performance of the categories in which instances have complicated shapes (e.g., table, chair and bookcase), because they benefit much from instance fusion.    instances, while the color itself does not mean anything. Either same class instances or different class instances are distinguished properly. For example, the points of the tables and the surrounding chairs are grouped into distinct instances. As for semantic segmentation, specific color refers to particular class (e.g., yellow for wall, purple for window). We also show some failure cases in <ref type="figure" target="#fig_7">Figure 6</ref>. In the scenes of the second and third row, two nearby chairs are mistakenly segmented together as a single instance. Though our method does not draw the point embeddings of the same class instances close, we yet do not contribute on better distinguishing this kind of cases. We leave it to future works to explore better solutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4">Qualitative Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.5">Computation Time</head><p>In <ref type="table" target="#tab_6">Table 5</ref>, we report computation time measured on a single Tesla P40 GPU. The inference procedure can be divided in to two steps: the network inference, and point grouping which groups points into individual instances. For SGPN, the grouping step refers to their GroupMerge algorithm. In our ASIS, it is the mean-shift clustering. We achieve comparable speed with SGPN on network inference, while our grouping step is much faster. Overall, it takes 205ms for ASIS to process an input point cloud with size 4096 × 9 and output the final labels, which is 3.5× faster than SGPN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">ShapeNet Results</head><p>We conduct experiments on ShapeNet dataset using instance segmentation annotations generated by <ref type="bibr" target="#b35">[35]</ref>, which are not "real" ground truths. Following <ref type="bibr" target="#b35">[35]</ref>, only qualitative results of part instance segmentation are provided. As shown in <ref type="figure" target="#fig_10">Figure 8</ref>, tires of the car and legs of the chair are well grouped into individual instances. Semantic segmentation results are reported in <ref type="table" target="#tab_8">Table 6</ref>. Using PointNet as backbone, we achieve a 0.6-point improvement. Based on PointNet++, ASIS outperforms the baseline by 0.7 mIoU. These results demonstrate that our method is also beneficial for part segmentation problem.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, a novel segmentation framework, namely ASIS, is proposed for associating instance segmentation and semantic segmentation on point clouds. The relationships between the two tasks are explicitly explored and directly guide our method design. Our experiments on S3DIS dataset and ShapeNet part dataset demonstrate the effectiveness and efficiency of ASIS. We expect wide application of the proposed method in 3D instance segmentation and 3D semantic segmentation, as well as hoping the novel design provides insights to future works on segmentation tasks, e.g., panoptic segmentation, and beyond.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>2 1 3 Figure 2 :</head><label>32</label><figDesc>1D embeddings of learned point-level instance embeddings. t-SNE</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>(a).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Illustration of our method for point cloud instance segmentation and semantic segmentation. (a) Full pipeline of the system. (b) Illustration of the ASIS module.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Comparison of our baseline method and ASIS on instance segmentation. Different colors represent different instances.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Comparison of our baseline method and ASIS on semantic segmentation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Qualitative results of ASIS on the S3DIS test fold.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Per class performance changes. (a) Changes of instance segmentation performance compared to our baseline method. (b) Changes of semantic segmentation performance compared to our baseline method. and class "wall". Some visualization examples of the comparison are illustrated in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 6</head><label>6</label><figDesc>shows some visualization examples of ASIS. For instance segmentation, different colors represent different mean ceiling floor wall beam column window door</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 8 :</head><label>8</label><figDesc>Qualitative results of ASIS on ShapeNet test split. (a) Instance segmentation results of ASIS. (b) Generated ground truth for instance segmentation. (c) Semantic segmentation results of ASIS. (d) Semantic segmentation ground truth.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Instance segmentation results on S3DIS dataset.</figDesc><table><row><cell>Backbone</cell><cell></cell><cell>Method</cell><cell cols="3">mCov mWCov mPrec mRec</cell></row><row><cell></cell><cell></cell><cell cols="3">Test on Area 5</cell></row><row><cell></cell><cell></cell><cell>SGPN [35]</cell><cell>32.7</cell><cell>35.5</cell><cell>36.0</cell><cell>28.7</cell></row><row><cell>PN</cell><cell cols="3">ASIS (vanilla) 38.0</cell><cell>40.6</cell><cell>42.3</cell><cell>34.9</cell></row><row><cell></cell><cell></cell><cell>ASIS</cell><cell>40.4</cell><cell>43.3</cell><cell>44.5</cell><cell>37.4</cell></row><row><cell>PN++</cell><cell cols="3">ASIS (vanilla) 42.6 ASIS 44.6</cell><cell>45.7 47.8</cell><cell>53.4 55.3</cell><cell>40.6 42.4</cell></row><row><cell></cell><cell></cell><cell cols="3">Test on 6-fold CV</cell></row><row><cell></cell><cell></cell><cell>SGPN [35]</cell><cell>37.9</cell><cell>40.8</cell><cell>38.2</cell><cell>31.2</cell></row><row><cell>PN</cell><cell cols="3">ASIS (vanilla) 43.0</cell><cell>46.3</cell><cell>50.6</cell><cell>39.2</cell></row><row><cell></cell><cell></cell><cell>ASIS</cell><cell>44.7</cell><cell>48.2</cell><cell>53.2</cell><cell>40.7</cell></row><row><cell>PN++</cell><cell cols="3">ASIS (vanilla) 49.6 ASIS 51.2</cell><cell>53.4 55.1</cell><cell>62.7 63.6</cell><cell>45.8 47.5</cell></row><row><cell cols="2">Backbone</cell><cell>Method</cell><cell></cell><cell cols="2">mAcc mIoU oAcc</cell></row><row><cell></cell><cell></cell><cell cols="3">Test on Area 5</cell></row><row><cell></cell><cell></cell><cell cols="2">PN (RePr)</cell><cell>52.1</cell><cell>43.4</cell><cell>83.5</cell></row><row><cell>PN</cell><cell></cell><cell cols="2">ASIS (vanilla)</cell><cell>52.9</cell><cell>44.7</cell><cell>83.7</cell></row><row><cell></cell><cell></cell><cell>ASIS</cell><cell></cell><cell>55.7</cell><cell>46.4</cell><cell>84.5</cell></row><row><cell>PN++</cell><cell></cell><cell cols="2">ASIS (vanilla) ASIS</cell><cell>58.3 60.9</cell><cell>50.8 53.4</cell><cell>86.7 86.9</cell></row><row><cell></cell><cell></cell><cell cols="3">Test on 6-fold CV</cell></row><row><cell></cell><cell></cell><cell>PN [26]</cell><cell></cell><cell>-</cell><cell>47.7</cell><cell>78.6</cell></row><row><cell>PN</cell><cell></cell><cell cols="2">PN (RePr) ASIS (vanilla)</cell><cell>60.3 60.7</cell><cell>48.9 49.5</cell><cell>80.3 80.4</cell></row><row><cell></cell><cell></cell><cell>ASIS</cell><cell></cell><cell>62.3</cell><cell>51.1</cell><cell>81.7</cell></row><row><cell>PN++</cell><cell></cell><cell cols="2">ASIS (vanilla) ASIS</cell><cell>69.0 70.1</cell><cell>58.2 59.3</cell><cell>85.9 86.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Semantic segmentation results on S3DIS dataset.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>table chair sofa bookcase board clutter</figDesc><table><row><cell>WCov</cell><cell>46.3 48.2</cell><cell>79.2 80.1</cell><cell>77.0 76.4</cell><cell>63.7 66.1</cell><cell>47.6 53.4</cell><cell>6.6 9.2</cell><cell>55.6 58.8</cell><cell>47.5 49.8</cell><cell>50.5 50.6</cell><cell>57.3 59.4</cell><cell>9.9 9.9</cell><cell>31.3 32.3</cell><cell>33.7 38.7</cell><cell>41.5 42.0</cell></row><row><cell>Sem IoU</cell><cell>49.5 51.1</cell><cell>90.1 91.3</cell><cell>87.8 89.7</cell><cell>69.2 69.8</cell><cell>42.3 45.8</cell><cell>26.0 27.0</cell><cell>50.4 51.9</cell><cell>54.9 55.1</cell><cell>57.5 61.0</cell><cell>45.8 49.3</cell><cell>8.9 9.1</cell><cell>38.0 40.2</cell><cell>33.4 33.5</cell><cell>39.2 40.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Per class results on the S3DIS dataset.</figDesc><table><row><cell>Method</cell><cell cols="3">Inference Time (ms) Overall Network Grouping</cell><cell>mWCov</cell></row><row><cell>SGPN</cell><cell>726</cell><cell>18</cell><cell>708</cell><cell>35.5</cell></row><row><cell>ASIS (vanilla)</cell><cell>212</cell><cell>11</cell><cell>201</cell><cell>41.4</cell></row><row><cell>ASIS</cell><cell>205</cell><cell>20</cell><cell>185</cell><cell>43.6</cell></row><row><cell>ASIS (vanilla.PN++)</cell><cell>150</cell><cell>35</cell><cell>115</cell><cell>45.7</cell></row><row><cell>ASIS (PN++)</cell><cell>179</cell><cell>54</cell><cell>125</cell><cell>47.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Comparisons of computation speed and performance. Inference time is estimated and averaged on Area 5, which is the time to process a point cloud with size 4096 × 9. The instance segmentation results on Area 5 are reported.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc>Semantic segmentation results on ShapeNet datasets. RePr is our reproduced PointNet. PointNet++* denotes the Point-Net++ trained by us without extra normal information.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We reproduced the results of SGPN using the code at github, published by the authors.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">3d semantic parsing of largescale indoor spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Armeni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Sener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Brilakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<title level="m">Rethinking atrous convolution for semantic image segmentation. arXiv: Comp. Res. Repository</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Mean shift: A robust approach toward feature space analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Comaniciu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Meer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Instance-sensitive fully convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Comp. Vis</title>
		<meeting>Eur. Conf. Comp. Vis</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Instance-aware semantic segmentation via multi-task network cascades</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>De Brabandere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Neven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<title level="m">Semantic instance segmentation with a discriminative loss function. arXiv: Comp. Res. Repository</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Exploring spatial context for 3d semantic segmentation of point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Francis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Theodora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bastian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 3DRMS Workshop of Int. Conf. Computer Vision</title>
		<meeting>3DRMS Workshop of Int. Conf. Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Rich feature hierarchies for accurate object detection and semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Snapnet-r: Consistent 3d multi-view semantic labeling for robotics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guerry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Boulch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">Le</forename><surname>Saux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Moras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Plyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Filliat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Workshop of Int. Conf. Computer Vision</title>
		<meeting>Workshop of Int. Conf. Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Mask r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comp. Vis</title>
		<meeting>IEEE Int. Conf. Comp. Vis</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Point cloud labeling using 3d convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>You</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Patt. Recogn</title>
		<meeting>Int. Conf. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Point cloud labeling using 3d convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>You</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. Patt. Recogn</title>
		<meeting>Int. Conf. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Recurrent slice networks for 3d segmentation of point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Neumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt</title>
		<meeting>IEEE Conf. Comp. Vis. Patt</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<title level="m">Panoptic segmentation. arXiv: Comp. Res. Repository</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Advances in Neural Inf. Process. Syst</title>
		<meeting>Advances in Neural Inf. ess. Syst</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Large-scale point cloud semantic segmentation with superpoint graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Landrieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Simonovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pointcnn. arXiv: Comp. Res. Repository</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Refinenet: Multipath refinement networks for high-resolution semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">D</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Exploring context with deep structured models for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Den Hengel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Sequential grouping networks for instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comp. Vis</title>
		<meeting>IEEE Int. Conf. Comp. Vis</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V D</forename><surname>Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Voxnet: A 3d convolutional neural network for real-time object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maturana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Scherer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ieee/Rsj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Int</surname></persName>
		</author>
		<title level="m">Conf. Intelligent Robots &amp; Systems</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Associative embedding: End-to-end learning for joint detection and grouping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Advances in Neural Inf. Process. Syst. 2017</title>
		<meeting>Advances in Neural Inf. ess. Syst. 2017</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning to segment object candidates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">O</forename><surname>Pinheiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Advances in Neural Inf. Process. Syst</title>
		<meeting>Advances in Neural Inf. ess. Syst</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Pointnet: Deep learning on point sets for 3d classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Volumetric and multi-view cnns for object classification on 3d data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nießner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Pointnet++: Deep hierarchical feature learning on point sets in a metric space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Advances in Neural Inf. Process. Syst</title>
		<meeting>Advances in Neural Inf. ess. Syst</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">End-to-end instance segmentation with recurrent attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Octnet: Learning deep 3d representations at high resolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">O</forename><surname>Ulusoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">DeepPano: Deep panoramic representation for 3-d shape recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Letters</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<title level="m">Very deep convolutional networks for large-scale image recognition. arXiv: Comp. Res. Repository</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Multiview convolutional neural networks for 3d shape recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kalogerakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Learned-Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Comp. Vis</title>
		<meeting>IEEE Int. Conf. Comp. Vis</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Segcloud: Semantic segmentation of 3d point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tchapmi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Armeni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Conf. 3D Vision</title>
		<meeting>Int. Conf. 3D Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">SGPN: Similarity group proposal network for 3d point cloud instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Neumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Dynamic graph cnn for learning on point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Sarma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Solomon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">arXiv: Comp. Res. Repository</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">3d shapenets: A deep representation for volumetric shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">3d recurrent neural networks with context fusion for point cloud semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Comp. Vis</title>
		<meeting>Eur. Conf. Comp. Vis</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A scalable active framework for region annotation in 3d shape collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ceylan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I.-C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sheffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Asia</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Indoor scene parsing with instance segmentation, semantic labeling and support relationship inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comp. Vis. Patt. Recogn</title>
		<meeting>IEEE Conf. Comp. Vis. Patt. Recogn</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
