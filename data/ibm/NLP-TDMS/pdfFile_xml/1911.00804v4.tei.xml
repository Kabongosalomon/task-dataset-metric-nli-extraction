<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">GENERALIZING TO UNSEEN DOMAINS VIA DISTRIBUTION MATCHING</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabela</forename><surname>Albuquerque</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">INRS-EMT</orgName>
								<orgName type="institution" key="instit2">Université du Québec</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">João</forename><surname>Monteiro</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">INRS-EMT</orgName>
								<orgName type="institution" key="instit2">Université du Québec</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Darvishi</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Fauber Lab</orgName>
								<orgName type="institution" key="instit1">Université de Montréal 3 Mila &amp; DIRO</orgName>
								<orgName type="institution" key="instit2">Université de Montréal</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiago</forename><forename type="middle">H</forename><surname>Falk</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">INRS-EMT</orgName>
								<orgName type="institution" key="instit2">Université du Québec</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Mitliagkas</surname></persName>
						</author>
						<title level="a" type="main">GENERALIZING TO UNSEEN DOMAINS VIA DISTRIBUTION MATCHING</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T11:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Supervised learning results typically rely on assumptions of i.i.d. data. Unfortunately, those assumptions are commonly violated in practice. In this work, we tackle this problem by focusing on domain generalization: a formalization where the data generating process at test time may yield samples from never-before-seen domains (distributions). Our work relies on a simple lemma: by minimizing a notion of discrepancy between all pairs from a set of given domains, we also minimize the discrepancy between any pairs of mixtures of domains. Using this result, we derive a generalization bound for our setting. We then show that low risk over unseen domains can be achieved by representing the data in a space where (i) the training distributions are indistinguishable, and (ii) relevant information for the task at hand is preserved. Minimizing the terms in our bound yields an adversarial formulation which estimates and minimizes pairwise discrepancies. We validate our proposed strategy on standard domain generalization benchmarks, outperforming a number of recently introduced methods. Notably, we tackle a real-world application where the underlying data corresponds to multi-channel electroencephalography time series from different subjects, each considered as a distinct domain.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The main assumption within the empirical risk minimization framework is that all examples used for training and testing predictors are independently drawn from a fixed distribution, i.e. the i.i.d. assumption. A number of generalization guarantees were derived upon that assumption and those results induced several algorithms for the solution of supervised learning problems. However, important limitations in this setting can be highlighted: (i) the i.i.d. property is unverifiable <ref type="bibr" target="#b0">[1]</ref> given that one doesn't have access to the data distribution, and (ii) it doesn't account for distribution shifts, and those often occur in practice. Representative examples of such distribution shifts include changes in data acquisition conditions such as illumination in images for object segmentation, or new data sources such as unseen speakers when performing speech recognition.</p><p>A number of alternative settings was then introduced in order to better cope with more realistic cases. Risk minimization under the domain adaptation setting, for instance, relaxes part of the i.i.d. assumption by allowing a source distribution (or domain) 2 as well as a different target distribution observed at test time. Generalization results for this setting introduced in <ref type="bibr" target="#b1">[2]</ref> thus showed the generalization gap in terms of risk difference across the two considered distributions for a fixed predictor is upper bounded by a notion of distance measured between the training and testing domains. While less restrictive than the previous setting, the domain adaptation case is still limited in that only that pair of distributions is expected to yield low risk, and shifts beyond those domains will likely induce poor performance. Moreover, algorithms devised for this setting rely on access at training time to an unlabeled sample from the target distribution so that representations can be learned inducing invariance across train and target domains <ref type="bibr" target="#b2">[3]</ref>, which is further limiting considering practical cases, e.g. a speech recognition service cannot be trained on data obtained from every new speaker it observes.</p><p>A more general setting is often referred to as domain generalization <ref type="bibr" target="#b3">[4]</ref>. In that case, it is assumed a set of distributions over the data is available at training time. At test time, however, both those observed distributions as well as unseen novel domains might appear, and a low risk is expected regardless of the underlying domain. More importantly, unlike domain adaptation settings in which the goal is to find a representation that aligns training data distributions with a specific target domain, domain generalization strategies aim at finding a representation space that yields good performance on novel distributions, unknown at training time. Recent work on domain generalization has included the use of data augmentation <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref> at training time, meta-learning to simulate domain shift <ref type="bibr" target="#b6">[7]</ref>, adding a self-supervised task to encourage an encoder to learn robust representations <ref type="bibr" target="#b7">[8]</ref>, learning domain-invariant representations <ref type="bibr" target="#b8">[9]</ref>, among other approaches.</p><p>In this contribution, we tackle the briefly described domain generalization setting. We first argue and prove that, given a set of distributions over data, if the distances measured between any pair of such distributions is small, so is the distance between mixtures obtained from the same set. That result yields a generalization guarantee to any distribution on the neighborhood of the "convex hull" 3 defined by the set of domains we started with. Inspired by that, we define an approach so that an encoder is enforced to map the data to a space where domain-dependent cues are filtered away while relevant information to the task of interest is conserved. While doing so, no data from test distributions is required, which is a major advantage compared to more traditional domain adaptation settings that target a specific distribution represented at training time through an unlabeled sample.</p><p>We summarize our contributions in the following:</p><p>• We introduce a set of assumptions on the data generating process tailored to the domain generalization setting which we argue are much more general than standard i.i.d requirements and more likely to hold in practice, i.e. given a data sample, it is more likely that our assumptions will hold compared to the more restrictive i.i.d. property; • We prove a generalization bound for the risk over unseen domains and show generalization can be expected for domains on the neighborhood of a notion of convex hull of distributions observed at training time; • Aiming to minimize the bound introduced, we devise an adversarial approach so that pairwise domain divergences are estimated and minimized. In order to do so, several practical improvements are performed on top of previously introduced approaches for domain adaption including the use of random projections prior to domains discriminators.</p><p>The remainder of this paper is organized as follows: In Section 2 we discuss past results which will be used in this work. In section 3 we define the domain generalization setting and present our main results as well as the resulting algorithm. Section 4 provides the experiments description and the respective results. Section 5 discusses related work while conclusions are drawn in Section 6 along with future directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>Let the data be represented by X ⊂ R D , while labels are given by Y, which would be {0, 1} in the binary case, for instance. Examples correspond to a pair (x, y) : x ∈ X , y ∈ Y, such that y = f (x), and f : X → Y is a deterministic labeling function.</p><p>A domain is defined as a tuple D, f where D corresponds to a probability distribution over X . Moreover, we define a mapping h : X → Y, such that h ∈ H, where H is a set of candidate hypothesis, and finally define the risk R associated with a given hypothesis h on domain D, f as:</p><formula xml:id="formula_0">R[h] = E x∼D [h(x), f (x)],<label>(1)</label></formula><p>where the loss : Y × Y → R + quantifies how different h(x) is from the true labeling function y = f (x) for a given data instance (x, y).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Generalization guarantees for domain adaptation</head><p>We now state results from the domain adaptation literature which are relevant for this work. The discussion in <ref type="bibr" target="#b9">[10]</ref> established the theoretical foundations for studying the cross-domain generalization properties for domain adaptation problems. Based on the covariate shift assumption, which considers that the labeling function is the same across domains (i.e. while D can change, f is fixed) they showed that, given a source domain D S and target domain D T , the risk of a given hypothesis h on the target is bounded by:</p><formula xml:id="formula_1">R T [h] ≤ R S [h] + d H [D S , D T ] + λ,<label>(2)</label></formula><p>where λ corresponds to the minimal total risk over both domains which can be achieved within a given hypothesis class H. The term d H [D S , D T ] corresponds to the H-divergence introduced in <ref type="bibr" target="#b10">[11]</ref> and defined is as follows:</p><formula xml:id="formula_2">d H [D S , D T ] = 2 sup η∈H |Pr x∼D S [η(x) = 1] − Pr x∼D T [η(x) = 1]|.<label>(3)</label></formula><p>As discussed in <ref type="bibr" target="#b1">[2]</ref>, an estimate of d H [D S , D T ] can be directly computed from the error of a binary classifier trained to distinguish domains.</p><p>In <ref type="bibr" target="#b11">[12]</ref>, an extension of the bound above was presented for the case where multiple source domains are available at training time. Given N S source domains D i S , i ∈ [N S ], and a mixture of the source domains</p><formula xml:id="formula_3">N S i=1 α i D i S (·), the risk R T [h] on the target domain is bounded by: R T [h] ≤ N S i=1 α i R i S [h] + 1 2 d H [D T , D i S ] + λ α ,<label>(4)</label></formula><p>where λ α is the minimum total risk, i.e. the sum of the risks measured on the target and the mixture of the sources, one can get within the considered hypothesis class, and the set α i of mixture coefficients is such that</p><formula xml:id="formula_4">α i ∈ [0, 1], i ∈ [N S ], N S i=1 α i = 1.</formula><p>3 Learning domain agnostic representations for domain generalization</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Formalizing domain generalization</head><p>We start by defining a set of assumptions we introduce over the data generating process considering the domain generalization case as well as the notion of risk we are concerned with. We then define D, referred to as meta-distribution, corresponding to a probability distribution over a countable set of possible domains. Under this view, a query for a data example consists of: (i) sampling a domain from the meta-distribution, and (ii) sampling a data point according to that particular domain. Such process is repeated m times so as to yield a training sample (x m ∼ D m , f (x m )). We remark the described model of data generating processes is sufficiently general so as to include the i.i.d. case (the meta-distribution yields a single domain) as well as the domain adaptation setting (if two domains are allowed), but further supports several other cases where multiple domains exist.  <ref type="figure" target="#fig_0">Figure 1</ref> illustrates the general model of data generating processes by representing the meta-distribution along with possible domains. We remark that, once a finite train sample is collected, a set of N S domains is observed. Each distribution D i S , i ∈ [N S ], in such set will be referred to as source domain. At test time however, drawing samples from D might yield data distributed according to new unseen domains. We then introduce extra notation and represent the set of possible domains unobserved while train data is acquired by D j U , j ∈ [N U ]. We proceed and define a risk minimization framework similar to that corresponding to the i.i.d. setting: find the predictor h * ∈ H that minimizes the meta-risk R D [h] defined as follows:</p><formula xml:id="formula_5">D D 1 S D N S S D 1 U D N U U ... ...</formula><formula xml:id="formula_6">h * = argmin h∈H R D [h], R D [h] = E D∼D [E x∼D [ (h(x), f (x))]].<label>(5)</label></formula><p>However, within the domain generalization setting, no information regarding possible test distributions is available at training time, which renders estimating R D [h] uninformative for a practical number of source domains. Moreover, we argue that no-free-lunch type of impossibility results may be used to conclude that it is impossible to generalize to any possible unknown distribution 4 , so that one must assume something about the test domains in order to enable generalization. In the following results, we tackle that issue and introduce generalization guarantees for a particular set of domains lying close to the set of mixtures of source distributions, i.e. those observed once train data is collected <ref type="bibr" target="#b12">[13]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Matching distributions in the convex hull</head><p>Let a set S of source domains such that |S| = N S be denoted by</p><formula xml:id="formula_7">D i S , i ∈ [N S ].</formula><p>The convex hull Λ S of S is defined as the set of mixture distributions given by:</p><formula xml:id="formula_8">Λ S = {D :D(·) = N S i=1 π i D i S (·), π i ∈ ∆ N S }.</formula><p>The following proposition shows that for any pair of domains such that D , D ∈ Λ 2 S , the H-divergence between D and D is upper-bounded by the largest H-divergence measured between elements of S.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proposition 1 (Bounding the H-divergence between domains in the convex hull</head><formula xml:id="formula_9">). Let d H [D i S , D k S ] ≤ , ∀ i, k ∈ [N S ].</formula><p>The following inequality holds for the H-divergence between any pair of domains D ,</p><formula xml:id="formula_10">D ∈ Λ 2 S : d H [D , D ] ≤ .<label>(6)</label></formula><p>Proof. C.f. supplementary material.</p><p>We thus argue that if one minimizes the maximum pairwise H-divergence between source domains, which can be achieved by an encoding process that filters away domain discriminative cues, the H-divergence between any two domains in Λ S also decreases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Generalizing to unseen domains</head><p>Now we turn our attention to the set of unseen distributions D j U , j ∈ [N U ], i.e. those in the support of the metadistribution but not observed within the training sample. We further introduceD j U , the element of Λ S which is closest to</p><formula xml:id="formula_11">D j U , i.e.D j U is given by argmin π1,...,π Ns d H D j U , N S i=1 π i,j D i S . Based on Proposition 1, we derive a generalization bound for the risk R j U [h] in terms of and d H [D j U , D j U ]: Proposition 2 (Generalization to unseen domains). Let d H [D j U , D j U ] = γ.</formula><p>Given the previous setup and assumptions, the following inequality holds for the risk R j U [h], ∀h ∈ H for any domain D j U :</p><formula xml:id="formula_12">R j U [h] ≤ N S i=1 π i,j R i S [h] + γ + 2 + λ πj (7)</formula><p>where λ πj is the minimum sum of the risks achieved by some h ∈ H on D j U andD j U . Proof. C.f. supplementary material.</p><p>The result discussed on the above can be used to define algorithms relying solely on source data, unlike domain adaptation approaches. While the total source risk can be minimized as usual, can be minimized by encoding source data to a space where source domains are hard to distinguish.</p><p>We further highlight that such results also provide insights regarding the importance of acquiring diverse datasets in practice when targeting domain generalization. The more diverse a dataset is regarding the number of domains present at training time, more likely it is that an unseen distribution lies within the convex hull of the source domains. In this case, γ = 0 and the bound stated in Proposition 2 is tighter. Therefore, not only the amount of data is important to achieve better generalization on unseen domains, but also the diversity of the training data is crucial. Another practical aspect worth remarking is that, even though our domain generalization setting is more general than ERM, Proposition 2 suggests that source domain labels should also be available, since they are required to estimate , which is not the case for ERM. However, collecting domain labels is inherent to the data acquisition procedure for several tasks and commonly available as meta-data in cases such as, for example, speech recognition, where different speakers or channels can be viewed as different domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Practical contributions</head><p>Motivated by the previous results, we propose to estimate and minimize along with the risks over the train sample. We thus aim at learning an encoder E : X → Z, where Z ⊂ R d preserves information relevant for separating classes, while removing domain-specific cues in such a way that it is harder to distinguish examples from different domains in comparison to the original space X .</p><p>Efficiently estimating : Previous work on domain adaptation introduced strategies based on minimizing the empirical H-divergence between sources and a given target domain <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b11">12]</ref>. Instead, as per the discussion following Proposition 2, the domain generalization setting requires estimating pairwise H-divergences across all available sources, not considering target data of any sort. Naively extending previous methods to our case would require O(N 2 S ) estimators, which is unpractical given real-world cases where several source domains are available. We thus propose to use one-vs-all classifiers. In this case, there is one domain discriminator per source domain and the k-th discriminator estimates <ref type="bibr" target="#b4">5</ref> l</p><formula xml:id="formula_13">=k d H [D k S , D l S ]</formula><p>, and improves the method to a number of H-divergence estimators linear on N S . Training: The proposed approach contains three main modules: an encoder E with parameters φ, a task classifier C with parameters θ C , and a set of H-divergence estimators D k with parameters θ k , k ∈ [N S ]. Intuitively, E attempts to minimize a classification loss L C (·; θ C ) (standard cross-entropy in our case) and empirical H-divergences, which is achieved through the maximization of domain discrimination losses, denominated L k . Each domain discriminator, on the other hand, aims at minimizing L k . The procedure for estimating φ, θ T , and all θ k 's can be thus formulated as the following multiplayer minimax game:</p><formula xml:id="formula_14">min φ,θ C max θ1,...,θ N S L C (C(E(x; φ); θ C ), y C ) − N S k=1 L k (D k (E(x; φ); θ k ), y k ),<label>(8)</label></formula><p>where y C corresponds to the task label for the example x, and y k is equal to 1 in case x ∼ D k S , or 0 otherwise. Training is carried out with alternate updates. A pseudocode describing the training procedure is presented in Algorithm 1.</p><p>Algorithm 1 Generalizing to unseen Domains via Distribution Matching 1: Requires: classifier and encoder learning rate (β C ), domain discriminators learning rate (β D ), scaling (α), minibatch size (m).</p><formula xml:id="formula_15">2: Initialize φ, θ C , θ 1 , . . . , θ N S as φ 0 , θ 0 C , θ 0 1 , . . . , θ 0 N S . 3: for t = 1, . . . , number of iterations do 4: Sample one mini-batch from each source domain {(x i 1 , y i C , y i 1 , . . . , y i N S )} m i=1 5:</formula><p># Update domain discriminators <ref type="bibr">6:</ref> for k = 1, . . . , N S do 7:</p><formula xml:id="formula_16">θ t k ← θ t−1 k + β D N S ·m N S ·m i=1 ∇ θ k L k (D k (E(x i ; φ t−1 ); θ t−1 k ), y i k ) 8:</formula><p>end for 9:</p><p># Update task classifier 10:</p><formula xml:id="formula_17">θ t C ← θ t−1 C + β C N S ·m N S ·m i=1 ∇ θ C L C (C(E(x i ; φ t−1 ); θ t−1 C ), y i C ) 11: # Update encoder 12: φ t ← φ t−1 + β C N S ·m ( N S ·m i=1 α∇ φ L C (C(E(x i ; φ t−1 ); θ t−1 C ), y i C ) 13: −(1 − α)∇ θ k L k (D k (E(x i ; φ t−1 ); θ t k ), y i k )) 14: end for</formula><p>We empirically found it helpful to augment our domain generalization approach with strategies for stabilizing the training of generative adversarial networks with multiple discriminators <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15]</ref>. A random projection layer is then introduced in the input of each domain discriminator with the goal of making examples from different distributions harder to be distinguished, and the negative log hypervolume is used instead of the summation in the game represented in (8) <ref type="bibr" target="#b4">5</ref> . We refer to the proposed approach as G2DM (Generalizing to unseen Domains via Distribution Matching).</p><p>Differences to multi-source domain adaptation: We further remark the differences between G2DM and previous adversarial approaches which are often employed in domain adaptation. Essentially, G2DM compares examples only from source domains to learn domain-agnostic representations, i.e. there is no notion of target distribution. Other settings such as <ref type="bibr" target="#b11">[12]</ref> are more restricted in that a particular distribution is targeted and data from that distribution is required, besides the source data we use in our case. Moreover, those approaches do not aim at matching source distributions and only consider H-divergences computed between each source domain and the given target. In the case of G2DM on the other hand, the goal is to match source domain distributions to decrease , and thus only pairwise discrepancies between training domains are considered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>Our empirical evaluation aims to answer the following questions: (i) Can we do better than standard ERM under i.i.d. assumptions by using information of source domains only? (ii) where does G2DM's performance stand in comparison to previous work? (iii) is G2DM indeed enforcing distribution matching? (iv) what is the effect on the resulting performance of employing different stopping criteria? We start the investigation performing experiments on two domain generalization benchmarks (VLCS <ref type="bibr" target="#b15">[16]</ref> and PACS <ref type="bibr" target="#b16">[17]</ref>) which consist of object recognition tasks. We then evaluate G2DM on a real-world task that involves classifying electroencephalography (EEG) time series for affective state prediction. Additionally, in the supplementary material we provide results showing the impact of the random projection layer size and the number of source domains on final performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">VLCS and PACS benchmarks</head><p>The VLCS benchmark is composed of 5 overlapping classes of objects obtained from the VOC2007 <ref type="bibr" target="#b17">[18]</ref>, LabelMe <ref type="bibr" target="#b18">[19]</ref>, Caltech-101 <ref type="bibr" target="#b19">[20]</ref>, and SUN <ref type="bibr" target="#b20">[21]</ref> datasets. The object recognition benchmark referred to as PACS, in turn, consists of images distributed into 7 classes originated from four different datasets: Photo (P), Art painting (A), Cartoon (C), and Sketch (S). Details regarding each benchmark can be found in the supplementary material. We compare the performance of our proposed approach with a model trained with ERM over all source domains with no mechanisms to enforce domain generalization. Moreover, we consider the recently introduced invariant risk minimization (IRM) strategy <ref type="bibr" target="#b21">[22]</ref> and include results reported in the literature achieved by Epi-FCR <ref type="bibr" target="#b22">[23]</ref>, JiGen <ref type="bibr" target="#b7">[8]</ref> along with the ERM results they provided (referred to as ERM-JiGen), and MMD-AAE <ref type="bibr" target="#b23">[24]</ref>. Finally, the adaptation of DANN for domain generalization reported in <ref type="bibr" target="#b22">[23]</ref> was also considered. All such methods have an encoder implemented as the convolutional stack of AlexNet <ref type="bibr" target="#b24">[25]</ref> and the weights are initialized from the pre-trained model on ImageNet <ref type="bibr" target="#b25">[26]</ref>. Further implementation details necessary for reproducing the results reported herein can be found in the supplementary material.</p><p>In <ref type="table" target="#tab_0">Tables 1 and 2</ref>, we report the average best accuracy across three runs with different random seeds on the test partition of the unseen domain under a leave-one-domain-out validation scheme. Results show that G2DM outperforms ERM in terms of average performance across the unseen domains for both benchmarks, and supports the claim that leveraging source domain information as done by G2DM provides an improvement on generalization to unseen distributions in comparison to simply considering the i.i.d. requirement is satisfied. G2DM further presented better average performance when compared to our implementation of IRM, as well as results from other methods previously reported in the literature. We finally highlight that G2DM showed an improvement in performance in more challenging domains <ref type="bibr" target="#b16">[17]</ref> such as LabelMe and Sketch.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Estimating pairwise H-divergences</head><p>We investigate whether cross-domain H-divergences are being in fact reduced by G2DM. We use ERM as a baseline for comparison since it does not include any mechanism to enforce distribution matching. We estimate H-divergences by computing the proxy pairwise A-distance <ref type="bibr" target="#b1">[2]</ref> for each pair of domains on the PACS benchmark. Classifiers are trained on top of the representations Z obtained with ERM and G2DM. We show in Figures 2 the differences in estimated discrepancies between ERM and G2DM for each unseen domain. Each entry corresponds to a pair of domains indicated in the row and the column and positive values indicate that G2DM decreased the corresponding pairwise A-distance in comparison to ERM. Notice that the diagonals are left blank as we do not compute the domain classification accuracy between the same domains. We observe that apart from the case where Photo is the unseen domain, G2DM was able to better match most of the source domains, thus yielding a smaller which favours generalization. Interestingly, we also noticed that the estimated pairwise H-divergence between the unseen domain and sources also decreased in most of the cases even though G2DM did not have access to data from the unseen domain at training time to explicitly match those distributions. This effect is explained by the fact that the H-divergence satisfies the triangle inequality (c.f. Eq. 13 in the supplementary material), which can be used to show that an upper-bound for the discrepancy between the unseen domain and any source gets tighter once decreases.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Domain generalization in practical scenarios</head><p>Results of previous experiments correspond to an optimistic scenario where target data is available for at least selecting the best performing model. This is not the case in practice since varying target distributions might appear. In <ref type="table" target="#tab_2">Table 3</ref>, we compare results obtained further considering stopping criteria that only use information from the source domains, such as validation accuracy on the source domains and training task loss. For comparison, we also present the performance reported by <ref type="bibr" target="#b8">[9]</ref> for CIDDG, since a stopping criterion using solely data from source domains was employed in that case. We notice that, when using the task loss as stopping criterion, our strategy outperforms CIDDG for almost all domains while its performance severely degrades when Sketch is the unseen domain. As an alternative to AlexNet, we further evaluate the performance of the proposed approach using the convolutional stack of a ResNet-18 <ref type="bibr" target="#b26">[27]</ref>, since it has shown promising results in recent work <ref type="bibr" target="#b7">[8]</ref>. We compare our approach with JiGen 6 adopting the same previous stopping criteria for both methods. We further report in <ref type="table" target="#tab_2">Table 3</ref> the performance obtained by JiGen as reported in <ref type="bibr" target="#b7">[8]</ref> although it is unclear which stopping criteria were adopted for that case. We observe that replacing AlexNet by ResNet-18 yields a more stable average performance across stopping criteria. Based mostly on the results obtained with AlexNet, we remark that different criteria might be too optimistic/pessimistic, and as such, one practical recommendation we can draw from our results is that the best methodology to be adopted when studying domain generalization strategies is to report their performance across different stopping criteria.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Real-world case: Affective state prediction from multi-variate time-series</head><p>We proceed to evaluate the proposed approach beyond domain generalization benchmarks. The goal of the selected task is to perform affective state estimation based on EEG signals from multiple subjects. EEG is a modality known to present high variability across different individuals given the same stimuli due to factors such as anatomic and environment variations <ref type="bibr" target="#b27">[28]</ref>. Therefore, since it cannot be assumed data from different individuals are identically distributed, this scenario consists in a challenging test bed for domain generalization approaches. We use the SEED dataset <ref type="bibr" target="#b28">[29]</ref>, which is composed of 62-channel EEG signals from 15 participants. During the data collection, subjects are asked to rate video clips extracted from movies as positive, neutral, or negative. We follow <ref type="bibr" target="#b29">[30]</ref> and use the architecture described in <ref type="bibr" target="#b30">[31]</ref> for both G2DM and ERM. We consider each subject as a different domain and perform leave-one-subject-out evaluation. For each subject left out for testing, we use 10 out of remaining 14 domains for training and use the other 4 as validation data. Similarly to our previous experiments, for each test domain we perform 3 independent runs. We report in <ref type="table" target="#tab_3">Table 4</ref> the affective state prediction accuracy (%) averaged across all unseen subjects and runs. Under source data validation, the performance reported was computed on the epoch of highest accuracy on the source domains at the validation partition. The results under semi-privileged were obtained on the epoch of highest accuracy on the unseen subject. The comparison between G2DM and ERM shows that using G2DM to leverage domain information (which in this case comes with no additional effort at the data collection) yields an improvement in performance for both stopping criteria. We further report in <ref type="table" target="#tab_3">Table 4</ref> results obtained by domain adaptation strategies (DA). Such methods, reported in <ref type="table" target="#tab_3">Table 4</ref> under privileged baselines, are privileged in the sense that unlabeled data belonging to the target domain (unknown in our case) is used to adapt representations to yield subject-specific models.</p><p>When comparing the DA strategies with our domain generalization (DG) approach, we remark that DG strategies aim to obtain domain-agnostic models, as opposed to DA methods which target a specific distribution. As such, one would expect DA approaches to achieve better performance than DG. However, we observe G2DM's performance to be on par or even better than some of the considered DA strategies. We conjecture a larger number of source domains available at training time would decrease the gap between DG and DA even further; i.e. it would be more likely that unseen domains are exactly represented in the convex hull of the sources yielding low γ (c.f. Proposition 2).   <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b29">30]</ref> 50.28 DANN <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b29">30]</ref> 55.87 MDAN <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b29">30]</ref> 56.65 MDMN <ref type="bibr" target="#b29">[30]</ref> 60.59</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related work</head><p>In <ref type="bibr" target="#b7">[8]</ref>, authors proposed to enforce generalization to unseen domains by adding a regularization term that depends on a self-supervised task. Other work proposed to enforce domain generalization with adversarial approaches. This is the case of CIDDG <ref type="bibr" target="#b8">[9]</ref>, where class-specific domain classifiers are employed to induce the encoder to learn representations where the mismatch between the labels conditional distributions is minimized. Moreover, MMD-AAE <ref type="bibr" target="#b23">[24]</ref>, proposed an approach that relies on an adversarial autoencoder and a maximum mean discrepancy penalty to remove domain-specific information. Recent approaches also proposed to simulate domain-shifts at training time by splitting the source domains into meta-train and meta-test sets <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b33">34]</ref> or by proposing an episodic training approach as in Epi-FCR <ref type="bibr" target="#b22">[23]</ref>. Previous work also included strategies based on learning domain-invariant representations <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b21">22]</ref>, data augmentation <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b4">5]</ref>, and on decomposing the model's parameters into domain-agnostic and domain-specific components <ref type="bibr" target="#b16">[17]</ref>. Work on other settings with more restrictive assumptions than domain generalization are also related to our contribution. For example, recent work on multi-domain learning <ref type="bibr" target="#b34">[35]</ref>, a setting where multiple domains are available at training time and test data is drawn from the same distributions seen during training <ref type="bibr" target="#b35">[36]</ref>, also leveraged H-divergence minimization to derive an adversarial approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We tackled the domain generalization setting and showed generalization can be achieved in the neighborhood of the set of mixtures of distributions observed during training. Based on this result, we introduced G2DM, an efficient approach in yielding invariant representations across unseen distributions. Our method employs multiple one-vs-all domain discriminators such that pairwise divergences between source distributions are estimated and minimized at training time. We provide empirical evidence that making use of domain information enables a boost in performance compared to standard settings relying on i.i.d. requirements. Moreover, the introduced approach outperformed recent methods which also leverage domain labels. We further showed such approach to yield strong results on a realistic setting, with performance comparable to privileged systems tailored to test distributions. In future work, we intend to investigate if the introduced assumptions on the data generating process can yield PAC-like results for domain complexity in a meta-distribution-agnostic fashion, i.e. we intend to assess questions such as: how many source domains are needed to guarantee low meta-risk with high probability?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Material</head><p>A Proof of Proposition 1</p><p>Consider two unseen domains, D U and D U on the convex-hull Λ S of N S source domains with support Ω.</p><formula xml:id="formula_18">Consider also D U (·) = N S k=1 π k D k S (·) and D U (·) = N S l=1 π l D l S (·)</formula><p>The H-divergence between D U and D U can be written as:</p><formula xml:id="formula_19">d H [D U , D U ] =2 sup h∈H |Pr x∼D U [h(x) = 1] − Pr x∼D U [h(x) = 1]|, =2 sup h∈H |E x∼D U [I(h(x))] − E x∼D U [I(h(x))]|, =2 sup h∈H Ω D U (x)I(h(x))dx − Ω D U (x)I(h(x))dx , =2 sup h∈H Ω N S k=1 π k D k S (x)I(h(x))dx − Ω N S l=1 π l D l S (x)I(h(x))dx , =2 sup h∈H Ω N S l=1 N S k=1 π l π k D k S (x)I(h(x))dx − Ω N S l=1 N S k=1 π l π k D l S (x)I(h(x))dx , =2 sup h∈H N S l=1 N S k=1 π l π k Ω D k S (x)I(h(x))dx − Ω D l S (x)I(h(x))dx .<label>(9)</label></formula><p>Using the triangle inequality, we can write:</p><formula xml:id="formula_20">d H [D U , D U ] ≤ 2 sup h∈H N S l=1 N S k=1 π l π k Ω D k S (x)I(h(x))dx − Ω D l S (x)I(h(x))dx .<label>(10)</label></formula><p>Finally, using the sub-additivity of the sup:</p><formula xml:id="formula_21">d H [D U , D U ] ≤ N S l=1 N S k=1 π l π k 2 sup h∈H Ω D k S (x)I(h(x))dx − Ω D l S (x)I(h(x))dx , = N S l=1 N S k=1 π l π k d H [D k S , D l S ].<label>(11)</label></formula><formula xml:id="formula_22">Given d H [D k S , D l S ] ≤ ∀ k, l ∈ [N S ]: d H [D U , D U ] ≤ .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Proof of Proposition 2</head><p>Recall the result from <ref type="bibr" target="#b11">[12]</ref> for the multi-source domain adaptation setting (for the sake of clarity, stated here replacing the target domain by an unseen domain according to our notation):</p><formula xml:id="formula_23">R U [h] ≤ N S i=1 α i R i S [h] + 1 2 d H [D U , D i S ] + λ α .<label>(12)</label></formula><p>Using the triangle inequality for the H-divergence, we can bound the H-divergence between an unseen domain D j U and a source domain</p><formula xml:id="formula_24">D i S , d H [D j U , D i S ] by: d H [D j U , D i S ] ≤ d H [D j U ,D j U ] + d H [D j U , D i S ] ≤ γ + ,<label>(13)</label></formula><p>where γ is the H-divergence between D j U and the convex-hull of the sources, i.e.</p><formula xml:id="formula_25">γ = d H [D j U ,D j U ] such that D j U = argmin π1,...,π Ns d H D j U , N S i=1 π i,j D i S .</formula><p>We can now choose each α i 's to correspond to the π i,j 's and re-write Eq. 12 for an unseen domain D j U as</p><formula xml:id="formula_26">R j U [h] ≤ N S i=1 π i,j R i S [h] + 1 2 d H [D j U , D i S ] + λ πj .<label>(14)</label></formula><p>Using Eq. 13, we can upper-bound </p><formula xml:id="formula_27">N S i=1 π i,j d H [D U , D i S ] by γ + , which gives R j U [h] ≤ N S i=1 π i,j R i S [h] + γ + 2 + λ πj .<label>(15)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Illustration</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Extra experiments E.1 Impact of source domains diversity on unseen domain accuracy</head><p>In this experiment, we verify whether removing examples from one source domain impacts the performance on the target domain. We evaluate each target domain on models trained using all possible combinations of the remaining domains as sources. The ERM baseline is also included for reference. Results presented in <ref type="table" target="#tab_4">Table 5</ref> show that for all unseen domains, decreasing the number of source domains from 3 (see <ref type="table" target="#tab_0">Table 1</ref>) to 2 hurt the classification performance for almost all combinations of source domains. We notice that in some cases, excluding a particular source from the training severely decreases the target loss. As an example, for the Caltech-101, excluding from training examples from the VOC dataset decreased the accuracy in more than 10% for the proposed approach, as well as for ERM. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.2 Effect of random projection size</head><p>We further investigate the effectiveness on providing a more stable training of the random projection layer in the input of each discriminator. For that, we run experiments with 7 different projection sizes, as well as directly using the output of the feature extractor model. Besides the random projection size, we use the same hyperparameters values (the same used in the previous experiment) and initialization for all models. We report in <ref type="figure" target="#fig_4">Figure 4</ref> the best target accuracy achieved with all random projection sizes on the PACS benchmark considering the Sketch dataset as unseen domain. Overall, we observed that the random projection layer has indeed an impact on the generalization of the learned representation and that the best result was achieved with a size equal to 1000. Moreover, we notice that, in this case, having a smaller (500) random projection layer is less hurtful for the performance than using a larger one. We also found that removing the random projection layer did not allow the training to converge with this experimental setting. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Domain generalization benchmarks</head><p>The VLCS benchmark is composed by 4 datasets with 5 common classes, namely, bird, car, chair, dog, and person. The number of data points per dataset is detailed as follows. We split each dataset in 80%/20% train/test partitions.</p><p>• Pascal VOC2007: 3376;</p><p>• LabelMe: 2656;</p><p>• Caltech-101: 1415;</p><p>• SUN09: 3282.</p><p>The PACS benchmark is composed by 4 datasets with 7 common classes, namely, dog, elephant, giraffe, guitar, horse, house, and person. The number of data points per dataset is detailed as follows. We use the original train/validation partitions provided by the benchmark authors.</p><p>• Photos: 1670;</p><p>• Art painting: 2048;</p><p>• Cartoon: 2344;</p><p>• Sketch: 3929.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G Implementation details G.1 VLCS and PACS benchmarks</head><p>In order to obtain a consistent comparison with the aforementioned baseline models, we follow previous work and employ the weights of a pre-trained AlexNet <ref type="bibr" target="#b24">[25]</ref> and ResNet-18 <ref type="bibr" target="#b26">[27]</ref> as the initialization for the feature extractor model on the experiments. The last layer is discarded and the representation of size 4096 for AlexNet and 512 for ResNet-18 is used as input for the task classifier and the domain discriminators. The domain discriminator architecture with AlexNet, consists of a four-layer fully-connected neural network of size 4096 → random projection size → 1024 → 1 and five-layer fully connected network of size 512 → random projection size → 512 → 256 → 1 for ResNet-18. The random projection layer is implemented as a linear layer with weights normalized to have unitary L2-norm. The task classifier is a one-layer fully-connected network of size 4096 → number of classes in the case of AlexNet and 512 → number of classes in the case of ResNet. Following previous work on domain generalization <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b22">23]</ref>, we use models pre-trained on the ILSVRC dataset <ref type="bibr" target="#b36">[37]</ref> as initialization. For fair comparison, all models we implemented were given a budget of 200 epochs. We use label smoothing <ref type="bibr" target="#b37">[38]</ref> on the task classifier in order to prevent overfitting. Models were trained using SGD with Polyak's acceleration. One epoch corresponds to the length of the largest source domain training sample. The learning rate was "warmed-up" for a number of training iterations equal to nw. Hyperparameter tuning was performed through random search over a pre-defined grid so as to find the best values for the learning rate (lr), momentum, weight decay, label smoothing parameter ls, nw, random projection size 7 , learning rate reduction factor, and weighting (α). Each model was run with three different initializations (random seeds 1, 10, and 100 selected a priori) and the average best accuracy on the test partition of the target domain is reported. Details of the hyperparameters grid used in the search are provided in the Appendix. For our ERM we used the same hyperparameters as in <ref type="bibr" target="#b7">[8]</ref>, while for IRM we employed the same hyperparameter values reported in the authors implementation of the colored MNIST experiments.</p><p>The grids used on the hyperparameter search for each hyperparameter are presented in the following. A budget of 200 runs was considered and for each combination of hyperparameters each model was trained for 200 and 30 epochs in the case of AlexNet and ResNet-18, respectively. The best hyperparamters values for AlexNet on PACS and VLCS benchmarks are respectively denoted by * , † . For the ResNet-18 experiments on PACS we indicate the hyperparameters by + . Moreover, in the case of ResNet-18, we aggregated the discriminators losses by computing the corresponding hypervolume as in <ref type="bibr" target="#b14">[15]</ref>, with a nadir slack equal to 2.5. All experiments were run considering a minibatch size of 64 (training each iteration took into account 64 examples from each source domain) on single GPU hardware (either an NVIDIA V100 or NVIDIA GeForce GTX 1080Ti).</p><p>• Learning rate for the task classifier and feature extractor: {0.01 * ,+ , 0.001 † , 0.0005};</p><p>• Learning for the domain classifiers: {0.0005 * , 0.001, 0.005 †,+ }; <ref type="bibr" target="#b6">7</ref> The option of not having the random projection layer is included in the grid search.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Illustration of the meta-distribution D composed by the source and unseen domains.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Differences between estimated pairwise H-divergences under ERM and G2DM on PACS (captions denote unseen domains). Higher values indicate that G2DM better matched domains. Overall, G2DM is able to decrease pairwise discrepancies.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Proposed approach illustration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Accuracy obtained on the PACS benchmark using Sketch as target domain.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Classification accuracy (%) for models trained considering leave-one-domain-out validation on the VLCS benchmark.</figDesc><table><row><cell>Unseen domain (→)</cell><cell>V</cell><cell>L</cell><cell>C</cell><cell>S</cell><cell>Average</cell></row><row><cell>DANN [23]</cell><cell cols="4">66.40 64.00 92.60 63.60</cell><cell>71.70</cell></row><row><cell>MMD-AAE [24]</cell><cell cols="4">67.70 62.60 94.40 64.40</cell><cell>72.28</cell></row><row><cell>Epi-FCR [23]</cell><cell cols="4">67.10 64.30 94.10 65.90</cell><cell>72.90</cell></row><row><cell>JiGen [8]</cell><cell cols="4">70.62 60.90 96.93 64.30</cell><cell>73.19</cell></row><row><cell>ERM -JiGen [8]</cell><cell cols="4">71.96 59.18 96.93 62.57</cell><cell>72.66</cell></row><row><cell>IRM</cell><cell cols="4">72.16 62.36 98.35 67.82</cell><cell>75.17</cell></row><row><cell>ERM</cell><cell cols="4">73.44 60.44 97.88 67.92</cell><cell>74.92</cell></row><row><cell>G2DM</cell><cell cols="4">71.14 67.63 95.52 69.37</cell><cell>75.92</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table><row><cell cols="6">Classification accuracy (%) for models trained</cell></row><row><cell cols="6">considering leave-one-domain-out validation on the PACS</cell></row><row><cell>benchmark.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Unseen domain (→)</cell><cell>P</cell><cell>A</cell><cell>C</cell><cell>S</cell><cell>Average</cell></row><row><cell>DANN [23]</cell><cell cols="4">88.10 63.20 67.50 57.00</cell><cell>69.00</cell></row><row><cell>Epi-FCR [23]</cell><cell cols="4">86.10 64.70 72.30 65.00</cell><cell>72.00</cell></row><row><cell>JiGen [8]</cell><cell cols="4">89.00 67.63 71.71 65.18</cell><cell>73.38</cell></row><row><cell>ERM -JiGen [8]</cell><cell cols="4">89.98 66.68 69.41 60.02</cell><cell>71.52</cell></row><row><cell>IRM</cell><cell cols="4">89.97 64.84 71.16 63.63</cell><cell>72.39</cell></row><row><cell>ERM</cell><cell cols="4">90.02 64.86 70.18 61.40</cell><cell>71.61</cell></row><row><cell>G2DM</cell><cell cols="4">88.12 66.60 73.36 66.19</cell><cell>73.55</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Accuracy (%) on PACS with different stopping criteria.</figDesc><table><row><cell>Method</cell><cell>Criterion</cell><cell>P</cell><cell>A</cell><cell>C</cell><cell>S</cell><cell>Average</cell></row><row><cell></cell><cell></cell><cell cols="2">AlexNet</cell><cell></cell><cell></cell><cell></cell></row><row><cell>CIDDG [9]</cell><cell>From [9]</cell><cell cols="4">78.65 62.70 69.73 64.45</cell><cell>68.88</cell></row><row><cell></cell><cell cols="5">Source acc. 85.33 57.76 69.71 49.45</cell><cell>65.56</cell></row><row><cell>G2DM</cell><cell cols="5">Source loss 87.37 66.70 70.26 50.98</cell><cell>68.82</cell></row><row><cell></cell><cell cols="5">Unseen acc. 88.80 66.70 73.29 65.03</cell><cell>73.45</cell></row><row><cell></cell><cell></cell><cell cols="2">ResNet-18</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="5">Source acc. 95.83 78.52 73.31 69.14</cell><cell>79.20</cell></row><row><cell>JiGen [8]</cell><cell cols="5">Source loss 95.83 78.89 73.32 70.73 Unseen acc. 96.11 79.56 74.25 71.00</cell><cell>79.69 80.23</cell></row><row><cell></cell><cell>From [8]</cell><cell cols="4">96.03 79.42 75.25 71.35</cell><cell>80.51</cell></row><row><cell></cell><cell cols="5">Source acc. 93.70 79.22 76.34 75.14</cell><cell>81.10</cell></row><row><cell>G2DM</cell><cell cols="5">Source loss 93.75 77.78 75.54 77.58</cell><cell>81.16</cell></row><row><cell></cell><cell cols="5">Unseen acc. 94.63 81.44 79.35 79.52</cell><cell>83.34</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Average accuracy (%) on the SEED dataset across 15 subjects. Privileged baselines have access to unseen domain data.</figDesc><table><row><cell>Setting</cell><cell>Method</cell><cell>Average acc. (%)</cell></row><row><cell></cell><cell cols="2">Source data validation</cell></row><row><cell></cell><cell>ERM</cell><cell>51.98</cell></row><row><cell>DG</cell><cell>G2DM</cell><cell>55.77</cell></row><row><cell></cell><cell cols="2">Semi-privileged</cell></row><row><cell></cell><cell>ERM</cell><cell>56.82</cell></row><row><cell></cell><cell>G2DM</cell><cell>60.26</cell></row><row><cell></cell><cell cols="2">Privileged baselines</cell></row><row><cell></cell><cell>DAN</cell><cell></cell></row><row><cell>DA</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Impact of decreasing the number of source domains on VLCS. Rows represent the two source domains used.</figDesc><table><row><cell>Source</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">i.e. the set of all mixtures obtained from given distributions.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">For a fixed hypothesis, one can always define a distribution yielding high risk.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">See supplementary material for details.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">Results are generated using JiGen authors' source code (https://github.com/fmcarlucci/JigenDG).</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C One-vs-all H-divergence estimation</head><p>We illustrate the estimation of H-divergences using one-vs-all discriminators by considering an example in which 3 source domains are available. Consider samples of size M from N S = 3 source domains which are available at training time. The loss L 1 for the domain discriminator D 1 accounting for estimating</p><p>can be written as:</p><p>where represents a loss function (e.g. 0-1 loss) and each term accounts for the loss provided by examples from one domain. Splitting the first term in two parts and replacing the domain labels y 1 by their corresponding values, we obtain:</p><p>The first two terms from Eq.17 account for d H [D 1 , D 2 ] and the last two terms account for d H [D 1 , D 3 ].</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Tutorial on practical prediction theory for classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Langford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="273" to="306" />
			<date type="published" when="2005-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Analysis of representations for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="137" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Domain-adversarial training of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2096" to="2030" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Domain generalization via invariant feature representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Muandet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="10" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Generalizing across domains via cross-gradient training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Piratla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Jyothi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sarawagi</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=r1Dx7fbCW" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Generalizing to unseen domains via adversarial data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Volpi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Namkoong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Sener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Murino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5334" to="5344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning to generalize: Meta-learning for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Domain generalization by solving jigsaw puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Carlucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>D&amp;apos;innocente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tommasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2229" to="2238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep domain generalization via conditional invariant adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="624" to="639" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A theory of learning from different domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Vaughan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="151" to="175" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Detecting change in data streams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kifer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gehrke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirtieth international conference on Very large data bases</title>
		<meeting>the Thirtieth international conference on Very large data bases</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="180" to="191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Adversarial multiple source domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Moura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Costeira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Gordon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8559" to="8570" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Algorithms and theory for multiple-source adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mohri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8246" to="8256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Stabilizing gan training with multiple random projections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Neyshabur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bhojanapalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chakrabarti</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.07831</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multi-objective training of generative adversarial networks with multiple discriminators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Albuquerque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Monteiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Doan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Considine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Falk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Mitliagkas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="202" to="211" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Unbiased metric learning: On the utilization of multiple datasets and web images for softening bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">N</forename><surname>Rockmore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1657" to="1664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deeper, broader and artier domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5542" to="5550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The pascal visual object classes (voc) challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="303" to="338" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Labelme: a database and web-based tool for image annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">P</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="157" to="173" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Caltech-256 object category dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Griffin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Holub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Exploiting hierarchical context on a large database of object categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Willsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="129" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Invariant risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.02893</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Episodic training for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.00113</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Domain generalization with adversarial feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Kot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5400" to="5409" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Reducing bci calibration effort in rsvp tasks using online weighted adaptation regularization with source domain selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">J</forename><surname>Lawhern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Lance</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 International Conference on Affective Computing and Intelligent Interaction (ACII)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="567" to="573" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Investigating critical frequency bands and channels for eeg-based emotion recognition with deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-L</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Autonomous Mental Development</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="162" to="175" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Extracting relationships by multi-domain matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Carlson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="6798" to="6809" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Targeting eeg/lfp synchrony with neural nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dzirasa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Carin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Carlson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4620" to="4630" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Learning transferable features with deep adaptation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="97" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Metareg: Towards domain generalization using metaregularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="998" to="1008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Domain generalization via model-agnostic learning of semantic features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>De Castro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kamnitsas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6447" to="6458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Multi-domain adversarial learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Schoenauer-Sebag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Heinrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schoenauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sebag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Altschuler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.09239</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Multi-domain learning by confidence-weighted parameter combination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dredze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crammer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="123" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">ImageNet Large Scale Visual Recognition Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<title level="m">• Momentum: {0.5, 0.9 * , †,+ } • Label smoothing: {0</title>
		<imprint/>
	</monogr>
	<note>.0 + , 0.1, 0.2 * , † }</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Losses</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>α): {0.35, 0.8 * , †,+ }</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Random projection size: {1000 * , 3000, 3500 †</title>
		<imprint>
			<pubPlace>None + }</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">• Task classifier and feature extractor learning rate warm-up iterations: {1, 300 * , † , 500 + }</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Affective state prediction</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">We follow previous work and apply a simple pre-processing that consists of clipping artifacts with amplitude 5 times higher than the mean of the channel signal and windowing data with chunks of 60 seconds. Each window was normalized to have zero mean and unit variance. For the encoder network, we adopt an one layer parameterized convolutional filter with 2 filters (designed to extract synchrony coherence which interpretable features based on the previous neuroscience literature [31]). We train all models for 100 epochs using SGD with Polyak&apos;s acceleration. The learning rate was</title>
		<imprint>
			<biblScope unit="page">500</biblScope>
		</imprint>
	</monogr>
	<note>We use SyncNet [31] as the encoder for the experiments with the SEED dataset</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">The output of the encoder with size 602 is used as input for the task classifier and the domain discriminators. to have unitary L2-norm. The task classifier is a two-layer fully-connected network of size</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
				<title level="m">• Window size: 60 seconds • Number of filters: 2 • Filters length: 40 • Pooling size: 40 • Input drop out rate: 0.2 • Initial learning rate task classifier: 9.963e-04 • Initial learning rate discriminator: 9.963e-05 • Random projection size</title>
		<imprint>
			<biblScope unit="page">602</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Proxy A-distance estimation</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">We implement the domain discriminators using tree ensemble classifiers with 100 estimators. We thus report the average classification accuracy using 5-fold cross-validation independently run for each domain pair</title>
	</analytic>
	<monogr>
		<title level="j">Each domain is</title>
		<imprint>
			<biblScope unit="page">500</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
