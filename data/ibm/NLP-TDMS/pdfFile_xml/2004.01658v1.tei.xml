<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PointGroup: Dual-Set Point Grouping for 3D Instance Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Jiang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Chinese University of Hong</orgName>
								<address>
									<addrLine>Kong 2 SmartMore</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Chinese University of Hong</orgName>
								<address>
									<addrLine>Kong 2 SmartMore</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoshuai</forename><surname>Shi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Chinese University of Hong</orgName>
								<address>
									<addrLine>Kong 2 SmartMore</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Chinese University of Hong</orgName>
								<address>
									<addrLine>Kong 2 SmartMore</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Wing</forename><surname>Fu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Chinese University of Hong</orgName>
								<address>
									<addrLine>Kong 2 SmartMore</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Chinese University of Hong</orgName>
								<address>
									<addrLine>Kong 2 SmartMore</addrLine>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">PointGroup: Dual-Set Point Grouping for 3D Instance Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T12:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Instance segmentation is an important task for scene understanding. Compared to the fully-developed 2D, 3D instance segmentation for point clouds have much room to improve. In this paper, we present PointGroup, a new endto-end bottom-up architecture, specifically focused on better grouping the points by exploring the void space between objects. We design a two-branch network to extract point features and predict semantic labels and offsets, for shifting each point towards its respective instance centroid. A clustering component is followed to utilize both the original and offset-shifted point coordinate sets, taking advantage of their complementary strength. Further, we formulate the ScoreNet to evaluate the candidate instances, followed by the Non-Maximum Suppression (NMS) to remove duplicates. We conduct extensive experiments on two challenging datasets, ScanNet v2 and S3DIS, on which our method achieves the highest performance, 63.6% and 64.0%, compared to 54.9% and 54.4% achieved by former best solutions in terms of mAP with IoU threshold 0.5.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Instance segmentation is a fundamental and challenging task that requires to predict not only the semantic labels but also the instance IDs for every object in the scene. It has drawn much interest recently, given the potential applications for both outdoor and indoor environment regarding autonomous driving, robot navigation, to name a few.</p><p>Convolutional neural networks has boosted the performance of 2D instance segmentation <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b4">5]</ref>. However, given unordered and unstructured 3D point clouds, 2D methods cannot be directly extended to 3D points and make the latter remains very challenging <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b52">53]</ref>. In this paper, we address the challenging 3D point cloud instance segmentation task by exploring the void space between 3D objects, along with the semantic information, to better segment individual objects. * Equal Contribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input</head><p>Instance Prediction Specifically, we design a bottom-up end-to-end framework named PointGroup for 3D instance segmentation, with the key target of better grouping of points. Our pipeline is to first extract per-point semantic prediction and conduct efficient point grouping to harvest candidate object instances. We utilize a semantic segmentation backbone to extract descriptive features and predict a semantic label for each point. Parallel to the segmentation head, we adopt an offset branch to learn a relative offset to bring each point to its respective ground-truth instance centroid. By this means, we shift points of the same object instance towards the same centroid and gather them closer, thus enabling better grouping of points into objects and separation of nearby objects of the same class.</p><p>With the predicted semantic labels and offsets, we then adopt a simple and yet effective algorithm to group points into clusters. For each point, we take its coordinates as a reference, group it with nearby points of the same label, and expand the group progressively. Importantly, we consider two coordinate sets in two separate passes -the original point positions and those shifted by the predicted offsets. We call the process "Dual-Set Point Grouping." The two types of results complement each other for accomplishing better performance. Further, we design the ScoreNet to evaluate and pick candidate groups. Non-maximum suppression is finally adopted to remove duplicate predictions.</p><p>We conduct extensive experiments on the challenging ScanNet v2 <ref type="bibr" target="#b7">[8]</ref> and S3DIS <ref type="bibr" target="#b1">[2]</ref> datasets. PointGroup achieves the highest accuracy on both of them. For Scan-Net v2, our performance on the test set is 63.6% in terms of mAP <ref type="bibr" target="#b49">50</ref> , which is 8.7% higher than the former best solution <ref type="bibr" target="#b22">[23]</ref>. For S3DIS, we accomplish 64.0% mAP 50 , 69.6% mPrec 50 , and 69.2% mRec <ref type="bibr" target="#b49">50</ref> , outperforming all previous approaches by a large margin.</p><p>In summary, our contribution is threefold.</p><p>• We propose a bottom-up 3D instance segmentation framework, named PointGroup, to deal with the challenging 3D instance segmentation task.</p><p>• We propose a point clustering method based on dual coordinate sets, i.e., the original and shifted sets. Along with the new ScoreNet, object instances can be better segmented out.</p><p>• The proposed method achieves state-of-the-art results on various challenging datasets, demonstrating its effectiveness and generality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Deep Learning in 3D Scenes 2D image pixels are in regular grids, thus can be naturally processed by convolutional neural networks <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b17">18]</ref>. In contrast, 3D point clouds are unordered and scattered in 3D space, causing extra difficulty in point cloud scene understanding <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b40">41]</ref>. Several approaches handle data irregularity. The Multi-Layer Perception (MLP)-style networks, e.g., PointNet <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b36">37]</ref>, directly apply MLP together with max-pooling to grab local and global structures in 3D. The learned features are then used for point cloud classification and segmentation. Other approaches <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b20">21]</ref> enhance feature learning on local regions by dynamic context aggregation and attention modules.</p><p>Besides working directly on the irregular input, several approaches transform the unordered point set to an ordered one to apply the convolution operations. PointCNN <ref type="bibr" target="#b25">[26]</ref> learns the order transformation for points reweighting and permutation. Some other approaches <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b6">7]</ref> align and voxelize point cloud to produce regular 3D ordered tensors for 3D convolution. Multi-view strategies <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b44">45]</ref> are also widely explored, where 3D point clouds are projected into 2D views for view-domain processing.</p><p>2D Instance Segmentation Instance segmentation aims to find the foreground objects in a scene and mark each object instance with a unique label. Overall, there are two major lines. The first is detection-or top-down-based, which directly detects object instances. Early works <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15]</ref> use proposals from MCG <ref type="bibr" target="#b0">[1]</ref> for feature extraction. Methods of <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b15">16]</ref> adopt pooled features for faster processing. Mask R-CNN <ref type="bibr" target="#b16">[17]</ref> is widely known as an effective approach with the extra segmentation head in the detection framework, like Faster R-CNN <ref type="bibr" target="#b37">[38]</ref>. Further works <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b4">5]</ref> enhance the feature learning for instance segmentation.</p><p>The other line is segmentation-or bottom-up-based, where pixel-level semantic segmentation is performed followed by grouping of pixels to find object instances. Zhang et al. <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b54">55]</ref> utilize MRF for local patch merging. Arnab and Torr <ref type="bibr" target="#b2">[3]</ref> use CRF. Bai and Urtasun <ref type="bibr" target="#b3">[4]</ref> combine the classical watershed transform and deep learning to produce energy maps to distinguish among individual instances. Liu et al. <ref type="bibr" target="#b27">[28]</ref> employ a sequence of neural networks to construct objects from pixels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3D Instance Segmentation</head><p>With available large-scale 3D labeled datasets <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b1">2]</ref>, instance segmentation of 3D point clouds becomes important. Similar to 2D cases, current 3D methods can also be grouped into two lines.</p><p>Detection-based methods extract 3D bounding boxes, and inside each box, utilize a mask learning branch to predict the object mask. Yang et al. <ref type="bibr" target="#b52">[53]</ref> present the 3D-BoNet that directly predicts 3D bounding boxes and pointlevel masks simultaneously per instance. Li et al. <ref type="bibr" target="#b53">[54]</ref> propose GSPN, which takes an analysis-by-synthesis strategy to generate proposals for instance segmentation. Hou et al. <ref type="bibr" target="#b18">[19]</ref> combine multi-view RGB input with 3D geometry to jointly infer object bounding boxes and corresponding instance masks in an end-to-end manner.</p><p>Contrarily, segmentation-based methods predict the semantic labels, and utilize point embedding to group points into object instances. Wang et al. <ref type="bibr" target="#b48">[49]</ref> design SGPN by clustering points based on the semantic segmentation predicted by backbones such as PointNet++. Liu and Furukawa <ref type="bibr" target="#b26">[27]</ref> predict both the semantic labels and affinity between adjacent voxels in different scales to group instances. Phm et al. <ref type="bibr" target="#b32">[33]</ref> develop a multi-task learning framework with a multi-value CRF model to jointly reason over both the semantic and instance labels. Wang et al. <ref type="bibr" target="#b49">[50]</ref> learn a semantic-aware point-level instance embedding to benefit learning of both the semantic and instance tasks. Lahoud et al. <ref type="bibr" target="#b22">[23]</ref> introduce a multi-task learning strategy where points of the same instance are grouped closer and different clusters are more separated from each other. Different from the above methods, we present a new approach named PointGroup to tackle the 3D instance segmentation task. Our proposed model mainly contains two parts -that is, (i) learning to group points into different clusters based on their semantic predictions in both the original coordinate space and shifted coordinate space, and (ii) ScoreNet to learn to predict the score for selecting proper clusters. The overall framework is differentiable. It can be jointly optimized and trained in an end-to-end manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Our Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Architecture Overview</head><p>To obtain instance-level segmentation labels for 3D objects, we consider two problems. The first is to separate Then, we introduce a clustering method to group points into candidate clusters on dual coordinate sets, i.e., the original set P and the shifted Q, which produce C p and C q respectively. Lastly, we use ScoreNet to produce cluster scores S c . The set of color f = {f i } serves as the input feature to the backbone.</p><p>the contents in the 3D space into individual objects, and the second is to determine the semantic label of each object. Unlike 2D images, there is no view-occlusion problem in the 3D scenes, and objects scattered in 3D are usually naturally separated by void space. Hence, we propose leveraging these characteristics of 3D objects to group 3D content into object instances according to the semantic information. <ref type="figure" target="#fig_1">Fig. 2</ref> overviews the architecture of our approach, which has three main components, i.e., the backbone, the point clustering part, and ScoreNet. The input to the backbone network ( <ref type="figure" target="#fig_1">Fig. 2(a)</ref>) is a point set P of N points. Each point has a color f i = (r i , g i , b i ) and 3D coordinates</p><formula xml:id="formula_0">p i = (x i , y i , z i ), where i ∈ {1, ..., N }.</formula><p>The backbone extracts feature F i for each point. We denote the output feature of the backbone as F = {F i } ∈ R N ×K , where K is the number of channels. We then feed F into two branches, one for semantic segmentation and the other for predicting a per-point offset vector to shift each point towards the centroid of its respective object instance. Let s i and o i = (∆x i , ∆y i , ∆z i ) denote the predicted semantic label and offset vector of point i, respectively.</p><p>After obtaining the semantic labels, we begin to group points into instance clusters based on the void space between objects. In the point clustering part <ref type="figure" target="#fig_1">(Fig. 2(b)</ref>), we introduce a clustering method to group points that are close to each other into the same cluster, if they have the same semantic label. However, clustering directly based on the point coordinate set P = {p i } may fail to separate samecategory objects that are close to each other in the 3D space and mis-group them, for example, two pictures that hang side-by-side on the wall.</p><p>Thus, we use the learned offset o i to shift point i towards its respective instance centroid and obtain the shifted coordinates q i = p i + o i ∈ R 3 . For points belonging to the same object instance, different from p i , the shifted coordinates q i clutter around the same centroid. So by clustering based on shifted coordinate set Q = {q i }, we separate nearby objects better, even though they have the same semantic labels.</p><p>However, for points near object boundary, the predicted offsets may not be accurate. So, our clustering algorithm employs "dual" point coordinate sets, i.e., the original coordinates P and the shifted coordinates Q. We denote the clustering results C as the union of C p = {C p 1 , ..., C p Mp } and C q = {C q 1 , ..., C q Mq }, which are the clusters discovered based on P and Q, respectively. Here, M p and M q denote the number of clusters in C p and C q , respectively, and M = M p + M q denotes the total.</p><p>Lastly, we construct the ScoreNet <ref type="figure" target="#fig_1">(Fig. 2(c)</ref>) to process the proposed point clusters C = C p ∪ C q and produce a score per cluster proposal. NMS is then applied to these proposals with the scores to generate final instance prediction. In the following, we denote the instance predictions as G = {G 1 , ..., G M pred } ⊆ C and the ground-truth instances as I = {I 1 , ..., I Mgt }. Here, G i and I i are subsets of P, while M pred and M gt denote the number of instances in G and I, respectively. Also, we use N I i and N G i to represent the number of points in I i and G i , respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Backbone Network</head><p>We may use any point feature extraction network to serve as the backbone network ( <ref type="figure" target="#fig_1">Fig. 2(a)</ref>). In our implementation, we voxelize the points and follow the procedure of <ref type="bibr" target="#b12">[13]</ref> to construct a U-Net <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b39">40]</ref> with Submanifold Sparse Convolution (SSC) and Sparse Convolution (SC). We then recover points from voxels to obtain the point-wise features. The contextual and geometric information is well extracted by the U-Net, which provides discriminative point-wise features F for subsequent processing. Afterwards, we construct two branches based on the point-wise features F to predict semantic label s i and offset vector o i for each point.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Semantic Segmentation Branch</head><p>We apply an MLP to F to produce semantic scores SC = {sc 1 , ..., sc N } ∈ R N ×N class for the N points over the N class classes, and regularize the results by a cross entropy loss L sem . The predicted semantic label s i for point i is the class with the maximum score, i.e., s i = argmax(sc i ).</p><p>Offset Prediction Branch The offset branch encodes F to produce N offset vectors O = {o 1 , ..., o N } ∈ R N ×3 for the N points. For points belonging to the same instance, we constrain their learned offsets by an L 1 regression loss as</p><formula xml:id="formula_1">L o reg = 1 i m i i ||o i − (ĉ i − p i )|| · m i ,<label>(1)</label></formula><p>where m = {m 1 , ..., m N } is a binary mask. m i = 1 if point i is on an instance and m i = 0 otherwise.ĉ i is the centroid of the instance that point i belongs to, i.e.,</p><formula xml:id="formula_2">c i = 1 N I g(i) j∈I g(i) p j ,<label>(2)</label></formula><p>where g(i) maps point i to the index of its corresponding ground-truth instance, i.e., the instance that contains point i. N I g(i) is the number of points in instance I g(i) . The above mechanism looks similar to the vote generation strategy in VoteNet <ref type="bibr" target="#b33">[34]</ref>. However, rather than regressing the bounding boxes based on the votes of a few subsampled seed points, we predict an offset vector per point to gather the instance points around a common instance centroid, in order to better cluster relevant points into the same instance. Also, we observe that the distances from points to their instance centroids usually have small values (0 to 1m). <ref type="figure" target="#fig_5">Fig. 3b</ref> gives the statistical analysis on the distribution of such distances in the ScanNet dataset. Considering diverse object sizes of different categories, we find it is hard for the network to regress precise offsets, particularly for boundary points of large-size objects, since these points are relatively far from the instance centroids. To address this issue, we formulate a direction loss to constrain the direction of predicted offset vectors. We follow <ref type="bibr" target="#b22">[23]</ref> to define the loss as a means of minus cosine similarities, i.e.,</p><formula xml:id="formula_3">L o dir = − 1 i m i i o i ||o i || 2 ·ĉ i − p i ||ĉ i − p i || 2 · m i .<label>(3)</label></formula><p>Such loss is irrelevant to the offset vector norm and ensures that the points move towards their instance centroids.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Clustering Algorithm</head><p>Given the predicted semantic labels and offset vectors, we are ready to group the input points into instances. To this end, we introduce a simple and yet effective clustering algorithm. It is detailed in Algorithm 1. if s i is a stuff class (e.g., wall) then if v i == 0 then <ref type="bibr">8:</ref> initialize an empty queue Q 9:</p><p>initialize an empty cluster C if number of points in C &gt;N θ then <ref type="bibr">17:</ref> add C to C 18: return C The core step of our algorithm is that for point i, we get points within the ball of radius r centered at x i (the coordinate of point i) and group points with the same semantic labels as point i into the same cluster. Here, r serves as a spatial constraint in the clustering, so that two intra-category objects at a distance larger than r are not grouped. Here, we use the breadth-first search to group points of the same instance into a cluster. In our implementation, for points in the scene, neighboring points within an r-sphere can be found in parallel in advance of the clustering to boost speed.</p><p>As presented in Sec. 3.1, we apply the clustering algorithm separately on the "dual" set, i.e., the original coordinate set P and the shifted set Q, to produce cluster sets C p and C q . Clustering on P may mis-group nearby objects of the same class, while clustering on Q does not have this problem but may fail to handle the boundary points of large objects. We collectively employ P and Q to find candidate clusters due to their complementary properties. Analysis on the clustering performance of using P alone, Q alone, or both P and Q is presented in Sec. 4.2.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">ScoreNet</head><p>The input to ScoreNet is the set of candidate clusters C = {C 1 , ..., C M }, where M denotes the total number of candidate clusters, and C i denotes the i-th cluster. Also, we use N i to represent the number of points in C i . The goal of ScoreNet is to predict a score for each cluster to indicate the quality of the associated cluster proposal, so that we could precisely reserve the better clusters in NMS and thus combine strength of C p and C q . To start, for each cluster, we gather the point features from F ∈ R N ×K (the features extracted by the backbone) and form F Ci = {F h(Ci,1) , ..., F h(Ci,Ni) } for cluster C i , where h maps the point index in C i to corresponding point index in P. Similarly, we express the coordinates for points in C i as P Ci = {p h(Ci,1) , ..., p h(Ci,Ni) }.</p><p>To better aggregate the cluster information, we take F Ci and P Ci as the initial features and coordinates, and voxelize the clusters the same way as we do at the beginning of the backbone network. The feature for each voxel is average-pooled from the initial features of points in that voxel. We then feed them into a small U-Net with SSC and SC to further encode the features. A cluster-aware maxpooling is then followed to produce a single cluster feature vector f Ci ∈ R 1×Kc per cluster. The final cluster scores S c = {s c 1 , ..., s c M } ∈ R M are obtained as</p><formula xml:id="formula_4">S c = Sigmoid(MLP(F C )),<label>(4)</label></formula><p>where F C = {f C1 , ..., f C M } ∈ R M ×Kc . The structure of ScoreNet is illustrated in <ref type="figure" target="#fig_5">Fig. 3a</ref>.</p><p>Inspired by <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b19">20]</ref>, to reflect the quality of clusters in the scores, we use a soft label to replace a binary 0/1 label to supervise the predicted cluster score aŝ</p><formula xml:id="formula_5">s c i =      0 iou i &lt; θ l 1 iou i &gt; θ h 1 θ h −θ l · (iou i − θ l ) otherwise ,<label>(5)</label></formula><p>where θ l and θ h are empirically set to 0.25 and 0.75 respectively in our implementation, and iou i is the largest Intersection over Union (IoU) between cluster C i and groundtruth instances as</p><formula xml:id="formula_6">iou i = max ({IoU(C i , I j ) | I j ∈ I}) .<label>(6)</label></formula><p>We then use the binary cross-entropy loss as our score loss, which is formulated as</p><formula xml:id="formula_7">L c score = − 1 M M i=1 (ŝ c i log(s c i )+(1−ŝ c i )log(1−s c i )). (7)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Network Training and Inference</head><p>Training We train the whole framework in an end-to-end manner with the total loss as</p><formula xml:id="formula_8">L = L sem + L o dir + L o reg + L c score .<label>(8)</label></formula><p>Inference In the inference process, we perform NMS on clusters C with predicted scores S c to obtain the final instance predictions G ⊆ C. The IoU threshold is empirically set as 0.3. Since we cluster based on the semantic information, the semantic label of a cluster is exactly the category that the cluster points belong to.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>Our proposed PointGroup architecture is effective for instance segmentation of 3D point clouds. To demonstrate its effectiveness, we conduct extensive experiments on two challenging point cloud datasets, ScanNet v2 <ref type="bibr" target="#b7">[8]</ref> and S3DIS <ref type="bibr" target="#b1">[2]</ref>. On both of them, we achieve state-of-the-art performance on the 3D instance segmentation task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental Setting</head><p>Datasets The ScanNet v2 <ref type="bibr" target="#b7">[8]</ref> dataset contains 1,613 scans with 3D object instance annotations. The dataset is split into training, validation, and testing sets, each with 1,201, 312, and 100 scans, respectively. 18 object categories are used for instance segmentation evaluation. For ablation studies, we train on the training set and report results on the validation set. To compare with other approaches, we train on the training set and report results on the testing set.</p><p>The S3DIS <ref type="bibr" target="#b1">[2]</ref> dataset has 3D scans across six areas with 271 scenes in total. Each point is assigned one label out of 13 semantic classes. All the 13 classes are used in instance  <ref type="bibr" target="#b18">[19]</ref> 0  evaluation. Overall, we evaluate our model under two settings: (i) Area 5 is adopted for testing, whereas all the others are used for training; and (ii) six-fold cross validation that each area is treated as the testing set once.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation Metrics</head><p>We use the widely-adopted evaluation metric -mean average precision (mAP). Specifically, AP <ref type="bibr" target="#b24">25</ref> and AP 50 denote the AP scores with IoU threshold set to 25% and 50%, respectively. Also, AP averages the scores with IoU threshold set from 50% to 95%, with a step size of 5%. Besides, approaches of <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b52">53]</ref> reported performance of mean precision (mPrec) and mean recall (mRec) on S3DIS, we also include these results for comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implementation Details</head><p>We set the voxel size as 0.02m. In the clustering part, we set the clustering radius r as 0.03m and the minimum cluster point number N θ as 50. In the training process, we use the Adam solver with a base learning rate of 0.001. For each scene in the dataset, we set the maximum number of points as 250k, due to GPU memory limit. If the scene has more than 250k points, we randomly crop part of the scene and gradually adjust the crop size, according to the number of points in the cropped area. During the testing process, we feed the whole scene into the network without cropping. Specifically, scenes in S3DIS have high point density. Some scenes are even with millions of points. Hence, for each S3DIS scene, we randomly sub-sample ∼1/4 points before each cropping.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Evaluation on ScanNet</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Benchmark Results</head><p>We first report performance of our PointGroup model on the testing set of ScanNet v2, as listed in <ref type="table" target="#tab_1">Table 1</ref>. PointGroup accomplishes the highest AP 50 score of 63.6%, outperforming all previous methods by a large margin. Compared with the former best solution <ref type="bibr" target="#b22">[23]</ref>, which obtains 54.9% AP 50 score, our result is 8.7% higher (absolute) and 15.8% better (relative). For detailed results on each category, PointGroup ranks the 1st place in 13 out of 18 classes in total.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Ablation Studies</head><p>We conduct ablation studies on the ScanNet validation set to analyze the design and parameter choice in our PointGroup. <ref type="table" target="#tab_3">Table 2</ref> shows the comparison using the original coordinates P alone, the shifted coordinates Q alone, and both P and Q in the clustering. Clustering on points with P alone may mis-group two close objects with the same semantic label into the same instance. Hence, for categories, in which two objects are likely to be very close to each other (e.g., chairs and pictures), clustering on P alone does not perform well. Clustering on Q solves the problem in part by gathering instance points around the instance centroids and enlarging the space between clusters. However, due to inaccuracy in offset prediction, especially for boundary points of large objects (e.g., curtains and counters), clustering on Q alone does not perform perfectly. <ref type="figure">Fig. 4</ref> shows the qualitative results with models trained with clusters from different coordinate sets -(i) P only, (ii) Q only, and (iii) both P and Q. We could observe that the problem in (i) is the mistakenly grouped pictures on the wall in one cluster. The case of (ii) successfully separates the pictures into individual instances. Nevertheless, it suffers from inaccuracy around the object boundary areas. The case of (iii) takes strength of both (i) and (ii). Clustering on dual point sets (both P and Q) along with the precise scores from ScoreNet to select the final instance clusters, we combine the advantages of clustering on P and on Q to attain the best performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Clustering based on Different Coordinate Sets</head><p>Ablation on the Clustering Radius r We use different values of r in the clustering algorithm. The performance varies as shown in <ref type="table">Table 3</ref>. A small r is sensitive to point density. The scan for an object may have inconsistent point density in different parts. Clustering with such an r may not be able to grow in low-density parts. On the contrary, a large r increases the risk of grouping two nearby same-class objects into one. We empirically set r to 0.03 (meter).    <ref type="table">Table 3</ref>: Ablation results for clustering with different radii r on the ScanNet v2 validation set.</p><p>Ablation for the ScoreNet We also ablate the ScoreNet, which is used to evaluate the quality of each candidate cluster (see Sec.3.4). Here, we directly use the output scores from ScoreNet to rank instances for calculating the AP. Apart from regressing the instance quality, an alternative way is to directly use the averaged semantic probability of the related instance category inside an instance as the quality confidence. By this means, the results in terms of AP/AP 50 /AP 25 are 30.2/51.9/68.9(%), which are worse than those with ScoreNet where results are 34.8/56.9/71.3(%). This indicates that the proposed ScoreNet is vital and necessary for improving the instance segmentation results by providing precise scores for NMS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Runtime Analysis</head><p>Our method takes a whole scene as input per pass. Its runtime depends on the number of points and scene complexity. For runtime analysis, we sampled four scenes randomly from the ScanNet v2 validation set and tested them 100 times on a Titan Xp GPU to get an average runtime per scene.   on Q (shifted) usually takes more time than clustering on P (original), as shifted points could have more neighbors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Evaluation on S3DIS</head><p>We also evaluate our proposed PointGroup model on the S3DIS dataset. Apart from adopting AP 50 as an evaluation Input Semantic GT Semantic Pred. Instance GT Instance Pred. metric, we also include the mPrec 50 and mRec 50 results in <ref type="table" target="#tab_6">Table 5</ref>, where we use a score threshold of 0.2 to remove some low-confidence clusters. PointGroup reaches the highest performance in terms of all three evaluation metrics. For results on Area 5, Point-Group gets 57.8% on AP 50 , 61.9% on mPrec 50 and 62.1% on mRec 50 . The mPrec 50 and mRec 50 are 6.6 and 19.7 points higher than ASIS <ref type="bibr" target="#b49">[50]</ref>, respectively. For the results on 6-fold cross validation, PointGroup is 9.6 points higher than SGPN <ref type="bibr" target="#b48">[49]</ref> regarding AP 50 , which is a big margin. The mPrec 50 and mRec 50 scores are 4 and 21.6 points higher than the second-best solution <ref type="bibr" target="#b52">[53]</ref>.</p><p>The large improvement of PointGroup over the former best approaches across different challenging datasets demonstrate its effectiveness and generality. Several visual illustrations of PointGroup over these two datasets are included in <ref type="figure" target="#fig_8">Fig. 5</ref>. We observe that the proposed approach well captures the 3D geometry information and obtains precise instance segmentation masks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We have proposed PointGroup for 3D instance segmentation, with a specific focus of better grouping points by exploring the in-between space and point semantic labels among the object instances. Considering the situation that two intra-category objects may be very close to each other, we design a two-branch network to respectively learn a perpoint semantic label and a per-point offset vector for moving each point towards its respective instance centroid. We then cluster points based on both the original point coordinates and the offset-shifted point coordinates. It combines the complementary strength of the two coordinate sets to optimize point grouping precision. Further, we introduced the ScoreNet to learn to evaluate the generated candidate clusters, followed by the NMS to avoid duplicates before we output the final predicted instances. PointGroup accomplished the best ever results.</p><p>In our future work, we plan to further introduce a progressive refinement module to relieve the semantic inaccuracy problem that affects the instance grouping and explore the possibility of incorporating weakly-or self-supervision techniques to further boost the performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Example of 3D instance segmentation by our method from ScanNet v2. Instances are in different colors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Illustration of the network architecture. It has three main components -(a) backbone network, (b) clustering part, and (c) ScoreNet. First, we use the backbone network to extract per-point features F, followed by two branches to produce offset vectors O = {o i } and semantic labels S = {s i }.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Algorithm 1</head><label>1</label><figDesc>Clustering algorithm. N is the number of points. M is the number of clusters found by the algorithm. Input: clustering radius r; cluster point number threshold N θ ; coordinates X = {x 1 , x 2 , ..., x N } ∈ R N ×3 ; and semantic labels S = {s 1 , ..., s N } ∈ R N . Output: clusters C = {C 1 , ..., C M }. 1: initialize an array v (visited) of length N with all zeros 2: initialize an empty cluster set C 3: for i = 1 to N do 4:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>6 :</head><label>6</label><figDesc>for i = 1 to N do 7:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>10 :</head><label>10</label><figDesc>v i = 1; Q.enqueue(i); add i to C 11: while Q is not empty do 12: k = Q.dequeue() 13: for j ∈ [1, N ] with ||x j − x k || 2 &lt; r do 14:if s j == s k and v j == 0 then 15: v j = 1; Q.enqueue(j); add j to C 16:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :</head><label>3</label><figDesc>(a) Structure of ScoreNet. (b) Distribution of distances from points to their respective instance centroids in the ScanNet dataset [8] (including the training and validation sets).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>.382 1 .</head><label>1</label><figDesc>000 0.432 0.245 0.190 0.577 0.013 0.263 0.033 0.320 0.240 0.075 0.422 0.857 0.117 0.699 0.271 0.883 0.235 MASC [27] 0.447 0.528 0.555 0.381 0.382 0.633 0.002 0.509 0.260 0.361 0.432 0.327 0.451 0.571 0.367 0.639 0.386 0.980 0.276 PanopticFusion [32] 0.478 0.667 0.712 0.595 0.259 0.550 0.000 0.613 0.175 0.250 0.434 0.437 0.411 0.857 0.485 0.591 0.267 0.944 0.35 3D-BoNet [53] 0.488 1.000 0.672 0.590 0.301 0.484 0.098 0.620 0.306 0.341 0.259 0.125 0.434 0.796 0.402 0.499 0.513 0.909 0.439 MTML [23] 0.549 1.000 0.807 0.588 0.327 0.647 0.004 0.815 0.180 0.418 0.364 0.182 0.445 1.000 0.442 0.688 0.571 1.000 0.396 PointGroup (Ours) 0.636 1.000 0.765 0.624 0.505 0.797 0.116 0.696 0.384 0.441 0.559 0.476 0.596 1.000 0.666 0.756 0.556 0.997 0.513</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>AP 0 .</head><label>0</label><figDesc>283 0.414 0.327 0.244 0.167 0.493 0.083 0.269 0.089 0.193 0.286 0.205 0.207 0.373 0.226 0.361 0.251 0.684 0.231 AP50 0.507 0.692 0.647 0.481 0.347 0.685 0.231 0.508 0.308 0.384 0.453 0.359 0.301 0.632 0.537 0.660 0.531 0.961 0.413 AP25 0.659 0.840 0.764 0.597 0.496 0.791 0.588 0.614 0.686 0.529 0.600 0.432 0.401 0.660 0.775 0.777 0.721 0.995 0.601 Shifted Q AP 0.328 0.499 0.383 0.248 0.217 0.713 0.008 0.241 0.165 0.216 0.318 0.211 0.238 0.422 0.292 0.383 0.362 0.799 0.194 AP50 0.529 0.738 0.694 0.550 0.435 0.884 0.035 0.389 0.410 0.413 0.501 0.363 0.366 0.617 0.590 0.648 0.571 0.948 0.375 AP25 0.677 0.863 0.795 0.699 0.617 0.931 0.426 0.541 0.697 0.538 0.623 0.446 0.366 0.765 0.826 0.848 0.669 0.999 0.533 Both P &amp; Q AP 0.348 0.597 0.376 0.267 0.253 0.712 0.069 0.266 0.140 0.229 0.339 0.208 0.246 0.416 0.298 0.434 0.385 0.758 0.275 AP50 0.569 0.805 0.696 0.549 0.481 0.877 0.224 0.449 0.416 0.420 0.530 0.377 0.372 0.644 0.611 0.715 0.629 0.983 0.462 AP25 0.713 0.865 0.795 0.744 0.673 0.925 0.648 0.616 0.741 0.548 0.654 0.482 0.383 0.711 0.828 0.851 0.742 1.000 0.636</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 5 :</head><label>5</label><figDesc>Visualization of the semantic and instance segmentation results on ScanNet v2 (top) and S3DIS (bottom). For instance predictions, different colors represent separate instances, and the semantic results indicate the categories of instances.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>.390 0.169 0.065 0.275 0.029 0.069 0.000 0.087 0.043 0.014 0.027 0.000 0.112 0.351 0.168 0.438 0.138 3D-BEVIS [11] 0.248 0.667 0.566 0.076 0.035 0.394 0.027 0.035 0.098 0.099 0.030 0.025 0.098 0.375 0.126 0.604 0.181 0.854 0.171 R-PointNet [54] 0.306 0.500 0.405 0.311 0.348 0.589 0.054 0.068 0.126 0.283 0.290 0.028 0.219 0.214 0.331 0.396 0.275 0.821 0.245 DPC [12] 0.355 0.500 0.517 0.467 0.228 0.422 0.133 0.405 0.111 0.205 0.241 0.075 0.233 0.306 0.445 0.439 0.457 0.974 0.23 3D-SIS</figDesc><table><row><cell>Method</cell><cell>Avg AP50</cell><cell>bathtub</cell><cell>bed</cell><cell>bookshe.</cell><cell>cabinet</cell><cell>chair</cell><cell>counter</cell><cell>curtain</cell><cell>desk</cell><cell>door</cell><cell>otherfu.</cell><cell>picture</cell><cell>refrige.</cell><cell>s. curtain</cell><cell>sink</cell><cell>sofa</cell><cell>table</cell><cell>toilet</cell><cell>window</cell></row><row><cell>SGPN [49]</cell><cell>0.143</cell><cell>0.208 0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>3D instance segmentation results on ScanNet v2 testing set with AP 50 scores. Our proposed PointGroup approach yields the highest average AP 50 , outperforming all state-of-the-art methods by a large margin. All numbers are from the ScanNet benchmark on 15/11/2019.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Ablation results using different coordinate sets on the ScanNet v2 validation set. Adopting both the original and shifted coordinates for clustering yields the best 3D instance segmentation performance. Instance predictions produced by models trained with clustering on (i) P only, (ii) shifted coordinates Q only, and (iii) both. The last column shows the predicted instances of (iii) represented with Q, where stuff points are ignored.</figDesc><table><row><cell>Input</cell><cell></cell><cell cols="2">(i) P Only</cell><cell>(ii) Q Only</cell><cell>(iii) P and Q</cell><cell>Shifted Coord.</cell></row><row><cell cols="4">Figure 4: Method avg AP avg AP 50 avg AP 25</cell><cell></cell></row><row><cell>r = 2cm</cell><cell>0.285</cell><cell>0.501</cell><cell>0.651</cell><cell></cell></row><row><cell>r = 3cm</cell><cell>0.348</cell><cell>0.569</cell><cell>0.713</cell><cell></cell></row><row><cell>r = 4cm</cell><cell>0.337</cell><cell>0.552</cell><cell>0.700</cell><cell></cell></row><row><cell>r = 5cm</cell><cell>0.342</cell><cell>0.552</cell><cell>0.699</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4</head><label>4</label><figDesc>reports the runtime breakdown. Clustering</figDesc><table><row><cell></cell><cell>#Points</cell><cell>Total Time</cell><cell>BB</cell><cell cols="4">Clustering on P and Q BQp CLp BQq CLq</cell><cell>SCN</cell><cell>NMS</cell></row><row><cell>1</cell><cell>239,261</cell><cell>865</cell><cell>332</cell><cell cols="2">95 16</cell><cell>95</cell><cell>70</cell><cell>176</cell><cell>82</cell></row><row><cell>2</cell><cell>45,557</cell><cell>261</cell><cell>177</cell><cell>5</cell><cell>2</cell><cell>5</cell><cell>5</cell><cell>52</cell><cell>14</cell></row><row><cell>3</cell><cell>186,857</cell><cell>567</cell><cell>281</cell><cell cols="2">44 9</cell><cell>45</cell><cell>31</cell><cell>95</cell><cell>62</cell></row><row><cell>4</cell><cell>60,071</cell><cell>271</cell><cell>180</cell><cell>6</cell><cell>3</cell><cell>7</cell><cell>15</cell><cell>55</cell><cell>6</cell></row><row><cell>avg</cell><cell>132,937</cell><cell>491</cell><cell>243</cell><cell cols="2">38 8</cell><cell>38</cell><cell>30</cell><cell>95</cell><cell>41</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Inference time (ms). BB denotes backbone + two branches; BQ denotes ballquery; subscripts p and q denote clustering on P and Q respectively; CL denotes our clustering algorithm; and SCN denotes ScoreNet.</figDesc><table><row><cell>Method</cell><cell cols="3">AP 50 mPrec 50 mRec 50</cell></row><row><cell>SGPN  † [49]</cell><cell>-</cell><cell>0.360</cell><cell>0.287</cell></row><row><cell>ASIS  † [50]</cell><cell>-</cell><cell>0.553</cell><cell>0.424</cell></row><row><cell>PointGroup  †</cell><cell>0.578</cell><cell>0.619</cell><cell>0.621</cell></row><row><cell>SGPN  ‡ [49]</cell><cell>0.544</cell><cell>0.382</cell><cell>0.312</cell></row><row><cell>PartNet  ‡ [31]</cell><cell>-</cell><cell>0.564</cell><cell>0.434</cell></row><row><cell>ASIS  ‡ [50]</cell><cell>-</cell><cell>0.636</cell><cell>0.475</cell></row><row><cell>3D-BoNet  ‡ [53]</cell><cell>-</cell><cell>0.656</cell><cell>0.476</cell></row><row><cell>PointGroup  ‡</cell><cell>0.640</cell><cell>0.696</cell><cell>0.692</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Instance segmentation results on the S3DIS validation set. Methods marked with † are evaluated on Area 5; those marked with ‡ are on the 6-fold cross validation.</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments This project is supported in part by the Research Grants Council of the Hong Kong Special Administrative Region (Project no. CUHK 14201717).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Multiscale combinatorial grouping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Arbeláez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordi</forename><surname>Pont-Tuset</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">T</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferran</forename><surname>Marques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">3D semantic parsing of large-scale indoor spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iro</forename><surname>Armeni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>Sener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Amir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><surname>Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Brilakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Pixelwise instance segmentation with a dynamically instantiated network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anurag</forename><surname>Arnab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deep watershed transform for instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Hybrid task cascade for instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangmiao</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuyang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wansen</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Masklab: Instance segmentation by refining object detection with semantic and direction features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Hermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">4D spatio-temporal ConvNets: Minkowski convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Gwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">ScanNet: Richly-annotated 3D reconstructions of indoor scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angel</forename><forename type="middle">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manolis</forename><surname>Savva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maciej</forename><surname>Halber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Funkhouser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Nießner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Convolutional feature masking for joint object and stuff segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Instance-aware semantic segmentation via multi-task network cascades</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cathrin</forename><surname>Elich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Engelmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Schult</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theodora</forename><surname>Kontogianni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Leibe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.02199</idno>
		<title level="m">3d-bevis: Birds-eye-view instance segmentation</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Engelmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theodora</forename><surname>Kontogianni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Leibe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.12046</idno>
		<title level="m">Dilated point convolutions: On the receptive field of point convolutions</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">3D semantic segmentation with submanifold sparse convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Engelcke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Simultaneous detection and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Bharath Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Arbeláez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Hypercolumns for object segmentation and fine-grained localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><forename type="middle">Andrés</forename><surname>Bharath Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Arbeláez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Boundary-aware instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeeshan</forename><surname>Hayder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Salzmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Piotr Dollár, and Ross Girshick. Mask R-CNN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">3D-SIS: 3D semantic instance segmentation of RGB-D scans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Nießner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Acquisition of localization confidence for accurate object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borui</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruixuan</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayuan</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tete</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuning</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Hierarchical point-edge interaction network for point cloud semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Wing</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">3D instance segmentation via multi-task metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Lahoud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Pollefeys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin R</forename><surname>Oswald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Gs3d: An efficient 3d object detection framework for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Buyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyu</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">PointCNN: Convolution on Xtransformed points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangyan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingchao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinhan</forename><surname>Di</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoquan</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">MASC: Multi-scale affinity with sparse convolution for 3D instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasutaka</forename><surname>Furukawa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.04478</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">SGN: Sequential grouping networks for instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Path aggregation network for instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifang</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">VoxNet: A 3D convolutional neural network for real-time object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Maturana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Scherer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IROS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Partnet: A largescale benchmark for fine-grained and hierarchical part-level 3d object understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaichun</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shilin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Angel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subarna</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Tripathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Guibas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">PanopticFusion: Online volumetric semantic mapping at the level of stuff and things</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaku</forename><surname>Narita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takashi</forename><surname>Seno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoya</forename><surname>Ishikawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yohsuke</forename><surname>Kaji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IROS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Jsis3d: Joint semantic-instance segmentation of 3d point clouds with multi-task pointwise networks and multi-value conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quang-Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thanh</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Binh-Son</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gemma</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sai-Kit</forename><surname>Roig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Deep hough voting for 3d object detection in point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Or</forename><surname>Charles R Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Litany</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">PointNet: Deep learning on point sets for 3D classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Charles Ruizhongtai Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaichun</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Volumetric and multi-view cnns for object classification on 3D data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Charles R Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Nießner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengyuan</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">PointNet++: Deep hierarchical feature learning on point sets in a metric space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Charles Ruizhongtai Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Faster R-CNN: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">OctNet: Learning deep 3D representations at high resolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gernot</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Osman Ulusoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Pointrcnn: 3d object proposal generation and detection from point cloud</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoshuai</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Semantic scene completion from a single depth image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuran</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Angel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manolis</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Savva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Funkhouser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Learned-Miller. Multi-view convolutional neural networks for 3D shape recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evangelos</forename><surname>Kalogerakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><forename type="middle">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">3D-assisted feature synthesis for novel views of an object</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">SEGCloud: Semantic segmentation of 3D point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lyne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">B</forename><surname>Tchapmi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iro</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Armeni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Gwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Savarese</surname></persName>
		</author>
		<idno>3DV</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Deep parametric continuous convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenlong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Suo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Chiu</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Pokrovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">SGPN: Similarity group proposal network for 3D point cloud instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiangui</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Neumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Associatively segmenting instances and semantics in point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Dynamic graph CNN for learning on point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongbin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjay</forename><forename type="middle">E</forename><surname>Sarma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><forename type="middle">M</forename><surname>Solomon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>TOG</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">PointConv: Deep convolutional networks on 3D point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenxuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongang</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fuxin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Learning object bounding boxes for 3D instance segmentation on point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyong</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Markham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Trigoni</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">GSPN: Generative shape proposal network for 3D instance segmentation in point cloud</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minhyuk</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Instancelevel segmentation for autonomous driving with deep densely connected MRFs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Monocular object instance segmentation and depth ordering with CNNs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">G</forename><surname>Schwing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">PointWeb: Enhancing local neighborhood features for point cloud processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Wing</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
