<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Sliced Recurrent Neural Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeping</forename><surname>Yu</surname></persName>
							<email>zepingyu@foxmail.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gongshen</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">School of Eclectronic Information and Electrical Engineering Shanghai</orgName>
								<orgName type="institution">Jiao Tong University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">School of Eclectronic Information and Electrical Engineering Shanghai Jiao</orgName>
								<orgName type="institution">Tong University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Sliced Recurrent Neural Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T21:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recurrent neural networks have achieved great success in many NLP tasks. However, they have difficulty in parallelization because of the recurrent structure, so it takes much time to train RNNs. In this paper, we introduce sliced recurrent neural networks (SRNNs), which could be parallelized by slicing the sequences into many subsequences. SRNNs have the ability to obtain high-level information through multiple layers with few extra parameters. We prove that the standard RNN is a special case of the SRNN when we use linear activation functions. Without changing the recurrent units, SRNNs are 136 times as fast as standard RNNs and could be even faster when we train longer sequences. Experiments on six largescale sentiment analysis datasets show that SRNNs achieve better performance than standard RNNs.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recurrent neural networks (RNNs) have been widely used in many NLP tasks, including machine translation <ref type="bibr" target="#b6">(Cho et al., 2014;</ref><ref type="bibr" target="#b0">Bahdanau et al., 2015;</ref><ref type="bibr" target="#b20">Luong et al., 2015;</ref><ref type="bibr" target="#b2">Bradbury and Socher, 2016)</ref>, question answering <ref type="bibr" target="#b25">(Xiong et al., 2016;</ref><ref type="bibr" target="#b5">Chen et al., 2017)</ref>, image caption <ref type="bibr" target="#b26">(Xu et al., 2015;</ref><ref type="bibr" target="#b13">Karpathy and Li, 2015)</ref>, and document classification <ref type="bibr" target="#b24">(Tang et al., 2015;</ref><ref type="bibr" target="#b27">Yang et al., 2016;</ref>. RNNs have the ability to obtain the order information of the input sequences. The two most popular recurrent units are long short-term memory (LSTM) <ref type="bibr" target="#b11">(Hochreiter and Schmidhuber, 1997)</ref> and gated recurrent unit (GRU) <ref type="bibr" target="#b6">(Cho et al., 2014)</ref>, both of which could store previous memory in hidden states and use a gating mechanism to determine how much previous memory should be combined with the current input. Unfortunately, because of the recurrent structure, RNNs cannot be computed in parallel. Therefore, training RNNs takes much time, which limits academic research and industrial applications.</p><p>To solve this problem, several scholars try to use convolutional neural networks (CNNs) <ref type="bibr" target="#b18">(Lecun et al., 1998)</ref> instead of RNNs in the field of NLP <ref type="bibr" target="#b14">(Kim, 2014;</ref><ref type="bibr" target="#b12">Kalchbrenner et al., 2014;</ref><ref type="bibr" target="#b8">Gehring et al., 2017)</ref>. However, CNNs may not obtain the order information of the sequences, which is very important in NLP tasks.</p><p>Some scholars tried to increase the speed of RNNs by improving the recurrent units and they have achieved good results. Quasi-recurrent neural networks (QRNNs) <ref type="bibr" target="#b3">(Bradbury et al., 2017)</ref> got up to 16 times faster speeds by combining CNNs with RNNs. <ref type="bibr" target="#b19">Lei et al. (2017)</ref> proposed the simple recurrent unit (SRU), which is 5-10 times faster than LSTM. Similarly, strongly-typed recurrent neural networks (T-RNN) <ref type="bibr" target="#b1">(Balduzzi and Ghifary, 2016)</ref> and minimal gated unit (MGU)  are also methods that could change the recurrent units.</p><p>Although RNNs have achieved faster speeds in these researches with the recurrent units improved, the recurrent structure among the entire sequence remains unchanged. As we still have to wait for the output of previous step, the bottleneck of RNNs still exists. In this paper, we introduce sliced recurrent neural networks (SRNNs), which are substantially faster than standard RNNs without changing the recurrent units. We prove that when we use linear activation functions, the standard RNN is a special case of the SRNN, and the SRNN has the ability to obtain high-level information of the sequences.</p><p>In order to compare our model with the standard RNN, we choose GRU as the recurrent unit. Other recurrent units could also be used in our structure, because we improve the overall RNN structure among the whole sequence rather than just changing the recurrent units. We complete experiments on six large-scale datasets and SRNNs perform better than standard RNNs on all the datasets. We open source our implementation in <ref type="bibr">Keras (François et al, 2015)</ref>. 1 2 Model Structure</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Gated Recurrent Unit</head><p>The GRU <ref type="bibr" target="#b6">(Bahdanau et al., 2014)</ref> has the reset gate r and the update gate z. The reset gate decides how much of the previous memory is combined with the new input, and the update gate determines how much of the previous memory is retained.</p><p>) (</p><formula xml:id="formula_0">1 r t r t r t b h U x W r      (1) ) ( 1 z t z t z t b h U x W z      (2)</formula><p>where x is the input and h is the hidden state.</p><formula xml:id="formula_1">) ) ( tanh( 1 h t t h t h t b h r U x W h      (3)</formula><p>The candidate hidden state t h is controlled by the reset gate. When the reset gate is 0, the previous memory is ignored.</p><formula xml:id="formula_2">h z h z h1 ) 1 (       (4)</formula><p>When the update gate is 1, the hidden state could copy the previous memory to the current moment and ignore the current input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">The Standard RNN Structure</head><p>The standard RNN structure is shown in <ref type="figure">Figure 1</ref>, where A denotes the recurrent units. <ref type="figure">Figure 1</ref>: The standard RNN structure. Each step waits for the output of its previous step, which is computed by the recurrent unit A.</p><p>The length of the input sequence X is T, and here we assume 8  T</p><p>as <ref type="figure">Figure 1</ref> shown. The standard RNN uses the last hidden state as the representation of the whole sequence, and then add a softmax classifier to predict the labels. In addition to GRU and LSTM, QRNN and SRU could be seen as one form of recurrent unit A as well. However, the overall RNN structure has not been improved, at each step we need to wait for the output of the previous step:</p><formula xml:id="formula_3">) , ( 1 t t t x h f h   (5)</formula><p>where h is the previous hidden state. This standard RNN structure in which every two adjacent cells are connected causes the bottleneck: the longer the input sequence is, the longer it takes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Sliced Recurrent Neural Networks</head><p>We construct a new RNN structure called sliced recurrent neural networks (SRNNs), which is shown in <ref type="figure">Figure 2</ref>. In <ref type="figure">Figure 2</ref> the recurrent unit is also referred to as A. <ref type="figure">Figure 2</ref>: The SRNN structure. It is constructed by slicing the input sequence into several minimum subsequences with equal length. The recurrent units could work on each subsequence simultaneously on each layer, and the information could be transmitted through multiple layers.</p><p>The length of input sequence X is T, and the input sequence is:</p><formula xml:id="formula_4">] ,..., , [ 2 1 T x x x X <label>(6)</label></formula><p>where x is the input at each step and it may have multiple dimensions such as word embeddings. Then we slice X into n subsequences of equal length, and the length of each subsequence N is:</p><formula xml:id="formula_5">n T t  (7)</formula><p>where n is the slice number, and the sequence X could be represented as:</p><formula xml:id="formula_6">] ,..., , [ 2 1 n N N N X  (8) where each subsequence is: ] ,..., , [ 2 ) 1 ( 1 ) 1 ( t p t p t p p x x x N        <label>(9)</label></formula><p>Similarly, we slice each subsequence N into n subsequences of equal length again, and then repeat this slice operation k times until we have an appropriate minimum subsequence length on the bottom layer (we call it 0th layer, which is shown in <ref type="figure">Figure 2</ref>), and k+1 layers are obtained by slicing k times. The minimum subsequence length of 0th layer is: </p><p>Because every parent sequence on pth layer (p&gt;0) is sliced into n parts, the number of the subsequences on pth layer is: <ref type="bibr">12)</ref> and the subsequence length of pth layer is: n l p  (13) Take <ref type="figure">Figure 2</ref> as an example. The sequence length T is 8, the slice operation times k is 2, and the slice number n of each pth layer is 2. After slicing the sequence twice, we get four minimum subsequences on 0th layer, and the length of each minimum subsequence is 2. If the length of the sequence or the length of its subsequences cannot be divided by n, we may exploit padding method or choose different slice number on each layer. Different k and n may be used on different tasks and datasets.</p><formula xml:id="formula_8">p k p n s  <label>(</label></formula><p>The difference between the SRNN and the standard RNN is that the SRNN slices the input sequence into many minimum subsequences and utilizes the recurrent units on each subsequence. In this way, the subsequences could be easily parallelized. On 0th layer, the recurrent units are acted on each minimum subsequence through the connection structure. Next, we obtain the last hidden states of each minimum subsequence on 0th layer, which are used as the input of their parent sequences on 1st layer. And then we use the last hidden state of each subsequence on (p-1)th layer as the input of their parent sequence on pth layer and compute the last hidden states of the subsequences on pth layer.</p><formula xml:id="formula_9">) ( 0) 1 ( 0 1 0 t l t t mss GRU h     (14) ) ( 1 p t p l t p p t h h GRU h p     (15)</formula><p>where p l h is the number l hidden state on pth layer, mss denotes minimum subsequences on 0th layer, and different GRUs could be used on different layers. This operation is repeated between each subparent sequence on each layer until we get the final hidden state F of the top layer (kth layer).</p><formula xml:id="formula_10">) ( k t k l t k h h GRU F k    (16)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Classification</head><p>Similar to the standard RNN, the softmax layer is added after the final hidden state F to classify the labels:</p><formula xml:id="formula_11">) ( softmax F F b F W p  <label>(17)</label></formula><p>and the loss function is negative log-likelihood:</p><formula xml:id="formula_12">   dj p loss log (18)</formula><p>where d is each document of the dataset with label j.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Speed Advantage</head><p>The reason why SRNNs could be parallelized is that SRNNs improve the traditional connection structure. In SRNNs, not every current input is connected with its previous moment, but the entire sequence is connected together by a sliced method. SRNNs could also obtain the sequence order by the recurrent units in each subsequence, and transmit the information through multiple layers. We assume that the time spent in each recurrent unit is r, then the time spent in the standard RNN is:</p><formula xml:id="formula_13">r T t RNN   (19)</formula><p>where T is the input sequence length. In the SRNN, each minimum subsequence could be parallelized, so the time spent on 0th layer is:</p><formula xml:id="formula_14">r n T t k   ) ( 0<label>(20)</label></formula><p>and similarly, the time spent on pth layer (not including 0th layer) is:</p><formula xml:id="formula_15">r n t p  <label>(21)</label></formula><p>so the total time in the SRNN is:</p><formula xml:id="formula_16">r n T k n t k SRNN     ) (<label>(22)</label></formula><p>At last we could compute the speed advantage of the SRNN:</p><formula xml:id="formula_17">T k n n t t R k RNN SRNN     1 (23)</formula><p>where R is how much faster the SRNN gets. We could choose different n and k to get different speed advantage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Relations between the SRNN and the Standard RNN</head><p>In this part we describe the relations between the SRNN and the standard RNN. In the standard RNN structure, each step is related to the input and the previous step, which could be computed by:</p><formula xml:id="formula_18">) ( 1 b Wh Ux f h t t t     (24)</formula><p>where x is the input and h is the hidden state. The function f could be a nonlinear activation function such as sigmoid, or a linear activation function such as rectified linear units <ref type="bibr" target="#b17">(Le et al., 2015)</ref>. To simplify the question, here we discuss the case when we use a linear function:</p><formula xml:id="formula_19">x x f  ) (<label>(25)</label></formula><p>and we set the bias b and 0 h to be zero. When we use the standard RNN, we could get the last hidden state:</p><formula xml:id="formula_20">1 1 2 2 1 2 1 1 ... ... ) ( Ux W Ux W WUx Ux Wh Ux W Ux Wh Ux h T T T T T T T T T T                  (26)</formula><p>where T is the sequence length. And then we construct the SRNN structure. When</p><formula xml:id="formula_21">1   k n T</formula><p>, we choose SRNN (n,k), which means slicing k times with the slice number n. The SRNN has k+1 layers, on each layer the length of each subsequence is n. We could compute the last hidden state of each minimum subsequence on 0th layer:</p><formula xml:id="formula_22">1 0 1 0 2 0 2 0 1 0 0 0 0 ... x U W x U W x U W x U h n n n n n         1 0 1 0 2 2 0 2 0 1 2 0 0 2 0 0 2 ...          n n n n n n x U W x U W x U W x U h ... 1 0 1 0 2 0 2 0 1 0 0 0 0 ...           n T n T T T T x U W x U W x U W x U h<label>(27)</label></formula><p>where p l h is the number l hidden state on pth layer. There are k n last hidden states on 0th layer. Similarly, we could take the hidden states on (p-1)th layer as the input, and compute the last hidden states of the subsequences on pth layer (p&gt;0).</p><formula xml:id="formula_23">1 1 1 2 2 1 1 ... 1 1 1 1                 p n p n p p n n p p p n n p p p n p p n p p p p p p p h U W h U W h U W h U h 1 1 1 2 2 2 1 2 1 2 2 1 1 1 1 1 ...                   p n n p n p p n n p p p n n p p p n p p n p p p p p p p p h U W h U W h U W h U h ... 1 ) 1 ( 1 1 2 2 1 1 ...               p n n T p n p p n T p p p n T p p p T p p T p p p h U W h U W h U W h U h<label>(28)</label></formula><p>There are p k nlast hidden states on pth layer. And this operation is repeated from 0th layer to kth layer. At last we get the final hidden state F of kth layer.</p><formula xml:id="formula_24">1 1 1 2 2 1 1 ...             k n k n k k n T k k k n T k k k T k k k k h U W h U W h U W h U F<label>(29)</label></formula><p>When we compute equation (29) using each hidden state calculated by equation <ref type="formula" target="#formula_8">(27)</ref> and <ref type="formula" target="#formula_8">(28)</ref>, we could get:</p><formula xml:id="formula_25">1 0 1 0 1 1 1 1 2 0 2 0 1 1 0 0 1 0 1 ... ... ... ... ... x U W U W U W x U W U U x U W U U x U U U F n k n k k n k T k k T k k T k k               <label>(30)</label></formula><p>When we compare equation <ref type="formula" target="#formula_8">(30)</ref> with equation <ref type="formula" target="#formula_4">(26)</ref>, we could find that the two equations compute the same results when:</p><formula xml:id="formula_26">U U  0 I U U U k k      1 1 ... k n k W W <label>(31)</label></formula><p>where I is the identity matrix, U and W are the parameters in equation <ref type="formula" target="#formula_4">(26)</ref>. This means that SRNNs could have the same output as standard RNNs when equation <ref type="formula" target="#formula_8">(31)</ref>   <ref type="figure">In SRNN (2,1)</ref>, the hidden states on 0th layer are:</p><formula xml:id="formula_27">1 0 0 2 0 0 2 x U W x U h   3 0 0 4 0 0 4 x U W x U h  </formula><p>and the final hidden state of 1st layer is:</p><formula xml:id="formula_28">1 0 0 1 1 2 0 1 1 3 0 0 1 4 0 1 0 2 1 1 0 4 1 x U W U W x U U W x U W U x U U h U W h U F       When we use equation (31) to set W W  0 , 2 1 W W  , U U  0 and I U  1 , we could get: 1 3 2 2 3 4 Ux W Ux W WUx Ux F    </formula><p>which is equal to 4 h above. We have proved that when the function f is linear, the output of the SRNN is equal to the output of the standard RNN when the parameters satisfy equation <ref type="formula" target="#formula_8">(31)</ref>, so the standard RNN is a special case of the SRNN. Furthermore, the SRNN may get high-level information when they have different parameters on different layers, so the SRNN is able to obtain more information from the input sequences than the standard RNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets</head><p>We evaluate SRNNs on six large-scale sentiment analysis datasets. <ref type="table" target="#tab_1">Table 1</ref> shows the information of the datasets. We choose 80% data for training, 10% for validation and 10% for testing. Yelp reviews: The Yelp reviews datasets are obtained from the Yelp Dataset Challenge, which has 5 sentiment labels (the higher, the better). This dataset consists of 4,736,892 documents, and we extract three subsets Yelp 2013, 2014, 2015 containing 468,608, 670,440 and 897,835 documents separately. <ref type="bibr" target="#b28">Zhang et al. (2015)</ref> created the polarity dataset including 598,000 documents with two sentiment labels, and we obtain the polarity dataset from them. Amazon reviews: The Amazon reviews dataset is a commentary dataset containing 34,686,770 reviews on 2,441,053 products from 6,643,669 users <ref type="bibr" target="#b10">(He and McAuley, 2016)</ref>. One review has a review title, a review content and a sentiment label, and we combine the title and content into one document. The dataset is also constructed into a full dataset with 3,650,000 documents and a polarity dataset with 4,000,000 documents, which is also obtained from <ref type="bibr" target="#b28">Zhang et al. (2015)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Baseline</head><p>We compare SRNNs with standard RNNs and take GRU as the recurrent unit. The output of the last hidden state is the representation of each document, and then we add a softmax layer on it to predict the sentiment labels. In order to compare SRNNs with convolutional structures, we also build a stack of dilated casual convolutional layers as a baseline, which is proposed in wavenet <ref type="figure">(Oord et al., 2016)</ref>. The dilated casual convolutional structure could maintain the order information of the sequences. The dilation is 1, 2, 4, ... , 256 for Yelp datasets, and 1, 2, 4, ... , 128 for Amazon datasets. The number of filters is 50, and the activation function after each layer is rectified linear units.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Training</head><p>We use the sequence preprocessing tool of Keras <ref type="bibr">(François et al, 2015)</ref> to pad sequences into the same length T. Sequences shorter than T are padded with zero at the end, and sequences longer than T are truncated. In this work, T is set to be 512 on Yelp datasets, and 256 on Amazon datasets. Different n and k values, which separately denotes the slice number and the slice times, are used on the experiments. For each dataset, we retain the top 30,000 words of the vocabulary. The pre-trained GloVe embeddings <ref type="bibr" target="#b22">(Pennington et al., 2014)</ref> are utilized to initialize the word embeddings. We set GRU as the recurrent unit of the SRNN. We have discussed the relations between the SRNN and the standard RNN in section 2.6 and have proved that the standard RNN is a special case of the SRNN when we use linear activation function between the recurrent units. However, it does not mean only linear activation function could be used in the SRNN. Both linear activation function such as hard sigmoid, and nonlinear activation function such as hyperbolic tangent could be used in or after each layer in the SRNN. In this paper, the recurrent activation function in GRU is sigmoid, and the activation function after each layer is linear function</p><formula xml:id="formula_29">x x f  ) (</formula><p>. The dimension of GRU on each layer is set to be 50 and the word embedding dimension is 200. In SRNNs, the final state F also has 50 dimensions. We set the mini-batch size to be 100 for training and use Adam <ref type="bibr" target="#b15">(Kingma and Ba, 2014)</ref>  . We tune the hyper parameters on the validation set and select the best model to predict the sentiment labels on the test set. We train the models with an NVIDIA GTX 1080 GPU, and record the training time per epoch on each dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Results and Analysis</head><p>The results on each dataset are shown on <ref type="table" target="#tab_4">Table 2</ref>. We choose different n and k values and get different SRNNs. For example, SRNN (16,1) means n=16 and k=1, which could get a 32-length minimum subsequence when T is 512 or a 16-length minimum subsequence when T is 256. We compare four SRNNs with the standard RNN. For each dataset, we use bold words to label the highest-performing model and the fastest model.  The results show that SRNNs achieve better performance and attain much faster speeds than standard RNNs on all the datasets with few extra parameters. Different SRNNs have achieved the best performance on different datasets. SRNN (16,1) gets the highest accuracy on Yelp 2013, Yelp 2015, Amazon_F and Amazon_P; SRNN (8,2) performs best on Yelp 2014; SRNN (4,3) is the best on Yelp_P. SRNNs with k more than 1 could get nearly 15 times faster than standard RNNs on the Yelp datasets, and the speed advantage depends on k, n and T. In this work, SRNN (4,3) has the fastest speed on Yelp 2015, while SRNN (8,2) is the fastest on the rest (except DCCNN).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>When we focus on the results of SRNN (2,8) on Yelp datasets and SRNN (2,7) on Amazon datasets, we could find that even if they did not achieve the best performance, they did not lose much accuracy. This means that SRNNs are able to transmit information through multiple layers, and because of this, SRNNs may achieve remarkable results when we train very long sequences. When n is 2, SRNN has the same number of layers as DCCNN, and it has much higher accuracy than DCCNN. So it means that the recurrent structure in SRNN is better than the dilated casual convolutional structure.</p><p>When we go back to equation <ref type="formula" target="#formula_8">(23)</ref>, we may find that when n and k are not set to be too small, we could get much faster. In this work, we set</p><formula xml:id="formula_30">8  n , 1   q k when q T 8  .</formula><p>We use an NVIDIA GTX 1080 GPU to train the models on 5120 documents, since the standard RNN would take too much time if we use more data. The training time is shown on <ref type="table">Table 3</ref>. We could get the amazing results from <ref type="table">Table 3</ref>: the longer the sequence length is, the bigger speed advantage the SRNN achieves. When the sequence length is 32768, SRNN would take only 52s while the standard RNN would take nearly 2 hours. The SRNN is 136 times as fast as the standard RNN, and the speed advantage may be even bigger when longer sequences are used. Therefore, SRNNs may achieve much faster speeds on long-sequence tasks such as speech recognition, character-level text classification and language modeling.  <ref type="table">Table 3</ref>: The training time and speed advantage on different sequence length. For each sequence length we choose a different SRNN structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Why SRNN</head><p>In this part we will discuss the advantages and importance of the SRNN. With the success of RNNs in many NLP tasks, many scholars have proposed different structures to increase the speed of RNNs. Most of the researches get faster by improving the recurrent units. However, the traditional connection structure has scarcely been questioned, in which each step is connected to its previous step. It is this connection structure that limits the speed of RNNs. The SRNN has improved the traditional connection method. Instead, a sliced structure is constructed to implement the parallelization of RNNs. The experimental results on six large-scale sentiment analysis datasets show that SRNNs achieve better performance than the standard RNN. The reasons are as follows:</p><p>(1) When we use the standard RNN connection structure, recurrent units with gated structures such as GRU and LSTM are useful, but they are not able to store all the important information when the sequences are very long. The SRNN, however, could divide the long sequence into many short subsequences and obtain the important information in short sequences. SRNNs are able to transmit the important information through the multiple-layers structure from 0th layer to the top layer.</p><p>(2) SRNNs have the ability to obtain high-level information from the sequences, instead of just the word-level information. When we use SRNN (8,2) in a document with 512 words, 0th layer may get the sentence-level information from the word embeddings, 1st layer may gain the paragraph-level information from the sentence-level information and 2nd layer could generate the final document-level representation from the paragraph-level information. The standard RNN, however, could only get the word-level information. Although it is impossible to have 8 paragraphs in each document, 8 sentences in each paragraph and 8 words in each sentence, the overall order information and structure information is uniform. Take the paragraph information as an example. People always express their opinions at the beginning or end of an article, and show examples in the middle of the article to explain their views. Compared to standard RNN, it is much easier for SRNNs to gain this information on the top layer.</p><p>(3) In terms of handling sequences, the SRNN is akin to the human brain mechanism. For example, if we, as humans, are given an article and asked to answer some questions about it, we usually do not need to read the whole article intensively. To answer the questions correctly, we try to locate the paragraph which mentions the specific information, and then find sentences and words in this paragraph that can answer the question. The SRNN could easily do this through multiple layers.</p><p>In addition to the improvement of accuracy, the most significant advantage of SRNNs is that SRNNs can be computed in parallel and achieve much faster speeds. Equation (23) computes the speed advantage of SRNN, and experiments of different sequence length also show that SRNNs could run much faster than standard RNNs. SRNNs could be even faster on longer sequences. As the Internet develops, hundreds of millions of data are generated every day, and SRNNs have devised new ways for us to handle these data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related Work</head><p>In order to increase the speed of RNNs, many scholars tried to improve the traditional RNN and achieved great results. <ref type="bibr" target="#b14">Kim (2014)</ref>, <ref type="bibr" target="#b12">Kalchbrenner et al. (2014)</ref>, and <ref type="bibr" target="#b8">Gehring et al. (2017)</ref> tried to use CNNs in NLP tasks, which are usually used in computer vision <ref type="bibr" target="#b18">(Lecun et al., 1998)</ref>. Several structures get faster with the recurrent units changed <ref type="bibr" target="#b9">(Greff et al., 2015;</ref><ref type="bibr" target="#b1">Balduzzi and Ghifary, 2016;</ref><ref type="bibr" target="#b3">Bradbury et al., 2017;</ref><ref type="bibr" target="#b19">Lei et al., 2017)</ref>. As an overall structure improvement, the SRNN are related to these models, because different types of recurrent units could be used in SRNNs. In this work we choose GRU <ref type="bibr" target="#b6">(Cho et al., 2014)</ref>, but other recurrent units are able to work in SRNNs as well.</p><p>The SRNN is related to the hierarchical structure proposed by <ref type="bibr" target="#b24">Tang et al. (2015)</ref> and <ref type="bibr" target="#b27">Yang et al. (2016)</ref>. <ref type="bibr" target="#b24">Tang et al. (2015)</ref> use CNN or LSTM to obtain the sentence representations, and then exploit gated RNN to generate the document representations. <ref type="bibr" target="#b27">Yang et al. (2016)</ref> build a hierarchical network on both word-level and sentence-level, then use attention mechanism on both level. The difference between the SRNN and the hierarchical structure is that the documents do not need to be split into sentences when we use the SRNN, and the SRNN could have multiple layers. The hierarchical structure could be viewed as a special case of the SRNN, where k is 1 and all the sentences have equal length.</p><p>Several other architectures have been proposed to improve the connection structure of RNNs <ref type="bibr" target="#b23">(Sutskever and Hinton, 2010;</ref><ref type="bibr" target="#b16">Koutnik et al., 2014;</ref><ref type="bibr" target="#b4">Chang et al., 2017)</ref>. The SRNN is different from those architectures in the connection structure. The SRNN could be computed in parallel by slicing the sequences into many subsequences, but these models may still limit parallelization.</p><p>Also, the SRNN structure is similar to the overall structure of wavenet <ref type="bibr" target="#b21">(Oord et al., 2016)</ref>, which is used for audio generation. The difference between the SRNN and wavenet, which is also the most important innovation of the SRNN, is that we use recurrent units on each layer. For sequences, recurrent structure has its inherent advantages than convolutional structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper we present the sliced recurrent neural network (SRNN), which is an overall structure improvement of RNN. The SRNN could reach a remarkably faster speed than the standard RNN and achieve better performance on six large-scale sentiment datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Future Work</head><p>The SRNN has been successful in text classification. In future work, we hope to promote it to other NLP applications, such as question answering, text summarization, and machine translation. In sequence to sequence model, the SRNN can be used as the encoder, and the decoder may be improved by using an inverse SRNN structure. Also, we hope to use the SRNN in several long sequence tasks, such as language model, music generation and audio generation. And we want to explore more about variants of the SRNN. For example, bidirectional structure and attention mechanism could be added.</p><p>In section 2.6, we have discussed the relations between the SRNN and the standard RNN when choosing the linear activation function. In future work, we will try to research the situation of using nonlinear recurrent activation functions by mathematics, though it may be harder.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Dataset information. Max words denotes the max sequence length, and Average words denotes the average length of the sentences in each dataset.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Dataset Classes Documents Max words Average words Vocabulary</head><label></label><figDesc></figDesc><table><row><cell>Yelp 2013</cell><cell>5</cell><cell>468,608</cell><cell>1060</cell><cell>129.2</cell><cell>202,058</cell></row><row><cell>Yelp 2014</cell><cell>5</cell><cell>670,440</cell><cell>1053</cell><cell>116.1</cell><cell>210,353</cell></row><row><cell>Yelp 2015</cell><cell>5</cell><cell>897,835</cell><cell>1092</cell><cell>108.3</cell><cell>228,715</cell></row><row><cell>Yelp_P</cell><cell>2</cell><cell>598,000</cell><cell>1073</cell><cell>139.7</cell><cell>308,028</cell></row><row><cell>Amazon_F</cell><cell>5</cell><cell>3,650,000</cell><cell>441</cell><cell>82.7</cell><cell>1,274,916</cell></row><row><cell>Amazon_P</cell><cell>2</cell><cell>4,000,000</cell><cell>257</cell><cell>80.9</cell><cell>1,348,126</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>The accuracy and training time on validation and test sets of the models on each dataset. Four different structures of SRNNs are constructed. DCCNN is dilated casual convolutional neural network, which is described in section 3.2.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">This work is licensed under a Creative Commons Attribution 4.0 International License. License details: http://creativecommons.org/licenses/by/4.0/ * Corresponding author</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">t t t t t</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>Special thanks to Linjuan Wu for her help in polishing the language. Also, we would like to thank the anonymous reviewers for their suggestions. This work is supported by the National Natural Science Foundation of China (Grant No. 61772337, 61472248, and U1736207)  and the SJTU-Shanghai Songheng Information Analysis Joint Lab.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
		<meeting>the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Strongly-typed recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><surname>Ghifary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 33th International Conference on Machine Learning</title>
		<meeting>33th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">MetaMind neural machine translation system for WMT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Conference on Machine Translation: Shared Task Papers</title>
		<meeting>the First Conference on Machine Translation: Shared Task Papers</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="264" to="267" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Quasi-recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Merity</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
		<meeting>the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Dilated recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Witbrock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Hasegawa-Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="76" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.00051</idno>
		<title level="m">Reading Wikipedia to answer open-domain questions</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Çaglar</forename><surname>Gülçehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Chollet François and others</title>
		<ptr target="https://github.com/keras-team/keras.GitHub" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Gehring</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denis</forename><surname>Yarats</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann N</forename><surname>Dauphin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.03122</idno>
		<title level="m">Convolutional sequence to sequence learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rupesh</forename><forename type="middle">Kumar</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Koutník</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Steunebrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.04069</idno>
		<title level="m">Lstm: A search space odyssey</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Ups and Downs: Modeling the Visual Evolution of Fashion Trends with One-Class Collaborative Filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruining</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th international conference on world wide web</title>
		<meeting>the 25th international conference on world wide web</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="507" to="517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jurgen</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno>0899-7667</idno>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A convolutional neural network for modelling sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics: Long Papers</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics: Long Papers</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep visual-semantic alignments for generating image descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei-Fei</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3128" to="3137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Empiricial Methods in Natural Language Processing</title>
		<meeting>the Empiricial Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A clockwork rnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Koutnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Faustino</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jurgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Machine Learning</title>
		<meeting>International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1863" to="1871" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">A simple way to initialize recurrent networks of rectified linear units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1504.00941</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.02755</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">Training RNNs as Fast as CNNs. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Effective approaches to attentionbased neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sander</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heiga</forename><surname>Zen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.03499</idno>
		<title level="m">Wavenet: A generative model for raw audio</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">GloVe: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing</title>
		<meeting>the 2014 conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Temporal-kernel recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Neural Networks</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="239" to="243" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Document modeling with gated recurrent neural network for sentiment classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1422" to="1432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Dynamic memory networks for visual and textual question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Merity</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 33th International Conference on Machine Learning</title>
		<meeting>33th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2397" to="2406" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Show, attend and tell: Neural image caption generation with visual attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Machine Learning</title>
		<meeting>the 32nd International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2048" to="2057" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Hierarchical Attention Networks for Document Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zichao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diyi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1480" to="1489" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Character-level convolutional networks for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbo</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="649" to="657" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Minimal gated unit for recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guo-Bing</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen-Lin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Hua</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In International Journal of Automation and Computing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="226" to="234" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Attention-Based Bidirectional Long Short-Term Memory Networks for Relation Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenyu</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingchen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongwei</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th</title>
		<meeting>the 54th</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
			</analytic>
	<monogr>
		<title level="m">Annual Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="207" to="212" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
