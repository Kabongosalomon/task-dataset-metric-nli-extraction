<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Toxic Language Detection in Social Media for Brazilian Portuguese: New Dataset and Multilingual Analysis</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">João</forename><forename type="middle">A</forename><surname>Leite</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Computação</orgName>
								<orgName type="institution">Federal University of São Carlos São Carlos</orgName>
								<address>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><forename type="middle">F</forename><surname>Silva</surname></persName>
							<email>diegofs@ufscar.br</email>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Computação</orgName>
								<orgName type="institution">Federal University of São Carlos São Carlos</orgName>
								<address>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kalina</forename><surname>Bontcheva</surname></persName>
							<email>k.bontcheva@sheffield.ac.ukc.scarton@sheffield.ac.uk</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Sheffield Sheffield</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carolina</forename><surname>Scarton</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Sheffield Sheffield</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Toxic Language Detection in Social Media for Brazilian Portuguese: New Dataset and Multilingual Analysis</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T08:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Hate speech and toxic comments are a common concern of social media platform users. Although these comments are, fortunately, the minority in these platforms, they are still capable of causing harm. Therefore, identifying these comments is an important task for studying and preventing the proliferation of toxicity in social media. Previous work in automatically detecting toxic comments focus mainly in English, with very few work in languages like Brazilian Portuguese. In this paper, we propose a new large-scale dataset for Brazilian Portuguese with tweets annotated as either toxic or non-toxic or in different types of toxicity. We present our dataset collection and annotation process, where we aimed to select candidates covering multiple demographic groups. State-of-the-art BERT models were able to achieve 76% macro-F 1 score using monolingual data in the binary case. We also show that large-scale monolingual data is still needed to create more accurate models, despite recent advances in multilingual approaches. An error analysis and experiments with multi-label classification show the difficulty of classifying certain types of toxic comments that appear less frequently in our data and highlights the need to develop models that are aware of different categories of toxicity.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Social media can be a powerful tool that enables virtual human interactions, connecting people and enhancing businesses' presence. On the other hand, since users feel somehow protected under their virtual identities, social media has also become a platform for hate speech and use of toxic language. Although hate speech is a crime in most countries, identifying cases in social media is not an easy task, given the massive amounts of data posted every day. Therefore, automatic approaches for detecting online hate speech have received significant attention in recent years <ref type="bibr" target="#b16">(Waseem and Hovy, 2016;</ref><ref type="bibr" target="#b4">Davidson et al., 2017;</ref><ref type="bibr" target="#b22">Zampieri et al., 2019b)</ref>. In this paper, we focus on the analysis and automatic detection of toxic comments. Our definition of toxic is similar to the one used by the Jigsaw competition, 1 where comments containing insults and obscene language are also considered, besides hate speech. 2 Systems capable of automatically identifying toxic comments are useful for platform's moderators and to select content for specific users (e.g. children). Nevertheless, there are multiple challenges specific to process toxic comments automatically, e.g. (i) toxic language may not be explicit, i.e. may not contain explicit toxic terms; (ii) there is a large spectrum of types of toxicity (e.g. sexism, racism, insult); (iii) toxic comments correspond to a minority of comments, which is fortunate, but means that automatic data-driven approaches need to deal with highly unbalanced data.</p><p>Although there is some work on this topic for other languages -e.g. Arabic <ref type="bibr" target="#b12">(Mubarak et al., 2017)</ref> and German <ref type="bibr" target="#b17">(Wiegand et al., 2018)</ref> -, most of the resources and studies available are for English <ref type="bibr" target="#b4">(Davidson et al., 2017;</ref><ref type="bibr" target="#b20">Wulczyn et al., 2017;</ref><ref type="bibr" target="#b9">Founta et al., 2018;</ref><ref type="bibr" target="#b10">Mandl et al., 2019;</ref><ref type="bibr" target="#b22">Zampieri et al., 2019b)</ref>. <ref type="bibr">3</ref> For Portuguese, only two previous works are available <ref type="bibr" target="#b8">(Fortuna et al., 2019;</ref><ref type="bibr" target="#b5">de Pelle and Moreira, 2017)</ref> and their datasets are considerably small, mainly when compared to resources available for English.</p><p>We present ToLD-Br (Toxic Language Dataset for Brazilian Portuguese), a new dataset with Twitter posts in the Brazilian Portuguese language. 4 A total of 21K tweets were manually annotated into seven categories: non-toxic, LGBTQ+phobia, obscene, insult, racism, misogyny and xenophobia. Each tweet has three annotations that were made by volunteers from a university in Brazil. Volunteers were selected taking into account demographic information, aiming to create a dataset as balanced as possible in regarding to demographic group biases. This is then the largest dataset available for toxic data analysis in social media for the Portuguese language and the first dataset with demographic information about annotators. <ref type="bibr">5</ref> We experiment with Brazilian Portuguese <ref type="bibr" target="#b14">(Souza et al., 2019)</ref> and Multilingual <ref type="bibr">(Wolf et al., 2019)</ref> BERT models <ref type="bibr" target="#b6">(Devlin et al., 2019)</ref> for the binary task of automatically classifying toxic comments, since similar models achieve state-of-the-art results for the same task in other languages <ref type="bibr" target="#b22">(Zampieri et al., 2019b)</ref>. Models fine-tuned on monolingual data achieve up to 76% of macro-F 1, improving 3 points over a baseline. Besides, BERT-based approaches with multilingual pre-trained models enable transfer learning and zero-shot learning. The OffensEval 2019 OLID dataset <ref type="bibr" target="#b21">(Zampieri et al., 2019a)</ref> is then used to experiment with (i) transfer-learning: where both OLID and ToLD-Br are used to fine-tune BERT; and, (ii) zero-shot learning: where BERT is fine-tuned using only OLID. Results highlight the importance of language-specific datasets, since transfer learning does not improve over monolingual models and zero-shot learning achieves only a macro-F 1 of 56%.</p><p>An error analysis is performed using our best model, where the worst-case scenario, i.e., classifying toxic comments as non-toxic, is further investigated, taking into account the fine-grained categories. Results show that categories with fewer examples in the dataset (racism and xenophobia) are more likely to be mislabelled than other classes, with the best performance being achieved by majority classes (insult and obscene). We also analyse the amount of data needed in order to achieve the best performance in binary classification. Models trained with few examples are only accurate in predicting the majority class (non-toxic). As the number of instances grow, the performance on the minority class (toxic) improves significantly.</p><p>there are multiple differences between Brazilian Portuguese lexicon and other variants of Portuguese. 5 ToLD-Br is available at: https://github.com/ JAugusto97/ToLD-Br Finally, we experiment with multi-label classification, where each different type of toxicity is automatically classified. This is a considerably harder problem than binary classification, where BERTbased models do not outperform the baseline.</p><p>Section 2 presents an overview of relevant previous work. Section 3 shows details about the ToLD-Br dataset. Material and methods are presented in Section 4, whilst results are discussed in Section 5. Finally, Section 6 shows a final discussion and future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Although multiple researchers have addressed the topic of hate speech (e.g. <ref type="bibr" target="#b16">Waseem and Hovy (2016)</ref>, <ref type="bibr" target="#b3">Chung et al. (2019)</ref>, <ref type="bibr" target="#b1">Basile et al. (2019)</ref>), we focus the literature review on previous work related to toxic comments detection, the topic of our paper. Due to space constraints, we only describe papers that create and use Twitter-based datasets and/or focus on the Brazilian Portuguese language.</p><p>English <ref type="bibr" target="#b4">Davidson et al. (2017)</ref> present a dataset with around 25K tweets annotated by crowdworkers as containing hate, offensive language, or neither. They build a feature-based classifier with TF-IDF transformation over n-grams, part-ofspeech information, sentiment analysis, network information (e.g., number of replies), among other features. Their best model, trained using logistic regression, achieves a macro-F 1 of 90. Founta et al. (2018) also rely on crowd-workers to annotate 80K tweets into eight categories: offensive, abusive, hateful speech, aggressive, cyberbullying, spam, and normal. They perform an exploratory approach to identify the categories that cause most confusion to crowd-workers. Their final, large-scale annotation is done using four categories: abusive, hateful, normal, or spam. OffensEval is a series of shared tasks focusing on offensive comments detection <ref type="bibr" target="#b22">(Zampieri et al., 2019b</ref><ref type="bibr" target="#b23">(Zampieri et al., , 2020</ref>. The OLID dataset (used in the 2019 edition) has around 14K tweets in English manually annotated as offensive or nonoffensive. The best model for the relevant task A (offensive versus non-offensive) uses a BERT-based classifier and achieves 82.9 of macro-F 1.</p><p>German A shared task (organized as part of Ger-mEval 2018) aimed to classify tweets in German categorized into offensive or non-offensive <ref type="bibr" target="#b17">(Wiegand et al., 2018)</ref>. They make available a manually annotated dataset with approximately 8.5K tweets.</p><p>The best system achieved 76.77 of F 1-score and was a feature-based ensemble approach.</p><p>Arabic <ref type="bibr" target="#b12">Mubarak et al. (2017)</ref> present a dataset with 1.1K manually annotated tweets into obscene, offensive, or clean. They experiment with lexicalbased approaches that achieve a maximum of 60 F 1-score. <ref type="bibr" target="#b13">Mulki et al. (2019)</ref> create a dataset with tweets in the Levantine dialect of Arabic manually annotated into normal, abusive, or hate (with approximately 5K tweets). The authors use featurebased approaches to induce models for ternary and binary scenarios, with best systems achieving 74.4 and 89.6 of F 1-score, respectively.</p><p>Spanish <ref type="bibr" target="#b2">Carmona et al. (2018)</ref> present a shared task aiming to detect aggressive tweets in Mexican Spanish. They manually annotate 11K tweets into aggressive or non-aggressive. The best system is a feature-based approach with macro-F 1 of 62.</p><p>Hindi <ref type="bibr" target="#b11">Mathur et al. (2018)</ref> present a dataset of around 3.6K tweets in Hinglish (spoken Hindi written using the Roman script). The dataset was annotated into three classes not offensive, abusive and hate-inducing by ten NLP researchers. A Convolutional Neural Network (CNN) architecture with transfer learning is used, where the model is trained with both Hinglish and English data (from (Davidson et al., 2017)), achieving 71.4% of F 1-score.</p><p>Portuguese de Pelle and Moreira (2017) make available a dataset with 1, 250 comments, extracted from comment sessions of g1.globo.com website, and annotated them into categories of offensive or non-offensive. The offensive class was also subdivided into racism, sexism, LGBTQ+phobia, xenophobia, religious in-tolerance, or cursing. They experiment with binary classification, using n-grams as features to SVM and NaiveBayes models. Best results are achieved with SVM reaching a weighted F1 score between 77 and 82, depending on different label interpretations. <ref type="bibr" target="#b8">Fortuna et al. (2019)</ref> describe a dataset with 5, 668 tweets classified as hate vs. non-hate, with the hate class further classified following a fine-grained hierarchy. Experiments with binary classification show a F 1 score of 78 using an LSTM-based architecture.</p><p>Multilingual HASOC was a shared task aiming to classify hate speech and offensive comments in English, German, and Hindi <ref type="bibr" target="#b10">(Mandl et al., 2019)</ref>. Their dataset contains around 7K tweets and Facebook posts manually annotated. Sub-task A sep-arates posts into hate speech or offensive versus neither; and, sub-task B separates posts containing hate speech or offence into three categories: hate speech, offensive or profane. Best performing systems in all languages used deep learning approaches. For OffensEval 2020 <ref type="bibr" target="#b23">(Zampieri et al., 2020)</ref>, a more extensive training data is available for English (over 9M tweets), although the annotation was made semi-automatically. Arabic, Danish, Greek, and Turkish datasets are also available with manually annotated labels. For all languages, best models are achieved using some variation of BERT.</p><p>Our work is different from previous approaches because we (i) release a large-scale dataset for a language other than English, that was created with the aim to reduce demographic biases; (ii) experiment with multilingual approaches, including transfer learning and zero-shot-learning; (iii) perform an analysis of the amount of data needed to train reliable models; and, (iv) experiment with multilabel classification, providing first insights into this challenge task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dataset</head><p>In this section, we describe the procedure adopted to create ToLD-Br and present its main features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data collection</head><p>We used the GATE Cloud's Twitter Collector 6 to collect posts on the Twitter platform from July to August 2019. We used two different strategies to select tweets for ToLD-Br, aiming to increase the probability of obtaining posts with toxic content, given that the volume of toxic tweets is significantly smaller than data without offensive language. Our first strategy searches for tweets that mention predefined hashtags or keywords. We chose predefined terms highly likely to belong to a toxic tweet in Brazilian Twitter, such as gay ("Gay tem que apanhar" -"Gay should be beaten up"), mulherzinha ("Mulherzinha, vai lavar louça" -"Sissy, go wash dishes"), and nordestino ("Nordestino preguiçoso" -"Lazy Northeastern"). However, using this strategy alone may hinder learning a model capable of generalising the concept of toxicity beyond the scope of keywords. Consequently, another strategy was adopted: we scraped tweets that mention influential users like Brazil's president Jair Bolsonaro and soccer player Neymar Jr, prone to receive abuse (around 50 influential users were monitored). Tweets collected through this method have no restrictions in terms of keywords and should broaden the scope of the data.</p><p>We collected more than 10M unique tweets and randomly selected 21K examples to compose the annotated corpus. We note that 12, 600 of these posts (60%) comes from the first strategy -predefined keywords -and the remaining are tweets from threads of predefined users. The data was pseudoanonymised before being sent for annotation, with all @ mentions replaced by @user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Corpus annotation</head><p>The annotation process started by choosing volunteers to perform the task of assigning labels for each example. For this, we made a public consultation at the Federal University of São Carlos (Brazil) to find candidate annotators (129 volunteers registered for the task). From these candidates, 42 were selected based on their demographic information, aiming to balance annotation bias as the interpretation of toxicity may vary. Each annotator labelled 1, 500 tweets, selecting one of the following categories:</p><p>LGBTQ+phobia, obscene, insult, racism, misogyny and/or xenophobia (or leaving it blank for none). Each tweet was annotated by three different annotators.</p><p>To evaluate the diversity among the annotators, we explore their profile. We emphasise that the identity of all annotators has been preserved. At this stage, we only survey general aspects of the volunteers who joined the labelling process. <ref type="table">Table 1</ref> presents the distribution of annotators regarding sex, sexual orientation, and ethnicity. To define these categories, we use the same values as the Brazilian Institute of Geography and Statistics, 7 in addition to giving the candidate the option of not declaring a value for each characteristic. Although we tried to keep the demographic aspects as balanced as possible when selecting the annotators, our pool of volunteers was still biased towards people identified as white and heterosexual (sex is a more balanced aspect than the others). The age of the annotators varies between 18 and 37 years, with most of them in the range between 19 and 23. <ref type="figure">Figure 1</ref> illustrates the age distribution.</p><p>We perform different data analysis over the dataset to better understand its properties. Inter-7 https://www.ibge.gov.br/en/home-eng. html  annotator agreement is calculated in terms of Krippendorf 's α <ref type="table" target="#tab_1">(Table 2)</ref>, since α is robust to multiple annotators, different degrees of disagreement and, missing values <ref type="bibr" target="#b0">(Artstein and Poesio, 2008</ref>). The</p><p>LGBTQ+phobia class shows the highest agreement, which may indicate that comments in this class have a more distinctive lexicon than other classes. The lowest agreement is seem in obscene and racism classes. Besides, we observed in the annotations many cases in which some examples were labelled as separate classes, although they intend  LGBTQ+phobia Obscene Insult Racism Misogyny Xenophobia viado <ref type="formula">(59)</ref> porra <ref type="formula">(332)</ref> puta <ref type="formula">(221)</ref> nego <ref type="formula">(6)</ref> putinha <ref type="formula">(38)</ref> sulista <ref type="formula">(12)</ref> boiola <ref type="formula">(15)</ref> caralho <ref type="formula">(317)</ref> caralho <ref type="formula">(150)</ref> branco <ref type="formula">(6)</ref> puta <ref type="formula">(22)</ref> carioca <ref type="formula">(7)</ref> viadinho <ref type="formula">(13)</ref> puta <ref type="formula">(268)</ref> cara <ref type="formula">(135)</ref> preto <ref type="formula">(4)</ref> piranha <ref type="formula">(19)</ref> fala <ref type="formula">(4)  sapatão (12)</ref> tomar <ref type="formula">(136)</ref> porra <ref type="formula">(122)</ref> nada <ref type="formula">(4)</ref> mulher <ref type="formula">(11)</ref> paulista <ref type="formula">(4)</ref> caralho <ref type="formula">(11)</ref> fuder <ref type="formula">(98)</ref> lixo <ref type="formula">(101)</ref> negão <ref type="formula">(3)</ref> vagabunda <ref type="formula">(11)</ref> gente <ref type="formula">(3)</ref> cara <ref type="formula">(10)</ref> cara <ref type="formula">(94)</ref> filho <ref type="formula">(92)</ref> cara <ref type="formula">(3)</ref> quer <ref type="formula">(8)</ref> nordestino <ref type="formula">(3)</ref> quer <ref type="formula">(9)</ref> merda <ref type="formula">(90)</ref> burro <ref type="formula">(87)</ref> falando <ref type="formula">(3)</ref> vaca <ref type="formula">(8)</ref> todo <ref type="formula">(3)</ref> homem <ref type="formula">(9)</ref> mano <ref type="formula">(87)</ref> tomar <ref type="formula">(86)</ref> vida <ref type="formula">(3)</ref> fica <ref type="formula">(6)</ref> ainda <ref type="formula">(3)</ref> todo <ref type="formula">(9)</ref> toma <ref type="formula">(85)</ref> merda <ref type="formula">(78)</ref> segue <ref type="formula">(2)</ref> onde <ref type="formula">(5)</ref> sendo <ref type="formula">(2)</ref> bicha <ref type="formula">(9)</ref> fazer <ref type="formula">(77)</ref> idiota <ref type="formula">(76)</ref> página <ref type="formula">(2)</ref> tudo <ref type="formula">(5)</ref> dança (2) to point the same concept. Classes like obscene and insult seem to have confused the annotators, which may indicate an intersection in these concepts. <ref type="table" target="#tab_3">Table 3</ref> shows examples of disagreements in the classification of obscene and insult. <ref type="table" target="#tab_4">Table 4</ref> presents the ten most frequent words for each class, after removing stopwords. It confirms the intersection between classes obscene and insult, with six out of ten words in common. For a quantitative analysis, <ref type="table" target="#tab_5">Table 5</ref> presents the Jaccard distance between the 100 most frequent words for each class. Obscene and insult show a considerably lower distance than other pairs (0.57), indicating that they have more words in common.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Dataset characteristics</head><p>For the purpose of training models for automatically classifying toxic comments, we must create aggregated annotations to provide only one binary label for each class. Different rules can be employed to aggregate the annotations, with different semantics. When we set an example as positive for toxicity only when all the annotators consider it to have the same category of offence, we insert bias to  the model to not accuse a comment as toxic unless the offence is evident. Since this is very restrictive, we can also use the majority rule, but there must still be a consensus among the annotators. A last option is to consider that only a positive annotation is sufficient to label the example as positive. This procedure acknowledges that annotators may have divergent views about what was said. It is a risky rule if we intend to create rigid systems that classify the tweets and take corrective or prohibitive actions. However, it is beneficial for training a model that "raises a flag" to help moderators to assess the com-</p><p>LGBTQ+phobia  ments. <ref type="table" target="#tab_7">Table 6</ref> shows the data distribution for each label and each aggregation strategy. For the sake of reproducibility and further usage, ToLD-Br is split into default training (80%), development (10%) and test (10%) sets using a stratified strategy. Besides, the corpus is released with all the annotations. Thus, future users of ToLD-Br will be able to use it with all the labels and with varying levels of agreement between the annotators. In this paper, we consider the least restrictive case, where if at least one annotator marked any offence category in an example, the example is positive for toxicity. Likewise, if a tweet was not tagged in any of these categories, it is considered non-toxic. We believe that it is essential that if any person feels uncomfortable with a post, it should be flagged as having a certain degree of toxicity. Therefore, a model built with this data must be able to identify offensive posts, even for a specific group of people.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Materials and Methods</head><p>In this section, we describe the techniques, tools, and other materials used in our experimental evaluation. As mentioned before, we restrict our experiments on the dataset labelled as positive when at least one annotator considers the example as toxic. We then investigate the effects of the number of instances in the training data, different algorithms to train a classification model, various scenarios considering single-and multilingual models, and perform an initial experiment with multi-label classification.</p><p>We use Bag-of-Words (BoW) to represent the examples and an AutoML model to build the baseline model <ref type="bibr">(BoW+AutoML)</ref>. For this, we use the auto-sklearn 8 library <ref type="bibr" target="#b7">(Feurer et al., 2019)</ref>. For our BERT-based models, we use the simpletransformers 9 library, that allows easy training and evaluation. We use default arguments for parameter tuning and define a seed to allow for reproducibility. Two versions of pretrained BERT language models are applied: Brazilian Portuguese BERT 10 <ref type="bibr" target="#b14">(Souza et al., 2019)</ref>, and Multilingual BERT 11 <ref type="bibr">(Wolf et al., 2019)</ref>.</p><p>ToLD-Br is used to fine-tune BERT-based models for our monolingual experiments, with monolingual BERT (BR-BERT) and multilingual BERT (M-BERT-BR). Although M-BERT-BR refers to the multilingual version of BERT, we refer to these two models as "monolingual models," as we trained using the dataset with Brazilian Portuguese sentences alone.</p><p>Using the multilingual model, we also carry out experiments in which we add data in English to train the models either through transfer learning or zero-shot learning. For these experiments we use the OLID data, concatenating the training and test splits into a single dataset. For transfer learning, we merged OLID and ToLD-Br to obtain a model with both languages as input, aiming to assess whether extra data in English helps in building better models (M-BERT(transfer)). For zero-shot learning, OLID is used alone at training time, building a model that did not have access to any data in Brazilian Portuguese (M-BERT(zero-shot)).</p><p>Through these experiments, we can assess the advantages of monolingual models, whether data from another language can directly benefit the classification, and whether a specific monolingual dataset is necessary or not.</p><p>We experiment with different sizes of the training set to assess the influence of the volume of data on the classification. For that, we evaluate the results on random subsets of the data. The size of each partition varies in a range between 10% and 100% adding 10% of the data at each iteration. For each step, we repeat the classification three times to minimise the probability of reporting results obtained by chance. Our best model (M-BERT-BR) is used for this experiment (c.f. Section 5).</p><p>Evaluation for binary classification is done in terms of precision, recall and, F 1-score per class and macro-F 1. We also analyse the confusion matrices of our systems in order to better visualise the performance of our models in each class, mainly focusing on an analysis of false negatives.</p><p>Although we mainly focus on binary classification, an initial approach for multi-label classification is also presented. We use the adaptation for the multi-label classification scenario available in simpletransformers. In this case, the transformer's output consists of six neurons, each representing one of the labels. These neurons are considered independent in the training and prediction process. Thus, when an output neuron is activated, we set the label represented by this neuron to positive. Besides, we evaluate the performance of a baseline based on BoW+AutoML, where we train an AutoML model for multilabel classification. Evaluation is done in terms of Hamming loss and average precision <ref type="bibr">(Tsoumakas et al., 2009)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Discussion</head><p>This section shows the results of our experiments in classifying toxic comments using ToLD-Br.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Binary Classification</head><p>For evaluating our models, we are particularly interested in models with high performance in the positive class (classification of toxic comments). The worst case scenario are false negatives, i.e. toxic comments classified as non-toxic. Tables 7 through 11 summarises the results for each model. BoW+AutoML is already a competitive model, achieving 74% of macro-F 1, as shown in <ref type="table" target="#tab_9">Table  7</ref> and <ref type="figure">Figure 2a</ref>.      The monolingual models BR-BERT and M-BERT-BR <ref type="table" target="#tab_10">(Tables 8 and 9, respectively)</ref> show very similar performances in all metrics, with BR-BERT being slightly better in terms of macro-F 1. However, M-BERT-BR is better in terms of F 1-score for the positive class and shows fewer false negatives than BR-BERT <ref type="figure">(Figure 2b</ref> for BR-BERT and <ref type="figure">Figure 2c</ref> for M-BERT-BR).</p><p>M-BERT(transfer) ( <ref type="table" target="#tab_12">Table 10)</ref> does not out- perform the monolingual models and it also shows more false negatives than M-BERT-BR <ref type="figure">(Figure 2e</ref>). On the other hand, the number of false negatives in BR-BERT (267) is slightly higher than the number of false negatives in M-BERT(transfer) (207). Finally, M-BERT(zero-shot) <ref type="table" target="#tab_13">(Table 11)</ref> is the worst model, as expected. It performs particularly bad when classifying the positive class, achieving only 43% of F 1-score for this class, mainly caused by its high number of false negatives <ref type="figure">(Figure 2d</ref>). In summary, transfer learning does not seem to improve over the overall performance of monolingual models. Based on the analysis of false negatives, M-BERT-BR appears as our best model. Zero-shot learning shows a very low performance, being particularly bad in the positive class.</p><p>Error Analysis We also analyse the performance of our best model (M-BERT-BR) in each finegrained class. The idea is to identify which toxic classes are most difficult to be classified as toxic by our binary classifier. As false negatives are a critical type of error in our application, <ref type="table" target="#tab_1">Table 12</ref> shows the false negative rate (false negatives / expected positives) for each toxic class. The ratio of false negatives is inversely proportional to the number of examples for a specific class. Insult and obscene, the largest classes, show the lowest false negative rate, whilst the highest rates are shown by classes with less examples (racism and xenophobia). Therefore, in order to improve classification models, these aspects of the imbalanced data need to be taken into account and further studied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>False negative rate</head><p>LGBTQ+phobia  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Importance of Large Datasets</head><p>In this experiment, we highlight the importance of collecting a considerable amount of examples, as toxicity can be expressed in many different ways. We separated the training data into 10 random splits from 10% to 100% of the data, increasing 10% of data at each step, and trained M-BERT-BR with three random samples for each step. <ref type="figure">Figure 3</ref> shows the mean recall, precision and F 1-score for the positive and negative classes, respectively, for each </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Multi-Label Classification</head><p>We experiment with multi-label classification, building a model using the Multilingual BERT (similar to M-BERT-BR). Our baseline is a set of BoW+AutoML models trained using Binary Relevance (Tsoumakas et al., 2009) for multi-label classification. The BERT-based models adopt a score threshold of 0.5 in the output neuron to deal with multi-label. If the activation for a label in the output layer is higher than the threshold, we consider it positive. The baseline model obtained 0.08 and 0.20 of Hamming loss and average precision, respectively, while M-BERT-BR resulted in 0.07 and 0.19 for these measures, respectively. <ref type="figure" target="#fig_2">Figure 4</ref> displays the confusion matrices obtained by M-BERT-BR. This scenario is considerably more challenging than binary classification. The positive class of each label corresponds to a subset of the examples labelled as toxic. Thus, it is likely that the number of instances for these classes will be insufficient for the model to learn. Besides, the problem of unbalanced classes becomes evident (c.f. <ref type="table" target="#tab_7">Table 6</ref>). As a consequence, it is clear that labels with a small number of positive examples, like racism, misogyny, xenophobia, and LGBTQ+phobia were almost entirely classified as negative. In contrast, for obscene and insult, labels with a considerable amount of positive examples, the model was capable of classifying some examples correctly. In all cases, besides insult, the baseline performs slightly better for the positive class (which justify the higher Hamming loss). This setback is likely due to the difficulty of the neural model to learn with few examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Concluding Remarks</head><p>In this paper, we present ToLD-Br: a dataset for the classification of toxic comments on Twitter in Brazilian Portuguese. Through a wide and comprehensive analysis, we demonstrated the need for this dataset for studies on automatic classification of toxic comments. We highlight that monolingual approaches for this task still outperform multilingual experiments and that large-scale datasets are needed for building reliable models. Also, we show that there are still challenges to be overcome, such as the naturally significant class imbalance when dealing with multi-label classification.</p><p>As future work, in addition to deal with class imbalance, we intend to evaluate if aggregating classes with high divergences between annotators can build more reliable models. Besides, we intend to assess the benefits of adding unlabelled data to ToLD-Br to use semi-supervised techniques.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>Confusion matrices for each model (a) BoW+AutoML (Baseline); (b) BR-BERT; (c) M-BERT-BR; (d) M-BERT(transfer); (e) M-BERT(zero-shot) Precision and recall for different sizes of the training dataset for the (a) positive and (b) negative classes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Confusion matrices for each label (a)LGBTQ+phobia; (b) Obscene; (c) Insult; (d) Racism; (e) Misogyny; (f) Xenophobia.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Krippendorff 's α for each label.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Ann 1 Ann 2 Ann 3 o fdp do filho dela nao parava de tocar auto pra c*****o [...] Insult None Obscene her sob son did not stop to play loud as f**k [...] [...] VAI SE F***R IRMÃO VC NÃOÉ FELIZ PQ NAO QUER Obscene Insult Insult [...] f**k you brother you are not happy because you do not want to be "Aonde tem um monte que fala mal, mas ninguém vai embora do morro." acha que alguém mora aqui por que quer, c*****o!? Que idéia. [...] Obscene Obscene Insult "Where there are loads saying bad things, but nobody leaves the slum." who thinks that someone lives here because they want, f**k!? What an idea. [...]</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Example of annotation divergence.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table /><note>The most common words of each class and the number of sentences they occur (within parentheses).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Jaccard distance between all pair of classes.</figDesc><table><row><cell>(a) LGBTQ+phobia; (b) Obscene; (c) Insult; (d)</cell></row><row><cell>Racism; (e) Misogyny; (f) Xenophobia.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 :</head><label>6</label><figDesc>Dataset distribution considering different types of label aggregation.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7</head><label>7</label><figDesc></figDesc><table><row><cell></cell><cell cols="2">: BoW + AutoML</cell><cell></cell></row><row><cell></cell><cell cols="3">Precision Recall F1-score</cell></row><row><cell>0</cell><cell>0.77</cell><cell>0.80</cell><cell>0.79</cell></row><row><cell>1</cell><cell>0.76</cell><cell>0.73</cell><cell>0.74</cell></row><row><cell>Macro Avg</cell><cell>0.76</cell><cell>0.76</cell><cell>0.76</cell></row><row><cell>Weighted Avg</cell><cell>0.76</cell><cell>0.77</cell><cell>0.76</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 8</head><label>8</label><figDesc></figDesc><table><row><cell></cell><cell cols="2">: BR-BERT</cell><cell></cell></row><row><cell></cell><cell cols="3">Precision Recall F1-score</cell></row><row><cell>0</cell><cell>0.81</cell><cell>0.69</cell><cell>0.75</cell></row><row><cell>1</cell><cell>0.69</cell><cell>0.82</cell><cell>0.75</cell></row><row><cell>Macro Avg</cell><cell>0.75</cell><cell>0.75</cell><cell>0.75</cell></row><row><cell>Weighted Avg</cell><cell>0.76</cell><cell>0.75</cell><cell>0.75</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 9</head><label>9</label><figDesc></figDesc><table><row><cell></cell><cell cols="2">: M-BERT-BR</cell><cell></cell></row><row><cell></cell><cell cols="3">Precision Recall F1-score</cell></row><row><cell>0</cell><cell>0.80</cell><cell>0.74</cell><cell>0.77</cell></row><row><cell>1</cell><cell>0.72</cell><cell>0.79</cell><cell>0.75</cell></row><row><cell>Macro Avg</cell><cell>0.76</cell><cell>0.76</cell><cell>0.76</cell></row><row><cell>Weighted Avg</cell><cell>0.77</cell><cell>0.76</cell><cell>0.76</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 10</head><label>10</label><figDesc></figDesc><table><row><cell></cell><cell cols="2">: M-BERT(transfer)</cell><cell></cell></row><row><cell></cell><cell cols="3">Precision Recall F1-score</cell></row><row><cell>0</cell><cell>0.59</cell><cell>0.83</cell><cell>0.69</cell></row><row><cell>1</cell><cell>0.63</cell><cell>0.32</cell><cell>0.43</cell></row><row><cell>Macro Avg</cell><cell>0.61</cell><cell>0.58</cell><cell>0.56</cell></row><row><cell>Weighted Avg</cell><cell>0.61</cell><cell>0.60</cell><cell>0.57</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 11</head><label>11</label><figDesc></figDesc><table><row><cell>: M-BERT(zero-shot)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 12 :</head><label>12</label><figDesc>Error analysis for each label.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head></head><label></label><figDesc>data split. With few training examples, the model only performs well on the majority class, but as the number of instances grows, recall for the negative class starts decreasing while recall for the positive class increases, and precision rises for both classes. At least 6K examples seems to be necessary to achieve reliable results, while previous work for Portuguese reports the largest dataset with only 5, 668 examples. This highlights the importance of ToLD-Br, as a large-scale dataset.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">https://cloud.gate.ac.uk/shopfront/ displayItem/twitter-collector</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">https://automl.github.io/auto-sklearn 9 github.com/ThilinaRajapakse/ simpletransformers</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12"> midas.ufscar.br   </note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Acknowledgements</head><p>We thank the volunteers from UFSCar that made this research possible. The MIDAS group 12 from the Federal University of São Carlos (UFSCar), Brazil, funded the annotation process. The SoBig-Data TransNational Access program (EU H2020, grant agreement: 654024) funded Diego Silva and João Leite's visits to the University of Sheffield.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Survey article: Inter-coder agreement for computational linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><surname>Artstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Poesio</surname></persName>
		</author>
		<idno type="DOI">10.1162/coli.07-034-R2</idno>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="555" to="596" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">SemEval-2019 task 5: Multilingual detection of hate speech against immigrants and women in twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valerio</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristina</forename><surname>Bosco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisabetta</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Debora</forename><surname>Nozza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viviana</forename><surname>Patti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco Manuel Rangel</forename><surname>Pardo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuela</forename><surname>Sanguinetti</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/S19-2007</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
		<meeting>the 13th International Workshop on Semantic Evaluation<address><addrLine>Minneapolis, Minnesota, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="54" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Overview of mex-a3t at ibereval 2018: Authorship and aggressiveness analysis in mexican spanish tweets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguelángelálvarez</forename><surname>Carmona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Estefanía</forename><surname>Guzmán-Falcón</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuel</forename><surname>Montes Y Gómez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><forename type="middle">Jair</forename><surname>Escalante</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luis</forename><forename type="middle">Villaseñor</forename><surname>Pineda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Verónica</forename><surname>Reyes-Meza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><forename type="middle">Rico</forename><surname>Sulayes</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Workshop on Evaluation of Human Language Technologies for Iberian Languages</title>
		<meeting>the Third Workshop on Evaluation of Human Language Technologies for Iberian Languages</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2150</biblScope>
			<biblScope unit="page" from="74" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">CONAN -COunter NArratives through nichesourcing: a multilingual dataset of responses to fight online hate speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Ling</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elizaveta</forename><surname>Kuzmenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Serra Sinem Tekiroglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guerini</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1271</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2819" to="2829" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Automated hate speech detection and the problem of offensive language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dana</forename><surname>Warmsley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">W</forename><surname>Macy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ingmar</forename><surname>Weber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International AAAI Conference on Web and Social Media</title>
		<meeting>the 11th International AAAI Conference on Web and Social Media</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="512" to="515" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Offensive comments in the Brazilian web: a dataset and baseline results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rogers</forename><surname>Prates De Pelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viviane</forename><forename type="middle">P</forename><surname>Moreira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the VI Brazilian Workshop on Social Network Analysis and Mining</title>
		<meeting>the VI Brazilian Workshop on Social Network Analysis and Mining<address><addrLine>Porto Alegre, RS, Brazil. SBC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="510" to="519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Long and Short Papers</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Auto-sklearn: efficient and robust automated machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Feurer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katharina</forename><surname>Eggensperger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jost</forename><forename type="middle">Tobias</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuel</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automated Machine Learning</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="113" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A hierarchically-labeled Portuguese hate speech dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paula</forename><surname>Fortuna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">João</forename><surname>Rocha Da</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leo</forename><surname>Soler-Company</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sérgio</forename><surname>Wanner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nunes</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W19-3510</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Workshop on Abusive Language Online</title>
		<meeting>the Third Workshop on Abusive Language Online<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="94" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Large scale crowdsourcing and characterization of twitter abusive behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Constantinos</forename><surname>Antigoni Maria Founta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Despoina</forename><surname>Djouvas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilias</forename><surname>Chatzakou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Leontiadis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gianluca</forename><surname>Blackburn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Athena</forename><surname>Stringhini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Vakali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Sirivianos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kourtellis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth International AAAI Conference on Web and Social Media</title>
		<meeting>the Twelfth International AAAI Conference on Web and Social Media<address><addrLine>Stanford, California</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="491" to="500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Overview of the HASOC Track at FIRE 2019: Hate Speech and Offensive Content Identification in Indo-European Languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Mandl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandip</forename><surname>Modha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prasenjit</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daksh</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohana</forename><surname>Dave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chintak</forename><surname>Mandlia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Patel</surname></persName>
		</author>
		<idno type="DOI">10.1145/3368567.3368584</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th Forum for Information Retrieval Evaluation</title>
		<meeting>the 11th Forum for Information Retrieval Evaluation<address><addrLine>Kolkata, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="14" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Detecting offensive tweets in Hindi-English code-switched language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Puneet</forename><surname>Mathur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajiv</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramit</forename><surname>Sawhney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Debanjan</forename><surname>Mahata</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W18-3504</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth International Workshop on Natural Language Processing for Social Media</title>
		<meeting>the Sixth International Workshop on Natural Language Processing for Social Media<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="18" to="26" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Abusive language detection on Arabic social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamdy</forename><surname>Mubarak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kareem</forename><surname>Darwish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walid</forename><surname>Magdy</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W17-3008</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Abusive Language Online</title>
		<meeting>the First Workshop on Abusive Language Online<address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="52" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">L-HSAB: A Levantine twitter dataset for hate speech and abusive language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hala</forename><surname>Mulki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hatem</forename><surname>Haddad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chedi</forename><surname>Bechikh Ali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Halima</forename><surname>Alshabani</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W19-3512</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Workshop on Abusive Language Online</title>
		<meeting>the Third Workshop on Abusive Language Online<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="111" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Lotufo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.10649</idno>
		<title level="m">Portuguese named entity recognition using bert-crf</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Mining multi-label data</title>
	</analytic>
	<monogr>
		<title level="m">Grigorios Tsoumakas, Ioannis Katakis, and Ioannis Vlahavas</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="667" to="685" />
		</imprint>
	</monogr>
	<note>Data mining and knowledge discovery handbook</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Hateful symbols or hateful people? predictive features for hate speech detection on twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeerak</forename><surname>Waseem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Hovy</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N16-2013</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL Student Research Workshop</title>
		<meeting>the NAACL Student Research Workshop<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="88" to="93" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Wiegand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melanie</forename><surname>Siegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Ruppenhofer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Overview of the GermEval</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Shared Task on the Identification of Offensive Language</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of GermEval 2018, 14th Conference on Natural Language Processing (KON-VENS 2018)</title>
		<meeting>GermEval 2018, 14th Conference on Natural Language Processing (KON-VENS 2018)<address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R&amp;apos;emi</forename><surname>Louf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.03771</idno>
		<idno>abs/1910.03771</idno>
		<title level="m">Morgan Funtowicz, and Jamie Brew. 2019. HuggingFace&apos;s Transformers: State-of-the-art natural language processing</title>
		<imprint>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Ex Machina: Personal Attacks Seen at Scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellery</forename><surname>Wulczyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nithum</forename><surname>Thain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Dixon</surname></persName>
		</author>
		<idno type="DOI">10.1145/3038912.3052591</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on World Wide Web</title>
		<meeting>the 26th International Conference on World Wide Web<address><addrLine>Perth, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1391" to="1399" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Predicting the type and target of offensive posts in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcos</forename><surname>Zampieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shervin</forename><surname>Malmasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noura</forename><surname>Farra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ritesh</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1144</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1415" to="1420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">SemEval-2019 task 6: Identifying and categorizing offensive language in social media (Of-fensEval)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcos</forename><surname>Zampieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shervin</forename><surname>Malmasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noura</forename><surname>Farra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ritesh</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/S19-2010</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
		<meeting>the 13th International Workshop on Semantic Evaluation<address><addrLine>Minneapolis, Minnesota, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="75" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">SemEval-2020 Task 12: Multilingual Offensive Language Identificationin Social Media (Offen-sEval 2020)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcos</forename><surname>Zampieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shervin</forename><surname>Malmasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noura</forename><surname>Farra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ritesh</forename><surname>Kumar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<pubPlace>Barcelona, Spain</pubPlace>
		</imprint>
	</monogr>
	<note>In To appear in the Proceedings of the 14th International Workshop on Semantic Evaluation</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
