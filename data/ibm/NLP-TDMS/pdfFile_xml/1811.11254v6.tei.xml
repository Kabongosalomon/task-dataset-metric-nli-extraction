<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ShelfNet for Fast Semantic Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juntang</forename><surname>Zhuang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Yale University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junlin</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Yale University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Gu</surname></persName>
							<email>ling@nii.ac.jp</email>
							<affiliation key="aff1">
								<orgName type="institution">National Institute of Infomatics</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicha</forename><forename type="middle">C</forename><surname>Dvornek</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Yale University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">ShelfNet for Fast Semantic Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T06:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we present ShelfNet, a novel architecture for accurate fast semantic segmentation. Different from the single encoder-decoder structure, ShelfNet has multiple encoder-decoder branch pairs with skip connections at each spatial level, which looks like a shelf with multiple columns. The shelf-shaped structure can be viewed as an ensemble of multiple deep and shallow paths, thus improving accuracy. We significantly reduce computation burden by reducing channel number, at the same time achieving high accuracy with this unique structure. In addition, we propose a shared-weight strategy in the residual block which reduces parameter number without sacrificing performance. Compared with popular non real-time methods such as PSPNet, our ShelfNet achieves 4Ã— faster inference speed with similar accuracy on PASCAL VOC dataset. Compared with real-time segmentation models such as BiSeNet, our model achieves higher accuracy at comparable speed on the Cityscapes Dataset, enabling the application in speed-demanding tasks such as street-scene understanding for autonomous driving. Furthermore, our ShelfNet achieves 79.0% mIoU on Cityscapes Dataset with ResNet34 backbone, outperforming PSPNet and BiSeNet with large backbones such as ResNet101. Through extensive experiments, we validated the superior performance of ShelfNet. We provide link to the implementation https://github.com/ juntang-zhuang/ShelfNet-lw-cityscapes.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Semantic segmentation is the key to image understanding <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b25">26]</ref>, and is related to other tasks such as scene parsing, object detection and instance segmentation <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b46">47]</ref>. The task of semantic segmentation is to assign each pixel a unique class label, and can be viewed as a dense classification problem. Recently many convolutional neural networks (CNN) have achieved remarkable results on semantic segmentation tasks <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b43">44</ref>]. However, the success of most deep learning models for semantic segmentation comes at a price of heavy computation burden. The training of CNNs on a large dataset such as PASCAL VOC <ref type="bibr" target="#b7">[8]</ref> and Cityscapes <ref type="bibr" target="#b5">[6]</ref> typically takes several days on a single GPU, and the running time during test phase is usually hundreds of milliseconds (ms) or more, which hinders their application in time-efficiency demanding tasks.</p><p>Real-time semantic segmentation has important applications, e.g., street scene understanding and autonomous driving. Prior research on accelerating semantic segmentation includes removing redundancy of deep neural networks through pruning <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b12">13]</ref> and distillation <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b34">35]</ref>. However, the running speed of these methods is typically insufficient for fast semantic segmentation. Another way to get faster running speed is to use a smaller model keeping the same structure, but this strategy would inevitably yield lower accuracy <ref type="bibr" target="#b44">[45]</ref>. Therefore, we aim to propose a new architecture for fast segmentation while maintaining satisfying accuracy.</p><p>Most state-of-the-art semantic segmentation models belong to the family of single "encoder-decoder" structure, where the image is progressively down-sampled then upsampled. Here, we propose ShelfNet, which employs a different structure like a multi-column shelf. As illustrated in <ref type="figure" target="#fig_1">Fig. 1(a)</ref>, multi-scale features encoded by different stages of a CNN backbone (e.g. ResNet) are fed into the "segmentation shelf". The segmentation shelf comprises of multiple encoder-decoder pairs with skip connections at each spatial resolution level. The unique structure increases the number of paths to improve information flow in the network, thus increasing the segmentation accuracy. We demonstrate the high accuracy and fast running speed of our ShelfNet on PASCAL VOC, PASCAL Context and Cityscapes datasets.</p><p>Our main contributions are listed as follows: 1. We propose a novel architecture, ShelfNet <ref type="figure" target="#fig_1">(Fig. 1)</ref>, for accurate and fast semantic segmentation. Our ShelfNet has a shelf structure of multiple encoder-decoder pairs to improve information flow in the network.</p><p>2. In the segmentation shelf, we propose to share the   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Semantic Segmentation</head><p>Semantic segmentation has been a hot topic for many years. Before the recent rise of deep learning, early approaches mainly relied on handcrafted features such as HOG <ref type="bibr" target="#b6">[7]</ref> and SIFT <ref type="bibr" target="#b23">[24]</ref>. Since the resurgence of deep learning, especially fully convolutional neural networks (FCN) <ref type="bibr" target="#b22">[23]</ref>, deep learning models have been widely used for semantic segmentation.</p><p>Like FCN, many models such as U-Net <ref type="bibr" target="#b35">[36]</ref>, RefineNet <ref type="bibr" target="#b17">[18]</ref> and SegNet <ref type="bibr" target="#b1">[2]</ref> also have an encoder-decoder structure, and use a "convolution-downsample" strategy for the encoder. The downsample layer reduces spatial resolution and increases channel number. <ref type="bibr" target="#b2">[3]</ref> based on dilated convolution. Instead of down-sampling, a dilated CNN gradually increases dilation rate to increase the size of receptive field, but does not shrink the size of the output tensor. Therefore, compared with the "conv-downsample" strategy, the dilated CNN has a better spatial resolution at a higher computation cost. For example, a standard ResNet shrinks image size to 1/32 of input size, while a dilated ResNet shrinks image size to 1/4 of input size. State-of-the-art networks, such as DeepLab <ref type="bibr" target="#b2">[3]</ref>, PSPNet <ref type="bibr" target="#b43">[44]</ref> and EncNet <ref type="bibr" target="#b42">[43]</ref>, are based on dilated CNN, and thus are not suitable for timeefficiency demanding tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Chen et al. proposed DeepLab</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Real-time Semantic Segmentation</head><p>There have been several approaches for real-time semantic segmentation by modifying a large network to a light-weight version. For example, ICNet <ref type="bibr" target="#b44">[45]</ref> is a modification of PSPNet and deals with multiple image scales, but the robustness to low-resolution is not extensively validated. Light-Weight RefineNet is a modification of Re-fineNet <ref type="bibr" target="#b26">[27]</ref>, where the kernel sizes of some convolutional layers are reduced from 3 Ã— 3 to 1 Ã— 1. However, most of the real-time models, such as GUN <ref type="bibr" target="#b24">[25]</ref>, EffConv <ref type="bibr" target="#b33">[34]</ref> and ENet <ref type="bibr" target="#b30">[31]</ref>, achieve high running speed at the cost of low accuracy. The recently proposed BiSeNet <ref type="bibr" target="#b40">[41]</ref> uses a shallow branch to capture spatial information, and a deep branch to capture context information. However, it's difficult for BiSeNet to deal with high-level features combined from different branches. All models mentioned in this paragraph can be viewed as modifications of the encoderdecoder structure. In this project, we propose a network with multiple encoder-decoder pairs (e.g. columns 3 and 4 in <ref type="figure" target="#fig_1">Fig. 1</ref>) and skip connections at different spatial levels (e.g. rows A-D in <ref type="figure" target="#fig_1">Fig. 1</ref>), and demonstrate its superior performance over previous methods both in inference speed and segmentation accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Structure of ShelfNet</head><p>We propose ShelfNet, a multi-column convolutional neural network for semantic segmentation as shown in <ref type="figure" target="#fig_1">Fig.  1</ref>. Different from the standard single encoder-decoder structure, our shelf-structure network introduces more paths to improve the information flow.</p><p>As shown in <ref type="figure" target="#fig_1">Fig 1,</ref> our ShelfNet relies on a backbone network. Different CNN architectures can be used as the backbone, such as ResNet <ref type="bibr" target="#b13">[14]</ref>, Xception <ref type="bibr" target="#b4">[5]</ref> and DenseNet <ref type="bibr" target="#b15">[16]</ref>. The backbone outputs feature maps of different spatial scales, named as rows A to D in <ref type="figure" target="#fig_1">Fig. 1</ref>. Take ResNet backbone for example, the spatial sizes of feature maps are 1/4, 1/8, 1/16, 1/32 of the input size at levels A-D, respectively. Feature maps encoded by different stages of the backbone are fed into the segmentation shelf.</p><p>The segmentation shelf has a shelf-shaped multi-column structure where columns are named with numbers 1 to 4. We name column 3 as an encoder branch (down-sample branch), and name column 2 and 4 as decoder branches (upsample branch). Between adjacent columns (e.g. column 3 and 4), there are skip connections at different spatial scale stages (A-D).</p><p>Stage-wise features encoded by column 1 are then passed to succeeding Shared-weight blocks (S-block) in column 2. The S-Block serves as a residual-block but with fewer parameters. Here, the S-block combines the features passed from the vertical direction and lateral direction. As shown in <ref type="figure" target="#fig_1">Fig. 1(b)</ref>, the two inputs are first summed up before feeding into the succeeding part. For the exception at A3 and D4 where there is only one input, the summing up step is skipped. As a residual-block, the input and output of a S-block has the same shape.</p><p>For the encoder branch at column 3, the feature maps are passed into a convolution layer with a stride of 2 (conv stride in <ref type="figure" target="#fig_1">Fig. 1</ref>), to halve the spatial size and double the channel number (e.g. B3 to C3). Similarly, in the decoder branches at column 2 and 4, feature maps are passed into a transposed convolution layer (conv trans in <ref type="figure" target="#fig_1">Fig. 1</ref>) with a stride of 2, to double the spatial size and halve the channel number (e.g. C2 to B2). Finally, output from block A4 goes through a 1 Ã— 1 convolutional layer and a softmax operation to generate the final segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Channel Reduction for Faster Inference Speed</head><p>The backbone feature maps typically have a large channel number (e.g. 2048 at level D for ResNet50). For faster inference speed, we reduce the number of feature map channels with 1 Ã— 1 convolution followed by a batch-norm layer and ReLU activation (e.g. for ResNet50, channel number of feature maps are reduced from 256, 512, 1024, 2048 to 64, 128, 256, 512 for levels A-D respectively). As shown in column 1 in <ref type="figure" target="#fig_1">Fig. 1</ref>, channel number is reduced by a 1 Ã— 1 convolution, batch-normalization and ReLU activation.</p><p>We theoretically show that reducing channel number significantly improves inference speed. The computation burden of a convolution with stride 1 is</p><formula xml:id="formula_0">H Ã— W Ã— K 2 Ã— C in Ã— C out ,</formula><p>where H, W are spatial sizes, K is the kernel size, and C in are C out are channel number of input and output respectively. Simply reducing C in and C out by a factor of 4 quadratically reduces the computation burden to <ref type="bibr">1 16</ref> . Even with two extra columns in the shelf structure, the computation burden is 2 Ã— 1 16 = 1 8 , thus is faster. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">ShelfNet as an Ensemble of FCNs</head><p>ShelfNet can also be viewed as an ensemble of FCNs. Andreas et al. <ref type="bibr" target="#b36">[37]</ref> argued that ResNet behaves like an ensemble of shallow networks, because the residual connections provide multiple paths for efficient information flow. Similarly, ShelfNet provides multiple paths of information flow. For ease of representation, we denote backbone as column 0 and list a few paths here as an example as shown in <ref type="figure">Fig. 2</ref></p><formula xml:id="formula_1">: (1) (Blue line in Fig. 2) A0 â†’ A1 â†’ A2 â†’ A3 â†’ A4, (2) (Green line in Fig. 2) A0 â†’ A1 â†’ A2 â†’ A3 â†’ B3 â†’ C3 â†’ C4 â†’ B4 â†’ A4, (3) (Red line in Fig. 2)A0 â†’ B0 â†’ B1 â†’ B2 â†’ A2 â†’ A3 â†’ A4, (4) (Orange line in Fig. 2) A0 â†’ B0 â†’ C0 â†’ D0 â†’ D1 â†’ D2 â†’ C2 â†’ B2 â†’ B3 â†’ C3 â†’ C4 â†’ B4 â†’ A4.</formula><p>Each path can be viewed as a variant of FCN (except that there are pooling layers in ResNet backbone). Therefore, ShelfNet has the potential to capture more complicated features and produce higher accuracy.</p><p>The effective number of FCN paths in ShelfNet is much larger than SegNet <ref type="bibr" target="#b1">[2]</ref>, which is a single encoder-decoder pair with skip connections. The total number of paths grows exponentially with the number of encoder-decoder pairs (e.g columns 0 and 2, 3 and 4 are two pairs) and the number of spatial levels (e.g., A to D in <ref type="figure" target="#fig_1">Fig. 1</ref>). Not considering the effective paths generated from residual connections in backbone, for a SegNet with 4 spatial levels (A-D), the total number of FCN paths is 4; for a ShelfNet with the same spatial levels, the total number of FCN paths is 29. The unique structure of ShelfNet significantly increases the number of effective FCN paths, thus achieving a higher accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Ensemble of Deep and Shallow Paths</head><p>GridNet <ref type="bibr" target="#b8">[9]</ref> also has a multi-column structure. We illustrate the key difference between ShelfNet and GridNet in <ref type="figure" target="#fig_3">Fig. 3</ref> by simplifying the structure. When stacking the same number of encoder-decoder blocks, the information path in ShelfNet can go much deeper. For example, the deepest path in ShelfNet goes through all 16 blocks, while GridNet can only use 10 blocks. The difference in depth is even bigger with more "downsample-upsample" branch pairs. Our ShelfNet takes advantage of ensemble information from a variety of shallow and deep paths, like the success of ResNet. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Shared-weights Residual Block (S-block)</head><p>Compared with SegNet, the larger effective number of FCN paths comes at a price of extra blocks. To reduce the model size, we propose a modified residual block (S-Block) as shown in <ref type="figure" target="#fig_1">Fig. 1(b)</ref>. Here we use it only in the segmentation shelf. The two convolutional layers in the same block share the same weights while the two batch normalization layers are different. The shared-weights design that reuses weights of convolution is similar to the recurrent convolutional neural network (RCNN) <ref type="bibr" target="#b0">[1]</ref> and recursive convolutional network <ref type="bibr" target="#b16">[17]</ref>. A drop-out layer is added between two convolutional layers to avoid overfitting. The sharedweights residual block combines the strength of skip connection, recurrent convolution and drop-out regularization while using many fewer parameters than a standard residual block.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments and Results</head><p>We carried out extensive experiments to validate the fast inference speed and high accuracy of ShelfNet on three public datasets: PASCAL VOC 2012, PASCAL Context and Cityscapes. Performance is measured by mean intersection over union (mIoU). To test inference speed, we feed a single image to the network, and measure the mean running time of 100 repetitions. We first introduce the datasets and inplementation details, then provide an ablation analysis for ShelfNet, finally we compare the performance with stateof-the-art methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets and Implementation Details</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">PASCAL VOC 2012</head><p>PASCAL VOC 2012 <ref type="bibr" target="#b7">[8]</ref> contains 20 object classes with one background class. We use the augmented PASCAL VOC dataset <ref type="bibr" target="#b11">[12]</ref> containing 10582, 1449 and 1456 images for training, validation and test set. MS COCO <ref type="bibr" target="#b19">[20]</ref> is also used as extra training data to generate higher accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">PASCAL-Context</head><p>PASCAL-Context dataset <ref type="bibr" target="#b25">[26]</ref> provides dense labels for the whole image with 59 classes and a background class. There are 4,998 training images and 5,105 test images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Cityscapes</head><p>Cityscapes <ref type="bibr" target="#b5">[6]</ref> consists of images for 50 cities in different seasons and are annotated with 19 categories. It contains 2975, 500 and 1525 fine-labeled images for training, validation and test respectively. More than 20,000 images with coarse annotations are also provided.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.4">Implementation Details</head><p>All models are implemented with PyTorch <ref type="bibr" target="#b31">[32]</ref>. Learning rate is scheduled in the form lr = baselr Ã— (1 âˆ’ iter total iter ) power with power = 0.9 as in <ref type="bibr" target="#b42">[43]</ref>, and crossentropy loss is used. The weight-decay is set as 10 âˆ’4 . For Pascal VOC, the model is first trained with Stochastic Gradient Descent (SGD) optimizer on MS COCO dataset for 30 epochs with a base learning rate of 0.01, then trained on PASCAL augmented dataset for 50 epochs with a base learning rate of 0.001, and finally fine-tuned on original PASCAL VOC dataset for 50 epochs with a base learning rate of 0.0001. For PASCAL-Context, we train our model with SGD optimizer for 80 epochs with cross-entropy loss. The base learning rate is set as 0.001. For Cityscapes dataset, we train the model using fine-labelled images, with an initial learning rate of 0.01.</p><p>For data augmentation, the image is randomly flipped and scaled between 0.5 to 2. The images are also randomly rotated between -10 and 10 degrees. The image is cropped into size 512 Ã— 512 for PASCAL VOC and PASCAL Context datasets, and cropped into 1536 Ã— 768 for Cityscapes dataset. For final prediction results, we predict the segmentation masks on multi-scale inputs ranging from 0.5 to 2 and calculate their average.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Ablation Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Ablation Study for Structure</head><p>We conduct the ablation analysis on PASCAL VOC validation dataset, and train all models with the same strategy as in Sec. 4.1.4. The results are summarized in <ref type="table">Table 1</ref>. Numbers after model name represent which column in <ref type="figure" target="#fig_1">Fig. 1</ref> is present.</p><p>First we show the shelf-shaped structure, which increases the number of paths for information flow, is the key to high performance. Compared with FCN, SegNet uses columns 0,1 and 2, and uses low-level features, thus generating a higher mIoU. We use W-Net which has a similar structure compared to ShelfNet, except skip connections between (B2,C2) and (B3,C3) are removed in W-Net. W-Net is equivalent to stacked hourglass network (SHN) <ref type="bibr" target="#b27">[28]</ref>. The number of paths for information flow from input to output has the following order: ShelfNet&gt;W-Net&gt; SegNet&gt;FCN, and we observe the same order of segmentation accuracy, which validates our argument.</p><p>We further validate that the improvement in accuracy comes from increased number of paths, not increased number of parameters. We reduce the number of channels in a ShelfNet by half (e.g. reduce from 64 to 32 channels for A2), but keep the backbone unchanged. This reduces the parameter number from 38.7M to 29.2M, but generates a comparable result (mIoU drops from 88.26% to 85.52%), and the result is much better compared to FCN with more parameters (35.0M).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Shared-weights Blocks (S-Block)</head><p>We evaluate the effect of Shared-weights blocks (S-blocks) by replacing S-blocks in the segmentation shelf with notshared-weight version of residual blocks. Both versions use the same ResNet50 backbone provided by PyTorch official website <ref type="bibr" target="#b31">[32]</ref>. Both models are trained with SGD optimizer on PASCAL augmented dataset for 50 epochs with a base  <ref type="figure" target="#fig_1">Fig. 1</ref> is present, and column 0 represents the backbone. For example, FCN only has a single column 0 followed by a convolution layer, SegNet has columns 0, 1 and 2, ShelfNet has columns 0 to 4 with skip connections between column 2 and 3, while W-Net has columns 0 to 4 without skip connections between (B2,C2) and (B3,C3).  learning rate of 0.01, and finally fine-tuned on original PAS-CAL VOC 2012 dataset for 50 epochs with a base learning rate of 0.001. We test them on the PASCAL VOC validation dataset, and results are summarized in <ref type="table" target="#tab_3">Table 2</ref>. The shared-weight strategy reduces the number of parameters from 45.8M to 38.7M without sacrificing the accuracy. In our experiment the shared-weights strategy even generates a slightly higher mIoU (88.26%) compared to the conventional residual block (88.02%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Speed Analysis for Backbone</head><p>ShelfNet is a flexible architecture and can be used with various backbone models. We summarize the inference speed of different backbones in <ref type="table" target="#tab_5">Table 3</ref>, and show that dilated convolution significantly reduces the inference speed. "Dilated" means the network uses dilated convolution to increase receptive field instead of a pooling layer. The number of flops of a convolution layer is calculated as:</p><formula xml:id="formula_2">Computation = C 1 Ã— C 2 Ã— K 1 Ã— K 2 Ã— H Ã— W (1)</formula><p>where C 1 , C 2 are channel numbers of the input and output tensors, K 1 , K 2 are sizes of the kernel, and H, W are sizes of the feature map. A dilated convolution network will generate a larger H, W , therefore is computationally intensive. As shown in <ref type="table" target="#tab_5">Table 3</ref>, with the same network structure, a dilated version has about 5Ã— larger computation burden. State-of-the-art semantic segmentation networks such as DeepLabv3 and PSPNet use dilated residual network as the backbone, while ShelfNet uses an undilated version. Therefore, ShelfNet is much faster. The speed up mainly comes from computation reduction of the backbone.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">PASCAL VOC 2012</head><p>Comparison with non real-time models We evaluate the segmentation results on the PASCAL evaluation server. Exemplary results are shown in <ref type="figure" target="#fig_4">Fig. 4</ref>. The detailed results are summarized in <ref type="table" target="#tab_8">Table 4</ref> and Compared to state-of-the-art semantic segmentation models such as PSPNet <ref type="bibr" target="#b43">[44]</ref> and EncNet <ref type="bibr" target="#b42">[43]</ref>, ShelfNet achieves a comparable mIoU but generates 4 to 5 times speed-up during inference (59 FPS for ShelfNet50 and 42 FPS for ShelfNet101, 11 FPS for PSPNet and 12 FPS for EncNet). Compared to DeepLabv2, our ShelfNet achieves comparable mIoU (79.3% vs 79.7%) but achieve almost 10Ã— speed up (103FPS vs 12 FPS). Compared with large networks such as PSPNet and DeepLab, our ShelfNet is faster mainly because there's no dilation in the backbone, thus less computation, as shown in <ref type="table" target="#tab_5">Table 3</ref>.</p><p>Comparison with real-time models Lightweight-RefineNet (LWRF) <ref type="bibr" target="#b26">[27]</ref> is one of the state-of-the-art real-time semantic segmentation models. Comparisons between our ShelfNet and LWRF are summarized in <ref type="table" target="#tab_10">Table  6</ref>. ShelfNet50 achieves higher accuracy (82.8%) than LWRF with a ResNet 152 backbone (82.7%) and RefineNet with a ResNet101 backbone (82.4%). Compared to Re-fineNet and LWRF, the better performance with a much smaller backbone of ShelfNet validates the efficiency of the proposed shelf-like structure in feature extraction. Our ShelfNet with Resnet101 backbone achieves the highest accuracy (84.2%) compared to all RefineNet and LWRF models.</p><p>In addition to the higher accuracy, ShelfNet achieves faster inference speed compared with LWRF when using the same backbone. Unlike LWRF, our ShelfNet reduces channel number with a 1 Ã— 1 convolution as in column 1 in <ref type="figure" target="#fig_1">Fig. 1</ref>. For levels A to D, LWRF uses 256, 256, 256, 512 channels, while in ShelfNet it's reduced to 64, 128, 256, 512. As mentioned in Sec. 3.2, the computation for a conv layer is H Ã— W Ã— K 2 Ã— C 2 ,hence quadratically reduced to ( 64 256 ) 2 = 1 16 for level A; even with two more columns, overall the computation burden is reduced to 2 Ã— 1 16 = 1 8 . Therefore, our ShelfNet is faster. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">PASCAL-Context</head><p>Examples of ShelfNet on PASCAL-Context test set are shown in <ref type="figure">Fig. 5</ref>. The detailed results are summarized in <ref type="table" target="#tab_11">Table 7</ref>     </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">Cityscapes</head><p>For non real-time tasks, we used the same structure as in <ref type="figure" target="#fig_1">Fig. 1</ref>, which is used for experiments on PASCAL datasets. For real-time tasks, we modified the network for a lightweight structure, denoted as ShelfNet-lw.  <ref type="bibr" target="#b33">[34]</ref> 68.0 ICNet <ref type="bibr" target="#b44">[45]</ref> 69.5 ENet <ref type="bibr" target="#b30">[31]</ref> 58.3 GUN <ref type="bibr" target="#b24">[25]</ref> 70.4 ContextNet <ref type="bibr" target="#b32">[33]</ref> 66.1 BiSeNet(Res18) <ref type="bibr" target="#b40">[41]</ref>    Numerical results For non real-time tasks, we average results from multi-scale evaluations; for real-time tasks, we use single-scale evaluation.</p><p>The results are summarized in <ref type="figure">Fig. 6</ref>, <ref type="table" target="#tab_14">Table 8</ref> and <ref type="table" target="#tab_15">Table 9</ref>. ShelfNet50 achieves 74.1% mIoU, and ShelfNet101 achieves 77.5% mIoU.</p><p>Our ShelfNet achieves significant improvement in both inference speed and accuracy. Our ShelfNet18-lw achieved 74.8% mIoU with single-scale evaluation, surpassing all existing real-time models. In terms of inference speed, our ShelfNet18-lw achieves comparable inference speed as BiSeNet, surpassing previous real-time models such as IC-Net and GUN.</p><p>Our ShelfNet34-lw achieves the highest mIoU of 79.0% on Cityscapes test set. Our model outperforms previous non real-time models with a large backbone such as ResNet101, which provides strong evidence for the effectiveness of our shelf-shaped structure. We provide links to results 34 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We proposed ShelfNet for fast semantic segmentation, which has multiple pairs of encoder-decoder branches with skip connections between adjacent branches. The unique shelf-shaped structure enables multiple paths for information flow and achieves high accuracy; the shared-weight design in the S-block significantly reduces parameter number without sacrificing accuracy. We validated the high segmentation accuracy and fast running speed on three benchmark datasets. ShelfNet achieves comparable segmentation accuracy to state-of-the-art off-line models with a 4 to 5 times faster inference speed. Our real-time model achieves the highest mIoU on the Cityscapes dataset, while maintaining a high inference speed comparable to BiSeNet. Our offline ShelfNet with ResNet34 backbone outperforms previous models with large backbones such as ResNet101, validating the effectiveness of our shelf-shaped structure.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>(a) Structure of ShelfNet.(b) S-Block (Shared-weight residual block).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Structure and modules of the ShelfNet. (a) Architecture of ShelfNet. Rows A-D represent different spatial levels (e.g. for ResNet backbone, the spatial sizes of A-D are 1/4, 1/8, 1/16 and 1/32 of input image respectively</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :Fig. 1 )</head><label>21</label><figDesc>ShelfNet (gray background, the structure is the same as can be viewed as an ensemble of FCNs. A few examples of information flow paths are marked with different colors. Each path is equivalent to an FCN (except that there are pooling layers in ResNet backbone). The equivalence to an ensemble of FCNs enables ShelfNet to perform accurate segmentation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Deepest path (orange curve) in ShelfNet and GridNet.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Examples on PASCAL VOC. Columns from left to right represent: input images, ground truth annotations, predictions from ShelfNet with ResNet50 backbone, predictions from ShelfNet with ResNet101 backbone.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>Comparison of ShelfNet with ResNet50 backbone us- ing shared-weights and conventional residual blocks on PASCAL VOC 2012 validation dataset.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Inference speed of different backbones. "Dilated" means the network uses dilated convolution.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5</head><label>5</label><figDesc></figDesc><table><row><cell>. For a fair com-</cell></row><row><cell>parison, we implemented ShelfNet and several state-of-the-</cell></row><row><cell>art segmentation models with PyTorch and measured their</cell></row><row><cell>inference speed on a single GTX 1080Ti GPU. ShelfNet</cell></row><row><cell>with ResNet18, ResNet50 and ResNet101 backbone are</cell></row><row><cell>named as ShelfNet18, ShelfNet50 and ShelfNet101 for</cell></row><row><cell>short respectively. When trained only on augmented PAS-</cell></row><row><cell>CAL training set and fine-tuned on original PASCAL VOC</cell></row><row><cell>dataset, ShelfNet18, ShelfNet50 and ShelfNet101 achieve</cell></row><row><cell>74.0%, 79.0% and 81.1% mIoU respectively. When trained</cell></row><row><cell>on both MS COCO and PASCAL dataset, they achieve</cell></row><row><cell>79.3%, 82.8% and 84.2% mIoU respectively. We provide</cell></row><row><cell>anonymous links to our results 12 .</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>. DeepLab-v2 achieves 45.7% mIoU with MS COCO as extra training data, while our ShelfNet achieves 45.6% and 48.4% with ResNet50 and ResNet101 respectively without extra training data. RefineNet achieves 47.3% mIoU at the speed of 29 FPS, while our ShelfNet achieves 45.6% mIoU at 59 FPS with ResNet50 backbone, and 48.4% mIoU at 42 FPS with ResNet100 backbone. ShelfNet has both higher accuracy and faster running speed</figDesc><table><row><cell>Method</cell><cell cols="2">aero bike bird boat bottle bus</cell><cell>car</cell><cell>cat</cell><cell cols="5">chair cow table dog horse mbike person plant sheep sofa train tv</cell><cell>mIoU FPS # Param</cell></row><row><cell>FCN [23]</cell><cell>76.8 34.2 68.9 49.4 60.3</cell><cell cols="4">75.3 74.7 77.6 21.4 62.5 46.8 71.8 63.9</cell><cell>76.5</cell><cell>73.9</cell><cell>45.2 72.4</cell><cell>37.4 70.9 55.1 62.2</cell><cell>-</cell></row><row><cell cols="2">DeepLabv2 [3] 84.4 54.5 81.5 63.6 65.9</cell><cell cols="4">85.1 79.1 83.4 30.7 74.1 59.8 79.0 76.1</cell><cell>83.2</cell><cell>80.8</cell><cell>59.7 82.2</cell><cell>50.4 73.1 63.7 71.6</cell><cell>-</cell></row><row><cell cols="2">CRF-RNN [46] 87.5 39.0 79.7 64.2 68.3</cell><cell cols="4">87.6 80.8 84.4 30.4 78.2 60.4 80.5 77.8</cell><cell>83.1</cell><cell>80.6</cell><cell>59.5 82.8</cell><cell>47.8 78.3 67.1 72.0</cell><cell>-</cell></row><row><cell cols="2">Deconvnet [29] 89.9 39.3 79.7 63.9 68.2</cell><cell cols="4">87.4 81.2 86.1 28.5 77.0 62.0 79.0 80.3</cell><cell>83.6</cell><cell>80.2</cell><cell>58.8 83.4</cell><cell>54.3 80.7 65.0 72.5</cell><cell>-</cell></row><row><cell>GCRF [38]</cell><cell>85.2 43.9 83.3 65.2 68.3</cell><cell cols="4">89.0 82.7 85.3 31.1 79.5 63.3 80.5 79.3</cell><cell>85.5</cell><cell>81.0</cell><cell>60.5 85.5</cell><cell>52.0 77.3 65.1 73.2</cell><cell>-</cell></row><row><cell>DPN [22]</cell><cell>87.7 59.4 78.4 64.9 70.3</cell><cell cols="4">89.3 83.5 86.1 31.7 79.9 62.6 81.9 80.0</cell><cell>83.5</cell><cell>82.3</cell><cell>60.5 83.2</cell><cell>53.4 77.9 65.0 74.1</cell><cell>-</cell></row><row><cell>Piecewise [19]</cell><cell>90.6 37.6 80.0 67.8 74.4</cell><cell cols="4">92.0 85.2 86.2 39.1 81.2 58.9 83.8 83.9</cell><cell>84.3</cell><cell>84.8</cell><cell>62.1 83.2</cell><cell>58.2 80.8 72.3 75.3</cell><cell>-</cell></row><row><cell>ResNet38 [40]</cell><cell>94.4 72.9 94.9 68.8 78.4</cell><cell cols="4">90.6 90.0 92.1 40.1 90.4 71.7 89.9 93.7</cell><cell>91.0</cell><cell>89.1</cell><cell>71.3 90.7</cell><cell>61.3 87.7 78.1 82.5</cell><cell>13</cell><cell>55.9M</cell></row><row><cell>PSPNet [44]</cell><cell>91.8 71.9 94.7 71.2 75.8</cell><cell cols="4">95.2 89.9 95.9 39.3 90.7 71.7 90.5 94.5</cell><cell>88.8</cell><cell>89.6</cell><cell>72.8 89.6</cell><cell>64.0 85.1 76.3 82.6</cell><cell>11</cell><cell>67.6M</cell></row><row><cell>EncNet [43]</cell><cell>94.1 69.2 96.3 76.7 86.2</cell><cell cols="4">96.3 90.7 94.2 38.8 90.7 73.3 90.0 92.5</cell><cell>88.8</cell><cell>87.9</cell><cell>68.7 92.6</cell><cell>59.0 86.4 73.4 82.9</cell><cell>12</cell><cell>54.5M</cell></row><row><cell>ShelfNet18</cell><cell>81.6 56.7 89.7 62.3 69.6</cell><cell cols="4">88.5 82.8 88.4 30.5 82.1 63.5 80.9 82.3</cell><cell>82.6</cell><cell>81.2</cell><cell>62.1 81.3</cell><cell>55.4 75.2 62.7 74.0</cell><cell>103 23.5M</cell></row><row><cell>ShelfNet50</cell><cell>94.0 63.2 86.1 68.9 73.3</cell><cell cols="4">93.6 87.7 91.5 31.4 87.1 67.9 89.5 88.8</cell><cell>86.2</cell><cell>85.5</cell><cell>69.9 88.5</cell><cell>56.1 82.4 72.3 79.0</cell><cell>59</cell><cell>38.7M</cell></row><row><cell>ShelfNet101</cell><cell>93.6 64.2 86.9 69.7 76.2</cell><cell cols="4">93.4 90.5 94.4 37.0 91.7 71.1 91.2 91.5</cell><cell>88.9</cell><cell>86.2</cell><cell>72.7 92.6</cell><cell>58.5 85.8 72.4 81.1</cell><cell>42</cell><cell>57.7M</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4 :</head><label>4</label><figDesc>Results on PASCAL VOC test set without pre-training on COCO. ShelfNet with ResNet18, ResNet50 and ResNet101 as backbone are named as ShelfNet18, ShelfNet50 and ShelfNet101 respectively. We implemented several models and measured the inference speed on a 512 Ã— 512 image as input with a single GTX 1080Ti GPU.</figDesc><table><row><cell>Method</cell><cell cols="4">aero bike bird boat bottle bus</cell><cell>car</cell><cell>cat</cell><cell cols="2">chair cow tale</cell><cell cols="5">dog horse mbike person plant sheep sofa train tv</cell><cell>mIoU FPS # Param</cell></row><row><cell cols="4">CRF-FCN [46] 90.4 55.3 88.7 68.4 69.8</cell><cell cols="6">88.3 82.4 85.1 32.6 78.5 64.4 79.6 81.9</cell><cell>86.4</cell><cell>81.8</cell><cell cols="2">58.6 82.4</cell><cell>53.5 77.4 70.1 74.7</cell><cell>-</cell></row><row><cell>Dilation8 [42]</cell><cell cols="3">91.7 39.6 87.8 63.1 71.8</cell><cell cols="4">89.7 82.9 89.8 37.2 84</cell><cell>63</cell><cell>83.3 89</cell><cell>83.8</cell><cell>85.1</cell><cell cols="2">56.8 87.6</cell><cell>56</cell><cell>80.2 64.7 75.3</cell><cell>-</cell></row><row><cell>DPN [22]</cell><cell>89</cell><cell cols="2">61.6 87.7 66.8 74.7</cell><cell cols="6">91.2 84.3 87.6 36.5 86.3 66.1 84.4 87.8</cell><cell>85.6</cell><cell>85.4</cell><cell cols="2">63.6 87.3</cell><cell>61.3 79.4 66.4 77.5</cell><cell>-</cell></row><row><cell cols="4">Piecewise [19] 94.1 40.7 84.1 67.8 75.9</cell><cell cols="6">93.4 84.3 88.4 42.5 86.4 64.7 85.4 89</cell><cell>85.8</cell><cell>86</cell><cell cols="2">67.5 90.2</cell><cell>63.8 80.9 73</cell><cell>78.0</cell><cell>-</cell></row><row><cell cols="4">DeepLabv2 [3] 92.6 60.4 91.6 63.4 76.3</cell><cell>95</cell><cell cols="5">88.4 92.6 32.7 88.5 67.6 89.6 92.1</cell><cell>87</cell><cell>87.4</cell><cell cols="2">63.3 88.3</cell><cell>60</cell><cell>86.8 74.5 79.7</cell><cell>12</cell><cell>43.9M</cell></row><row><cell cols="2">RefineNet [18] 95</cell><cell cols="2">73.2 93.5 78.1 84.8</cell><cell cols="4">95.6 89.8 94.1 43.7 92</cell><cell cols="2">77.2 90.8 93.4</cell><cell>88.6</cell><cell>88.1</cell><cell cols="2">70.1 92.9</cell><cell>64.3 87.7 78.8 83.4</cell><cell>14</cell><cell>118M</cell></row><row><cell cols="4">ResNet38 [40] 96.2 75.2 95.4 74.4 81.7</cell><cell cols="4">93.7 89.9 92.5 48.2 92</cell><cell cols="2">79.9 90.1 95.5</cell><cell>91.8</cell><cell>91.2</cell><cell>73</cell><cell>90.5</cell><cell>65.4 88.7 80.6 84.9</cell><cell>13</cell><cell>55.9M</cell></row><row><cell>PSPNet [44]</cell><cell cols="2">95.8 72.7 95</cell><cell>78.9 84.4</cell><cell cols="2">94.7 92</cell><cell cols="2">95.7 43.1 91</cell><cell cols="2">80.3 91.3 96.3</cell><cell>92.3</cell><cell>90.1</cell><cell cols="2">71.5 94.4</cell><cell>66.9 88.8 82</cell><cell>85.4</cell><cell>11</cell><cell>67.6M</cell></row><row><cell cols="4">DeepLabv3 [4] 96.4 76.6 92.7 77.8 87.6</cell><cell cols="6">96.7 90.2 95.4 47.5 93.4 76.3 91.4 97.2</cell><cell>91</cell><cell>92.1</cell><cell cols="2">71.3 90.9</cell><cell>68.9 90.8 79.3 85.7</cell><cell>8</cell><cell>58.0M</cell></row><row><cell>EncNet [43]</cell><cell cols="3">95.3 76.9 94.2 80.2 85.2</cell><cell cols="5">96.5 90.8 96.3 47.9 93.9 80</cell><cell>92.4 96.6</cell><cell>90.5</cell><cell>91.5</cell><cell cols="2">70.8 93.6</cell><cell>66.5 87.7 80.8 85.9</cell><cell>12</cell><cell>54.5M</cell></row><row><cell>ShelfNet18</cell><cell cols="3">92.7 64.4 91.8 72.3 76.0</cell><cell cols="6">90.6 84.4 91.1 34.8 89.5 68.2 83.6 88.1</cell><cell>86.8</cell><cell>85.5</cell><cell cols="2">70.6 85.6</cell><cell>62.0 83.5 68.7 79.3</cell><cell>103 23.5M</cell></row><row><cell>ShelfNet50</cell><cell cols="3">95.6 71.5 94.2 72.4 74.3</cell><cell cols="6">94.1 88.4 92.6 35.6 93.9 77.8 88.2 95.5</cell><cell>89.7</cell><cell>88.7</cell><cell cols="2">71.3 91.4</cell><cell>61.6 87.9 77.1 82.8</cell><cell>59</cell><cell>38.7M</cell></row><row><cell>ShelfNet101</cell><cell cols="3">95.4 73.9 94.9 75.7 83.2</cell><cell cols="6">96.3 91.2 93.9 35.3 90.0 79.4 90.2 94.2</cell><cell>92.8</cell><cell>90.1</cell><cell cols="2">73.2 92.3</cell><cell>64.5 88.0 77.5 84.2</cell><cell>42</cell><cell>57.7M</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5 :</head><label>5</label><figDesc>Results on PASCAL VOC test set with pre-training on COCO.</figDesc><table><row><cell>Model</cell><cell cols="8">RefineNet-101 RefineNet-152 RefineNet-LW-50 RefineNet-LW-101 RefineNet-LW-152 ShelfNet-18 ShelfNet-50 ShelfNet-101</cell></row><row><cell cols="2">mIoU, % 82.4</cell><cell>83.4</cell><cell>81.1</cell><cell>82.0</cell><cell>82.7</cell><cell>79.3</cell><cell>82.8</cell><cell>84.2</cell></row><row><cell>FPS</cell><cell>19</cell><cell>16</cell><cell>53</cell><cell>37</cell><cell>29</cell><cell>103</cell><cell>59</cell><cell>42</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 6 :</head><label>6</label><figDesc>Results on PASCAL VOC test set. Comparison with RefineNet and Lightweight-RefineNet (RefineNet-LW). Numbers represent the number of layers in backbone ResNet.</figDesc><table><row><cell cols="5">and sacrifices the inference speed. The inference speed of</cell></row><row><cell cols="5">ShelfNet is 4 to 5 times faster than EncNet as shown in Ta-</cell></row><row><cell cols="5">ble 5. Overall, our ShelfNet achieves high mIoU with fast</cell></row><row><cell>inference speed.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Model</cell><cell>BaseNet</cell><cell cols="3">mIoU, % FPS # Parameters</cell></row><row><cell>FCN-8s [23]</cell><cell></cell><cell>37.8</cell><cell></cell><cell></cell></row><row><cell>CRF-RNN [46]</cell><cell></cell><cell>39.3</cell><cell></cell><cell></cell></row><row><cell>ParseNet [21]</cell><cell></cell><cell>40.4</cell><cell></cell><cell></cell></row><row><cell>Piecewise [19]</cell><cell></cell><cell>43.3</cell><cell></cell><cell></cell></row><row><cell cols="3">DeepLab-v2[3] Res101-COCO 45.7</cell><cell>12</cell><cell>43.9M</cell></row><row><cell cols="2">RefineNet [18] Res101</cell><cell>47.1</cell><cell>19</cell><cell>118M</cell></row><row><cell cols="2">RefineNet [18] Res152</cell><cell>47.3</cell><cell>16</cell><cell>134M</cell></row><row><cell>EncNet [43]</cell><cell></cell><cell>51.7</cell><cell>12</cell><cell>54.5M</cell></row><row><cell>ShelfNet50</cell><cell>Res50</cell><cell>45.6</cell><cell>59</cell><cell>38.7M</cell></row><row><cell>ShelfNet101</cell><cell>Res101</cell><cell>48.4</cell><cell>42</cell><cell>57.7M</cell></row><row><cell>Figure 5: Example predictions of ShelfNet on PASCAL</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Context dataset.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>compared with RefineNet. EncNet achieves a higher mIoU</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>of 51.7%; this is because EncNet uses dilated convolution</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 7 :</head><label>7</label><figDesc>Segmentation results on PASCAL-Context dataset</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Figure 6 :</head><label>6</label><figDesc>Results of ShelfNet on Cityscapes validation dataset. Results from real-time models are generated from single scale test.</figDesc><table><row><cell cols="2">Light-weight ShelfNet We further modify our ShelfNet</cell></row><row><cell cols="2">into a light-weight version (ShelfNet-lw). Different from</cell></row><row><cell cols="2">Fig. 1, in ShelfNet-lw, only features from levels B, C, D</cell></row><row><cell cols="2">are fed into the segmentation shelf; features in level A are</cell></row><row><cell cols="2">not used. For ShelfNet34-lw, we set the channel number</cell></row><row><cell cols="2">for B, C, D as 128, 256, 512 respectively; for ShelfNet18-</cell></row><row><cell cols="2">lw, we set the channel number for B, C, D as 64, 128, 256</cell></row><row><cell cols="2">respectively, further reducing the computation burden. We</cell></row><row><cell cols="2">replace the conv transpose layer with a direct upsampling</cell></row><row><cell cols="2">to reduce number of parameters, and replace S-block in the</cell></row><row><cell cols="2">upsample branch with a conv-bn-relu along with channel</cell></row><row><cell cols="2">attention. For training of our light-weight ShelfNet, we use</cell></row><row><cell cols="2">online hard example mining loss and distributed training to</cell></row><row><cell cols="2">match the training scheme for BiSeNet.</cell></row><row><cell>Method</cell><cell>mIoU (test)</cell></row><row><cell>EffiConv</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 8 :</head><label>8</label><figDesc>Mean IoU (%) for Cityscapes dataset. Real-time ShelfNet was evaluated on single scale input. Light-weight ShelfNet is marked with -lw.</figDesc><table><row><cell>Input size</cell><cell cols="7">EffConv ICNet ENet GUN Context BiSeNet ShelfNet18-lw</cell></row><row><cell cols="2">1024x2048 -</cell><cell>30.3</cell><cell>-</cell><cell>33.3</cell><cell>18.3</cell><cell>37.0</cell><cell>36.9</cell></row><row><cell cols="2">1920x1280 11.4</cell><cell>-</cell><cell>21.6</cell><cell>-</cell><cell>-</cell><cell>31.3</cell><cell>31.2</cell></row><row><cell>768x1536</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>61.7</cell><cell>59.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 9 :</head><label>9</label><figDesc>Speed analysis (FPS) for a single forward pass. BiSeNet and ShelfNet use ResNet18 as backbone and are tested on a single GTX 1080Ti GPU. Speed for other models are from the literature.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://host.robots.ox.ac.uk:8080/anonymous/ 5NMB0K.html 2 http://host.robots.ox.ac.uk:8080/anonymous/ KAZMJD.html</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://tinyurl.com/y65vt9ct 4 https://tinyurl.com/y6ed2uf9</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Inception recurrent convolutional neural network for object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Z</forename><surname>Alom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Segnet: A deep convolutional encoder-decoder architecture for image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Badrinarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cipolla</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.00561</idno>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Deeplab: semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.00915</idno>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Rethinking atrous convolution for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.05587</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Xception: Deep learning with depthwise separable convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chollet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1251" to="1258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Histograms of oriented gradients for human detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="886" to="893" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The pascal visual object classes challenge: A retrospective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Eslami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Residual conv-deconv grid network for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fourure</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Emonet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Fromont</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Muselet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tremeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wolf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.07958</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Dally</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1510.00149</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning both weights and connections for efficient neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dally</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1135" to="1143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Hypercolumns for object segmentation and fine-grained localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>ArbelÃ¡ez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="447" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Second order derivatives for network pruning: Optimal brain surgeon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hassibi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Stork</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="164" to="171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4700" to="4708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deeply-recursive convolutional network for image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Kwon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K. Mu</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1637" to="1645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Refinenet: Multipath refinement networks for high-resolution semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">D</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cvpr</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Efficient piecewise training of deep structured models for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Hengel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3194" to="3203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>DollÃ¡r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.04579</idno>
		<title level="m">Parsenet: Looking wider to see better</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Semantic image segmentation via deep parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1377" to="1385" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="3431" to="3440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Distinctive image features from scaleinvariant keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Guided upsampling network for real-time semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mazzini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The role of context for object detection and semantic segmentation in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mottaghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N.-G</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Light-weight refinenet for real-time semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nekrasov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.03272</idno>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Stacked hourglass networks for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="483" to="499" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning deconvolution network for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Noh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1520" to="1528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Distillation as a defense to adversarial perturbations against deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mcdaniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Swami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Symposium on Security and Privacy (SP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="582" to="597" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Enet: A deep neural network architecture for real-time semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chaurasia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Culurciello</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.02147</idno>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Automatic differentiation in pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>De-Vito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Contextnet: Exploring context and detail for semantic segmentation in real-time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Poudel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Bonde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liwicki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zach</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.04554</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Efficient convnet for real-time semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Romera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IV</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Kahou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chassang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gatta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6550</idno>
		<title level="m">Fitnets: Hints for thin deep nets</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Residual networks behave like ensembles of relatively shallow networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Veit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Gaussian conditional random field network for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vemulapalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Tuzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellapa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3224" to="3233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Understanding convolution for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cottrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE winter conference on applications of computer vision (WACV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1451" to="1460" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V D</forename><surname>Hengel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.10080</idno>
		<title level="m">Wider or deeper: Revisiting the resnet model for visual recognition</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Bilateral segmentation network for realtime semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Multi-scale context aggregation by dilated convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.07122</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Context encoding for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tyagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Pyramid scene parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Icnet for real-time semantic segmentation on high-resolution images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.08545</idno>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Conditional random fields as recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jayasumana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Romera-Paredes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vineet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1529" to="1537" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Scene parsing through ade20k dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Puig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Barriuso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
