<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Simple Applications of BERT for Ad Hoc Document Retrieval</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-03-26">26 Mar 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University of Waterloo</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haotian</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University of Waterloo</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University of Waterloo</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">R</forename><surname>Cheriton</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University of Waterloo</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Simple Applications of BERT for Ad Hoc Document Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-03-26">26 Mar 2019</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T19:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Following recent successes in applying BERT to question answering, we explore simple applications to ad hoc document retrieval. This required confronting the challenge posed by documents that are typically longer than the length of input BERT was designed to handle. We address this issue by applying inference on sentences individually, and then aggregating sentence scores to produce document scores. Experiments on TREC microblog and newswire test collections show that our approach is simple yet effective, as we report the highest average precision on these datasets by neural approaches that we are aware of.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The dominant approach to ad hoc document retrieval using neural networks today is to deploy the neural model as a reranker over an initial list of candidate documents retrieved using a standard bag-of-words term-matching technique. Researchers have proposed many neural ranking models <ref type="bibr" target="#b11">(Mitra and Craswell, 2019)</ref>, but there has recently been some skepticism about whether they have truly advanced the state of the art <ref type="bibr" target="#b8">(Lin, 2018)</ref>, at least in the absence of large amounts of log data only available to a few organizations.</p><p>One important recent innovation is the use of neural models that make heavy use of pretraining <ref type="bibr" target="#b15">(Peters et al., 2018;</ref><ref type="bibr" target="#b16">Radford et al., 2018)</ref>, culminating in BERT <ref type="bibr" target="#b3">(Devlin et al., 2018)</ref>, the most popular example of this approach today. Researchers have applied BERT to a broad range of NLP tasks and reported impressive gains. Most relevant to document retrieval, BERTserini  integrates passage retrieval using the open-source Anserini IR toolkit with a BERT-based reader to achieve large gains * equal contribution over the previous state of the art in identifying answer spans from a large Wikipedia corpus.</p><p>Given the successes in applying BERT to question answering and the similarities between QA and document retrieval, we naturally wondered: Would it be possible to apply BERT to improve document retrieval as well? In short, the answer is yes. Adapting BERT for document retrieval requires overcoming the challenges associated with long documents, both during training and inference. We present a simple yet effective approach, based on the same BERTserini framework, that applies inference over individual sentences in a document and then combines sentence scores into document scores.</p><p>Our approach is evaluated on standard ad hoc retrieval test collections from the TREC Microblog Tracks <ref type="bibr">(2011)</ref><ref type="bibr">(2012)</ref><ref type="bibr">(2013)</ref><ref type="bibr">(2014)</ref> and the TREC 2004 Robust Track. We report the highest average precision on these datasets for neural approaches that we are aware of. The contribution of our work is, to our knowledge, the first successful application of BERT to ad hoc document retrieval, yielding state of the art results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background and Related Work</head><p>In ad hoc document retrieval, the system is given a short query q and the task is to produce the best ranking of documents in a corpus, according to some standard metric such as average precision (AP). <ref type="bibr" target="#b11">Mitra and Craswell (2019)</ref> provide a recent overview of many of these models, to which we refer interested readers in lieu of a detailed literature review due to space considerations.</p><p>However, there are aspects of the task worth discussing. Researchers have understood for a few years now that relevance matching and semantic matching (for example, paraphrase detection, natural language inference, etc.) are different tasks, despite shared common characteristics <ref type="bibr" target="#b4">(Guo et al., 2016)</ref>. The first task has a heavier dependence on exact match (i.e., "one-hot") signals, whereas the second task generally requires models to more accurately capture semantics. Question answering has elements of both, but nevertheless remains a different task from document retrieval. Due to these task differences, neural models for document ranking, for example, DRMM <ref type="bibr" target="#b4">(Guo et al., 2016)</ref>, are quite different architecturally from neural models for capturing similarity; see, for example, the survey of <ref type="bibr" target="#b7">Lan and Xu (2018)</ref>.</p><p>Another salient fact is that documents can be longer than the length of input texts that BERT was designed for. This creates a problem during training because relevance judgments are annotations on documents, not on individual sentences or passages. Typically, within a relevant document, only a few passages are relevant, but such fine-grained annotations are not available in most test collections. Thus, it is unclear how exactly one would fine-tune BERT given (only) existing document-level relevance judgments. In this paper, we sidestep the training challenge completely and present a simple approach to aggregating sentence-level scores during inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Searching Social Media Posts</head><p>Despite the task mismatch between QA and ad hoc document retrieval, our working hypothesis is that BERT can be fine-tuned to capture relevance matching, as long as we can provide appropriate training data. To begin, we tackled microblog retrieval--searching short social media posts-where document length does not pose an issue. Fortunately, test collections from the TREC Microblog Tracks <ref type="bibr" target="#b9">(Lin et al., 2014)</ref>, from 2011 to 2014, provide data for exactly this task.</p><p>As with BERTserini, we adopted a simple architecture that uses the Anserini IR toolkit 1 for initial retrieval, followed by inference using a BERT model. Building on best practice, query likelihood (QL) with RM3 relevance feedback <ref type="bibr" target="#b0">(Abdul-Jaleel et al., 2004)</ref> provides the initial ranking to depth 1000. The texts of the retrieved documents (posts) are then fed into a BERT classifier, and the BERT scores are combined with the retrieval scores via linear interpolation. We used the BERT-Base model (uncased, 12-layer, 768-hidden, 12-heads, 110M pa-rameters) described in <ref type="bibr" target="#b3">Devlin et al. (2018)</ref>. As input, we concatenated the query Q and the document D into a text sequence [[CLS], Q, [SEP], D, [SEP]], and then padded each text sequence in a mini-batch to N tokens, where N is the maximum length in the batch. Following <ref type="bibr" target="#b13">Nogueira and Cho (2019)</ref>, BERT is used for binary classification (i.e., relevance) by taking the [CLS] vector as input to a single layer neural network.</p><p>Test collections from the TREC Microblog Tracks were used for fine-tuning the BERT model, using cross-entropy loss. For evaluation on each year's dataset, we used the remaining years for fine tuning, e.g., tuning on 2011-2013 data, testing on 2014 data. From the training data, we sampled 10% for validation. We fine-tuned BERT with a learning rate of 3 × 10 −6 for 10 epochs. The interpolation weight between the BERT scores and the retrieval scores was tuned on the validation data. We only used as training examples the social media posts that appear in our initial ranking (i.e., as opposed to all available relevance judgments). There are a total of 225 topics <ref type="bibr">(50,</ref><ref type="bibr">60,</ref><ref type="bibr">60,</ref><ref type="bibr">55)</ref> in the four datasets, which yields 225,000 examples (unjudged posts are treated as not relevant).</p><p>Experimental results are shown in <ref type="table" target="#tab_0">Table 1</ref>, where we present average precision (AP) and precision at rank 30 (P30), the two official metrics of the evaluation <ref type="bibr" target="#b14">(Ounis et al., 2011)</ref>. The first two blocks of the table are copied from <ref type="bibr" target="#b17">Rao et al. (2019)</ref>, who compared bag-of-words baselines (QL and RM3) to several popular neural ranking models as well as MP-HCNN, the model they introduced. Results for all the neural models include interpolation with the original document scores. <ref type="bibr" target="#b17">Rao et al. (2019)</ref> demonstrated that previous neural models are not suitable for ranking short social media posts, and are no better than the RM3 baseline in many cases. In contrast, MP-HCNN was explicitly designed with characteristics of tweets in mind: it significantly outperforms previous neural ranking models (see original paper for comparisons, not repeated here). We also copied results from <ref type="bibr" target="#b18">Shi et al. (2018)</ref>, who reported even higher effectiveness than MP-HCNN.</p><p>These results represent, to our knowledge, the most comprehensive summary of search effectiveness measured on the TREC Microblog datasets. Note that for these comparisons we leave aside many non-neural approaches that take advantage of learning-to-ranking techniques over manually-  engineered features, as we do not believe they form a fair basis of comparison. In general, such approaches also take advantage of non-textual features (e.g., social signals), and these additional signals (naturally) allow them to beat approaches that use only the text of the social media posts (like all the models discussed here). The final row of <ref type="table" target="#tab_0">Table 1</ref> reports results using our simple BERT-based technique, showing quite substantial and consistent improvements over previous results. Since we have directly copied results from previous papers, we did not conduct significance tests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Searching Newswire Articles</head><p>Results on the microblog test collections confirm our working hypothesis that BERT can be finetuned to capture document relevance, at least for short social media posts. In other words, task differences between QA and document retrieval do not appear to hinder BERT's adaptability. Having demonstrated this, we turn our attention to longer documents. For this, we take advantage of the test collection from the TREC 2004 Robust Track <ref type="bibr" target="#b19">(Voorhees, 2004)</ref>, which comprises 250 topics over a newswire corpus. We selected this collection for a couple of reasons: it is the largest newswire collection we know of in terms of training data, and Lin (2018) provides well-tuned baselines that support fair comparisons to recent neural ranking models.</p><p>Given the success of BERT on microblogs, one simple idea is to apply inference over each sentence in a candidate document, select the one with the highest score, and then combine that with the original document score (with linear interpo-lation). One rationale for this approach comes from <ref type="bibr">Zhang et al. (2018b,a)</ref>, who found that the "best" sentence or paragraph in a document provides a good proxy for document relevance. This is also consistent with a long thread of work in information retrieval that leverages passage retrieval techniques for document ranking <ref type="bibr" target="#b1">(Callan, 1994;</ref><ref type="bibr" target="#b2">Clarke et al., 2000;</ref><ref type="bibr" target="#b10">Liu and Croft, 2002)</ref>.</p><p>Generalizing, we could consider the top n scoring sentences as follows:</p><formula xml:id="formula_0">Score d = a · S doc + (1 − a) · n i=1 w i · S i</formula><p>where S doc is the original document score and S i is the i-th top scoring sentence according to BERT. The hyperparameters a and w i can be tuned via cross-validation.</p><p>Sentence-level inference seems like a reasonable initial attempt at adapting BERT to document retrieval, but what about fine-tuning? As previously discussed, the issue is that we lack sentencelevel relevance judgments. Since our efforts represent an initial exploration, we simply sidestep this challenge (for now) and fine tune on existing sentence-level datasets. Specifically, we used:</p><p>(1) the microblog data from the previous section and (2) the union of the TrecQA <ref type="bibr" target="#b23">(Yao et al., 2013)</ref> and WikiQA <ref type="bibr" target="#b22">(Yang et al., 2015)</ref> datasets. This sets up an interesting contrast: the first dataset captures the document retrieval task but on a different domain, while the second dataset captures a different task but on corpora that are much closer to newswire. It is an empirical question as to which source is more effective.</p><p>To support a fair comparison, we adopted the same experimental procedure as <ref type="bibr" target="#b8">Lin (2018)</ref>. He described two separate data conditions: one based on two-fold cross-validation to compare against "Paper 1" and one based on five-fold crossvalidation to compare against "Paper 2". <ref type="bibr">2</ref> The exact fold settings are provided online, which ensures a fair comparison. 3 In our implementation, documents are first cleaned by stripping all tags and then segmenting the text into sentences using NLTK. If the input to BERT is longer than 512 tokens (BERT's maximum limit), we further split sentences into fixed sized chunks. Across the 250 topics, each document averages 43 sentences, with 27 tokens per sentence.</p><p>In our experiments, we considered up to the top four sentences. For up to three sentences, a and w i are tuned via exhaustive grid search in the following range: a ∈ [0, 1], w 1 = 1 (fixed), w 2 ∈ [0, 1], and w 3 ∈ [0, 1], all with step size 0.1. In the foursentence condition, to reduce the search space, we started with the best three-sentence parameters and explored w 4 ∈ [0, 1] with step size 0.1, along with neighboring regions in a, w 2 , and w 3 . We selected the parameters with the highest AP score on the training folds.</p><p>Results of our experiments are shown in Table 2, divided into two blocks: Paper 1 on the top and Paper 2 on the bottom. The effectiveness of the two papers are directly copied from <ref type="bibr" target="#b8">Lin (2018)</ref>; all other results are our own runs. The paper aggregation site "Papers With Code" places Lin's result as the state of the art on Robust04 as of this writing. 4 As a point of comparison, in the most recent survey of neural ranking models by <ref type="bibr" target="#b5">Guo et al. (2019)</ref>, the best AP on Robust04 is in the 0.29 range, consistent with the above site. Therefore, we are quite confident that we are evaluating against competitive models. In the results table, "FT" indicates the dataset used for finetuning and nS indicates inference using the top n scoring sentences of the document. We find that the learned w 4 value is zero, indicating that additional sentences do not help beyond the top three (at least according to our tuning procedure); thus, 4S results are omitted from the  we find that fine-tuning BERT on microblog data is more effective than QA data, suggesting that task (QA vs. relevance matching) is more important than document genre (tweets vs. newswire). Cognizant of the potential dangers of repeated hypothesis testing, we probed the statistical significance of one five-fold setting, BM25+RM3 vs. "3S: BERT FT (Microblog)". According to a paired t-test, the differences are statistically significant (p &lt; 10 −7 ).</p><p>As a summary, we see that a well-tuned BM25+RM3 baseline already outperforms neural ranking approaches (which was Lin's original point). Our simple BERT-based reranker yields further significant improvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this preliminary study, we have adapted BERT for document retrieval in the most obvious manner, via sentence-level inference and simple score aggregation. Results show substantial improvements in both ranking social media posts and newswire documents-to our knowledge, the highest AP scores reported on the TREC Microblog and Robust04 datasets for neural approaches that we are aware of (although the literature does report non-neural approaches that are even better, for both tasks). We readily con-cede that our techniques are quite simple and that there are many obvious next steps. In particular, we simply sidestepped the issue of not having sentence-level relevance judgments, although there are some obvious distant supervision techniques to "project" relevance labels down to the sentence level that should be explored. We are actively pursuing these and other directions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Results on test collections from the TREC Microblog Tracks, comparing BERT with selected neural ranking models. The first two blocks of the table contain results copied from<ref type="bibr" target="#b17">Rao et al. (2019)</ref>.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>table .</head><label>.</label><figDesc></figDesc><table><row><cell>Model</cell><cell>AP</cell><cell>P20</cell></row><row><cell>Paper 1 (two fold)</cell><cell cols="2">0.2971 0.3948</cell></row><row><cell>BM25+RM3</cell><cell cols="2">0.2987 0.3871</cell></row><row><cell>1S: BERT FT(QA)</cell><cell cols="2">0.3014 0.3928</cell></row><row><cell>2S: BERT FT(QA)</cell><cell cols="2">0.3003 0.3948</cell></row><row><cell>3S: BERT FT(QA)</cell><cell cols="2">0.3003 0.3948</cell></row><row><cell cols="3">1S: BERT FT(Microblog) 0.3241 0.4217</cell></row><row><cell cols="3">2S: BERT FT(Microblog) 0.3240 0.4209</cell></row><row><cell cols="3">3S: BERT FT(Microblog) 0.3244 0.4219</cell></row><row><cell>Paper 2 (five fold)</cell><cell>0.272</cell><cell>0.386</cell></row><row><cell>BM25+RM3</cell><cell cols="2">0.3033 0.3974</cell></row><row><cell>1S: BERT FT(QA)</cell><cell cols="2">0.3102 0.4068</cell></row><row><cell>2S: BERT FT(QA)</cell><cell cols="2">0.3090 0.4064</cell></row><row><cell>3S: BERT FT(QA)</cell><cell cols="2">0.3090 0.4064</cell></row><row><cell cols="3">1S: BERT FT(Microblog) 0.3266 0.4245</cell></row><row><cell cols="3">2S: BERT FT(Microblog) 0.3278 0.4267</cell></row><row><cell cols="3">3S: BERT FT(Microblog) 0.3278 0.4287</cell></row><row><cell>Interestingly,</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Results on Robust04. FT indicates the dataset used for fine tuning; nS indicates inference using the top n scoring sentences of the document.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://anserini.io/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Since Lin's article is critical of neural methods, he anonymized the neural approaches but mentioned that they come from articles published in late 2018 and are representative of the most recent advances in neural approaches to document retrieval. 3 https://github.com/castorini/Anserini/blob/master/docs/ experiments-forum2018.md 4 https://paperswithcode.com/sota/ ad-hoc-information-retrieval-trec-robust</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was supported by the Natural Sciences and Engineering Research Council (NSERC) of Canada.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">UMass at TREC 2004: Novelty and HARD</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nasreen</forename><surname>Abdul-Jaleel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leah</forename><surname>Larkey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><forename type="middle">D</forename><surname>Smucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Strohman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth Text REtrieval Conference</title>
		<meeting>the Thirteenth Text REtrieval Conference<address><addrLine>Howard Turtle, and Courtney Wade</addrLine></address></meeting>
		<imprint>
			<publisher>TREC</publisher>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Passage-level evidence in document retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">P</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;94</title>
		<meeting>the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;94</meeting>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="302" to="310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Relevance ranking for one to three term queries. Information Processing and Management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gordon</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elizabeth</forename><surname>Tudhope</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="291" to="311" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A deep relevance matching model for ad-hoc retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixing</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyao</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM International on Conference on Information and Knowledge Management, CIKM &apos;16</title>
		<meeting>the 25th ACM International on Conference on Information and Knowledge Management, CIKM &apos;16</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="55" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixing</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyao</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamed</forename><surname>Zamani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.06902v1</idno>
		<title level="m">A deep look into neural ranking models for information retrieval</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">PACRR: A position-aware neural IR model for relevance matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Berberich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>De Melo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1049" to="1058" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Neural network models for paraphrase identification, semantic textual similarity, natural language inference, and question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wuwei</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3890" to="3902" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<title level="m">The neural hype and comparisons against weak baselines. SIGIR Forum</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="40" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Overview of the TREC-2014 Microblog Track</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miles</forename><surname>Efron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Garrick</forename><surname>Sherman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Third Text REtrieval Conference</title>
		<meeting>the Twenty-Third Text REtrieval Conference</meeting>
		<imprint>
			<publisher>TREC</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Passage retrieval based on language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W. Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Information and Knowledge Management, CIKM &apos;02</title>
		<meeting>the Eleventh International Conference on Information and Knowledge Management, CIKM &apos;02</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="375" to="382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">An introduction to neural information retrieval. Foundations and Trends in Information Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhaskar</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning to match using local and distributed representations of text for web search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhaskar</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on World Wide Web, WWW &apos;17</title>
		<meeting>the 26th International Conference on World Wide Web, WWW &apos;17</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1291" to="1299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.04085</idno>
		<title level="m">Passage re-ranking with BERT</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Overview of the TREC-2011 Microblog Track</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iadh</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Craig</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Soboroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twentieth Text REtrieval Conference</title>
		<meeting>the Twentieth Text REtrieval Conference</meeting>
		<imprint>
			<publisher>TREC</publisher>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep contextualized word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2227" to="2237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Improving language understanding by generative pre-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Technical report</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multi-perspective relevance matching with hierarchical ConvNets for social media search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinfeng</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferhan</forename><surname>Ture</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence (AAAI)</title>
		<meeting>the Thirty-Third AAAI Conference on Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Simple attention-based representation learning for ranking short social media posts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinfeng</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<idno>arxiv:1811.01013</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Overview of the TREC 2004 Robust Track</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth Text REtrieval Conference (TREC 2004)</title>
		<meeting>the Thirteenth Text REtrieval Conference (TREC 2004)</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="52" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">End-to-end neural ad-hoc ranking with kernel pooling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuyun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Callan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russell</forename><surname>Power</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;17</title>
		<meeting>the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;17</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="55" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aileen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luchen</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.01718</idno>
		<title level="m">End-to-end open-domain question answering with BERTserini</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">WikiQA: A challenge dataset for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yih</forename><surname>Wen-Tau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Meek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2013" to="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Answer extraction as sequence tagging with tree edit distance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuchen</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callisonburch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="858" to="867" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Effective user interaction for high-recall retrieval: Less is more</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haotian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><surname>Abualsaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nimesh</forename><surname>Ghelani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><forename type="middle">D</forename><surname>Smucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gordon</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maura</forename><forename type="middle">R</forename><surname>Grossman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM International Conference on Information and Knowledge Management, CIKM &apos;18</title>
		<meeting>the 27th ACM International Conference on Information and Knowledge Management, CIKM &apos;18</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="187" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Evaluating sentence-level relevance feedback for high-recall information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haotian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gordon</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maura</forename><forename type="middle">R</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><forename type="middle">D</forename><surname>Smucker</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.08988</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
