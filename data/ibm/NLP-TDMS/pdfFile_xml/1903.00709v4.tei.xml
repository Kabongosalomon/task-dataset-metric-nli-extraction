<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PartNet: A Recursive Part Decomposition Network for Fine-grained and Hierarchical Shape Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fenggen</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Nanjing University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Nanjing University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Nanjing University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenyang</forename><surname>Zhu</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">National University of Defense Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Xu</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">National University of Defense Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">PartNet: A Recursive Part Decomposition Network for Fine-grained and Hierarchical Shape Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T21:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep learning approaches to 3D shape segmentation are typically formulated as a multi-class labeling problem. Existing models are trained for a fixed set of labels, which greatly limits their flexibility and adaptivity. We opt for topdown recursive decomposition and develop the first deep learning model for hierarchical segmentation of 3D shapes, based on recursive neural networks. Starting from a full shape represented as a point cloud, our model performs recursive binary decomposition, where the decomposition network at all nodes in the hierarchy share weights. At each node, a node classifier is trained to determine the type (adjacency or symmetry) and stopping criteria of its decomposition. The features extracted in higher level nodes are recursively propagated to lower level ones. Thus, the meaningful decompositions in higher levels provide strong contextual cues constraining the segmentations in lower levels. Meanwhile, to increase the segmentation accuracy at each node, we enhance the recursive contextual feature with the shape feature extracted for the corresponding part. Our method segments a 3D shape in point cloud into an unfixed number of parts, depending on the shape complexity, showing strong generality and flexibility. It achieves the stateof-the-art performance, both for fine-grained and semantic segmentation, on the public benchmark and a new benchmark of fine-grained segmentation proposed in this work. We also demonstrate its application for fine-grained part refinements in image-to-shape reconstruction.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Segmentation is a long-standing problem in 3D shape analysis, on which data-driven approach has shown clear advantage over traditional geometric methods <ref type="bibr" target="#b36">[37]</ref>. With the proliferation of deep learning techniques, researchers have been seeking for exploiting the powerful feature learning ability of deep neural networks to replace the hand- <ref type="figure">Figure 1</ref>. PartNet segments 3D point clouds in a top-down recursive fashion, leading to a hierarchy of fine-grained parts. The same model trained for Chair class can be used to segment different chair models into different number of parts, depending on the structure complexity of the input shapes. crafted features used in previous data-driven approaches. In these works, deep networks are trained for multi-class labeling task, which outputs a semantic label for each geometric primitive (such as voxels <ref type="bibr" target="#b21">[22]</ref> or points <ref type="bibr" target="#b18">[19]</ref>).</p><p>There are two issues with these existing models. First, the models are trained targeting a fixed set of labels, which greatly limits its flexibility and adaptivity. For example, a model trained to segment a chair into three semantic parts cannot be used to correctly segment a chair with four parts, even they both belong to the same shape family. Training different models for different targeted label sets is neither general nor efficient. Second, labeling all primitives simultaneously cannot exploit the hierarchical nature of shape decomposition. Hierarchical shape segmentation reduces the difficulty of shape segmentation through dividing the multi-class labeling problem into a cascade of binary labeling problems <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b37">38]</ref>. On the other hand, hierarchical segmentation can utilize structural constraints across different levels: The segmentations in higher levels provide strong cues constraining those in the lower levels. This enables accurate segmentation into very fine-grained levels <ref type="figure">(Figure 1</ref>).</p><p>In this work, we opt for the top-down decomposition and propose the first deep learning model for hierarchical segmentation of 3D shapes into fine-grained parts, based on recursive neural networks (RvNN). Starting from a full shape represented as a point cloud, our model performs recursive binary decomposition, where the decomposition network at all nodes in the hierarchy share weights. At each node, a node classifier is trained to determine the type of its decomposition (adjacency or symmetry node) and whether the decomposition should stop (leaf node). The features extracted in higher level nodes are recursively propagated to lower level ones through the tree structure, which we refer to as recursive context features. Therefore, the meaningful decompositions in higher levels constrain the segmentations in lower levels. Meanwhile, to increase the segmentation accuracy at each node, we enhance the recursive context feature with the part shape feature extracted for the corresponding point cloud.</p><p>The network is trained with point sampled 3D models from ShapeNet <ref type="bibr" target="#b2">[3]</ref> which are typically composed of semantically labeled parts. For each shape, a hierarchy is constructed with an existing rule-based method <ref type="bibr" target="#b34">[35]</ref>. Such principled training hierarchies help the training converges faster. The loss is computed at each node, including node classification loss and binary point labeling loss.</p><p>Our method produces accurate segmentation, even for highly fine-grained decomposition into arbitrary number of parts, due to the flexibility of dynamic, RvNN-based architecture. Moreover, it recovers the part relations (adjacency or symmetry) which further improves the labeling accuracy, e.g., symmetric parts can be identified and thus correctly labeled ( <ref type="figure">Figure 1</ref>). Our method achieves state-ofthe-art performance, both on the public benchmark and a new benchmark of fine-grained segmentation proposed in this work. We also demonstrate its utility in image-to-shape reconstruction with fine-grained structure recovery.</p><p>Our contributions include:</p><p>• A deep learning model for top-down hierarchical, finegrained segmentation of 3D shapes based on dynamic RvNN-based architecture. • A part feature learning scheme which integrates both contextual information and per-part shape geometry. • A benchmark for fine-grained, part instance segmentation of 3D shapes. • An application of our fine-grained structure recovery for high-quality image-to-shape reconstruction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Learning 3D shape segmentation. Semantic segmentation of 3D shapes has gained significant research progress in recent year, benefiting from the advances in machine learning techniques <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b35">36]</ref>. A comprehensive survey on learning-based 3D shape segmentation can be found in <ref type="bibr" target="#b36">[37]</ref>. The basic idea of these approaches is to learn a shape primitive (e.g., a triangle, a point or a voxel) classifier, based on the geometric features of the shape primitives.</p><p>Recently, several deep learning models have been developed for supervised segmentation of 3D shapes in various representations including volumetric grid <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b30">31]</ref>, point cloud <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b6">7]</ref>, multi-view rendering <ref type="bibr" target="#b8">[9]</ref> or surface mesh <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b29">30]</ref>. The main idea is to replace the hand-crafted geometric features employed in the traditional methods with data-driven learned ones. All these models, however, are trained targeting a fixed set of semantic labels. Given a different set of targeting labels, the model has to be re-trained, using a training dataset annotated with the new labels.</p><p>Hierarchical segmentation of 3D shapes. 3D shapes are usually modeled with parts in a hierarchical construction manner. This is evidenced in part by the wide availability of scene graphs in human-created 3D models of objects or scenes, and by the well-known hierarchical modeling paradigm of Constructive Solid Geometry (CSG) <ref type="bibr" target="#b19">[20]</ref>. This naturally leads to the idea of hierarchical decomposition of 3D shapes. Hierarchical shape segmentation can be achieved either with a bottom-up grouping approach <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b32">33]</ref>, or in a top-down fashion based on a global topological analysis <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b40">41]</ref>. Given a pre-segmented 3D shape, Wang et al. <ref type="bibr" target="#b34">[35]</ref> infer a hierarchical organization of the parts based on proximity and symmetry relations. Later, this heuristic method is improved with an unsupervised learning approach <ref type="bibr" target="#b28">[29]</ref>. Yi et al. <ref type="bibr" target="#b37">[38]</ref> propose a supervised learning approach to hierarchical segmentation of 3D shapes. Their model is, again, trained for a fixed set of semantic tags. The tag sets are determined in a pre-processing of part label analysis and organized with a pre-defined canonical hierarchy. Our method, on the other hand, does not require a prescribed canonical hierarchy and learns the decomposition hierarchies in a data-driven manner, thank to the recursively trained node classification. Our method is, to our knowledge, the first end-to-end trainable model for hierarchical shape segmentation.</p><p>Recursive neural networks. Recursive neural nets (RvNN) are developed by Socher et al. <ref type="bibr" target="#b23">[24]</ref>, for text and image understanding <ref type="bibr" target="#b25">[26]</ref>, and for 3D shape classification <ref type="bibr" target="#b24">[25]</ref>. Recently, Li et al. <ref type="bibr" target="#b11">[12]</ref> introduce a generative recursive auto-encoder for generating 3D shape structures. Given a collection of pre-segmented 3D shapes, a variational auto-encoder (VAE) model is learned with RvNNbased encoding and decoding of part structures. Following that, RvNN-based VAE is also trained for 3D scene generation <ref type="bibr" target="#b12">[13]</ref>, structure-aware single-view 3D reconstruction <ref type="bibr" target="#b16">[17]</ref> and substructure prior learning for part group composition <ref type="bibr" target="#b41">[42]</ref>. We are not aware of a previous work on using RvNN for hierarchical 3D shape segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>We first introduce the overall architecture of PartNet, which is a recursive part decomposition network. Several key designs in the network will then follow.   • Node decoding module used to pass the global contextual information from the current node to its children. Such information constraints the segmentation of a node with higher level context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Recursive part decomposition network</head><p>• Node classification module devised to construct the topological structure of the decomposition hierarchy. This is achieved by learning to predict the node type which determines how to decompose a node and when to stop the decomposition.</p><p>• Node segmentation module used for performing actual segmentation of the point cloud of the current node. This is achieved by learning a point classification network shared across all nodes.</p><p>Below we elaborate the discussion on these modules.</p><p>Node decoding module. To bootstrap, we first extract a 128D PointNet <ref type="bibr" target="#b17">[18]</ref> feature for the full shape point cloud, which is then duplicated and concatenated, forming a 256D the root node feature. This 256D feature is then decoded into two 128D features, one for each of its two child nodes, which we refer to as recursive context feature. At each non-root node, we also extract a 128D PointNet feature for the partial point cloud corresponding to that node, which is called part shape feature. This 128D part shape feature is then concatenated with the 128D recursive context feature passed down from the parent node, forming the current node feature. Please see <ref type="figure" target="#fig_2">Figure 3</ref> for a visual explanation of these features. The decoding module is implemented with a  two-layer fully connected network with tanh nonlinearity. This PointNet used in this module is referred to as Point-Net 1, to distinguish with the one to be used in the node segmentation module (see below).</p><p>Node classification module. At a given node, taking its current node feature as input, the node classification module predicts its node type as one of the following three ones: adjacency, symmetry or leaf. Through determining the how and whether a node is split, this module constructs the topological structure of the hierarchy. This node classification module is implemented with two fully-connected layers with tanh nonlinearity. It can be trained with the ground-truth hierarchical segmentation of a point cloud.</p><p>Note that when a node is classified as a symmetry node, we interpret its left child as a symmetry generator (representing a part) and its right child as symmetry parameters, similar to <ref type="bibr" target="#b11">[12]</ref>. Applying the symmetry parameters on the symmetry generator part obtains the complete point cloud of that symmetry node. For example, the node corresponding to the spokes in the leg part of a swivel chair <ref type="figure">(Figure 1</ref>, left) is a rotational symmetry node. Its left child represents the point cloud of one of the spokes and the right child encodes the symmetry axis and symmetry fold.  Net (denoted as PointNet 2) to extract per-point feature, leading to a N × 128 feature matrix, with N being the number of points of the current node. Then for each row (point feature), we enhance it by concatenating the 256D current node feature. This results in a N ×384 feature matrix, which is fed into a point classification network to produce pointwise binary labels. This point classifier is implemented with the last five layers of a PointNet. Note that these layers do not share weight with PointNet 1 or PointNet 2.</p><p>For a symmetry node, only its left child, i.e., the symmetry generator, needs to be segmented. After the segmentation, the point labels are transferred to all other symmetric counterparts, based on the predicted symmetry parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Loss function</head><p>For each training point cloud, the overall loss function for PartNet, L partnet , consists of the average node classification loss and average node segmentation loss over all relevant nodes:</p><formula xml:id="formula_0">L partnet = 1 |H| n∈H L class (n) + 1 |T | n∈T L seg (n) (1)</formula><p>where L class (n) and L seg (n) are the classification loss and segmentation loss of node n, respectively. Both losses are defined as the cross-entropy loss. H is the set of all nodes in the hierarchy, and T the set of all non-leaf nodes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Training details</head><p>The PointNet 1 for node classification ( <ref type="figure" target="#fig_2">Figure 3</ref>) uses six point convolution layers with 64, 128, 128, 256, 256 and 128 filters, respectively. The PointNet 2 for node segmentation ( <ref type="figure" target="#fig_3">Figure 4</ref>) uses four point convolution layers with 64, 64, 128 and 128 filters, respectively. The point cloud segmentation network in <ref type="figure" target="#fig_3">Figure 4</ref> consists of four point convolution layers, with 512, 256, 128 and 128 filters, respectively, plus the output layer with a 2 filters for binary label prediction. 20% random feature dropout are used between every two of the last three layers in all these networks. Batch normalization are used between every two layers. We use the Adam optimizer for training, with a batch size of 10 and the initial learning rate of 0.001.</p><p>The size of input point cloud is 2048. The training point clouds are obtained by point sampling 3D models. Gaussian noise is added for data enhancement. All PointNets use point normals to improve fine-grained part segmentation performance. Therefore, the dimension of input tensors to PartNet is 2048 × 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results and evaluations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Benchmark</head><p>The Fine-grained Segmentation Benchmark (FineSeg). With the advances in deep learning based 3D shape seg-mentation, a benchmark for instance segmentation of finegrained parts is called for. A nice benchmark for evaluating fine-grained shape segmentation is recently proposed in a concurrent work in <ref type="bibr" target="#b15">[16]</ref>. In this work, we propose FineSeg. The dataset contains about 3000 3D shapes over six shape categories: chair (1000), table (500), airplanes (600), sofa (600), helicopter (100) and bike (140). The models are collected from a subset of ShapeNet <ref type="bibr" target="#b2">[3]</ref> used in the work of Sung et al. <ref type="bibr" target="#b27">[28]</ref>. These models are consistently aligned and uniformly scaled. For those model whose segmentation is not fine-grained enough (e.g., no instance part segmentation), we manually segment the models. We then build a part hierarchy for each shape, using the method proposed in <ref type="bibr" target="#b34">[35]</ref>. We point sample each 3D model, thus generating a ground-truth fine-grained segmentation of the corresponding 3D point cloud. The hierarchies can be used for training our recursive part decomposition network. This benchmark can be used to quantitatively evaluate fine-grained segmentation of 3D point clouds, based on Average Precision (AP) for part detection (with the IoU against ground-truth greater than a threshold). The benchmark is publicly available at: www.kevinkaixu.net/ projects/partnet.html.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Segmentation results and evaluation</head><p>Our PartNet model is trained with 80% models of Fine-Seg, leaving the rest 20% for testing. The discussion of complexity and timing (for both training and testing) can be found in the supplemental material.</p><p>Visual results on FineSeg. We first show in <ref type="figure" target="#fig_4">Figure 5</ref> some visual examples of fine-grained point cloud segmentation obtained by PartNet. For side-by-side comparison, we also show the ground-truth segmentation for each example. Our method produces precise fine-grained segmentation on the noisy point clouds with complicated part structures. Furthermore, once trained, the same model can be used to segment the test (unseen) point clouds into varying number of parts, demonstrating its flexibility and generality. <ref type="figure" target="#fig_5">Figure 6</ref> demonstrates how the same model of PartNet can segment different shapes in a category into for an arbitrary number of targeting parts, depending on structure complexity. More results can be found in the supplemental material. In the supplemental material, we also show a visual comparison of hierarchical segmentation with two traditional (non-learned) baseline methods.</p><p>Quantitative evaluation with ablation study. In quantitative evaluation on FineSeg, we compare to two baselines which are ablated versions of our method. Specially, we are interested in the effect of the two important node features used in PartNet: recursive context feature (RCF) and part shape feature (PSF).  In the first baseline (w/o RCF), recursive context feature is removed from both node classification (see <ref type="figure" target="#fig_2">Figure 3</ref>) and node segmentation (see <ref type="figure" target="#fig_3">Figure 4</ref>). To compensate the miss- ing of recursive context feature, the 128D part shape feature is duplicated into a 256D feature. The ablated network is re-trained using the training set of FineSeg. In the second baseline (w/o PSF), PSF is removed only from the node classification module. <ref type="table" target="#tab_3">Table 1</ref> reports AP on all six categories of the testing set, with the IoU thresholds being 0.25 and 0.5, respectively. The consistent superiority of our full model demonstrates the importance of the two features. <ref type="figure" target="#fig_6">Figure 7</ref> plots the training loss over iterations for the three methods, on three shape categories (Bike, Sofa and Airplane). The results show that both features are critical for fast training of the node classification module and the node segmentation module. This evidences the importance of both global context information and local shape geometry on learning hierarchical segmentation. More results are in the supplemental material.</p><p>ShapeNet challenge for fine-grained segmentation. In addition, we conduct a moderate-scale stress test using ShapeNet <ref type="bibr" target="#b2">[3]</ref> challenge for fine-grained segmentation. We randomly select a collection of shapes from ShapNet and use PartNet to segment them. Since we don't have groundtruth fine-grained segmentation for ShapeNet models, we resort to a subjective study to evaluate our segmentation results. We ask the participants to rate the quality of finegrained segmentation in the range from 1 to 5. The user study shows that our method attains &gt; 4.0 average ratings for all the categories tested, much higher than the results of the "w/o RCF" baseline. The details and results of this study are provided in the supplemental material. In <ref type="figure">Figure 8</ref>, we show a few visual examples, from which one can see that our method produces fine-grained segmentation these un- <ref type="figure">Figure 8</ref>. A few results from the ShapeNet fine-grained segmentation challenge. Besides segmentation, PartNet can also recover the relations (adjacency and symmetry) between the segmented parts. We visualize the recovered symmetry relations with colored arrows (Reflective: Red; Translational: Blue; Rotational: Green). seen shapes with complicated structures. Moreover, our method obtains the adjacency and symmetry relations of the decomposed parts, which can be used for many downstream structure-aware applications <ref type="bibr" target="#b14">[15]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Comparison of semantic segmentation</head><p>Although PartNet is designed for fine-grained segmentation, the recursive decomposition should work even better for semantic segmentation since the latter is usually a much coarser-level segmentation. We evaluate PartNet for semantic segmentation of 3D point clouds on the ShapeNet part dataset <ref type="bibr" target="#b38">[39]</ref>, through comparing with seven state-ofthe-art methods on this task. Similar to PointNet <ref type="bibr" target="#b17">[18]</ref>, we re-sample the point cloud for each shape into 2048 points. We use the same training/testing split setting as those stateof-the-arts, and compute part-wise average IoU as metric.</p><p>Note that PartNet does not produce semantic labels for points, so it cannot perform labeled segmentation. To enable the comparison, we add an extra module to PartNet to predict a semantic label for each part it decomposes. The part label prediction module takes the node feature of the leaf nodes as input and outputs a semantic label for all points included in that leaf node. This module is implemented with three fully-connected layers and is trained with cross-entropy loss.  <ref type="table">Table 2</ref>. Comparison of semantic segmentation on the ShapeNet part dataset <ref type="bibr" target="#b38">[39]</ref>. Metric is part-wise IoU (%).</p><p>The results are reported in <ref type="table">Table 2</ref>. PartNet, augmented with a part label prediction module, achieves better performance in most of the categories, and the highest mean accuracy over all categories. Furthermore, our method works especially well for those categories with complex structures such as chair, table, and aeroplane, etc. We believe that the divide-and-conquer nature of recursive decomposition does help reduce the difficulty of segmentation learning. Another key benefit of recursive decomposition is that the segmentation of higher levels provides contextual cues constraining that of the lower levels. Similar results can also be observed in testing our trained model on the Princeton Segmentation Benchmark <ref type="bibr" target="#b3">[4]</ref> (see supplemental material).</p><p>For semantic segmentation, PartNet can be trained with a consistent hierarchy for all shapes in a category. The training is can be done with any hierarchy that is consistent across all training shapes. Therefore, we do not need an extra process (such as the one <ref type="bibr" target="#b34">[35]</ref> used in fine-grained segmentation) for hierarchy construction. Taking any random hierarchy of one training shape as a "template", we unify the hierarchies of all the other shapes based on the semantic part labels. Therefore, PartNet does not require an extra supervision of part hierarchy for training for semantic segmentation. Consequently, the comparison reported in <ref type="table">Table 2</ref> of the main paper is a fair one. <ref type="bibr">SGPN [32]</ref> is the first deep learning model that learns instance segmentation on 3D point clouds. It can segment object instances and predict a class label for each instance, which is very similar to our method (augmented the label prediction module), except that SGPN cannot obtain part relations as our method does. We make a comparison to SGPN on our FineSeg dataset, using again AP with IoU thresholds of 0.25 and 0.5. <ref type="figure">Figure 9</ref> shows a few visual comparisons, where incorrectly segmented regions are marked out. <ref type="table" target="#tab_5">Table 3</ref> shows the quantitative comparison on our datasets. We attribute the consistent improvement over SGPN to two factors. First, the instance group learning of SGPN is based on point clustering. Such a one-shot point grouping over the entire shape is hard to learn. Our method, on the other hand, performs top-down recursive decomposition which breaks the <ref type="bibr">Figure 9</ref>. Visual comparison of fine-grained part instance segmentation with SGPN <ref type="bibr" target="#b31">[32]</ref> full shape segmentation into a cascade of partial shape segmentations. Second, the point features used by SGPN are solely point convolutional features <ref type="bibr" target="#b17">[18]</ref> while our features accounts for both local part shape and global context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Comparison of instance segmentation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Applications</head><p>We demonstrate an application of the fine-grained segmentation of PartNet in refining 3D point clouds reconstructed from single view images. The basic idea is a segment-and-refine process. Given a 3D point cloud reconstructed in a holistic fashion (using, e.g., the method of Fan et al. <ref type="bibr" target="#b4">[5]</ref>), we first perform a recursive decomposition of the point cloud, resulting in a hierarchical organization of part point clouds. We then train a network to refine the part point cloud at each leaf node, yielding a high-quality point cloud for that part. These refined part point clouds together constitute a refined point cloud of the full shape.</p><p>The part refiner network used at each leaf node is composed of two channels of PointNet, to encode the point clouds of the part and the full shape, respectively. The resulting two features are concatenated and fed into a four layer fully-connected networks to generate a refined part point cloud. To train this refiner network, we use reconstruction loss computed as the Chamfer distance and the earth mover's distance between point clouds <ref type="bibr" target="#b4">[5]</ref>. To gain more training signals, we opt to train the refiner with a hierarchical reconstruction loss, through a bottom-up composition of the refined part point clouds, following the hierarchy obtained by PartNet segmentation. This way, we can compute a reconstruction loss at each node of the hierarchy, with the corresponding point cloud composed from the part point clouds within its subtree. Please refer to the supplemental material for more details on the network architecture. <ref type="figure" target="#fig_7">Figure 10</ref> shows a few examples of point cloud refinement, guided by the fine-grained, hierarchical segmentation of PartNet. Although the refinement may sometimes lose part fidelity w.r.t. the input images, it does produce highly detailed point clouds and with plausible part structure, thanks to the fine-grained part decomposition of Part-Net. See more examples in the supplemental material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>We have presented a top-down recursive decomposition network for fine-grained segmentation of 3D point clouds. With the hierarchical decomposition scheme, our model obtains fine-grained and accurate segmentation even for highly complex shapes. Different from most existing deeplearning based segmentation models, our method segments a shape into an arbitrary number of parts, depending on its structural complexity, instead of producing a labeled segmentation with a fixed label set. Even for semantic segmentation, our model also achieves superior performance, benefiting from our divide-and-conquer segmentation learning.</p><p>Limitations and future work. Our current method has a few limitations. First, although PartNet segments a shape in a hierarchical fashion, the resulting segment hierarchy is not necessarily as meaningful as the those learned purposively for shapes <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b37">38]</ref> or scenes <ref type="bibr" target="#b13">[14]</ref>. Second, although our model can be used to segment different shapes into different number of parts, instead of targeting a fixed part label set. It still needs to be trained for each shape category separately. Learning a more general model for recursive decomposition of shapes from multiple classes would be a very interesting future direction to look into. Third, PartNet is trained with reasonable ground-truth hierarchies built with the method in <ref type="bibr" target="#b34">[35]</ref>. Training with totally random hierarchy would lead to performance degrading. We show this effect in the supplemental material. Therefore, another future direction is to learn hierarchical segmentation in a unsupervised manner, without the need of building ground-truth hierarchies.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>The architecture of PartNet. At each node, there are three modules devised for context propagation, hierarchy construction and point cloud segmentation, respectively. Being a recursive network, these modules are shared by all node in the hierarchy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2</head><label>2</label><figDesc>shows the architecture of PartNet. Taking a point cloud of 3D shape as input, PartNet performs a topdown decomposition and and outputs a segmented point cloud at the level of part instances. At each node, three modules are devised:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Network design of the node decoding module and the node classification module. The recursive contextual feature and part shape feature are concatenated and fed into the node classifier.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Network design of the node segmentation module. The concatenation of recursive contextual feature and part shape feature is enhanced with point-wise PointNet features for the purpose of point label prediction (point cloud segmentation).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Fine-grained point cloud segmentation by PartNet. For comparison, we show for each shape the fine-grained segmentation result (bottom) and the corresponding ground-truth (top).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 .</head><label>6</label><figDesc>The same PartNet model trained on the Chair set, can be used to segment different chair models into different number of parts, depending on the structure complexity of the input shapes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 .</head><label>7</label><figDesc>Training loss over iterations in the ablation study of the two key node features (RCF and PSF), on three shape categories (Bike, Sofa and Airplane). For each category (row), we plot both node segmentation loss (left) and node classification loss (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 10 .</head><label>10</label><figDesc>A few examples on refining point clouds reconstructed from single view images, guided by the fine-grained segmentation of PartNet. In each row, we show from left to right the input image, result of holistic reconstruction, fine-grained segmentation of the reconstruction, and the final refinement result by our method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Node segmentation module. This module performs point labeling based on both the current node feature and perpoint PointNet features. Specifically, we use another Point-</figDesc><table><row><cell>N × 6</cell><cell>PointNet_2</cell><cell>N×128</cell><cell>Max pooling</cell><cell>128D Part shape feature</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>+</cell><cell>256D</cell></row><row><cell></cell><cell></cell><cell>256D Parent node feature</cell><cell>Node decoder</cell><cell>Recursive context feature 128D</cell></row><row><cell></cell><cell>N×384</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>N×128</cell><cell>256 × 1 256 × 1 … 256 × 1</cell><cell>Point classifier</cell><cell>N × 2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 .</head><label>1</label><figDesc>RCF 66.0 85.3 83.4 71.8 56.7 42.5 56.4 w/o PSF 64.9 85.2 88.4 65.6 57.5 36.9 55.6 Comparing our full model with two baselines (w/o RCF and w/o PSF) on FineSeg. AP(%) is measured with IoU threshold being 0.25 and 0.5, respectively.</figDesc><table><row><cell></cell><cell></cell><cell>mean aero bike chair heli. sofa table</cell></row><row><cell>IoU &gt; 0.25</cell><cell cols="2">Full w/o RCF 79.2 92.8 92.0 87.1 71.1 61.6 70.8 84.8 95.2 97.0 91.1 83.0 65.4 77.2 w/o PSF 77.6 90.8 95.1 83.6 77.8 54.1 64.0</cell></row><row><cell>IoU &gt; 0.5</cell><cell>Full w/o</cell><cell>72.8 88.0 89.4 80.5 69.4 46.7 62.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Method mean aero bag cap car chair eph. guitar knife lamp laptop motor mug pistol rocket skate.table PointNet [18] 83.7 83.4 78.7 82.5 74.9 89.6 73.0 91.5 85.9 80.8 95.3 65.2 93.0 81.2 57.9 72.8 80.6 PointNet++ [19] 85.1 82.4 79.0 87.7 77.3 90.8 71.8 91.0 85.9 83.7 95.3 71.6 94.1 81.3 58.7 76.4 82.6 O-CNN [31] 85.9 85.5 87.1 84.7 77.0 91.1 85.1 91.9 87.4 83.3 95.4 56.9 96.2 81.6 53.5 74.1 84.4 SSCN [6] 86.0 84.1 83.0 84.0 80.8 91.4 78.2 91.6 89.1 85.0 95.8 73.7 95.2 84.0 58.5 76.0 82.7 PCNN [2] 85.1 82.4 80.1 85.5 79.5 90.8 73.2 91.3 86.0 85.0 95.7 73.2 94.8 83.3 51.0 75.0 81.8 SPLATNet [27] 85.4 83.2 84.3 89.1 80.3 90.7 75.5 92.1 87.1 83.9 96.3 75.6 95.8 83.8 64.0 75.5 81.8 PointCNN [12] 86.1 84.1 86.4 86.0 80.8 90.6 79.7 92.3 88.4 85.3 96.1 77.2 95.3 84.2 64.2 80.0 83.0 Ours 87.4 87.8 86.7 89.7 80.5 91.9 75.7 91.8 85.9 83.6 97.0 74.6 97.3 83.6 64.6 78.4 85.8</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 .</head><label>3</label><figDesc>. Left: Ground-truths. Middle: Segmentation results by PartNet. Right: Results by SGPN. Incorrect segmentations (w.r.t. ground-truth) are marked with red circles. Comparison with SGPN [32] on fine-grained instance segmentation over the FineSeg dataset. The metric is AP (%) with IoU threshold being 0.25 and 0.5, respectively.</figDesc><table><row><cell></cell><cell></cell><cell>mean aero bike chair heli. sofa table</cell></row><row><cell>IoU</cell><cell cols="2">SGPN [12] 62.2 67.8 75.8 66.2 59.4 50.4 53.6</cell></row><row><cell>&gt; 0.25</cell><cell>Ours</cell><cell>84.8 95.2 97.0 91.1 83.0 65.4 77.2</cell></row><row><cell>IoU</cell><cell cols="2">SGPN [12] 47.0 56.7 63.7 54.6 38.9 29.5 38.4</cell></row><row><cell>&gt; 0.5</cell><cell>Ours</cell><cell>72.8 88.0 89.4 80.5 69.4 46.7 62.6</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>We thank the anonymous reviewers for their valuable comments. We are also grateful to Hao (Richard) Zhang for the fruitful discussions, and to Yuan Gan and Pengyu Wang for the tremendous help on data preparation. This work was supported in part by NSFC (61572507, 61532003, 61622212) and Natural Science Foundation of Hunan Province for Distinguished Young Scientists (2017JJ1002).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Hierarchical mesh segmentation based on fitting primitives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Attene</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Falcidieno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Spagnuolo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Visual Computer</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="181" to="193" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Point convolutional neural networks by extension operators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Atzmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Maron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lipman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM SIGGRAPH</title>
		<imprint>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Funkhouser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Savva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.03012</idno>
		<title level="m">An information-rich 3d model repository</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A benchmark for 3D mesh segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Golovinskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Funkhouser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (Proc. SIGGRAPH)</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A point set generation network for 3d object reconstruction from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2463" to="2471" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">3d semantic segmentation with submanifold sparse convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Engelcke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="9224" to="9232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Recurrent slice networks for 3d segmentation of point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Neumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2626" to="2635" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Shape decomposition using modal analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q.-X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wicke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="407" to="416" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">3d shape segmentation with projective convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kalogerakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Averkiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning 3d mesh segmentation and labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kalogerakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hertzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Singh</surname></persName>
		</author>
		<idno>102:1-102:12</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (Proc. SIGGRAPH)</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Escape from cells: Deep kdnetworks for the recognition of 3d point cloud models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Klokov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="863" to="872" />
		</imprint>
	</monogr>
	<note>Computer Vision (ICCV</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">GRASS: Generative recursive autoencoders for shape structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yumer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.09193</idno>
		<title level="m">Grains: Generative recursive autoencoders for indoor scenes</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Creating consistent scene graphs using a probabilistic grammar</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Funkhouser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">211</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Structure-aware shape processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q.-X</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIG-GRAPH Asia</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tripathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.02713</idno>
		<title level="m">Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Im2struct: Recovering 3d shape structure from a single rgb image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4521" to="4529" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Pointnet: Deep learning on point sets for 3d classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.00593</idno>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Pointnet++: Deep hierarchical feature learning on point sets in a metric space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="5099" to="5108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Constructive solid geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Requicha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">B</forename><surname>Voelcker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Hierarchical shape segmentation and registration via topological features of laplace-beltrami eigenfunctions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Reuter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="287" to="308" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Octnet: Learning deep 3d representations at high resolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">O</forename><surname>Ulusoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Unsupervised co-segmentation of a set of shapes via descriptor-space spectral clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Sidi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Van Kaick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kleiman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. on Graph. (SIGGRAPH Asia)</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Recursive deep learning for natural language processing and computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Citeseer</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Convolutional-recursive deep learning for 3d object classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Huval</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="656" to="664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Parsing natural scenes and natural language with recursive neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th international conference on machine learning (ICML-11)</title>
		<meeting>the 28th international conference on machine learning (ICML-11)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="129" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">SPLATNet: Sparse lattice networks for point cloud processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Jampani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kalogerakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2530" to="2539" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">ComplementMe: Weakly-supervised component suggestions for 3D modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
		<idno>2017. 4</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. on Graph</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Co-hierarchical analysis of shape structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Van Kaick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. on Graph. (SIGGRAPH)</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">69</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">3d shape segmentation via shape fully convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Graphics</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="128" to="139" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">O-cnn: Octree-based convolutional neural networks for 3d shape analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-Y.</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (SIG-GRAPH)</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Sgpn: Similarity group proposal network for 3d point cloud instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Neumann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning to group and label fine-grained shape components</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH Asia 2018 Technical Papers</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page">210</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Projective analysis for 3d shape segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">192</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Symmetry hierarchy of man-made objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="287" to="296" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">3d shape segmentation and labeling via extreme learning machine. Computer Graphics Forum</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">L</forename><surname>Abd Yueshan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SGP)</title>
		<meeting>SGP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="85" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Data-driven shape analysis and processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kalogerakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH ASIA 2016 Courses</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
	<note>page 4. ACM</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning hierarchical shape segmentation and labeling from online repositories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hertzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yumer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. on Graph</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A scalable active framework for region annotation in 3d shape collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ceylan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I.-C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sheffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGGRAPH Asia</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Syncspeccnn: Synchronized spectral cnn for 3d shape segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6584" to="6592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Generalized cylinder decomposition. ACM Trans. on Graph. (SIGGRAPH Asia)</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="171" to="172" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Scores: Shape composition with recursive substructure priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (SIGGRAPH Asia</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
