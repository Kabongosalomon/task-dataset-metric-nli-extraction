<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Coarse-to-Fine Decoding for Neural Semantic Parsing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
							<email>li.dong@ed.ac.ukmlap@inf.ed.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Institute for Language, Cognition and Computation School of Informatics</orgName>
								<orgName type="institution">University of Edinburgh</orgName>
								<address>
									<addrLine>10 Crichton Street</addrLine>
									<postCode>EH8 9AB</postCode>
									<settlement>Edinburgh</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Language, Cognition and Computation School of Informatics</orgName>
								<orgName type="institution">University of Edinburgh</orgName>
								<address>
									<addrLine>10 Crichton Street</addrLine>
									<postCode>EH8 9AB</postCode>
									<settlement>Edinburgh</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Coarse-to-Fine Decoding for Neural Semantic Parsing</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Semantic parsing aims at mapping natural language utterances into structured meaning representations. In this work, we propose a structure-aware neural architecture which decomposes the semantic parsing process into two stages. Given an input utterance, we first generate a rough sketch of its meaning, where low-level information (such as variable names and arguments) is glossed over. Then, we fill in missing details by taking into account the natural language input and the sketch itself. Experimental results on four datasets characteristic of different domains and meaning representations show that our approach consistently improves performance, achieving competitive results despite the use of relatively simple decoders.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Semantic parsing maps natural language utterances onto machine interpretable meaning representations (e.g., executable queries or logical forms). The successful application of recurrent neural networks to a variety of NLP tasks <ref type="bibr" target="#b4">(Bahdanau et al., 2015;</ref><ref type="bibr" target="#b41">Vinyals et al., 2015)</ref> has provided strong impetus to treat semantic parsing as a sequence-to-sequence problem <ref type="bibr" target="#b19">(Jia and Liang, 2016;</ref><ref type="bibr" target="#b10">Dong and Lapata, 2016;</ref>. The fact that meaning representations are typically structured objects has prompted efforts to develop neural architectures which explicitly account for their structure. Examples include tree decoders <ref type="bibr" target="#b10">(Dong and Lapata, 2016;</ref><ref type="bibr" target="#b1">Alvarez-Melis and Jaakkola, 2017)</ref>, decoders constrained by a grammar model <ref type="bibr" target="#b44">(Xiao et al., 2016;</ref><ref type="bibr" target="#b47">Yin and Neubig, 2017;</ref>, or modular decoders which use syntax to dynamically compose various submodels <ref type="bibr" target="#b34">(Rabinovich et al., 2017)</ref>.</p><p>In this work, we propose to decompose the decoding process into two stages. The first decoder focuses on predicting a rough sketch of the meaning representation, which omits low-level details, such as arguments and variable names. Example sketches for various meaning representations are shown in <ref type="table">Table 1</ref>. Then, a second decoder fills in missing details by conditioning on the natural language input and the sketch itself. Specifically, the sketch constrains the generation process and is encoded into vectors to guide decoding.</p><p>We argue that there are at least three advantages to the proposed approach. Firstly, the decomposition disentangles high-level from low-level semantic information, which enables the decoders to model meaning at different levels of granularity. As shown in <ref type="table">Table 1</ref>, sketches are more compact and as a result easier to generate compared to decoding the entire meaning structure in one go. Secondly, the model can explicitly share knowledge of coarse structures for the examples that have the same sketch (i.e., basic meaning), even though their actual meaning representations are different (e.g., due to different details). Thirdly, after generating the sketch, the decoder knows what the basic meaning of the utterance looks like, and the model can use it as global context to improve the prediction of the final details.</p><p>Our framework is flexible and not restricted to specific tasks or any particular model. We conduct experiments on four datasets representative of various semantic parsing tasks ranging from logical form parsing, to code generation, and SQL query generation. We adapt our architecture to these tasks and present several ways to obtain sketches from their respective meaning representations. Experimental results show that our framework achieves competitive performance compared arXiv:1805.04793v1 [cs.CL] 12 May 2018 Dataset Length Example GEO 7.6 13.7 6.9</p><p>x : which state has the most rivers running through it? y : (argmax $0 (state:t $0) (count $1 (and (river:t $1) (loc:t $1 $0)))) a : (argmax#1 state:t@1 (count#1 (and river:t@1 loc:t@2 ) ) ) ATIS 11.1 21.1 9.2</p><p>x : all flights from dallas before 10am y : (lambda $0 e (and (flight $0) (from $0 dallas:ci) (&lt; (departure time $0) 1000:ti))) a : (lambda#2 (and flight@1 from@2 (&lt; departure time@1 ? ) ) ) DJANGO 14.4 8.7 8.0</p><p>x : if length of bits is lesser than integer 3 or second element of bits is not equal to string 'as' , y : if len(bits) &lt; 3 or bits[1] != 'as': a : if len ( NAME ) &lt; NUMBER or NAME [ NUMBER ] != STRING : WIKISQL 17.9 13.3 13.0 2.7 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Various models have been proposed over the years to learn semantic parsers from natural language expressions paired with their meaning representations <ref type="bibr" target="#b38">(Tang and Mooney, 2000;</ref><ref type="bibr" target="#b13">Ge and Mooney, 2005;</ref><ref type="bibr" target="#b49">Zettlemoyer and Collins, 2007;</ref><ref type="bibr" target="#b42">Wong and Mooney, 2007;</ref><ref type="bibr" target="#b27">Lu et al., 2008;</ref><ref type="bibr" target="#b24">Kwiatkowski et al., 2011;</ref><ref type="bibr" target="#b2">Andreas et al., 2013;</ref><ref type="bibr" target="#b52">Zhao and Huang, 2015)</ref>. These systems typically learn lexicalized mapping rules and scoring models to construct a meaning representation for a given input.</p><p>More recently, neural sequence-to-sequence models have been applied to semantic parsing with promising results <ref type="bibr" target="#b10">(Dong and Lapata, 2016;</ref><ref type="bibr" target="#b19">Jia and Liang, 2016;</ref>, eschewing the need for extensive feature engineering. Several ideas have been explored to enhance the performance of these models such as data augmentation <ref type="bibr" target="#b19">Jia and Liang, 2016)</ref>, transfer learning <ref type="bibr" target="#b11">(Fan et al., 2017)</ref>, sharing parameters for multiple languages or meaning representations <ref type="bibr" target="#b36">(Susanto and Lu, 2017;</ref><ref type="bibr" target="#b16">Herzig and Berant, 2017)</ref>, and utilizing user feedback signals <ref type="bibr" target="#b18">(Iyer et al., 2017)</ref>. There are also efforts to develop structured decoders that make use of the syntax of meaning representations. <ref type="bibr" target="#b10">Dong and Lapata (2016)</ref> and Alvarez-Melis and Jaakkola (2017) develop models which generate tree structures in a topdown fashion. <ref type="bibr" target="#b44">Xiao et al. (2016)</ref> and  employ the grammar to constrain the decoding process. <ref type="bibr" target="#b9">Cheng et al. (2017)</ref> use a transition system to generate variable-free queries. <ref type="bibr" target="#b47">Yin and Neubig (2017)</ref> design a grammar model for the generation of abstract syntax trees <ref type="bibr" target="#b0">(Aho et al., 2007)</ref> in depth-first, left-to-right order. <ref type="bibr" target="#b34">Rabinovich et al. (2017)</ref> propose a modular decoder whose submodels are dynamically composed according to the generated tree structure.</p><p>Our own work also aims to model the structure of meaning representations more faithfully. The flexibility of our approach enables us to easily apply sketches to different types of meaning representations, e.g., trees or other structured objects. Coarse-to-fine methods have been popular in the NLP literature, and are perhaps best known for syntactic parsing <ref type="bibr" target="#b8">(Charniak et al., 2006;</ref><ref type="bibr" target="#b32">Petrov, 2011)</ref>.  and <ref type="bibr" target="#b51">Zhang et al. (2017)</ref> use coarse lexical entries or macro grammars to reduce the search space of semantic parsers. Compared with coarse-to-fine inference for lexical induction, sketches in our case are abstractions of the final meaning representation.</p><p>The idea of using sketches as intermediate representations has also been explored in the field of program synthesis <ref type="bibr" target="#b35">(Solar-Lezama, 2008;</ref><ref type="bibr" target="#b50">Zhang and Sun, 2013;</ref><ref type="bibr" target="#b12">Feng et al., 2017)</ref>. <ref type="bibr" target="#b46">Yaghmazadeh et al. (2017)</ref> use SEMPRE <ref type="bibr" target="#b5">(Berant et al., 2013)</ref> to map a sentence into SQL sketches which are completed using program synthesis techniques and iteratively repaired if they are faulty.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Problem Formulation</head><p>Our goal is to learn semantic parsers from instances of natural language expressions paired with their structured meaning representations.  <ref type="figure">Figure 1</ref>: We first generate the meaning sketch a for natural language input x. Then, a fine meaning decoder fills in the missing details (shown in red) of meaning representation y. The coarse structure a is used to guide and constrain the output decoding. Let x = x 1 · · · x |x| denote a natural language expression, and y = y 1 · · · y |y| its meaning representation. We wish to estimate p (y|x), the conditional probability of meaning representation y given input x. We decompose p (y|x) into a twostage generation process:</p><formula xml:id="formula_0">p (y|x) = p (y|x, a) p (a|x)<label>(1)</label></formula><p>where a = a 1 · · · a |a| is an abstract sketch representing the meaning of y. We defer detailed description of how sketches are extracted to Section 4. Suffice it to say that the extraction amounts to stripping off arguments and variable names in logical forms, schema specific information in SQL queries, and substituting tokens with types in source code (see <ref type="table">Table 1</ref>). As shown in <ref type="figure">Figure 1</ref>, we first predict sketch a for input x, and then fill in missing details to generate the final meaning representation y by conditioning on both x and a. The sketch is encoded into vectors which in turn guide and constrain the decoding of y. We view the input expression x, the meaning representation y, and its sketch a as sequences. The generation probabilities are factorized as:</p><formula xml:id="formula_1">p (a|x) = |a| t=1 p (a t |a &lt;t , x) (2) p (y|x, a) = |y| t=1 p (y t |y &lt;t , x, a)<label>(3)</label></formula><p>where a &lt;t = a 1 · · · a t−1 , and y &lt;t = y 1 · · · y t−1 . In the following, we will explain how p (a|x) and p (y|x, a) are estimated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Sketch Generation</head><p>An encoder is used to encode the natural language input x into vector representations. Then, a decoder learns to compute p (a|x) and generate the sketch a conditioned on the encoding vectors.</p><p>Input Encoder Every input word is mapped to a vector via</p><formula xml:id="formula_2">x t = W x o (x t ), where W x ∈ R n×|Vx| is an embedding matrix, |V x | is the vo- cabulary size, and o (x t ) a one-hot vector.</formula><p>We use a bi-directional recurrent neural network with long short-term memory units (LSTM, Hochreiter and Schmidhuber 1997) as the input encoder. The encoder recursively computes the hidden vectors at the t-th time step via:</p><formula xml:id="formula_3">− → e t = f LSTM − → e t−1 , x t , t = 1, · · · , |x| (4) ← − e t = f LSTM ← − e t+1 , x t , t = |x|, · · · , 1 (5) e t = [ − → e t , ← − e t ]<label>(6)</label></formula><p>where [·, ·] denotes vector concatenation, e t ∈ R n , and f LSTM is the LSTM function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Coarse Meaning Decoder</head><p>The decoder's hidden vector at the t-th time step is computed by</p><formula xml:id="formula_4">d t = f LSTM (d t−1 , a t−1 )</formula><p>, where a t−1 ∈ R n is the embedding of the previously predicted token.</p><p>The hidden states of the first time step in the decoder are initialized by the concatenated encoding vectors d 0 = [ − → e |x| , ← − e 1 ]. Additionally, we use an attention mechanism <ref type="bibr" target="#b28">(Luong et al., 2015)</ref> to learn soft alignments. We compute the attention score for the current time step t of the decoder, with the k-th hidden state in the encoder as:</p><formula xml:id="formula_5">s t,k = exp{d t · e k }/Z t<label>(7)</label></formula><p>where Z t = |x| j=1 exp{d t · e j } is a normalization term. Then we compute p (a t |a &lt;t , x) via:</p><formula xml:id="formula_6">e d t = |x| k=1 s t,k e k (8) d att t = tanh W 1 d t + W 2 e d t (9) p (a t |a &lt;t , x) = softmax at W o d att t + b o (10) where W 1 , W 2 ∈ R n×n , W o ∈ R |Va|×n , and b o ∈ R |Va| are parameters.</formula><p>Generation terminates once an end-of-sequence token "&lt;/s&gt;" is emitted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Meaning Representation Generation</head><p>Meaning representations are predicted by conditioning on the input x and the generated sketch a.</p><p>The model uses the encoder-decoder architecture to compute p (y|x, a), and decorates the sketch a with details to generate the final output.</p><p>Sketch Encoder As shown in <ref type="figure">Figure 1</ref>, a bidirectional LSTM encoder maps the sketch sequence a into vectors {v k } |a| k=1 as in Equation <ref type="formula" target="#formula_3">(6)</ref>, where v k denotes the vector of the k-th time step.</p><p>Fine Meaning Decoder The final decoder is based on recurrent neural networks with an attention mechanism, and shares the input encoder described in Section 3.1. The decoder's hidden states {h t } |y| t=1 are computed via:</p><formula xml:id="formula_7">i t = v k y t−1 is determined by a k y t−1 otherwise (11) h t = f LSTM (h t−1 , i t )</formula><p>where h 0 = [ − → e |x| , ← − e 1 ], and y t−1 is the embedding of the previously predicted token. Apart from using the embeddings of previous tokens, the decoder is also fed with {v k } |a| k=1 . If y t−1 is determined by a k in the sketch (i.e., there is a one-toone alignment between y t−1 and a k ), we use the corresponding token's vector v k as input to the next time step.</p><p>The sketch constrains the decoding output. If the output token y t is already in the sketch, we force y t to conform to the sketch. In some cases, sketch tokens will indicate what information is missing (e.g., in <ref type="figure">Figure 1</ref>, token "flight@1" indicates that an argument is missing for the predicate "flight"). In other cases, sketch tokens will not reveal the number of missing tokens (e.g., "STRING" in DJANGO) but the decoder's output will indicate whether missing details have been generated (e.g., if the decoder emits a closing quote token for "STRING"). Moreover, type information in sketches can be used to constrain generation. In <ref type="table">Table 1</ref>, sketch token "NUMBER" specifies that a numeric token should be emitted.</p><p>For the missing details, we use the hidden vector h t to compute p (y t |y &lt;t , x, a), analogously to Equations (7)-(10).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Training and Inference</head><p>The model's training objective is to maximize the log likelihood of the generated meaning representations given natural language expressions:</p><formula xml:id="formula_8">max (x,a,y)∈D log p (y|x, a) + log p (a|x) where D represents training pairs.</formula><p>At test time, the prediction for input x is obtained viaâ = arg max a p (a |x) andŷ = arg max y p (y |x,â), where a and y represent coarse-and fine-grained meaning candidates. Because probabilities p (a|x) and p (y|x, a) are factorized as shown in Equations <ref type="formula" target="#formula_1">(2)-(3)</ref>, we can obtain best results approximately by using greedy search to generate tokens one by one, rather than iterating over all candidates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Semantic Parsing Tasks</head><p>In order to show that our framework applies across domains and meaning representations, we developed models for three tasks, namely parsing natural language to logical form, to Python source code, and to SQL query. For each of these tasks we describe the datasets we used, how sketches were extracted, and specify model details over and above the architecture presented in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Natural Language to Logical Form</head><p>For our first task we used two benchmark datasets, namely GEO (880 language queries to a database of U.S. geography) and ATIS (5, 410 queries to a flight booking system). Examples are shown in <ref type="table">Table 1</ref> (see the first and second block). We used standard splits for both datasets: 600 training and 280 test instances for GEO <ref type="bibr" target="#b48">(Zettlemoyer and Collins, 2005)</ref>; 4, 480 training, 480 development, and 450 test examples for ATIS. Meaning representations in these datasets are based on λ-calculus <ref type="bibr" target="#b24">(Kwiatkowski et al., 2011)</ref>. We use brackets to linearize the hierarchical structure.</p><p>Algorithm 1 Sketch for GEO and ATIS Input: t: Tree-structure λ-calculus expression t.pred: Predicate name, or operator name Output: a: Meaning sketch (count $0 (&lt; (fare $0) 50:do))→(count#1 (&lt; fare@1 ?)) function SKETCH(t)</p><p>if t is leaf then No nonterminal in arguments return "%s@%d" % (t.pred, len(t.args)) if t.pred is λ operator, or quantifier then e.g., count</p><p>Omit variable information defined by t.pred t.pred ← "%s#%d" % (t.pred, len(variable)) for c ← argument in t.args do if c is nonterminal then c ← SKETCH(c) else c ← "?" Placeholder for terminal return t</p><p>The first element between a pair of brackets is an operator or predicate name, and any remaining elements are its arguments.</p><p>Algorithm 1 shows the pseudocode used to extract sketches from λ-calculus-based meaning representations. We strip off arguments and variable names in logical forms, while keeping predicates, operators, and composition information. We use the symbol "@" to denote the number of missing arguments in a predicate. For example, we extract "from@2" from the expression "(from $0 dallas:ci)" which indicates that the predicate "from" has two arguments. We use "?" as a placeholder in cases where only partial argument information can be omitted. We also omit variable information defined by the lambda operator and quantifiers (e.g., exists, count, and argmax). We use the symbol "#" to denote the number of omitted tokens. For the example in <ref type="figure">Figure 1</ref>, "lambda $0 e" is reduced to "lambda#2".</p><p>The meaning representations of these two datasets are highly compositional, which motivates us to utilize the hierarchical structure of λ-calculus. A similar idea is also explored in the tree decoders proposed in <ref type="bibr" target="#b10">Dong and Lapata (2016)</ref> and <ref type="bibr" target="#b47">Yin and Neubig (2017)</ref> where parent hidden states are fed to the input gate of the LSTM units. On the contrary, parent hidden states serve as input to the softmax classifiers of both fine and coarse meaning decoders.</p><p>Parent Feeding Taking the meaning sketch "(and flight@1 from@2)" as an example, the parent of "from@2" is "(and". Let p t denote the parent of the t-th time step in the decoder. Compared with Equation <ref type="formula" target="#formula_0">(10)</ref>, we use the vector d att t and the hidden state of its parent d pt to compute the prob-ability p (a t |a &lt;t , x) via:</p><formula xml:id="formula_9">p (a t |a &lt;t , x) = softmax at W o [d att t , d pt ] + b o</formula><p>where [·, ·] denotes vector concatenation. The parent feeding is used for both decoding stages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Natural Language to Source Code</head><p>Our second semantic parsing task used DJANGO <ref type="bibr" target="#b30">(Oda et al., 2015)</ref>, a dataset built upon the Python code of the Django library. The dataset contains lines of code paired with natural language expressions (see the third block in <ref type="table">Table 1</ref>) and exhibits a variety of use cases, such as iteration, exception handling, and string manipulation. The original split has 16, 000 training, 1, 000 development, and 1, 805 test instances. We used the built-in lexical scanner of Python 1 to tokenize the code and obtain token types. Sketches were extracted by substituting the original tokens with their token types, except delimiters (e.g., "[", and ":"), operators (e.g., "+", and "*"), and built-in keywords (e.g., "True", and "while"). For instance, the expression "if s[:4].lower() == 'http':" becomes "if NAME [ : NUMBER ] . NAME ( ) == STRING :", with details about names, values, and strings being omitted.</p><p>DJANGO is a diverse dataset, spanning various real-world use cases and as a result models are often faced with out-of-vocabulary (OOV) tokens (e.g., variable names, and numbers) that are unseen during training. We handle OOV tokens with a copying mechanism <ref type="bibr" target="#b14">(Gu et al., 2016;</ref><ref type="bibr" target="#b15">Gulcehre et al., 2016;</ref><ref type="bibr" target="#b19">Jia and Liang, 2016)</ref>, which allows the fine meaning decoder (Section 3.2) to directly copy tokens from the natural language input.</p><p>Copying Mechanism Recall that we use a softmax classifier to predict the probability distribution p (y t |y &lt;t , x, a) over the pre-defined vocabulary. We also learn a copying gate g t ∈ [0, 1] to decide whether y t should be copied from the input or generated from the vocabulary. We compute the modified output distribution via:</p><formula xml:id="formula_10">g t = sigmoid(w g · h t + b g )</formula><p>p (y t |y &lt;t , x, a) = (1 − g t )p (y t |y &lt;t , x, a)</p><formula xml:id="formula_11">+ 1 [yt / ∈Vy] g t k:x k =yt s t,k</formula><p>where w g ∈ R n and b g ∈ R are parameters, and the indicator function 1 [yt / ∈Vy] is 1 only if y t is not in the target vocabulary V y ; the attention score s t,k (see Equation <ref type="formula" target="#formula_5">(7)</ref>) measures how likely it is to copy y t from the input word x k .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Natural Language to SQL</head><p>The WIKISQL <ref type="bibr" target="#b53">(Zhong et al., 2017)</ref> dataset contains 80, 654 examples of questions and SQL queries distributed across 24, 241 tables from Wikipedia. The goal is to generate the correct SQL query for a natural language question and table schema (i.e., table column names), without using the content values of tables (see the last block in <ref type="table">Table 1</ref> for an example). The dataset is partitioned into a training set (70%), a development set (10%), and a test set (20%). Each table is present in one split to ensure generalization to unseen tables. WIKISQL queries follow the format "SELECT agg op agg col WHERE (cond col cond op cond) AND ...", which is a subset of the SQL syntax. SELECT identifies the column that is to be included in the results after applying the aggregation operator agg op 2 to column agg col. WHERE can have zero or multiple conditions, which means that column cond col must satisfy the constraints expressed by the operator cond op 3 and the condition value cond. Sketches for SQL queries are simply the (sorted) sequences of condition operators cond op in WHERE clauses. For example, in <ref type="table">Table 1</ref>, sketch "WHERE &gt; AND =" has two condition operators, namely "&gt;" and "=".</p><p>The generation of SQL queries differs from our previous semantic parsing tasks, in that the table schema serves as input in addition to natural language. We therefore modify our input encoder in order to render it table-aware, so to speak. Furthermore, due to the formulaic nature of the SQL query, we only use our decoder to generate the WHERE clause (with the help of sketches). The SELECT clause has a fixed number of slots (i.e., aggregation operator agg op and column agg col), which we straightforwardly predict with softmax classifiers (conditioned on the input). We briefly explain how these components are modeled below.  <ref type="figure">Figure 2</ref>: <ref type="table" target="#tab_1">Table-</ref>aware input encoder (left) and table column encoder (right) used for WIKISQL.</p><p>as " c 1,1 · · · c 1,|c 1 | · · · c M,1 · · · c M,|c M | ", where the k-th column ("c k,1 · · · c k,|c k | ") has |c k | words. As shown in <ref type="figure">Figure 2</ref>, we use bi-directional LSTMs to encode the whole sequence. Next, for column c k , the LSTM hidden states at positions c k,1 and c k,|c k | are concatenated. Finally, the concatenated vectors are used as the encoding vectors {c k } M k=1 for table columns. As mentioned earlier, the meaning representations of questions are dependent on the tables. As shown in <ref type="figure">Figure 2</ref>, we encode the input question x into {e t } |x| t=1 using LSTM units. At each time step t, we use an attention mechanism towards table column vectors {c k } M k=1 to obtain the most relevant columns for e t . The attention score from e t to c k is computed via u t,k ∝ exp{α(e t ) · α(c k )}, where α(·) is a one-layer neural network, and M k=1 u t,k = 1. Then we compute the context vector c e t = M k=1 u t,k c k to summarize the relevant columns for e t . We feed the concatenated vectors {[e t , c e t ]} |x| t=1 into a bi-directional LSTM encoder, and use the new encoding vectors {ẽ t } |x| t=1 to replace {e t } |x| t=1 in other model components. We define the vector representation of input x as:</p><formula xml:id="formula_12">ẽ = [ − → e |x| , ← − e 1 ]<label>(12)</label></formula><p>analogously to Equations (4)-(6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SELECT Clause</head><p>We feed the question vectorẽ into a softmax classifier to obtain the aggregation operator agg op. If agg col is the k-th table column, its probability is computed via:</p><formula xml:id="formula_13">σ(x) = w 3 · tanh (W 4 x + b 4 ) (13) p (agg col = k|x) ∝ exp{σ([ẽ, c k ])} (14)</formula><p>where M j=1 p (agg col = j|x) = 1, σ(·) is a scoring network, and W 4 ∈ R 2n×m , w 3 , b 4 ∈ R m are parameters. WHERE Clause We first generate sketches whose details are subsequently decorated by the fine meaning decoder described in Section 3.2. As the number of sketches in the training set is small (35 in total), we model sketch generation as a classification problem. We treat each sketch a as a category, and use a softmax classifier to compute p (a|x):</p><formula xml:id="formula_14">p (a|x) = softmax a (W aẽ + b a )</formula><p>where W a ∈ R |Va|×n , b a ∈ R |Va| are parameters, andẽ is the table-aware input representation defined in Equation <ref type="formula" target="#formula_0">(12)</ref>.</p><p>Once the sketch is predicted, we know the condition operators and number of conditions in the WHERE clause which follows the format "WHERE (cond op cond col cond) AND ...". As shown in <ref type="figure" target="#fig_1">Figure 3</ref>, our generation task now amounts to populating the sketch with condition columns cond col and their values cond.</p><p>Let {h t } |y| t=1 denote the LSTM hidden states of the fine meaning decoder, and {h att t } |y| t=1 the vectors obtained by the attention mechanism as in Equation <ref type="formula">(9)</ref>. The condition column cond col yt is selected from the table's headers. For the k-th column in the table, we compute p (cond col yt = k|y &lt;t , x, a) as in Equation <ref type="formula" target="#formula_0">(14)</ref>, but use different parameters and compute the score via σ([h att t , c k ]). If the k-th table column is selected, we use c k for the input of the next LSTM unit in the decoder.</p><p>Condition values are typically mentioned in the input questions. These values are often phrases with multiple tokens (e.g., Mikhail Snitko in Table 1). We therefore propose to select a text span from input x for each condition value cond yt rather than copying tokens one by one. Let x l · · · x r denote the text span from which cond yt is copied. We factorize its probability as: p (cond yt = x l · · · x r |y &lt;t , x, a) = p l L yt |y &lt;t , x, a p r R yt |y &lt;t , x, a, l L yt p l L yt |y &lt;t , x, a ∝ exp{σ([h att t ,ẽ l ])} p r R yt |y &lt;t , x, a, l L yt ∝ exp{σ([h att t ,ẽ l ,ẽ r ])} where l L yt / r R yt represents the first/last copying index of cond yt is l/r, the probabilities are normalized to 1, and σ(·) is the scoring network defined in Equation <ref type="formula" target="#formula_0">(13)</ref>. Notice that we use different parameters for the scoring networks σ(·). The copied span is represented by the concatenated vector [ẽ l ,ẽ r ], which is fed into a one-layer neural network and then used as the input to the next LSTM unit in the decoder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We present results on the three semantic parsing tasks discussed in Section 4. Our implementation and pretrained models are available at https:// github.com/donglixp/coarse2fine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Setup</head><p>Preprocessing For GEO and ATIS, we used the preprocessed versions provided by <ref type="bibr" target="#b10">Dong and Lapata (2016)</ref>, where natural language expressions are lowercased and stemmed with NLTK <ref type="bibr" target="#b7">(Bird et al., 2009)</ref>, and entity mentions are replaced by numbered markers. We combined predicates and left brackets that indicate hierarchical structures to make meaning representations compact. We employed the preprocessed DJANGO data provided by <ref type="bibr" target="#b47">Yin and Neubig (2017)</ref>, where input expressions are tokenized by NLTK, and quoted strings in the input are replaced with place holders. WIK-ISQL was preprocessed by the script provided by <ref type="bibr" target="#b53">Zhong et al. (2017)</ref>, where inputs were lowercased and tokenized by Stanford CoreNLP .</p><p>Configuration Model hyperparameters were cross-validated on the training set for GEO, and were validated on the development split for the other datasets. Dimensions of hidden vectors and word embeddings were selected from {250, 300} and {150, 200, 250, 300}, respectively.</p><p>The dropout rate was selected from {0.3, 0.5}. Label smoothing <ref type="bibr" target="#b37">(Szegedy et al., 2016)</ref> was employed for GEO and ATIS. The smoothing parameter was set to 0.1. For WIKISQL, the hidden size of σ(·) Method GEO ATIS ZC07 <ref type="bibr" target="#b49">(Zettlemoyer and Collins, 2007)</ref> 86.1 84.6 UBL <ref type="bibr" target="#b22">(Kwiatkowksi et al., 2010)</ref> 87.9 71.4 FUBL <ref type="bibr" target="#b24">(Kwiatkowski et al., 2011)</ref> 88.6 82.8 GUSP++ <ref type="bibr" target="#b33">(Poon, 2013)</ref> -83.5 KCAZ13 <ref type="bibr" target="#b23">(Kwiatkowski et al., 2013)</ref> 89.0 -DCS+L  87.9 -TISP <ref type="bibr" target="#b52">(Zhao and Huang, 2015)</ref> 88.9 84.2 SEQ2SEQ <ref type="bibr" target="#b10">(Dong and Lapata, 2016)</ref> 84.6 84.2 SEQ2TREE <ref type="bibr" target="#b10">(Dong and Lapata, 2016)</ref> 87.1 84.6 ASN <ref type="bibr" target="#b34">(Rabinovich et al., 2017)</ref> 85.7 85.3 ASN+SUPATT <ref type="bibr" target="#b34">(Rabinovich et al., 2017)</ref>   and α(·) in Equation <ref type="formula" target="#formula_0">(13)</ref> was set to 64. Word embeddings were initialized by GloVe <ref type="bibr" target="#b31">(Pennington et al., 2014)</ref>, and were shared by table encoder and input encoder in Section 4.3. We appended 10-dimensional part-of-speech tag vectors to embeddings of the question words in WIKISQL. The part-of-speech tags were obtained by the spaCy toolkit. We used the RMSProp optimizer (Tieleman and Hinton, 2012) to train the models. The learning rate was selected from {0.002, 0.005}. The batch size was 200 for WIKISQL, and was 64 for other datasets. Early stopping was used to determine the number of epochs.</p><p>Evaluation We use accuracy as the evaluation metric, i.e., the percentage of the examples that are correctly parsed to their gold standard meaning representations. For WIKISQL, we also execute generated SQL queries on their corresponding tables, and report the execution accuracy which is defined as the proportion of correct answers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results and Analysis</head><p>We compare our model (COARSE2FINE) against several previously published systems as well as various baselines. Specifically, we report results with a model which decodes meaning representations in one stage (ONESTAGE) without leveraging sketches. We also report the results of several ablation models, i.e., without a sketch encoder and without a table-aware input encoder. <ref type="table" target="#tab_3">Table 2</ref> presents our results on GEO and ATIS. Overall, we observe that COARSE2FINE outperforms ONESTAGE, which suggests that disentangling high-level from low-level information dur-    and <ref type="bibr" target="#b47">Yin and Neubig (2017)</ref>.</p><p>ing decoding is beneficial. The results also show that removing the sketch encoder harms performance since the decoder loses access to additional contextual information. Compared with previous neural models that utilize syntax or grammatical information (SEQ2TREE, ASN; the second block in <ref type="table" target="#tab_3">Table 2</ref>), our method performs competitively despite the use of relatively simple decoders. As an upper bound, we report model accuracy when gold meaning sketches are given to the fine meaning decoder (+oracle sketch). As can be seen, predicting the sketch correctly boosts performance. The oracle results also indicate the accuracy of the fine meaning decoder. <ref type="table" target="#tab_5">Table 3</ref> reports results on DJANGO where we observe similar tendencies. COARSE2FINE outperforms ONESTAGE by a wide margin. It is also superior to the best reported result in the literature (SNM+COPY; see the second block in the table). Again we observe that the sketch encoder is beneficial and that there is an 8.9 point difference in accuracy between COARSE2FINE and the oracle.</p><p>Results on WIKISQL are shown in <ref type="table" target="#tab_7">Table 4</ref>. Our model is superior to ONESTAGE as well as to previous best performing systems. COARSE2FINE's accuracies on aggregation agg op and agg col are 90.2% and 92.0%, respectively, which is comparable to SQLNET <ref type="bibr" target="#b45">(Xu et al., 2017)</ref>. So the most gain is obtained by the improved decoder of the WHERE clause. We also find that a tableaware input encoder is critical for doing well on this task, since the same question might lead to different SQL queries depending on the table schemas. Consider the question "how many presidents are graduated from A ". The SQL query over   COUNT(President) WHERE (College = A)", but the query over table " College Number of Presidents " would be "SELECT Number of Presidents WHERE (College = A)". We also examine the predicted sketches themselves in <ref type="table" target="#tab_8">Table 5</ref>. We compare sketches generated by COARSE2FINE against ONESTAGE. The latter model generates meaning representations without an intermediate sketch generation stage. Nevertheless, we can extract sketches from the output of ONESTAGE following the procedures described in Section 4. Sketches produced by COARSE2FINE are more accurate across the board. This is not surprising because our model is trained explicitly to generate compact meaning sketches. Taken together (Tables 2-4), our results show that better sketches bring accuracy gains on GEO, ATIS, and DJANGO. On WIKISQL, the sketches predicted by COARSE2FINE are marginally better compared with ONESTAGE. Performance improvements on this task are mainly due to the fine meaning decoder. We conjecture that by decomposing decoding into two stages, COARSE2FINE can better match table columns and extract condition values without interference from the prediction of condition operators. Moreover, the sketch provides a canonical order of condition operators, which is beneficial for the decoding process <ref type="bibr" target="#b40">(Vinyals et al., 2016;</ref><ref type="bibr" target="#b45">Xu et al., 2017)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>In this paper we presented a coarse-to-fine decoding framework for neural semantic parsing. We first generate meaning sketches which abstract away from low-level information such as arguments and variable names and then predict missing details in order to obtain full meaning representations. The proposed framework can be easily adapted to different domains and meaning representations. Experimental results show that coarseto-fine decoding improves performance across tasks. In the future, we would like to apply the framework in a weakly supervised setting, i.e., to learn semantic parsers from question-answer pairs and to explore alternative ways of defining meaning sketches.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Fine meaning decoder of the WHERE clause used for WIKISQL.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table schema :Table 1 :</head><label>schema1</label><figDesc>Pianist Conductor Record Company Year of Recording Format x : What record company did conductor Mikhail Snitko record for after 1996? y : SELECT Record Company WHERE (Year of Recording &gt; 1996) AND (Conductor = Mikhail Snitko) a : WHERE &gt; AND = Examples of natural language expressions x, their meaning representations y, and meaning sketches a. The average number of tokens is shown in the second column.</figDesc><table><row><cell>with previous systems, despite employing rela-</cell></row><row><cell>tively simple sequence decoders.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table - Aware</head><label>-</label><figDesc>Input Encoder Given a table schema with M columns, we employ the special token " " to concatenate its header names 2 agg op ∈ {empty, COUNT, MIN, MAX, SUM, AVG}. 3 cond op ∈ {=, &lt;, &gt;}.</figDesc><table><row><cell>ǁ 1</cell><cell>ǁ 2</cell><cell>ǁ 3</cell><cell>ǁ 4</cell><cell></cell><cell></cell><cell></cell><cell cols="2">LSTM units</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Vectors</cell><cell></cell></row><row><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Attention</cell><cell></cell></row><row><cell cols="4">Question-to-Table Attention</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>1</cell><cell></cell><cell></cell><cell>2</cell><cell></cell><cell></cell></row><row><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>|| college</cell><cell>||</cell><cell>number</cell><cell>of</cell><cell>presidents</cell><cell>||</cell></row><row><cell></cell><cell cols="2">Input Question</cell><cell></cell><cell>Column 1</cell><cell></cell><cell cols="3">Column 2</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Accuracies on GEO and ATIS.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>DJANGO results. Accuracies in the first and second block are taken from</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>table "</head><label>"</label><figDesc>President College " is "SELECT</figDesc><table><row><cell>Method</cell><cell>Accuracy</cell><cell>Execution Accuracy</cell></row><row><cell>SEQ2SEQ</cell><cell>23.4</cell><cell>35.9</cell></row><row><cell>Aug Ptr Network</cell><cell>43.3</cell><cell>53.3</cell></row><row><cell>SEQ2SQL (Zhong et al., 2017)</cell><cell>48.3</cell><cell>59.4</cell></row><row><cell>SQLNET (Xu et al., 2017)</cell><cell>61.3</cell><cell>68.0</cell></row><row><cell>ONESTAGE</cell><cell>68.8</cell><cell>75.9</cell></row><row><cell>COARSE2FINE</cell><cell>71.7</cell><cell>78.5</cell></row><row><cell>− sketch encoder</cell><cell>70.8</cell><cell>77.7</cell></row><row><cell>− table-aware input encoder</cell><cell>68.6</cell><cell>75.6</cell></row><row><cell>+ oracle sketch</cell><cell>73.0</cell><cell>79.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>Evaluation results on WIKISQL. Accuracies in the first block are taken from<ref type="bibr" target="#b53">Zhong et al. (2017)</ref> and<ref type="bibr" target="#b45">Xu et al. (2017)</ref>.</figDesc><table><row><cell>Method</cell><cell cols="4">GEO ATIS DJANGO WIKISQL</cell></row><row><cell>ONESTAGE</cell><cell>85.4</cell><cell>85.9</cell><cell>73.2</cell><cell>95.4</cell></row><row><cell>COARSE2FINE</cell><cell>89.3</cell><cell>88.0</cell><cell>77.4</cell><cell>95.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>Sketch accuracy. For ONESTAGE, sketches are extracted from the meaning representations it generates.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://docs.python.org/3/library/ tokenize</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank Pengcheng Yin for sharing with us the preprocessed version of the DJANGO dataset. We gratefully acknowledge the financial support of the European Research Council (award number 681760; Dong, Lapata) and the AdeptMind Scholar Fellowship program (Dong).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi</forename><surname>Alfred V Aho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">D</forename><surname>Sethi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ullman</surname></persName>
		</author>
		<title level="m">Compilers: principles, techniques, and tools</title>
		<imprint>
			<publisher>Addison-wesley Reading</publisher>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Tree-structured decoding with doubly-recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Alvarez-Melis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommi</forename><forename type="middle">S</forename><surname>Jaakkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Conference on Learning Representations</title>
		<meeting>the 5th International Conference on Learning Representations<address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Semantic parsing as machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="47" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Weakly supervised learning of semantic parsers for mapping instructions to actions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association of Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="49" to="62" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Conference on Learning Representations</title>
		<meeting>the 3rd International Conference on Learning Representations<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Semantic parsing on Freebase from question-answer pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013</title>
		<meeting>the 2013</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<title level="m">Conference on Empirical Methods in Natural Language Processing</title>
		<meeting><address><addrLine>Seattle, Washington</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="1533" to="1544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Natural Language Processing with Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ewan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Loper</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<pubPlace>O&apos;Reilly Media</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Multilevel coarse-to-fine PCFG parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micha</forename><surname>Elsner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Austerweil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isaac</forename><surname>Haxton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catherine</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Shrivaths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Pozar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theresa</forename><surname>Vu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Human Language Technology Conference of the NAACL</title>
		<meeting>the Human Language Technology Conference of the NAACL<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="168" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning structured natural language representations for semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianpeng</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Saraswat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1005</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="44" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Language to logical form with neural attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="33" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Transfer learning for neural semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emilio</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lambert</forename><surname>Mathias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Dreyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Representation Learning for NLP</title>
		<meeting>the 2nd Workshop on Representation Learning for NLP<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="48" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Component-based synthesis for complex apis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruben</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuepeng</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1145/3009837.3009851</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 44th ACM SIGPLAN Symposium on Principles of Programming Languages</title>
		<meeting>the 44th ACM SIGPLAN Symposium on Principles of Programming Languages<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="599" to="612" />
		</imprint>
	</monogr>
	<note>Isil Dillig, and Thomas Reps</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A statistical semantic parser that integrates syntax and semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruifang</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth Conference on Computational Natural Language Learning</title>
		<meeting>the Ninth Conference on Computational Natural Language Learning<address><addrLine>Ann Arbor, Michigan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Incorporating copying mechanism in sequence-to-sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiatao</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengdong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">K</forename><surname>Victor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1631" to="1640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Pointing the unknown words</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungjin</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="140" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Neural semantic parsing over multiple knowledge-bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-2098</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="623" to="628" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="DOI">10.1162/neco.1997.9.8.1735</idno>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning a neural semantic parser from user feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinivasan</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Konstas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alvin</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jayant</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="963" to="973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Data recombination for neural semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="12" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Semantic parsing with semi-supervised sequential autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomáš</forename><surname>Kočiský</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gábor</forename><surname>Melis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><forename type="middle">Moritz</forename><surname>Hermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1078" to="1087" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Neural semantic parsing with type constraints for semi-structured tables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jayant</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pradeep</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1517" to="1527" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Inducing probabilistic CCG grammars from logical form with higherorder unification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowksi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Goldwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1223" to="1233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Scaling semantic parsers with on-the-fly ontology matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Seattle, Washington</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1545" to="1556" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Lexical generalization in CCG grammar induction for semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Goldwater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Edinburgh, Scotland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1512" to="1523" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning dependency-based compositional semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">39</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Latent predictor networks for code generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><forename type="middle">Moritz</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomáš</forename><surname>Kočiský</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fumin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Senior</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="599" to="609" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A generative model for parsing natural language to meaning representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wee</forename><surname>Hwee Tou Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Sun Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2008 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Honolulu, Hawaii</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="783" to="792" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Effective approaches to attention-based neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1412" to="1421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mc-Closky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Association for Computational Linguistics System Demonstrations</title>
		<meeting><address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning to generate pseudo-code from source code using statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Oda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroyuki</forename><surname>Fudaba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideaki</forename><surname>Hata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sakriani</forename><surname>Sakti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoki</forename><surname>Toda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satoshi</forename><surname>Nakamura</surname></persName>
		</author>
		<idno type="DOI">10.1109/ASE.2015.36</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 30th IEEE/ACM International Conference on Automated Software Engineering</title>
		<meeting>the 2015 30th IEEE/ACM International Conference on Automated Software Engineering<address><addrLine>Washington, DC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="574" to="584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">GloVe: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Coarse-to-fine natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Grounded unsupervised semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoifung</forename><surname>Poon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="933" to="943" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Abstract syntax networks for code generation and semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Rabinovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><surname>Stern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1139" to="1149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Program Synthesis by Sketching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armando</forename><surname>Solar-Lezama</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<pubPlace>Berkeley, CA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of California at Berkeley</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Neural architectures for multilingual semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond Hendy</forename><surname>Susanto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="38" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zbigniew</forename><surname>Wojna</surname></persName>
		</author>
		<idno type="DOI">10.1109/cvpr.2016.308</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Automated construction of database interfaces: Intergrating statistical and relational learning for semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lappoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mooney</surname></persName>
		</author>
		<idno type="DOI">10.3115/1117794.1117811</idno>
	</analytic>
	<monogr>
		<title level="m">2000 Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora</title>
		<meeting><address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="133" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Lecture 6.5-RMSProp: Divide the gradient by a running average of its recent magnitude</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Order matters: Sequence to sequence for sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manjunath</forename><surname>Kudlur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th International Conference on Learning Representations</title>
		<meeting>the 4th International Conference on Learning Representations<address><addrLine>San Juan, Puerto Rico</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Grammar as a foreign language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Neural Information Processing Systems</title>
		<meeting>the 28th International Conference on Neural Information Processing Systems<address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2773" to="2781" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Learning synchronous grammars for semantic parsing with lambda calculus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuk</forename><forename type="middle">Wah</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th</title>
		<meeting>the 45th</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
				<title level="m">Annual Meeting of the Association of Computational Linguistics</title>
		<meeting><address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="960" to="967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Sequence-based structured prediction for semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyang</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Dymetman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Gardent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1341" to="1350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.04436</idno>
		<title level="m">SQL-Net: Generating structured queries from natural language without reinforcement learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">SQLizer: Query synthesis from natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navid</forename><surname>Yaghmazadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuepeng</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1145/3133887</idno>
		<idno>1:63:1-63:26</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Programming Languages</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Isil Dillig, and Thomas Dillig</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A syntactic neural model for general-purpose code generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengcheng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="440" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st Conference on Uncertainty in Artificial Intelligence</title>
		<meeting>the 21st Conference on Uncertainty in Artificial Intelligence<address><addrLine>Edinburgh, Scotland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="658" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Online learning of relaxed CCG grammars for parsing to logical form</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="678" to="687" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Automatically synthesizing SQL queries from input-output examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuyin</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.1109/ASE.2013.6693082</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th IEEE/ACM International Conference on Automated Software Engineering</title>
		<meeting>the 28th IEEE/ACM International Conference on Automated Software Engineering<address><addrLine>Piscataway, NJ</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="224" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Macro grammars and holistic triggering for efficient semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panupong</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/d17-1125</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1214" to="1223" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Type-driven incremental semantic parsing with polymorphism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Denver, Colorado</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1416" to="1421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.00103</idno>
		<title level="m">Seq2SQL: Generating structured queries from natural language using reinforcement learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
