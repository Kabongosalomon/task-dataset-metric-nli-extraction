<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SCALABLE NEURAL DIALOGUE STATE TRACKING</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vevake</forename><surname>Balaraman</surname></persName>
							<email>balaraman@fbk.eu</email>
							<affiliation key="aff0">
								<orgName type="institution">Fondazione Bruno Kessler</orgName>
								<address>
									<settlement>Trento</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">ICT Doctoral School</orgName>
								<orgName type="institution">University of Trento</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardo</forename><surname>Magnini</surname></persName>
							<email>magnini@fbk.eu</email>
							<affiliation key="aff0">
								<orgName type="institution">Fondazione Bruno Kessler</orgName>
								<address>
									<settlement>Trento</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SCALABLE NEURAL DIALOGUE STATE TRACKING</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T17:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Dialogue state tracking</term>
					<term>deep learning</term>
					<term>dialogue systems</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A Dialogue State Tracker (DST) is a key component in a dialogue system aiming at estimating the beliefs of possible user goals at each dialogue turn. Most of the current DST trackers make use of recurrent neural networks and are based on complex architectures that manage several aspects of a dialogue, including the user utterance, the system actions, and the slot-value pairs defined in a domain ontology. However, the complexity of such neural architectures incurs into a considerable latency in the dialogue state prediction, which limits the deployments of the models in real-world applications, particularly when task scalability (i.e. amount of slots) is a crucial factor. In this paper, we propose an innovative neural model for dialogue state tracking, named Global encoder and Slot-Attentive decoders (G-SAT), which can predict the dialogue state with a very low latency time, while maintaining high-level performance. We report experiments on three different languages (English, Italian, and German) of the WOZ2.0 dataset, and show that the proposed approach provides competitive advantages over state-of-art DST systems, both in terms of accuracy and in terms of time complexity for predictions, being over 15 times faster than the other systems.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Spoken dialogue systems, or conversational systems, are designed to interact and assist users using speech and natural language to achieve a certain goal <ref type="bibr" target="#b0">[1]</ref>. A consolidated approach to build a task-oriented dialogue system involves a pipeline architecture (see <ref type="figure">Figure 1)</ref>, where each component is trained to perform a sub-task, and the combination of the modules in a given sequence aims at handling the complete task-oriented dialogue. In such a pipeline, a spoken language understanding (SLU) module determines the user's intent and the relevant information that the user is providing represented in terms of slot-value pairs. Then, the dialogue state tracker (DST) uses the information of the SLU together with the past dialogue context and updates its belief state <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>. In this <ref type="figure">Fig. 1</ref>. A typical flow in a task-oriented dialog system <ref type="bibr" target="#b3">[4]</ref>. framework a dialogue state indicates what the user requires at any point in the dialogue, and it is represented as a probability distribution over the possible states (typically a set of pre-defined slot-value pairs specific of the task). The dialogue policy manager, then, decides on the next system action based on the dialogue state. Finally, a natural language generation (NLG) component is responsible for the generation of an utterance that is returned as response to the user.</p><p>In this paper we focus on the dialogue state tracker component, whose role is to track the state of the dialogue based on the current user utterance, the conversation history and any additional information available to the system <ref type="bibr" target="#b0">[1]</ref>. Deep neural network techniques, such as recurrent neural network and convolutional neural networks, are the current state-of-the-art models for DST <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9]</ref>, showing high capacity to generalize from annotated dialogues. As an example, the GLAD model (Global-Locally Self-Attentive Dialogue State Tracker - <ref type="bibr" target="#b8">[9]</ref>), employs independent slot-specific encoders, consisting of a recurrent and a self-attention layer, for each of the user utterance, the system action and the slot-value pairs. Another DST system, GCE (Globally Conditioned Encoder - <ref type="bibr" target="#b9">[10]</ref>), simplifies the GLAD neural architecture removing the slotspecific recurrent and self-attention layers of the encoder, but still requires separate encoders for the utterance, the system action and the slot-values.</p><p>Although the neural network models mentioned above achieve state-of-the-art performance, the complexity of their architectures make them highly inefficient in terms of time complexity, with a significant latency in their prediction time.</p><p>Such latency may soon become a serious limitation for their deployment into concrete application scenarios with increasing number of slots, where real time is a strong requirement. Along this perspective, this work investigates the time complexity of state-of-the-art DST models and addresses their current limitations. Our contributions are the following:</p><p>• we have designed and implemented an efficient DST, consisting of a Global encoder and Slot-Attentive decoders (G-SAT);</p><p>• we provide empirical evidences (three languages of the WOZ2.0 dataset <ref type="bibr" target="#b6">[7]</ref>) that the proposed G-SAT model considerably reduces the latency time with respect to state-of-art DST systems (i.e. over 15 times faster), while keeping the dialogue state prediction inline with such systems;</p><p>• further experiments show that the proposed model is highly robust when either pre-trained embeddings are used or when they are not used, in this case outperforming state-of-art systems.</p><p>The implementation of the proposed G-SAT model is publicly available <ref type="bibr" target="#b0">1</ref> .</p><p>The paper is structured as follows. Section 2 summarizes the main concepts behind the definition of dialogue state tracking. Section 3 reports the relevant related work. Section 4 provides the details of the proposed G-SAT neural model, and, finally, Section 5 and 6 focus on the experiments and the discussion of the results we achieved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">DIALOGUE STATE TRACKING</head><p>A Dialogue State Tracker (DST) estimates the distribution over the values V s for each slot s ∈ S based on the user utterance and the dialogue history at each turn in the dialogue. Slots S are typically provided by a domain ontology, and they can either be informable (S inf ) or requestable (S req ). Informable slots are attributes that can be provided by the user during the dialogue as constraints, while requestable slots are attributes that the user may request from the system. The dialogue state typically maintains two internal properties:</p><p>• joint goal -indicating a value v ∈ V s that the user specifies for each informable slot s ∈ S inf .</p><p>• requests -indicating the information that the user has asked the system from the set of requestable slots S req .</p><p>For example, in the restaurant booking dialogue shown in <ref type="figure" target="#fig_0">Figure 2</ref>, extracted from the the WOZ2.0 dataset <ref type="bibr" target="#b6">[7]</ref>, the user specifies a constraint on the price range slot (i.e. inform(price range=moderate)) in the first utterance of the dialogue, and requests the phone number and the address (i.e. request(address, phone number)) in the second user utterance. The set of slot-value pairs specifying the constraints at any point in the dialogue (e.g. (price range=moderate, area=west, food=italian)) is referred to as the joint goal, while the requested slot-value pairs for a given turn (e.g. request(address, phone number)) as turn request.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Latency in Dialogue Systems</head><p>An effective dialogue system should be able to process the user utterance and respond in real-time in order to achieve a smooth dialogue interaction between the user and the dialogue system itself <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>. As a consequence, time latency in dialogue systems is very crucial, as it directly impacts the user experience. In real world applications, task-oriented dialogue systems typically follow a pipeline architecture (as shown in <ref type="figure">Figure 1</ref>) where multiple components need to interact with each other to produce a response for the user, the time complexity of each component plays a key role. In particular, the DST component is a bottleneck, as it needs to track the user's goals based on the dialogue and provides the output to other components of the whole process. Though end-to-end (E2E) approaches for dialogue systems have attracted recent research, dialog state tracking still remains an integral part in those systems, as shown by <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b13">14]</ref>. Current DST models use recurrent neural networks (RNN), as they are able to capture temporal dependencies in the input sentence. A RNN processes each token in the input sequentially, one after the other, and so can incur significant latency if not modeled well. Apart from the architecture, the number of slots and values of the domain ontology also affects the time complexity of the DST. Recent works <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b7">8]</ref> use RNNs to obtain very high performance for DST, but nevertheless are quite limited as far as the efficiency of the models are concerned. For instance, the GCE model <ref type="bibr" target="#b9">[10]</ref> addresses time complexity within the same architectural framework used by of GLAD <ref type="bibr" target="#b8">[9]</ref>, although the latency prediction of the model is still quite poor, at least for a production system (more details in Section 5). This limitation could be attributed to the fact that both GLAD and GCE use separate recurrent modules to output representations for user utterance, system action and slot-value pairs. These output representations need then to be combined using a scoring module which scores a given slotvalue pair based on the user utterance and the system action separately. In this work, we investigate approaches that overcome the complexity of such architectures and improve the latency time without compromising the DST performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">RELATED WORK</head><p>Spoken dialogue systems typically consist of a spoken language understanding (SLU) component that performs slotfilling to detect slot-value pairs expressed in the user utterance. This information is then used by dialogue state tracker(DST) <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>. Recent research has focused on jointly modeling the SLU and the DST <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>. For such joint models, deep neural network techniques have been the choice of use because of their proven ability to extract features from a given input and their generalization capability <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8]</ref>. Following this research line, <ref type="bibr" target="#b4">[5]</ref> proposed a word-based DST (based on a delexicalisation approach) that jointly models SLU and DST, and directly maps from the utterances to an updated belief state. <ref type="bibr" target="#b6">[7]</ref> proposed a data-driven approach for DST, named neural belied tracker (NBT), which learns a vector representation for each slot-value pair and compares them with the vector representation of the user utterance to predict if the user has expressed the corresponding slot-value pair. The NBT model uses pre-trained semantic embeddings to train a model without semantic lexicon.</p><p>GLAD (Global-Locally Self-Attentive Dialogue State Tracker) <ref type="bibr" target="#b8">[9]</ref> consists of a shared global bidirectional-LSTM <ref type="bibr" target="#b14">[15]</ref> for all slots, and a local bidirectional-LSTM for each slot. The global and local representations are then combined using attention, which then is used by a scoring module to obtain scores for each slot-value pair. GLAD also relies on pre-trained embeddings, and since it consists of multiple recurrent modules, the latency of the model is quite high. In <ref type="bibr" target="#b9">[10]</ref>, a Globally conditioned encoder (GCE) is used as a shared encoder for all slots and aim to address this issue by proposing a single encoder with global conditioning. While this approach reduced the latency of GLAD, it still has a considerable time complexity for real-world applications, which is discussed in Section 6.</p><p>StateNet, proposed by <ref type="bibr" target="#b7">[8]</ref>, uses a LSTM network to create a vector representation of the user utterance, which is then compared against the vector representation of the slot-value candidates. <ref type="bibr" target="#b7">[8]</ref> is the current state-of-art for DST: however it can be used for domains iff pre-trained embeddings exist and can only be modelled for informable slot and not for the requestable slots. <ref type="bibr" target="#b15">[16]</ref> used convolutional neural network (CNN) for DST and showed that without pre-trained embeddings or semantic dictionaries, the model can be competitive to state-of-the-art.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">THE G-SAT MODEL</head><p>The proposed approach, G-SAT (Global encoder and Slot-Attentive decoders), is designed to predict slot value pairs for a given turn in the dialogue. For a dialogue turn, given the user utterance U , the previous system action A and the value set V s for slot s ∈ S, the proposed model provides a probability distribution over slot-value set V s .</p><formula xml:id="formula_0">P s = DST (A, U, V s )<label>(1)</label></formula><p>The model consists of a single encoder module and a number of slot specific decoder (classifier) modules. The encoder consists of a recurrent neural network that takes as input both the user utterance U and the previous system action A, and outputs a vector representation h. The classifier then receives the representation h and the slot-values v ∈ V s and estimates the probability of each value in a given slot.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Encoder</head><p>The encoder takes in the previous system action A and the current user utterance U as inputs, and processes them iteratively to output a hidden representation for each token in the input, as well as the context vector.</p><p>Let the user utterance at time t be denoted as U = {u 1 , u 2 , ..., u k } with k words and A denotes the previous system action. The system action A is converted into a sequence of tokens that include the action, slot and value (e.g. confirm(food=Italian) → confirm food Italian) and is denoted as A = {a 1 , a 2 , .., a l }. In case of multiple actions expressed by the system, we concatenate them together. The user utterance U and system action A are then concatenated forming the input X to the encoder.</p><formula xml:id="formula_1">X = [a 1 , ...a l ; u 1 , ..u k ] = [x 1 , x 2 , ...x n ]</formula><p>where [ ; ] denotes concatenation. Each input tokens in {x 1 , x 2 , ..x n } is then represented as a vector {x 1 , x 2 , .., x n } by an embedding matrix E ∈ R |v|×d , where |v| is the vocabulary size and d is the embedding dimension. This representation is then input to a bidirectional-LSTM <ref type="bibr" target="#b14">[15]</ref> that processes the input in both forward and backward directions, to yield the hidden representations, as follows:</p><formula xml:id="formula_2">− → h t = LST M f ( − → h t−1 , x t ) (2) ← − h t = LST M b ( ← − h t+1 , x t )<label>(3)</label></formula><p>where LST M f (.) and LST M b (.) are the forward and backward LSTMs. − → h t and ← − h t are the corresponding hidden states of forward and backward LSTMs at time t. The representations h t for each token in the input and the overall input representation h L are then obtained as follows:</p><formula xml:id="formula_3">h t = [ − → h t ; ← − h t ]<label>(4)</label></formula><formula xml:id="formula_4">h L = [ − → h n ; ← − h 1 ]<label>(5)</label></formula><p>Since our model uses a shared encoder for all slots, the outputs of the encoder h t and h L are used by slot specific classifiers for prediction on corresponding slots.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Classifier</head><p>The classifier predicts the probability for each of the possible values v ∈ V s of a given slot s ∈ S. It takes in the hidden representations h t and h L of the encoder, and the set of possible values V s for a given slot s, and computes the probability for each value being expressed as a constraint by the user. Initially, each of the slot-value is represented by a vector v, using the same embedding matrix E of the encoder. For slotvalues with multiple tokens, their corresponding embeddings are summed together to yield a single vector. The embeddings are then transformed as following to obtain a representation of the slot values:</p><formula xml:id="formula_5">Z s = W s V T s<label>(6)</label></formula><p>where V s = {v 1 , v 2 , ..} for slot s, and W s is the parameter learned during training. The encoder hidden state h L is then transformed using the ReLU activation function, to obtain a slot specific representation of the user utterance, as follows:</p><formula xml:id="formula_6">U s = ReLU (W h h L )<label>(7)</label></formula><p>Based on the slot specific input representation U s , an attention mechanism weights the hidden states of the input tokens h t to provide a context vector C.</p><formula xml:id="formula_7">a i = tanh(W c [U s ; h i ]) (8) α = Sof tmax(a)<label>(9)</label></formula><formula xml:id="formula_8">C = i α i h i<label>(10)</label></formula><p>Depending on the slot type (informable or requestable), the final layer of the classifier varies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">Informable slots</head><p>The context vector C and the slot-value representations Z s are then used to obtain the probability for each slot-value as follows:</p><formula xml:id="formula_9">score = C · Z s<label>(11)</label></formula><formula xml:id="formula_10">ψ i p = Sof tmax([score none ; score])<label>(12)</label></formula><p>where score none is the score for none value, and it is learned by the model. ψ i p is the probability of the slot-value pair expressed as constraint.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2.">Requestable slots</head><p>For requestable slots, we model a binary prediction for each possible requestable slot as follows:</p><formula xml:id="formula_11">score = C · Z s (13) ψ r p = Sigmoid(score)<label>(14)</label></formula><p>where ψ r p contains the probability for each requestable slot being requested by the user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">EXPERIMENTS</head><p>In this section we describe the dataset and the experimental setting used for the dialogue state tracking task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Datasets</head><p>We use the the WOZ2.0 <ref type="bibr" target="#b6">[7]</ref> dataset, collected using a Wizard of Oz framework, and consisting of written text conversations for the restaurant booking task. Each turn in a dialogue was contributed by different users, who had to review all previous turns in that dialogue before contributing to the turn. WOZ2.0 consists of a total of 1200 dialogues, out of which 600 are for training, 200 for development and 400 for testing. <ref type="bibr" target="#b17">[17]</ref> translated the WOZ.0 English data both to German and Italian using professional translators. We experiment on the three languages (English, German, Italian) of the WOZ2.0 dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Evaluation metrics</head><p>We evaluate our proposed model both in terms of performance and prediction latency. The performance of the model is evaluated using the standard metrics for dialogue state tracking, namely, joint goal and turn request <ref type="bibr" target="#b18">[18]</ref>.</p><p>• Joint Goal: indicates the performance of the model in correctly tracking the goal constraints over a dialogue. The joint goal is the set of accumulated turn level goals up to a given turn.</p><p>• Turn Request: indicates the performance of the model in correctly identifying the user's request for information at a given turn.</p><p>The prediction latency of the model is evaluated using time complexity.</p><p>• Time complexity: indicates the latency incurred by the model in making predictions. The time complexity is indicated as the time taken to process a single batch of data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Experimented Models</head><p>We compared our G-SAT model against seven DST models. The Delexicalisation model <ref type="bibr" target="#b6">[7]</ref> uses a delexicalisation approach (i.e. replacing slot value tokens with generic terms) and requires large semantic dictionaries, while all the other approaches are data driven. The neural belief tracker (NBT) <ref type="bibr" target="#b6">[7]</ref> builds on the advances in representation learning and uses pre-trained embeddings to overcome the requirement of handcrafted features. The convolutional neural network (CNN)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Joint Goal Turn Request Delexicalisation Model <ref type="bibr" target="#b6">[7]</ref> 70.8 87.1 NBT -CNN <ref type="bibr" target="#b6">[7]</ref> 84.2 91.6 NBT -DNN <ref type="bibr" target="#b6">[7]</ref> 84.4 91.2 CNN <ref type="bibr" target="#b15">[16]</ref> 86.9 95.4 GLAD <ref type="bibr" target="#b8">[9]</ref> 88.1 97.1 GCE <ref type="bibr" target="#b9">[10]</ref> 88.5 97.4 StateNet PSI <ref type="bibr" target="#b7">[8]</ref> 88.9 -Our Approach (G-SAT) 88.7 96.9 <ref type="table">Table 1</ref>. Dialog state tracking results on the WOZ2.0 English testset.</p><p>model <ref type="bibr" target="#b15">[16]</ref> is the only approach that does not use pre-trained embeddings, although they use also the development data for model training. GLAD <ref type="bibr" target="#b8">[9]</ref>, GCE <ref type="bibr" target="#b9">[10]</ref> and StateNet PSI <ref type="bibr" target="#b7">[8]</ref> are based on recurrent neural networks and use pre-trained embeddings. To facilitate comparison, our G-SAT approach is trained with the same pre-trained embeddings as used in GLAD and GCE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Implementation</head><p>We use the pytorch <ref type="bibr" target="#b19">[19]</ref> library to implement our model (G-SAT). The encoder of the model is shared across all slots and a separate classifier is defined for each slot. The number of hidden units of the LSTM is set to 64 and a dropout of 0.2 is applied between different layers. We use Adam optimizer with a learning rate of 0.001. The embedding dimension of the default model is set to 128, and embeddings are learned during training. In order to have a fair comparison with other models that use pre-trained embeddings, we also experiment our approach using pre-trained GloVe embeddings (of dimension 300) <ref type="bibr" target="#b20">[20]</ref>, and character n-gram embeddings (of dimension 100) <ref type="bibr" target="#b22">[21]</ref> as used in GLAD, leading to embedding of size 400. The turn-level predictions are accumulated forward through the dialogue and the goal for slot s is None until it is predicted as value v by the model. The implemented model is experimented with 10 different random initializations for each language, and the scores reported in Section 6 are the mean and standard deviation obtained in the experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">RESULTS AND DISCUSSION</head><p>In this section we initially discuss the model performance in terms of joint goal and turn request; and later we show a comparison of the time complexity of the models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">DST Performance</head><p>The joint goal and turn request performance of the experimented models (as they are reported in their respective papers) are shown in <ref type="table">Table 1</ref>. We can see that the G-SAT proposed architecture is comparable with respect to the other model and outperforms both GLAD and GCE on joint goal metric. This shows that G-SAT is highly competitive with the state of the art in DST. To investigate the behaviour of different models without any pre-trained embeddings, we use the official implementations of GLAD 2 and GCE 3 , and perform the experiments such that embeddings are learned from the data. We increased the epochs from 50 (default) to 150 for GLAD and GCE experiments, as we noticed that the model did not converge with 50 epochs (since embeddings are also learned here). The other parameters of the model are set as the default implementation. Since the core of the StateNet PSI model is to output a representation on which a 2-Norm distance is calculated against the word-vector of the slot-value, which is fixed, it is not suitable to train the embeddings. For this reason we do not experiment with StateNet PSI. In addition, the StateNet PSI model can only predict informable slots (i.e. can not predict requestable slots), unlike the other approaches considered in our experiments. <ref type="table">Table 2</ref> shows the joint goal performance of the models on both the development and test data for three different languages. We can see that our model (G-SAT) outperforms both GLAD and GCE on the three languages of the WOZ2.0 dataset when no pre-trained resources are available, and that the model performance is consistent across both the development and the test data. <ref type="table" target="#tab_1">Table 3</ref> shows the turn request performance of each model for the three languages. Even in this case the G-SAT model is very competitive on the three languages compared to both GLAD and GCE models. In addition, since predicting a requestable slot is a much easier task than predicting an informable slot, we note that all three models show very high performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Time Complexity Performance</head><p>The time complexity for GLAD, GCE and our model (G-SAT) is shown in <ref type="figure" target="#fig_1">Figure 3</ref>. All models are executed with  batch size of 50, under the same environment and hardware (single GeForce GTX 1080Ti GPU). As the pre-processing and post-processing of each model can vary based on the implementation and the approach, we report only the time complexity for the model execution after it is loaded and ready to be executed. GLAD requires 1.78 seconds for training for each batch of data, and 0.84 seconds to predict for a batch. Since GCE does not require a separate encoder for each slot, as in GLAD, it reduces the training time to 1.16 seconds, and the prediction time to 0.52 seconds. Our approach has a significant advantage in the execution time, requiring only 0.06 seconds for training and 0.03 for prediction of each batch. We notice that, while the time complexity of GLAD and GCE reported in <ref type="bibr" target="#b9">[10]</ref> coincide with our results for training, results on the test data differ considerably. In fact, the time complexity for GCE reported in <ref type="bibr" target="#b9">[10]</ref> was 1.92 seconds, while in our experiment we found that GCE instead processes 1.92 batches/second leading to 0.52 seconds/batch. We also considered the number of parameters of the three models, as they have a direct impact on the memory footprint and the training/execution time. Only the trainable parameters for each model are reported under the default setting. Since both GLAD and GCE use pre-trained embeddings, the parameter count do not include the embedding size, while our approach includes also the embeddings as parameters as they are learned from the model. The GLAD model has ∼14M trainable parameters, while the GCE model has ∼5M parameters. Since GCE has a single encoder, compared to different encoders for each slot as in GLAD, it reduces the model size to almost one-third. On the other hand, our G-SAT approach has only ∼460K parameters, making it suitable for low memory footprint scenarios. To sum up, GCE has over 11 times the parameters than the proposed model, while GLAD has over 31 times the proposed model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Discussion</head><p>Both GLAD and GCE, by default, use embeddings of size 400, while our G-SAT model has a default embedding size of 128. So we also investigated the effect of embedding dimension on these different models, to understand if results are consistent, or if the choice of the embedding size has a significant role in the performance of the models (as the embeddings are learned during training). First, we experimented our approach with the same embedding size as GLAD and GCE, which is of dimension 400. In this case G-SAT achieved 88.6 and 86.7 on the dev and test on English, respectively, still outperforming GLAD (dev:88.4, test:84.6) and GCE (dev:89.0, test:85.1).</p><p>In a second experiment, we reduced the embedding dimension of both GLAD and GCE to 128, and trained the model. The performance of GLAD (dev:87.1, test:84.6), GCE (dev:87.8, test:85.6) and G-SAT (dev:89.0, test:87.6) showed again the same trend.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">CONCLUSION</head><p>In this paper we addressed time complexity issues in modelling an effective dialogue state tracker such that it is suitable to be used in real-world applications, particularly where the number of slots for the task becomes very high. We proposed a neural model, G-SAT, with a simpler architecture compared to other approaches. We provided experimental evidences that the G-SAT model significantly reduces the prediction time (more than 15 times faster than previous approaches), still performing competitive to the state-of-the-art. As for future work, we would like to investigate our approach in the case of a multi-domain dialogue state tracking, where the DST should track for multiple domains and the number of slots is much higher compared to single-domain datasets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>1Fig. 2 .</head><label>2</label><figDesc>https://github.com/vevake/GSAT An annotated dialogue from the WOZ2.0 dataset, with each turn separated by a dashed line.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Time complexity of various models for each batch of size 50 during training and testing (low execution time means low latency in prediction).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>4±0.6 89.0±1.0 89.0±0.6 Test 84.6±0.7 85.1±1.1 87.6±0.6 * Italian Dev 73.2±1.3 72.1±0.9 76.6±1.4 * Test 76.3±1.2 77.2±1.7 79.4±1.5 *</figDesc><table><row><cell>Language Data</cell><cell>GLAD</cell><cell>Model GCE</cell><cell>G-SAT</cell></row><row><cell cols="4">English Dev 88.German Dev 52.3±1.4 52.1±1.0 56.4±1.0 * Test 59.3±1.9 59.8±1.2 62.4±1.4 *</cell></row><row><cell cols="4">Table 2. Joint Goal performance on WOZ2.0 test data: all</cell></row><row><cell cols="4">models trained without pre-trained embeddings. * indicates</cell></row><row><cell cols="4">statistically significant [22] than both GLAD and GCE, using</cell></row><row><cell cols="3">Wilcoxon signed-rank test (with p&lt;0.05).</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 .</head><label>3</label><figDesc>0±0.3 96.8±0.3 97.2±0.2 Italian 95.9±0.2 95.9±0.2 95.8±0.2 German 94.7±0.4 94.4±0.4 94.8±0.4 Turn Request performance on WOZ2.0 test data: all models trained without pre-trained embeddings.</figDesc><table><row><cell>Language</cell><cell>GLAD</cell><cell>Model GCE</cell><cell>G-SAT</cell></row><row><cell>English</cell><cell>97.</cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://github.com/salesforce/glad 3 https://github.com/elnaaz/GCE-Model</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Machine learning for dialog state tracking: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Henderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The First International Workshop on Machine Learning in Spoken Language Processing</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A simple and generic belief tracking mechanism for the dialog state tracking challenge: On the believability of observed information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuoran</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Lemon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGDIAL 2013 Conference</title>
		<meeting>the SIGDIAL 2013 Conference</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="423" to="432" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Recurrent polynomial network for dialogue state tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
		<idno>abs/1507.03934</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Pomdp-based statistical spoken dialog systems: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1160" to="1179" />
			<date type="published" when="2013-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Word-based dialog state tracking with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaise</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL)</title>
		<meeting>the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="292" to="299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A network-based end-to-end trainable task-oriented dialogue system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Tsung-Hsien Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Vandyke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Mrkšić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lina</forename><forename type="middle">M</forename><surname>Gasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei-Hao</forename><surname>Rojas Barahona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Ultes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter</title>
		<meeting>the 15th Conference of the European Chapter<address><addrLine>Long Papers, Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017-04" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="438" to="449" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Neural belief tracker: Data-driven dialogue state tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Mrkšić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diarmuidó</forename><surname>Séaghdha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Hsien</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaise</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1777" to="1788" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Towards universal dialogue state tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liliang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaige</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2780" to="2786" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Global-locally self-attentive encoder for dialogue state tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1458" to="1467" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Toward scalable neural dialogue state tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elnaz</forename><surname>Nouri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehsan</forename><surname>Hosseini-Asl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS 2018, 2nd Conversational AI workshop</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Understanding unsegmented user utterances in real-time spoken dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikio</forename><surname>Nakano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noboru</forename><surname>Miyazaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Ichi</forename><surname>Hirasawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kohji</forename><surname>Dohsaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeshi</forename><surname>Kawabata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 37th Annual Meeting of the Association for Computational Linguistics<address><addrLine>College Park, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1999-06" />
			<biblScope unit="page" from="200" to="207" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Challenges in building highly interactive dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nigel</forename><forename type="middle">G</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Devault</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ai Magazine</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page">2016</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">An end-to-end trainable neural network model with belief tracking for task-oriented dialog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Lane</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">End-to-end task-completion neural dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiujun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Nung</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asli</forename><surname>Celikyilmaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Joint Conference on Natural Language Processing</title>
		<meeting>the Eighth International Joint Conference on Natural Language Processing<address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017-11" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="733" to="743" />
		</imprint>
	</monogr>
	<note>Asian Federation of Natural Language Processing</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Long shortterm memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for dialogue state tracking without pretrained word vectors or semantic dictionaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandy</forename><surname>Korpusik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Glass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE Spoken Language Technology Workshop (SLT)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="page" from="884" to="891" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Semantic specialization of distributional word vector spaces using monolingual and crosslingual constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikola</forename><surname>Mrkšić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vulić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diarmuidó</forename><surname>Séaghdha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ira</forename><surname>Leviant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Gašić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="309" to="324" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The second dialog state tracking challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blaise</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><forename type="middle">D</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue</title>
		<meeting>the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue</meeting>
		<imprint>
			<publisher>SIG-DIAL</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="263" to="272" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Automatic differentiation in pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qatar</forename><surname>Doha</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014-10" />
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A joint many-task model: Growing a neural network for multiple NLP tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuma</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshimasa</forename><surname>Tsuruoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017-09" />
			<biblScope unit="page" from="1923" to="1933" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Reporting score distributions makes a difference: Performance study of LSTM-networks for sequence tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-09" />
			<biblScope unit="page" from="338" to="348" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
