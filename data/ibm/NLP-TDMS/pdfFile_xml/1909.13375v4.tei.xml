<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Simple and Effective Model for Answering Multi-span Questions</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Segal</surname></persName>
							<email>elad.segal@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Tel Aviv University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avia</forename><surname>Efrat</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Tel Aviv University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mor</forename><surname>Shoham</surname></persName>
							<email>morshoham@mail.tau.ac.ilamir.globerson@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Tel Aviv University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Globerson</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Tel Aviv University</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Google Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
							<email>joberant@cs.tau.ac.il</email>
							<affiliation key="aff0">
								<orgName type="institution">Tel Aviv University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Allen Institute for AI</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A Simple and Effective Model for Answering Multi-span Questions</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T08:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Models for reading comprehension (RC) commonly restrict their output space to the set of all single contiguous spans from the input, in order to alleviate the learning problem and avoid the need for a model that generates text explicitly. However, forcing an answer to be a single span can be restrictive, and some recent datasets also include multi-span questions, i.e., questions whose answer is a set of non-contiguous spans in the text. Naturally, models that return single spans cannot answer these questions. In this work, we propose a simple architecture for answering multi-span questions by casting the task as a sequence tagging problem, namely, predicting for each input token whether it should be part of the output or not. Our model substantially improves performance on span extraction questions from DROP and QUOREF by 9.9 and 5.5 EM points respectively.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The task of reading comprehension (RC), where given a question and context, one provides an answer, has gained immense attention recently. In most datasets and models <ref type="bibr" target="#b13">(Rajpurkar et al., 2016;</ref><ref type="bibr" target="#b17">Trischler et al., 2016;</ref><ref type="bibr" target="#b16">Seo et al., 2017;</ref><ref type="bibr">Yu et al., 2018;</ref><ref type="bibr" target="#b9">Kwiatkowski et al., 2019)</ref>, RC is set up as an extractive task, where the answer is constrained to be a single span from the input. This makes learning easier, since the model does not need to generate text abstractively, while still being expressive enough to capture a large set of questions.</p><p>However, for some questions, while the answer is indeed extractive, i.e., contained in the input, it is not a single span. For example, in <ref type="figure">Figure 1</ref> the answer includes two people who appear as noncontiguous spans in the context. Existing models <ref type="bibr" target="#b16">(Seo et al., 2017;</ref><ref type="bibr" target="#b4">Dua et al., 2019)</ref> are by design unable to provide the correct answer to such multispan questions. While most work has largely ignored this issue, recent work has taken initial steps towards handling multi-span questions. <ref type="bibr" target="#b6">Hu et al. (2019)</ref> proposed to predict the number of output spans for each question, and used a non-differentiable inference procedure to find them in the text, leading to a complex training procedure. <ref type="bibr" target="#b0">Andor et al. (2019)</ref> proposed a Merge operation that merges spans, but is constrained to at most 2 spans. <ref type="bibr" target="#b1">Chen et al. (2020)</ref> proposed a non-differentiable symbolic approach which outputs programs that compose single-span extractions.</p><p>In this work, we propose a simple and fully differentiable architecture for handling multi-span questions that evades the aforementioned shortcomings, and outperforms prior work. Similar to <ref type="bibr" target="#b20">Yao et al. (2013)</ref>, who used a linear model over treebased features, we cast question answering as a sequence tagging task, predicting for each token whether it is part of the answer. At test time, we decode the answer with standard decoding methods, such as Viterbi.</p><p>We show the efficacy of our approach on spanextraction questions from both the DROP <ref type="bibr" target="#b4">(Dua et al., 2019)</ref> and QUOREF  datasets. Replacing the single-span architecture with our multi-span approach improves performance by 7.8 and 5.5 EM points respectively. Com-bining the single-span and multi-span architectures further improves performance by 2.1 EM on DROP, surpassing results by other span-extraction methods on both datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background: Single-span Model</head><p>Setup Given a training set of question-contextanswer triplets (q i , c i , a i ) N i=1 , our goal is to learn a function that maps a question-context pair (q, c) to an answer a. We briefly review the standard singlespan architecture for RC , which we build upon.</p><p>First, we encode the question and context with a pre-trained language model, such as BERT </p><formula xml:id="formula_0">: h = Encoder([q, c]), where h = (h 1 , . . . , h m )</formula><p>is a sequence of contextualized representations for all input tokens. Then, two parameterized functions (feed-forward networks), f start (h i ) and f end (h i ), are used to compute a score for each token, corresponding to whether that token is the start or the end of the answer. Last, the start and end probability for each token i is computed as follows:</p><formula xml:id="formula_1">p start i = softmax (f start (h 1 ), . . . , f start (h m )) i , p end i = softmax (f end (h 1 ), . . . , f end (h m )) i , where both p start , p end ∈ R m×1 .</formula><p>Training is done by minimizing cross entropy of the start and end indices of the gold span, and at test time the answer span is extracted by finding the indices (s, e):</p><p>(s, e) = arg max s≤e p start s p end e .</p><p>3 Multi-span Model</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Span Extraction as Sequence Tagging</head><p>Extracting a variable number of spans from an input text is standard in many natural language processing tasks, such as Named Entity Recognition (NER) and is commonly cast as a sequence tagging problem <ref type="bibr" target="#b14">(Ramshaw and Marcus, 1995)</ref>. Here we apply this approach to multi-span questions. Our model uses the same contextualized representations h, but rather than predicting start and end probabilities, it outputs a probability distribution over a set of tags for each token. We experiment with two tagging schemes. First, the wellknown BIO tagging <ref type="bibr" target="#b15">(Sang, 2000;</ref><ref type="bibr" target="#b7">Huang et al., 2015)</ref>, in which B denotes the first token of an output span, I denotes subsequent tokens in a span, and O denotes tokens that are not part of an output span. In addition, we experiment with a simpler IO tagging scheme, where words are tagged as either part of the answer (I) or not (O). Formally, given a tagging scheme with |S| tags (|S| = 3 for BIO and |S| = 2 for IO), for each of the m tokens, the probability for the tag of the i-th token is</p><formula xml:id="formula_2">p i = softmax(f (h i )) (1) where p ∈ R m×|S| , and f is a parameterized func- tion with |S| outputs.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Training</head><p>Assume each answer a is a set of strings, where each string corresponds to a span in the input. We would like to train our model to predict the correct output for this set of spans. When the answer spans appear only once in the input, this is simple, since the ground-truth tagging is immediately available. However, there are many cases where a given answer span appears multiple times in the input. We next explain how to address this.</p><p>To illustrate, consider the following simple example (assume a BIO scheme). Given the input "X Y Z Y Z" and the correct multi-span answer {"X", "Z"}, there are three possible gold taggings:</p><formula xml:id="formula_3">B O B O B, B O B O O, and B O O O B.</formula><p>Thus, the groundtruth BIO cannot be determined unambiguously in this case. <ref type="figure">Figure 1</ref> illustrates this issue with a real example from DROP. <ref type="bibr">1</ref> To tackle the above issue, we enumerate over the set of all possibly-correct taggings, T , where given a multi-span answer a, a possibly-correct tagging is one in which all gold answer spans are tagged as such at least once. <ref type="bibr">2</ref> We train our models by maximizing the marginal probability of all possibly-correct taggings:</p><formula xml:id="formula_4">log p(T | h) = log T ∈T m i=1 p i [T i ] , where p i [T i ] (see Eq.</formula><p>(1)) is the probability the model assigns to token i having the tag T i . The loss is minimized when p gives probability 1.0 to one of the possibly-correct taggings in T .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Decoding Spans from a Tagging</head><p>At test time, given predicted tag probabilities p, we would like to find the most likely taggingT . Let V be the set of all valid taggings. We wish to find:</p><formula xml:id="formula_5">T = arg max T ∈V m i=1 p i [T i ].</formula><p>For BIO tags, the set V comprises all taggings that don't include an I after an O, and the maximization problem can be solved in linear time using Viterbi decoding <ref type="bibr" target="#b18">(Viterbi, 1967)</ref> as in <ref type="bibr" target="#b20">Yao et al. (2013);</ref><ref type="bibr" target="#b11">Mehta et al. (2018)</ref>. For IO tags, all taggings are valid, and maximization is done by predicting the tag with highest probability in each token independently. Because answer spans are (practically) never adjacent in RC, an IO-tagging produces a set of spans by choosing all maximal spans that are contiguously tagged with I.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">"Multi-Head" Models</head><p>Some RC datasets contain questions where the output is not necessarily a span. For example, in DROP, the answer to some questions is a number that is not in the text, but can be computed by performing arithmetic operations. To handle such cases, many models <ref type="bibr" target="#b4">(Dua et al., 2019;</ref><ref type="bibr" target="#b6">Hu et al., 2019</ref>) employ a multi-head architecture. In these models, each head z is a small module that takes the contextualized representations h as input and computes a probability distribution over answers p z (a | q, c) = p z (a | h). For example, in <ref type="bibr" target="#b6">Hu et al. (2019)</ref>, there are two heads that output spans, and three heads that output numbers. To determine which head to use for each question, an additional module is trained: p head (z | q, c) = p head (z | h). Thus, the model probability for an answer is:</p><formula xml:id="formula_6">p(a | q, c) = z p head (z | q, c) · p z (a | q, c).</formula><p>With this architecture, we can seamlessly integrate our multi-span approach into existing RC models. Specifically, a model can include both a single-span head and a multi-span head, dynamically deciding which span extraction method to utilize based on the input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Empirical Evaluation</head><p>Experimental setup As an encoder, we use the Hugging Face implementation of RoBERTa LARGE <ref type="bibr" target="#b19">(Wolf et al., 2019;</ref>, which produces the representations h. For DROP, we add the arithmetic and count heads from <ref type="bibr" target="#b4">Dua et al. (2019)</ref> to handle non-span questions. Full details of the experimental setup are in Appendix A. <ref type="table" target="#tab_2">Table 1</ref> shows development set results on the spanextraction questions of DROP <ref type="bibr" target="#b4">(Dua et al., 2019)</ref> and QUOREF . We compare the previous best-performing multi-span models to a combination of our multi-span architecture (TASE: TAg-based Span Extraction) with the traditional single-span extraction (SSE), as well as to each separately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Results</head><p>Comparison to previous models For a fair comparison with prior work on DROP, we also train our model initialized with BERT LARGE , as all prior work used it as an encoder. On DROP, TASEBIO+SSE (BERT LARGE ) outperforms all prior models that handle multi-span questions, improving by at least 3.2 EM points. On multi-span questions, we dramatically improve performance over BERT-CALC and MTMSN, while obtaining similar performance to NeRd. On QUOREF, compared to CorefRoBERTa LARGE <ref type="bibr" target="#b21">(Ye et al., 2020)</ref> which uses the same method as MTMSN for multi-span extraction, we achieve a substantial improvement of over 20 EM on multi-span questions and an improvement of 4.5 EM and 3.2 F1 on the full development set, where the best results are achieved when using solely our multi-span architecture with IO-tagging.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparing span extraction architectures</head><p>Table 1 also shows that in both DROP and QUOREF, replacing the single-span extraction architecture with our multi-span extraction results in dramatic improvement in multi-span question performance, while single-span question performance is either maintained or improved. Furthermore, although combining both architectures tends to yield the best overall performance, 3 the improvement over using only our multi-span architecture is not substantial, suggesting that the multi-span architecture may be used by itself as a general span extraction method.</p><p>Effects of tagging scheme Overall, the results are quite similar for the BIO and IO schemes. The slight advantage of IO could perhaps be explained by the fact that the model no longer requires distinguishing between B and I, in the presence of powerful contextualized representations.   Effect of marginalization To check whether marginalizing over all possibly-correct taggings is beneficial, we ran TASEBIO in a setup where only a single tagging is considered, namely where all occurrences of a gold answer span are tagged. Table 1 shows that this indeed leads to a moderate drop of up to 2 points in performance. We note that the top 10 models on the DROP leaderboard (as of September 15, 2020) have all incorporated our multi-span head using our code base which has been public for a while. <ref type="figure" target="#fig_0">Figure 2</ref> shows that in both DROP and QUOREF the performance of TASEBIO decreases only moder-ately as the number of gold spans increases. This shows relative robustness to the number of answer spans. In addition, we can see that our architecture is quite accurate in predicting the correct number of spans, with a tendency for under-estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Analysis</head><p>We analyzed the performance of the p head module in TASEBIO+SSE. A non-multi-span head is selected erroneously for 3.7% and 7.2% of the multispan questions in DROP and QUOREF respectively. The multi-span head is selected for 1.2% and 1.5% of the single-span questions in DROP and QUOREF respectively. However, this is reasonable as the multi-span head is capable of answering singlespan questions as well, and indeed it returned a single span in 45% of these cases on both datasets.</p><p>We manually analyzed errors of TASEBIO+SSE on DROP, and detected 3 main failure cases: <ref type="formula">(1)</ref> questions where the answer is a span, but requires some numerical computation internally, (2) questions where the number of output spans is explicitly mentioned in the question but is not followed by the model, and (3) questions where a single contiguous span is unnecessarily split into two shorter spans. An example for each case is given in Appendix B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this work, we cast the task of answering multi-span questions as a sequence tagging problem, and present a simple corresponding multispan architecture. We show that replacing the standard single-span architecture with our multispan architecture dramatically improves results on multi-span questions, without harming performance on single-span questions, leading to state-of-the-art results on QUOREF. In addition, integrating our multi-span architecture into existing models further improves performance on DROP, as is evident from the leading models on DROP's leaderboard. Our code can be downloaded from https://github.com/eladsegal/tag-based-multispan-extraction.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>DROP Performance of TASEBIO by number of spans in the gold answer. Labels at the bottom indicate the average number of predicted spans. Circles at the top are the number of examples. These same trends are observed in QUOREF as well.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Development set results on DROP and QUOREF questions whose answer is a span (or list of spans).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Test set results We ran TASEIO on the QUOREF test set. Our model obtains 79.7 EM and 86.1 F1, an improvement of 3.9 EM points and 3.3 F1 points over the state-of-the-art CorefRoBERTa LARGE . On DROP, our TASEIO+SSE model achieves 80.4 EM and 83.6 F1 on the entire test set (including nonspan questions).</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">In QUOREF, the indices of the gold answer spans are explicitly given, so a single gold tagging can be defined.2 While |T | can grow exponentially with the number of spans in an answer, in practice |T | is at most 1000 for 99.66% of the examples of DROP, and so we can enumerate over T directly in these cases. In the other 0.34%, we take a single tagging that marks all occurrences of the answer spans.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">As single-span questions outnumber multi-span questions in DROP and QUOREF 1:7 and 1:10 respectively, the overall span performance ("All Spans") gives a much larger weight to single-span performance.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This research was partially supported by The Israel Science Foundation grants 942/16 and 1186/18, The Yandex Initiative for Machine Learning and the European Research Council (ERC) under the European Union Horizons 2020 research and innovation programme (grant ERC DELPHI 802800).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix for "A Simple and Effective</head><p>Model for Answering Multi-span Questions"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Experimental Setup</head><p>We experiment with model variations that use either SSE, TASE, or their combination as a multi-head model. For DROP, we additionally use arithmetic and count heads based on <ref type="bibr" target="#b4">(Dua et al., 2019;</ref><ref type="bibr" target="#b8">Kinley and Lin, 2019)</ref>. Our model is implemented with PyTorch <ref type="bibr" target="#b12">(Paszke et al., 2019)</ref> and AllenNLP <ref type="bibr" target="#b5">(Gardner et al., 2017)</ref>. For f in Eq. (1) we use a 2layer feed-forward network with ReLU activations and |S| outputs. We use the Hugging Face implementation of RoBERTa LARGE <ref type="bibr" target="#b19">(Wolf et al., 2019;</ref> as the encoder in our model. 5% of DROP and 30% of QUOREF are inputs with over 512 tokens. Due to RoBERTa LARGE 's limitation of 512 positional embeddings, we truncate inputs by removing over-flowing tokens from the passage, both at train and test time. We discard 3.87% of the training examples of DROP and 5.05% of the training example of QUOREF, which are cases when the answer cannot be outputted by the model (due to a dataset error, or truncation of the correct answer span). For training, the BertAdam 4 optimizer is used with default parameters and learning rates of either 5 × 10 −6 or 10 −5 . Hyperparameter search was not performed. We train on a single NVIDIA Titan XP with a batch size of 2 and gradient accumulation of 6, resulting in an effective batch size of 12, for 20 epochs with an early-stopping patience of 10. The average runtime per epoch is 3.5 hours. Evaluation was performed with the official evaluation scripts of 4 https://github.com/ huggingface/transformers/blob/ 694e2117f33d752ae89542e70b84533c52cb9142/ README.md#optimizers DROP and QUOREF. Our full implementation can be found at https://github.com/eladsegal/tag-basedmulti-span-extraction.  <ref type="table">Table 2</ref>: Example failure cases of TASEBIO+SSE on DROP. The first answer exhibits a lack of numeric reasoning and ignores the expected number of spans stated in the question. The second splits a correct span into two spans.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Failure Cases Examples</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Giving BERT a calculator: Finding operations and arguments with reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Andor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Pitler</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/d19-1609</idno>
	</analytic>
	<monogr>
		<title level="j">EMNLP-IJCNLP</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Neural symbolic reader: Scalable integration of distributed and symbolic representations for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adams</forename><forename type="middle">Wei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denny</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Quoref: A reading comprehension dataset with questions requiring coreferential reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pradeep</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nelson</forename><forename type="middle">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ana</forename><surname>Marasović</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1606</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. of EMNLP-IJCNLP</title>
		<meeting>of EMNLP-IJCNLP</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dheeru</forename><surname>Dua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pradeep</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Stanovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1246</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL</title>
		<meeting>of NAACL</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">AllenNLP: A deep semantic natural language processing platform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Grus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pradeep</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nelson</forename><forename type="middle">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Schmitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A multi-type multi-span network for reading comprehension that requires discrete reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghao</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxing</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongsheng</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1170</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Bidirectional LSTM-CRF models for sequence tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">NABERT+: Improving numerical reasoning in reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jambay</forename><surname>Kinley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">URL https</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Natural questions: a benchmark for question answering research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennimaria</forename><surname>Palomaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivia</forename><surname>Redfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danielle</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00276</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="453" to="466" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m">RoBERTa: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Towards semi-supervised learning for deep semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jay</forename><forename type="middle">Yoon</forename><surname>Sanket Vaibhav Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><forename type="middle">G</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Carbonell</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1538</idno>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Py-Torch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alykhan</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sasank</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Wallach, H. Larochelle, A. Beygelzimer, F. d&apos;Alché-Buc, E. Fox, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">SQuAD: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D16-1264</idno>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Text chunking using transformation-based learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lance</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitch</forename><surname>Marcus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Third Workshop on Very Large Corpora</title>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Transforming a chunker to a parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><forename type="middle">F</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tjong Kim</forename><surname>Sang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLIN</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Bidirectional attention flow for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aniruddha</forename><surname>Kembhavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Newsqa: A machine comprehension dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingdi</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaheer</forename><surname>Suleman</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W17-2623</idno>
	</analytic>
	<monogr>
		<title level="m">Workshop on Representation Learning for NLP</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Error bounds for convolutional codes and an asymptotically optimum decoding algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">J</forename><surname>Viterbi</surname></persName>
		</author>
		<idno type="DOI">10.1109/TIT.1967.1054010</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Information Theory</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="260" to="269" />
			<date type="published" when="1967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">HuggingFace&apos;s transformers: State-of-the-art natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R&amp;apos;emi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Brew</surname></persName>
		</author>
		<idno>abs/1910.03771</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Answer extraction as sequence tagging with tree edit distance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuchen</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Coreferential reasoning learning for language representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deming</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaju</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenghao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ArXiv</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adams</forename><forename type="middle">Wei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">QANet: Combining local convolution with global self-attention for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
