<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Large-Scale Multi-Label Text Classification on EU Legislation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilias</forename><surname>Chalkidis</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Informatics</orgName>
								<orgName type="institution">Athens University of Economics and Business</orgName>
								<address>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manos</forename><surname>Fergadiotis</surname></persName>
							<email>fergadiotis@aueb.gr</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Informatics</orgName>
								<orgName type="institution">Athens University of Economics and Business</orgName>
								<address>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prodromos</forename><surname>Malakasiotis</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Informatics</orgName>
								<orgName type="institution">Athens University of Economics and Business</orgName>
								<address>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ion</forename><surname>Androutsopoulos</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Informatics</orgName>
								<orgName type="institution">Athens University of Economics and Business</orgName>
								<address>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Large-Scale Multi-Label Text Classification on EU Legislation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T22:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We consider Large-Scale Multi-Label Text Classification (LMTC) in the legal domain. We release a new dataset of 57k legislative documents from EUR-LEX, annotated with ∼4.3k EUROVOC labels, which is suitable for LMTC, few-and zero-shot learning. Experimenting with several neural classifiers, we show that BIGRUs with label-wise attention perform better than other current state of the art methods. Domain-specific WORD2VEC and context-sensitive ELMO embeddings further improve performance. We also find that considering only particular zones of the documents is sufficient. This allows us to bypass BERT's maximum text length limit and finetune BERT, obtaining the best results in all but zero-shot learning cases.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Large-scale multi-label text classification (LMTC) is the task of assigning to each document all the relevant labels from a large set, typically containing thousands of labels (classes). Applications include building web directories <ref type="bibr" target="#b1">(Partalas et al., 2015)</ref>, labeling scientific publications with concepts from ontologies <ref type="bibr">(Tsatsaronis et al., 2015)</ref>, assigning diagnostic and procedure labels to medical records <ref type="bibr">(Mullenbach et al., 2018;</ref><ref type="bibr" target="#b4">Rios and Kavuluru, 2018)</ref>. We focus on legal text processing, an emerging NLP field with many applications (e.g., legal judgment <ref type="bibr">(Nallapati and Manning, 2008;</ref><ref type="bibr" target="#b0">Aletras et al., 2016)</ref>, contract element extraction <ref type="bibr">(Chalkidis et al., 2017)</ref>, obligation extraction <ref type="bibr">(Chalkidis et al., 2018)</ref>), but limited publicly available resources.</p><p>Our first contribution is a new publicly available legal LMTC dataset, dubbed EURLEX57K, containing 57k English EU legislative documents from the EUR-LEX portal, tagged with ∼4.3k labels (concepts) from the European Vocabulary (EUROVOC). 1 EUROVOC contains approx. 7k labels, but most of them are rarely used, hence they are under-represented (or absent) in EURLEX57K, making the dataset also appropriate for few-and zero-shot learning. <ref type="bibr">EURLEX57K</ref> can be viewed as an improved version of the dataset released by <ref type="bibr">Mencia and Fürnkranzand (2007)</ref>, which has been widely used in LMTC research, but is less than half the size of EURLEX57K (19.6k documents, 4k EU-ROVOC labels) and more than ten years old.</p><p>As a second contribution, we experiment with several neural classifiers on EURLEX57K, including the Label-Wise Attention Network of <ref type="bibr">Mullenbach et al. (2018)</ref>, called CNN-LWAN here, which was reported to achieve state of the art performance in LMTC on medical records. We show that a simpler BIGRU with self-attention <ref type="bibr" target="#b8">(Xu et al., 2015)</ref> outperforms CNN-LWAN by a wide margin on EURLEX57K. However, by replacing the CNN encoder of CNN-LWAN with a BIGRU, we obtain even better results on EURLEX57K. Domainspecific WORD2VEC <ref type="bibr">(Mikolov et al., 2013)</ref> and context-sensitive ELMO embeddings <ref type="bibr" target="#b3">(Peters et al., 2018)</ref> yield further improvements. We thus establish strong baselines for <ref type="bibr">EURLEX57K.</ref> As a third contribution, we investigate which zones of the documents are more informative on <ref type="bibr">EURLEX57K,</ref><ref type="bibr"></ref> showing that considering only the title and recitals of each document leads to almost the same performance as considering the full document. This allows us to bypass <ref type="bibr">BERT's (Devlin et al., 2018</ref>) maximum text length limit and finetune BERT, obtaining the best results for all but zero-shot learning labels. To our knowledge, this is the first application of BERT to an LMTC task, which provides further evidence of the superiority of pretrained language models with task-specific fine-tuning, and establishes an even stronger baseline for EURLEX57K and LMTC in general. <ref type="bibr" target="#b10">You et al. (2018)</ref> explored RNN-based methods with self-attention on five LMTC datasets that had also been considered by <ref type="bibr">Liu et al. (2017)</ref>, namely <ref type="bibr">RCV1 (Lewis et al., 2004)</ref>, Amazon-13K, <ref type="bibr">(McAuley and Leskovec, 2013)</ref>, Wiki-30K and Wiki-500K <ref type="bibr" target="#b12">(Zubiaga, 2012)</ref>, as well as the previous <ref type="bibr">EUR-LEX dataset (Mencia and Fürnkranzand, 2007)</ref>, reporting that attention-based RNNs produced the best results overall (4 out of 5 datasets). <ref type="bibr">Mullenbach et al. (2018)</ref> investigated the use of label-wise attention in LMTC for medical code prediction on the MIMIC-II and MIMIC-III datasets <ref type="bibr">(Johnson et al., 2017)</ref>. Their best method, Convolutional Attention for Multi-Label Classification, called CNN-LWAN here, employs one attention head per label and was shown to outperform weak baselines, namely logistic regression, plain BIGRUs, CNNs with a single convolution layer. <ref type="bibr" target="#b4">Rios and Kavuluru (2018)</ref> consider few-and zero-shot learning on the MIMIC datasets. They propose Zero-shot Attentive CNN, called ZERO-CNN-LWAN here, a method similar to <ref type="bibr">CNN-LWAN,</ref> which also exploits label descriptors. Although ZERO-CNN-LWAN did not outperform CNN-LWAN overall on MIMIC-II and MIMIC-III, it had much improved results in few-shot and zero-shot learning, among other variations of ZERO-CNN-LWAN that exploit the hierarchical relations of the labels with graph convolutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>We note that the label-wise attention methods of <ref type="bibr">Mullenbach et al. (2018)</ref> and <ref type="bibr" target="#b4">Rios and Kavuluru (2018)</ref> were not compared to strong generic text classification baselines, such as attention-based RNNs <ref type="bibr" target="#b10">(You et al., 2018)</ref> or Hierarchical Attention Networks (HANs) <ref type="bibr" target="#b9">(Yang et al., 2016)</ref>, which we investigate below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The New Dataset</head><p>As already noted, EURLEX57K contains 57k legislative documents from EUR-LEX 2 with an average length of 727 words <ref type="table" target="#tab_1">(Table 1)</ref>  enforcing the legal act; the recitals, which are legal background references; the main body, usually organized in articles; and the attachments (e.g., appendices, annexes). Some of the LMTC methods we consider need to be fed with documents split into smaller units. These are often sentences, but in our experiments they are sections, thus we preprocessed the raw text, respectively. We treat the header, the recitals zone, each article of the main body, and the attachments as separate sections.</p><p>All the documents of the dataset have been annotated by the Publications Office of EU 4 with multiple concepts from EUROVOC. While EU-ROVOC includes approx. 7k concepts (labels), only 4,271 (59.31%) are present in EURLEX57K, from which only 2,049 (47.97%) have been assigned to more than 10 documents. Similar distributions were reported by <ref type="bibr" target="#b4">Rios and Kavuluru (2018)</ref> for the MIMIC datasets. We split EURLEX57K into training (45k documents), development (6k), and test subsets (6k). We also divide the 4,271 labels into frequent (746 labels), few-shot (3,362), and zeroshot (163), depending on whether they were assigned to more than 50, fewer than 50 but at least one, or no training documents, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Methods</head><p>Exact Match, Logistic Regression: A first naive baseline, Exact Match, assigns only labels whose descriptors can be found verbatim in the document. A second one uses Logistic Regression with feature vectors containing TF-IDF scores of n-grams (n = 1, 2, . . . , 5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BIGRU-ATT:</head><p>The first neural method is a BIGRU with self-attention <ref type="bibr" target="#b8">(Xu et al., 2015)</ref>. Each document is represented as the sequence of its word embeddings, which go through a stack of BIGRUs <ref type="figure" target="#fig_0">(Figure 1a</ref>). A document embedding (h) is computed as the sum of the resulting context-aware embeddings (h = i a i h i ), weighted by the selfattention scores (a i ), and goes through a dense HAN: The Hierarchical Attention Network <ref type="bibr" target="#b9">(Yang et al., 2016</ref>) is a strong baseline for text classification. We use a slightly modified version, where a BIGRU with self-attention reads the words of each section, as in BIGRU-ATT but separately per section, producing section embeddings. A second-level BIGRU with self-attention reads the section embeddings, producing a single document embedding (h) that goes through a similar output layer as in BIGRU-ATT <ref type="figure" target="#fig_0">(Figure 1b</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CNN-LWAN, BIGRU-LWAN:</head><p>In the original Label-Wise Attention Network (LWAN) of <ref type="bibr">Mullenbach et al. (2018)</ref>, called CNN-LWAN here, the word embeddings of each document are first converted to a sequence of vectors h i by a CNN encoder. A modified version of CNN-LWAN that we developed, called BIGRU-LWAN, replaces the CNN encoder with a BIGRU <ref type="figure" target="#fig_0">(Figure 1c</ref>), which converts the word embeddings into context-sensitive embeddings h i , much as in BIGRU-ATT. Unlike BIGRU-ATT, however, both CNN-LWAN and BIGRU-LWAN use L independent attention heads, one per label, generating L document embeddings (h (l) = i a l,i h i , l = 1, . . . , L) from the sequence of vectors h i produced by the CNN or BI-GRU encoder, respectively. Each document embedding (h (l) ) is specialized to predict the corresponding label and goes through a separate dense layer (L dense layers in total) with a sigmoid, to produce the probability of the corresponding label.</p><p>ZERO-CNN-LWAN, ZERO-BIGRU-LWAN: Rios and Kavuluru (2018) designed a model similar to CNN-LWAN, called ZACNN in their work and ZERO-CNN-LWAN here, to deal with rare labels. In ZERO-CNN-LWAN, the attention scores (a l,i ) and the label probabilities are produced by comparing the h i vectors that the CNN encoder pro-duces and the label-specific document embeddings (h (l) ), respectively, to label embeddings. Each label embedding is the centroid of the pretrained word embeddings of the label's descriptor; consult <ref type="bibr" target="#b4">Rios and Kavuluru (2018)</ref> for further details. By contrast, CNN-LWAN and BIGRU-LWAN do not consider the descriptors of the labels. We also experiment with a variant of ZERO-CNN-LWAN that we developed, dubbed ZERO-BIGRU-LWAN, where the CNN encoder is replaced by a BIGRU.</p><p>BERT: BERT (Devlin et al., 2018) is a language model based on Transformers <ref type="bibr" target="#b6">(Vaswani et al., 2017)</ref> pretrained on large corpora. For a new target task, a task-specific layer is added on top of BERT. The extra layer is trained jointly with BERT by fine-tuning on task-specific data. We add a dense layer on top of BERT, with sigmoids, that produces a probability per label. Unfortunately, BERT can currently process texts up to 512 wordpieces, which is too small for the documents of EURLEX57K. Hence, BERT can only be applied to truncated versions of our documents (see below).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>Evaluation measures: Common LMTC evaluation measures are precision (P @K) and recall (R@K) at the top K predicted labels, averaged over test documents, micro-averaged F1 over all labels, and nDCG@K (Manning et al., 2009). However, P @K and R@K unfairly penalize methods when the gold labels of a document are fewer or more than K, respectively. Similar concerns have led to the introduction of R-Precision and nDCG@K in Information Retrieval <ref type="bibr">(Manning et al., 2009</ref>), which we believe are also more appropriate for LMTC. Note, however, that R-Precision requires the number of gold labels per document to be known beforehand, which is unrealistic in practical applications. Therefore we propose using R-Precision@K (RP @K), where  K is a parameter. This measure is the same as P @K if there are at least K gold labels, otherwise K is reduced to the number of gold labels. <ref type="figure" target="#fig_1">Figure 2</ref> shows RP @K for the three best systems, macro-averaged over test documents. Unlike P @K, RP @K does not decline sharply as K increases, because it replaces K by the number of gold labels, when the latter is lower than K. For K = 1, RP @K is equivalent to P @K, as confirmed by <ref type="figure" target="#fig_1">Fig. 2</ref>. For large values of K that almost always exceed the number of gold labels, RP @K asymptotically approaches R@K, as also confirmed by 5 See Appendix C for a more detailed discussion on the evaluation measures. <ref type="bibr">6</ref> Evaluating at other values of K lead to similar conclusions (see <ref type="figure" target="#fig_1">Fig. 2</ref> and Appendix D).</p><p>Setup: Hyper-parameters are tuned using the HYPEROPT library selecting the values with the best loss on development data. 7 For the best hyper-parameter values, we perform five runs and report mean scores on test data. For statistical significance tests, we take the run of each method with the best performance on development data, and perform two-tailed approximate randomization tests <ref type="bibr">(Dror et al., 2018)</ref> on test data. 8 Unless otherwise stated, we used 200-D pretrained GLOVE embeddings <ref type="bibr" target="#b2">(Pennington et al., 2014)</ref>.</p><p>Full documents: The first five horizontal zones of <ref type="table" target="#tab_3">Table 2</ref> report results for full documents. The naive baselines are weak, as expected. Interestingly, for all, frequent, and even few-shot labels, the generic BIGRU-ATT performs better than CNN-LWAN, which was designed for LMTC. HAN also performs better than CNN-LWAN for all and frequent labels. However, replacing the CNN encoder of CNN-LWAN with a BIGRU (BIGRU-LWAN) leads to the best results, indicating that the main weakness of CNN-LWAN is its vanilla CNN encoder.</p><p>The zero-shot versions of CNN-LWAN and BIGRU-LWAN outperform all other methods on zero-shot labels <ref type="table" target="#tab_3">(Table 2)</ref>, in line with the findings of <ref type="bibr" target="#b4">Rios and Kavuluru (2018)</ref>, because they exploit label descriptors, but more importantly because they have a component that uses prior knowledge as is (i.e., label embeddings are frozen). Exact Match also performs better on zero-shot labels, for the same reason (i.e., the prior knowledge is intact). BIGRU-LWAN, however, is still the best method in few-shot learning. All the differences between the best (bold) and other methods in Table 2 are statistically significant (p &lt; 0.01). <ref type="table" target="#tab_5">Table 3</ref> shows that using WORD2VEC embeddings trained on legal texts (L2V) (Chalkidis and Kampas, 2018) or ELMO embeddings <ref type="bibr" target="#b3">(Peters et al., 2018)</ref> trained on generic texts further improve the performance of BIGRU-LWAN.   First 512 tokens: Given that H+R contains enough information and is shorter than 500 tokens in 83% of our dataset's documents, we also apply BERT to the first 512 tokens of each document (truncated to BERT's max. length), comparing to BIGRU-LWAN also operating on the first 512 tokens. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Document zones:</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Limitations and Future Work</head><p>One major limitation of the investigated methods is that they are unsuitable for Extreme Multi-Label Text Classification where there are hundreds of thousands of labels <ref type="bibr">(Liu et al., 2017;</ref><ref type="bibr">Zhang et al., 9</ref> The approximate randomization tests detected no statistically significant difference in this case (p = 0.20). <ref type="bibr" target="#b7">Wydmuch et al., 2018)</ref>, as opposed to the LMTC setting of our work where the labels are in the order of thousands. We leave the investigation of methods for extremely large label sets for future work. Moreover, RNN (and GRU) based methods have high computational cost, especially for long documents. We plan to investigate more computationally efficient methods, e.g., dilated CNNs <ref type="bibr">(Kalchbrenner et al., 2017)</ref> and Transformers <ref type="bibr" target="#b6">(Vaswani et al., 2017;</ref><ref type="bibr">Dai et al., 2019)</ref>. We also plan to experiment with hierarchical flavors of BERT to surpass its length limitations. Furthermore, experimenting with more datasets e.g., RCV1, Amazon-13K, Wiki-30K, MIMIC-III will allow us to confirm our conclusions in different domains. Finally, we plan to investigate Generalized Zero-Shot Learning <ref type="bibr">(Liu et al., 2018</ref>  <ref type="figure" target="#fig_2">Figure 3</ref> shows the distribution of labels across EURLEX57K documents. From the 7k labels fewer than 50% appear in more than 10 documents. Such an aggressive Zipfian distribution has also been noted in medical code predictions <ref type="bibr" target="#b4">(Rios and Kavuluru, 2018)</ref>, where such thesauri are used to classify documents, demonstrating the practical importance of few-shot and zero-shot learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2018;</head><p>B Hyper-paramater tuning <ref type="table" target="#tab_10">Table 5</ref> shows the best hyper-parameters returned by HYPEROPT. Concerning BERT, we set the dropout rate and learning rate to 0.1 and 5e-5, respectively, as suggested by Devlin et al. <ref type="formula" target="#formula_0">(2018)</ref>, while batch size was set to 8 due to GPU memory limitations. Finally, we noticed that the model did </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Evaluation Measures</head><p>The macro-averaged versions of R@K and P @K are defined as follows:</p><formula xml:id="formula_0">R@K = 1 T T t=1 S t (K) R t (1) P @K = 1 T T t=1 S t (K) K<label>(2)</label></formula><p>where T is the total number of test documents, K is the number of labels to be selected per document, S t (K) is the number of correct labels among those ranked as top K for the t-th document, and R t is the number of gold labels for each document. Although these measures are widely used in LMTC, we question their appropriateness for the following reasons:</p><p>1. R@K leads to excessive penalization when documents have more than K gold labels. For example, evaluating at K = 1 for a single document with 5 gold labels returns R@1 = 0.20, if the system managed to return a correct label. The system is penalized, even though it was not allowed to return more than one label.</p><p>2. P @K does the same for documents with fewer than K gold labels. For example, evaluating at K = 5 for a single document with a single gold label returns P @1 = 0.20.  @5 @10 @1 @5 @10 @1 @5 @10 @1 @5 @10 Exact  3. Both measures over-or under-estimate performance on documents whose number of gold labels largely diverges from K. This is clearly illustrated in <ref type="figure" target="#fig_1">Figure 2</ref> of the main article.</p><p>4. Because of these drawbacks, both measures do not correctly single out the best methods.</p><p>Based on the above arguments, we believe that R-Precision@K (RP @K) and nDCG@K lead to a more informative and fair evaluation. Both measures adjust to the number of gold labels per document, without over-or under-estimating performance when documents have few or many gold labels. The macro-averaged versions of the two measures are defined as follows:</p><formula xml:id="formula_1">RP @K = 1 T T t=1 S t (K) min (K, R t ) (3) nDCG@K = 1 T T t=1 K k=1 2 St(k) − 1 log (1 + k)<label>(4)</label></formula><p>Again, T is the total number of test documents, K is the number of labels to be selected, S t (K) is the number of correct labels among those ranked as top K for the t-th document, and R t is the number of gold labels for each document. In the main article we report results for K = 5. The reason is that the majority of the documents of EURLEX57K (57.7%) have at most 5 labels. The detailed distributions can be seen in <ref type="figure" target="#fig_4">Figure 4</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Experimental Results</head><p>In Tables 6-9, we present additional results for the main measures used across the LMTC literature (P @K, R@K, RP @K, nDGC@K).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>OVERALL FREQUENT</head><p>FEW ZERO @1 @5 @10 @1 @5 @10 @1 @5 @10 @1 @5 @10  @5 @10 @1 @5 @10 @1 @5 @10 @1 @5 @10 Exact  <ref type="table">Table 8</ref>: RP @1, RP @5 and RP @10 results on EURLEX57K for all, frequent, few-shot, zero-shot labels. Starred methods use the first 512 document tokens; all other methods use full documents. Unless otherwise stated, GLOVE embeddings are used.</p><p>OVERALL FREQUENT FEW ZERO @1 @5 @10 @1 @5 @10 @1 @5 @10 @1 @5 @10  <ref type="table">Table 9</ref>: nDCG@1, nDCG@5 and nDCG@10 results on EURLEX57K for all, frequent, few-shot, zero-shot labels. Starred methods use the first 512 document tokens; all other methods use full documents. Unless otherwise stated, GLOVE embeddings are used.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Illustration of (a) BIGRU-ATT, (b) HAN, (c) BIGRU-LWAN, and (d) BERT. layer of L = 4, 271 output units with sigmoids, producing L probabilities, one per label.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Fig. 2.5  In our dataset, there are 5.07 labels per document, hence K = 5 is reasonable. 6 R@K (green lines), P @K (red), RP @K (black) of the best methods (BIGRU-LWANs (L2V), BIGRU-LWANs (ELMO), BERT-BASE), for K = 1 to 10. All scores macro-averaged over test documents.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Distribution of EUROVOC concepts across EURLEX57K documents not converge in the fourth epoch, as suggested by Devlin et al. (2018). Thus we used early-stopping with no patience and trained the model for eight to nine epochs on average among the five runs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>0.619 0.386 0.867 0.599 0.367 0.488 0.184 0.107 0.247 0.093 0.057 BIGRU-LWAN-L2V 0.913 0.669 0.417 0.905 0.639 0.390 0.593 0.219 0.122 0.013 0.007 0.008 BIGRU-LWAN-L2V* 0.915 0.664 0.413 0.905 0.637 0.387 0.586 0.214 0.120 0.013 0.010 0.010 BIGRU-LWAN-ELMO* 0.921 0.674 0.419 0.912 0.644 0.391 0.595 0.226 0.127 0.011 0.009 0.007 BERT-BASE * 0.922 0.687 0.424 0.914 0.656 0.394 0.611 0.229 0.129 0.019 0.006 0.007</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Distribution of number of labels per document in EURLEX57K.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Match 0.131 0.097 0.168 0.194 0.219 0.344 0.037 0.111 0.214 0.178 0.194 0.206 Logistic Regression 0.861 0.710 0.765 0.864 0.767 0.846 0.458 0.508 0.560 0.011 0.011 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>. 3 Each document contains four major zones: the header, which includes the title and name of the legal body</figDesc><table><row><cell cols="4">Subset Documents (D) Words/D Labels/D</cell></row><row><cell>Train</cell><cell>45,000</cell><cell>729</cell><cell>5</cell></row><row><cell>Dev.</cell><cell>6,000</cell><cell>714</cell><cell>5</cell></row><row><cell>Test</cell><cell>6,000</cell><cell>725</cell><cell>5</cell></row><row><cell>Total</cell><cell>57,000</cell><cell>727</cell><cell>5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Statistics of the EUR-LEX dataset.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Micro-F 1 RP @5 nDCG@5 RP @5 nDCG@5 RP @5 nDCG@5</figDesc><table><row><cell></cell><cell></cell><cell>ALL LABELS</cell><cell></cell><cell cols="2">FREQUENT</cell><cell></cell><cell>FEW</cell><cell></cell><cell>ZERO</cell></row><row><cell cols="3">RP @5 nDCG@5 Exact Match 0.097 0.099</cell><cell>0.120</cell><cell>0.219</cell><cell>0.201</cell><cell>0.111</cell><cell>0.074</cell><cell>0.194</cell><cell>0.186</cell></row><row><cell>Logistic Regression</cell><cell>0.710</cell><cell>0.741</cell><cell>0.539</cell><cell>0.767</cell><cell>0.781</cell><cell>0.508</cell><cell>0.470</cell><cell>0.011</cell><cell>0.011</cell></row><row><cell>BIGRU-ATT</cell><cell>0.758</cell><cell>0.789</cell><cell>0.689</cell><cell>0.799</cell><cell>0.813</cell><cell>0.631</cell><cell>0.580</cell><cell>0.040</cell><cell>0.027</cell></row><row><cell>HAN</cell><cell>0.746</cell><cell>0.778</cell><cell>0.680</cell><cell>0.789</cell><cell>0.805</cell><cell>0.597</cell><cell>0.544</cell><cell>0.051</cell><cell>0.034</cell></row><row><cell>CNN-LWAN</cell><cell>0.716</cell><cell>0.746</cell><cell>0.642</cell><cell>0.761</cell><cell>0.772</cell><cell>0.613</cell><cell>0.557</cell><cell>0.036</cell><cell>0.023</cell></row><row><cell>BIGRU-LWAN</cell><cell>0.766</cell><cell>0.796</cell><cell>0.698</cell><cell>0.805</cell><cell>0.819</cell><cell>0.662</cell><cell>0.618</cell><cell>0.029</cell><cell>0.019</cell></row><row><cell>ZERO-CNN-LWAN</cell><cell>0.684</cell><cell>0.717</cell><cell>0.618</cell><cell>0.730</cell><cell>0.745</cell><cell>0.495</cell><cell>0.454</cell><cell>0.321</cell><cell>0.264</cell></row><row><cell>ZERO-BIGRU-LWAN</cell><cell>0.718</cell><cell>0.752</cell><cell>0.652</cell><cell>0.764</cell><cell>0.780</cell><cell>0.561</cell><cell>0.510</cell><cell>0.438</cell><cell>0.345</cell></row><row><cell>BIGRU-LWAN-L2V</cell><cell>0.775</cell><cell>0.804</cell><cell>0.711</cell><cell>0.815</cell><cell>0.828</cell><cell>0.656</cell><cell>0.612</cell><cell>0.034</cell><cell>0.024</cell></row><row><cell>BIGRU-LWAN-L2V*</cell><cell>0.770</cell><cell>0.796</cell><cell>0.709</cell><cell>0.811</cell><cell>0.825</cell><cell>0.641</cell><cell>0.600</cell><cell>0.047</cell><cell>0.030</cell></row><row><cell>BIGRU-LWAN-ELMO*</cell><cell>0.781</cell><cell>0.811</cell><cell>0.719</cell><cell>0.821</cell><cell>0.835</cell><cell>0.668</cell><cell>0.619</cell><cell>0.044</cell><cell>0.028</cell></row><row><cell>BERT-BASE *</cell><cell>0.796</cell><cell>0.823</cell><cell>0.732</cell><cell>0.835</cell><cell>0.846</cell><cell>0.686</cell><cell>0.636</cell><cell>0.028</cell><cell>0.023</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Results on EURLEX57K for all, frequent, few-shot, zero-shot labels. Starred methods use the first 512 document tokens; all other methods use full documents. Unless otherwise stated, GLOVE embeddings are used.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Table 4compares the performance of BIGRU-LWAN on the development set for different combinations of document zones (Section 3): header (H), recitals (R), main body (MB), full text. Surprisingly H+R leads to almost the same results as full documents, 9 indicating that H+R provides most of the information needed to assign EUROVOC labels.</figDesc><table><row><cell></cell><cell cols="3">RP @5 nDCG@5 Micro-F 1</cell></row><row><cell>GLOVE</cell><cell>0.766</cell><cell>0.796</cell><cell>0.698</cell></row><row><cell>L2V</cell><cell>0.775</cell><cell>0.804</cell><cell>0.711</cell></row><row><cell cols="2">GLOVE + ELMO 0.777</cell><cell>0.808</cell><cell>0.714</cell></row><row><cell>L2V + ELMO</cell><cell>0.781</cell><cell>0.811</cell><cell>0.719</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>BIGRU-LWAN with GLOVE, L2V, ELMO.</figDesc><table><row><cell>H</cell><cell>43</cell><cell>0.747</cell><cell>0.782</cell><cell>0.688</cell></row><row><cell>R</cell><cell>317</cell><cell>0.734</cell><cell>0.765</cell><cell>0.669</cell></row><row><cell>H+R</cell><cell>360</cell><cell>0.765</cell><cell>0.796</cell><cell>0.701</cell></row><row><cell>MB</cell><cell>187</cell><cell>0.643</cell><cell>0.674</cell><cell>0.590</cell></row><row><cell>Full</cell><cell>727</cell><cell>0.766</cell><cell>0.797</cell><cell>0.702</cell></row></table><note>µ words RP @5 nDCG@5 Micro-F 1</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>BIGRU-LWAN with different document zones.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>(bottom zone) shows that BERT out-</cell></row><row><cell>performs all other methods, even though it consid-</cell></row><row><cell>ers only the first 512 tokens. It fails, however, in</cell></row><row><cell>zero-shot learning, since it does not have a com-</cell></row><row><cell>ponent that exploits prior knowledge as is (i.e., all</cell></row><row><cell>the components are fine-tuned on training data).</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>). Minneapolis, MN, USA. Rotem Dror, Gili Baumer, Segev Shlomov, and Roi Reichart. 2018. The Hitchhiker's Guide to Testing Statistical Significance in Natural Language Processing. In Proceedings of the 56th Annual Meeting of</figDesc><table><row><cell>Computational Linguistics: Human Language Tech-</cell><cell>Proceedings of the 2018 Conference of the North</cell></row><row><cell>nologies, the Association for Computational Linguistics (Vol-</cell><cell>American Chapter of the Association for Computa-tional Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 1101-1111, New Orleans, Louisiana. Association for Computational Linguistics. Ramesh Nallapati and Christopher D. Manning. 2008.</cell></row><row><cell>ume 1: Long Papers), pages 1383-1392, Melbourne,</cell><cell>Legal Docket Classification: Where Machine Learn-</cell></row><row><cell>Australia.</cell><cell>ing Stumbles. In Proceedings of the Conference on</cell></row><row><cell></cell><cell>Empirical Methods in Natural Language Processing</cell></row><row><cell>Alistair EW Johnson, David J. Stone, Leo A. Celi, and</cell><cell>(EMNLP), pages 438-446, Honolulu, Hawaii. Asso-</cell></row><row><cell>Tom J. Pollard. 2017. MIMIC-III, a freely accessi-</cell><cell>ciation for Computational Linguistics.</cell></row><row><cell>ble critical care database. Nature.</cell><cell></cell></row><row><cell>Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan,</cell><cell></cell></row><row><cell>Aäron van den Oord, Alex Graves, and Koray</cell><cell></cell></row><row><cell>Kavukcuoglu. 2017. Neural Machine Translation in</cell><cell></cell></row><row><cell>Linear Time. In Proceedings of the Conference on</cell><cell></cell></row><row><cell>Empirical Methods in Natural Language Processing</cell><cell></cell></row><row><cell>(EMNLP), Copenhagen, Denmark.</cell><cell></cell></row><row><cell>David D. Lewis, Yiming Yang, Tony G. Rose, and Fan</cell><cell></cell></row><row><cell>Li. 2004. RCV1: A New Benchmark Collection for</cell><cell></cell></row><row><cell>Text Categorization Research. J. Mach. Learn. Res.,</cell><cell></cell></row><row><cell>5:361-397.</cell><cell></cell></row><row><cell>Jingzhou Liu, Wei-Cheng Chang, Yuexin Wu, and</cell><cell></cell></row><row><cell>Yiming Yang. 2017. Deep Learning for Extreme</cell><cell></cell></row><row><cell>Multi-label Text Classification. In Proceedings</cell><cell></cell></row><row><cell>of the 40th International ACM SIGIR Conference</cell><cell></cell></row><row><cell>on Research and Development in Information Re-</cell><cell></cell></row><row><cell>trieval, SIGIR '17, pages 115-124, New York, NY,</cell><cell></cell></row><row><cell>USA.</cell><cell></cell></row><row><cell>Shichen Liu, Mingsheng Long, Jianmin Wang, and</cell><cell></cell></row><row><cell>Michael I Jordan. 2018. Generalized Zero-Shot Learning with Deep Calibration Network. In Ad-vances in Neural Information Processing Systems 31, pages 2005-2015. Curran Associates, Inc.</cell><cell>Ilias Chalkidis, Ion Androutsopoulos, and Achilleas Michos. 2017. Extracting Contract Elements. In Proceedings of the 16th Edition of the International Conference on Articial Intelligence and Law, pages</cell></row><row><cell>Christopher D. Manning, Prabhakar Raghavan, and</cell><cell>19-28, London, UK.</cell></row><row><cell>Hinrich Schtze. 2009. Introduction to Information Retrieval. Cambridge University Press.</cell><cell>Ilias Chalkidis, Ion Androutsopoulos, and Achilleas Michos. 2018. Obligation and Prohibition Extrac-</cell></row><row><cell>Julian McAuley and Jure Leskovec. 2013. Hidden</cell><cell>tion Using Hierarchical RNNs. In Proceedings of</cell></row><row><cell>Factors and Hidden Topics: Understanding Rating</cell><cell>the 56th Annual Meeting of the Association for Com-</cell></row><row><cell>Dimensions with Review Text. In Proceedings of</cell><cell>putational Linguistics (Volume 2: Short Papers),</cell></row><row><cell>the 7th ACM Conference on Recommender Systems,</cell><cell>pages 254-259, Melbourne, Australia.</cell></row><row><cell>RecSys '13, pages 165-172, New York, NY, USA.</cell><cell>Ilias Chalkidis and Dimitrios Kampas. 2018. Deep</cell></row><row><cell>Eneldo Loza Mencia and Johannes Fürnkranzand.</cell><cell>learning in law: early adaptation and legal word em-</cell></row><row><cell>2007. An Evaluation of Efficient Multilabel Classi-</cell><cell>beddings trained on large corpora. Artificial Intelli-</cell></row><row><cell>fication Algorithms for Large-Scale Problems in the</cell><cell>gence and Law.</cell></row><row><cell>Legal Domain. In Proceedings of the LWA 2007, pages 126-132, Halle, Germany.</cell><cell>Zihang Dai, Zhilin Yang, Yiming Yang, Jaime G. Carbonell, Quoc V. Le, and Ruslan Salakhutdi-</cell></row><row><cell>Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey</cell><cell>nov. 2019. Transformer-XL: Attentive Language</cell></row><row><cell>Dean. 2013. Efficient Estimation of Word Repre-</cell><cell>Models Beyond a Fixed-Length Context. CoRR,</cell></row><row><cell>sentations in Vector Space. In Proceedings of the</cell><cell>abs/1901.02860.</cell></row><row><cell>International Conference on Learning Representa-</cell><cell></cell></row><row><cell>tions (ICLR), Scottsdale, AZ.</cell><cell>Jacob Devlin, Ming-Wei Chang, Kenton Lee, and</cell></row><row><cell></cell><cell>Kristina Toutanova. 2018. BERT: Pre-training of</cell></row><row><cell>James Mullenbach, Sarah Wiegreffe, Jon Duke, Jimeng</cell><cell>Deep Bidirectional Transformers for Language Un-</cell></row><row><cell>Sun, and Jacob Eisenstein. 2018. Explainable Pre-</cell><cell>derstanding. In Proceedings of the Conference of</cell></row><row><cell>diction of Medical Codes from Clinical Text. In</cell><cell>the North American Chapter of the Association for</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 5 :</head><label>5</label><figDesc>Best hyper parameters for neural methods. N l : number of layers, HU : hidden units size, D d : dropout rate across dimensions, D we : dropout rate of word embeddings, BS: batch size. * Hidden units size is fixed to word embedding dimensionality, + N l , HU are fixed from the pre-trained model. Dropout rate fixed as suggested byDevlin et al. (2018).</figDesc><table><row><cell>OVERALL</cell><cell>FREQUENT</cell><cell>FEW</cell><cell>ZERO</cell></row><row><cell>@1</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 6 :</head><label>6</label><figDesc>P @1, P @5 and P @10 results on EURLEX57K for all, frequent, few-shot, zero-shot labels. Starred methods use the first 512 document tokens; all other methods use full documents. Unless otherwise stated, GLOVE embeddings are used.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 7 :</head><label>7</label><figDesc>R@1, R@5 and R@10 results on EURLEX57K for all, frequent, few-shot, zero-shot labels. Starred methods use the first 512 document tokens; all other methods use full documents. Unless otherwise stated, GLOVE embeddings are used.</figDesc><table><row><cell>OVERALL</cell><cell>FREQUENT</cell><cell>FEW</cell><cell>ZERO</cell></row><row><cell>@1</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">See https://eur-lex.europa.eu/ for EUR-LEX, and https://publications.europa.eu/en/ web/eu-vocabularies for EUROVOC.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Our dataset is available at http://nlp.cs. aueb.gr/software_and_datasets/EURLEX57K, with permission of reuse under European Union c , https://eur-lex.europa.eu, 1998-2019.  3  See Appendix A for more statistics.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">See https://publications.europa.eu/en.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">We implemented all methods in KERAS (https:// keras.io/). Code available at https://github. com/iliaschalkidis/lmtc-eurlex57k.git. See Appendix B for details on hyper-parameter tuning.8  We perform 10k iterations, randomly swapping in each iteration the responses (sets of returned labels) of the two compared systems for 50% of the test documents.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was partly supported by the Research Center of the Athens University of Economics and Business.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A EURLEX57K statistics</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Predicting judicial decisions of the European Court of Human Rights: a Natural Language Processing perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolaos</forename><surname>Aletras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PeerJ Computer Science</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">93</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">LSHTC: A Benchmark for Large-Scale Text Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Partalas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aris</forename><surname>Kosmopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Baskiotis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thierry</forename><surname>Artières</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Paliouras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Éric</forename><surname>Gaussier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ion</forename><surname>Androutsopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massih-Reza</forename><surname>Amini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Gallinari</surname></persName>
		</author>
		<idno>abs/1503.08581</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">GloVe: Global Vectors for Word Representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deep contextualized word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Few-Shot and Zero-Shot Multi-Label Learning for Structured Label Spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Rios</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramakanth</forename><surname>Kavuluru</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3132" to="3142" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Éric Gaussier, Liliana Barrio-Alvers, Michael Schroeder, Ion Androutsopoulos, and Georgios Paliouras. 2015. An overview of the BIOASQ large-scale biomedical semantic indexing and question answering competition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Tsatsaronis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Balikas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prodromos</forename><surname>Malakasiotis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Partalas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Zschunke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">R</forename><surname>Alvers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anastasia</forename><surname>Krithara</surname></persName>
		</author>
		<idno type="DOI">https:/bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-015-0564-6</idno>
	</analytic>
	<monogr>
		<title level="m">Sergios Petridis, Dimitris Polychronopoulos, Yannis Almirantis, John Pavlopoulos, Nicolas Baskiotis, Patrick Gallinari, Thierry Artières, Axel-Cyrille Ngonga Ngomo</title>
		<meeting><address><addrLine>Norman Heino</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Attention Is All You Need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31th Annual Conference on Neural Information Processing Systems</title>
		<meeting>the 31th Annual Conference on Neural Information Processing Systems<address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A no-regret generalization of hierarchical softmax to extreme multi-label classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marek</forename><surname>Wydmuch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kalina</forename><surname>Jasinska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikhail</forename><surname>Kuznetsov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Róbert</forename><surname>Busa-Fekete</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krzysztof</forename><surname>Dembczynski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Neural Information Processing Systems</title>
		<meeting>the 32nd International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="6355" to="6366" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhudinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Machine Learning</title>
		<meeting>the 32nd International Conference on Machine Learning<address><addrLine>Lille, France. PMLR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="2048" to="2057" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Hierarchical Attention Networks for Document Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zichao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diyi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1480" to="1489" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Atten-tionXML: Extreme Multi-Label Text Classification with Multi-Label Attention Based Recurrent Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronghui</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suyang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroshi</forename><surname>Mamitsuka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanfeng</forename><surname>Zhu</surname></persName>
		</author>
		<idno>abs/1811.01727</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep Extreme Multi-label Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junchi</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangfeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyuan</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 ACM on International Conference on Multimedia Retrieval, ICMR &apos;18</title>
		<meeting>the 2018 ACM on International Conference on Multimedia Retrieval, ICMR &apos;18<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="100" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Enhancing Navigation on Wikipedia with Social Tags</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arkaitz</forename><surname>Zubiaga</surname></persName>
		</author>
		<idno>abs/1202.5469</idno>
		<imprint>
			<date type="published" when="2012" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
