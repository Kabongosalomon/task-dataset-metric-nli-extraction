<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Anomaly Detection in Time Series with Triadic Motif Fields and Application in Atrial Fibrillation ECG Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yadong</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Chen</surname></persName>
						</author>
						<title level="a" type="main">Anomaly Detection in Time Series with Triadic Motif Fields and Application in Atrial Fibrillation ECG Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T05:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Anomaly Detection</term>
					<term>Triadic Motif Field</term>
					<term>Trans- fer Learning</term>
					<term>Atrial Fibrillation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In the time-series analysis, the time series motifs and the order patterns in time series can reveal general temporal patterns and dynamic features. Triadic Motif Field (TMF) is a simple and effective time-series image encoding method based on triadic time series motifs. Electrocardiography (ECG) signals are time-series data widely used to diagnose various cardiac anomalies. The TMF images contain the features characterizing the normal and Atrial Fibrillation (AF) ECG signals. Considering the quasi-periodic characteristics of ECG signals, the dynamic features can be extracted from the TMF images with the transfer learning pre-trained convolutional neural network (CNN) models. With the extracted features, the simple classifiers, such as the Multi-Layer Perceptron (MLP), the logistic regression, and the random forest, can be applied for accurate anomaly detection. With the test dataset of the PhysioNet Challenge 2017 database, the TMF classification model with the VGG16 transfer learning model and MLP classifier demonstrates the best performance with the 95.50% ROC-AUC and 88.43% F1 score in the AF classification. Besides, the TMF classification model can identify AF patients in the test dataset with high precision. The feature vectors extracted from the TMF images show clear patient-wise clustering with the t-distributed Stochastic Neighbor Embedding technique. Above all, the TMF classification model has very good clinical interpretability. The patterns revealed by symmetrized Gradient-weighted Class Activation Mapping have a clear clinical interpretation at the beat and rhythm levels.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>T IME series classification and anomaly detection are important techniques in the understanding of the varieties of dynamics in Science and Engineering <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>. The temporal patterns in time series contain important information about the underlying dynamics. The electrocardiogram (ECG) is the important medical time series used by cardiologists and medical practitioners for monitoring cardiac health and detecting cardiac abnormality, such as Atrial Fibrillation (AF), Myocardial Infarction (MI), etc. ECG signals from normal healthy and abnormal hearts have certain clinical patterns.</p><p>This work was supported in part by the National Natural Science Foundation of China (Grant No.21773182 (B030103)) and the HPC Platform, Xi'an Jiaotong University. Xin Chen thanks Prof. Chunhua Shen at the University of Adelaide for the discussion on the transfer learning and feature extraction. (Corresponding author: Xin Chen.)</p><p>Yadong Zhang is with Center of Nanomaterials for Renewable Energy, School of Electrical Engineering, Xi'an Jiaotong University, Xi'an, Shaanxi, China (e-mail: zhangyadong@stu.xjtu.edu.cn).</p><p>Xin Chen is with Center of Nanomaterials for Renewable Energy, School of Electrical Engineering, Xi'an Jiaotong University, Xi'an, Shaanxi, China (e-mail: xin.chen.nj@xjtu.edu.cn).</p><p>Identifying and learning these temporal patterns/features in the ECG time series are critically essential to the ECG analysis <ref type="bibr" target="#b2">[3]</ref>.</p><p>The conventional ECG anormaly detection and signal classification require the identification of the AF features according to the expert rules in the ECG diagnosis <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>. The random forest classifiers <ref type="bibr" target="#b4">[5]</ref> are implemented with the features from time, frequency, time-frequency domain and phase space reconstruction. Recently, deep learning is successfully applied in the ECG analysis <ref type="bibr" target="#b5">[6]</ref>- <ref type="bibr" target="#b8">[9]</ref>. Feature extraction is carried out automatically with deep learning models. Convolutional Neural Networks <ref type="bibr" target="#b5">[6]</ref>, BiLSTM-Attention Neural Network <ref type="bibr" target="#b6">[7]</ref> and Convolutional Recurrent Neural Networks <ref type="bibr" target="#b7">[8]</ref>, etc. are used to learn temporal patterns and features of the ECG signals in the time and frequency domain. MultIlevel kNowledgeguided Attention networks <ref type="bibr" target="#b8">[9]</ref> is implemented with multilevel attention in the knowledge of beat, rhythm, and frequency information in the AF classification.</p><p>Motivated by the success of Convolutional Neural Network (CNN) in the image classification, the time series classification with image encoding of time series also demonstrates high performance, e.g. Gramian Angular Summation/Difference Fields (GASF/GADF) and Markov Transition Fields (MTF) <ref type="bibr" target="#b9">[10]</ref>, the Recurrence plots <ref type="bibr" target="#b10">[11]</ref> and time-frequency-domain images <ref type="bibr" target="#b7">[8]</ref>. The Tiled CNN can classify the time series based on the GASF/GADF images <ref type="bibr" target="#b9">[10]</ref>. CNN is applied for the classification of time series based on the Recurrence plots <ref type="bibr" target="#b10">[11]</ref>. CRNN based on spectrogram images of ECG signals do well in the AF classification <ref type="bibr" target="#b7">[8]</ref>.</p><p>Time series motifs define the local order patterns in time series. Motif occurrence probabilities provide the information about the complexity of the underlying dynamics. Permutation entropy <ref type="bibr" target="#b11">[12]</ref> according the motif ordinal patterns has been successfully used for the time series complexity measurement <ref type="bibr" target="#b11">[12]</ref>, chaotic maps characterization <ref type="bibr" target="#b12">[13]</ref>, stock market analysis <ref type="bibr" target="#b13">[14]</ref>, ECG signals analysis <ref type="bibr" target="#b14">[15]</ref>, and etc. The statistical probabilities of triadic time series motif have been applied for the UCR time series archive classification <ref type="bibr" target="#b15">[16]</ref>.</p><p>In this paper, a novel image encoding method, Triadic Motif Field (TMF) is proposed by considering the triadic motifs in time series. With the TMF images, we successfully detect AF ECG signals with transferred knowledge from ImageNet dataset. And the clinical patterns can be interpreted using symmetrized Gradient-weighted Class Activation Mapping (Grad-CAM). The proposed method is simple, effective, and accurate. Above all, it has good interpretability compared to other AF classification methods based on deep learning. Section II discusses the TMF image encoding method and describes the feature extraction with the TMF images and the classification model. In Section III, the performance of the classification model is evaluated and discussed. In Section IV, the interpretability of the TMF classification model is discussed.</p><p>II. METHOD <ref type="figure" target="#fig_1">Fig. 1</ref> shows the image encoding method, Triadic Motif Field (TMF), that converts the order patterns and temporal structures of time series to images based on triadic motifs in ECG signals. Using the transfer learning pre-trained CNN models based on the ImageNet dataset, the TMF images are used to extract the features for the Atrial Fibrillation (AF) and non-AF ECG signals. The symmetrized Gradient-weighted Class Activation Mapping (Grad-CAM) is used to interpret results by identifying beat-level and rhythm-level patterns.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Triadic Motif Field Images</head><p>The time series motifs are the sub-sequences that are widely used in pattern recognitions in time series <ref type="bibr" target="#b16">[17]</ref>- <ref type="bibr" target="#b18">[19]</ref>. Triadic Motif Field (TMF) is constructed based on triadic time series motifs. Given a time series X = {x(n), n = 1, 2, 3, · · · , N }, the sequence of triadic time series motifs is defined as</p><formula xml:id="formula_0">M = {M (n|τ ), n = 1, 2, 3, · · · , N − 2τ }<label>(1)</label></formula><p>where M (n|τ ) is a triadic time series motif M (n|τ ) = [x(n), x(n + τ ), x(n + 2τ )] with delay τ . In the definition of a triadic time motif M (n|τ ), the delay τ is the separation step of two sequential points. The range of τ = 1, 2, 3, · · · , τ max is (N − 1)/2 . Usually, τ is 1. However, the different delays are also important in detecting the long-range patterns in time series. Taking an ECG signal as an example, the three triadic time series motifs with different τ = 5, 134, 265 can approximately match the R peak, beat, and RR interval as shown in <ref type="figure" target="#fig_2">Fig. 2</ref>. According to the triadic time series motifs with different delays, the TMF array V , a three-channel image V ∈ R τmax×(N −2)×3 , is defined as a stack of triadic time series motifs with all the possible delays,</p><formula xml:id="formula_1">V τ nk = I k (n|τ ), k = 1, 2, 3<label>(2)</label></formula><p>where</p><formula xml:id="formula_2">I(n|τ ) = M (n|τ ), if 1 ≤ n ≤ N − 2τ [0, 0, 0] , if N − 2τ &lt; n ≤ N − 2 (3) Finally, the TMF image, T M F ∈ R τmax×(N −2)×3 , is defined as, T M F τ nk = V τ nk + K[τ, n] · V τ n k<label>(4)</label></formula><p>where τ = τ max − τ + 1, n = N − n − 1 and K ∈ R τmax×(N −2) is defined as a masker to prevent overlapping of the two arrays, <ref type="figure" target="#fig_3">Fig. 3</ref> shows the procedure of encoding an ECG signal into a TMF image. In a word, the horizontal and vertical axises of TMF image are associated with the temporal and multi-scale informations of the triadic time series in the signal. </p><formula xml:id="formula_3">K[τ, n] = 0, if 1 ≤ n ≤ N − 2τ 1, if N − 2τ &lt; n ≤ N − 2<label>(5)</label></formula><formula xml:id="formula_4">X V τ!k K[τ,n]"V τ # ! # k TMF (a) (b) (c) (d)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Deep Feature Transfer Learning and TMF Classification</head><p>With the transferred knowledge of instances, feature representations, and parameters, the deep transfer learning <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b20">[21]</ref> has been applied successfully in many real-world applications such as classification, regression, and clustering problems. The transfer learning pre-trained models are used to extract the features based on the TMF images of ECG signals. The TMF classification model has two parts, feature extractors and classifiers as shown in <ref type="figure" target="#fig_4">Fig. 4</ref>. The transfer learning feature extractors can be the pre-trained network models F including VGG16 <ref type="bibr" target="#b21">[22]</ref>, VGG19 <ref type="bibr" target="#b21">[22]</ref>, ResNet50 <ref type="bibr" target="#b22">[23]</ref>, and etc.</p><formula xml:id="formula_5">The multi-channel feature map, A ∈ R W ×H×S , is extracted as, A = F(T M F )<label>(6)</label></formula><p>where W, H, S are the width, height and channel number of the feature map. Followed by the Global Average Pooling (GAP) layer, the feature map A is aggregated as the feature vector,</p><formula xml:id="formula_6">h = 1 W · H [ W i H j A ij1 , W i H j A ij2 , · · · , W i H j A ijS ]<label>(7)</label></formula><p>With feature vector as the input, the classifiers can be multilayer perceptron (MLP), logistic regression (LR), random forest (RF), and etc. The MLP classifier includes one hidden layer with 128 neurons in <ref type="bibr" target="#b7">(8)</ref> and the predicted probability y of AF or non-AF is given with the last layer in <ref type="formula" target="#formula_7">(9)</ref>,</p><formula xml:id="formula_7">h o = ReLU (W h + b) (8) y = Sof tmax(W o h o + b o )<label>(9)</label></formula><p>where y is a C dimension vector and C is the number of classes. In this problem, y is [y 1 , y 2 ] where y 1 and y 2 indicate the AF and non-AF probabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Frame-wise Preprocessed Datasets</head><p>The ECG recordings in PhysioNet Challenge 2017 database <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref> are used for the training and test of the classification models. The dataset contains ECG recordings of 8528 recordings sampled among which there are 738 AF patients and 7790 non-AF controls including normal, noisy, and other types.</p><p>We divide the dataset according to the recordings into the training dataset (75%), the validation dataset (10%), and the test dataset (15%) as shown in <ref type="table" target="#tab_0">Table I</ref>. Each ECG recording is converted into the sliding frames with a length of 3000. 50 and 500 strides are used for the sliding windows of the AF and non-AF ECG recordings. For the TMF classification model, the TMF images of the frames are used for the training and test. The preprocessed datasets consisting of the sliding frames are summarized in <ref type="table" target="#tab_0">Table II</ref>. The transfer learning models, VGG16, VGG19, and ResNet50 pre-trained on the ImageNet dataset excluding their top fully-connect layers in TensorFlow <ref type="bibr" target="#b25">[26]</ref> are used. The three classifiers in <ref type="figure" target="#fig_4">Fig. 4</ref> are trained, validated, and tested on the same datasets in <ref type="table" target="#tab_0">Table II</ref>. With categorical cross entropy as loss function, the MLP classifier is trained with Adam <ref type="bibr" target="#b26">[27]</ref> at the learning rate 0.001, β 1 0.9 and β 2 0.999, and it is validated with early stopping criteria on validation set. Using Scikit-learn <ref type="bibr" target="#b27">[28]</ref>, the hyper-parameters in LR and RF classifiers are tuned with the random-search strategy on the validation dataset. For the LR classifier, the selection of the penalty, solver, and etc. are optimized. For the RF classifier, the number of trees, number of features, and etc. are optimally selected. The system is equipped with HPC server, 32 dual CPU (2650 v3) nodes/640 cores. Our code will be publicly available later.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. CLASSIFICATION PERFORMANCE AND DISCUSSION</head><p>The preprocessed datasets consist of the moving frames for the ECG signals of patients since the ECG recordings have varied lengths. The classification performance is measured by the area under the Receiver Operating Characteristic (ROC-AUC), Area under the Precision Recall Curve (PR-AUC), and the F1 score according to the sliding frames of patients in the test dataset. In the subsection III-B and subsection III-C, we will discuss the patient-wise classification performance and clusterings.</p><p>The TMF (VGG16-MLP) classification model is benchmarked with the three existing classification methods including the random forest with expert features (ExpertRF) <ref type="bibr" target="#b8">[9]</ref>, the convolutional recurrent network with spectrogram images (CRNN) <ref type="bibr" target="#b7">[8]</ref> and the multi-level attention network (MINA) <ref type="bibr" target="#b8">[9]</ref>. The VGG16 pre-trained model is used for feature extraction and the MLP classifier is trained with the early stopping criteria on the validation set. We then test it 5 times using different random seeds and report its mean values with standard deviations. <ref type="table" target="#tab_0">Table III</ref> shows the TMF (VGG16-MLP) classification model outperforms all benchmarking models and has the F1 score 5.01% higher than the current best model, MINA. Furthermore, <ref type="table" target="#tab_0">Table IV</ref> shows the frame-wise performance for the TMF classification model with different feature extractors and classifiers. The pre-trained VGG16 <ref type="bibr" target="#b21">[22]</ref>, VGG19 <ref type="bibr" target="#b21">[22]</ref> and ResNet50 <ref type="bibr" target="#b22">[23]</ref> on the ImageNet dataset followed by Global Average Pooling are used as feature extractors. MLP, LR and RF are used as classifiers. LR and RF are selected with the random-search strategy on the validation dataset to tune the hyper-parameters. It shows that the VGG16-MLP combination has the best performance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Frame Length of Test Dataset</head><p>The frame-wise accuracy of the trained TMF (VGG16-MLP) classification model is also dependent on the frame length in the test. In the experiment, the VGG16-MLP model trained with 3000 frame length is evaluated on the test dataset where the frame length ranges from 100 to 3000 with step 100.</p><p>With an AF ECG signal, as shown in <ref type="figure">Fig. 5</ref>, we can see that the predicted AF probability y 1 increases rapidly when the length goes beyond the 7 th and 8 th R peaks corresponding to where the abnormal rhythm is located. With the frame 1600 step long, the TMF classification model can predict the AF probability y 1 as well as the frame 3000 steps long. Therefore, the length of frames used in the test can be much shorter than the one in the training. As for statistical analysis in <ref type="figure">Fig. 6</ref>, it is important to notice that the frame length longer than 1500 steps in the test dataset already can give a stable performance. Therefore, in the application of the TMF classification model, the frame 1500 step (5 seconds) long is sufficient enough.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Patient-wise Classification Performance</head><p>Given the preprocessed dataset, the performance of the TMF classification model is evaluated with the frame-wise pre- processed datasets. However, the patient-wise classification is important for the clinical application. According to the frames belonging to one AF patient, the patient-wise classification accuracy is defined as,</p><formula xml:id="formula_8">accuracy = m M × 100%<label>(10)</label></formula><p>where m is the number of frames with which the TMF classification model predicts that it is the AF patient if the AF probability y 1 is higher than 50%. M is the total number of frames belonging to this patient. For example, in <ref type="figure">Fig. 7</ref>, its patient-wise accuracy is 88/120 = 73.3%. <ref type="figure">Fig. 8</ref> shows that the TMF (VGG16-MLP) classification model has better patient-wise accuracies and narrow distribution compared to MINA. According to the definition of the patient-wise accuracy, we define two extreme groups of the patient-wise classification results, totally incorrect (TI) and totally correct (TC). The TI and TC groups refer to the patients with the patient-wise accuracy equal to 0% and 100% respectively. In <ref type="table" target="#tab_3">Table V</ref>, it shows that the TMF classification model can correctly identify 90 patients as AF among all 124 AF patients in the test dataset, which is 44 more than MINA.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Patient-wise ECG Feature Clustering</head><p>In order to visualize the transfered representation, tdistributed Stochastic Neighbor Embedding (t-SNE) <ref type="bibr" target="#b28">[29]</ref> is used to map high-dimensional feature vectors h extracted <ref type="figure" target="#fig_8">Fig. 9a</ref> shows the points in 2D space demonstrate clear separation between AF and non-AF classes of the test dataset. By repainting the AF points with the same color and connecting them according to the patients, <ref type="figure" target="#fig_8">Fig. 9b</ref> shows clear patientwise clusterings. Due to the knowledge transferred from Ima-geNet, the features naturally retain the basic similarity among frames in individual patients. Therefore transfer learning based on VGG16 performs well in the patient-wise feature extraction and classification as shown in <ref type="figure">Fig. 8</ref> and <ref type="table" target="#tab_3">Table V.</ref> IV. IMAGE-BASED TEMPORAL PATTERN RECOGNITION AND CLINICAL INTERPRETATION The symmetrized Grad-CAM of the TMF images is used to interpret the TMF classification model for the ECG signals. The Gradient-weighted Class Activation Mapping (Grad-CAM) <ref type="bibr" target="#b29">[30]</ref> is a technique to produce a visual explanation to varieties of CNN models. In the paper, we apply Grad-CAM to detect the ECG clinical temporal patterns in the TMF classification model.</p><p>Given the TMF images of the ECG signal of the AF or non-AF class, the Grad-CAM, L c ∈ R W ×H of the VGG16-MLP in <ref type="figure" target="#fig_4">Fig. 4</ref> can be generated by the gradient-based weighted combinations of the feature maps A,</p><formula xml:id="formula_9">L c = ReLU [ S s (α c s A s )]<label>(11)</label></formula><p>where s is channel index of the feature map, c is 1 or 2 that indicates AF or non-AF, and</p><formula xml:id="formula_10">α c s = 1 W · H W i H j ∂y c ∂A ijs .<label>(12)</label></formula><p>Then, the Grad-CAM image will be up-sampled into L c in ∈ R τmax×(N −2) , which have the same width and height of the input TMF images.</p><p>Due to the symmetry in the TMF images as constructed, we </p><p>where τ = τ max − τ + 1 and n = N − n − 1. G c gives the significance of the triadic motif in the TMF images of patient class c of AF or non-AF. This helps us to identify the clinically meaningful patterns in the ECG signals.</p><p>Cardiologists diagnose an ECG recording as the AF or non-AF case according to the following clinical patterns: 1) P wave; 2) RR interval. The TMF images consist of triadic time series with different delay and initial time indices that are associated with the clinical patterns. As shown in <ref type="figure" target="#fig_2">Fig. 2</ref>, triadic motifs with small delays can match the beat-level patterns such as QRS complex and R peak, while the triadic motifs with big delays catch rhythm-level patterns such as RR interval. The initial time index of the triadic motif will locate the pattern temporally.</p><p>The symmetrized Grad-CAM demonstrates strong interpretability for the AF and non-AF recordings at the beat and rhythm levels. As shown in <ref type="figure" target="#fig_1">Figs. 10c and 10d</ref>, hot spots with small delays are strongly associated with the QRS complex in the non-AF controls. In <ref type="figure" target="#fig_1">Fig. 10c</ref>, the weak regions on the left of the QRS complex indicate the abnormal or the absence of P waves in the AF recording while the strong and wide regions indicate the normal P waves in <ref type="figure" target="#fig_1">Fig. 10d</ref>. As shown in <ref type="figure" target="#fig_1">Fig. 10a</ref>, the highlighted regions corresponding to the triadic motifs with big delays match the abnormal interval in the AF patient. In <ref type="figure" target="#fig_1">Figs. 10b and 10d</ref>, the hot red spots demonstrate the spatial periodicity that naturally associated with the temporal periodicity of beats in the non-AF recording, while the nonperiodicity in the AF recording shown in Figs. 10a and 10c reflect the abnormal interval at the rhythm level. In summary, the symmetrized Grad-CAM can precisely match the clinically important patterns in the AF class at the beat and rhythm levels and distinguish the AF and non-AF classes.</p><p>V. CONCLUDING REMARKS In this paper, the interpretable classification model based on TMF images is proposed to detect the Atrial Fibrillation in the ECG recordings. It outperforms the baseline models in the AF classification. The TMF image encoding scheme has the following advantages:</p><p>1) The TMF images can visualize the order patterns and temporal structures of time series associated with the ECG analysis. 2) The TMF (VGG16-MLP) classification model has stateof-the-art performance compared to the baseline models based on the moving frames. Besides, the TMF classification model has much better patient-wise accuracies and clusterings in terms of the moving frames belonging to one patient.</p><p>3) The TMF classification model is simple and effective to be implemented and doesn't cost too much time on training, model selection, and hyper-parameters optimization. 4) The symmetrized Grad-CAM technique can be used to identify the clinical patterns in the TMF images of AF patients. It allows us to interpret the results from beat and rhythm levels.</p><p>The temporal data extensively exist in the medical, mechanical, electronic, and power systems. In the next step, we will further explore the applications of the TMF classification model in engineering systems such as fault detection, system health monitoring, distributed event detection in sensor networks, and etc. Currently, mobile edging computing devices such as smartphones all have good GPU and image processing capability. Given the advantages and efficiency of the TMF imaging encoding scheme, the TMF classification model has promising applications in edge computing and the Internet of Things (IoT).</p><p>(a) AF frame: G 1 with y 1 = 94.03% (b) Non-AF frame: G 1 with y 1 = 0.96%</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>QRS P</head><p>(c) AF frame: G 2 with y 2 = 5.97%</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>QRS P</head><p>(d) Non-AF frame: G 2 with y 2 = 99.04% </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>The framework of interpretable classification model based on the TMF images. The probabilities of AF and non-AF are predicted with feature transfer learning. On the parallel, symmetrized Grad-CAM is used for the pattern recognitions in the AF and non-AF ECG signals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>The ECG signal and triadic time series motifs with different delays, τ . τ = 5 corresponds to the R peak, τ = 134 beat and τ = 265 RR.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>The TMF images of an ECG signals. The blank spaces in (b) and (c) are 0 due to the structures of the TMF arrays V .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Architecture of the TMF classification model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .Fig. 6 .</head><label>56</label><figDesc>Length effect on the predicted AF probability for the ECG signal. Lower panel show an frame in the ECG signal. Upper panel shows the predicted AF probability y 1 and time consumption for the frame of different lengths. Frame length effect in the application of the classification model in the test dataset and the mean time consumed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>5 ECGFig. 7 .Fig. 8 .</head><label>578</label><figDesc>The classification probability y 1 for an AF patient. Lower panel is the full ECG signal of the patient. Upper panel indicates the predicted AF probability y 1 for the frames of the ECG signal. There are 88 frames predicted as AF class and 32 frames predicted as non-AF class in this patient. Box plot shows the patient-wise accuracy distribution according to the TMF classification model and MINA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>enforce the same symmetry by defining the new symmetrized Grad-CAM G c τ n with (L c in [τ, n] + L c in [τ , n ])/2 where (τ, n) and (τ , n ) are the two array indices according to the 180 rotation symmetry in V and the masked one, G c [τ, n] = L c in [τ, n], if K[τ, n] = K[τ , n ] = 0 (L c in [τ, n] + L c in [τ , n ])/2, others</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 .</head><label>9</label><figDesc>Visualization of features extracted from TMF images on test dataset. (a) AF and non-AF clustering based on the frame-wise feature vectors. (b) Patient-wise clustering of the AF patients. All the frame-wise features belonging to the same patients are connected and painted with the same colors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 .</head><label>10</label><figDesc>The AF and non-AF signals and their symmetrized Grad-CAM images. (a) and (c) show the symmetrized Grad-CAM images of the AF ECG frame while (b) and (d) show the non-AF ECG frame. Vertical dash lines in ECG signals indicate the R peaks. The triadic time series motifs with big delay associated abnormal non-periodic interval in the ECG recording are labeled with the red crosses in symmetrized Grad-CAM images in (a) and (b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I NUMBER</head><label>I</label><figDesc>OF RECORDINGS IN THE PREPROCESSED DATASETS FOR THE AF PATIENTS AND NON-AF CONTROLS.</figDesc><table><row><cell>Type</cell><cell cols="2">Training Validation</cell><cell>Test</cell></row><row><cell>AF patients</cell><cell>564</cell><cell>70</cell><cell>124</cell></row><row><cell>non-AF controls</cell><cell>5832</cell><cell>782</cell><cell>1156</cell></row><row><cell></cell><cell>TABLE II</cell><cell></cell><cell></cell></row><row><cell cols="4">NUMBER OF FRAMES IN THE PREPROCESSED DATASETS FOR THE AF AND</cell></row><row><cell cols="3">NON-AF CLASSES.</cell><cell></cell></row><row><cell>Type</cell><cell cols="2">Training Validation</cell><cell>Test</cell></row><row><cell>AF frames</cell><cell>75979</cell><cell>8402</cell><cell>17317</cell></row><row><cell>non-AF frames</cell><cell>79423</cell><cell>10462</cell><cell>15865</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE III PERFORMANCE</head><label>III</label><figDesc></figDesc><table><row><cell></cell><cell cols="3">COMPARISON ON AF CLASSIFICATION (%)</cell></row><row><cell>Method</cell><cell>ROC-AUC</cell><cell>PR-AUC</cell><cell>F1</cell></row><row><cell>ExpertRF</cell><cell>93.94 ± 0.00</cell><cell>88.16 ± 0.00</cell><cell>81.80 ± 0.00</cell></row><row><cell>CRNN</cell><cell>90.40 ± 1.15</cell><cell>89.43 ± 1.11</cell><cell>82.62 ± 2.15</cell></row><row><cell>MINA</cell><cell>94.88 ± 0.81</cell><cell>94.36 ± 0.82</cell><cell>83.42 ± 2.29</cell></row><row><cell>TMF (VGG16-MLP)</cell><cell cols="3">95.50 ± 0.50 95.84 ± 0.42 88.43 ± 0.39</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE IV COMPARISON</head><label>IV</label><figDesc>OF PERFORMANCES OF THREE FEATURE EXTRACTORS, VGG16, VGG19 AND RESNET50, AND THREE CLASSIFIERS, MLP, LR AND RF.</figDesc><table><row><cell>Model</cell><cell>ROC-AUC</cell><cell>PR-AUC</cell><cell>F1</cell></row><row><cell>VGG16-MLP</cell><cell cols="3">95.50 ± 0.50 95.84 ± 0.42 88.43 ± 0.39</cell></row><row><cell>VGG16-LR</cell><cell>95.49 ± 0.00</cell><cell>95.64 ± 0.00</cell><cell>87.24 ± 0.00</cell></row><row><cell>VGG16-RF</cell><cell>93.72 ± 0.00</cell><cell>94.33 ± 0.00</cell><cell>83.07 ± 0.00</cell></row><row><cell>VGG19-MLP</cell><cell>95.21 ± 0.31</cell><cell>95.38 ± 0.31</cell><cell>87.57 ± 0.55</cell></row><row><cell>VGG19-LR</cell><cell>94.67 ± 0.00</cell><cell>94.68 ± 0.00</cell><cell>87.74 ± 0.00</cell></row><row><cell>VGG19-RF</cell><cell>92.50 ± 0.00</cell><cell>93.07 ± 0.00</cell><cell>80.56 ± 0.00</cell></row><row><cell>ResNet50-MLP</cell><cell>93.85 ± 0.31</cell><cell>93.92 ± 0.46</cell><cell>86.37 ± 0.71</cell></row><row><cell>ResNet50-LR</cell><cell>94.40 ± 0.00</cell><cell>94.33 ± 0.00</cell><cell>86.74 ± 0.00</cell></row><row><cell>ResNet50-RF</cell><cell>89.35 ± 0.00</cell><cell>90.51 ± 0.00</cell><cell>78.04 ± 0.00</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE V THE</head><label>V</label><figDesc>NUMBER OF PATIENTS IN THE TOTALLY INCORRECT (TI) AND TOTALLY CORRECT (TC) GROUPS.</figDesc><table><row><cell>Model</cell><cell cols="2">TI TC</cell></row><row><cell>TMF (VGG16-MLP)</cell><cell>1</cell><cell>90</cell></row><row><cell>MINA</cell><cell>7</cell><cell>46</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deep learning for time series classification: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Fawaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Min. Knowl. Discov</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="917" to="963" />
			<date type="published" when="2019-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Anomaly detection: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Chandola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2009-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A survey on various machine learning approaches for ECG analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Roopa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Harish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Applications</title>
		<imprint>
			<biblScope unit="volume">163</biblScope>
			<biblScope unit="page" from="25" to="33" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Automatic detection of atrial fibrillation using the coefficient of variation and density histograms of RR and deltaRR intervals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tateno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Glass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical &amp; biological engineering &amp; computing</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="664" to="71" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Detection of atrial fibrillation in ECG hand-held devices using a random forest classifier</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zabihi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing in Cardiology (CinC)</title>
		<imprint>
			<biblScope unit="page" from="1" to="4" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Real-Time Patient-Specific ECG Classification by 1-D Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kiranyaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ince</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gabbouj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="664" to="675" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Interpretability Analysis of Heartbeat Classification Based on Heartbeat Activity&apos;s Global Sequence Features and BiLSTM-Attention Neural Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="109870" to="109883" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Convolutional recurrent neural networks for electrocardiogram classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zihlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Perekrestenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tschannen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing in Cardiology (CinC)</title>
		<imprint>
			<biblScope unit="page" from="1" to="4" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">MINA: Multilevel Knowledge-Guided Attention for Modeling Electrocardiography Signals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-19</title>
		<meeting>the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-19</meeting>
		<imprint>
			<date type="published" when="2019-07" />
			<biblScope unit="page" from="5888" to="5894" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Imaging Time-Series to Improve Classification and Imputation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Oates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on Artificial Intelligence, IJCAI&apos;15</title>
		<meeting>the 24th International Conference on Artificial Intelligence, IJCAI&apos;15</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3939" to="3945" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Classification of time-series images using deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Debayle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Hatami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gavet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Tenth International Conference on Machine Vision</title>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04" />
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Permutation Entropy: A Natural Complexity Measure for Time Series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Pompe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review Letters</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">17</biblScope>
			<biblScope unit="page">174102</biblScope>
			<date type="published" when="2002-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Characterization of chaotic maps using the permutation Bandt-Pompe probability distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">A</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The European Physical Journal B</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Forbidden patterns, permutation entropy and stock market inefficiency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zunino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Physica A: Statistical Mechanics and its Applications</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">388</biblScope>
			<biblScope unit="page" from="2854" to="2864" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Application of the Permutation Entropy over the Heart Rate Variability for the Improvement of Electrocardiogrambased Sleep Breathing Pause Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ravelo-Garcia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Entropy</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="914" to="927" />
			<date type="published" when="2015-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Time series classification based on triadic time series motifs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.00110</idno>
		<imprint>
			<date type="published" when="2019-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Probabilistic Discovery of Time Series Motifs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lonardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="493" to="498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Discovery of Time-Series Motif from MultiDimensional Data Based on MDL Principle</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Iwamoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Uehara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning -ML</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="269" to="300" />
			<date type="published" when="2005-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Mining Approximate Motifs in Time Series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">G</forename><surname>Ferreira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Conference on Discovery Science, DS&apos;06</title>
		<meeting>the 9th International Conference on Discovery Science, DS&apos;06<address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="89" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A Survey on Transfer Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1345" to="1359" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">How transferable are features in deep neural networks?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yosinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="3320" to="3328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Very Deep Convolutional Networks for Large-Scale Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Deep Residual Learning for Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016-06" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">PhysioBank, PhysioToolkit, and PhysioNet: components of a new research resource for complex physiologic signals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Goldberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Circulation</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="215" to="235" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">AF Classification from a Short Single Lead ECG Recording: the PhysioNet/Computing in Cardiology Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Clifford</surname></persName>
		</author>
		<idno type="DOI">10.22489/CinC.2017.065-469</idno>
	</analytic>
	<monogr>
		<title level="j">Computing in cardiology</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the 3rd International Conference for Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine Learning in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Viualizing data using t-SNE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Grad-CAM: Visual Explanations From Deep Networks via Gradient-Based Localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Selvaraju</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017-10" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
