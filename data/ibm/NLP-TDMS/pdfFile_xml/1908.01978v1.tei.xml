<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multi-view Deep Subspace Clustering Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Zhu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binyuan</forename><surname>Hui</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changqing</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawei</forename><surname>Du</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Longyin</forename><surname>Wen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinghua</forename><surname>Hu</surname></persName>
						</author>
						<title level="a" type="main">Multi-view Deep Subspace Clustering Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>SUBMISSION TO IEEE TRANSACTIONS ON IMAGE PROCESSING, 2019 1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-subspace clustering</term>
					<term>multi-view learning</term>
					<term>self- representation</term>
					<term>deep clustering</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Multi-view subspace clustering aims to discover the inherent structure by fusing multi-view complementary information. Most existing methods first extract multiple types of hand-crafted features and then learn a joint affinity matrix for clustering. The disadvantage lies in two aspects: 1) Multi-view relations are not embedded into feature learning. 2) The endto-end learning manner of deep learning is not well used in multi-view clustering. To address the above issues, we propose a novel multi-view deep subspace clustering network (MvDSCN) by learning a multi-view self-representation matrix in an endto-end manner. MvDSCN consists of two sub-networks, i.e., diversity network (Dnet) and universality network (Unet). A latent space is built upon deep convolutional auto-encoders and a self-representation matrix is learned in the latent space using a fully connected layer. Dnet learns view-specific self-representation matrices while Unet learns a common self-representation matrix for all views. To exploit the complementarity of multi-view representations, Hilbert Schmidt Independence Criterion (HSIC) is introduced as a diversity regularization, which can capture the non-linear and high-order inter-view relations. As different views share the same label space, the self-representation matrices of each view are aligned to the common one by a universality regularization. Experiments on both multi-feature and multimodality learning validate the superiority of the proposed multiview subspace clustering model.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Subspace clustering aims to segment a set of unlabeled samples drawn from a union of multiple subspaces corresponding to different clusters into several groups. Recently, self-representation based models have achieved superior performance in subspace clustering <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>. It assumes that a sample can be represented by a linear combination of a set of samples:</p><formula xml:id="formula_0">min Z L(X, Z) + R(Z), s.t. X = XZ,<label>(1)</label></formula><p>where X ∈ R d×n and Z ∈ R n×n denote the training data and self-representation matrix, respectively. L(X, Z) represents the reconstruction loss and R(Z) is the regularization item.</p><p>The key differences of self-representation based subspace clustering models lie in the option of the loss function and regularizer. For R(Z), l 0 -norm, l 1 -norm, square of Frobenius norm, elastic net, trace Lasso, and k-block diagonal regularizer have been used under certain subspace assumptions <ref type="bibr" target="#b3">[4]</ref>. As hand-crafted features cannot well capture the severe variations, <ref type="figure">Fig. 1</ref>: Examples of multi-view learning. A sample can be represented by different modalities, e.g., image, video and text. Different kinds of features, e.g., SIFT, Gabor, and deep features can be extracted. Generally, multi-view learning covers multi-modal and multi-feature learning.</p><p>deep subspace clustering models are developed to jointly learn hierarchical representation and cluster structure <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>. The rapid growth of digital sensors and widespread application of social networks bring about the explosion of multimodal data in multimedia analysis <ref type="bibr" target="#b13">[14]</ref>, medical image analysis <ref type="bibr" target="#b14">[15]</ref>, autonomous driving <ref type="bibr" target="#b15">[16]</ref>, etc. As shown in <ref type="figure">Figure 1</ref>, different types of data can be collected, including text, image, audio and video, to represent a sample. Even for single-modal data, e.g., images or video sequences, diverse features can be extracted to capture scale, occlusion, illumination, rotation variations for robust recognition <ref type="bibr" target="#b16">[17]</ref>. Generally, multi-view learning covers multi-modal and multi-feature learning. Multimodal and multi-feature information can be fused to boost the performance of subspace clustering.</p><p>Multi-view subspace clustering (MVSC) aims to utilize data collected from different modalities or represented by different types of features to discover the underlying clustering structure. Most MVSC methods design multi-view regularizer to characterize the inter-view relationships between several types of hand-crafted features for multi-view clustering <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b22">[23]</ref>. However, their performances are still not satisfactory for two reasons. Firstly, existing methods adopt a two-stage strategy, i.e., first extracting features and then learning the affinity matrix. The features extraction process is irrelevant to the subspace clustering task. Multi-view relationships can only work during the affinity matrix learning process, which ignores the role of inter-view relations in feature learning. Secondly, they consider little about hierarchical representation learning in an end-to-end manner.</p><p>In this paper, we propose a multi-view deep subspace arXiv:1908.01978v1 [cs.CV] 6 Aug 2019 clustering networks (MvDSCN) by learning a multi-view selfrepresentation matrix in an end-to-end manner. MvDSCN is composed of diversity network (Dnet) and universality network (Unet). Dnet learns view-specific self-representation matrices (Z 1 , Z 2 , ..., Z v ) while Unet learns a common selfrepresentation matrix Z. Deep convolutional auto-encoders are learned for each view with either handcrafted features or raw data as the input. Multi-view reconstruction and selfrepresentation losses are simultaneously minimized. To exploit the complementary multi-view information, a diversity regularizer is defined based on Hilbert Schmidt Independence Criterion (HSIC). Additionally, we used a universality regularizer to make view-specific Z i close to the common Z. With diversity and universality regularization, multi-view relations are well embedded in both feature learning and self-representation stages. Experiments on both multi-feature and multi-modal clustering validate the superiority of the proposed model to the state-of-the-art subspace clustering methods. The structure of this paper is organized as: Section II introduces the related work on multi-view learning, selfrepresentation and auto-encoders. Section III presents the proposed multi-view clustering model. Section IV conducts experiments on both multi-feature and multi-modal tasks. Section V concludes and gives the future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>In this section, we give a brief review of multi-view clustering, self-representation, and auto-encoders.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Multi-view Clustering</head><p>Subspace clustering aims to uncover the inherent cluster structure from data composed of multiple subspaces <ref type="bibr" target="#b2">[3]</ref>. In the past few years, most existing subspace clustering methods focus on learning a good affinity matrix and then conduct spectral clustering. Self-representation based subspace clustering methods are essentially based on the hypothesis that a sample can be reconstructed by a linear combination of other samples. Sparse subspace clustering (SSC) imposes l 1 -norm regularization on the representation coefficients to enhance the sparsity <ref type="bibr" target="#b23">[24]</ref>. Low rank representation (LRR) explores the multi-block diagonal property of the self-representation matrix to discover the multiple subspace structure <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b3">[4]</ref>. Deep subspace clustering network embeds self-representation into deep convolutional autoencoder by a fully connected layer <ref type="bibr" target="#b1">[2]</ref>. To conduct clustering in an end-to-end manner, clustering loss is proposed to output the clustering results directly <ref type="bibr" target="#b7">[8]</ref>. Deep adversarial subspace clustering uses GAN-like model to evaluate the clustering performance besides self-representation loss <ref type="bibr" target="#b2">[3]</ref>.</p><p>Multi-view clustering boosts the performance of clustering by exploring the complementary information by modeling inter-view relations or learning a latent representation. Most existing multi-view clustering methods can be considered as an extension of single-view models, including spectral clustering <ref type="bibr" target="#b19">[20]</ref>, matrix factorization <ref type="bibr" target="#b16">[17]</ref>, and k-means <ref type="bibr" target="#b21">[22]</ref>, etc. Multiview relations can be generally categorized into universality and diversity <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b20">[21]</ref>. Universality emphasizes on that all views should be similar while diversity focuses on the inter-view complementarity and therefore induces diverse view-specific representation. Some work build multi-view connections by a common latent representation for clustering and model multi-view relations using neural networks <ref type="bibr" target="#b24">[25]</ref>. Deep learning has achieved superior performance in many tasks because of the end to end learning manner to a great extent. However, the existing multi-view subspace clustering methods treat multi-view feature extraction and affinity learning as two separate stages. Additionally, due to the view-specific characteristic, it is unreasonable to force the self-representation matrices of all views to be the same.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Self-representation</head><p>Self-representation reflects the intra-relations among samples, and has been widely used in image processing, clustering, feature selection, and deep learning. In image processing, especially image denoising, non-local mean has been widely used by reconstructed a pixel or image patch using related pixels or patches in the image <ref type="bibr" target="#b25">[26]</ref>, which inspires many successful image processing models in low-level vision. Besides pixellevel self-representation, a sample can be well reconstructed by a linear combination of bases. Self-representation has been successfully used in clustering in that it can accurately capture the sample relations by embedding sparse, dense, or lowrank priors <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b3">[4]</ref>. To alleviate the curse of dimensionality, feature selection aims to select a subset of features by evaluating the importance of features. Feature-level selfrepresentation assumes that one feature can be reconstructed by all features, and the self-representation coefficients can be used for feature evaluation <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b28">[29]</ref>. Inspired by the success of non-local mean in image denoising, a nonlocal neural network is proposed to utilize the relations across elements of feature maps, channels, or frames to improve the representation ability of the networks <ref type="bibr" target="#b29">[30]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Auto-Encoders</head><p>Auto-encoders (AE) extract features of data by mapping the data to a low-dimensional space. With the rapid development of deep learning, deep (or stacked) auto-encoders have become popular for unsupervised learning. Deep autoencoders have been widely used in dimensionality reduction <ref type="bibr" target="#b30">[31]</ref> and image denoising <ref type="bibr" target="#b31">[32]</ref>. Recently, deep auto-encoders have been used to initialize deep embedding networks for unsupervised clustering <ref type="bibr" target="#b32">[33]</ref>. The work in <ref type="bibr" target="#b33">[34]</ref> uses a fully connected deep auto-encoders by incorporating a sparsity prior into the hidden representation learning to preserve the sparse reconstruction relation. By comparison, <ref type="bibr" target="#b1">[2]</ref> directly learn the affinities between all data points through a deep auto-encoder network by using a fully connected self-representation layer.</p><p>Since convolutional layers have fewer parameters and stronger learning ability than the fully connected layer, convolutional auto-encoders(CAE) that can be trained in an end to end manner are designed for feature learning from unlabeled data. The work in <ref type="bibr" target="#b34">[35]</ref> is the first trial to train CAE directly in an end to end manner without pre-training. Convolutional neural networks can be initialized by a CAE stack <ref type="bibr" target="#b35">[36]</ref> which  is an unsupervised method for hierarchical feature extraction. CAE have been successfully used for generative adversarial networks (GANs). <ref type="bibr" target="#b36">[37]</ref> combines a convolutional auto-encoder loss, a GAN loss, and a classification loss defined using a pretrained classifier. In the field of natural language processing, <ref type="bibr" target="#b37">[38]</ref> proposed a general framework for text modeling by embedding a paragraph into a latent representation vector using CAE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-Modal Data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. MULTI-VIEW DEEP SUBSPACE CLUSTERING</head><p>In this section we present the proposed multi-view deep subspace clustering networks (MvDSCN).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Network Architecture</head><p>Let X 1 , ..., X i , ..., X v denote the inputs of multiple views, where X i ∈ R n×di , v, n and d i are the number of views, samples, and features in the i th view, respectively. X i can be hand-crafted features or raw data, such as image and RGB-D data. The architecture of multi-view deep subspace clustering is shown in <ref type="figure" target="#fig_0">Figure 2</ref>. The proposed network consists of two parts, i.e., diversity net (Dnet) that learns view-specific representation and universality net (Unet) that shares viewconsistent self-representation matrix.</p><p>Dnet embeds the input X i into the hidden representation F s i by the view-specific encoder for the i th view. Then self-representation is conducted by a fully connected layer without bias and non-linear activations, i.e., F s i =F s i Z i . Unet uses a common self-representation matrix Z for all views, which is connected with hidden representation F c 1 , F c 2 , ..., F c v of all views. After self-representation layer, the samples are recovered by the view-specific decoders.</p><p>For both Dnet and Unet, we advocate the usage of convolutional auto-encoders with fewer parameters and stronger learning ability rather than the fully connected layer. We use three-layer encoders with [64, 32, 16] channels, and threelayer decoders with <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr">64</ref>] channels correspondingly. We adopt a 3 × 3 kernel and rectified linear unit(ReLU) <ref type="bibr" target="#b38">[39]</ref> for the non-linear activations. Notably, no pooling layers are used. The latent features are then back to the space of the same size as the input via the transpose convolution layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Loss Function</head><p>The losses of the proposed MvDSCN consists of two parts, i.e., reconstruction loss by auto-encoders and self- min</p><formula xml:id="formula_1">       v i=1 X i −X s i 2 F + X i −X c i 2 F + v i=1 F s i − F s i Z i 2 F + F c i − F c i Z 2 F       <label>(2)</label></formula><p>To embed multi-view relations into feature learning and selfrepresentation, two types of regularizer are used. To exploit the complementary information from multiple views, e.g., RGB and depth information, a diversity regularization is defined based on Hilbert Schmidt Independence Criterion (HSIC). HSIC measures the nonlinear and high-order correlations and has been successfully used in multi-view subspace clustering.</p><p>Assuming that there are two variables A = [a 1 , ..., a i , ..., a N ] and B = [b 1 , ..., b i , ..., b N ], we define a mapping φ(a) from a ∈ A to kernel space F, where the inner product of two vectors is defined as</p><formula xml:id="formula_2">k(a 1 , a 2 ) = φ(a 1 ), φ(a 2 ) . Then ϕ(b) is defined to map b ∈ B to kernel space G. Similarly, the inner product of two vectors in G is defined as g(b 1 , b 2 ) = φ(b 1 ), φ(b 2 )</formula><p>. The empirical version of HSIC is induced as:</p><formula xml:id="formula_3">Definition 1: Consider a series of N independent obser- vations drawn from p ab , Z := {(a 1 , b 1 ), ..., (a N , b N )} ⊆ A × B</formula><p>, an estimator of HSIC, written as HSIC(Z, F, G), is given by:</p><formula xml:id="formula_4">HSIC(Z, F, G) = (N − 1) −2 tr(G 1 HG 2 H),<label>(3)</label></formula><p>where tr(·) is the trace of a square matrix. G 1 and G 2 are the Gram matrices with g 1,ij = g 1 (a i , a j ), g 2,ij = g 2 (b i , b j ). h ij = δ ij −1/N centers the Gram matrix which has zero mean in the feature space. Please refer to <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b40">[41]</ref> for more details about HSIC. Based on HSIC, the diversity regularizer is defined as</p><formula xml:id="formula_5">R d (Z 1 , Z 2 , ..., Z v ) = ij HSIC(Z i , Z j )<label>(4)</label></formula><p>The diversity regularizer in Eq. <ref type="formula" target="#formula_5">(4)</ref> can effectively exploit the complementary information from multiple views. As all views share the same decision space, the view-specific selfrepresentation matrices that reflect sample relations should be aligned with the common self-representation matrix in Unet.</p><p>We define a centralization regularizer as follows</p><formula xml:id="formula_6">R c (Z, Z 1 , Z 2 , ..., Z v ) = v i=1 Z − Z i 2 F<label>(5)</label></formula><p>By taking multi-view relations into account, the objective function becomes</p><formula xml:id="formula_7">min                                                                  v i=1 X i −X s i 2 F + X i −X c i 2 F auto-encoder loss +λ 1 v i=1 F s i − F s i Z i 2 F + F c i − F c i Z 2 F self-representation loss +λ 2 Z p + v i=1 Z i p lp -norm regularizer +λ 3 v i=1 Z − Z i 2 F universality regularizer +λ 4 ij HSIC(Z i , Z j ) diversity regularizer                                                                  s.t. diag(Z i ) =0, i = 1, 2, ..., v, diag(Z) =0 ,<label>(6)</label></formula><p>where λ 1 , λ 2 , λ 3 and λ 4 are positive constants, and Z p is l p -norm on Z. Here we can also consider other types of regularizer, e.g., nuclear norm <ref type="bibr" target="#b0">[1]</ref>, and block diagonal regularizer <ref type="bibr" target="#b41">[42]</ref>. <ref type="figure" target="#fig_1">Figure 3</ref> shows the affinity matrix of each view learned independently by deep subspace clustering network in <ref type="bibr" target="#b1">[2]</ref> and the one learned by our proposed MvDSCN on multiview data. The affinity matrix learned by MvDSCN has better block diagonal property and less noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Optimization</head><p>We use a gradient decent method to solve the problem in Eq. <ref type="bibr" target="#b5">(6)</ref>. For the back propagation (BP) process, the gradients should be derived for each variable. The encoders and decoders can be updated by standard BP. Here we focus on the updating of self-representation layer. As the optimization problems in Eq. (6) with respect to the view-specific self-representation matrices Z 1 , Z 2 , ..., Z v and view-consistent Z are convex, we can get the gradients easily.</p><p>When we use square of Frobenius norm regularization, the gradient for Z i is</p><formula xml:id="formula_8">∂L Zi ∂Z i = 2λ 1 F s i T F s i (Z i − I) − 2λ 3 (Z − Z i ) + 2λ 2 Z + λ 4 (N − 1) −2 j&gt;i (HZ j H) T<label>(7)</label></formula><p>The gradient for Z is  <ref type="formula" target="#formula_8">7)</ref> and <ref type="formula">(8)</ref>;</p><formula xml:id="formula_9">∂L Z ∂Z = 2λ 1 v i=1 F c i T F c i (Z − I) + 2λ 2 Z + 2λ 3 (Z − Z i ) (8)</formula><p>Perform spectral clustering using affinity matrix Z; Output: Clustering result C .</p><p>We first pre-train the deep auto-encoder without the selfrepresentation layer on all multi-view data because the network is difficult to directly train from scratch and avoid the trivial all-zero solution while minimizing the loss function. We then use the pre-trained parameters to initialize the convolutional encoder-decoder layers of both Dnet and Unet. In the finetuning stage, we build a big batch using all the data to minimize the loss function. The model is trained with Adam <ref type="bibr" target="#b42">[43]</ref> and an initial learning rate of 0.001. For the regularization hyper-parameters of self-representation loss and l p -norm regularizer, we usually set λ 1 = 1.0 × 10 k 10 −3 where the k is the number of subspaces, λ 2 = 1.0, λ 3 = 0.1, λ 4 = 0.1.</p><p>Our network jointly updates Dnet and Unet. Once the network converges, we can use the parameters of the common self-expressive layer for all views to construct an affinity matrix |Z| + |Z| T /2 for spectral clustering. Similar to <ref type="bibr" target="#b1">[2]</ref>, since we have no access to labels, our training strategy is unsupervised. Besides, the algorithm for solving MvDSCN is summarized in Alg. 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Discussions</head><p>Recent works on multi-view subspace clustering focus on learning a latent representation across views by dictionary learning or matrix factorization <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b16">[17]</ref>. As shown in Eq. (9), a latent representation C is learned for X and then self-representation is conducted on C. All views can share the same latent representation <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b24">[25]</ref> but view-specific D.</p><formula xml:id="formula_10">min {C,D,Z} X − CD 2 F + C − CZ 2 F<label>(9)</label></formula><p>Compared with latent representation based methods, the proposed MvDSCN also learns a hidden representation F by autoencoder φ. Auto-encoder can be considered as a mapping function which projects the input to a latent space. MvD-SCN has the following two advantages: 1) Compared with the existing shallow models, the hidden representation F is more informative by using deep convolutional auto-encoders whether the input X is hand-crafted feature or the raw data. 2) MvDSCN joints feature learning and self-representation together in an end to end manner. Thus, the multi-view relations can guide both affinity matrix learning and feature learning. Hence, our proposed MvDSCN can learn a good affinity matrix and therefore boost the performance of multiview subspace clustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS</head><p>In this section, extensive experiments are conducted to verify the effectiveness of the proposed clustering model. Beyond multi-feature subspace clustering, MvDSCN can be easily extended to multi-modal learning by replacing the input with data with different modalities. We evaluate the proposed deep multi-view subspace clustering methods on real-world RGB-D Object Dataset <ref type="bibr" target="#b43">[44]</ref>. It contains visual and depth images of 300 physically distinct objects taken from multiple views and the objects are organized into 51 categories arranged by WordNet hypernym-hyponym relationships (similar to Ima-geNet). Our experiment datasets is composed of 50 categories randomly selected from RGB-D Object Dataset with each class containing 10 examples. All visual images and depth images are resized to 64×64 pixels. We apply median filter recursively until all missing values are filled to visualize. A subset of RGB and depth images are shown in <ref type="figure" target="#fig_2">Figure 4</ref>.</p><p>Comparison methods. The performance of MvDSCN is compared with the state-of-the-art subspace clustering methods in term of four evaluation metrics. There are six shallow and deep single-view clustering algorithms, and five multiview clustering algorithms. For all single-view clustering algorithms, the performance of the best view is reported.</p><p>• BestSV reports the result of the individual view which achieves the best spectral clustering performance with a single view of data <ref type="bibr" target="#b44">[45]</ref>. • LRR seeks the lowest-rank representation among all the candidates that can represent the data samples as linear combinations of the bases in a given dictionary with the best single view <ref type="bibr" target="#b0">[1]</ref>. • RMSC has a flavor of low-rank and sparse decomposition <ref type="bibr" target="#b45">[46]</ref>. It firstly construct a transition probability matrix from each single view, and then uses these matrices to recover a shared low-rank transition probability matrix as a crucial input to the standard Markov chain method for clustering. • DSCN is a deep auto-encoder framework for subspace clustering with a best single view. <ref type="bibr" target="#b33">[34]</ref> • DCSC imposes a self-paced regularizer on the loss and presents a robust deep subspace clustering algorithm <ref type="bibr" target="#b6">[7]</ref>. • DC proposes a scalable clustering approach for the unsupervised learning of convnets. It iterates between clustering with k-means and updating its weights by predicting the cluster assignments as pseudo-labels in a discriminative loss <ref type="bibr" target="#b46">[47]</ref>.</p><p>• Min-Disagreement creates a bipartite graph and is based on the minimizing-disagreement idea <ref type="bibr" target="#b47">[48]</ref>. • Co-Reg SPC uses spectral clustering objective functions that implicitly combine graphs from multiple views of the data to achieve a better clustering result <ref type="bibr" target="#b48">[49]</ref>. • DMF learns the hierarchical semantics of multi-view data through the semi-nonnegative matrix factorization <ref type="bibr" target="#b16">[17]</ref>. • LMSC seeks the underlying latent representation and simultaneously performs data reconstruction based on the learned latent representation <ref type="bibr" target="#b20">[21]</ref>. • MSCN observes that spatial fusion methods in a deep multimodal subspace clustering task relay on spatial correspondences among the modalities <ref type="bibr" target="#b49">[50]</ref>.</p><p>Evaluation Metrics. Following the experiment setting in <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b20">[21]</ref>, four popular metrics are used to evaluate the cluster-ing quality, including NMI (Normalized Mutual Information), ACC (Accuracy), F-Measure, and AR (Adjusted Rand Index) which can comprehensively evaluate the performance.</p><p>The NMI calculates the normalized measure of similarity between two labels of the same data as follows:</p><formula xml:id="formula_11">N M I = I(l; c) max{H(l), H(c)} ,<label>(10)</label></formula><p>where I(l; c) denotes the mutual information between l and c, and H represents their entropy. Result of NMI do not change by permutations of clusters (classes), and they are normalized to the range of [0, 1], with 0 meaning no correlation and 1 exhibiting perfect correlation.</p><p>The ACC score is caculated as:</p><formula xml:id="formula_12">ACC = max m n i=1 {l i = m (c i )} n ,<label>(11)</label></formula><p>where l i is the ground-truth label, c i is the cluster assignment produced by the model. m(c i ) is the permutation map function, which maps the cluster labels into class labels. n is the number of samples. The best map can be obtained by the Kuhn-Munkres algorithm. The F-measure can be interpreted as a weighted average of the precision and recall, where an F-measure reaches its best value at 1 and worst score at 0. The relative contribution of precision and recall to the F-measure are equal. Its formulation is:</p><formula xml:id="formula_13">F measure = recall −1 + precision −1 2 −1<label>(12)</label></formula><p>The adjusted rand index is the corrected-for-chance version of the rand index <ref type="bibr" target="#b50">[51]</ref>.</p><p>Note that lower values indicate better performance for average entropy, and higher values indicate better performance for the other metrics. We optimize all the parameters to achieve the best performance of the comparison method. Especially, we run each method 30 times and report the average performance and standard deviation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Results of Multi-feature Subspace Clustering</head><p>The multi-view clustering performance of different methods is given in <ref type="table" target="#tab_2">Table I</ref>. Our proposed method significantly outperforms other methods on Yale, ORL and Still DB datasets, and shows very competitive performance on BBCSport dataset. For Yale, we raise the performance bar by around 7.9% in ACC, 4.7% in AR, 4.9% in F-measure. In addition, for ORL, we raise the performance bar by around 4.7% in ACC, 3.6% in AR, 6.1% in F-measure. On StillDB our method gains significant improvements around 9.1%, 3.7%, 4.5%, 5.5%, over the second best method in terms of NMI, ACC, AR, F-measure, respectively. For BBCSport, the performance of the proposed method is better than DMF in terms of three evaluation metrics. This demonstrates the effectiveness of the proposed MvDSCN on multi-feature subspace clustering task. The performance improvement owns to two aspects, i.e., the end to end manner in learning the affinity matrix, and multiview relations embedded into both feature learning and selfrepresentation. Still DB View1 0.113 ± 0.001 0.329 ± 0.004 0.083 ± 0.003 0.243 ± 0.014 View2 0.216 ± 0.011 0.323 ± 0.006 0.145 ± 0.002 0.293 ± 0.019 View3 0.211 ± 0.002 0.313 ± 0.012 0.142 ± 0.014 0.289 ± 0.007 ALL 0.245 ± 0.020 0.377 ± 0.023 0.169 ± 0.003 0.320 ± 0.015 BBCSport View1 0.617 ± 0.000 0.801 ± 0.000 0.847 ± 0.001 0.559 ± 0.000 View2 0.652 ± 0.000 0.821 ± 0.000 0.856 ± 0.001 0.683 ± 0.001 ALL 0.835 ± 0.000 0.931 ± 0.001 0.909 ± 0.001 0.860 ± 0.000   Single View versus Multiple Views. To further investigate the improvement of our method, we compare ours method with deep subspace clustering networks (DSCN) <ref type="bibr" target="#b1">[2]</ref> with only single-view data. <ref type="figure">Figure 6</ref> shows the detailed results on different datasets. According to <ref type="table" target="#tab_2">Table II</ref>, the clustering performance with multiple views consistently outperform that of each single view, which empirically proves that clustering with multiple views is more robust than that with single view.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Results of Multi-modal Subspace Clustering</head><p>For multi-modal experiments, we use the pre-trained deep auto-encoders to extract features for the comparison shallow methods. There are 4, 096 features for both RGB image and depth image. The experimental results on the RGB-D dataset are presented in <ref type="table" target="#tab_2">Table III</ref>. Our method outperforms all the other competitors. We raise the performance bar by around 3.4% in NMI, 5.3% in ACC, 4.8% in AR, 5.8% in F-measure compared with the second best method. Compared with the shallow models that first extract deep features and then conduct subspace clustering, our proposed MvDSCN joints feature learning and subspace clustering together and multi-view relations affect on both parts. Hence, MvDSCN outperforms the state-of-the-art subspace clustering algorithms.</p><p>Single Modal versus Multiple Modal. As shown in <ref type="table" target="#tab_2">Table  IV</ref>, our methods significantly outperform subspace clustering with only single modal data, which further demonstrates the superiority of multi-modal fusion. Overall, the RGB modality achieve better performance than Depth modality. We improve the clustering performance by 5.0% in NMI, 4.9% in ACC, 4.7% in AR and 4.6% in F-measure when we fuse them by MvDSCN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Convergence Analysis</head><p>To empirically analyze the convergence of MvDSCN, in <ref type="figure" target="#fig_5">Figure 7</ref>, we show the relationship between the loss of the   MvDSCN and the clustering performance on the ORL dataset.</p><p>The reported values in this figure are normalized between zero and one. As can be seen from the figure, the loss decreases rapidly in a few epoches. The clustering performance increases significantly in the first few epoches and then grows slowly. Similar results can be observed on other datasets. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Parameter Sensitivity</head><p>To analyze the impact the parameters on the clustering performance of MvDSCN, we plot the performance of MvD-SCN with different parameters in <ref type="figure" target="#fig_4">Figure 5</ref>. There are four parameters, i.e., λ 1 , λ 2 , λ 3 , and λ 4 . λ 1 seeks the balance between self-representation loss and reconstruction loss of autoencoders. λ 2 reflects the impact of the l p -norm regularization. λ 3 controls the degree of the universality regularizer, while λ 4 controls the degree of the diversity regularizer. We fix the other three parameters and analyze the impact of the rest parameter. The results show that the clustering performance grows with the value of λ 1 and varies little when λ 1 is above 10. For lambda 1 , the best performance is achieved across different datasets when λ 1 is set as 1. Similarly, we can observe that when λ 3 and λ 4 are set as 0.1, our proposed MvDSCN achieves superior performance. For all datasets, we fix the values of four parameters as 10, 1, 0.1, 0.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Ablation Study</head><p>To verify the effectiveness of diversity and universality regularization, we conduct the ablation study with respect to the proposed model. D-MvDSCN represents the proposed model without diversity regularization while U-MvDSCN refers to the one without universality regularization. Note that U-MvDSCN can be considered as the case when only the Unet part is kept. As presented in <ref type="table" target="#tab_6">Table V</ref>, MvDSCN substantially outperforms D-MvDSCN, which numerically indicates that we cannot ignore diversity regularization that can enhance multi-view complementary information. Besides, our proposed method performs better than U-MvDSCN. Universality regularization forces the view-specific representation to be centralized to the common representation. We conduct a sensitivity test for the ragularizer parameter of diversity (λ 3 ) and universality (λ 4 ) by varying from 0.001 to 1. <ref type="figure" target="#fig_6">Figure  8</ref> shows the influence of different parameter values with respect to NMI on RGB-D dataset. Moreover, our method performs much stable when λ 3 and λ 4 becomes larger. In sum, both diversity and universality regularization contribute to the enhancement of the proposed model in terms of multi-view clustering performance. V. CONCLUSIONS</p><p>In this paper, we proposed a new multi-view deep subspace clustering network (MvDSCN). The proposed method learns multi-view self-representation in an end-to-end manner by combining convolutional auto-encoder and self-representation together. It consists of diversity net (Dnet) and universality net (Unet), which are connected by diversity and universality regularizer. Experiments on both multi-feature and multimodal tasks validate the superiority of our method compared with the state-of-the-arts.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 :</head><label>2</label><figDesc>The network architecture of multi-view deep subspace clustering</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 :</head><label>3</label><figDesc>Visualization of affinity matrices of different views. The first three columns are affinity matrices of view1, view2, view3 learned by DSCN [2]. The last column is the proposed MvDSCN obtained all views. The top row is the result on Yale dataset, and the bottom row is the result on ORL dataset. representation loss.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 :</head><label>4</label><figDesc>Sample objects from the RGB-D Object Dataset. RGB image (left) and the corresponding depth image using a recursive median filter(right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 :</head><label>5</label><figDesc>The effect of different parameters on MvDSCN learning.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 :</head><label>7</label><figDesc>The loss, and clustering performance (NMI and ACC) of MvDSCN with training epoches.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 8 :</head><label>8</label><figDesc>Sensitivity test on λ3 and λ4 versus NMI on RGB-D.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Self-representation Layer View 1 View 2 View n Encoder Encoder Encoder Decoder Decoder Decoder Encoder Decoder Diversity Net Universality Net A dog is running in an open field. A man sings with a guitar.</head><label></label><figDesc></figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE I :</head><label>I</label><figDesc>Results on four multi-feature datasets (mean ± standard deviation). Higher value indicates better performance. Yale is a widely used face dataset which contains 165 gray scale images, which are composed of 15 individuals with 11 images per person. Variations of the data include center light, with glasses, happy, left light, without glasses, normal, right light, sad, sleepy, surprised and wink. The standard LBP features are then extracted from the 72 × 80 loosely cropped image with a histogram size of 59 over 910 pixels. The Gabor feature is dominated by four directions θ = 0 • , 45 • , 90 • , 135 • and extracted at a scale of λ = 4. It has a resolution of 25 × 30 pixels and a loose face cropping. Note that all descriptors except intensity are scaled to have a unit norm. Still DB consists of 467 images with 6 classes of actions. sift bow, color sift bow and shape context bow are extracted.</figDesc><table><row><cell>Datasets</cell><cell>Methods</cell><cell>NMI</cell><cell>ACC</cell><cell>AR</cell><cell>F-measure</cell></row><row><cell></cell><cell>BestSV</cell><cell>0.654 ± 0.009</cell><cell>0.616 ± 0.030</cell><cell>0.440 ± 0.011</cell><cell>0.475 ± 0.011</cell></row><row><cell></cell><cell>LRR</cell><cell>0.709 ± 0.011</cell><cell>0.697 ± 0.000</cell><cell>0.515 ± 0.004</cell><cell>0.547 ± 0.007</cell></row><row><cell></cell><cell>Min-Disagreement</cell><cell>0.645 ± 0.005</cell><cell>0.615 ± 0.043</cell><cell>0.433 ± 0.006</cell><cell>0.470 ± 0.006</cell></row><row><cell></cell><cell>Co-Reg</cell><cell>0.648 ± 0.002</cell><cell>0.564 ± 0.000</cell><cell>0.436 ± 0.002</cell><cell>0.466 ± 0.000</cell></row><row><cell></cell><cell>RMSC</cell><cell>0.684 ± 0.033</cell><cell>0.642 ± 0.036</cell><cell>0.485 ± 0.046</cell><cell>0.517 ± 0.043</cell></row><row><cell>Yale</cell><cell>DSCN DCSC</cell><cell>0.738 ± 0.006 0.744 ± 0.009</cell><cell>0.727 ± 0.014 0.733 ± 0.007</cell><cell>0.509 ± 0.021 0.521 ± 0.011</cell><cell>0.542 ± 0.019 0.556 ± 0.012</cell></row><row><cell></cell><cell>DC</cell><cell>0.756 ± 0.001</cell><cell>0.766 ± 0.007</cell><cell>0.553 ± 0.017</cell><cell>0.579 ± 0.004</cell></row><row><cell></cell><cell>LMSC</cell><cell>0.702 ± 0.013</cell><cell>0.670 ± 0.012</cell><cell>0.472 ± 0.018</cell><cell>0.506 ± 0.010</cell></row><row><cell></cell><cell>DMF</cell><cell>0.782 ± 0.010</cell><cell>0.745 ± 0.011</cell><cell>0.579 ± 0.002</cell><cell>0.601 ± 0.002</cell></row><row><cell></cell><cell>MSCN</cell><cell>0.769 ± 0.003</cell><cell>0.772 ± 0.004</cell><cell>0.582 ± 0.012</cell><cell>0.598 ± 0.006</cell></row><row><cell></cell><cell>MvDSCN</cell><cell cols="2">0.797 ± 0.007 0.824 ± 0.004</cell><cell>0.626 ± 0.011</cell><cell>0.650 ± 0.010</cell></row><row><cell></cell><cell>BestSV</cell><cell>0.903 ± 0.016</cell><cell>0.777 ± 0.033</cell><cell>0.738 ± 0.001</cell><cell>0.711 ± 0.043</cell></row><row><cell></cell><cell>LRR</cell><cell>0.895 ± 0.006</cell><cell>0.773 ± 0.003</cell><cell>0.724 ± 0.002</cell><cell>0.731 ± 0.004</cell></row><row><cell></cell><cell>Min-Disagreement</cell><cell>0.816 ± 0.001</cell><cell>0.734 ± 0.040</cell><cell>0.621 ± 0.003</cell><cell>0.663 ± 0.003</cell></row><row><cell></cell><cell>Co-Reg</cell><cell>0.853 ± 0.003</cell><cell>0.715 ± 0.000</cell><cell>0.602 ± 0.004</cell><cell>0.615 ± 0.000</cell></row><row><cell></cell><cell>RMSC</cell><cell>0.872 ± 0.012</cell><cell>0.723 ± 0.025</cell><cell>0.645 ± 0.029</cell><cell>0.654 ± 0.028</cell></row><row><cell>ORL</cell><cell>DSCN DCSC</cell><cell>0.883 ± 0.005 0.893 ± 0.003</cell><cell>0.801 ± 0.009 0.811 ± 0.003</cell><cell>0.704 ± 0.012 0.709 ± 0.021</cell><cell>0.711 ± 0.011 0.718 ± 0.004</cell></row><row><cell></cell><cell>DC</cell><cell>0.865 ± 0.011</cell><cell>0.788 ± 0.002</cell><cell>0.684 ± 0.007</cell><cell>0.701 ± 0.008</cell></row><row><cell></cell><cell>LMSC</cell><cell>0.931 ± 0.011</cell><cell>0.819 ± 0.017</cell><cell>0.769 ± 0.044</cell><cell>0.758 ± 0.009</cell></row><row><cell></cell><cell>DMF</cell><cell>0.933 ± 0.010</cell><cell>0.823 ± 0.021</cell><cell>0.783 ± 0.001</cell><cell>0.773 ± 0.002</cell></row><row><cell></cell><cell>MSCN</cell><cell>0.928 ± 0.001</cell><cell>0.833 ± 0.008</cell><cell>0.790 ± 0.005</cell><cell>0.787 ± 0.001</cell></row><row><cell></cell><cell>MvDSCN</cell><cell cols="2">0.943 ± 0.002 0.870 ± 0.006</cell><cell>0.819 ± 0.001</cell><cell>0.834 ± 0.012</cell></row><row><cell></cell><cell>BestSV</cell><cell>0.104 ± 0.078</cell><cell>0.297 ± 0.089</cell><cell>0.063 ± 0.001</cell><cell>0.221 ± 0.064</cell></row><row><cell></cell><cell>LRR</cell><cell>0.109 ± 0.030</cell><cell>0.306 ± 0.039</cell><cell>0.066 ± 0.002</cell><cell>0.240 ± 0.052</cell></row><row><cell></cell><cell>Min-Disagreement</cell><cell>0.097 ± 0.005</cell><cell>0.336 ± 0.014</cell><cell>0.103 ± 0.013</cell><cell>0.223 ± 0.004</cell></row><row><cell></cell><cell>Co-Reg</cell><cell>0.093 ± 0.016</cell><cell>0.263 ± 0.024</cell><cell>0.092 ± 0.004</cell><cell>0.226 ± 0.035</cell></row><row><cell></cell><cell>RMSC</cell><cell>0.106 ± 0.056</cell><cell>0.285 ± 0.020</cell><cell>0.113 ± 0.063</cell><cell>0.232 ± 0.021</cell></row><row><cell>Still DB</cell><cell>DSCN DCSC</cell><cell>0.216 ± 0.011 0.222 ± 0.008</cell><cell>0.323 ± 0.006 0.325 ± 0.007</cell><cell>0.145 ± 0.002 0.148 ± 0.003</cell><cell>0.293 ± 0.019 0.301 ± 0.002</cell></row><row><cell></cell><cell>DC</cell><cell>0.199 ± 0.003</cell><cell>0.315 ± 0.001</cell><cell>0.131 ± 0.001</cell><cell>0.280 ± 0.011</cell></row><row><cell></cell><cell>LMSC</cell><cell>0.137 ± 0.032</cell><cell>0.328 ± 0.029</cell><cell>0.088 ± 0.007</cell><cell>0.269 ± 0.055</cell></row><row><cell></cell><cell>DMF</cell><cell>0.154 ± 0.010</cell><cell>0.336 ± 0.017</cell><cell>0.124 ± 0.001</cell><cell>0.265 ± 0.005</cell></row><row><cell></cell><cell>MSCN</cell><cell>0.168 ± 0.001</cell><cell>0.312 ± 0.008</cell><cell>0.133 ± 0.005</cell><cell>0.261 ± 0.001</cell></row><row><cell></cell><cell>MvDSCN</cell><cell cols="2">0.245 ± 0.020 0.377 ± 0.023</cell><cell>0.169 ± 0.003</cell><cell>0.320 ± 0.015</cell></row><row><cell></cell><cell>BestSV</cell><cell>0.715 ± 0.060</cell><cell>0.836 ± 0.037</cell><cell>0.659 ± 0.005</cell><cell>0.768 ± 0.038</cell></row><row><cell></cell><cell>LRR</cell><cell>0.690 ± 0.019</cell><cell>0.832 ± 0.026</cell><cell>0.667 ± 0.008</cell><cell>0.774 ± 0.023</cell></row><row><cell></cell><cell>Min-Disagreement</cell><cell>0.776 ± 0.019</cell><cell>0.797 ± 0.049</cell><cell>0.783 ± 0.034</cell><cell>0.260 ± 0.013</cell></row><row><cell></cell><cell>Co-Reg</cell><cell>0.718 ± 0.003</cell><cell>0.564 ± 0.000</cell><cell>0.696 ± 0.001</cell><cell>0.766 ± 0.002</cell></row><row><cell></cell><cell>RMSC</cell><cell>0.608 ± 0.007</cell><cell>0.737 ± 0.003</cell><cell>0.723 ± 0.025</cell><cell>0.655 ± 0.002</cell></row><row><cell>BBCSport</cell><cell>DSCN DCSC</cell><cell>0.652 ± 0.000 0.683 ± 0.001</cell><cell>0.821 ± 0.000 0.843 ± 0.000</cell><cell>0.856 ± 0.001 0.864 ± 0.012</cell><cell>0.683 ± 0.001 0.712 ± 0.002</cell></row><row><cell></cell><cell>DC</cell><cell>0.556 ± 0.001</cell><cell>0.724 ± 0.000</cell><cell>0.781 ± 0.000</cell><cell>0.492 ± 0.000</cell></row><row><cell></cell><cell>LMSC</cell><cell>0.826 ± 0.006</cell><cell>0.900 ± 0.044</cell><cell>0.893 ± 0.012</cell><cell>0.887 ± 0.071</cell></row><row><cell></cell><cell>DMF</cell><cell>0.821 ± 0.003</cell><cell>0.890 ± 0.031</cell><cell>0.883 ± 0.012</cell><cell>0.889 ± 0.001</cell></row><row><cell></cell><cell>MSCN</cell><cell>0.813 ± 0.002</cell><cell>0.888 ± 0.003</cell><cell>0.859 ± 0.001</cell><cell>0.854 ± 0.002</cell></row><row><cell></cell><cell>MvDSCN</cell><cell cols="2">0.835 ± 0.000 0.931 ± 0.001</cell><cell>0.909 ± 0.001</cell><cell>0.860 ± 0.000</cell></row><row><cell>A. Experiment Setup</cell><cell></cell><cell></cell><cell cols="3">(4,096 dimensions), LBP (3,304 dimensions) and Gabor</cell></row><row><cell cols="3">Datasets. We extensively evaluate the multi-view clustering</cell><cell cols="2">(6,750 dimensions).</cell><cell></cell></row><row><cell cols="3">performance of the proposed model on benchmark multi-view</cell><cell></cell><cell></cell><cell></cell></row><row><cell>datasets.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>, intensity</cell><cell></cell><cell></cell><cell></cell></row></table><note>•• ORL contains 10 different images of each of 40 dis- tinct subjects. For each subject, the images were taken under varying lighting conditions with different facial expressions (open / closed eyes, smiling / not smiling) and facial details (glasses / no glasses). For the face dataset (Yale and ORL), we adjust the image size to 48 × 48 and extract three types of features, i.e.•• BBCSport contains 544 documents from the BBC Sport website of sports news articles, which are related to two viewpoints in five topical areas during 2004-2005. For each sample, there are 3,183 features for the first view and 3,203 features for the second view.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE II :</head><label>II</label><figDesc>Results on four multi-feature datasets (mean ± standard deviation). Higher value indicates better performance. .738 ± 0.006 0.727 ± 0.014 0.509 ± 0.021 0.542 ± 0.019 View2 0.613 ± 0.007 0.598 ± 0.008 0.401 ± 0.008 0.439 ± 0.008 View3 0.545 ± 0.009 0.522 ± 0.012 0.267 ± 0.011 0.311 ± 0.011 ALL 0.797 ± 0.007 0.824 ± 0.004 0.626 ± 0.011 0.650 ± 0.010</figDesc><table><row><cell>Datasets</cell><cell>Views</cell><cell>NMI</cell><cell>ACC</cell><cell>AR</cell><cell>F-measure</cell></row><row><cell cols="6">Yale View1 0ORL View1 0.883 ± 0.005 0.801 ± 0.009 0.704 ± 0.012 0.711 ± 0.011 View2 0.793 ± 0.011 0.627 ± 0.024 0.504 ± 0.023 0.516 ± 0.023 View3 0.764 ± 0.009 0.580 ± 0.024 0.458 ± 0.024 0.471 ± 0.023</cell></row><row><cell></cell><cell>ALL</cell><cell cols="4">0.943 ± 0.002 0.870 ± 0.006 0.819 ± 0.001 0.834 ± 0.012</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE III :</head><label>III</label><figDesc>Results on RGB-D Object datasets (mean ± standard deviation). Higher value indicates better performance.</figDesc><table><row><cell>Datasets</cell><cell>Methods</cell><cell>NMI</cell><cell>ACC</cell><cell>AR</cell><cell>F-measure</cell></row><row><cell></cell><cell>BestSV</cell><cell>0.554 ± 0.006</cell><cell>0.278 ± 0.001</cell><cell>0.106 ± 0.006</cell><cell>0.125 ± 0.006</cell></row><row><cell></cell><cell>LRR</cell><cell>0.589 ± 0.002</cell><cell>0.299 ± 0.010</cell><cell>0.143 ± 0.002</cell><cell>0.156 ± 0.001</cell></row><row><cell></cell><cell>Min-Disagreement</cell><cell>0.605 ± 0.008</cell><cell>0.332 ± 0.002</cell><cell>0.160 ± 0.013</cell><cell>0.177 ± 0.011</cell></row><row><cell></cell><cell>Co-Reg</cell><cell>0.602 ± 0.007</cell><cell>0.268 ± 0.003</cell><cell>0.155 ± 0.020</cell><cell>0.175 ± 0.018</cell></row><row><cell></cell><cell>RMSC</cell><cell>0.603 ± 0.006</cell><cell>0.341 ± 0.015</cell><cell>0.162 ± 0.010</cell><cell>0.178 ± 0.010</cell></row><row><cell>RGB-D Object</cell><cell>DSCN DCSC</cell><cell>0.589 ± 0.004 0.591 ± 0.002</cell><cell>0.339 ± 0.006 0.340 ± 0.002</cell><cell>0.163 ± 0.004 0.170 ± 0.001</cell><cell>0.179 ± 0.004 0.182 ± 0.003</cell></row><row><cell></cell><cell>DC</cell><cell>0.594 ± 0.003</cell><cell>0.340 ± 0.002</cell><cell>0.177 ± 0.004</cell><cell>0.184 ± 0.004</cell></row><row><cell></cell><cell>LMSC</cell><cell>0.593 ± 0.030</cell><cell>0.335 ± 0.028</cell><cell>0.151 ± 0.035</cell><cell>0.167 ± 0.034</cell></row><row><cell></cell><cell>DMF</cell><cell>0.549 ± 0.004</cell><cell>0.286 ± 0.006</cell><cell>0.107 ± 0.002</cell><cell>0.123 ± 0.001</cell></row><row><cell></cell><cell>MSCN</cell><cell>0.608 ± 0.001</cell><cell>0.354 ± 0.003</cell><cell>0.190 ± 0.002</cell><cell>0.203 ± 0.004</cell></row><row><cell></cell><cell>MvDSCN</cell><cell>0.639 ± 0.003</cell><cell>0.388 ± 0.005</cell><cell>0.210 ± 0.004</cell><cell>0.225 ± 0.004</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE IV :</head><label>IV</label><figDesc>Results on RGB-D Object dataset (mean ± standard deviation). Higher value indicates better performance. ± 0.004 0.300 ± 0.005 0.131 ± 0.004 0.147 ± 0.004 RGB+Depth 0.639 ± 0.003 0.388 ± 0.005 0.210 ± 0.004 0.225 ± 0.004</figDesc><table><row><cell>Datasets</cell><cell>Views</cell><cell>NMI</cell><cell>ACC</cell><cell>AR</cell><cell>F-measure</cell></row><row><cell></cell><cell>RGB</cell><cell cols="4">0.589 ± 0.004 0.339 ± 0.006 0.163 ± 0.004 0.179 ± 0.004</cell></row><row><cell>RGB-D Object</cell><cell>Depth</cell><cell>0.576</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE V :</head><label>V</label><figDesc>Ablation study on RGB-D Object dataset (mean ± standard deviation). Higher value indicates better performance.</figDesc><table><row><cell>Methods</cell><cell>NMI</cell><cell>ACC</cell><cell>AR</cell><cell>F-measure</cell></row><row><cell>D-MvDSCN</cell><cell>0.594 ± 0.004</cell><cell>0.343 ± 0.007</cell><cell>0.190 ± 0.006</cell><cell>0.205 ± 0.006</cell></row><row><cell>U-MvDSCN</cell><cell>0.593 ± 0.005</cell><cell>0.350 ± 0.006</cell><cell>0.192 ± 0.006</cell><cell>0.197 ± 0.006</cell></row><row><cell>MvDSCN</cell><cell>0.639 ± 0.003</cell><cell>0.388 ± 0.005</cell><cell>0.210 ± 0.004</cell><cell>0.225 ± 0.004</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Robust recovery of subspace structures by low-rank representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guangcan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhouchen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shuicheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="171" to="184" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep subspace clustering networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="24" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Deep adversarial subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Subspace clustering by block diagonal representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="issue">99</biblScope>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Unsupervised multi-manifold clustering by learning deep representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Workshops</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deepcluster: A general clustering framework based on deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECML/PKDD</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">When to learn what: Deep cognitive subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACMMM</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Structured autoencoders for subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-Y</forename><surname>Yau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="5076" to="5086" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Improved deep embedded clustering with local structure preservation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Projective low-rank subspace clustering via learning deep encoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep density clustering of unconstrained faces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Sub-gan: An unsupervised generative model via subspaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Ole: Orthogonal low-rank embedding, a plug and play geometric loss for deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lezama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Musé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Simple to complex cross-modal learning to rank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Hauptmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">163</biblScope>
			<biblScope unit="page" from="67" to="77" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Dasc: Dense adaptive self-correlation descriptor for multi-modal and multi-spectral correspondence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ryu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2103" to="2112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Multi-view 3d object detection network for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1907" to="1915" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Multi-view clustering via deep matrix factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Non-redundant multi-view clustering via orthogonalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">Z</forename><surname>Fern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Dy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Multi-view clustering using mixture models in subspace projections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Günnemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Färber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Seidl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KDD</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Robust subspace clustering for multi-view data by exploiting correlation consensus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="3939" to="3949" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Latent multi-view subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Discriminatively embedded k-means for multi-view clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Nie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Partial multi-view clustering via consistent gan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Sparse subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Elhamifar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Generalized latent multi-view subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="1" to="1" />
		</imprint>
	</monogr>
	<note type="report_type">TPAMI</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A non-local algorithm for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&apos;05)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="60" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Unsupervised feature selection by regularized self-representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Shiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="438" to="446" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Coupled dictionary learning for unsupervised feature selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirtieth AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Subspace clustering guided unsupervised feature selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="364" to="374" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Non-local neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7794" to="7803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Reducing the dimensionality of data with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">313</biblScope>
			<biblScope unit="issue">5786</biblScope>
			<biblScope unit="page" from="504" to="511" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Lajoie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-A</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="3371" to="3408" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Unsupervised deep embedding for clustering analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Deep subspace clustering with sparsity prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-Y</forename><surname>Yau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Discriminatively boosted image clustering with fully convolutional auto-encoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PR</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="161" to="173" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Stacked convolutional auto-encoders for hierarchical feature extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Ciresan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<editor>ICANN</editor>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Plug &amp; play generative networks: Conditional iterative generation of images in latent space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">T L</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yosinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Clune</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR</title>
		<imprint>
			<biblScope unit="page" from="3510" to="3520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Deconvolutional paragraph representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Henao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Carin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Measuring statistical dependence with hilbert-schmidt norms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Scholkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Algorithmic Learning Theory</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="63" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Diversity-induced multi-view subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Subspace clustering by block diagonal representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="487" to="501" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno>abs/1412.6980</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A large-scale hierarchical multiview rgb-d object dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICRA</title>
		<imprint>
			<biblScope unit="page" from="1817" to="1824" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">On spectral clustering: Analysis and an algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Robust multi-view spectral clustering via low-rank and sparse decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Deep clustering for unsupervised learning of visual features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Spectral clustering with two views</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">R</forename><surname>De Sa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Co-regularized multi-view spectral clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Daumé</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Deep multimodal subspace clustering networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abavisani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Signal Processing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1601" to="1614" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Objective criteria for the evaluation of clustering methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">M</forename><surname>Rand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical association</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">336</biblScope>
			<biblScope unit="page" from="846" to="850" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
