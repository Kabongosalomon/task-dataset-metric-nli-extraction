<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Towards Discriminative and Interpretable Network: Deep Convolutional Decision Jungle</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seungryul</forename><surname>Baek</surname></persName>
							<email>s.baek15@imperial.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwang</forename><forename type="middle">In</forename><surname>Kim</surname></persName>
							<email>k.kim@bath.ac.uk</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Bath</orgName>
								<address>
									<settlement>Bath</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tae-Kyun</forename><surname>Kim</surname></persName>
							<email>tk.kim@imperial.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Towards Discriminative and Interpretable Network: Deep Convolutional Decision Jungle</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>BAEK ET AL.: DEEP CONVOLUTIONAL DECISION JUNGLE 1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose a novel method called deep convolutional decision jungle (CDJ) and its learning algorithm for image classification. While the CDJ maintains the structure of the standard convolutional neural networks (CNNs) with multiple layers of multiple response maps, it aims at making intermediate representations more discriminative and interpretable, which in turn improves the classification accuracy of the network. During testing, each response map (or node) in both the convolutional and fully-connected layers selectively respond to class labels such that each data sample in effect travels via a specific soft route of those activated nodes. Therefore, CDJ's operational characteristics resemble those of the decision jungle. Compared to standard CNNs, the method embeds the benefits of using data-dependent discriminative functions, which better handles multi-modal/heterogeneous data. The network is learnt by combining the conventional softmax loss at the last layer and the proposed routing losses in each layer. The routing loss, as used in growing decision trees, measures the purity of data activation according to the class label distribution. Experiments on four real-world learning problems show that our method improves existing CNN architectures in the respective of both accuracy and interpretability.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Random forests (RF) have been widely used for various computer vision problems, particularly on classification. RFs exhibit multiple inherent benefits from its tree structure: a complex classification problem is tackled in a hierarchical divide-conquer manner, and their training and testing steps are computationally efficient. Its structural diversity also motivates an ensemble learning. Convolutional neural networks (CNNs) have been proven to achieve state-of-the-art results in diverse problems. Its convolutional layers learn powerful features and fully connected layers and the last soft-max layer serve as a classifier. Recently, several works <ref type="bibr" target="#b1">[3,</ref><ref type="bibr" target="#b2">4,</ref><ref type="bibr" target="#b7">9,</ref><ref type="bibr" target="#b8">10,</ref><ref type="bibr" target="#b12">14,</ref><ref type="bibr" target="#b17">19,</ref><ref type="bibr" target="#b21">23,</ref><ref type="bibr" target="#b28">30,</ref><ref type="bibr" target="#b30">32]</ref> have attempted combining the two methods (e.g. see <ref type="figure" target="#fig_1">Fig. 1a</ref>), for exploiting hierarchical tree-structures <ref type="bibr" target="#b2">[4,</ref><ref type="bibr" target="#b11">13,</ref><ref type="bibr" target="#b12">14,</ref><ref type="bibr" target="#b26">28]</ref>, tackling multimodal data <ref type="bibr" target="#b28">[30]</ref>, clustering and learning modular networks per cluster <ref type="bibr" target="#b4">[6,</ref><ref type="bibr" target="#b17">19,</ref><ref type="bibr" target="#b29">31,</ref><ref type="bibr" target="#b30">32]</ref>, and accelerating trainig and testing <ref type="bibr" target="#b7">[9]</ref>. Also relevant to this study is to encourage sparsity in representation for regularization and efficiency in memory/time <ref type="bibr" target="#b1">[3,</ref><ref type="bibr" target="#b8">10,</ref><ref type="bibr" target="#b10">12,</ref><ref type="bibr" target="#b21">23]</ref>. Our method can be seen as a new regularizer that enforces sparsity per data point in testing time. The prior-works aforementioned reported improved accuracy; however, there is room to improve especially in the following aspects:</p><p>In the adopted binary tree structure <ref type="bibr" target="#b2">[4,</ref><ref type="bibr" target="#b7">9,</ref><ref type="bibr" target="#b12">14,</ref><ref type="bibr" target="#b28">30]</ref>, once a data sample goes in a wrong path, it cannot be recovered i.e. they overfit. Soft partitioning helps relieve the issue to a certain degree, however, exponentially growing recursive binary splits <ref type="bibr" target="#b7">[9,</ref><ref type="bibr" target="#b28">30]</ref> remains as an issue. The decision jungle <ref type="bibr" target="#b22">[24]</ref> type of algorithm becomes a natural extension for solving both and has shown good generalization ability. In another aspect, most existing methods for combining trees and CNNs <ref type="bibr" target="#b7">[9,</ref><ref type="bibr" target="#b28">30]</ref> require additional model parameters: The split process is often performed by a separate routing network <ref type="bibr" target="#b28">[30]</ref>. Often the network layers need to be shallower to solve the explosion of the number of model parameters <ref type="bibr" target="#b7">[9]</ref>. To summarize, it is challenging to apply such methods to existing large/deep networks <ref type="bibr" target="#b14">[16,</ref><ref type="bibr" target="#b24">26,</ref><ref type="bibr" target="#b25">27]</ref>. <ref type="bibr" target="#b12">[14]</ref> applied the tree structure using big networks; however tree structure exists only in the last fully connected layers. Our aim is to propose a novel method that applies class entropy or purity adopted from RFs to existing CNNs for more discriminative and interpretable representations in earlier layers and thus higher classification accuracy. The proposed architecture offers the following benefits: Class-wise purity in early layers: Our method learns a convolutional neural network (CNN) with routing loss per layer. The proposed loss helps purify response maps, which we will call 'nodes', in all intermediate layers of CNNs. The response maps in each layer are pushed on or off conditionally on the input vectors such that each response map is dedicated to certain classes (ideally a class) than all. Note that the response maps for each data point take continuous values, thus this operation is treated as 'soft' routing. We observe that the supervised purification by class labels leads to more discriminative intermediate representations and higher accuracies. Data-dependent dynamic activation by the decision jungle structure: Combination of CNNs and RFs is to improve the capacity of the given CNNs <ref type="bibr" target="#b30">[32]</ref> thanks to its data-dependent discriminative functions. Compared to binary decision trees, the sample's paths are recoverable in later layers in the fully connected decision jungle structure. The decision jungle has shown improved generalization over binary trees. Also, such a structure makes the method be more flexible (applicable to any existing CNNs not altering their original architectures) and memory efficient than the binary tree structures <ref type="bibr" target="#b22">[24]</ref> by sharing multiple branches. More Interpretable CNNs: Several methods have been introduced [1, <ref type="bibr" target="#b0">2,</ref><ref type="bibr" target="#b18">20,</ref><ref type="bibr" target="#b32">34]</ref> to better understand intermediate representations learnt in CNNs.</p><p>[1] propose a linear classifier as a probe to observe the behavior of intermediate layers. They use the probe for the trained CNNs and have shown that the entropy is a good measure for information contained in each layer. Similar to this, we evaluate each layer's discriminant power by the entropy measure. Further, we have an explicit mechanism to reduce the entropy in each layer by the gradient optimization. <ref type="bibr" target="#b0">[2]</ref> propose a procedure for quantifying hidden layers' interpretabilty based on the alignment between individual hidden units and a set of semantic concepts evaluated on datasets. In the experiments (see <ref type="table" target="#tab_2">Table 3</ref>), we demonstrate that our algorithm also significantly improves the interpretability from the baseline convolutional network architectures. Without additional routing parameters at testing: The proposed architecture learns routing using additional routing path (the right path of <ref type="figure" target="#fig_1">Fig. 1(b)</ref>) during the training phase. At testing, this path is not used, which keeps the complexity of the model same as the original CNN models. Existing methods <ref type="bibr" target="#b7">[9]</ref> require explicitly building routing networks at both train/test phases or change of the network structure to use binary routing <ref type="bibr" target="#b28">[30]</ref> where the number of parameters increases exponentially (see <ref type="figure" target="#fig_1">Fig. 1(a)</ref>). Encoding auxiliary information: Intermediate layers can be further purified by auxiliary labels (e.g. super-class labels or any other privileged information) in addition to the class labels. Experiments demonstrate significant accuracy improvements when using such auxiliary information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>CNNs meet tree structures. One of objectives in combining trees and CNNs is to learn both feature representations of input data and tree-structure classifiers conditioned on input data, in a joint manner <ref type="bibr" target="#b2">[4,</ref><ref type="bibr" target="#b7">9,</ref><ref type="bibr" target="#b12">14,</ref><ref type="bibr" target="#b28">30]</ref>. Previous methods can be categorized based on their operational characteristics as shown in <ref type="table" target="#tab_0">Table 1</ref>: tree split structures in <ref type="bibr" target="#b2">[4,</ref><ref type="bibr" target="#b12">14]</ref> are embedded in the fully connected (FC) layers <ref type="bibr" target="#b12">[14]</ref> rather than the convolutional (Conv) layers, which provide the final prediction as a classifier.  The class conditional distributions are displayed as a histogram within each node. The black response maps at each node denotes the turned-off map by the binary routing, as proposed in <ref type="bibr" target="#b28">[30]</ref>. Note that the number of nodes in each layer grows exponentially in (a). In (b), soft routing decisions are implicitly made by maximizing the class purity during training (Eq. 2). The class conditional distributions are obtained by applying the nonlinear activation functions (ReLU) and the average pooling to each intermediate layers' response map (displayed as blue arrows). In contrast, in <ref type="bibr" target="#b7">[9,</ref><ref type="bibr" target="#b28">30]</ref>, split structures are embedded in the convolutional layers. They discover hidden modalities of data, e.g. face poses in <ref type="bibr" target="#b28">[30]</ref>, super-classes in <ref type="bibr" target="#b7">[9]</ref>, from the early layers. <ref type="bibr" target="#b7">[9]</ref> uses continuous weights rather than discrete weights, thus their method can represent multiple soft routes than hard binary splits as in <ref type="bibr" target="#b2">[4,</ref><ref type="bibr" target="#b12">14,</ref><ref type="bibr" target="#b28">30]</ref>, However, the work has demonstrated routing only to 2-3 splits. A major difficulty in applying <ref type="bibr" target="#b7">[9]</ref> to the fully connected networks such as decision jungle <ref type="bibr" target="#b22">[24]</ref>, where a node routes to all the nodes in the next layer, is in need of additional routing network parameters: Parameters increase as the number of routes increases. Furthermore, <ref type="bibr" target="#b2">[4,</ref><ref type="bibr" target="#b28">30]</ref> use small network architectures, while the methods in <ref type="bibr" target="#b7">[9,</ref><ref type="bibr" target="#b12">14]</ref> are applied to recently-proposed CNN architectures (AlexNet <ref type="bibr" target="#b14">[16]</ref>, VGG-16 Net <ref type="bibr" target="#b24">[26]</ref>, and GoogleNet <ref type="bibr" target="#b25">[27]</ref>). Besides, the concept of using tree structures or conditional activation has been shown to improve CNN efficiency <ref type="bibr" target="#b1">[3,</ref><ref type="bibr" target="#b8">10]</ref>.</p><p>Compared to the previous works <ref type="bibr" target="#b2">[4,</ref><ref type="bibr" target="#b7">9,</ref><ref type="bibr" target="#b12">14,</ref><ref type="bibr" target="#b28">30]</ref>, our method does not require additional routing parameters, while enabling multiple soft routing and being applied to existing big architectures <ref type="bibr" target="#b7">[9]</ref>. The experiments using three image classification and face verification benchmarks demonstrate improved accuracy (Sec. 4). When using additional label information, the method further improves accuracy via a more explicit network routing. Adding clustering loss to CNNs. Though not explicitly using tree structures, relevant is a group of work that learns CNNs while performing hierarchical clustering <ref type="bibr" target="#b17">[19,</ref><ref type="bibr" target="#b21">23,</ref><ref type="bibr" target="#b30">32]</ref>. The method in <ref type="bibr" target="#b30">[32]</ref> iteratively performs feature representation learning and data clustering to better cluster data samples, while the method in <ref type="bibr" target="#b17">[19]</ref> introduces a clustering loss to help classification. The concept of mixture of experts is introduced in the LSTM architecture <ref type="bibr" target="#b21">[23]</ref> to improve its model capacity for language modeling. Set-based loss functions <ref type="bibr" target="#b20">[22,</ref><ref type="bibr" target="#b27">29]</ref> have also been proposed to encourage optimizing the intra-class/inter-class data variation, in addition to the softmax function. Compared to these existing methods, our method captures data separation from the early layers using class labels rather than exploiting sample distances in an unsupervised way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Deep convolutional decision jungle</head><p>The proposed deep convolutional decision jungle (CDJ) adopts the conventional convolutional neural network (CNN) architecture. Given a fixed network topology (i.e. the number and size of layers), the operation of a CNN is prescribed by a set of weight vectors (or convolution filters) W ={w</p><formula xml:id="formula_0">(l) j,k }: 1 the filter w (l) j,k at the l-th layer is convoluted with the j-th output (or response) map of the (l−1)-th layer R (l−1) j to generate the l-th layer's k-th response map R (l) k : R (l) k (x i )= R l ∑ j=1 ψ(R (l−1) j (x i )) * w (l) j,k ,<label>(1)</label></formula><p>where R l is the number of response maps in the l-th layer, * denotes the convolution operation, and ψ represents the non-linear activation and max-pooling operations. We use rectified linear units (ReLUs) while other activation functions can also be applied. Our CDJ is instantiated by interpreting the response maps and convolution filters, respectively, as decision nodes and edges joining pairs of nodes in decision jungle <ref type="figure" target="#fig_1">(Fig. 1b</ref>). In traditional decision trees and jungles, an input x at a node is exclusively routed to a single child node. In our CDJ, a soft decision is made at each node R </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Training deep convolutional decision jungles</head><p>Suppose we are given a set of training data points X ={(x i ,y i )} N i=1 ⊂R D ×R with D being the dimensionality of the input space. For a C-class classification problem, y i ∈{1,...,C}. Training the CDJ corresponds to identifying the optimal set of convolutional filter parameters W * achieved by minimizing the energy function that combines the standard training cost, a new routing cost, and a balancing cost:</p><formula xml:id="formula_1">C(W)= N ∑ i=1 C S (x i ,y i ;W) training cost +λ 1 L ∑ l=1 C (l) R x i ;{R (l) j (x i ;W)} i∈[1,N], j∈[1,R l ] routing cost +λ 2 L ∑ l=1 C (l) C x i ;{R (l) j (x i ;W)} i∈[1,N], j∈[1,R l ] label balancing cost ,<label>(2)</label></formula><p>where λ 1 ,λ 2 ≥0 control the contributions of the routing cost and label balancing cost over the training cost, and L is the number of layers in CDJ. We use the softmax loss for the training cost functional C S :</p><formula xml:id="formula_2">C S (x i ,y i ;W)=−ln e R (L) y i (x i ;W) ∑ C j=1 e R (L) j (x i ;W) .<label>(3)</label></formula><p>With the goal of embedding decision jungle into a CNN architecture, we design our routing loss as a differentiable approximation of the class purity criteria used in decision forests and jungles <ref type="bibr" target="#b22">[24]</ref>: Our routing loss enforces non-homogeneous responses according to inputs' class labels (i.e. each response is dominated by some classes) at the l-th layer:</p><formula xml:id="formula_3">C (l) R x i ;{R (l) j (x i ;W)} i=1,...,N, j=1,...,R l =− 1 R l ·C R l ∑ j=1 C ∑ h=1 C (l) h j (W)− 1 C C ∑ h =1 C (l) h j (W) 2 ,<label>(4)</label></formula><formula xml:id="formula_4">C (l) h j (W)= N ∑ i=1 a (l) i j δ(y i ,h),<label>(5)</label></formula><p>where δ(y i ,h) = 1 if y i = h and δ(y i ,h) = 0, otherwise. The scalar response a (l) i j is obtained from R (l) j (x i ;W)) via two layers that are differentiable: non-linear activation (ReLU) layer, followed by the average pooling layer is applied to the R The interpretation of the routing loss as the class purity measure follows straightforwardly from its usage in decision trees (reducing entropy). However, naïvely applying this loss to training CNNs tends to generate degenerate solutions: The optimized solutions disable some classes by allocating (near-)zero probabilities to selected columns of (corresponding to specific classes) C (l) h j (W). This still contributes to reducing the overall entropy, but leads to poor generalization. <ref type="figure" target="#fig_5">Fig. 2b</ref> illustrates this problem with examples. <ref type="figure" target="#fig_5">Fig. 2e</ref> is the desirable solution compared to <ref type="figure" target="#fig_5">Fig. 2d</ref>.</p><p>To relieve the problem, the Label balancing cost is added to the optimization of Eq. 2. The cost is proposed to enforce the responses of each class label to have the similar scales to prevent from vanishing certain labels in the distribution of C (l) at each layer:</p><formula xml:id="formula_5">C (l) C x i ;{R (l) j (x i ;W)} i=1,...,N, j=1,...,R l = 1 C C ∑ h=1 R l ∑ j=1 C (l) h j (W)− 1 C C ∑ h=1 R l ∑ j=1 C (l) h j (W) 2 .<label>(6)</label></formula><p>The definition of routing loss and label balancing cost is consistent with our interpretation of CNN response maps as nodes in decision jungle. All three terms in the loss function (Eq. 2) are differentiable with respect to W, and enable gradient descent-type optimization, e.g. stochastic gradient descent (SGD). We adopt mini-batch optimization instead of batch-optimizing the cost-functional C (Eq. 2). This facilitates efficient training using GPUs. Algorithm 1 summarizes the CDJ training process. We further derive the gradient update rules for our new modules (Eqs. 4 and 6) and perform experiments on the model variants using training with auxiliary labels and ensemble learning.</p><p>Algorithm 1: CDJ training algorithm.</p><p>Input: Training data X ={(x i ,y i )} N i=1 and initial filters W, the number of epochs T , and the size of mini-batch N ; Output: Learned filters W; for t=1 to T do for n=1 to N do Construct C (l) (W) from n-th mini-batch (Eq. 5); Update W based on sample gradients (Eq. 7); end end Gradient update rule. The cost C(W) in Eq. 2 is decomposed into three terms as follows:</p><formula xml:id="formula_6">∂C(W) ∂W = N ∑ i=1 ∂C S (x i ,y i ;W) ∂W +λ 1 L ∑ l=1 ∂C (l) R x i ;{R (l) j (x i ;W)} i∈[1,N], j∈[1,R l ] ∂W +λ 2 L ∑ l=1 ∂C (l) C x i ;{R (l) j (x i ;W)} i∈[1,N], j∈[1,R l ] ∂W ,<label>(7)</label></formula><p>where ∂C S ∂W can be derived same as the standard CNNs, can be calculated via ∂x 2 ∂x =2x and</p><formula xml:id="formula_7">∂C (l) R ∂W = ∂C (l) R ∂C (l) h j (W) · ∂C (l) h j (W) ∂a i j · ∂a i j ∂W , ∂C (l) C ∂W = ∂C (l) C ∂C (l) h j (W) · ∂C (l) h j (W) ∂a i j · ∂a i j ∂W where ∂a i j ∂W = ∂a i j ∂R (l) j (x i ;W) · ∂R (l) j (x i ;W) ∂W</formula><formula xml:id="formula_8">∂C (l) h j (W) ∂a i j = 1 if δ(y i ,h)=1 0 otherwise for each i-th sample x i .</formula><p>Training with auxiliary labels. Our new routing loss can be defined for any variables {z i } N i=1 that replace the class labels {y i } N i=1 . This enables a systematic way of exploiting auxiliary information when available. We demonstrate the effectiveness of this approach in our face verification experiment using the pose as auxiliary labels. The class labels {y i } N i=1 are used for the soft-max loss. See <ref type="table">Table 2</ref>. Ensemble learning. As in tree-based algorithms, our method inherits implicit structural diversity.</p><p>In the experiments, we learnt 7 CDJ networks, and formed up an ensemble by combining their class predictions. The ensembled accuracy comparison between ensembled CNNs and ensembled CDJs on Oxford-IIIT Pet is shown in the <ref type="table" target="#tab_2">Table 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>Setup. We evaluate our convolutional decision jungle (CDJ) on three image classification datasets: Oxford-IIIT Pet <ref type="bibr" target="#b19">[21]</ref>, CIFAR-100 <ref type="bibr" target="#b13">[15]</ref>, and Caltech-101 <ref type="bibr" target="#b3">[5]</ref>; and a face verification dataset: Multi-PIE <ref type="bibr" target="#b6">[8]</ref>. The Oxford-IIIT Pet dataset consists of 7,349 images covering 37 different breeds of cats and dogs (e.g., Shiba Inu and Yorkshire Terrier). We adopt the training and test splits of 3,680 and 3,669 images respectively <ref type="bibr" target="#b19">[21,</ref><ref type="bibr" target="#b20">22]</ref>. The CIFAR-100 dataset contains 60,000 natural images of 100 classes that are grouped into 20 superclasses. We use a 50,000 training and 10,000 testing splits following <ref type="bibr" target="#b4">[6,</ref><ref type="bibr" target="#b5">7,</ref><ref type="bibr" target="#b16">18,</ref><ref type="bibr" target="#b17">19]</ref>. The Caltech-101 dataset contains 9,146 images of 101 object categories. 30 images are chosen from each category for training and the remaining images (with at most 50 per category) are used for testing <ref type="bibr" target="#b9">[11]</ref>. The Multi-PIE (Session 1 subset) face verification dataset consists of photographs of 250 individuals taken at 20 different illumination levels and 15 poses ranging from −90°to +90°. We proceed as per <ref type="bibr" target="#b28">[30]</ref>: For training, all images (15 poses, 20 illumination levels) of the first 150 individuals are used, while for testing a frontal view with neutral illumination (ID07 entries) is used as the gallery image for each of the remaining 100 subjects. The rest of the images are used as probes. We use the responses of the last hidden layer of our trained network as features for cosine distance-based matching. For each dataset, we adopt the competitive network architecture: AlexNet <ref type="bibr" target="#b14">[16]</ref> and VGG-16 <ref type="bibr" target="#b24">[26]</ref> for Oxford-IIIT Pet and Caltech-101, respectively, and NiN <ref type="bibr" target="#b16">[18]</ref> for CIFAR-100. Each network is then initialized based on the standard ImageNet classification dataset. For Multi-PIE, our primary comparison is performed with c-CNN forests <ref type="bibr" target="#b28">[30]</ref> that embed a decision tree into a small CNN architecture (Sec. 2). To show the flexibility (easy to use larger-scale network) of our method compared to c-CNN, we adopt AlexNet as our baseline.</p><p>The training parameters, including network topology, the mini-batch size, the number of training epochs, and dropout and local response normalization decisions are adopted from the respective state-of-the-art baseline: The mini-batch sizes are decided at 256, 32, and 100 for AlexNet, VGG-16, and NiN, respectively. The number of epochs are 60 for AlexNet and VGG-16, and 100 for NiN.</p><p>The learning rate is scheduled from 10 −2 to 10 −4 at every epoch for AlexNet, from 10 −4 to 10 −6 for VGG-16. Our learning rate for the NiN architecture is overall slightly smaller than <ref type="bibr" target="#b16">[18]</ref>, being fixed at 0.04 until the 80-th epoch, and reduced to 0.004 and 0.0004 after 80-th and 90-th epochs, respectively: This small learning rate ensures that the energy functional decreases constantly. For our new routing cost (Eq. 2), we use a larger mini-batch size of 10×C (C being the number of classes) to ensure a balanced class distributions within each batch. Due to the label balancing constraint (Eq. 6), our routing cost is applicable only when the corresponding layer is larger than C. Therefore, we apply the routing loss from the second convolutional layer for AlexNet and VGG-16, and from the cccp3 layer for NiN. The earlier layers-which do not use the routing loss-can be regarded as feature extractors of a decision jungle. Results. <ref type="table">Table 2</ref>(a)-(c) compare the results of our method with eleven state-of-the-art methods across three image classification problems. Overall, our algorithm constantly improves on each baseline with a large margin: Since we use the same network architecture as each baseline, these results can be attributed to the effectiveness of our new routing loss. More importantly, our method outperforms existing algorithms that incorporate special cost functions similarly to ours, including squared hinge loss applied to hidden layers (DSN <ref type="bibr" target="#b15">[17]</ref>), clustering cost (DDN <ref type="bibr" target="#b17">[19]</ref>), set-based loss of Magnet <ref type="bibr" target="#b20">[22]</ref> that further uses data augmentation, and label balancing cost <ref type="bibr" target="#b9">[11]</ref>. Our network attains routing from supervised class information rather than from unsupervised sample distances, as in these previous works, which helps learn more discriminative features.</p><p>Table 2(d) shows the results of different algorithms on Multi-PIE dataset. State-of-the-art performance on this dataset was achieved by c-CNN forests <ref type="bibr" target="#b28">[30]</ref> which embed binary decision trees into a CNN architecture. To show the flexibility (easy to use larger-scale network) of our method compared to c-CNN, we adopt AlexNet as our baseline. As c-CNN forests doubles the number of nodes (or response maps) across each layer, it cannot be used to construct a deep network. This can pose severe application constraints: By simply training the deeper AlexNet, we already achieved much higher accuracy than c-CNN forests <ref type="figure" target="#fig_5">(Table 2(d)</ref>). In contrast, our CDJ facilitates large-scale, deep decision networks as it embeds computationally efficient and topologically flexible decision jungles into CNNs. The performance of the resulting CDJ is on par with the original AlexNet. However, CDJ inherits an important advantage of decision jungles: It is inherently tailored to heterogeneous feature modalities. By straightforwardly incorporating domain specific, auxiliary facial pose information into our routing cost, CDJ achieved significant improvement over AlexNet that already outperforms the state-of-the-art c-CNN forests (see <ref type="figure" target="#fig_6">Fig. 3</ref>(a) for the change in accuracy across different facial pose). Minimizing CNN's standard classification loss (softmax) tends to improve the class purity around the last layer. By explicitly enforcing it, our algorithm achieved low entropy even at the early layers. Note the strong correlation between the test accuracy (b) and (the inverse of) the average entropy at each layer (d) demonstrating the effectiveness of our new routing cost in improving generalization performance.</p><p>Finally, <ref type="table" target="#tab_2">Table 3</ref> shows the ensembled accuracies and average interpretability scores of the baseline CNNs and our method, respectively evaluated over all images and the response maps (Oxford-IIIT Pet dataset). The ensemble meaningfully improves the accuracy of CDJs over ensembled CNNs. Also, our algorithm achieved 19.81% and 16.18% increases of interpretability scores from AlexNet and VGG-16 baselines, respectively. The interpretability is defined based on the agreement of fine-grained ground-truth scene labels and the corresponding network responses as proposed by <ref type="bibr" target="#b0">[2]</ref>. High interpretability facilitates the understanding of semantics developed within hidden units' of networks <ref type="bibr" target="#b0">[2]</ref>, which is an extremely important active problem in deep network research. Furthermore, the observed strong correlations between the accuracy and interpretability support <ref type="bibr" target="#b0">[2]</ref>'s hypothesis that disentangled representations (as factorizations of the underlying problem structure) developed in the hidden layers are aligned with human-interpretable concepts. <ref type="table">Table 2</ref>: Results for three image classification and one face verification tasks: (a) Oxford-IIIT Pet, (b) CIFAR-100, (c) Caltech-101, and (d) Multi-PIE. 'Superclass info.' in (b) and 'Pose' column in (d) represent the use of auxiliary pose information, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Accuracy (%)</p><p>AlexNet <ref type="bibr" target="#b14">[16]</ref> 78.6 GoogLeNet <ref type="bibr" target="#b25">[27]</ref> 88.7 VGG-16 <ref type="bibr" target="#b24">[26]</ref> 88.8 Magnet <ref type="bibr" target="#b20">[22]</ref> 89.4</p><p>Ours (AlexNet) 83.2 Ours (VGG- <ref type="bibr" target="#b14">16)</ref> 90.5</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(a)</head><p>Method Accuracy (%)</p><p>Maxout pooling <ref type="bibr" target="#b5">[7]</ref> 61.4 NiN <ref type="bibr" target="#b16">[18]</ref> 64.3 DSN <ref type="bibr" target="#b15">[17]</ref> 65.4 DDN <ref type="bibr" target="#b17">[19]</ref> 68.3 NiN+Superclass info. <ref type="bibr" target="#b4">[6]</ref> 68.8</p><p>Ours (NiN) 68.8 Ours (NiN + Superclass info.) 69.0</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(b)</head><p>Method Accuracy (%)</p><p>Zeiler <ref type="bibr" target="#b31">[33]</ref> 86.5 AlexNet <ref type="bibr" target="#b14">[16]</ref> 87.1 LCN (AlexNet) <ref type="bibr" target="#b9">[11]</ref> 90.1 VGG-16 <ref type="bibr" target="#b24">[26]</ref> 92.5 LCN (VGG-16) <ref type="bibr" target="#b9">[11]</ref> 93.7</p><p>Ours (AlexNet) 90.5 Ours (VGG- <ref type="bibr" target="#b14">16)</ref> 94.2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(c)</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method Accuracy Pose</head><p>Fisher Vector <ref type="bibr" target="#b23">[25]</ref> 66.60 FIP 20 <ref type="bibr" target="#b33">[35]</ref> 67.87 FIP 40 <ref type="bibr" target="#b33">[35]</ref> 70.90 CNN 40 <ref type="bibr" target="#b28">[30]</ref> 70.81 c-CNN <ref type="bibr" target="#b28">[30]</ref> 73.54 c-CNN Forest <ref type="bibr" target="#b28">[30]</ref> 76.89  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We presented a new convolutional neural network architecture and the corresponding training process called deep convolutional decision jungles, which shares the benefits of decision jungles and CNNs: class-wise purity at each node is maximized while end-to-end feature learning and classification are facilitated based on a single unified criteria. Compared to existing combinations of decision graphs and CNNs (e.g., c-CNN Forests <ref type="bibr" target="#b28">[30]</ref>), our model offers higher flexibility in routing data and enables to exploit large-scale CNN architectures, thereby leading to enhanced performance and interpretability.   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Schematic diagram of the proposed convolutional decision jungle (b) compared to the binary tree+CNN architecture of [30] (a). Green arrows represent the routing where the degrees of soft routing are represented by their thickness. In (a), hard binary decisions are made by external routing networks (orange balls).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>(l) k instead. If the filter w(l) j,k produces a non-zero response map R (l) k , x is interpreted as being softly routed to the node R (l) k .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>j</head><label></label><figDesc>(x i ;W)). The joint distribution C (l) h j (W) is a two-dimensional array storing the relative frequencies of patterns activated at each pair of response j and class index h.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 2 :</head><label>2</label><figDesc>Examples response maps C (l) h j (W) in our CDJ: a toy example with C =3 and R l =6. (a) C (l) h j (W) trained using only the softmax loss (the original CNN responses; λ 1 =λ 2 =0); (b) and (c) the probability maps that minimize C (Eq. 2); Both (b) and (c) achieve smaller entropy values than (a) by suppressing a specific class (Y =3) in (b). However, the way of (b) is not desirable and we propose the Label balancing constraint in Eq. 2. The introduced Label balancing constraint makes the sum of each labels similar; thus the non-generate map as (c) could be obtained. (d) and (e) denotes the C (l)h j (W) from the 13-th convolutional layers (w/ 512 responses) from the vanilla VGG-16 and CDJ network trained on Oxford-IIIT Pet (w/ 37 classes). (e) has more peaks in each class labels compared to (d). This shows that filters in CDJ respond to input semantics more sensitively than those of vanilla networks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 3 (</head><label>3</label><figDesc>b-d) show the performance variation of the CDJ under hyper-parameter changes (Oxford-IIIT Pet): (b) and (c) show test accuracy variations with changes in epoch, and hyper-parameters λ 1 and λ 2 , respectively; (d) shows the average entropy of each layer in CNNs and CDJs, respectively:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 3 :</head><label>3</label><figDesc>AlexNet results on Multi-PIE (a) and Oxford-IIIT Pet (b-d) datasets. (a) accuracy per human face over varying pose (out-of-plane horizontal rotation range); (b) test accuracy with respect to epoch: Our algorithm converges faster as guided by the new entropy energy; (c) test accuracy with varying hyper-parameters λ 1 and λ 2 ; The performance of our algorithm varies smoothly and predicatively; (d) average entropy of each layer in CNNs and CDJ: For both networks, entropy lowers toward the output layers. CDJ shows consistently lower entropy than CNN, especially at early layers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Comparison to previous works that combine decision trees and CNN networks. Our algorithm does not require external routing networks, applicable to large-scale networks and straightforwardly incorporate auxiliary information.</figDesc><table><row><cell>[4] [14] [30] [9] Ours</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Ensembled accuracies and interpretability scores<ref type="bibr" target="#b0">[2]</ref> on Oxford-IIIT Pet dataset.</figDesc><table><row><cell>Method</cell><cell cols="3">Accuracy (%) Interpretablity Method</cell><cell cols="2">Accuracy (%) Interpretablity</cell></row><row><cell>AlexNet [16] VGG-16 [26]</cell><cell>87.1 92.3</cell><cell>0.212 0.272</cell><cell>Ours (AlexNet) Ours (VGG-16)</cell><cell>89.5 94.1</cell><cell>0.254 0.316</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">© 2018. The copyright of this document resides with its authors. It may be distributed unchanged freely in print or electronic forms.arXiv:1706.02003v2 [cs.CV] 18 May 2018</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The weight vectors of the fully-connected layers are regarded as convolution filters of size 1.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work is in part supported by EPSRC program grant FACER2VM (EP/N007743/1). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Network dissection: Quantifying interpretability of deep visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Conditional computation in neural networks for faster models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-L</forename><surname>Bacon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Precup</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICLR workshop track</title>
		<meeting>ICLR workshop track</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Neural decision forests for semantic image labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bulò</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kontschieder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">One-shot learning of object categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Taxonomy-regularized semantic deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Goo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Hwang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Maxout networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Multi-pie. Image and Vision Computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Baker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Decision forests, convolutional networks and the models in-between</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ioannou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zikic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kontschieder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
		<idno>ArXiv 1603.01250</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep roots: Improving cnn efficiency with hierarchical filter groups</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ioannou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cipolla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning discriminative features via label consistent neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuolin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaming</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walt</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viktor</forename><surname>Rozgic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. WACV</title>
		<meeting>WACV</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">SplitNet: Learning to semantically split deep networks for parameter reduction and model parallelization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Hwang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Escape from cells deep kd-networks for the recognition of 3d point cloud models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Klokov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep neural decision forests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kontschieder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fiterau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bulò</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
		<respStmt>
			<orgName>University of Toronto</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deeply-supervised nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AISTATS</title>
		<meeting>AISTATS</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Network in network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep decision network for multi-class image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">N</forename><surname>Murthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Manmatha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Comaniciu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Synthesizing the preferred inputs for neurons in neural networks via deep generator networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yosinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Clune</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Cats and dogs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">M</forename><surname>Parkhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">V</forename><surname>Jawahar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Metric learning with adaptive density discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Rippel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Paluri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bourdev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Outrageously large neural networks: The sparsely-gated mixture-of-experts layer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mirhoseini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Maziarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Decision jungles: compact and rich models for classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sharp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Fisher vector faces in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">M</forename><surname>Parkhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. BMVC</title>
		<meeting>BMVC</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Improved semantic representations from tree-structured long short-term memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">S</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A discriminative feature learning approach for deep face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Conditional convolutional neural network for modality-aware face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Jayashree</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T-K</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">HD-CNN: Hierarchical deep convolutional neural network for large-scale visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Piramuthu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Jagadeesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Decoste</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Di</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Joint unsupervised learning of deep representations and image clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Visualizing and understanding convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Object detectors emerge in deep scene cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Deep learning identity-preserving face space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
