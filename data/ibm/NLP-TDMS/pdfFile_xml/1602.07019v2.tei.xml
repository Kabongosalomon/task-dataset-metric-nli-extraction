<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Sentence Similarity Learning by Lexical Decomposition and Composition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
							<email>zhigwang@us.ibm.com</email>
							<affiliation key="aff0">
								<orgName type="institution">IBM T.J. Watson Research Center Yorktown Heights</orgName>
								<address>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haitao</forename><surname>Mi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IBM T.J. Watson Research Center Yorktown Heights</orgName>
								<address>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abraham</forename><surname>Ittycheriah</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IBM T.J. Watson Research Center Yorktown Heights</orgName>
								<address>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Sentence Similarity Learning by Lexical Decomposition and Composition</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Most conventional sentence similarity methods only focus on similar parts of two input sentences, and simply ignore the dissimilar parts, which usually give us some clues and semantic meanings about the sentences. In this work, we propose a model to take into account both the similarities and dissimilarities by decomposing and composing lexical semantics over sentences. The model represents each word as a vector, and calculates a semantic matching vector for each word based on all words in the other sentence. Then, each word vector is decomposed into a similar component and a dissimilar component based on the semantic matching vector. After this, a two-channel CNN model is employed to capture features by composing the similar and dissimilar components. Finally, a similarity score is estimated over the composed feature vectors. Experimental results show that our model gets the state-of-the-art performance on the answer sentence selection task, and achieves a comparable result on the paraphrase identification task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Sentence similarity is a fundamental metric to measure the degree of likelihood between a pair of sentences. It plays an important role for a variety of tasks in both NLP and IR communities. For example, in paraphrase identification task, sentence similarity is used to determine whether two sentences are paraphrases or not (Yin and Schütze, 2015;<ref type="bibr" target="#b5">He et al., 2015)</ref>. For question answering and information retrieval tasks, sentence similarities between query-answer pairs are used for assessing the relevance and ranking all the candidate answers <ref type="bibr" target="#b16">(Severyn and Moschitti, 2015;</ref><ref type="bibr" target="#b17">Wang and Ittycheriah, 2015)</ref>.</p><p>However, sentence similarity learning has following challenges:</p><p>1. There is a lexical gap between semantically equivalent sentences. Take the E 1 and E 2 in <ref type="table">Table 1</ref> for example, they have the similar meaning but with different lexicons.</p><p>2. Semantic similarity should be measured at different levels of granularity (word-level, phrase-level and syntax-level). E.g., "not related" in E 2 is an indivisible phrase when matching with "irrelevant" in E 1 (shown in square brackets).</p><p>3. The dissimilarity (shown in angle brackets) between two sentences is also a significant clue <ref type="bibr" target="#b14">(Qiu et al., 2006)</ref>. For example, by judging the dissimilar parts, we can easily identify that E 3 and E 5 share the similar meaning "The study is about salmon", because "sockeye" belongs to the salmon family, and "flounder" does not. Whereas the meaning of E 4 is quite different from E 3 , which emphasizes "The study is about red (a special kind of) salmon", because both "sockeye" and "coho" are in the salmon family. How we can extract and utilize those information becomes another challenge.</p><p>In order to handle the above challenges, researchers have been working on sentence similarity algorithms for a long time. To bridge the lexical gap (challenge 1), some word similarity metrics were proposed to match different but semantically related words. Examples include knowledge-based metrics <ref type="bibr" target="#b15">(Resnik, 1995)</ref> and corpus-based metrics <ref type="bibr" target="#b8">(Jiang and Conrath, 1997;</ref> Yin and Schütze, 2015;<ref type="bibr" target="#b5">He et al., 2015)</ref>. To measure sentence similarity from various granularities (challenge 2), researchers have explored features extracted from n-grams, continuous phrases, discontinuous phrases, and parse trees (Yin  and Schütze, 2015;<ref type="bibr" target="#b5">He et al., 2015;</ref><ref type="bibr" target="#b6">Heilman and Smith, 2010)</ref>. The third challenge did not get much arXiv:1602.07019v2 [cs.CL] 14 Jul 2017 E1 The research is [irrelevant] to sockeye. E2 The study is [not related] to salmon. E3 The research is relevant to salmon. E4 The study is relevant to sockeye, instead of coho . E5 The study is relevant to sockeye, rather than flounder .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="table">Table 1</ref><p>: Examples for sentence similarity learning, where sockeye means "red salmon", and coho means "silver salmon". "coho" and "sockeye" are in the salmon family, while "flounder" is not. attention in the past, the only related work of <ref type="bibr" target="#b14">Qiu et al. (2006)</ref> explored the dissimilarity between sentences in a pair for paraphrase identification task, but they require human annotations in order to train a classifier, and their performance is still below the state of the art.</p><p>In this paper, we propose a novel model to tackle all these challenges jointly by decomposing and composing lexical semantics over sentences. Given a sentence pair, the model represents each word as a low-dimensional vector (challenge 1), and calculates a semantic matching vector for each word based on all words in the other sentence (challenge 2). Then based on the semantic matching vector, each word vector is decomposed into two components: a similar component and a dissimilar component (challenge 3). We use similar components of all the words to represent the similar parts of the sentence pair, and dissimilar components of every word to model the dissimilar parts explicitly. After this, a two-channel CNN operation is performed to compose the similar and dissimilar components into a feature vector (challenge 2 and 3). Finally, the composed feature vector is utilized to predict the sentence similarity. Experimental results on two tasks show that our model gets the state-of-the-art performance on the answer sentence selection task, and achieves a comparable result on the paraphrase identification task.</p><p>In following parts, we start with a brief overview of our model (Section 2), followed by the details of our end-to-end implementation (Section 3). Then we evaluate our model on answer sentence selection and paraphrase identifications tasks (Section 4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model Overview</head><p>In this section, we propose a sentence similarity learning model to tackle all three challenges (mentioned in Section 1). To deal with the first challenge, we represent each word as a distributed vector, so that we can calculate similarities for formally different but semantically related words. To tackle the second challenge, we assume that each word can be semantically matched by several words in the other sentence, and we calculate a semantic matching vector for each word vector based on all the word vectors in the other side. To cope with the third challenge, we assume that each semantic unit (word) can be partially matched, and can be decomposed into a similar component and a dissimilar component based on its semantic matching vector. <ref type="figure" target="#fig_0">Figure 1</ref> shows an overview of our sentence similarity model. Given a pair of sentences S and T , our task is to calculate a similarity score sim(S, T ) in following steps:</p><p>Word Representation. Word embedding of <ref type="bibr" target="#b13">Mikolov et al. (2013)</ref> is an effective way to handle the lexical gap challenge in the sentence similarity task, as it represents each word with a distributed vector, and words appearing in similar contexts tend to have similar meanings <ref type="bibr" target="#b13">(Mikolov et al., 2013)</ref>. With those pre-trained embeddings, we transform S and T into sentence matrixes S = [s 1 , ..., s i , ..., s m ] and T = [t 1 , ..., t j , ..., t n ], where s i and t j are d-dimension vectors of the corresponding words, and m and n are sentence length of S and T respectively.</p><p>Semantic Matching. In order to judge the similarity between two sentences, we need to check whether each semantic unit in one sentence is covered by the other sentence, or vice versa. For example, in <ref type="table">Table 1</ref>, to check whether E 2 is a paraphrase of E 1 , we need to know the single word "irrelevant" in E 1 is matched or covered by the phrase "not related" in E 2 . In our model, we treat each word as a primitive semantic unit, and calculate a semantic matching vectorŝ i for each word s i by composing part or full word vectors in the other sentence T . In this way, we can match a word s i to a word or phrase in T .  Similarly, for the reverse direction, we also calculate all semantic matching vectorst j in T .</p><formula xml:id="formula_0">s i = f match (s i , T ) ∀s i ∈ Ŝ t j = f match (t j , S) ∀t j ∈ T<label>(1)</label></formula><p>We explore different f match functions later in Section 3. Decomposition. After the semantic matching phase, we have the semantic matching vectors ofŝ i and t j . We interpretŝ i (ort j ) as a semantic coverage of word s i (or t j ) by the sentence T (or S). However, it is not necessary that all the semantics of s i (or t j ) are fully covered byŝ i (ort j ). Take the E 1 and E 2 in <ref type="table">Table 1</ref> for example, the word "sockeye" in E 1 is only partially matched by the word "salmon" (the similar part) in E 2 , as the full meaning of "sockeye" is "red salmon" (the semantic meaning of "red" is the dissimilar part). Motivated by this phenomenon, our model further decomposes word s i (or t j ), based on its semantic matching vectorŝ i (ort j ), into two components: similar component s + i (or t + j ) and dissimilar component s − i (or t − j ). Formally, we define the decomposition function as: </p><formula xml:id="formula_1">[s + i ; s − i ] = f decomp (s i ,ŝ i ) ∀s i ∈ S [t + j ; t − j ] = f decomp (t j ,t j ) ∀t j ∈ T<label>(2)</label></formula><formula xml:id="formula_2">− = [s − 1 , ..., s − m ] (or T − = [t − 1 , ..., t −<label>n</label></formula><p>]), our goal in this step is how to utilize those information. Besides the suggestion from <ref type="bibr" target="#b14">Qiu et al. (2006)</ref> that the significance of the dissimilar parts alone between two sentences has a great effect of their similarity, we also think that the dissimilar and similar components have strong connections. For example, in <ref type="table">Table 1</ref>, if we only look at the dissimilar or similar part alone, it is hard to judge which one between E 4 and E 5 is more similar to E 3 . We can easily identify that E 5 is more similar to E 3 , when we consider both the similar and dissimilar parts. Therefore, our model composes the similar component matrix and dissimilar component matrix into a feature vector S (or T ) with the composition function:</p><formula xml:id="formula_3">S = f comp (S + , S − ) T = f comp (T + , T − ) (3)</formula><p>Similarity assessing. In the final stage, we concatenate the two feature vectors ( S and T ) and predict the final similarity score:</p><formula xml:id="formula_4">sim(S, T ) = f sim ( S, T )<label>(4)</label></formula><p>3 An End-to-End Implementation Section 2 gives us a glance of our model. In this section, we describe details of each phase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Semantic Matching Functions</head><p>This subsection describes our specifications for the semantic matching function f match in Eq.</p><p>(1). The goal of f match is to generate a semantic matching vectorŝ i for s i by composing the vectors from T . For a sentence pair S and T , we first calculate a similarity matrix A m×n , where each element a i,j ∈ A m×n computes the cosine similarity between words s i and t j as</p><formula xml:id="formula_5">a i,j = s T i t j s i · t j ∀s i ∈ S, ∀t j ∈ T.<label>(5)</label></formula><p>Then, we define three different semantic matching functions over A m×n :</p><formula xml:id="formula_6">f match (s i , T ) =          n j=0 a i,j t j n j=0 a i,j global k+w j=k−w a i,j t j k+w j=k−w a i,j local-w t k max<label>(6)</label></formula><p>where k = argmax j a i,j . The idea of the global function is to consider all word vectors t j in T . A semantic matching vectorŝ i is a weighted sum vector of all words t j in T , where each weight is the normalized word similarity a i,j . The max function moves to the other extreme. It generates the semantic matching vector by selecting the most similar word vector t k from T . The local-w function takes a compromise between global and max, where w indicates the size of the window to consider centered at k (the most similar word position). So the semantic matching vector is a weighted average vector from t k−w to t k+w .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Decomposition Functions</head><p>This subsection describes the implementations for the decomposition function f decomp in Eq.</p><p>(2). The intention of f decomp is to decompose a word vector s j based on its semantic matching vectorŝ j into a similar component s + i and a dissimilar component s − i , where s + i indicates the semantics of s i covered byŝ i and s − i indicates the uncovered part. We implement three types of decomposition function: rigid, linear and orthogonal.</p><p>The rigid decomposition only adapts to the max version of f match . First, it detects whether there is an exactly matched word in the other sentence, or s i equal toŝ i . If yes, the vector s i is dispatched to the similar component s + i , and the dissimilar component is assigned with a zero vector 0. Otherwise, the vector s i is assigned to the dissimilar component s − i . Eq. <ref type="formula" target="#formula_7">(7)</ref> gives the formal definition:</p><formula xml:id="formula_7">[s + i = s i ; s − i = 0] if s i =ŝ i [s + i = 0; s − i = s i ] otherwise<label>(7)</label></formula><p>The motivation for the linear decomposition is that the more similar between s i andŝ i , the higher proportion of s i should be assigned to the similar component. First, we calculate the cosine similarity α between s i andŝ i . Then, we decompose s i linearly based on α. Eq. <ref type="formula">(8)</ref> gives the corresponding definition:</p><formula xml:id="formula_8">α = s T iŝ i s i · ŝ i s + i = αs i s − i = (1 − α)s i (8)</formula><p>The orthogonal decomposition is to decompose a vector in the geometric space. Based on the semantic matching vectorŝ i , our model decomposes s i into a parallel component and a perpendicular component. Then, the parallel component is viewed as the similar component s + i , and perpendicular component is taken as the dissimilar component s − i . Eq. <ref type="formula">(9)</ref> gives the concrete definitions.</p><formula xml:id="formula_9">s + i = s i ·ŝ î s i ·ŝ iŝ i parallel s − i = s i − s + i perpendicular (9)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Composition Functions</head><p>The aim of composition function f comp in Eq. <ref type="formula">(3)</ref> is to extract features from both the similar component matrix and the dissimilar component matrix. We also want to acquire similarities and dissimilarities of various granularity during the composition phase. Inspired from Kim <ref type="formula" target="#formula_0">(2014)</ref>, we utilize a two-channel convolutional neural networks (CNN) and design filters based on various order of n-grams, e.g., unigram, bigram and trigram. The CNN model involves two sequential operations: convolution and max-pooling. For the convolution operation, we define a list of filters {w o }. The shape of each filter is d × h, where d is the dimension of word vectors and h is the window size. Each filter is applied to two patches (a window size h of vectors) from both similar and dissimilar channels, and generates a feature. Eq. (10) expresses this process. To deal with variable feature size, we perform a max-pooling operation over c o by selecting the maximum value c o = max c o . Therefore, after these two operations, each filter generates only one feature. We define several filters by varying the window size and the initial values. Eventually, a vector of features is captured by composing the two component matrixes, and the feature dimension is equal to the number of filters.</p><formula xml:id="formula_10">c o,i = f (w o * S + [i:i+h] + w o * S − [i:i+h] + b o )<label>(10)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Similarity Assessment Function</head><p>The similarity assessment function f sim in Eq. (4) predicts a similarity score by taking two feature vectors as input. We employ a linear function to sum up all the features and apply a sigmoid function to constrain the similarity within the range [0, 1].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Training</head><p>We train our sentence similariy model by maximizing the likelihood on a training set. Each training instance in the training set is represented as a triple (S i , T i , L i ), where S i and T i are a pair of sentences, and L i ∈ {0, 1} indicates the similarity between them. We assign L i = 1 if T i is a paraphrase of S i for the paraphrase identification task, or T i is a correct answer for S i for the answer sentence selection task. Otherwise, we assign L i = 0. We implement the mathematical expressions with Theano <ref type="bibr" target="#b1">(Bastien et al., 2012)</ref> and use Adam <ref type="bibr" target="#b10">(Kingma and Ba, 2014)</ref> for optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setting</head><p>We evaluate our model on two tasks: answer sentence selection and paraphrase identification. The answer sentence selection task is to rank a list of candidate answers based on their similarities to a question sentence, and the performance is measured by mean average precision (MAP) and mean reciprocal rank (MRR). We experiment on two datasets: QASent and WikiQA. The statistics of the two datasets can be found in <ref type="bibr" target="#b19">Yang et al. (2015)</ref>, where QASent <ref type="bibr" target="#b18">(Wang et al., 2007)</ref> was created from the TREC QA track, and WikiQA <ref type="figure" target="#fig_0">(Yang et al., 2015)</ref> is constructed from real queries of Bing and Wikipedia. The paraphrase identification task is to detect whether two sentences are paraphrases based on the similarity between them. The metrics include the accuracy and the positive class F 1 score. We experiment on the Microsoft Research Paraphrase corpus (MSRP) <ref type="bibr" target="#b2">(Dolan et al., 2004)</ref>, which includes 2753 true and 1323 false instances in the training set, and 1147 true and 578 false instances in the test set. We build a development set by randomly selecting 100 true and 100 false instances from the training set. In all experiments, we set the size of word vector dimension as d =300, and pre-train the vectors with the word2vec toolkit <ref type="bibr" target="#b13">(Mikolov et al., 2013)</ref> on the English Gigaword (LDC2011T07).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Model Properties</head><p>There are several alternative options in our model, e.g., the semantic matching functions, the decomposition operations, and the filter types. The choice of these options may affect the final performance. In this subsection, we present some experiments to demonstrate the properties of our model, and find a good configuration that we use to evaluate our final model. All the experiments in this subsection were performed on the QASent dataset and evaluated on the development set.</p><p>First, we evaluated the effectiveness of various semantic matching functions. We switched the semantic matching functions among {max, global, local-l}, where l ∈ {1, 2, 3, 4}, and fixed the other options as: the linear decomposition, the filter types including {unigram, bigram, trigram}, and 500 filters for each type. <ref type="figure">Figure 2 (a)</ref> presents the results. We found that the max function worked better than the global function on both MAP and MRR. By increasing the window size, the local-l function acquired progressive improvements when the window size is smaller than 4. But after we enlarged the window size to 4, the performance dropped. The local-3 function worked better than the max function in term of the MAP, and also got a comparable MRR. Therefore, we use the local-3 function in the following experiments.</p><p>Second, we studied the effect of various decomposition operations. We varied the decomposition operation among {rigid, linear, orthogonal}, and kept the other options unchanged. <ref type="figure">Figure 2 (b)</ref> shows the performance. We found that the rigid operation got the worst result. This is reasonable, because the rigid operation decomposes word vectors by exactly matching words. The orthogonal operation got a similar MAP as the linear operation, and it worked better in term of MRR. Therefore, we choose the orthogonal operation in the following experiments.</p><p>Third, we tested the influence of various filter types. We constructed 5 groups of filters: win-1 contains only the unigram filters, win-2 contains both unigram and bigram filters, win-3 contains all the filters in win-2 plus trigram filters, win-4 extends filters in win-3 with 4-gram filters, and win-5 adds 5-gram filters into win-4. We generate 500 filters for each filter type (with different initial values). Experimental results are shown in <ref type="figure">Figure 2 (c)</ref>. At the beginning, adding higher-order ngram filters was helpful for the performance. The performance reached to the peak, when we used the win-3 filters. After that, adding more complex filters decreased the performance. Therefore, the trigram is the best granularity for our model. In the following experiments, we utilize filter types in win-3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Comparing with State-of-the-art Models</head><p>In this subsection, we evaluated our model on the test sets of QASent, WikiQA and MSRP.</p><p>QASent dataset. <ref type="table" target="#tab_2">Table 2</ref> presents the performances of the state-of-the-art systems and our model, where the performances were evaluated with the standard trec eval-8.1 script 1 . Given a pair of sentences,   Severyn and Moschitti (2015) employed a CNN model to compose each sentence into a vector separately, and joined the two sentence vectors to compute the sentence similarity. Because only the sentencelevel granularity was used, the performance is much lower (the second row of <ref type="table" target="#tab_2">Table 2</ref>). After adding some word overlap features between the two sentences, the performance was improved significantly (the third row of <ref type="table" target="#tab_2">Table 2</ref>). Therefore, the lower-level granularity is an indispensable factor for a good performance. <ref type="bibr" target="#b17">Wang and Ittycheriah (2015)</ref> conducted word alignment for a sentence pair based on word vectors, and measured the sentence similarity based on a couple of word alignment features. They got a slightly better performance (the fourth row of <ref type="table" target="#tab_2">Table 2</ref>), which indicates that the vector representation for words is helpful to bridging the lexical gap problem. dos <ref type="bibr" target="#b3">Santos et al. (2016)</ref> introduced the attention mechanism into the CNN model, and learnt sentence representation by considering the influence of the other sentence. They got better performance than all the other previous work. Our model makes use of all these useful factors and also considers the dissimilarities of a sentence pair. We can see that our model (the last row of  <ref type="table" target="#tab_3">Table 3</ref> presents the results of our model and several state-of-the-art models. <ref type="bibr" target="#b19">Yang et al. (2015)</ref> constructed the dataset and reimplemented several baseline models. The best performance (shown at the second row of <ref type="table" target="#tab_3">Table 3</ref>) was acquired by a bigram CNN model combining with the word overlap features. <ref type="bibr" target="#b12">Miao et al. (2015)</ref> models the sentence similarity by enriching LSTMs with a latent stochastic attention mechanism. The corresponding performance is given at the fourth row of <ref type="table" target="#tab_3">Table  3</ref>. <ref type="bibr" target="#b21">Yin et al. (2015)</ref> introduced the attention mechanism into the CNN model, and captured the best performance (the fifth row of <ref type="table" target="#tab_3">Table 3</ref>). The semantic matching phase in our model is similar to the attention mechanism. But different from the previous models, our model utilizes both the similarity and dissimilarity simultaneously. The last row of <ref type="table" target="#tab_3">Table 3</ref> shows that our model is more effective than the other models.</p><p>MSRP dataset.  granularity and modeled interaction features at each level for a pair of sentences. They obtained their best performance by pretraining the model on a language modeling task (the 3rd row of <ref type="table" target="#tab_6">Table 4</ref>). However, their model heavily depends on the pretraining strategy. Without pretraining, they got a much worse performance (the second row of <ref type="table" target="#tab_6">Table 4</ref>). <ref type="bibr" target="#b5">He et al. (2015)</ref> proposed a similar model to <ref type="bibr">Yin and Schütze (2015)</ref>. Similarly, they also used a CNN model to extract features at multiple levels of granularity.</p><p>Differently, they utilized some extra annotated resources, e.g., embeddings from part-of-speech (POS) tags and PARAGRAM vectors trained from the Paraphrase Database <ref type="bibr" target="#b4">(Ganitkevitch et al., 2013)</ref>. Their model outperformed Yin and Schütze <ref type="formula" target="#formula_0">(2015)</ref> without the need of pretraining (the sixth row of <ref type="table" target="#tab_6">Table 4</ref>). However, the performance was reduced after removing the extra resources (the fourth and fifth rows of <ref type="table" target="#tab_6">Table 4</ref>). Yin et al. <ref type="formula" target="#formula_0">(2015)</ref> applied their attention-based CNN model on this dataset. By adding a couple of sparse features and using a layerwise training strategy, they got a pretty good performance. Comparing to these neural network based models, our model obtained a comparable performance (the last row of <ref type="table" target="#tab_6">Table  4</ref>) without using any sparse features, extra annotated resources and specific training strategies. However, the best performance so far on this dataset is obtained by <ref type="bibr" target="#b7">Ji and Eisenstein (2013)</ref>. In their model, they just utilized several hand-crafted features in a Support Vector Machine (SVM) model. Therefore, the deep learning methods still have a long way to go for this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>The semantic matching functions in subsection 3.1 are inspired from the attention-based neural machine translation <ref type="bibr" target="#b0">(Bahdanau et al., 2014;</ref><ref type="bibr" target="#b11">Luong et al., 2015)</ref>. However, most of the previous work using the attention mechanism in only LSTM models. Whereas our model introduces the attention mechanism into the CNN model. A similar work is the attention-based CNN model proposed by <ref type="bibr" target="#b21">Yin et al. (2015)</ref>. They first build an attention matrix for a sentence pair, and then directly take the attention matrix as a new channel of the CNN model. Differently, our model uses the attention matrix (or similarity matrix) to decompose the original sentence matrix into a similar component matrix and a dissimilar component matrix, and then feeds these two matrixes into a two-channel CNN model. The model can then focus much on the interactions between similar and dissimilar parts of a sentence pair.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this work, we proposed a model to assess sentence similarity by decomposing and composing lexical semantics. To bridge the lexical gap problem, our model represents each word with its context vector. To extract features from both the similarity and dissimilarity of a sentence pair, we designed several methods to decompose the word vector into a similar component and a dissimilar component. To extract features at multiple levels of granularity, we employed a two-channel CNN model and equipped it with multiple types of ngram filters. Experimental results show that our model is quite effective on both the answer sentence selection task and the paraphrase identification task .</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Model overview.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>where the operation A * B sums up all elements in B with the corresponding weights in A, S + [i:i+h] and S − [i:i+h] indicate the patches from S + and S − , b o is a bias term and f is a non-linear function (we use tanh in this work). We apply this filter to all possible patches, and produce a series of features c o = [c o,1 , c o,2 , ..., c o,O ]. The number of features in c o depends on the shape of the filter w o and the length of the input sentence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Figure 2: Influence of different configuration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Results on the QASent dataset.</figDesc><table><row><cell>Models</cell><cell>MAP</cell><cell>MRR</cell></row><row><cell>Yang et al. (2015) (2-gram CNN)</cell><cell cols="2">0.6520 0.6652</cell></row><row><cell>dos Santos et al. (2016) (Attention-based CNN)</cell><cell cols="2">0.6886 0.6957</cell></row><row><cell>Miao et al. (2015) (Attention-based LSTM)</cell><cell cols="2">0.6886 0.7069</cell></row><row><cell>Yin et al. (2015) (Attention-based CNN)</cell><cell cols="2">0.6921 0.7108</cell></row><row><cell>This work</cell><cell cols="2">0.7058 0.7226</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Results on the WikiQA dataset.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2</head><label>2</label><figDesc>) got the best MAP among all previous work, and a comparable MRR than dos<ref type="bibr" target="#b3">Santos et al. (2016)</ref>.WikiQA dataset.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Table 4summarized the results from our model and several state-of-the-art models. Yin and Schütze (2015) employed a CNN model to learn sentence representations on multiple level of</figDesc><table><row><cell>Models</cell><cell>Acc</cell><cell>F1</cell></row><row><cell cols="3">Yin and Schütze (2015) (without pretraining) 72.5 81.4</cell></row><row><cell>Yin and Schütze (2015) (with pretraining)</cell><cell cols="2">78.4 84.6</cell></row><row><cell>He et al. (2015) (without POS embeddings)</cell><cell cols="2">77.8 N/A</cell></row><row><cell>He et al. (2015) (without Para. embeddings)</cell><cell cols="2">77.3 N/A</cell></row><row><cell cols="3">He et al. (2015) (POS and Para. embeddings) 78.6 84.7</cell></row><row><cell>Yin et al. (2015) (with sparse features)</cell><cell cols="2">78.9 84.8</cell></row><row><cell>Ji and Eisenstein (2013)</cell><cell cols="2">80.4 86.0</cell></row><row><cell>This work</cell><cell cols="2">78.4 84.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Experimental results for paraphrase identification on MSRP corpus.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://trec.nist.gov/trec eval/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the anonymous reviewers for useful comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>References</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bahdanau</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.0473</idno>
		<title level="m">Neural machine translation by jointly learning to align and translate</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Bastien</surname></persName>
		</author>
		<title level="m">Theano: new features and speed improvements. Deep Learning and Unsupervised Feature Learning NIPS 2012 Workshop</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th international conference on Computational Linguistics</title>
		<meeting>the 20th international conference on Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page">350</biblScope>
		</imprint>
	</monogr>
	<note>Bill Dolan, Chris Quirk, and Chris Brockett</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Santos</forename><surname>Dos</surname></persName>
		</author>
		<title level="m">Cícero Nogueira dos Santos, Ming Tan, Bing Xiang, and Bowen Zhou. 2016. Attentive pooling networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Ppdb: The paraphrase database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Ganitkevitch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="758" to="764" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multi-perspective sentence similarity modeling with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1576" to="1586" />
		</imprint>
	</monogr>
	<note>Hua He, Kevin Gimpel, and Jimmy Lin</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Tree edit models for recognizing textual entailments, paraphrases, and answers to questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Smith2010] Michael</forename><surname>Heilman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Heilman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1011" to="1019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Discriminative improvements to distributional sentence similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="891" to="896" />
		</imprint>
	</monogr>
	<note>Ji and Eisenstein2013</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">W</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Conrath</surname></persName>
		</author>
		<idno>cmp-lg/9709008</idno>
		<title level="m">Semantic similarity based on corpus statistics and lexical taxonomy</title>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1746" to="1751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representation (ICLR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Kingma and Ba2014</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Effective approaches to attention-based neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Luong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1508.04025</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Miao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06038</idno>
		<title level="m">Neural variational inference for text processing</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Paraphrase recognition via dissimilarity significance classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2006 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="18" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Using information content to evaluate semantic similarity in a taxonomy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
		<idno>cmp-lg/9511007</idno>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning to rank short text pairs with convolutional deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aliaksei</forename><surname>Severyn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Moschitti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="373" to="382" />
		</imprint>
	</monogr>
	<note>Severyn and Moschitti2015</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ittycheriah2015] Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abraham</forename><surname>Ittycheriah</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1507.02628</idno>
		<title level="m">Faq-based question answering via word alignment</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">What is the jeopardy model? a quasi-synchronous grammar for qa</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-CoNLL</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="22" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Wikiqa: A challenge dataset for opendomain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Convolutional neural network for paraphrase identification</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="901" to="911" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Abcnn: Attention-based convolutional neural network for modeling sentence pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Wenpeng Yin, Hinrich Schütze, Bing Xiang, and Bowen Zhou</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
