<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Unified System for Aggression Identification in English Code-Mixed and Uni-Lingual Texts</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anant</forename><surname>Khandelwal</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">M.Tech</orgName>
								<orgName type="institution">IIT Delhi Bangalore</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niraj</forename><surname>Kumar</surname></persName>
							<email>nirajrkumar@gmail.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Conduent Labs</orgName>
								<address>
									<addrLine>PhD, IIIT-Hyderabad</addrLine>
									<settlement>Bangalore</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Unified System for Aggression Identification in English Code-Mixed and Uni-Lingual Texts</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3371158.3371165</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T08:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>English code-mixed Text</term>
					<term>Deep Pyramid CNN</term>
					<term>Disconnected RNN</term>
					<term>Pooled BiLSTM</term>
					<term>Model Averaging</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Wide usage of social media platforms has increased the risk of aggression, which results in mental stress and affects the lives of people negatively like psychological agony, fighting behavior, and disrespect to others. Majority of such conversations contains codemixed languages <ref type="bibr" target="#b27">[28]</ref>. Additionally, the way used to express thought or communication style also changes from one social media platform to another platform (e.g., communication styles are different in twitter and Facebook). These all have increased the complexity of the problem. To solve these problems, we have introduced a unified and robust multi-modal deep learning architecture which works for English code-mixed dataset and uni-lingual English dataset both. The devised system, uses psycho-linguistic features and very basic linguistic features. Our multi-modal deep learning architecture contains, Deep Pyramid CNN, Pooled BiLSTM, and Disconnected RNN(with Glove and FastText embedding, both). Finally, the system takes the decision based on model averaging. We evaluated our system on English Code-Mixed TRAC 1 2018 dataset and uni-lingual English dataset obtained from Kaggle 2 . Experimental results show that our proposed system outperforms all the previous approaches on English code-mixed dataset and uni-lingual English dataset.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The exponential increase of interactions on the various social media platforms has generated the huge amount of data on social media platforms like Facebook and Twitter, etc. These interactions 1 https://sites.google.com/view/trac1/home 2 https://www.kaggle.com/dataturks/dataset-for-detection-of-cybertrolls Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CoDS COMAD 2020, January 5-7, 2020, Hyderabad, India © 2020 Association for Computing Machinery. ACM ISBN 978-1-4503-7738-6/20/01. . . $15.00 https://doi.org/10.1145/3371158.3371165 resulted not only positive effect but also negative effect over billions of people owing to the fact that there are lots of aggressive comments (like hate, anger, and bullying). These cause not only mental and psychological stress but also account deactivation and even suicide <ref type="bibr" target="#b12">[13]</ref>. In this paper we concentrate on problems related to aggressiveness. The fine-grained definition of the aggressiveness/aggression identification is provided by the organizers of TRAC-2018 <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b27">28]</ref>. They have classified the aggressiveness into three labels (Overtly aggressive(OAG), Covertly aggressive(CAG), Non-aggressive(NAG)). The detailed description for each of the three labels is described as follows:</p><p>(1) Overtly Aggressive(OAG) -This type of aggression shows direct verbal attack pointing to the particular individual or group. For example, "Well said sonu..you have courage to stand against dadagiri of Muslims". (2) Covertly Aggressive(CAG) -This type of aggression the attack is not direct but hidden, subtle and more indirect while being stated politely most of the times. For example, "Dear India, stop playing with the emotions of your people for votes." (3) Non-Aggressive(NAG) -Generally these type of text lack any kind of aggression it is basically used to state facts, wishing on occasions and polite and supportive. The additional discussion on aggressiveness task can be found in Kaggle task <ref type="bibr" target="#b2">3</ref> , which just divided the task into two classes -i.e., presence or absence of aggression in tweets. The informal setting/environment of social media often encourage multilingual speakers to switch back and forth between languages when speaking or writing. These all resulted in "code-mixing" and "code-switching". Code-mixing refers to the use of linguistic units from different languages in a single utterance or sentence, whereas code-switching refers to the co-occurrence of speech extracts belonging to two different grammatical systems <ref type="bibr" target="#b8">[9]</ref>. This language interchange makes the grammar more complex and thus it becomes tough to handle it by traditional algorithms. Thus the presence of high percentage of code-mixed content in social media text has increased the complexity of the aggression detection task. For example, the dataset provided by the organizers of TRAC-2018 <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b27">28]</ref> is actually a code-mixed dataset. The massive increase of the social media data rendered the manual methods of content moderation difficult and costly. Machine Learning and Deep Learning methods to identify such phenomena have attracted more attention to the research community in recent years <ref type="bibr" target="#b25">[26]</ref>. Based on the current context, we can divide the problem into three sub-problems: (a) detection of aggression levels, (b) handling codemixed data and (c) handling styles (due to differences in social media platforms and text entry rules/restrictions). A lot of the previous approaches <ref type="bibr" target="#b26">[27]</ref> have used an ensemble model for the task. For example, some of them uses ensemble of statistical models <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b42">42]</ref> some used ensemble of statistical and deep learning models <ref type="bibr" target="#b40">[40,</ref><ref type="bibr" target="#b41">41,</ref><ref type="bibr" target="#b48">48]</ref> some used ensemble of deep learning models <ref type="bibr" target="#b28">[29]</ref>. There are approaches which proposed unified architecture based on deep learning <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b39">39]</ref> while some proposed unified statistical model <ref type="bibr" target="#b5">[6]</ref>. Additionally, there are some approaches uses data augmentation either through translation or labeling external data to make the model generalize across domains <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b41">41]</ref>. Most of the above-discussed systems either shows high performance on (a) Twitter dataset or (b) Facebook dataset (given in the TRAC-2018), but not on both English code-mixed datasets. This may be due to the text style or level of complexities of both datasets. So, we concentrated to develop a robust system for English code-mixed texts, and uni-lingual texts, which can also handle different writing styles. Our approach is based on three main ideas:</p><p>• Deep-Text Learning. The goal is to learn long range associations, dependencies between regions of text, N-grams, key-patterns, topical information, and sequential dependencies. • Exploiting psycho-linguistic features with basic linguistic features as meta-data. The main aim is to minimize the direct dependencies on in-depth grammatical structure of the language (i.e., to support code-mixed data). We have also included emoticons, and punctuation features with it. We use the term "NLP Features" to represent it in the entire paper. • Dual embedding based on FastText and Glove. This dual embedding helps in high vocabulary coverage and to capture the rare and partially incorrect words in the text (specially by FastText <ref type="bibr" target="#b30">[31]</ref>). Our "Deep-text architecture" uses model averaging strategy with three different deep learning architectures. Model averaging belongs to the family of ensemble learning techniques that uses multiple models for the same problem and combines their predictions to produce a more reliable and consistent prediction accuracy <ref type="bibr" target="#b21">[22]</ref>. This is the simplest form of weighted average ensemble based prediction <ref type="bibr" target="#b34">[35]</ref> where, each ensemble member contribute equally to predictions. Specifically in our case, three different models have been used. The following contains the intuition behind the selection of these three models:</p><p>(1) Deep Pyramid CNN <ref type="bibr" target="#b20">[21]</ref> being deeper helps to learn long range associations between temporal regions of text using two-view embeddings. (2) Disconnected RNN <ref type="bibr" target="#b50">[50]</ref> is very helpful in encoding the sequential information with temporal key patterns in the text. (3) Pooled BiLSTM In this architecture the last hidden state of BiLSTM is concatenated with mean and max-pooled representation of the hidden states obtained over all the time steps of Bi-LSTM. The idea of using mean and max pooling layers together is taken from <ref type="bibr" target="#b14">[15]</ref> to avoid the loss of information in longer sequences of texts and max-pooling is taken to capture the topical information <ref type="bibr" target="#b44">[44]</ref>.</p><p>(4) NLP Features In each of the individual models, the NLP features are concatenated with last hidden state before the softmax classification layer as meta-data. The main aim is to provide additional information to the deep learning network. The intuition behind the NLP features are the following:</p><p>• Emotion Sensor Dataset We have introduced to use of emotion sensor features, as a meta-data information. We have obtained the word sensor dataset from Kaggle 4 . In this dataset each word is statistically classified into 7 distinct classes (Disgust, Surprise, Neutral, Anger, Sad, Happy and Fear) using Naive Bayes, based on sentences collected from twitter and blogs. • Controlled Topical Signals from Empath 5 . Empath can analyse the text across 200 gold standard topics and emotions. Additionally, it uses neural embedding to draw connotation among words across more than 1.8 billion words. We have used only selected categories like violence, hate, anger, aggression, social media and dispute from 200 Empath categories useful for us unlike <ref type="bibr" target="#b40">[40]</ref> which takes 194 categories. • Emoticons frequently used on social media indicates the sense of sentence <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b39">39]</ref>. • Normalized frequency of POS tags According to <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b40">40,</ref><ref type="bibr" target="#b48">48]</ref> POS Tags provide the degree of target aggressiveness. Like <ref type="bibr" target="#b40">[40]</ref>, we have used only four tags (a) adjective (JJ, JJR, JJS), (b) adverb (RB, RBR, RBS), (c) verb (VB, VBD, VBG, VBN, VBP, VBZ) and (d) noun (NN, NNS, NNP, NNPS) (See "Penn-Treebank POS Tags" 6 for abbreviations and the full list). The main reason behind the selection of these four tags is to just identify words related to persons, activities, quality, etc, in the text. • Sentiment polarity obtained from VADER Sentiment Analysis <ref type="bibr" target="#b15">[16]</ref> (positive, negative and neutral) like used in <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b41">41,</ref><ref type="bibr" target="#b48">48]</ref>. It helps to demarcate aggressiveness with nonaggressiveness in the text. The block diagram of the proposed system is shown in <ref type="figure" target="#fig_0">Figure 1</ref>. The proposed system does not use any data augmentation techniques like <ref type="bibr" target="#b0">[1]</ref>, which is the top performer in TRAC (in English codemixed Facebook data). This means the performance achieved by our system totally depends on the training dataset provided by TRAC. This also proves the effectiveness of our approach. Our system outperforms all the previous state of the art approaches used for aggression identification on English code-mixed TRAC data, while being trained only from Facebook comments the system outperforms other approaches on the additional Twitter test set. The remaining part of this paper is organized as follows: Section 2 is an overview of related work. Section 3 presents the methodology and algorithmic details. Section 4 discusses the experimental evaluation of the system, and Section 5 concludes this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>There are several works for aggression identification submitted at TRAC 2018 among them some approaches use the ensemble of multiple statistical models <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b42">42]</ref>. Similarly, some of the  <ref type="bibr" target="#b40">[40,</ref><ref type="bibr" target="#b41">41,</ref><ref type="bibr" target="#b48">48]</ref> have used ensemble of statistical and deep learning models. In these models the statistical part of the model uses additional features from text analysis like parts-of-speech tags, punctuation, emotion, emoticon etc. Model like: <ref type="bibr" target="#b28">[29]</ref> has used the ensemble of deep learning models based on majority voting. Some other models like: <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b40">40]</ref> have used different models for Facebook and twitter. While approaches like: <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b39">39]</ref> have proposed unified architecture based on deep learning. Systems like <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b41">41]</ref> have used data augmentation either through translation or labelling external data to make the model generalize across domains. While <ref type="bibr" target="#b5">[6]</ref> has proposed a unified statistical model. Among approaches like <ref type="bibr" target="#b1">[2]</ref> extracted features from TF-IDF of character n-grams while <ref type="bibr" target="#b29">[30]</ref> uses LSTM with pre-trained embeddings from FastText. <ref type="bibr" target="#b7">[8]</ref> have used the BiLSTM based model and the SVM metaclassifier model for the Facebook and Twitter test sets, respectively. While <ref type="bibr" target="#b28">[29]</ref> tried ensembling of CNN, LSTM, and BILSTM. Some approaches like: <ref type="bibr" target="#b40">[40]</ref> has used emotions frequency as one of the features, while some others use sentiment emotion as feature <ref type="bibr" target="#b48">[48]</ref>. Also, <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b39">39]</ref> have converted emoticons to their description. <ref type="bibr" target="#b33">[34]</ref> have used TF-IDF of emoticons per-class as one of the features. Compared to all these approaches, we have concentrated to capture multiple linguistic/pattern based relations, key-terms and key-patters (with their association in text) through a combination of deep learning architectures with model averaging. We have also used NLP features as additional features with our deep learning architecture, obtained from psycho-linguistic and basic linguistic features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODOLOGY</head><p>In this section, we describe our system architecture for aggressiveness classifier. In section 3.1 we describe data preprocessing applied on the input text before feeding it to each of the classification models. Section 3.2 describes the computation of NLP features. In Sections 3.3, 3.4 and 3.5 we have described the architecture of different deep learning models like Deep Pyramid CNN, Disconnected RNN and Pooled BiLSTM respectively. Finally, in Section 3.6, we describe model averaging based classification model which combines the prediction probabilities from three deep learninig architectures discussed above. (see <ref type="figure" target="#fig_0">Figure 1</ref>. for block diagram of system architecture).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data Preprocessing</head><p>We consider the text to be well formatted before applying the text to the embedding layer. First, we detect non-English text(which are few) and translate all of them to English using Google Translate 7 . Still, there is some code mixed words like "mc", "bc" and other English abbreviations and spelling errors like "nd" in place of "and", "u" in place of "you" causes deep learning model to confuse with sentences of the same meaning. We follow the strategy of preprocessor as in <ref type="bibr" target="#b39">[39]</ref> to normalize the abbreviations and remove spelling errors, URLs and punctuation marks, converting emojis to their description.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">NLP Features</head><p>We have identified a novel combination of features which are highly effective in aggression classification when applied in addition to the features obtained from the deep learning classifier at the classification layer. We have introduced two new features in addition to the previously available features. The first one is the Emotion Sensor Feature 9 which use a statistical model to classify the words into 7 different classes based on the sentences obtained from twitter and blogs which contain total 1,185,540 words. The second one is the collection of selected topical signal from text collected using Empath 10 (see <ref type="table" target="#tab_1">Table 1</ref>.). Different from previous approaches <ref type="bibr" target="#b40">[40,</ref><ref type="bibr" target="#b42">42]</ref> where <ref type="bibr" target="#b40">[40]</ref> have used Emotion features in the form of frequency while <ref type="bibr" target="#b42">[42]</ref> have used emotion feature vector obtained from LIWC 2007 <ref type="bibr" target="#b36">[37]</ref>. Unlike <ref type="bibr" target="#b40">[40]</ref> we have used only 6 topical signals from Emapth <ref type="bibr" target="#b4">[5]</ref>. We have borrowed the idea of using other features like punctuation features and parts-of-speech tags from <ref type="bibr" target="#b40">[40]</ref> Like <ref type="bibr" target="#b40">[40]</ref> we have used the normalized frequencies of noun, adjective, verb, and adverb which serve as a rich feature for exaggerating type of aggressiveness in the text. We used the Spacy 8 POS tagger.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Punctuation</head><p>Like in "Communist parties killed lacks of opponents in WB in 35 years ruling????? ?" the presence of multiple question marks linked with the aggressiveness content in the text. Similarly "!" also has the same effect. We have used the count of "!" &amp; "?" in the text as a feature.</p><p>1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sentiment analysis</head><p>The percentage of positive, negative, and neutral can indicate the amount of aggressiveness in the text. We have used VADER Sentiment Analysis <ref type="bibr" target="#b15">[16]</ref> to extract the weight for positive, negative &amp; neutral class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Topic Signals from text</head><p>We have used open source library Empath <ref type="bibr" target="#b1">[2]</ref> introduced in <ref type="bibr" target="#b4">[5]</ref> which has categories highly correlated to LIWC <ref type="bibr" target="#b36">[37]</ref>. Although it has a rich number of categories we particularly identified selected categories useful for our case these are aggressiveness, violence, hate, anger, dispute &amp; social_media. We have used the normalized weight of each of these categories as separate features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">TF-IDF Emoticon Feature</head><p>Since emoticons are widely used to convey the meaning on social media platform analyzing the data emoticons are an important feature for classifying aggressive behavior and tf-idf feature for each class is calculated as in <ref type="bibr" target="#b33">[34]</ref> 3 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Total Features 24</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Deep Pyramid CNN(DPCNN)</head><p>Since it has been proved that CNNs are great feature extractors for text classification <ref type="bibr">[18-21, 23, 52]</ref> while deeper networks(whether RNNs or CNN's) has been proven for learning long-range association like deeper character level CNN's <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b54">54]</ref>, and complex combination of RNN and CNN <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b43">43,</ref><ref type="bibr" target="#b51">51,</ref><ref type="bibr" target="#b53">53]</ref>. Deep Pyramid CNN (DPCNN) <ref type="bibr" target="#b20">[21]</ref> has 15 layers of word-level CNN's and contains similar pre-activation as proposed in improved Resnet <ref type="bibr" target="#b11">[12]</ref>. DPCNN outperforms the 32-layer character CNN <ref type="bibr" target="#b3">[4]</ref> and Hierarchical attention networks <ref type="bibr" target="#b51">[51]</ref> it has added advantage that due to its pyramid structure it does not require dimension matching in shortcut connections defined as z + h(z) as in <ref type="bibr" target="#b11">[12]</ref> where h(z) represents the skipped layers essentially contains two convolutional layers with pre-activation. It uses enhanced region embedding which consumes pre-trained embeddings (in our case it is FastText+Glove based dual embedding). Enhanced Region Embedding. The current DPCNN <ref type="bibr" target="#b20">[21]</ref>, uses two view type enhanced region embedding. For the text categorization, it defines a region of text as view-1 and its adjacent regions as view-2. Then using unlabeled data, it trains a neural network of one hidden layer with an artificial task of predicting view-2 from view-1. The obtained hidden layer, which is an embedding function that takes view-1 as input, serves as an unsupervised embedding function in the model for text categorization. The detailed architecture has been shown in <ref type="figure">Figure 2</ref>. Let each word input x j ∈ R d be the d-dimensional vector for the j th word w j and the sentence s i contains sequence of n words {w 1 , w 2 , w 3 , ......, w n } as shown in <ref type="figure">Figure 2</ref>. In comparision to conventional convolution layer, DPCNN proposes to use pre-activation, thus essentially the convolutional layer of DPCNN is Wσ (x) + b, where W and b(unique to each layer) are the weights matrix and bias respectively, we use σ as PReLU <ref type="bibr" target="#b9">[10]</ref>. During implementation we use kernel size of 3(represented by x to denote the small overlapping regions of text.), The number of filters(number of feature maps denoted by the number of rows of W) is 128 as depicted in <ref type="figure">Figure  2</ref>. With the number of filters same in each convolution layer and max-pooling with stride 2 makes the computation time halved, and doubles the net coverage of convolution kernel. Thus the deeper layers cause to learn long-range associations between regions of text. Let's say h dpcnn ∈ R p 1 be the hidden state obtained from DPCNN just before the classification layer and f nlp ∈ R 24 be the NLP features computed from the text. Lets z 1 ∈ R p 1 +24 be another hidden state obtained as</p><formula xml:id="formula_0">z 1 = h dpcnn ⊕ f nlp<label>(1)</label></formula><p>where, ⊕ denotes concatenation. The vector z 1 obtained, then fed to the fully connected layer with softmax activation. Let y * i1 be the softmax probabilities, specifically for class label k is given as:</p><formula xml:id="formula_1">y * i1,k = p(y i = k |s i ) = so f tmax(W T dpcnn z 1 +b dpcnn )[k] ∀k ∈ [1...K]<label>(2)</label></formula><p>where K is the number of classes,W dpcnn and b dpcnn are the weight matrix and bias respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Disconnected RNN(DRNN)</head><p>Given a sequence s i = [x 1 , x 2 , x 3 , ....x n ] where x j ∈ R d represents the d-dimensional word vector for word w j and n is the length of input text applied to a variant of RNN called Long Short-Term Memory (LSTM) <ref type="bibr" target="#b13">[14]</ref> as shown in <ref type="figure">Figure 3</ref>  <ref type="figure">Figure 3</ref>: DRNN sequential modelling with long-term dependencies. For sequence modelling it keeps on updating the memory cell with current input using an adaptive gating mechanism. At time step t the memory c t and the hidden state h t are updated as follows:</p><formula xml:id="formula_2">        i t f t o t c t         =         σ σ σ tanh         = W .[h t −1 , x t ]<label>(3)</label></formula><formula xml:id="formula_3">c t = f t ⊙ c t −1 + i t ⊙ĉ t<label>(4)</label></formula><p>whereĉ t is the current cell state obtained from current input x t and previous hidden state h t −1 , i t , f t and o t are the activation corresponding to input gate, forget gate and output gate respectively, σ denotes the logistic sigmoid function and ⊙ denotes the elementwise multiplication. Hence the hidden state representation at time step t depends on all the previous input vectors given as</p><formula xml:id="formula_4">h t = LST M(x t , ...., x 2 , x 1 ) ∀t ∈ [1...n]<label>(5)</label></formula><p>Specifically we have used Bi-directional LSTM <ref type="bibr" target="#b13">[14]</ref> to capture both past and future context. It provides h t from both directions(forward &amp; backward). The forward LSTM takes the natural order of words from x 1 to x n to obtain − → h t , while backward-LSTM x n to x 1 to obtain ← − h t . then h t is calculated as</p><formula xml:id="formula_5">h t = − → h t ⊕ ← − h t ∈ R 2L (6)</formula><p>where ⊕ is the concatenation and L is the size for one-directional LSTM. Therefore we denote the hidden state in equation 5 with BiLSTM as</p><formula xml:id="formula_6">h t = BiLST M(x t , , ......x 2 , x 1 ) ∈ R 2L ∀t ∈ [1..n]<label>(7)</label></formula><p>To avoid handling of long sequence and to capture local information for each word we define the window size k for each word such that the BiLSTM only sees the the previous k − 1 words with the current word, where k is a hyperparameter <ref type="bibr" target="#b50">[50]</ref>. We use padding &lt;PAD&gt; to make the slices of fixed size k(as shown in <ref type="figure">Figure 3</ref>). It provides each hidden state h t with sequence of k previous words. Since the phrase of k words can lie anywhere in the text it helps to model the position invariant phrase representation due to which the it identifies key phrases important for identifying particular category. In this case, the equation of h t is given as</p><formula xml:id="formula_7">h t = BiLST M(x t , x t −1 , x t −2 , ......, x t −k +1 )<label>(8)</label></formula><p>The output hidden vectors, H = [h 1 , h 2 , h 3 , ......h n ] ∈ R n×2L are converted to fixed-length vector h dr nn ∈ R 2L with max pooling over time:</p><formula xml:id="formula_8">h l dr nn = max t h l t , t ∈ [1, ...n], ∀l ∈ [1, .....2L]<label>(9)</label></formula><p>Let's say f nlp ∈ R 24 be the NLP features computed from the text. Let's z 2 ∈ R 2L+24 be another hidden state obtained as</p><formula xml:id="formula_9">z 2 = h dr nn ⊕ f nlp<label>(10)</label></formula><p>where ⊕ denotes concatenation. The vector z 2 obtained, then fed to the fully connected layer with softmax activation. Let y * i2 be the softmax probabilities, specifically for class label k is given as:</p><formula xml:id="formula_10">y * i2,k = p(y i = k |s i ) = so f tmax(W T dr nn z 2 + b dr nn )[k] ∀k ∈ [1...K]<label>(11)</label></formula><p>where K is the number of classes, W dr nn is the weight matrix, and b dr nn is the bias.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Pooled BiLSTM</head><p>The architecture has been shown in <ref type="figure" target="#fig_2">Figure 4</ref>. Given a sequence</p><formula xml:id="formula_11">s i = [x 1 , x 2 , x 3 , .....x j ]</formula><p>, where x j ∈ R d is the d-dimensional word vector for word w j , the hidden state obtained after BiLSTM is given as To avoid the loss of information because of modelling the entire sequence, we have concatenated the max-pooled(c max ) and meanpooled(c mean ) representation of hidden states calculated over all time steps <ref type="bibr" target="#b14">[15]</ref>. We have also concatenated the nlp features, f nlp ∈ R 24 the final feature vector z 3 is given as</p><formula xml:id="formula_12">h t = BiLST M(x t , x t −1 , ....x 1 )∀t ∈ [1...n]<label>(12)</label></formula><formula xml:id="formula_13">z 3 = h n ⊕ c max ⊕ c mean ⊕ f nlp<label>(13)</label></formula><p>where ⊕ denotes concatenation. The final feature z 3 vector is fed to the fully connected layer with softmax activation. Let y * i3 be the softmax probablities, specifically for class label k given as:</p><formula xml:id="formula_14">y * i3,k = p(y i = k |s i ) = so f tmax(W T bil stm z 3 +b bil stm )[k] ∀k ∈ [1...K]<label>(14)</label></formula><p>where K is the number of classes and W bil stm and b bil stm are the weight matrix and bias respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Classification Model</head><p>According to deep learning literature <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b45">45,</ref><ref type="bibr" target="#b46">46]</ref>, unweighted averaging might be a reasonable ensemble for similar base learners of comparable performance. Now, similar to the information discussed in <ref type="bibr" target="#b21">[22]</ref>, we can compute the model averaging (unweighted) by combining the softmax probabilities of three different classification models obtained from equations 2, 11, 14. The averaged class probabilities are computed as:</p><formula xml:id="formula_15">y * i,k = y * i1,k + y * i2,k + y * i3,k 3 ∀k ∈ [1....K]<label>(15)</label></formula><formula xml:id="formula_16">y i = arg max k (y * i )<label>(16)</label></formula><p>where K is the number of classes, andŷ i is the predicted label for sentence s i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENT AND EVALUATION 4.1 Dataset Description</head><p>We have used two datasets in our experimental evaluations: (1) TRAC 2018 Dataset 11 and (2) Kaggle Dataset 12 .</p><p>TRAC 2018 Dataset: We have used the English code-mixed dataset <ref type="bibr" target="#b10">11</ref> https://sites.google.com/view/trac1/shared-task 12 https://www.kaggle.com/dataturks/dataset-for-detection-of-cybertrolls provided by TRAC 2018. This dataset contains three labels, (a) Non-Aggressive(NAG), (b) Overtly-Aggressive (OAG) and (c) Covertly-Aggressive(CAG). The distribution of training, validation and test sets are described in <ref type="table" target="#tab_3">Table 2</ref>.</p><p>Kaggle Dataset: This dataset contains 20001 tweets which are manually labeled. The labels are divided into two categories (indicating presence or absence of aggression in tweets) AGG(Aggressive) or NAG(Non-Aggressive). We have used the same test split available in the baseline code <ref type="bibr" target="#b12">13</ref> . The distribution for each of the training and test is given in <ref type="table">Table 3</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Number</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Setup</head><p>We have used Glove Embeddings <ref type="bibr" target="#b38">[38]</ref> concatenated with FastText Embeddings <ref type="bibr" target="#b30">[31]</ref> in all the three classification models presented in this paper. Specifically, we used Glove pre-trained vectors obtained from Twitter corpus containing 27 billion tokens and 1.2 million vocabulary entries where each word is represented using 100-dimensional vector. In the case of FastText the word is represented using 300-dimensional vector. Also, we have applied spatial dropout <ref type="bibr" target="#b49">[49]</ref> of 0.3 at embedding layer for DPCNN(in section 3.3) and Pooled BiLSTM(in section 3.5). For DPCNN model(in 3.3) we have learnt 128-dimensional vector representation for unsupervised embeddings implicitly for task specific representation as in <ref type="bibr" target="#b20">[21]</ref>. Additionally, for DPCNN all the convolutional layers used 128 filters, kernel size of 3 and max-pooling stride 2. Additionally, in the case of DPCNN we have used kernel and bias regularizer of value 0.00001 for all convolutional kernels. The pre-activation function used in DPCNN is Parametric ReLU (PReLU) proposed in <ref type="bibr" target="#b9">[10]</ref> while the activation at each of the convolutional kernel is linear. For, DRNN(in section 3.4) we have used the window size of 8 and rest of the parameters related to LSTM units are same as given in <ref type="bibr" target="#b50">[50]</ref>. For, Pooled BiLSTM(in section 3.5) we have used LSTM hidden units size as 256. The maximum sequence length is 200 in all three models. In each of the classification model the classification layer contains the fully connected layer with softmax activation with output size of 3 equal to number of classes in case of TRAC 2018 dataset and its 2 in case of Kaggle dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rank in Trac 2018</head><p>System F1 (Weighted) Facebook    Training has been done using ADAM optimizer <ref type="bibr" target="#b23">[24]</ref> for DPCNN and RMSPROP <ref type="bibr" target="#b47">[47]</ref> for DRNN and Pooled Bi-LSTM models. All the models are trained end-to-end using softmax cross entropy loss <ref type="bibr" target="#b2">[3]</ref> for TRAC 2018 dataset and binary cross entropy loss <ref type="bibr" target="#b2">[3]</ref> for Kaggle dataset. To train our model for TRAC 2018 dataset, we merged the training and validation dataset and then used 10% split from shuffled dataset to save the best model, for all classifiers. We have used only 20 NLP features (except TF-IDF Emoticon feature and Punctuation feature as given in <ref type="table" target="#tab_1">Table 1</ref>) for Kaggle dataset (as these are not present in the Kaggle dataset).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation Strategy</head><p>To compare our experimental results we have used top-5 systems from the published results of TRAC-2018 <ref type="bibr" target="#b26">[27]</ref>. To compare our results on Kaggle dataset, we have used the last &amp; the best published result on Kaggle website as a baseline. We have conducted the separate experiments, to properly investigate the performance of (a) each of the classifiers (used in our model averaging based system), (b) impact of the NLP features on each of these classifiers and finally, (c) the performance of our proposed system. In <ref type="table" target="#tab_5">Table 4</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Results and Discussion</head><p>In this paper, we have evaluated our model using weighted macroaveraged F-score. The measure is defined as in (See <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b26">27]</ref>). It weights the F-score computed per class based on the class composition in the test set and then takes the average of these per-class F-score gives the final F-score. <ref type="table" target="#tab_5">Table 4</ref>, 5 and 6. presents the comparative experimental results for the proposed method in this paper with respect to the state-of-the-art. The top 5 models <ref type="bibr" target="#b26">[27]</ref> given in <ref type="table" target="#tab_5">Table 4</ref>   and Twitter test dataset respectively on TRAC 2018. We have followed all the experimental guidelines as discussed in TRAC contest guideline paper <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b26">27]</ref>. From the results given in <ref type="table" target="#tab_5">Table 4</ref>, 5 and 6 it is clear that our proposed model shows the best performance among all of the approaches. These results also state that all the deep learning architectures with NLP features, perform better than individual corresponding deep learning architectures. This means NLP features, adds some value to the architectures, even if it is not very high.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION AND FUTURE WORK</head><p>In this paper, we have briefly described the approach we have taken to solve the aggressive identification on online social media texts which is very challenging since the dataset is noisy and code-mixed. We presented an ensemble of deep learning models which outperform previous approaches by sufficient margin while having the ability to generalize across domains. In future, we will explore other methods to increase the understanding of deep learning models on group targeted text, although the categories are well defined we will look after if we further fine-tune the categories with more data. In the future, we are planning to pay attention on a generalized language model for code-mixed texts which can also handle Hindi-code-mixed and other multi-lingual code-mixed datasets (i.e., trying to reduce the dependencies on language-specific code-mixed resources).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Block diagram of the proposed system models like</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>. It is widely used for</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Pooled BiLSTM</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Confusion Matrix for Facebook, Twitter and Kaggle Datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>.The Table 1. lists and describes Emotion Sensor Features are developed by classifying the words statistically using Naive Bayes algorithm into 7 different categories (Disgust, Surprise, Neutral, Anger, Sad, Happy and Fear) using sentences collected from twitter or blogs.</figDesc><table><row><cell>Feature Name</cell><cell>Description</cell><cell>Feature Count</cell></row><row><cell>Emotion Sensor Feature</cell><cell></cell><cell></cell></row></table><note>7 Parts-of-Speech(POS)</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Details of NLP featuresfeatures, tools used to obtain them and the number of features resulted from each type.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell cols="3">: TRAC 2018, Details of English Code-Mixed Dataset</cell></row><row><cell>Number</cell><cell>Training</cell><cell>Test</cell></row><row><cell>Texts</cell><cell>15000</cell><cell>5001</cell></row><row><cell>Aggressive(AGG)</cell><cell>5867</cell><cell>1955</cell></row><row><cell>Non-Aggressive(NAG)</cell><cell>9133</cell><cell>3046</cell></row><row><cell cols="3">Table 3: Kaggle, Uni-lingual(English) Dataset</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Facebook Test results(TRAC 2018 Dataset)</figDesc><table><row><cell>Rank</cell><cell></cell><cell></cell></row><row><cell>in Trac</cell><cell>System</cell><cell>F1 (Weighted) Twitter</cell></row><row><cell>2018</cell><cell></cell><cell></cell></row><row><cell>1</cell><cell>vista.ue[39]</cell><cell>0.6008</cell></row><row><cell>2</cell><cell>Julian[41]</cell><cell>0.5994</cell></row><row><cell>3</cell><cell>saroyehun[1]</cell><cell>0.5920</cell></row><row><cell>4</cell><cell>EBSI-LIA-UNAM[2]</cell><cell>0.5716</cell></row><row><cell>5</cell><cell>uOttawa[33]</cell><cell>0.5690</cell></row><row><cell></cell><cell>Our Models</cell><cell></cell></row><row><cell>A</cell><cell>DPCNN</cell><cell>0.5364</cell></row><row><cell>B</cell><cell>DRNN</cell><cell>0.5272</cell></row><row><cell>C</cell><cell>Pooled BiLSTM</cell><cell>0.5513</cell></row><row><cell>D</cell><cell>DPCNN + NLP Features</cell><cell>0.5529</cell></row><row><cell>E</cell><cell>DRNN + NLP Features</cell><cell>0.6189</cell></row><row><cell>F</cell><cell>Pooled BiLSTM + NLP Features</cell><cell>0.6227</cell></row><row><cell></cell><cell>Model Averaging(A + B + C)</cell><cell>0.5967</cell></row><row><cell></cell><cell>Our proposed method Model Averaging(D + E + F)</cell><cell>0.6480</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table><row><cell>Twitter Test results(TRAC 2018 Dataset)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 :</head><label>6</label><figDesc>Results on Kaggle Test Dataset</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>, 5 and 6, models, named as DPCNN(ref 3.3), DRNN (ref 3.4) and Pooled BiLSTM(ref 3.5) are corresponding models without NLP features. Similarly, DPCNN+NLP Features, DRNN + NLP Features and Pooled BiLSTM + NLP Features are corresponding models with NLP features. The Model Averaging (A+B+C) is the ensemble of three models (i.e., model averaging of DPCNN, DRNN and Pooled BiLSTM) without NLP features. Finally, Our Proposed Method, which represents the model averaging of three models with NLP features.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>and 5. are the best performing models for Facebook</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>450</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>400</cell></row><row><cell></cell><cell>OAG</cell><cell>91</cell><cell>19</cell><cell>34</cell><cell>400</cell><cell></cell><cell>OAG</cell><cell>279</cell><cell>71</cell><cell>11</cell><cell>350</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>350</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>300</cell></row><row><cell>True label</cell><cell>CAG</cell><cell>29</cell><cell>43</cell><cell>70</cell><cell>200 250 300</cell><cell>True label</cell><cell>CAG</cell><cell>171</cell><cell>138</cell><cell>104</cell><cell>200 250</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>150</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>150</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>100</cell></row><row><cell></cell><cell>NAG</cell><cell>73</cell><cell>76</cell><cell>481</cell><cell>100</cell><cell></cell><cell>NAG</cell><cell>5</cell><cell>56</cell><cell>422</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>50</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>50</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>O A G</cell><cell>C A G</cell><cell>N A G</cell><cell></cell><cell></cell><cell></cell><cell>O A G</cell><cell>C A G</cell><cell>N A G</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Predicted label</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Predicted label</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="4">(a) Confusion Matrix for Facebook Test Set(TRAC 2018)</cell><cell></cell><cell></cell><cell cols="4">(b) Confusion Matrix for Twitter Test Set(TRAC 2018)</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>2700</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>2400</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>NAG</cell><cell>2712</cell><cell></cell><cell></cell><cell>334</cell><cell></cell><cell>2100</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1800</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>True label</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1200 1500</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>900</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>AGG</cell><cell>158</cell><cell></cell><cell></cell><cell>1797</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>600</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>300</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>N A G</cell><cell></cell><cell></cell><cell>A G G</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">Predicted label</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">(c) Confusion Matrix for Kaggle Test Set</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://www.kaggle.com/dataturks/dataset-for-detection-of-cybertrolls arXiv:2001.05493v2 [cs.CL] 18 Jan 2020</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">https://www.kaggle.com/iwilldoit/emotions-sensor-data-set 5 http://empath.stanford.edu/ 6 https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">https://pypi.org/project/googletrans/ 8 https://spacy.io/usage/linguistic-features#pos-tagging 9 https://www.kaggle.com/iwilldoit/emotions-sensor-data-set 10 http://empath.stanford.edu/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13">https://www.kaggle.com/alisaeidi92/a-very-simple-nlp-model-0-75-accuracy</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Aggression detection in social media: Using deep neural networks, data augmentation, and pseudo labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Segun Taofeek Aroyehun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gelbukh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying</title>
		<meeting>the First Workshop on Trolling, Aggression and Cyberbullying</meeting>
		<imprint>
			<publisher>TRAC</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="90" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Cyberbullying Detection Task: the EBSI-LIA-UNAM System (ELU) at COLING&apos;18 TRAC-1</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ignacio</forename><surname>Arroyo-Fernández</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dominic</forename><surname>Forest</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan-Manuel</forename><surname>Torres-Moreno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mauricio</forename><surname>Carrasco-Ruiz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Legeleux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Joannette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying</title>
		<meeting>the First Workshop on Trolling, Aggression and Cyberbullying</meeting>
		<imprint>
			<publisher>TRAC</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="140" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Keras: The python deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Chollet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Astrophysics Source Code Library</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Loıc</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.01781</idno>
		<title level="m">Very deep convolutional networks for natural language processing</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Empath: Understanding topic signals in large-scale text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Fast</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binbin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael S</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2016 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4647" to="4657" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Merging datasets for aggressive text identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paula</forename><surname>Fortuna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">José</forename><surname>Ferreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luiz</forename><surname>Pires</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guilherme</forename><surname>Routar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sérgio</forename><surname>Nunes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying</title>
		<meeting>the First Workshop on Trolling, Aggression and Cyberbullying</meeting>
		<imprint>
			<publisher>TRAC</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="128" to="139" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Aggression identification and multi lingual word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thiago</forename><surname>Galery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Efstathios</forename><surname>Charitos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying</title>
		<meeting>the First Workshop on Trolling, Aggression and Cyberbullying</meeting>
		<imprint>
			<publisher>TRAC</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="74" to="79" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Combining shallow and deep learning for aggressive text detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viktor</forename><surname>Golem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mladen</forename><surname>Karan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Šnajder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying</title>
		<meeting>the First Workshop on Trolling, Aggression and Cyberbullying</meeting>
		<imprint>
			<publisher>TRAC</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="188" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gumperz</surname></persName>
		</author>
		<title level="m">Discourse strategies</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1982" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Delving deep into rectifiers: Surpassing human-level performance on imagenet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1026" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Identity mappings in deep residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="630" to="645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Bullying, cyberbullying, and suicide. Archives of suicide research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Hinduja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><forename type="middle">W</forename><surname>Patchin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="206" to="221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Universal Language Model Finetuning for Text Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1031</idno>
		<ptr target="https://doi.org/10.18653/v1/P18-1031" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018-07-15" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="328" to="339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Vader: A parsimonious rule-based model for sentiment analysis of social media text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Clayton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Hutto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gilbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eighth international AAAI conference on weblogs and social media</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenxiang</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiqin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irwin</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.04446</idno>
		<title level="m">HiGRU: Hierarchical Gated Recurrent Units for Utterance-level Emotion Recognition</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Effective use of word order for text categorization with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rie</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.1058</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Semi-supervised convolutional neural networks for text categorization via region embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rie</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="919" to="927" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rie</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.00718</idno>
		<title level="m">Convolutional neural networks for text categorization: Shallow word-level vs. deep character-level</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep pyramid convolutional neural networks for text categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rie</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="562" to="570" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The relative performance of ensemble methods with deep convolutional neural networks for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurélien</forename><surname>Bibaut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Van Der Laan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Statistics</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="2800" to="2818" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1408.5882</idno>
		<title level="m">Convolutional neural networks for sentence classification</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Trac-1 shared task on aggression identification: Iit (ism)@ coling&apos;18</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ritesh</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guggilla</forename><surname>Bhanodai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajendra</forename><surname>Pamula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maheshwar Reddy</forename><surname>Chennuru</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying</title>
		<meeting>the First Workshop on Trolling, Aggression and Cyberbullying</meeting>
		<imprint>
			<publisher>TRAC</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="58" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Benchmarking aggression identification in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ritesh</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atul</forename><surname>Kr Ojha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shervin</forename><surname>Malmasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcos</forename><surname>Zampieri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying</title>
		<meeting>the First Workshop on Trolling, Aggression and Cyberbullying</meeting>
		<imprint>
			<publisher>TRAC</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC-2018)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ritesh</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atul</forename><surname>Kr Ojha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcos</forename><surname>Zampieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shervin</forename><surname>Malmasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying</title>
		<meeting>the First Workshop on Trolling, Aggression and Cyberbullying</meeting>
		<imprint>
			<publisher>TRAC</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Aggression-annotated Corpus of Hindi-English Code-mixed Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ritesh</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aishwarya</forename><forename type="middle">N</forename><surname>Reganti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akshit</forename><surname>Bhatia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tushar</forename><surname>Maheshwari</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/L18-1226" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC-2018). European Languages Resources Association (ELRA)</title>
		<meeting>the Eleventh International Conference on Language Resources and Evaluation (LREC-2018). European Languages Resources Association (ELRA)<address><addrLine>Miyazaki, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Aggression detection in social media using deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sreekanth</forename><surname>Madisetty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maunendra</forename><surname>Sankar Desarkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying</title>
		<meeting>the First Workshop on Trolling, Aggression and Cyberbullying</meeting>
		<imprint>
			<publisher>TRAC</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="120" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Filtering aggression from the multilingual social media feed</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prasenjit</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Mandl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying</title>
		<meeting>the First Workshop on Trolling, Aggression and Cyberbullying</meeting>
		<imprint>
			<publisher>TRAC</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="199" to="207" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Advances in Pre-Training Distributed Word Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Puhrsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Language Resources and Evaluation</title>
		<meeting>the Eleventh International Conference on Language Resources and Evaluation</meeting>
		<imprint>
			<publisher>LREC</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Lstms with attention for aggression detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nishant</forename><surname>Nikhil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramit</forename><surname>Pahwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehul</forename><surname>Kumar Nirala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohan</forename><surname>Khilnani</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.06151</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Cyber-aggression detection using cross segmentand-concatenate multi-task learning from text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><surname>Husseini Orabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahmoud</forename><forename type="middle">Husseini</forename><surname>Orabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qianjia</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Inkpen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Van Bruwaene</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying</title>
		<meeting>the First Workshop on Trolling, Aggression and Cyberbullying</meeting>
		<imprint>
			<publisher>TRAC</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="159" to="165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Aggressive language identification using word embeddings and sentiment features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Constantin</forename><surname>Orasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying</title>
		<meeting>the First Workshop on Trolling, Aggression and Cyberbullying</meeting>
		<imprint>
			<publisher>TRAC</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="113" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Weighted ensemble of statistical models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maciej</forename><surname>Pawlikowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agata</forename><surname>Chorowska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Forecasting</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiran</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Senzhang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip S</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.04898</idno>
		<title level="m">Hierarchical Taxonomy-Aware and Attentional Graph Capsule RCNNs for Large-Scale Multi-Label Text Classification</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pennebaker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Roger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><forename type="middle">E</forename><surname>Booth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Francis</surname></persName>
		</author>
		<title level="m">Linguistic inquiry and word count: LIWC [Computer software</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Austin</forename></persName>
		</author>
		<idno>TX: liwc. net 135</idno>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Fully connected neural network with advance preprocessor to identify aggression over facebook and twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kashyap</forename><surname>Raiyani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teresa</forename><surname>Gonçalves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paulo</forename><surname>Quaresma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vítor</forename><surname>Nogueira</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Irit at trac</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Faneva</forename><surname>Ramiandrisoa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josiane</forename><surname>Mothe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying</title>
		<meeting>the First Workshop on Trolling, Aggression and Cyberbullying</meeting>
		<imprint>
			<publisher>TRAC</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="19" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Aggression identification using deep learning and data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Risch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Krestel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying</title>
		<meeting>the First Workshop on Trolling, Aggression and Cyberbullying</meeting>
		<imprint>
			<publisher>TRAC</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="150" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepthi</forename><surname>Niloofar Safi Samghabadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sudipta</forename><surname>Mave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thamar</forename><surname>Kar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Solorio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.11712</idno>
		<title level="m">RiTUAL-UH at TRAC 2018 shared task: Aggression identification</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinghan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asli</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhe</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liqun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Carin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.00154</idno>
		<title level="m">Towards Generating Long and Coherent Text with Multi-Level Latent Variable Models</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A latent semantic model with convolutional-pooling structure for information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yelong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grégoire</forename><surname>Mesnil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM international conference on conference on information and knowledge management</title>
		<meeting>the 23rd ACM international conference on conference on information and knowledge management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="101" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<title level="m">Very deep convolutional networks for large-scale image recognition</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Lecture 6.5âĂŤRmsProp: Divide the gradient by a running average of its recent magnitude</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tijmen</forename><surname>Tieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<idno>. TRITA-MAT-E 2017: 81 ISRN-KTH/MAT/E-17/81-SE</idno>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
	<note>COURSERA: Neural Networks for Machine Learning</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Textual aggression detection through deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonela</forename><surname>Tommasel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan</forename><forename type="middle">Manuel</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniela</forename><surname>Godoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying</title>
		<meeting>the First Workshop on Trolling, Aggression and Cyberbullying</meeting>
		<imprint>
			<publisher>TRAC</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="177" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Efficient object localization using convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Tompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Goroshin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Bregler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="648" to="656" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Disconnected Recurrent Neural Networks for Text Categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoxin</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2311" to="2320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Hierarchical attention networks for document classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zichao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diyi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 conference of the North American chapter of the association for computational linguistics: human language technologies</title>
		<meeting>the 2016 conference of the North American chapter of the association for computational linguistics: human language technologies</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1480" to="1489" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenpeng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katharina</forename><surname>Kann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schütze</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.01923</idno>
		<title level="m">Comparative study of CNN and RNN for natural language processing</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Mattnet: Modular attention network for referring expression comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Licheng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohui</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamara</forename><forename type="middle">L</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1307" to="1315" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Character-level convolutional networks for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbo</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="649" to="657" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
