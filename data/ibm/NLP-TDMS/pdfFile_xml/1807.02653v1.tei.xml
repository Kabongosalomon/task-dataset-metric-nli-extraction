<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">When Work Matters: Transforming Classical Network Structures to Graph CNN</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenting</forename><surname>Zhao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyan</forename><surname>Xu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Cui</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Southeast University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiatao</forename><surname>Jiang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenyu</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Yang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanjing</forename></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Science and Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">When Work Matters: Transforming Classical Network Structures to Graph CNN</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T12:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Graph CNN</term>
					<term>Spectral filtering</term>
					<term>ResNet</term>
					<term>Incep- tion</term>
					<term>DenseNet</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Numerous pattern recognition applications can be formed as learning from graph-structured data, including social network, protein-interaction network, the world wide web data, knowledge graph, etc. While convolutional neural network (CNN) facilitates great advances in gridded image/video understanding tasks, very limited attention has been devoted to transform these successful network structures (including Inception net, Residual net, Dense net, etc.) to establish convolutional networks on graph, due to its irregularity and complexity geometric topologies (unordered vertices, unfixed number of adjacent edges/vertices). In this paper, we aim to give a comprehensive analysis of when work matters by transforming different classical network structures to graph CNN, particularly in the basic graph recognition problem. Specifically, we firstly review the general graph CNN methods, especially in its spectral filtering operation on the irregular graph data. We then introduce the basic structures of ResNet, Inception and DenseNet into graph CNN and construct these network structures on graph, named as G ResNet, G Inception, G DenseNet. In particular, it seeks to help graph CNNs by shedding light on how these classical network structures work and providing guidelines for choosing appropriate graph network frameworks. Finally, we comprehensively evaluate the performance of these different network structures on several public graph datasets (including social networks and bioinformatic datasets), and demonstrate how different network structures work on graph CNN in the graph recognition task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>A graph-structured data sample consists of a finite set of vertices/nodes, together with a set of connections revealing the relationship between unordered pairs of these vertices (named edges). Numerous important high-level applications, especially in the increasingly connected and blended world, can be framed as learning from graph data, including social network <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, protein-interaction network <ref type="bibr" target="#b2">[3]</ref>, the world wide web data <ref type="bibr" target="#b3">[4]</ref>, knowledge graph, etc. Among these practical problems, learning an appropriate neural network from such structured graphs becomes the most critical topic.</p><p>Recently, convolutional neural networks (CNNs), together with multiple evolved variants, have achieved very promising performance in processing grid-shaped images/videos <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, such as image recognition, object detection, depth estimation, image restoration, object segmentation, etc. LeCun et al. <ref type="bibr" target="#b8">[9]</ref> originally trained the layer-wise convolutional network with the back-propagation algorithm in 1998. Krizhevsky et al. <ref type="bibr" target="#b4">[5]</ref> introduced a similar CNN network with a deeper and much wider version, and achieved a breakthrough, outperforming the existing handcrafted features on ILSVRC 2012 competition. GoogLeNet <ref type="bibr" target="#b9">[10]</ref> proposed more effective inception module to design a local network topology by adopting multiple receptive field sizes. VGGNet <ref type="bibr" target="#b5">[6]</ref>, which consisted of 16 convolutional layers, was also very appealing because of its very uniform architecture. He et al. <ref type="bibr" target="#b7">[8]</ref> introduced a substantially deeper architecture (dubbed Residual Neural Network, ResNet)) with skip connections, which are also known as gated units or gated recurrent units. Dense Convolutional Network (DenseNet) <ref type="bibr" target="#b6">[7]</ref> further proposed a densely connected structure, which can connect each layer to every other layer in a feed-forward fashion. However, due to the irregularity and complexity geometric topologies of graph-structured data, these successful CNN structures on representing grid-shaped image/video data cannot be straightforwardly applied to the graph data, especially these elementary operators including convolutional filtering, pooling, translation, etc.</p><p>Driven by the developments and limitation of above CNNs, various algorithms devoted to graph CNNs have been proposed in previous literatures. In general, these algorithms can be divided into two main categories according to their ways of conducting convolution on graphs: one can be named as spatial graph CNNs convolving directly on graphs according to the spatial information of nodes, while the other employs spectral filtering based on Spectral Graph Theory <ref type="bibr" target="#b10">[11]</ref>. The former one is analogues to CNN which firstly constructs a window of certain size for nodes on the graph and then conducts convolution operation <ref type="bibr" target="#b11">[12]</ref>. However, its disadvantage is the loss of structural information of graph data. To overcome this shortcoming, DGCNN <ref type="bibr" target="#b12">[13]</ref> proposed dynamic convolutional kernel to adapt to the size and order of the node neighborhood, supporting different scales of convolutional receptive fields. As another kind of spatial graph CNNs, a mixture model networks (MoNet) is proposed in <ref type="bibr" target="#b13">[14]</ref>, using a parametric patch to match template for convolution operations on graphs or manifolds. Moreover, as a particular instance of MoNet <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref> introduces an attention-based architecture to perform node classification of graph-structured data. The latter category of graph CNNs is based on the Spectral Graph Theory <ref type="bibr" target="#b10">[11]</ref>. In the graph setting, the graph Laplacian eigenvalues and eigenvectors provide a notion of frequency <ref type="bibr" target="#b15">[16]</ref> and spectral filtering has been successfully applied to the field of arXiv:1807.02653v1 [cs.LG] 7 Jul 2018 graphs. In <ref type="bibr" target="#b16">[17]</ref>, CNN was firstly generalized to graph using spectral filtering. On the basis, <ref type="bibr" target="#b17">[18]</ref> considered large-scale classification problems with small learning complexity and further made some extension. <ref type="bibr" target="#b18">[19]</ref> approximated smooth filters in the spectral domain using Chebyshev polynomials with free parameters that are learned in a neural network-like model. To further improve computation efficiency, <ref type="bibr" target="#b19">[20]</ref> presented a firstorder approximation of spectral graph convolutions, and in many cases allowed both for significantly faster training times and higher predictive accuracy. Although these approaches have devoted to design more effective convolutional filtering and pooling on graph, very limited attention has been focused on how to transform these successful network structures (including Inception net, Residual net, Dense net, etc.) to establish more promising Graph CNN architectures on graph domains.</p><p>In this paper, we pay attention to give a comprehensive analysis of when work matters by transforming different classical network structures to graph CNN, particularly in the basic graph recognition problem. Specifically, we firstly review the general graph CNN methods, especially in its spectral filtering operation on the irregular graph data. We then introduce the basic structures of ResNet, Inception and DenseNet into graph CNN and extend these network structures on graph domains, named as G ResNet, G Inception, G DenseNet. G ResNet with a similar structure with ResNet <ref type="bibr" target="#b7">[8]</ref>, is a multi-layer gated graph CNN by learning residual functions with reference to the layer inputs. G Inception can better consider the different receptive fields of graph signal and also increase the width of the network while keeping the computational budget constant. G DenseNet can strengthen feature propagation and encourage graph signals of all preceding layers in the graph CNN. In particular, it seeks to help graph CNNs by shedding light on how these classical network structures work and providing guidelines for choosing appropriate graph network frameworks. We comprehensively evaluate the performance of these different network structures on several public graph datasets (including social networks and bioinformatic datasets), and demonstrate how different network structures work on graph CNN in the graph recognition task.</p><p>The remainder of this paper is organized as follows. Section II reviews some related works about classical network structures and methods of graph CNN. Section III briefly introduces the approach we used to convolve on the graph in this paper. Section IV presents the three network structures of G ResNet, G Inception and G DenseNet. Section V describes the implementation details, reports the performance of our three graph CNN structures on social networks and bioinformatic datasets and makes some discussions. Finally, Section VI concludes this paper and gives future research direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>Classical network structures: Deep network learning has been long studied for dealing with these gridded image/video understanding problems <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b23">[24]</ref>. In 1998, LeCun et al. <ref type="bibr" target="#b8">[9]</ref> trained multilayer neural networks with the backpropagation algorithm and the gradient learning technique, and then demonstrated its effectiveness on the handwritten digit recognition task. Recently, for further boosting its discriminative capability, there has been a resurgence of research interest in the exploration of various network structures. AlexNet <ref type="bibr" target="#b4">[5]</ref> is a special type of deep CNN model and achieves a breakthrough, outperforming the existing handcrafted features on ILSVRC 2012 which contains 1000 object classes. Another deep network structure, namely "Network In Network" (NIN) <ref type="bibr" target="#b24">[25]</ref> is proposed to build a micro network with more complex structures to abstract the data within the receptive field, and the proposed 1 × 1 convolution kernel is later applied in the GoogLeNet model to reduce the dimension and avoid computational explosion. VGGNet <ref type="bibr" target="#b5">[6]</ref> consists of 16 convolutional layers and is very appealing because of its very uniform architecture. And It is currently the most preferred choice in the community for extracting features from vision inputs. A more effective inception module, introduced by GoogLeNet [10] model, can be employed to design a local network topology. It convolves with different sized kernels, concatenates the results as input to the next layer, and implements the use of multi-scale features. ResNet <ref type="bibr" target="#b7">[8]</ref> can easily improve performance by significantly increasing the depth of network compared to the plain nets (that simply stack layers). And it addresses the degradation problem <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref> of accuracy that arises with the network depth increasing by introducing a deep residual learning framework. Through the connection between each convolution layer, DenseNet <ref type="bibr" target="#b6">[7]</ref> encourages feature reuse and then learns more and compact features while keeping fewer parameters and less computation by using 1 × 1 convolution.</p><p>Graph CNN: Recent CNN on graph data has raised a progressive direction in the problem of graph recognition. At present, there are two main categories to execute the convolution operation on graphs. One is analogous to the common CNN in the gridded image/video samples, constructing a window of a certain size on the graph, and then doing the convolution by a fixed-size template. The other is based on Spectral Graph Theory <ref type="bibr" target="#b10">[11]</ref>. Features of the graph are first transformed into the frequency domain using the Fourier transform and convolved on the spectrum of the graph. Then an inverse Fourier transform is done to transform the feature maps to vertex domain.</p><p>Based on image CNN, the work of <ref type="bibr" target="#b11">[12]</ref> proposed a general method to learn representation for arbitrary graphs and transformed the data of a graph structure into a structure that CNN can efficiently handle. It mainly consists of two steps: selecting a representative node sequence from the graph structure and finding a convolutional neighborhood for each selected node. However, in this process, structural information of the graph may be lost and also some redundant information can be introduced. Therefore, the paper <ref type="bibr" target="#b12">[13]</ref> introduced a Gaussian mixture model by adding a disordered graph convolutional layer (DGCL) to overcome the above problems. Besides, <ref type="bibr" target="#b14">[15]</ref> presented masked self-attentional layers to adptively endow different weights to those neighbor vertices of a vertex, and thereby the performance of the model can be improved. To capture temporal evolution of graph sequences, recursive neural networks are introduced into the graph in <ref type="bibr" target="#b27">[28]</ref>.</p><p>Based on the Spectral Graph Theory <ref type="bibr" target="#b10">[11]</ref>, a generic framework for processing data on graphs is presented in <ref type="bibr" target="#b15">[16]</ref>, and the fundamental operations such as filtering, translation, modulation, dilation, and downsampling are generalized to the graph setting. <ref type="bibr" target="#b16">[17]</ref> proposed two efficient constructions: Spatial Construction and Spectral Construction. Then, <ref type="bibr" target="#b17">[18]</ref> extended <ref type="bibr" target="#b16">[17]</ref> to large-scale classification problems with small learning complexity, and proposed unsupervised and new supervised graph estimation strategies. In <ref type="bibr" target="#b18">[19]</ref>, the spectral graph theoretical of CNNs on graphs is formulated and strictly localized spectral filters are given. More importantly, recursive Chebyshev polynomials are utilized to approximate parameterized polynomial filters such that the complexity and efficiency of learning are significantly reduced. <ref type="bibr" target="#b19">[20]</ref> was based on spectral graph convolutional neural networks <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b16">[17]</ref> simplifying to a linear function of first-order and conducted the task of transductive node classification in a large-scale network. The paper <ref type="bibr" target="#b28">[29]</ref> learned a residual Laplacian matrix for each graph and the optimal distance metric parameters shared among the data, then graphs of arbitrary structure and size can be input into the CNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. CONVOLUTION ON GRAPH</head><p>As we have introduced, the graph-structured data is with the irregular structure and completely coordinate-free on vertices and edges. To generalize the idea of common CNNs onto graphs, we would like to review the convolution filter on homomorphic graphs/subgraphs, which is different to the convolution on these gridded images/videos, as shown in <ref type="figure">Fig. 1</ref>.</p><p>Here we mainly introduce the Spectral filtering of graphs, which is also used in our followed experiments.</p><p>For a graph G (V, E), V represents a set of vertices with the number |V| = n and E represents a set of edges. Let W denotes the adjacent matrix representing the topology of G, then W ij = 1 if there is an edge connection between vertices v i and v j , otherwise W ij = 0. Each vertex has a feature or signal denoted as x ∈ R d , and d is the number of feature. The features of all vertices in graph are summarized by X ∈ R n×d .</p><p>Laplacian matrix of combinational definition is</p><formula xml:id="formula_0">L = D − W ∈ R n×n , where D ∈ R n×n is the degree matrix with D ij = j W ij , and the normalized definition is L = I n − D −1/2 WD −1/2 , where I n is identify matrix. As Laplacian matrix is positive semidefinite, there exists a matrix denoted as U which is composed of a set of orthogonal eigenvectors {u 1 , u 2 , u 3 · · · u n } satisfying L = UΛU T , where Λ is a diagonal matrix consisting of eigenvalues {λ 1 , λ 2 , λ 3 · · · λ n }.</formula><p>In Fourier domain, the eigenvalue represents a specific frequency. The eigenvectors {u 1 , u 2 , u 3 · · · u n } are Fourier basis. Then, the graph Fourier transform can be formulated aŝ</p><formula xml:id="formula_1">X = U T X<label>(1)</label></formula><p>and the inverse transformation is given by</p><formula xml:id="formula_2">X = UX<label>(2)</label></formula><p>In the Fourier domain, the filtering operation of graph is given asX</p><formula xml:id="formula_3">out =ĥ(Λ)X<label>(3)</label></formula><p>whereĥ(·) is the spectral operator. Equivalently, we transform it to the time domain as</p><formula xml:id="formula_4">X out = Uĥ(Λ)X = Uĥ(Λ)U T X = U     ĥ (λ 1 )ĥ (λ 2 ) . . .ĥ (λ n )      U T X =ĥ(L)X (4)</formula><p>The spectral filtering is parameterized aŝ</p><formula xml:id="formula_5">h θ (Λ) =     ĥ θ (λ 1 )ĥ θ (λ 2 ) . . .ĥ θ (λ n )      = k=0 θ k Λ k<label>(5)</label></formula><p>In order to reduce the complexity of learning, Chebyshev are used to approximate aŝ</p><formula xml:id="formula_6">h θ ,k (Λ) = K k=0 θ k T k (Λ) (6) where θ k is the Chebyshev polynomial coefficient, T k (Λ) is the Chebyshev approximate polynomial, T 0 (α) = 1, T 1 (α) = α and the recursive formulation is T k (α) = 2αT k−1 (α) − 2αT k−2 (α).</formula><p>Then, the Chebyshev approximate local filter is finally given as</p><formula xml:id="formula_7">X out = Uĥ θ ,k (Λ)U T X = K k=0 θ k T k (L)X<label>(7)</label></formula><p>whereL = 2L λmax − I n , I n is identify matrix. In the following experiments, we set λ max = 2. θ k is the Chebyshev polynomial coefficient that needs to learn.</p><p>In the training process, the cross-entropy loss function is employed for optimizing the parameters of graph CNNs.</p><formula xml:id="formula_8">J(θ) = − i I(y = C i )ln{ŷ i (θ)}<label>(8)</label></formula><p>Samples can be divided into C classes and i ∈ C. y is the label of the sample. I(y = C i ) is the indicative function,</p><formula xml:id="formula_9">I(y = C i ) = 1 when y = C i , otherwise I(y = C i ) = 0.</formula><p>The back-propagation process can be given as</p><formula xml:id="formula_10">∂J(θ) ∂θ = − i I(y = C i ) 1 y i (θ) ∂ŷ i (θ) ∂θ<label>(9)</label></formula><p>IV. TRANSFORMING CLASSIC NETWORK STRUCTURES TO GRAPH CNN In this section, we transform these classic network structures (including ResNet <ref type="bibr" target="#b7">[8]</ref>, Inception <ref type="bibr" target="#b9">[10]</ref> and DenseNet <ref type="bibr" target="#b6">[7]</ref>) to graph CNN and show the structures of three different networks. We will detailedly introduce four graph CNNs with different network structures, i.e., plain Graph CNN, G ResNet, G Inception, G DenseNet.</p><p>(a) (b) <ref type="figure">Fig. 1</ref>. Different convolution operations on graph (left) and gridded image (right) samples. (a) shows the 1-localized convolution on graph data, where the red node has 6 adjacencies, and the green node has 3 adjacencies. In the process of convolution, they use the features of the 6 and 3 nodes respectively, in addition to the feature of their own nodes. (b) shows the convolution operation on the regular gridded data (e.g., images and videos). As long as a fixed-size convolution kernel is given, the convolution kernel will slid from left-to-right and top-to-bottom, all vertices can be then convolved once.</p><formula xml:id="formula_11">Input Conv1 Conv2 Conv3 Conv4 Conv5 Conv6 FC ... Input ... Conv1 Conv2 Conv3 Conv4 Conv5 Conv6 FC ... Input ... Input Input Conv4 Conv5 Conv6 Conv5 Conv5 Conv6 Conv6 Conv FC Conv1 Conv2 Conv3 Conv2 Conv2 Conv3 Conv3 Conv ... ... Conv1 Conv2 Conv3 Conv4 Conv5 Conv6 FC ... ... Conv1 Conv2 Conv3 Conv4 Conv5 Conv6 FC ... Input ... Conv1 Conv2 Conv1 Conv1 Conv2 Conv2 Conv Conv3 Conv4 Conv5 Conv4 Conv4 Conv5 Conv5 Conv Conv2 Conv3 Conv1</formula><p>...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conv4</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conv5</head><p>Conv6 ...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conv4</head><p>Conv5 (b) G Densenet <ref type="figure">Fig. 2</ref>. Graph CNN architectures of the baseline and G Densenet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Plain Graph CNN</head><p>The plain baseline of graph CNN are mainly inspired by the philosophy of VGG nets <ref type="bibr" target="#b5">[6]</ref>, as illustrated in <ref type="figure">Fig. 2(a)</ref>. We stack 6 convolution layers, each of which is followed with a batch normalization and rectified linear layer. Different from the gridded images/videos, on which local convolution kernels can be defined as multiple lattices with various receptive fields, graph CNN can adopt a K-localized convolution for every vertex in a graph <ref type="bibr" target="#b18">[19]</ref>. i.e. K hops from the central vertex. The number of channels in the first three convolution layers is 32, and 64 channels have been set for the last three convolution layers. According to Eq. 7, in the forward propagation of Graph CNN, we denoteX k = T k (L)X, and the k-th iteration X k = 2LX k−1 −X k−2 withX 0 = X andX 1 =LX, where X ∈ R n×d is the initial feature map of graph data. For the K-localized convolution,X K is the result of K-th iteration. Here the receptive field K of all convolution layers is simply set to 6. The plain Graph CNN ends with a fully-connected layer with softmax, which dimension equals to the number of classes in the graph datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Dense Graph CNN</head><p>DenseNet combines features by concatenating them instead of combining features through summation. DenseNet improve flow of information and gradients throughout the network, which makes network easy to train. Based on the plain Graph CNN, we construct Dense graph CNN (G DenseNet) by connecting each layer to every other layer in a feed-forward fashion, which is shown in <ref type="figure">Fig. 2(b)</ref>. The input of each convolutional layer is the output of all previous convolutions, and the output of each convolutional layer must be used as the input of following convolutions. As the number of feature maps per layer gradually increases, the size of Θ i also increases from layer to layer. We can formulate Dense graph CNN as</p><formula xml:id="formula_12">Y 0 = F dens (X K , Θ 0 ) Y 1 = F dens (X K ||Ȳ 0K , Θ 1 ) Y 2 = F dens (X K ||Ȳ 0K ||Ȳ 1K , Θ 2 ) · · · Y l = F dens (X K ||Ȳ 0K || · · · ||Ȳ l−1 K , Θ l )<label>(10)</label></formula><p>where Y 0 , Y 1 , · · · , Y l denote the output of different convolution layers,X K ,Ȳ 0K , · · · ,Ȳ l−1 K correspond to the Klocalized convolution of input graph signals. Based on the feature information of all preceding layers, the function F dnes (·) represents the dense operation to be learned by convolution layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Residual Graph CNN</head><p>Based on the above plain network, similar to the ResNet <ref type="bibr" target="#b7">[8]</ref>, we insert shortcuts connections which turn the plain Graph CNN into its residual version. The residual graph CNN is built by stacking two residual graph blocks, each of which consists of the residual part and identity mapping. The residual part consists of three convolutions, each of which is followed by a batch normalization and a rectified linear layer, and the identity mapping has a linear projection to match the same dimensions. The residual graph block is formulated as</p><formula xml:id="formula_13">Y = F res (X K , {Θ 0 , Θ 1 , Θ 2 }) +X K Θ s ,<label>(11)</label></formula><p>where Θ 0 , Θ 1 , Θ 2 are the parameters of three different convolution layers, respectively. Θ s is a linear projection matrix of identity mapping. The function F res (X K , {Θ 0 , Θ 1 , Θ 2 }) represents the residual mapping to be learned by three convolution layers. Each convolution layer is followed by a batch normalization (BN) layer and ReLU activation function. Every convolution of the first residual graph block is 32 channels, the second is 64 channels. The receptive field is set to 6 (i.e., K=6). For simplicity, the residual graph CNN is named as G ResNet, and the corresponding architecture is illustrated in <ref type="figure">Fig.3(a)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Inception Graph CNN</head><p>For the Inception graph CNN named as G Inception, we stack two Inception graph blocks that both followed by one convolution layer 3(b). Each Inception graph block is composed of four tributaries. Each tributary of the first three tributaries contains two convolutions and the last tributary contains one convolution. According to Eq. 7, we choose convolution layers with different receptive fields at different tributaries for better capturing various information of graph data. For the j-th convolution of the i-th tributary, Θ ij represents the corresponding parameter matrix. The Inception graph block can be given as</p><formula xml:id="formula_14">Y =F inc (X K1 , {Θ 00 , Θ 01 }) || F inc (X K2 , {Θ 10 , Θ 11 }) || F inc (X K3 , {Θ 20 , Θ 21 }) || F inc (X K4 , {Θ 30 }),<label>(12)</label></formula><p>where the symbol "||" represents concatenation <ref type="bibr" target="#b29">[30]</ref> among convolution layers, Each convolution layer is also followed by a batch normalization (BN) layer and ReLU activation function. The function F inc (·) denotes how to represent the graph information with a prescribed receptive field in each path of inception block, and receptive fields are not exactly the same in different tributaries.</p><p>In the graph Inception block, the receptive fields of convolution layers in the first three paths can be set as K 1 = 3, K 2 = 6 and K 3 = 9, respectively. And the rest path only includes one convolution layer, and we choose K 4 = 6 as the size of receptive field. Such a designed Inceptive structure can take multi-scale information of graph signal into account. The convolution layers in the first Inception graph block is with 32 channels, the second is with 64 channels. The receptive field is set to 6 of both "Conv3" with 32 channels and "Conv6" with 64 channels followed by two graph Inception block.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTS</head><p>In the section, we evaluate the performance of four different graph CNN structures on several public benchmark datasets including bioinformatics and social network datasets. They are all undirected graphs and their global properties are summarized in <ref type="table" target="#tab_2">Table I</ref>  <ref type="bibr" target="#b30">[31]</ref>. We first introduce the datasets and experimental setups, and then report and analyze the experimental results, after which a further discussion will be held about different parameters of Graph CNN. ...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conv1_2</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conv2_2</head><p>Conv1_1 Conv1_3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conv2_1 Conv2_3</head><p>Conv12 Conv3 (b) G Inception <ref type="figure">Fig. 3</ref>. Graph CNN architectures of G ResNet and G Inception.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Datasets</head><p>Bioinformatics datasets. MUTAG <ref type="bibr" target="#b31">[32]</ref> is a nitro compounds dataset including 188 samples and divided into 2 classes. PTC <ref type="bibr" target="#b32">[33]</ref> consists of compounds labeled according to carcinogenicity on rodents with 19 vertex labels. NCI109 <ref type="bibr" target="#b33">[34]</ref> is a balanced dataset of chemical compounds screened for activity against non-small cell lung cancer and ovarian cancer cell, and they contain 4110 and 4127 chemical compounds, respectively. ENZYMES <ref type="bibr" target="#b34">[35]</ref> is a dataset of 600 protein tertiary structures obtained from the BRENDA enzyme database. The ENZYMES dataset contains 6 enzymes.</p><p>Social network datasets. These social network datasets come from <ref type="bibr" target="#b35">[36]</ref>. We use the number of neighbors of each node as the label of the node. COLLAB is a scientific collaboration dataset containing ego-networks of different researchers from three subfields of Physics. The task can then determine whether the ego-collaboration network belongs to any of three classes: High Energy Physics, Condense Mater Physics and Astro Physics. IMDB-BINARY and IMDB-MULTI are movie collaboration datasets. Each graph represents a movie. Each vertex represents an actor that appears in the movie. IMDB-BINARY are constructed from Action and Romance genres. IMDB-MULTI contain three classes: Comedy, Romance and Sci-Fi. The task is to predict which genre a graph belongs to.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Experimental Setups</head><p>We train four different graph CNNs, which structures has been described in Section IV. Each dataset is divided into 10 groups, of which nine are used to train the network and the remaining one is used for testing. We carry out 10-fold cross validation, and its average results can be used as the final accuracy rates. The prediction accuracy is expressed in form of "standard ± deviation" in graph classification benchmark datasets. For each cross-validation, we train 300 epochs using Momentum Optimizer and the learning rate is set to 0.01. In addition, the momentum is 0.9 and the decay rate is with 0.95. We use cross entropy as loss function. For the baseline Graph CNN, G ResNet and G DenseNet, the receptive field of each convolution layer is set to 6. For G Inception, it can merge multi-scale information of graph signals. Therefore, in the G Inception block, for each of the two convolutions, we set 3, 6 and 9 as the receptive fields, respectively. And for the rest only one convolution, We choose the middle 6 as its receptive field. To prevent overfitting, we add a dropout layer followed the fully connected layer, which can randomly discard half of the neurons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Results and comparisons</head><p>We compare the proposed Graph CNNs (i.e., baseline Graph CNN, G ResNet, G DenseNet and G Inception) with several state-of-the-art approaches on seven graph datasets, such as random walk kernel (RW) <ref type="bibr" target="#b36">[37]</ref>, the graphlet kernels (GK) <ref type="bibr" target="#b37">[38]</ref>, the Weisfeiler-Lehman subtree kernels (WL) <ref type="bibr" target="#b38">[39]</ref>, Feature-Based (FB) <ref type="bibr" target="#b16">[17]</ref>, Deep Graphlet (DGK) and DWL <ref type="bibr" target="#b39">[40]</ref>, the convolutional neural network (PSCN) <ref type="bibr" target="#b11">[12]</ref>, the shift aggregate extract network (SAEN) <ref type="bibr" target="#b1">[2]</ref> and the dynamics based features (DyF) <ref type="bibr" target="#b30">[31]</ref>. The performance of four Graph CNNs and comparisons with several state-of-the-art methods are shown in table II. Overall, the experimental performance of the our four Graph CNN structures is superior to other existing methods. Comparing with kernel based method <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b39">[40]</ref>, feature based method <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b30">[31]</ref>, convolution neural network (PSCN) <ref type="bibr" target="#b11">[12]</ref> and shift aggregate extract network (SAEN) <ref type="bibr" target="#b1">[2]</ref>, all our graph CNN structures with spectral filtering method achieve the state-of-the-art performance on all datasets and obtain a significantly improvement on MUTAG, PTC, ENZYMES and IMDB-BINARY datasets in contrast to the second best performance. G ResNet achieves state-of-theart on two social network datasets: 79.90% vs 72.87% <ref type="bibr" target="#b30">[31]</ref> on IMDB-BINARY and 54.43% vs 50.55% <ref type="bibr" target="#b38">[39]</ref> on IMDB-MULTI. G Inception can significantly outperform these stateof-the-art algorithms on two datasets: 95.00% vs 92.63% <ref type="bibr" target="#b11">[12]</ref> on MUTAG and 67.50% vs 53.43% <ref type="bibr" target="#b39">[40]</ref> on ENZYMES. G DenseNet shows much improvement than other methods on two bioinformatic datasets: 73.24% vs 60.00% <ref type="bibr" target="#b11">[12]</ref> on PTC and 80.66% vs 80.32% [40] on NCI109 and 83.16% vs 80.61% [31] on COLLAB. Our graph CNNs are able to render very impressive results. The performance pf graph recognition can be further improved to some extent when we deepen these three graph CNN and the results are reported in the following discussion.</p><p>When comparing the performance of the baseline Graph CNN, G ResNet, G Inception and G DenseNet, different Graph CNN models have the certain advantages on various types of graph datasets. The structures of ResNet, Inception and DenseNet were proposed initially to boost the performance of deep convolution networks from different aspects, such as residual learning, considering information in multiple receptive fields, densely employing multi-level representations. For better show how to transform these CNN structures to Graph CNNs, the proposed G ResNet, G Inception and G DenseNet can still outperform our baseline network, which is a simple 6-layer graph CNN framework. For example, our G Inception model on the ENZYMES dataset can significantly outperform the baseline network, 67.50% vs 64.83%. This indicates that our G Inception model can introduce greater data diversity in multiple receptive fields and improve the network performance of graph data. We achieve much better performance with the G DenseNet framework then the baseline network on PTC dataset, e.g., 73.24% vs 71.76%. It demonstrates that the G DenseNet perform very well on the graph recognition problem by simultaneously considering different level information. The accuracies of G ResNet have been improved on IMDB-BINARY and IMDB-MULTI datasets, which also show its capability by transforming the ResNet structure to Graph CNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Discussion</head><p>Deeper graph CNN: Here we explore how deeper graph CNNs impact the performance of graph recognition. For G ResNet and G Inception networks, the number of convolution layers can be set to: 3 layers, 6 layers, 9 layers and 12 layers, respectively. Considering that each previous result in G DenseNet will be used as the input to the convolution layer behind. In this way, the number of parameters in the last few layers is huge, and the amount of calculations also increases dramatically. Therefore the number of convolution layers is set to: 4 layers, 6 layers, 8 layers and 10 layers for G DenseNet. We choose a small dataset MUTAG with 188 nodes and a large dataset NCI109 with 4127 nodes described above. All experiments of exploring deeper graph CNN are (c) G Densenet <ref type="figure">Fig. 4</ref>. Performance comparison of G ResNet, G Inception, G DenseNet with different number of convolution layers. Experiments are conducted on two datasets : MUTAG (a small dataset with 188 nodes) and NCI109 (a large dataset with 4127 nodes). performed on these two datasets, and the experimental results are reported in <ref type="figure">Fig. 4</ref>.</p><p>For the G ResNet model, we stack 3-layer convolution for each residual graph block. In order to build deeper G ResNet, we stack 6-layer, 9-layer, 12-layer convolution by 2, 3, 4 residual graph block, respectively. The <ref type="figure">Fig. 4(a)</ref> shows the comparisons of different G ResNet with different number of network layers on MUTAG and NCI109 datasets. For MUTAG dataset, the results of G ResNet models, which are with 3-layer convolution, the 6-layer convolution, the 9-layer convolution, and the 12-layer convolution, can achieve 92.22%, 94.44%, 94.44% and 95%, respectively. For NCI109 dataset, the performance of different G ResNet models are 77.33%, 80.27%, 81.07% and 81.21%, respectively. In the G Inception network, we further observe the changes of classification performance by stacking different number of inception blocks. Stacking 3layer convolution means that there is only one Inception graph block in the G Inception model. Stacking 6-layer, 9-layer, 12layer convolution means that there are 2,3,4 Inception graph block in G Inception, respectively. As can be illustrated in the <ref type="figure">Fig. 4(b)</ref>, the performance of 3-layer G Inception model is 92.78% on MUTAG dataset. The G Inception with 12layer convolution is better than with the 3-layer convolution, e.g., 95.56% vs 92.78%. For NCI109 dataset, the results with different deeper G Inception models are 77.31%, 80.32%, 81.24% and 80.56%, respectively. The G Inception network with 9-layer convolution achieves the highest performance 81.24% and improves the average accuracy by 3.93% than the G Inception model with the 3-layer convolution. Similar to comparisons of G ResNet and G Inception, we explore the performance of G DenseNet with 4-layer, 6-layer, 8layer and 10 layer network, respectively. As reported in <ref type="figure">Fig.  4(c)</ref>, the G Inception network with the 12-layer convolution can outperform the G Inception with 3-layer convolution by 2.22%. On the NCI109 dataset, The G Inception with 12layer convolution is better than with the 3-layer convolution, e.g., 81.19% vs 78.62%. We can observe that as the number of convolution layers increases, the classification accuracy increases. Another reasonable explanation is that deeper Graph CNN models abstract higher-level presentations that will also help improve the performance of graph recognition.</p><p>Extend the receptive field of convolution layer. For G ResNet and G DenseNet, we also explore the performance of different receptive fields. The structure of G Inception has been combined with a variety of receptive fields information, so we don't conduct this discussion on it. In different G Inception networks, the size of receptive field is set to: 3, 6 and 9, respectively. We think that the selection (b) G Densenet <ref type="figure">Fig. 5</ref>. Performance comparison of G ResNet and G Densenet with different receptive fields on two datasets : MUTAG (a small dataset with 188 nodes) and NCI109 (a large dataset with 4127 nodes). The size of receptive field can be set to 3, 6 and 9, respectively. of receptive fields, which is important for graph CNN, can consider different local structural information. The experiment is performed on the same two datasets: MUTAG and NCI109, and the comparisons of different receptive fields are reported in <ref type="figure">Fig. 5</ref>. With the 3, 6 and 9 receptive fields of G ResNet, we can observe accuracies of 91.67%, 94.44%, 92.78% on MUTAG dataset, and 78.45%, 80.27%, 79.85% on NCI109 dataset (see <ref type="figure">Fig. 5(a)</ref>). When the receptive field is set to 6, the performance of G ResNet is highest on both datasets. As can be reported in <ref type="figure">Fig. 5(b)</ref>, we can observe that different G DenseNet models with 3, 6, 9 receptive fields can gain 92.22%, 94.44%, 93.33% on MUTAG dataset, and 79.15%, 80.66%, 79.85% on NCI109 dataset. The performance is also highest when the receptive field is set to 6 in the G DenseNet model. It demonstrates that extracted representations of graph signals are overly complex and too small to represent useful features, when the size of the receptive field is too large. If the receptive field is too small, local structural features may not be extracted, and the performance of graph CNN will be reduced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSIONS AND FUTURE WORK</head><p>In this work, we have given a comprehensive analysis of when work matters by transforming classical network structures to graph CNN, particularly for the basic graph recognition task. Inspired by the basic ideas of ResNet, DenseNet and Inception network, we have constructed different Graph CNN architectures, including the plain graph CNN, G ResNet, G Inception, G DenseNet. By constructing the G Inception network, we focus on considering different receptive fields of graph signals in the process of convolution, while G DenseNet is responsible for capturing different-level representations of graph CNN. The G ResNet is benefit to constructing deeper graph networks with the help of residual learning. Extensive experimental results clearly demonstrated that effective of the proposed G ResNet, G Inception, G DenseNet models for the problem of graph recognition. In the future, we will further extent the Graph CNN architectures for generic understanding tasks, e.g., image restoration, social network analysis, visual understanding, etc.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Input...</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>...</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Input Conv2 Conv3 Conv1 ... Conv4 Conv5 Conv6</cell><cell>Conv1 Conv2 Conv3 Conv4 Conv5 Conv6 FC ... ...</cell><cell>Conv1 Conv2 Conv4 Conv5</cell><cell>Input Conv1 ... Conv2 Conv3 Conv4 Conv5 Conv6</cell><cell>Conv1 Conv2 Conv4 Conv5</cell><cell>Conv2 Conv3 Conv1 ... Conv4 Conv5 Conv6</cell><cell>Conv Conv</cell><cell>Conv4_1 Conv5_1</cell><cell>Conv1 Conv2 Conv3 Conv4 Conv5 Conv6 FC ... ... Conv6 Conv4_2 Input Conv1 Conv2 Conv4 Conv5 Conv5_2 Conv4_3 Conv5_3</cell><cell>Input Conv45 ... Conv1 Conv2 Conv3 Conv4 Conv5 Conv6</cell><cell>Conv1 Conv2 Conv4 Conv5</cell><cell>Conv Conv</cell></row><row><cell>FC</cell><cell></cell><cell></cell><cell>FC</cell><cell></cell><cell>FC</cell><cell></cell><cell></cell><cell>FC</cell><cell>FC</cell><cell></cell><cell></cell></row><row><cell>...</cell><cell></cell><cell></cell><cell>...</cell><cell></cell><cell>...</cell><cell></cell><cell></cell><cell>...</cell><cell>...</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">(a) G ResNet</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE I SUMMARY</head><label>I</label><figDesc>OF GRAPH DATASETS USED IN OUR EXPERIMENTS.</figDesc><table><row><cell>Dataset</cell><cell cols="5">Num graphs Classes Node labels Avg nodes Avg edges</cell></row><row><cell>MUTAG [32]</cell><cell>188</cell><cell>2</cell><cell>7</cell><cell>17.93</cell><cell>19.79</cell></row><row><cell>PTC [33]</cell><cell>344</cell><cell>2</cell><cell>19</cell><cell>14.29</cell><cell>14.69</cell></row><row><cell>NCI109 [34]</cell><cell>4127</cell><cell>2</cell><cell>38</cell><cell>29.68</cell><cell>32.13</cell></row><row><cell>ENZYMES [35]</cell><cell>600</cell><cell>6</cell><cell>3</cell><cell>32.63</cell><cell>62.14</cell></row><row><cell>COLLAB [36]</cell><cell>5000</cell><cell>3</cell><cell>-</cell><cell>74.49</cell><cell>2457.78</cell></row><row><cell>IMDB-BINARY [36]</cell><cell>1000</cell><cell>2</cell><cell>-</cell><cell>19.77</cell><cell>96.53</cell></row><row><cell>IMDB-MULTI [36]</cell><cell>1500</cell><cell>3</cell><cell>-</cell><cell>13.0</cell><cell>65.94</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE II COMPARISON</head><label>II</label><figDesc>OF GRAPH RECOGNITION PERFORMANCES WITH DIFFERENT GRAPH CNN MODELS AND SEVERAL STATE-OF-THE-ARTS ON GRAPH DATASETS.</figDesc><table><row><cell cols="3">Dataset</cell><cell></cell><cell>MUTAG</cell><cell></cell><cell>PTC</cell><cell></cell><cell></cell><cell cols="2">NCI109</cell><cell></cell><cell cols="3">ENZYMES</cell><cell>COLLAB</cell><cell>IMDB-B</cell><cell>IMDB-M</cell></row><row><cell cols="3">RW [37]</cell><cell></cell><cell>83.72 ± 1.50</cell><cell></cell><cell cols="2">57.85 ± 1.30</cell><cell></cell><cell cols="3">49.75 ± 0.60</cell><cell cols="3">24.16 ± 1.64</cell><cell>69.01 ± 0.09</cell><cell>64.54 ± 1.22</cell><cell>34.54 ± 0.76</cell></row><row><cell cols="3">GK [38]</cell><cell></cell><cell>81.66 ± 2.11</cell><cell></cell><cell cols="2">57.26 ± 1.41</cell><cell></cell><cell cols="3">62.60 ± 0.19</cell><cell cols="3">26.61 ± 0.99</cell><cell>72.84 ± 0.28</cell><cell>65.87 ± 0.98</cell><cell>43.89 ± 0.38</cell></row><row><cell cols="3">WL [39]</cell><cell></cell><cell>80.72 ± 3.00</cell><cell></cell><cell cols="2">56.97 ± 2.01</cell><cell></cell><cell cols="3">80.22 ± 0.34</cell><cell cols="3">53.15 ± 1.14</cell><cell>77.79 ± 0.19</cell><cell>72.86 ± 0.76</cell><cell>50.55 ± 0.55</cell></row><row><cell cols="3">FB [17]</cell><cell></cell><cell>84.66 ± 2.01</cell><cell></cell><cell cols="2">55.58 ± 2.30</cell><cell></cell><cell cols="3">62.43 ± 1.13</cell><cell cols="3">29.00 ± 1.16</cell><cell>76.35 ± 1.64</cell><cell>72.02 ± 4.71</cell><cell>47.34 ± 3.56</cell></row><row><cell cols="4">DGK [40]</cell><cell>82.66 ± 1.45</cell><cell></cell><cell cols="2">57.32 ± 1.13</cell><cell></cell><cell cols="3">62.69 ± 0.23</cell><cell cols="3">27.08 ± 0.79</cell><cell>73.09 ± 0.25</cell><cell>66.96 ± 0.56</cell><cell>44.55 ± 0.52</cell></row><row><cell cols="4">DWL [40]</cell><cell>82.94 ± 2.68</cell><cell></cell><cell cols="2">59.17 ± 1.56</cell><cell></cell><cell cols="3">80.32 ± 0.33</cell><cell cols="3">53.43 ± 0.91</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell cols="4">PSCN [12]</cell><cell>92.63 ± 4.21</cell><cell></cell><cell cols="2">60.00 ± 4.82</cell><cell></cell><cell></cell><cell>-</cell><cell></cell><cell></cell><cell>-</cell><cell>72.60 ± 2.15</cell><cell>71.00 ± 2.29</cell><cell>45.23 ± 2.84</cell></row><row><cell cols="4">SAEN [2]</cell><cell>84.99 ± 1.82</cell><cell></cell><cell cols="2">57.04 ± 1.30</cell><cell></cell><cell></cell><cell>-</cell><cell></cell><cell></cell><cell>-</cell><cell>75.63 ± 0.31</cell><cell>71.26 ± 0.74</cell><cell>49.11 ± 0.64</cell></row><row><cell cols="3">DyF [31]</cell><cell></cell><cell>88.00 ± 2.37</cell><cell></cell><cell cols="2">57.15 ± 1.47</cell><cell></cell><cell cols="3">66.72 ± 0.20</cell><cell cols="3">33.21 ± 1.20</cell><cell>80.61 ± 1.60</cell><cell>72.87 ± 4.05</cell><cell>48.12 ± 3.56</cell></row><row><cell cols="4">Our baseline</cell><cell>93.89 ± 6.31</cell><cell></cell><cell cols="2">71.76 ± 7.58</cell><cell></cell><cell cols="3">80.51 ± 2.67</cell><cell cols="3">64.83 ± 5.45</cell><cell>82.96 ± 0.86</cell><cell>79.70 ± 3.66</cell><cell>54.40 ± 4.88</cell></row><row><cell cols="4">G ResNet</cell><cell>94.44 ± 5.56</cell><cell></cell><cell cols="2">73.24 ± 8.05</cell><cell></cell><cell cols="3">80.27 ± 2.56</cell><cell cols="3">66.83 ± 7.47</cell><cell>82.64 ± 0.99</cell><cell>79.90 ± 3.96 54.53 ± 4.25</cell></row><row><cell cols="4">G Inception</cell><cell cols="2">95.00 ± 4.61</cell><cell cols="2">72.94 ± 6.28</cell><cell></cell><cell cols="3">80.32 ± 1.73</cell><cell cols="3">67.50 ± 5.54</cell><cell>82.58 ± 1.28</cell><cell>78.40 ± 3.72</cell><cell>54.53 ± 4.71</cell></row><row><cell cols="4">G DenseNet</cell><cell>94.44 ± 4.30</cell><cell></cell><cell cols="6">73.24 ± 6.64 80.66 ± 2.49</cell><cell cols="3">66.83 ± 4.86</cell><cell>83.16 ± 1.00</cell><cell>79.20 ± 4.19</cell><cell>54.40 ± 4.70</cell></row><row><cell></cell><cell>100</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>100</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>100</cell></row><row><cell></cell><cell>95</cell><cell>92.22</cell><cell cols="2">94.44 94.44 95</cell><cell></cell><cell>3Layers 6Layers 9Layers</cell><cell></cell><cell>95</cell><cell>92.78</cell><cell>95 94.44</cell><cell>95.56</cell><cell></cell><cell></cell><cell>3Layers 6Layers 9Layers</cell><cell>95</cell><cell>92.78</cell><cell>94.44 95</cell><cell>95</cell><cell>4Layers 6Layers 8Layers</cell></row><row><cell></cell><cell>90</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>12Layers</cell><cell></cell><cell>90</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>12Layers</cell><cell>90</cell><cell>10Layers</cell></row><row><cell></cell><cell>85</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>85</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>85</cell></row><row><cell>Accuracy</cell><cell>80</cell><cell></cell><cell></cell><cell>77.33</cell><cell cols="2">80.27 81.07 81.21</cell><cell>Accuracy</cell><cell>80</cell><cell></cell><cell></cell><cell></cell><cell>77.31</cell><cell>80.32</cell><cell>81.24 80.56</cell><cell>Accuracy</cell><cell>80</cell><cell>78.62</cell><cell>80.66 81.09 81.19</cell></row><row><cell></cell><cell>75</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>75</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>75</cell></row><row><cell></cell><cell>70</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>70</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>70</cell></row><row><cell></cell><cell>65</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>65</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>65</cell></row><row><cell></cell><cell>60</cell><cell></cell><cell>MUTAG</cell><cell></cell><cell></cell><cell>NCI109</cell><cell></cell><cell>60</cell><cell></cell><cell>MUTAG</cell><cell></cell><cell></cell><cell cols="2">NCI109</cell><cell>60</cell><cell>MUTAG</cell><cell>NCI109</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>(a) G ResNet</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">(b) G Inception</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Email address: {wtingzhao, cyx, zhen.cui, csjyang}@njust.edu.cn (W. Zhao, C. Xu, Z. Cui and J. Yang), tongzhang@seu.edu.cn (T. Zhang), zhangjesse@foxmail.com (Z. Zhang).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>ACKNOWLEDGMENT This work was supported by the National Natural Science Foundation of China (Grant 61073094 and U1233119). This research was partly supported under Australian Research Council Discovery Projects funding scheme (project DP140102270).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Time-variant graph classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.04350</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Shift aggregate extract networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Orsini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Baracchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Frasconi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.05537</idno>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Graph kernels for disease outcome prediction from proteinprotein interaction networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">N</forename><surname>Schraudolph</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pacific Symposium on Biocomputing Pacific Symposium on Biocomputing</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="4" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">The pagerank citation ranking: Bringing order to the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Brin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Motwani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Winograd</surname></persName>
		</author>
		<idno>1999-66</idno>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">R</forename><surname>Chung</surname></persName>
		</author>
		<title level="m">Spectral graph theory</title>
		<imprint>
			<publisher>American Mathematical society</publisher>
			<date type="published" when="1997" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning convolutional neural networks for graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Niepert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kutzkov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">DGCNN: disordered graph convolutional neural network based on the gaussian mixture model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.03563</idno>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Geometric deep learning on graphs and manifolds using mixture model cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Boscaini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rodola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Svoboda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Graph attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10903</idno>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">I</forename><surname>Shuman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Frossard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Spectral networks and locally connected networks on graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Henaff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.05163</idno>
		<title level="m">Deep convolutional networks on graph-structured data</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Convolutional neural networks on graphs with fast localized spectral filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Facial expression recognition with convolutional neural networks: coping with few data and the training sample order</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">T</forename><surname>Lopes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Aguiar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">F</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Oliveira-Santos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="610" to="628" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Human detection from images and videos: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">O</forename><surname>Ogunbona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="148" to="175" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Two-stream convolutional networks for action recognition in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="568" to="576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A deep convolutional neural network for video sequence background subtraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Babaee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">T</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Rigoll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="635" to="649" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Network in network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Convolutional neural networks at constrained time cost</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015-06" />
			<biblScope unit="page" from="5353" to="5360" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Highway networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.00387</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Structured sequence modeling with graph convolutional recurrent networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.07659</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Adaptive graph convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.03226</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Mixed link networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.01808</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Dynamics based features for graph classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">G</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chiem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-C</forename><surname>Delvenne</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.10817</idno>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Structure-activity relationship of mutagenic aromatic and heteroaromatic nitro compounds. correlation with molecular orbital energies and hydrophobicity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Debnath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Lopez De Compadre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Debnath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Shusterman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hansch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of medicinal chemistry</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Statistical evaluation of the predictive toxicology challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Toivonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kramer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Helma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Comparison of descriptor spaces for chemical compound retrieval and classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">A</forename><surname>Watson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Karypis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge and Information Systems</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Protein function prediction via graph kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schönauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deep graph kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Yanardag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">On graph kernels: Hardness results and efficient alternatives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gärtner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Flach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wrobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Learning Theory and Kernel Machines</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Efficient graphlet kernels for large graph comparison</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shervashidze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Petri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mehlhorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Borgwardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Weisfeiler-lehman graph kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shervashidze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Schweitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Leeuwen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mehlhorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="2539" to="2561" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Deep graph kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Yanardag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
