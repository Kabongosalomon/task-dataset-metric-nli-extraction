<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Rethinking the CSC Model for Natural Images</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dror</forename><surname>Simon</surname></persName>
							<email>dror.simon@cs.technion.ac.il</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science Technion</orgName>
								<address>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Elad</surname></persName>
							<email>elad@cs.technion.ac.il</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science Technion</orgName>
								<address>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Rethinking the CSC Model for Natural Images</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T21:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Sparse representation with respect to an overcomplete dictionary is often used when regularizing inverse problems in signal and image processing. In recent years, the Convolutional Sparse Coding (CSC) model, in which the dictionary consists of shift invariant filters, has gained renewed interest. While this model has been successfully used in some image processing problems, it still falls behind traditional patch-based methods on simple tasks such as denoising. In this work we provide new insights regarding the CSC model and its capability to represent natural images, and suggest a Bayesian connection between this model and its patch-based ancestor. Armed with these observations, we suggest a novel feed-forward network that follows an MMSE approximation process to the CSC model, using strided convolutions. The performance of this supervised architecture is shown to be on par with state of the art methods while using much fewer parameters.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The field of image restoration deals with the recovery of degraded images. Popular forms of degradation include an additive noise, a blurring kernel, missing pixels, and more. Retrieving an image from its degraded version is typically an ill-posed problem. Therefore, to enable the inversion task, it is necessary to include prior information on the original signal. An image prior, also referred to as an image model, relates to a mathematical description of the image true distribution. In the past 2-3 decades, many such models have been suggested and deployed. Some of these include reliance on spatial smoothness, self-similarity, and sparse representation <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref>. The later is the focus of this work. The sparse representation model has been successfully incorporated in various signal and image processing applications <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref>. This model assumes that a signal X ∈ R N is formed by a linear combination of only a few atoms, taken from the dictionary D ∈ R N ×M , i.e. X = DΓ, where Γ ∈ R M is sparse. When a noisy signal Y = X + V ∈ R N is at hand (V is a bounded energy noise: V 2 ≤ ), seeking for its sparse representation Γ, leads to an estimation of the original signal via X = D Γ. Finding Γ is commonly referred to as sparse-coding or a pursuit, formulated as min</p><formula xml:id="formula_0">Γ Γ 0 s.t. DΓ − Y 2 ≤ ,<label>(1)</label></formula><p>where the 0 pseudo-norm counts the number of non-zeros in the vector. <ref type="bibr" target="#b0">1</ref> Sparse coding is NP-hard in general <ref type="bibr" target="#b9">[10]</ref>, hence approximation methods are used. A common approach replaces the 0 pseudonorm with the 1 , leading to a convex problem termed Basis-Pursuit (BP) <ref type="bibr" target="#b10">[11]</ref>. The BP method has been theoretically analyzed <ref type="bibr" target="#b11">[12]</ref>, shown to successfully recover a solution close to the original sparse representation, depending on properties of the dictionary and the cardinality of the sought solution.</p><p>The dictionary is an important ingredient in the formation of this prior, as its atoms characterize the signals that this model can represent sparsely. Learning the dictionary from the corrupted signal itself, or from an external dataset, has been shown to be quite effective, leading to the development of various dictionary learning algorithms and their use <ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref>. Unfortunately, due to the curse of dimensionality, these algorithms are applicable only for reasonably sized signals. Many algorithms overcome this limitation by dividing the complete signal (e.g. a complete image) into fully overlapping small patches, treating each independently <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b16">17]</ref>. This treatment consists of imposing the sparse representation model on the patches using a local dictionary D L ∈ R n×m ,</p><formula xml:id="formula_1">∀i : min αi α i 0 s.t. D L α i − P i Y 2 ≤ ,<label>(2)</label></formula><p>where P i ∈ R n×N extracts the i-th patch from Y (n N ), and its representation α i ∈ R m is assumed to be sparse. Once clean estimates of the patches are found, this process proceeds by Patch Averaging (PA), i.e. merging all the refined patches together to form a final global estimate of the clean image:</p><formula xml:id="formula_2">X = 1 n i P T i D L α i ,<label>(3)</label></formula><p>where P T i places D L α i in the i-th location in the constructed image. Intuitively, operating independently on patches must be sub-optimal, since the dependencies between the patches are falsely neglected <ref type="bibr" target="#b17">[18]</ref>. To overcome this flaw, past work suggested enforcing the local prior on the patches of the merged image <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b18">19]</ref>, leveraging the self-similarity between different patches <ref type="bibr" target="#b19">[20]</ref>, and more.</p><p>Recently, there has been a renewed interest in global models that may overcome this local-global dichotomy. The Convolutional Sparse Coding (CSC) prior <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22]</ref> replaces the traditional patchbased model with a global shift-invariant one. Instead of operating on patches, it suggests a global dictionary constrained by a specific structure -a concatenation of banded circulant matrices 2 , limiting the degrees of freedom introduced by the general sparsity-based model. Various algorithms have been suggested to efficiently handle the global pursuit <ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref>. These methods have been augmented by efficient dictionary learning algorithms <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref><ref type="bibr" target="#b29">[30]</ref>. A recent work provided theoretical guarantees for the CSC model and its corresponding global pursuit results <ref type="bibr" target="#b30">[31]</ref>.</p><p>The CSC model has shown great success in several natural image processing tasks such as image separation, image fusion, and super-resolution, matching or outperforming local-based methods <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b31">[32]</ref><ref type="bibr" target="#b32">[33]</ref><ref type="bibr" target="#b33">[34]</ref>. Interestingly, one can find two common properties to all these success stories. The first is the fact that the CSC is merely used as a complementary component, modeling only the texture part of the image, after stripping its low-frequencies. Second, these applications assume noiseless images, and thus the CSC cannot fail in over-fitting the data. Indeed, when brought to other classical tasks, such as image denoising or other inverse problems that involve an additive noise, the CSC has been shown to fail utterly.</p><p>The main contribution of this work is in providing novel insights regarding the CSC for modeling natural images, and extending the applicability of this prior while tying it to deep-learning. We propose an explanation for the incompetence of this model in representing natural images reliably, and show that PA can be perceived as a Minimum Mean Square Error (MMSE) approximation to the CSC. Building on this, we suggest to improve this approximation and obtain a CSC estimation process that operates directly on an image without any pre-processing steps. Finally, we leverage these observations to implement a feed-forward Convolutional Neural Network (CNN) whose layers strictly correspond to each step in the processing flow of sparse-coding based image denoising. Our results are on par with current state of the art supervised methods while drastically reducing the number of parameters. The CSC model considers a shift-invariant property in the signal, by assuming that 3 X ∈ R N is constructed by a sum of m convolutions of sparse feature maps <ref type="figure">Figure 1</ref>: The CSC model and its components.</p><formula xml:id="formula_3">{Z i } m i=1 ∈ R N by filters {d i } m i=1 of =</formula><p>length n N . CSC then refers to solving the following optimization problem:</p><formula xml:id="formula_4">min {Zi} m i=1 m i=1 Z i 0 s.t. X = m i=1 d i * Z i .<label>(4)</label></formula><p>Equivalently, we define a single global sparse representation vector Γ ∈ R N m , constructed by interlacing the sparse feature maps {Z i } m i=1 . A global dictionary is then composed as follows: Let D L ∈ R n×m represent a local dictionary whose columns are the filters {d i } m i=1 ; then D contains N shifts of this local dictionary -see <ref type="figure">Figure 1</ref>. Under this description, (4) is equivalent to</p><formula xml:id="formula_5">min Γ Γ 0 s.t. X = DΓ.<label>(5)</label></formula><p>When noisy measurements Y are at hand, (5) is modified to allow for variations in the signal, leading to the problem defined in Equation <ref type="bibr" target="#b0">(1)</ref>.</p><p>We introduce additional definitions, taken from <ref type="bibr" target="#b30">[31]</ref>, which will aid in our exposition. The sparse representation vector Γ can be thought of N concatenated vectors α i ∈ R m , termed needles. Each describes the contribution of the m filters when aligned to the i-th element in X, i.e.</p><formula xml:id="formula_6">X = DΓ = N i=1 P T i D L α i = N i=1 P T i s i ,<label>(6)</label></formula><p>where we have defined the slice s i = D L α i . Observe the resemblance between this and the patchaveraging in Equation <ref type="formula" target="#formula_2">(3)</ref>. This may suggest that the CSC is in-fact a global model extending PA. If this was true, one could have expected the CSC to be at least as good as the local model on any image processing task. Is this the case? Keep reading.</p><p>Similarly, P i X = P i DΓ is a patch of size n extracted from X. Equivalently, one may write P i DΓ = Ωγ i , where a stripe γ i concatenates 2n − 1 needles and Ω is termed the stripe dictionary. <ref type="figure">Figure 1</ref> demonstrates these definitions. An analysis of the convolutional sparse coding problem is proposed in <ref type="bibr" target="#b30">[31]</ref>, showing that when all the stripes γ i are sparse, 4 the solution to (5) is unique. Moreover, under the same conditions, BP is guaranteed to retrieve this solution. An analysis was also given for the noisy case, showing that under similar conditions, the solution attained by BP is stable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">CSC in Practice</head><p>The first application we mention is cartoon-texture separation, where the goal is to blindly decompose an image into its texture and cartoon parts. Recent papers have achieved successful results by incorporating the CSC model <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b33">34]</ref>. Curiously, these algorithms model the cartoon image via the Total-Variation smoothness assumption, while using the CSC to model only the texture.</p><p>A second application where the CSC achieves satisfactory results is image fusion <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b32">33]</ref>. Here the goal is to integrate complementary information from multiple source images of the same scene.</p><p>The results obtained by integrating the CSC model surpass those achieved by patch-based methods on various metrics <ref type="bibr" target="#b32">[33]</ref>. In such an algorithm, each image is first decomposed to smooth and detail layers. The fusion itself is obtained by computing the convolutional sparse representation of the detailed layers, and merging these by a pixel-wise max-pooling strategy.</p><p>Another application where CSC has been demonstrated to perform very well is single-image-superresolution. Here, the objective is a high resolution (HR) image, obtained from a low resolution (LR) one. In <ref type="bibr" target="#b31">[32]</ref> a CSC scheme is suggested, leading to superior results over patch-based methods. As in the image fusion task, the algorithm separates the LR image into a smooth and a residual image. While the smooth part is simply interpolated, the residual is coded using CSC, and the final details image is recovered by applying a set of filters on the obtained sparse representations.</p><p>In all these successful applications, the input image is first separated into smooth and non-smooth images. Then, without a formal reasoning, the CSC only models the detail-rich content of the image, hinting to its limitations. Why does the CSC perform well only on non-smooth signals? We answer this question in the following sections. Another common feature to these successful applications is the fact that the data is assumed to be noiseless. Is this a coincidence? Can the CSC be of benefit on noisy natural images?</p><p>In order to answer these questions let us refer to an unsuccessful use of the CSC: image denoising. Applying the CSC model directly on the noisy image leads to disappointing results, falling far behind PA <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b35">36]</ref>. We emphasize that the same is true for other applications where noise cannot be neglected, such as deblurring and other inverse problems.</p><p>To date, no CSC denoising algorithm competes favorably with the PA method on natural images, with the exception of <ref type="bibr" target="#b36">[37]</ref>. This work extends the concept of Learned Iterative Soft Thresholding (LISTA) <ref type="bibr" target="#b37">[38]</ref><ref type="bibr" target="#b38">[39]</ref><ref type="bibr" target="#b39">[40]</ref> to CSC, unfolding the pursuit algorithm into a recurrent network. The results obtained are on par with the K-SVD algorithm <ref type="bibr" target="#b2">[3]</ref>. <ref type="bibr" target="#b4">5</ref> The last part of our work is closely related to <ref type="bibr" target="#b36">[37]</ref>. By adopting our insights on the CSC model and its MMSE approximation, we offer a CSC deployment that leads to enhanced denoising performance that are on par with the most recent supervised methods.</p><p>3 Why Does the CSC Model Denoise Natural Images Poorly?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Poor Coherence</head><p>The work in <ref type="bibr" target="#b30">[31]</ref> has show that the theoretical uniqueness and stability guarantees for the convolutional sparse coding problem are conditioned on the maximum number of local non-zero elements in Γ</p><formula xml:id="formula_7">Γ 0,∞ &lt; 1 2 1 + 1 µ(D) ,<label>(7)</label></formula><p>where µ (D) is the mutual coherence of D, i.e. the max absolute normalized cross-correlation between its columns. <ref type="bibr" target="#b5">6</ref> Moreover, under the same conditions, BP is guaranteed to recover this solution. This bound implies that to allow for a large number of active filters in the signal while keeping the solution accessible, the filters and all their shifts must have low cross-correlations. Specifically, the auto-correlation of the filters should be low as well. Unfortunately, this property does not align with the characteristics of natural images. For the most part, these consist of piece-wise smooth regions and occasional textures. This structure is key in many denoising and compression methods <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b40">41]</ref>. Hence, to allow for a sparse representation, a convolutional dictionary must contain smooth or piece-wise smooth filters. That said, the auto-correlation of a these filters decay slowly, leading to highly correlated atoms in the global dictionary, restricting the number of non-zero elements allowed in each stripe γ i while satisfaying the above bound. For example, if a dictionary contains the constant (DC) filter, the maximum number of non-zeros allowed in a stripe to assure uniqueness is 1, enforcing unpainted pixels in the signal.</p><p>Generally, a CSC representation of a natural image imposes a contradiction between the cardinality of the sparse representation and the coherence of the global dictionary. To assure a sparse representation, the former requires piecewise smooth filters, whereas the latter demands low global mutual-coherence, which counters these slow-changing filters. In its current form, the CSC cannot satisfy the two demands simultaneously, making it unsuitable for natural images. Note that the successful applications that were mentioned in Section 2.2, apply the CSC model only on the texture rich part of the image, leading to Gabor-like non-smooth filters, thus avoiding the described conflict.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">A Bayesian Standpoint</head><p>From a Bayesian point of view, the solution to the problem posed in Equation (1) (or its Lagrangian form) corresponds to the Maximum A-posteriori Probability (MAP) estimator under a sparse prior <ref type="bibr" target="#b41">[42]</ref><ref type="bibr" target="#b42">[43]</ref><ref type="bibr" target="#b43">[44]</ref><ref type="bibr" target="#b44">[45]</ref>. Clearly, this solution is inferior to the Minimum MSE (MMSE) estimator in terms of MSE when the two differ. As we show next, as opposed to a convolutional pursuit (being MAP approximation), PA performs a restrained approximation to the CSC MMSE estimator w.r.t. the entire image, explaining its superiority. To do so, we first formalize the PA approach, then we present the CSC MMSE estimator and finally, we show their connection.</p><p>PA obtains a clean estimate for each patch and averages overlapping estimates together. Specifically, under a (local) sparse prior with a dictionary D L , each patch participates in a local pursuit independently, leading to N independent optimization problems, 7</p><formula xml:id="formula_8">α i = arg min αi λ i α i 1 + 1 2 D L α i − P i Y 2 2 N i=1 .<label>(8)</label></formula><p>Once α i are found, the clean patches are synthesized by x i = D L α i , and these are placed in the signal while averaging overlapping elements from different patches -see Equation <ref type="formula" target="#formula_2">(3)</ref>.</p><p>We move now to discuss the MMSE estimation under a sparsity-promoting prior <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b44">45]</ref>. Using marginalization, MMSE of the global convolutional sparse representation vector can be written as</p><formula xml:id="formula_9">Γ MMSE = E {Γ|Y } = E S {E {Γ|Y , S}} = S∈Θ P (S) E {Γ|Y , S} = S∈Θ P (S) Γ S ,<label>(9)</label></formula><p>where S stands for the support of Γ, P (S) is the prior probability of such a support (assumed to promote sparse vectors) and Θ is the set of all possible supports. Furthermore, Γ S = E {Γ|Y , S} is the MMSE estimator of the sparse representation vector given the support and the noisy measurements, known as the oracle estimator <ref type="bibr" target="#b43">[44]</ref>. Equation <ref type="bibr" target="#b8">(9)</ref> suggests that the MMSE estimator is actually a dense vector consisting of a weighted average of all the possible oracle estimators, where the weight of each is its prior probability, P (S). Note that computing the MMSE is an exhaustive task that sweeps through all the possible supports, and therefore approximation methods are needed. A natural strategy in this context is to sample a sufficient number of supports from P (S), and replace the expectation with a sample mean over these.</p><p>Indeed, consider the case where the sampled supports are such that DΓ results in non-overlapping tangent slices. Overall, there are n different slice arrangements that uphold this assumption differing only in the location of the first slice on the image. Equivalently, the k-th arrangement can be described by a convolutional strided dictionary, where the stride equals the size of the filter n, and the first non-zero needle in Γ is located in the k-th index 1 ≤ k ≤ n. We shall denote this strided dictionary by D k and its corresponding representation as Γ k . Sparse coding the k-th shift can be done using BP, which under these constraints can be written as</p><formula xml:id="formula_10">Γ k = arg min Γ λ Γ 1 + 1 2 D k Γ − Y 2 2 (10) = arg min Γ=[α k ;α k+n ,...] N n −1 i=0 λ α k+in 1 + 1 2 D L α k+in − P k+in Y 2 2 .<label>(11)</label></formula><p>This can be solved for each needle separately,</p><formula xml:id="formula_11">α k+in = arg min α λ α 1 + 1 2 D L α − P k+in Y 2 2 ,<label>(12)</label></formula><p>while zeroing all the other needles. Thus, under the constraint of non-overlapping slices, estimating the CSC representation Γ S is equivalent to N n independent local pursuits. Clearly, this estimation results with a "blockified" image, due to the lack of overlaps. <ref type="bibr" target="#b6">7</ref> we assume the use of the BP in its Lagrangian form Repeating this estimation process n times, each time forcing a different shift 1 ≤ k ≤ n, leads to a set of estimates Γ 1 , Γ 2 , ..., Γ n , where Γ k denotes the estimate obtained using the k-th shift. Looking back into the MMSE estimator in Equation <ref type="formula" target="#formula_9">(9)</ref>, the MMSE can be approximated as</p><formula xml:id="formula_12">Γ MMSE ≈ n i=1 P (S) Γ i ≈ 1 n n i=1 Γ i ,<label>(13)</label></formula><p>if we further assume that all the estimates are a-priori equally likely. Since each Γ i is obtained by a local non-overlapping pursuit <ref type="bibr" target="#b10">(11)</ref>, the result in (13) is exactly the above outlined PA procedure. Hence, PA can be perceived as an MMSE approximation of the CSC model, explaining its superior MSE performance when compared to a single global CSC pursuit. <ref type="bibr" target="#b7">8</ref> Armed with this insight, can we propose better CSC MMSE estimates? This takes us to the next section.</p><p>4 The Proposed Approach</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Generalizing the MMSE Approximation Using Strided Convolutions</head><p>We suggest to generalize the non-overlapping slices assumption and allow for a smaller constant stride. Formally, in the non-overlapping case, the stride between adjacent slices was of the same size as the filters themselves, leading to n such estimates. We suggest to use a stride q, where 1 ≤ q &lt; n, leading to q estimates in a 1D signal or q 2 in a 2D one -each originating from a different initial shift in the signal. Finally, we average these together, as suggested in Equation <ref type="bibr" target="#b8">(9)</ref>. Note that when q &lt; n, each estimate allows for overlapping slices, implying that the pursuit must be done globally on all the involved slices together. This necessarily leads to a global agreement between these slices, as opposed to PA where each patch (slice) is estimated separately. Furthermore, when q is sufficiently large, the mutual coherence of the global dictionary can be preserved even for smooth filters, in contrast to the standard CSC pursuit (q = 1), since the filters only partially overlap.</p><p>For a preliminary evaluation of our approach, we perform a denoising experiment on images from the Set12 dataset contaminated with white Gaussian noise with standard deviation σ ∈ {15, 25, 50, 75}.</p><p>We use both the standard PA algorithm, and the proposed strided CSC using various strides 1 ≤ q &lt; n = 11, followed by an averaging operation. BP in its error-bounded from followed by a debiasing step is used to sparse code the signals both in the convolutional and the PA cases. The twice over-redundant DCT dictionary of size 11 × 11 is chosen as the local dictionary D L . Note that in the strided case, pixels may now have a different number of slices (filters) overlapping them, depending on their position in the image and the stride. To compensate for this, we normalize the filters appropriately for each stride.</p><p>A summary of the results of this experiment are presented in <ref type="table" target="#tab_0">Table 1</ref> (per-image results can be found in the supplementary material). As expected, when using CSC with a stride of 1, i.e. standard CSC, the denoising performance is poor and the PA method is substantially better. We attribute this to the high coherence of the global dictionary, making the estimated image overfit the noise. However, the best results are achieved when the stride is large but smaller than the size of the filters, restraining the coherence, while allowing the filters to overlap, leading to a global consensus in each of the estimates. Interestingly, the CSC achieved better results even though its error constraint ( D k Γ − Y 2 ≤ ) is global, as opposed to the much more detailed local constraint used by PA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">CSCNet -a Supervised Denoising Model</head><p>A popular method to solve BP, i.e. Γ = arg min Γ 1 2 DΓ − Y 2 2 + λ Γ 1 , is the ISTA algorithm, which operates iteratively as follows:</p><formula xml:id="formula_13">Γ k+1 = S λ c Γ k + 1 c D T (Y − DΓ k ) ,<label>(14)</label></formula><p>where c ≥ σ max D T D , and S τ is the soft-thresholding operator extended to operate in an elementwise fashion. <ref type="bibr" target="#b8">9</ref> Often times, convergence requires a large number of iterations, making this process  inefficient. To overcome this burden, the LISTA algorithm <ref type="bibr" target="#b37">[38]</ref> has been proposed to approximate the sparse coding process, by learning the parameters of a non-linear recurrent encoder that strictly follows L iterations of the iterative process described in Equation <ref type="formula" target="#formula_0">(14)</ref>. This concept has been extended to the convolutional setting in <ref type="bibr" target="#b36">[37]</ref> as follows:</p><formula xml:id="formula_14">Γ k+1 = S τ Γ k + 1 c A (Y − BΓ k ) ,<label>(15)</label></formula><p>where A stands for a convolution operator and B a transposed-convolution one. Once the sparse vector is at hand, the estimated clean image is then obtained by a linear transposed-convolutional decoder, i.e. X = CΓ L . The matrices A, B and C are structured as a set of support bounded shift invariant filters, and together with the thresholds vector τ , are learned in a supervised manner. Note that the number of parameters does not grow with L, the number of unrolled iterations.</p><p>Following the CSC MMSE approximation introduced in Section 4.1, we propose to use a strided convolutional structure on the learned matrices using a constant stride q. To obtain an estimate for each possible shift, we duplicate the input image q 2 times, where each duplicate is a shifted version of the original image. Following Equation <ref type="formula" target="#formula_0">(13)</ref> the estimated image is a simple average of the estimates of all the shifts. A diagram of the proposed architecture is presented in <ref type="figure" target="#fig_1">Figure 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Experiments</head><p>To train the proposed model, we prepare a training set of input-output pairs. The clean images are taken from the Waterloo Exploration Dataset <ref type="bibr" target="#b45">[46]</ref> and 432 images from BSD <ref type="bibr" target="#b46">[47]</ref>. The noisy inputs are obtained by adding white Gaussian noise with a constant standard deviation σ. In each iteration, a random patch of size 128 is cropped from an image and a random realization of noise is sampled.</p><p>We train 4 models, one for each noise level {15, 25, 50, 75}. For each model we learn 175 filters of size 11 × 11, use a stride q = 8 and set L = 12. To learn the parameters of the model, we employ the ADAM optimizer <ref type="bibr" target="#b47">[48]</ref> and minimize the 2 loss, i.e. L(X, X) = X − X 2 2 . We use a learning rate of 10 −4 and decrease it by a factor of 0.7 every 50 epochs and iterate over 250 epochs. To avoid divergence, we set the parameter of the optimizer to 10 −3 . We evaluate the performance of the models using the BSD68 dataset that was excluded from the training set. Additional experiments and information can be found in the supplementary material and in https://github.com/drorsimon/CSCNet. <ref type="table" target="#tab_1">Table 2</ref> presents the results of our models compared to other leading methods, and <ref type="figure">Figure 3</ref> shows some of the learned filters, taken from C. The proposed model outperforms BM3D <ref type="bibr" target="#b1">[2]</ref>, TNRD <ref type="bibr" target="#b48">[49]</ref>,  <ref type="figure">Figure 4</ref>: CSCNet test error for various strides.</p><p>WNNM <ref type="bibr" target="#b49">[50]</ref> and MLP <ref type="bibr" target="#b50">[51]</ref>, while being on par with DnCNN <ref type="bibr" target="#b51">[52]</ref> and FFDNet <ref type="bibr" target="#b52">[53]</ref>. That said, we mention two differences between the proposed model and the other two leading methods:</p><p>1. Number of parameters -The number of parameters in the proposed approach does not grow with the depth of the model. Hence, it uses much fewer parameters compared to other modern methods, as demonstrated in <ref type="table" target="#tab_2">Table 3.</ref> 2. Batch Normalization (BN) -The other two leading denoising methods are based on general deep learning techniques, and therefore employ BN which is known to improve the performance and convergence rate of the trained model <ref type="bibr" target="#b53">[54]</ref>. As our presented method relies only on the CSC prior, we did not include such operators.</p><p>To study the effect of the stride-size, we have trained 6 models, each one with a different stride. The results in <ref type="figure">Figure 4</ref>, referring to noise level σ = 25, show the same tendency as in <ref type="table" target="#tab_0">Table 1</ref>, namely, setting the stride too high (q = 11) results in independent patch based processing with weaker performance (28.9dB); setting it to q = 1 leads to a regular (non-MMSE) deployment of the CSC with highly correlated atoms and the weakest estimate (28.74dB), which is still better than BM3D. The best results are obtained for q = 7 or q = 8 (29.11dB). We further test our approach on color image denoising. We perform similar experiments to those described earlier, where this time the input image and each filter have 3 channels (RGB). The denoising performance of our architecture is presented in <ref type="table" target="#tab_3">Table 4</ref>. As before, our results are on par with other leading methods (DnCNN, FFDNet) while using much fewer parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>This work exposed the limitations of the CSC model in representing natural images in the presence of noise. Investigation of the patch-averaging scheme and the origins for its success has lead us to offer an MMSE approximation pursuit that overcomes these limitations effectively. A feed-forward architecture based on our insights was shown to be on par with the best supervised denoising algorithms in the literature. Our future work will focus on further improvements of this scheme by considering (i) the addition of batch-normalization; (ii) a multi-scale architecture, as proposed in recent leading methods; (iii) adoption of a local error constraint as in PA; and (iv) exploiting self-similarity, as practiced in <ref type="bibr" target="#b19">[20]</ref> and more recently in <ref type="bibr" target="#b54">[55]</ref>. In all these directions, our prime goal is to incorporate these ideas while maintaining the purity of CSC model, so as to preserve intact the theoretical justification of the proposed architecture.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>The CSCNET architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Average Set12 denoising results (PSNR) using PA and CSC with various strides (q). CSC Results that surpass PA are marked in blue. Best results are bold. CSC -stride size (q) 29.27 30.01 30.66 31.06 31.21 31.31 31.39 31.45 31.46 31.23 25 25.78 26.11 26.94 27.72 28.26 28.50 28.64 28.75 28.84 28.88 28.73 50 21.49 22.11 23.17 23.83 24.52 24.86 25.05 25.29 25.47 25.56 25.32 75 18.83 19.58 20.95 21.81 22.43 22.75 22.97 23.25 23.51 23.66 23.28</figDesc><table><row><cell>σ</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>9</cell><cell>10</cell><cell>PA</cell></row><row><cell cols="6">15 28.99 LISTA Iteration</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Deconv</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>(B)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Denoising performance (PSNR) on the BSD68 dataset. σ BM3D WNNM TNRD MLP DnCNN FFDNet CSCNet</figDesc><table><row><cell>15 31.07</cell><cell>31.37</cell><cell>31.42</cell><cell>-</cell><cell></cell><cell>31.72</cell><cell></cell><cell>31.63</cell><cell>31.57</cell></row><row><cell>25 28.57</cell><cell>28.83</cell><cell cols="3">28.92 28.96</cell><cell>29.22</cell><cell></cell><cell>29.19</cell><cell>29.11</cell></row><row><cell>50 25.62</cell><cell>25.87</cell><cell cols="3">25.97 26.03</cell><cell>26.23</cell><cell></cell><cell>26.29</cell><cell>26.24</cell></row><row><cell>75 24.21</cell><cell>24.40</cell><cell>-</cell><cell cols="2">24.59</cell><cell>24.64</cell><cell></cell><cell>24.79</cell><cell>24.77</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>29.00</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Test set PSNR</cell><cell>28.25 28.50 28.75</cell><cell></cell><cell></cell><cell>Stride=1 Stride=3 Stride=5 Stride=7 Stride=9</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>28.00</cell><cell></cell><cell></cell><cell>Stride=11</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0</cell><cell>50</cell><cell>100</cell><cell>150</cell><cell>200</cell><cell>250</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Epochs</cell></row><row><cell cols="2">Figure 3: CSCNet filters.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Comparison of number of parameters in leading denoising architectures. × 3 × 1 × 64 3 × 3 × 64 × 1 (3 × 3 × 64 × 64 + 128) × 15 556,032 FFDNet 3 × 3 × 5 × 64 3 × 3 × 64 × 4 (3 × 3 × 64 × 64 + 128) × 13 486,080 CSCNet -11 × 11 × 175 × 1 (11 × 11 × 175 × 1) × 2 + 175 63,700</figDesc><table><row><cell>Model</cell><cell>First layer</cell><cell>Last layer</cell><cell>Mid layers</cell><cell>Total</cell></row><row><cell cols="2">DnCNN 3</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Denoising performance (PSNR) on the color-BSD68 dataset.</figDesc><table><row><cell cols="5">σ CBM3D CDnCNN FFDNet CSCNet</cell></row><row><cell>15</cell><cell>33.52</cell><cell>33.89</cell><cell>33.87</cell><cell>33.83</cell></row><row><cell>25</cell><cell>30.71</cell><cell>31.23</cell><cell>31.21</cell><cell>31.18</cell></row><row><cell>50</cell><cell>27.38</cell><cell>27.92</cell><cell>27.96</cell><cell>28.00</cell></row><row><cell>75</cell><cell>25.74</cell><cell>24.47</cell><cell>26.24</cell><cell>26.32</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">These represent convolutions with small support filters.<ref type="bibr" target="#b2">3</ref> For simplicity of the description, and without loss of generality, we describe the CSC throughout this paper as operating on 1D signals.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">This is measured via an 0,∞ pseudo-norm, defined as Γ 0,∞ = maxi γi 0.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">Improved performance is reported in their follow-up thesis.<ref type="bibr" target="#b5">6</ref> The 0,∞ is defined as Γ 0,∞ = maxi γi 0.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">The term approximation refers to considering only a small subset of supports in the averaging process. 9 σmax (·) represent the largest eigenvalue, and Sτ (·) is defined as Sτ (y) = sign(y) · max(y − τ, 0).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>The research leading to these results has received funding from the Technion Hiroshi Fujiwara Cyber Security Research Center and the Israel Cyber Directorate.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Nonlinear total variation based noise removal algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">I</forename><surname>Rudin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Fatemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physica D: Nonlinear Phenomena</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">1-4</biblScope>
			<biblScope unit="page" from="259" to="268" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Image denoising by sparse 3-d transform-domain collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dabov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2080" to="2095" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Image denoising via sparse and redundant representations over learned dictionaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Aharon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image processing</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3736" to="3745" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A non-local algorithm for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="60" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Image deblurring and super-resolution by adaptive sparse domain selection and adaptive regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1838" to="1857" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Poisson noise reduction with non-local pca</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Salmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Harmany</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-A</forename><surname>Deledalle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Willett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Imaging and Vision</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="279" to="294" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Nonlocally centralized sparse representation for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1620" to="1630" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Mri image reconstruction from highly undersampled k-space data by dictionary learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravishankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bresler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1028" to="1041" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Sparse representations in audio and music: from coding to source separation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Plumbley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Blumensath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Daudet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gribonval</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Davies</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="995" to="1005" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Sparse approximate solutions to linear systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">K</forename><surname>Natarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="227" to="234" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Basis pursuit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Donoho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 1994 28th Asilomar Conference on Signals</title>
		<meeting>1994 28th Asilomar Conference on Signals</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1994" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="41" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Sparse and redundant representations: from theory to applications in signal and image processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Method of optimal directions for frame design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Engan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">O</forename><surname>Aase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Husoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Acoustics, Speech, and Signal Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1999" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="2443" to="2446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">K-svd: An algorithm for designing overcomplete dictionaries for sparse representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Aharon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bruckstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">4311</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Online dictionary learning for sparse coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="689" to="696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Dictionary learning: What is the right representation for my signal?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tosic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Frossard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="27" to="38" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">From learning models of natural image patches to whole image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zoran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="479" to="486" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">On the global-local dichotoy in sparsity modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Batenkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Romano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Compressed Sensing and its Applications</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Expected patch log likelihood with a sparse prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sulam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Energy Minimization Methods in Computer Vision and Pattern Recognition (EMMCVPR)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="99" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Non-local sparse models for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">R</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="54" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Shift-invariant sparse coding for audio classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Raina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kwong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Third Conference on Uncertainty in Artificial Intelligence</title>
		<meeting>the Twenty-Third Conference on Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="149" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1010.0422</idno>
		<title level="m">Convolutional matching pursuit and dictionary training</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Fast and flexible convolutional sparse coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Heide</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Heidrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wetzstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="5135" to="5143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Fast convolutional sparse coding with separable filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Quesada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rodríguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wohlberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6035" to="6039" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A greedy approach to 0,infinity based convolutional sparse coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Plaut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Giryes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Imaging Sciences</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="186" to="210" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A local block coordinate descent algorithm for the convolutional sparse coding model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zisselman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sulam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Efficient algorithms for convolutional sparse representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wohlberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="301" to="315" />
			<date type="published" when="2016-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Convolutional dictionary learning via local processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Papyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Romano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sulam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5306" to="5314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Convolutional dictionary learning: A comparative review and new algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Garcia-Cardona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wohlberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computational Imaging</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Convolutional dictionary learning: Acceleration and convergence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">Y</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Fessler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1697" to="1712" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Working locally thinking globally: Theoretical guarantees for convolutional sparse coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Papyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sulam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">21</biblScope>
			<biblScope unit="page" from="5687" to="5701" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Convolutional sparse coding for image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1823" to="1831" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Image fusion with convolutional sparse representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Letters</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1882" to="1886" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Rey-Otero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sulam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.01169</idno>
		<title level="m">Variations on the csc model</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Sparse overcomplete denoising: aggregation versus global optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Carrera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Boracchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wohlberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Letters</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1468" to="1472" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Convolutional sparse coding with overlapping group norms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wohlberg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.09038</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Learned convolutional sparse coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sreter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Giryes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2191" to="2195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning fast approximations of sparse coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<publisher>Omnipress</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="399" to="406" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Discriminative recurrent sparse auto-encoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Rolfe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Deep networks for image super-resolution with sparse prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="370" to="378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Image compression using the 2-d wavelet transform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Knowles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="244" to="250" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Linear regression with a sparse parameter vector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">G</forename><surname>Larsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Selén</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="451" to="460" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Fast bayesian matching pursuit: Model uncertainty and parameter estimation for sparse linear models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Schniter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Potter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ziniel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="page" from="326" to="333" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A plurality of sparse representations is better than the sparsest one alone</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Yavneh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transaction on Information Theory</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1" to="35" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Mmse approximation for sparse coding algorithms using stochastic resonance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sulam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Romano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">M</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">17</biblScope>
			<biblScope unit="page" from="4597" to="4610" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Waterloo exploration database: New challenges for image quality assessment models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Duanmu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1004" to="1016" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Contour detection and hierarchical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Arbelaez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="898" to="916" />
			<date type="published" when="2011-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Trainable nonlinear reaction diffusion: A flexible framework for fast and effective image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1256" to="1272" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Weighted nuclear norm minimization with application to image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2862" to="2869" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Image denoising: Can plain neural networks compete with bm3d?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">C</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Schuler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Harmeling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2392" to="2399" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Beyond a gaussian denoiser: Residual learning of deep cnn for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3142" to="3155" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Ffdnet: Toward a fast and flexible solution for cnn-based image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4608" to="4622" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Batch normalization: accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Non-local recurrent network for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1673" to="1682" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
