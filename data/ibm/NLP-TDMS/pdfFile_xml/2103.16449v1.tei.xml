<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Bilevel Online Adaptation for Out-of-Domain Human Mesh Reconstruction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanyan</forename><surname>Guan</surname></persName>
							<email>shyanguan@sjtu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Lab of Artificial Intelligence</orgName>
								<orgName type="institution" key="instit1">AI Institute</orgName>
								<orgName type="institution" key="instit2">Shanghai Jiao Tong University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingwei</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Lab of Artificial Intelligence</orgName>
								<orgName type="institution" key="instit1">AI Institute</orgName>
								<orgName type="institution" key="instit2">Shanghai Jiao Tong University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunbo</forename><surname>Wang</surname></persName>
							<email>yunbow@sjtu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Lab of Artificial Intelligence</orgName>
								<orgName type="institution" key="instit1">AI Institute</orgName>
								<orgName type="institution" key="instit2">Shanghai Jiao Tong University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingbing</forename><surname>Ni</surname></persName>
							<email>nibingbing@sjtu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Lab of Artificial Intelligence</orgName>
								<orgName type="institution" key="instit1">AI Institute</orgName>
								<orgName type="institution" key="instit2">Shanghai Jiao Tong University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaokang</forename><surname>Yang</surname></persName>
							<email>xkyang@sjtu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Lab of Artificial Intelligence</orgName>
								<orgName type="institution" key="instit1">AI Institute</orgName>
								<orgName type="institution" key="instit2">Shanghai Jiao Tong University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moe</forename><surname>Key</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Lab of Artificial Intelligence</orgName>
								<orgName type="institution" key="instit1">AI Institute</orgName>
								<orgName type="institution" key="instit2">Shanghai Jiao Tong University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Bilevel Online Adaptation for Out-of-Domain Human Mesh Reconstruction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T09:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper considers a new problem of adapting a pretrained model of human mesh reconstruction to out-ofdomain streaming videos. However, most previous methods based on the parametric SMPL model <ref type="bibr" target="#b35">[36]</ref> underperform in new domains with unexpected, domain-specific attributes, such as camera parameters, lengths of bones, backgrounds, and occlusions. Our general idea is to dynamically finetune the source model on test video streams with additional temporal constraints, such that it can mitigate the domain gaps without over-fitting the 2D information of individual test frames. A subsequent challenge is how to avoid conflicts between the 2D and temporal constraints. We propose to tackle this problem using a new training algorithm named Bilevel Online Adaptation (BOA), which divides the optimization process of overall multi-objective into two steps of weight probe and weight update in a training iteration. We demonstrate that BOA leads to state-of-the-art results on two human mesh reconstruction benchmarks 1 . * Equal contribution † Corresponding authors: Yunbo Wang, Bingbing Ni 1 The project website with code, supplementary materials and video results is at https://sites.google.com/view/humanmeshboa Domain Gap Camera Height (m) Bone Length (m) Focal Length (pixel)</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Human mesh reconstruction is a hot topic in computer vision, where improving the generalization ability is one of the major challenges at present. We observe that previous models <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b42">43]</ref> are prone to overfit the training dataset and usually underperform in out-of-domain testing scenarios. As shown in <ref type="figure" target="#fig_0">Figure 1</ref>, between different datasets, there usually exist large domain gaps in camera parameters, lengths of body bones, backgrounds, and occlusions, whose negative impact becomes even more severe when we apply the model to streaming data due to the rapidly changing environment of the test domain. In this work, we are interested in finding a good solution to adapting human mesh reconstruction models to out-of-domain video frames that arrive in a sequential order, which is a Here, the bone length refers to the sum of lengths between body joints, whose topology is shared across datasets.</p><p>practical task in many downstream, real applications, e.g., augmented reality <ref type="bibr" target="#b2">[3]</ref>, and human-robot interaction <ref type="bibr" target="#b47">[48]</ref>. The most serious technical challenge of this task is the lack of 3D annotations of test data. To cope with this problem, some optimization-based approaches <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b41">42]</ref> learn to update the model on each test frame using frame-wise losses, such as the pose re-projection loss <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b25">26]</ref> of 2D keypoints 2 . However, the imperfect frame-based loss functions do not always lead to effective online learning directions as expected by the 3D evaluation metric. There is a severe gap between them. As shown in <ref type="figure" target="#fig_1">Figure 2</ref>, it may cause severe ambiguity in the estimation of depth information, thus worsening the quality of mesh reconstruction. Moreover, due to the asynchronous arrival of streaming data, the online adaptation model is prone to over-fitting, which will further amplify the difference between the 2D objectives and 3D evaluation metrics.</p><p>A straightforward solution is to regularize the training process towards 2D pose objectives using temporal constraints <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b21">22]</ref>, such as the smoothness of mesh reconstruction over time. If the temporal constraints are used properly, the ambiguity of depth estimation can be greatly reduced. However, empirically, a simple combination of 2D losses and temporal constraints tends to obtain undesirable results due to the competition and incompatibility between multiple objectives, in the sense that the gradient of 2D objectives may interfere with the training of the temporal one. Further, solving this problem becomes even more urgent in online adaptation scenarios with streaming data, because without global knowledge of the test domain, the model can easily fall into a sub-optimal solution to either part of the loss functions that is more readily available.</p><p>The above two concerns motivate us to tackle the challenging problem of out-of-domain mesh reconstruction from a new perspective. We propose an algorithm named Bilevel Online Adaptation (BOA) that greatly benefits joint learning of multiple objectives in this task. It effectively incorporates temporal consistency into the few-step online training by performing bilevel optimization on the streaming test data. Specifically, in BOA, the lower-level optimization step serves as a weight probe to rational model parameters under single-frame pose constraints, while the upper-level optimization step finds a feasible response to overall loss function with temporal constraints. On one hand, our approach avoids overfitting the temporal constraints by retaining the 2D losses for the upper-level optimization. On the other hand, it avoids overfitting the 2D losses by updating the model only at the upper-level optimization step with second-order derivatives. By this means, our approach effectively combines the benefits of pose and temporal constraints. In experiments, we use Hu-man3.6M <ref type="bibr" target="#b18">[19]</ref> as the source domain, and take 3DPW <ref type="bibr" target="#b55">[56]</ref> and MPI-INF-3DHP <ref type="bibr" target="#b36">[37]</ref> as target domains with streaming video frames. On both benchmarks, our approach consis-tently outperforms existing approaches <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b41">42]</ref>, showing the excellent ability to tackle notable domain gaps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Problem Setup</head><p>A SMPL-based solution to human mesh reconstruction can be usually specified as a tuple of (X, Θ, Π, L), where X denotes the observation space <ref type="bibr" target="#b2">3</ref> , and Θ is the parameter space of SMPL <ref type="bibr" target="#b35">[36]</ref>. For each input frame x i ∈ X, a first-stage model is trained to estimate { β i , θ i } ∈ Θ. Then the SMPL model generates the corresponding mesh and recovers 3D keypoints denoted by J i using a mesh-to-3Dskeleton mapping pre-defined in SMPL. The third element in the tuple is a weak-perspective projection model for pro-</p><formula xml:id="formula_0">jecting J i to 2D space, i.e.,ĵ i = Π ψ i ( J i ), where ψ i is estimated from x i . The last one in the tuple defines a loss function L(·) on ( β i , θ i , ψ i , J i , j i ) to learn the first-stage model M φ , usually in terms of neural networks.</formula><p>In this work, we make two special modifications to the above task. First, we focus on out-of-domain scenarios, in the sense that large discrepancies may exist between the data distributions of the source training domain D tr and the target test domain D test . Second, we specifically focus on dealing with streaming video frames at test time. These changes bring in two challenges: (1) The ground truth values of the target domain parameters in (Θ, Π) are always unavailable throughout the learning process, which is different from standard online learning. (2) The distribution of the target domain is difficult to be estimated because the frames {x i } N i=1 ∈ X are sequentially available and their distributions are continuously changing, which is different from standard domain adaptation setups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Bilevel Online Adaptation</head><p>In this section, we first formalize the online adaptation framework as a solution to out-of-domain human mesh reconstruction from streaming sequential data. To make the online adaptation more effective, we then propose a bilevel optimization algorithm that incorporates unsupervised temporal constraints into the training paradigm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Online Adaptation Framework</head><p>Unlike the existing approaches <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b48">49</ref>] that try to solve the problem introduced in Section 2 by learning more generalizable features in the source domain D tr , we here present an alternative solution that performs online test-time training directly on the target domain D test . A potential benefit is that as it is solely performed on D test , it can be jointly used with the state-of-the-art approaches that learn generalizable features from D tr to further improve the quality of transfer learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Bilevel Online Adaptation</head><p>Input: sequential frames {x i } N i=1 from test set, the base model M φ0 with model parameter φ 0 , a teacher model T ω0 with model parameter ω 0 , learning rates α and η.</p><formula xml:id="formula_1">Output: SMPL parameters { β i , θ i } N i=1 , camera parameters { ψ i } N i=1 1: Initialize ω 0 ← φ 0 2: for i = 1, . . . , N do 3: φ 0 i−1 ← φ i−1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4:</head><p>for t = 1, . . . , T do For each bilevel optimization step 5:</p><formula xml:id="formula_2">L low ← L F (x i ; φ t−1 i−1 )</formula><p>Calculate lower-level loss with single-frame pose constraints <ref type="bibr" target="#b5">6</ref>:</p><formula xml:id="formula_3">φ (t−1) i−1 ← φ t−1 i−1 − α∇ φ L low</formula><p>Probe for rational weights under pose constraints 7:</p><formula xml:id="formula_4">L up ← L F (x i ; φ (t−1) i−1 ) + L T (x i ; ω i−1 , φ (t−1) i−1 )</formula><p>Calculate upper-level loss with temporal constraints 8:</p><formula xml:id="formula_5">φ t i−1 ← φ t−1 i−1 − η∇ φ L up</formula><p>Update model weights with second-order derivatives <ref type="bibr">9:</ref> end for 10:</p><formula xml:id="formula_6">φ i ← φ T i−1 11</formula><p>:</p><formula xml:id="formula_7">ω i ← δω i−1 + (1 − δ)φ i</formula><p>Update the teacher model <ref type="bibr" target="#b11">12</ref>:</p><formula xml:id="formula_8">{ β i , θ i }, Π ψ i ← M φi (x i )</formula><p>Estimate the SMPL parameters and the camera parameter of x i using M φi 13: end for Alg. 1 shows the proposed online adaptation framework.</p><p>Here we denote the pre-trained model from the source domain as M φ0 . Our framework does not have special requirements for the pre-training method, but typically, M φ0 is trained offline to regress the ground truth SMPL parameters in a fully supervised manner. Given sequentially arrived target video frames {x i } N i=1 ∈ D test , a straight forward solution to quickly absorbing the domain-specific knowledge is to fine-tuning M continuously on each individual x i , following the online adaptation paradigm proposed by Tonioni et al. <ref type="bibr" target="#b51">[52]</ref>. We take it as a baseline algorithm that computes the unsupervised loss function L with pose constraints <ref type="bibr" target="#b3">4</ref> on each x i , and performs a single optimization step as follows before the inference step:</p><formula xml:id="formula_9">φ i = φ i−1 − α∇ φ L(x i ; M φi ),<label>(1)</label></formula><p>where α is the learning rate of gradient descent. A potential disadvantage of the baseline algorithm is that although fine-tuning a learned model on unlabeled target data may help to handle rapidly changing test environments, an imperfect unsupervised loss function may lead to wrong directions of the one-step gradient descent, and may harm the overall algorithm. It may cause catastrophic overfitting to some undesirable information of current observation that is unrelated to the reconstruction quality. To alleviate this issue, we propose the following spatiotemporal bilevel optimization approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Spatiotemporal Bilevel Optimization</head><p>Considering the setting of out-of-domain streaming data, i.e., video frames arrive at a sequential order, there generally <ref type="bibr" target="#b3">4</ref> We discuss more about the specific forms of L in Section 4. exists strong temporal dependency between frames, which can be leveraged to improve the quality of online adaptation. Let us suppose that we have two objectives respectively for frame-wise constraints and temporal consistency, denoted by L F and L T , whose specific forms will be discussed later. Straightforward approaches to combine L F and L T include jointly optimizing them by adding them together or iteratively performing two-stage optimization ( <ref type="figure" target="#fig_1">Figure 2b</ref>). However, these methods usually lead to suboptimal results due to the competition and incompatibility between the objectives, in the sense that the gradient of the single-frame constraint may interfere with the training of the temporal one. We also observe that the single-frame constraint is usually optimized much faster than the temporal one. That is to say, in a small number of inferencestage optimization steps, the model may learn pose priors very quickly but then get stuck trying to learn temporal consistency. Therefore, the first and foremost challenge we confront is to design an online optimization scheme to prevent overfitting to each objective and maximize the power of both single-frame and temporal constraints.</p><p>Lower-level weight probe with single-frame constraints. We formulate the problem of identifying effective model weights under spatiotemporal multi-objectives as a bilevel optimization problem. In this setup, as shown in <ref type="figure" target="#fig_3">Figure 3</ref>, the lower-level optimization step serves as a weight probe to rational models under single-frame pose constraints, while the upper-level optimization step finds a feasible response to temporal constraints. Specifically, for the i-th test sample, the model from the last online adaptation step, denoted by M φi−1 , is firstly optimized with the single-frame constraints, L F , to obtain a set of temporary weights denoted by φ i . We name this procedure as the lower-level probe Lower-level weight probe (Lines 5-6 in Alg. 1), in the sense that first, φ i can be feasible responses to the easy component of multi-objectives, which best facilitates the rest of the learning procedure for temporal consistency; Second, φ i is not directly used to update M φi−1 . At this level we focus on the spatial constraints on individual frames:</p><formula xml:id="formula_10">!"# − ∇ $ !"# ℒ % ℒ % ℳ $ !"# … Streaming data ! !"# " ! !"# " ! !"# " ℳ $ ! $ " ! ! $ " ! ! $ " ! ! $ ! ! $ "#$ θ ! ! $ "#$ ! ! $ "#$ ℒ * ℒ % + ℳ $ ! SMPL( " , " ) Upper-level weight update !"# − ∇ $ ! $ (ℒ * + ℒ % ) … Results Time − Time Time − Time</formula><formula xml:id="formula_11">L F = γ 1 ||j i − j i || 2 2 + γ 2 ρ( β i , θ i ) + γ 3 L S ,<label>(2)</label></formula><p>where {γ 1 , γ 2 , γ 3 } are the loss weights. The first term in L F is a straightforward supervision of the re-projection error of 2D keypoints. The second term is the prior constraint on the shape and pose parameters, which is a common practice in mesh reconstruction. ρ(·) calculates the distance of the estimated β i , θ i to their statistic priors <ref type="bibr" target="#b4">5</ref> . The third term is the fully supervised loss with 3D keypoints on a randomly sampled source data, which has two benefits: (1) preventing the catastrophic forgetting of the basic knowledge learned from D tr . (2) providing the online updated model a continuous 3D supervision to keep it from overfitting the imperfect unsupervised loss functions. After optimization at the lower level, we obtain the probe model M φ i for subsequent upper-level learning. Note that, due to a lack of 3D supervisions in the target domain, the above L F is insufficient to recover the 3D body. Therefore, it is essential to explore temporal correlations in streaming data to reduce the ambiguity of mesh construction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Upper-level weight update with temporal constraints.</head><p>At an upper optimization level, we calculate the overall spatiotemporal multi-objectives using M φ i obtained at the lower-level optimization step, and then back-propagate with second-order derivatives to update the original φ i−1 , as <ref type="bibr" target="#b4">5</ref> These priors are obtained from a commonly-used third-party database.</p><p>shown in Lines 7-8 in Alg. 1. As for the specific form the motion constraints, given two images x i , x i−τ at an interval τ with their 2D keypoints j i , j i−τ and the estimated j i , j i−τ , the motion loss is defined as</p><formula xml:id="formula_12">L m = || m i − m i || 2 2 ,<label>(3)</label></formula><p>where m i = j i − j i−τ , and m i = j i − j i−τ . Note that both j i and j i−τ are obtained from the probe model M φ i . Furthermore, we maintain an exponential moving average of history models with a teacher model (similar to Mean-Teacher <ref type="bibr" target="#b49">[50]</ref>), denoted by T ω . We regularize the output of M φ i to be consistent with T ωi−1 :</p><formula xml:id="formula_13">L mt = ||T ωi−1 (x) − M φ i (x)|| 2 2 ,<label>(4)</label></formula><p>which is then combined with the motion loss to obtain the overall temporal constraints that focus on the consistency of both the sequentially updated model weights and the reconstruction results as well:</p><formula xml:id="formula_14">L T = µ 1 L m + µ 2 L mt ,<label>(5)</label></formula><p>where µ 1 and µ 2 control the weights of the two temporal loss terms. From another perspective, these two losses are complementary with each other: the teacher model T maintains long-term temporal information, and the motion loss L m is a constraint on short-term motion consistency.</p><p>Alternatives for online adaptation schemes. As briefly mentioned above, there are several single-level optimization alternatives of the spatiotemporal multi-objectives, e.g., (1) one-stage joint adaptation: online adapting the model with a combined loss of L F + L T . (2) two-stage adaptation:</p><p>adapting the model iteratively with L F and L T in a cascaded optimization manner. However, we observe that the joint adaptation scheme is prone to lead to ineffective training of the temporal constraints due to the incompatibility between multiple objectives. The two-stage scheme adapts the model to individual frames under the single-frame constraints repeatedly, which commonly leads to severe overfitting and drifting away from the final 3D reconstruction metric. The key insights of BOA are as follows: First, it avoids overfitting the temporal constraints by retaining the pose prior loss for the upper optimization level. Second, it avoids overfitting the pose priors by updating the model weights only at the upper optimization level with secondorder derivatives. By this means, BOA effectively combines the profits of both single-frame and temporal constraints, achieving considerable improvement over its alternatives.</p><p>Network architectures. Following the majority of previous SMPL-based human reconstruction models, we use a ResNet-50 <ref type="bibr" target="#b15">[16]</ref> pre-trained on ImageNet <ref type="bibr" target="#b7">[8]</ref> for encoding individual video frames. The encoded features are then delivered to two fully-connected layers with 1,024 neurons, followed by a dropout layer <ref type="bibr" target="#b46">[47]</ref>. The final layer of M φ is a fully-connected layer with 85 neurons. During streaming adaptation, only one image is taken as input. As a result, we replace Batch Normalization <ref type="bibr" target="#b17">[18]</ref> with Group Normalization <ref type="bibr" target="#b57">[58]</ref> to estimate more accurate statistics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>Datasets. We use the Human3.6M dataset for training the source model and learn to adapt the model to the 3DHP and 3DPW datasets. <ref type="table" target="#tab_0">Table 1</ref> presents the statistics of typical domain gaps among these datasets.</p><p>• Human3.6M <ref type="bibr" target="#b18">[19]</ref> is captured in a controlled environment, which has 11 subjects in total. Following the previous approaches <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b20">21]</ref>, we train the base model on 5 subjects (S1, S5, S6, S7, S8), and down-sample all videos from 50fps to 10fps.</p><p>• 3DHP <ref type="bibr" target="#b36">[37]</ref> is the test split of the MPI-INF-3DHP dataset. It consists of 2,929 valid frames from 6 subjects performing 7 actions, collected from both indoor and outdoor environments. keypoints. For the base model M, we follow the same training scheme as SPIN (more details can be found in <ref type="bibr" target="#b25">[26]</ref>). For the training of BOA on 3DPW, we choose the Adam optimizer <ref type="bibr" target="#b23">[24]</ref> with the learning rate η = 3e −6 (β 1 = 0.5, β 2 = 0.999). The loss weights in L F are γ 1 = 10, γ 2 = 1, and γ 3 = 0.1. The loss weights in L T are µ 1 = 0.1 and µ 2 = 0.1. As for 3DHP, the learning rate is set to 2e −6 (β 1 = 0.2, β 2 = 0.999). We set γ 1 = 10, γ 2 = 1, γ 3 = 0.1 in L F and µ 1 = 0.1, µ 2 = 0.1 in L T . Note that the order of streaming videos in 3DPW and 3DHP is pre-defined (same for all compared models), and the batch size of online optimization is 1. We set T = 1 (Alg. 1) for the efficiency of adaptation. Please refer to the supplementary material for more analyses of hyper-parameters.</p><p>Baselines. We initially compare BOA with end-to-end methods, including frame-based methods <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b37">38]</ref>, video-based methods <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b24">25]</ref>, and those attempting to learn generalizable features from the training domain, such as Sim2Real <ref type="bibr" target="#b8">[9]</ref> and DSD-SATN <ref type="bibr" target="#b48">[49]</ref>. Given a video frame, end-to-end methods directly estimate its SMPL parameters. We also include existing approaches that fine-tune SMPL parameters β, θ <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b1">2]</ref> or model parameters φ <ref type="bibr" target="#b19">[20]</ref> on the target domain. Different from these approaches, BOA adapts φ i in an online fashion, which is more challenging. Please refer to the supplementary material for more details.</p><p>Evaluation metrics. Following previous works <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b60">61]</ref>, we evaluate our model in terms of Mean Per Joint Position Error (MPJPE), Procrustes-Aligned MPJPE (PA-MPJPE), and the Percentage of Correct Keypoints (PCK) with a threshold of 150mm on 3DHP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Quantitative Evaluation</head><p>Results on 3DPW.  <ref type="table">Table 3</ref>. Different protocols of pre-processing the 3DPW data by SPIN <ref type="bibr" target="#b25">[26]</ref> and HMMR <ref type="bibr" target="#b21">[22]</ref>. #PS uses the SMPL annotations from the original 3DPW as labels, while #PH uses the fitted neutral results (without gender information) as labels.</p><p>#PS and #PH, and particularly outperforms the methods that are designed to learn generalizable features at training time <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b8">9]</ref>, which indicates that our test-time adaptation approach can better mitigate the domain gap by properly exploiting the streaming data from the test domain. Besides, we also observe that BOA outperforms the compared models that are fine-tuned on the entire training set of 3DPW in an offline manner (middle part uses the same SMPL annotations under #PS.</p><p>Results on 3DHP. <ref type="table" target="#tab_2">Table 4</ref> gives the MPJPE and PA-PMJPE results on 3DHP, which is the test set of the entire MPI-INF-3DHP domain. Note that all models but BOA are directly trained on the training set D train of MPI-INF-3DHP in an offline fashion, in the sense that the global knowledge from the test domain is more accessible to these compared models. Although BOA has never been trained on D train , it still performs best on the corresponding test split, showing a strong adaptability to a rapidly changing test environment. <ref type="figure">Figure 4</ref> presents a typical showcase of mesh reconstruction on the challenging 3DPW dataset. The first row refers to human meshes generated by VIBE <ref type="bibr" target="#b24">[25]</ref>, while the second row corresponds to our results. We zoom in on the limbs for better visualization and observe that the reconstruction quality of VIBE is less satisfying, e.g., the positions of arms and legs are not correctly estimated. By contrast, our model can capture the depth structure of the human subject, which is mainly due to the proposed bilevel optimization scheme and spatiotemporal constraints.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Qualitative Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Ablation Study</head><p>Ablations on the number of optimization steps. With the growth of the optimization steps (T in Alg. 1), as shown in <ref type="figure" target="#fig_6">Figure 6</ref>, the error of single-level training scheme, which combines L F and L T in a multi-objective, in both PA-MPJPE and MPJPE increases quickly. For comparison, the performance of BOA decreases at a much slower rate, which indicates that the single-level optimization is more likely to result in over-fitting to the current video frame, and thus makes it difficult for the model to quickly adapt to the next frame. This effect can be greatly alleviated by the proposed bilevel optimization method. Analyses on the online bilevel optimization framework. As shown in <ref type="table" target="#tab_3">Table 5</ref>, we investigate the effectiveness of the proposed bilevel adaptation scheme and compare it with other variants. Specifically, B1-B3 refer to the single-level, one-stage optimization scheme, while B4-B5 are trained by updating model parameters with alternate loss functions (i.e., L low and L up ). Note that the major difference between two-stage and bilevel is whether the parameters in M φi are obtained from M φ i−1 or M φi−1 . We observe that, despite the use of temporal constraints, B3 performs worse than B1, indicating that the straightforward combination of multiobjectives leads to sub-optimal results. Even though we use the multi-objectives in a two-stage training scheme (B5), we can only observe a minor improvement over the vanilla B1 model. By contrast, the final proposed BOA is shown to effectively combine the best of both constraints and achieve considerable improvement over all compared baselines.</p><p>Ablations on temporal constraints.  <ref type="table" target="#tab_3">Table 5</ref>) B3 (in <ref type="table" target="#tab_3">Table 5</ref>) Ours (BOA) <ref type="figure">Figure 7</ref>. Correlations between the 2D pose re-projection loss and the evaluation metric. B1 uses frame-based losses only. B3 optimizes the frame-based and temporal losses by integrating them in a unified loss function. Only with BOA, the MPJPE results are consistent with the frame-based loss, showing that BOA greatly reduces the 3D ambiguity of estimated meshes.</p><p>domain gaps caused by systematic biases such as the focal length and camera orientations.</p><p>Ablations on loss-metric correlations. In <ref type="figure">Figure 7</ref>, the X-axis refers to the normalized 2D keypoint loss and the Y-axis is the MPJPE. The blue dots are the results of the vanilla baseline only trained with frame-based loss functions (B1), the yellow stars correspond to the baseline model trained with multi-objectives (B3), and the red dots indicate bilevel online adaptation. We can see that, first, although a straightforward use of temporal constraints (B3) achieves comparable results in the 2D loss with B1, it harms the 3D evaluation metric. Second, with BOA, the model achieves MPJPE results that are more consistent with the frame-based loss, indicating that BOA can reduce 3D ambiguity by using the temporal constraints more appropriately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Related Work</head><p>3D human mesh reconstruction. SMPL <ref type="bibr" target="#b35">[36]</ref> is a widely used parametric model for 3D human mesh reconstruction, which is also adopted in this work. The early methods <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b59">60]</ref> generally adopt the optimization scheme, where a standard T-Pose SMPL model is gradually fit to an input image according to the silhouettes <ref type="bibr" target="#b27">[28]</ref> or 2D keypoints <ref type="bibr" target="#b4">[5]</ref>. These optimization-based methods are time-consuming, i.e., they often struggle to reduce the inference time spent on a single input. Recently, many approaches <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b42">43]</ref> use deep neural networks to regress the parameters of the SMPL model, which are efficient and accurate if large-scale data is available. The major drawback of CNN-based regression models is the generalization ability. For example, deep models trained on indoor dataset generally do not have satisfying results <ref type="bibr" target="#b20">[21]</ref> if tested on an in-the-wild dataset. To tackle this problem, Kanazawa et al. <ref type="bibr" target="#b20">[21]</ref> propose an adversarial framework, utilizing the unpaired 3D annotations, to facilitate the reconstruction. Several researches <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b43">44]</ref> also show that the paired 3D annotation is not necessary, attempting to find more representative temporal features <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b52">53]</ref> or employ more informative input such as RGB-D <ref type="bibr" target="#b32">[33]</ref>, and part segmentation <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b43">44]</ref> to facilitate human mesh reconstruction. However, there still exists a principled challenge in this task, where neither the unpaired 3D annotation nor the other mentioned intermediate representations could effectively fill the gap between two largely different datasets. In this work, we propose to tackle this problem by using an online adaptation algorithm, named BOA. The key insight is BOA exploits the time constraints of test frames while avoiding overfitting with bilevel optimization.</p><p>Unsupervised online adaptation. Unsupervised online adaptation refers to sequentially adapting a pre-trained model at test time in an unsupervised manner. It is an emerging technique to prevent model crashing when the test data is diverse from the training data. Previous methods <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b33">34]</ref> use it for tasks other than mesh reconstruction, such as video segmentation <ref type="bibr" target="#b53">[54]</ref>, tracking <ref type="bibr" target="#b40">[41]</ref>, and stereo matching <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b50">51]</ref>. In this paper, we present a pilot study of unsupervised online adaptation in the context of human mesh reconstruction. Beyond unsupervised online adaptation, many previous approaches effectively learn generalizable features through meta-learning <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b10">11]</ref>, extracting domain-invariant representations <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31]</ref>, or learning with adversarial examples <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b54">55]</ref> without requiring access to target labels. However, none of these approaches focus on how to adapt a pre-trained model to streaming data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper, we presented a new research problem of reconstructing human meshes from out-of-domain streaming videos. We proposed a new online adaption algorithm that learns temporal consistency with bilevel optimization and demonstrated that it can greatly benefit the multi-objective training process in space-time. Our approach outperforms the state-of-the-art mesh reconstruction methods on two benchmarks with rapidly changing test environments.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Top: Learning to reconstruct human meshes from outof-domain streaming videos. The main challenges include the domain gaps of plain/crowded backgrounds, with/without occlusions, etc. Bottom: Statistics of other typical domain gaps.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Left: Adapting the model with 2D re-projection loss leads to depth ambiguity, where multiple 3D vertices are projected to the same 2D position. Right: A showcase that the uncertainty of depth information may lead to the wrong estimation of leg posture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>A diagram of the proposed bilevel online adaptation method. For simplicity, we only show one iteration of bilevel optimization. The lower-level training step serves as a parameter probe to find a feasible response to the frame-wise pose constraints. The upper-level training step minimizes the overall multi-objectives in space-time and updates the model with second-order derivatives.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Figure 5 presents a sequence of input videos with severe occlusions, where the subject of interest (the man in the middle) is covered by the walking woman. Still, BOA successfully estimates the occluded human body.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Reconstruction results under severe occlusion. First row: the input frames. Second row: mesh reconstruction results. The subject of interest (the man in the middle) is occluded by the walking woman, which is challenging for out-of-domain mesh reconstruction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>Ablations on the number of optimization steps T (#PS on 3DPW). BOA has a more stable performance with the growth of T , compared with the its single-level counterpart.Index Optim. L low L up PA-MPJPE MPJPE B1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Typical domain gaps among datasets in terms of focal length, bone length, camera distance, and camera height<ref type="bibr" target="#b56">[57]</ref>.</figDesc><table><row><cell>• 3DPW [56] is a multi-person dataset captured by a</cell></row><row><cell>handheld camera, where most videos are collected</cell></row><row><cell>from outdoor environments. As 3DHP, we also use the</cell></row><row><cell>test set of 3DPW as a streaming target domain.</cell></row></table><note>Training details. We first train the base model M on the Human3.6M dataset and take 3DPW and 3DHP as test sets. All video frames are cropped and then scaled to 224 × 224 pixels according to the bounding boxes calculated from 2D</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>presents quantitative comparisons on 3DPW in MPJPE and PA-MPJPE. Following HMMR or SPIN, most existing methods adopt two kinds of pre-processing protocols on 3DPW as illustrated inTable 3. These two protocols have significant differences in the number of test images and SMPL annotations, which have a great impact on the evaluation. Please refer to the</figDesc><table><row><cell>VIBE</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Ours</cell><cell></cell><cell></cell><cell></cell></row><row><cell>(BOA)</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">Figure 4. A qualitative comparison of mesh reconstruction on 3DPW streaming data. We zoom in on the limbs for better visualization.</cell></row><row><cell>Method</cell><cell cols="3">Prot. PA-MPJPE ↓ MPJPE ↓</cell></row><row><cell>HMR [21]</cell><cell>#PH</cell><cell>76.7</cell><cell>130.0</cell></row><row><cell>Sim2Real [9]</cell><cell>#PH</cell><cell>74.7</cell><cell>-</cell></row><row><cell>GraphCMR [27]</cell><cell>#PS</cell><cell>70.2</cell><cell>-</cell></row><row><cell>SPIN [26]</cell><cell>#PS</cell><cell>59.2</cell><cell>96.9</cell></row><row><cell cols="2">I2L-MeshNet [38] #PS</cell><cell>58.6</cell><cell>93.2</cell></row><row><cell>Pose2Mesh [7]</cell><cell>#PS</cell><cell>58.9</cell><cell>89.2</cell></row><row><cell>DSD-SATN [49]</cell><cell>#PS</cell><cell>69.5</cell><cell>-</cell></row><row><cell>HMMR [22]</cell><cell>#PH</cell><cell>73.6</cell><cell>116.5</cell></row><row><cell>SMPLify [5]</cell><cell>#PH</cell><cell>106.1</cell><cell>199.2</cell></row><row><cell>Arnab et al. [2]</cell><cell>#PH</cell><cell>72.2</cell><cell>-</cell></row><row><cell>EFT [20]</cell><cell>#PS</cell><cell>55.7</cell><cell>-</cell></row><row><cell>BOA</cell><cell>#PH</cell><cell>58.8</cell><cell>92.1</cell></row><row><cell>BOA</cell><cell>#PS</cell><cell>49.5</cell><cell>77.2</cell></row><row><cell cols="4">Table 2. Results on 3DPW, including end-to-end approaches (top)</cell></row><row><cell cols="3">and those fine-tuned on the target domain (middle).</cell><cell></cell></row><row><cell>Prot.</cell><cell cols="3">SMPL annotation #Valid frames</cell></row><row><cell>#PS (SPIN)</cell><cell>Original</cell><cell cols="2">35,515</cell></row><row><cell>#PH (HMMR)</cell><cell>The fits</cell><cell cols="2">26,234</cell></row></table><note>supplementary materials for more details. In Table 2, we mark the protocol used in the original literature of each compared method. Compared with other end-to-end meth- ods (top part), BOA achieves better performance in both</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell cols="4">Method 3DHP-D train PA-MPJPE ↓ MPJPE ↓ PCK ↑</cell></row><row><cell>Vnect</cell><cell>98.0</cell><cell>124.7</cell><cell>83.9</cell></row><row><cell>HMR</cell><cell>113.2</cell><cell>169.5</cell><cell>77.1</cell></row><row><cell>SPIN</cell><cell>80.4</cell><cell>124.8</cell><cell>87.0</cell></row><row><cell>BOA</cell><cell>77.4</cell><cell>117.6</cell><cell>90.3</cell></row></table><note>). Note that BOA does not require access to the training set. In addition, we do not include the results from VIBE [25] (56.5 in PA-MPJPE and 93.5 in MPJPE) in quantitative comparison, since it was evaluated on the same number of test images under #PH but. Results on 3DHP. All models but BOA are trained on the training split of MPI-INF-3DHP, while BOA performs best.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 5 .</head><label>5</label><figDesc>Ablation studies on the training schemes (#PS on 3DPW). B1-B3 update model parameters with constant forms of losses in a single optimization step. B4-B5 update model parameters with alternate loss functions. B6 and Final use bilevel optimization.</figDesc><table><row><cell></cell><cell>1-stage L F</cell><cell>-</cell><cell>55.7</cell><cell>86.0</cell></row><row><cell>B2</cell><cell>1-stage L T</cell><cell>-</cell><cell>140.1</cell><cell>245.5</cell></row><row><cell>B3</cell><cell cols="2">1-stage L F , L T -</cell><cell>58.9</cell><cell>94.5</cell></row><row><cell>B4</cell><cell>2-stage L F</cell><cell>L T</cell><cell>59.3</cell><cell>91.5</cell></row><row><cell>B5</cell><cell>2-stage L F</cell><cell>L F , L T</cell><cell>55.2</cell><cell>85.1</cell></row><row><cell>B6</cell><cell>Bilevel L F</cell><cell>L T</cell><cell>142.5</cell><cell>257.1</cell></row><row><cell cols="2">Final Bilevel L F</cell><cell>L F , L T</cell><cell>49.5</cell><cell>77.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6</head><label>6</label><figDesc>shows the ablation studies for the proposed two temporal constraints L mt and L m . By comparing B7 with Final, we can observe that the ues of L m reduces PA-MPJPE from 53.0mm to 49.5mm, while the use of L T B8 reduces PA-MPJPE from 51.7mm to 49.5mm. A possible reason is that the motion loss L m focuses on short-term temporal constraint and helps to recalibrate pose artifacts relative to the last frame. By comparing B8 with Final, we can find that the use of L mt significantly reduces MPJPE, which indicates that the long-term information carried by L mt is beneficial for consistent mesh reconstruction. It may help to mitigate the</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">B1 (in</cell></row><row><cell></cell><cell>400</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>MPJPE</cell><cell>200 300</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>100</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.000</cell><cell>0.001</cell><cell>0.002</cell><cell>0.003</cell><cell>0.004</cell><cell>0.005</cell></row><row><cell></cell><cell></cell><cell cols="3">Normalized 2D Keypoint Loss</cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">It is a common practice to use the ground-truth 2D keypoints for crossdomain human mesh/pose reconstruction</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">We here consider {x i } N i=1 ∈ X as a set of consecutive video frames.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>This work was supported by NSFC (U19B2035) and Shanghai Municipal Science &amp; Technology Major Project (2021SHZDZX0102). This work was also supported by the NSFC grants U20B2072 and 61976137.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Structured prediction helps 3D human motion modelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emre</forename><surname>Aksan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuel</forename><surname>Kaufmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Otmar</forename><surname>Hilliges</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="7144" to="7153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Exploiting temporal context for 3d human pose estimation in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anurag</forename><surname>Arnab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Introduction to Augmented Reality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Billinghurst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VR</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page">266</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Adapting to continuously shifting domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreea</forename><surname>Bobu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Keep it SMPL: Automatic estimation of 3d human pose and shape from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federica</forename><surname>Bogo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angjoo</forename><surname>Kanazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Lassner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="561" to="578" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Streaming variational bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamara</forename><surname>Broderick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andre</forename><surname>Wibisono</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ashia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1727" to="1735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Pose2Mesh: Graph convolutional network for 3d human pose and mesh recovery from a 2d human pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsuk</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gyeongsik</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyoung Mu</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">ImageNet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Sim2real transfer learning for 3d human pose estimation: motion to the rescue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">On the convergence theory of gradient-based model-agnostic meta-learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alireza</forename><surname>Fallah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aryan</forename><surname>Mokhtari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asuman</forename><surname>Ozdaglar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1082" to="1092" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Modelagnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1126" to="1135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Domain generalization for object recognition with multi-task autoencoderss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><surname>Ghifary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengjie</forename><surname>Bastiaan Kleijn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Balduzzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2551" to="2559" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Estimating human shape and pose from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Alexandru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Balan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1381" to="1388" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Holopose: Holistic 3D human reconstruction in-the-wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alp</forename><surname>Riza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Guler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kokkinos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="10884" to="10894" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Towards accurate marker-less human shape and pose estimation over time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinghao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federica</forename><surname>Bogo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Lassner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angjoo</forename><surname>Kanazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ijaz</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Akhter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="421" to="430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Batch Normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">6M: Large scale datasets and predictive methods for 3d human sensing in natural environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catalin</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragos</forename><surname>Papava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vlad</forename><surname>Olaru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Human3</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Exemplar Fine-Tuning for 3d human pose fitting towards in-the-wild 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanbyul</forename><surname>Joo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Neverova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.03686</idno>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">End-to-end recovery of human shape and pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angjoo</forename><surname>Kanazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="7122" to="7131" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning 3d human dynamics from video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angjoo</forename><surname>Kanazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><forename type="middle">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panna</forename><surname>Felsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Undoing the damage of dataset bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinghui</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomasz</forename><surname>Malisiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="158" to="171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">VIBE: Video inference for human body pose and shape estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammed</forename><surname>Kocabas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Athanasiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="5253" to="5263" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning to reconstruct 3d human pose and shape via model-fitting in the loop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Kolotouros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="2252" to="2261" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Convolutional mesh regression for single-image human shape reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Kolotouros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Unite the people: Closing the loop between 3D and 2D human representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Lassner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Kiefel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federica</forename><surname>Bogo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">V</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gehler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6050" to="6059" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deeper, broader and artier domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5542" to="5550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning to generalize: Meta-learning for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In AAAI</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Episodic training for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianshu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1446" to="1455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Domain generalization with adversarial feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiqi</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5400" to="5409" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Towards robust RGB-D human mesh recovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ren</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changjiang</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Georgakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srikrishna</forename><surname>Karanam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terrence</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziyan</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.07383</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Self-supervised deep visual odometry with online adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shunkai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingdian</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zike</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongbin</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6339" to="6348" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning to Adapt to Evolving Domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">SMPL: A skinned multiperson linear model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naureen</forename><surname>Mahmood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Pons-Moll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Monocular 3D human pose estimation in the wild using improved cnn supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Sotnychenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weipeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">I2l-MeshNet: Image-to-lixel prediction network for accurate 3d human pose and mesh estimation from a single rgb image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gyeongsik</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kyoung Mu Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Domain generalization via invariant feature representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krikamol</forename><surname>Muandet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="10" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Neural body fitting: Unifying deep learning and model based human pose and shape estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Lassner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Pons-Moll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3DV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="484" to="494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Meta-tracker: Fast and robust online adaptation for visual object trackers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunbyung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander C</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="569" to="585" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Expressive Body Capture: 3D Hands, Face, and Body from a Single Image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasileios</forename><surname>Choutas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nima</forename><surname>Ghorbani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Bolkart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><forename type="middle">A A</forename><surname>Osman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><surname>Tzionas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="10975" to="10985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Learning to estimate 3d human pose and shape from a single color image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luyang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="459" to="468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Chained representation cycling: Learning to estimate 3d human pose and shape by cycling between representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nadine</forename><surname>Rueegg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Lassner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konrad</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schindler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5561" to="5569" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Generalizing across domains via cross-gradient training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiv</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vihari</forename><surname>Piratla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumen</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddhartha</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preethi</forename><surname>Jyothi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunita</forename><surname>Sarawagi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Combined discriminative and generative articulated pose and non-rigid shape estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Sigal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandru</forename><surname>Balan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1337" to="1344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Dropout: a simple way to prevent neural networks from overfitting. The journal of machine learning research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1929" to="1958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Challenges to grounding in human-robot interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristen</forename><surname>Stubbs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pamela</forename><forename type="middle">J</forename><surname>Hinds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Wettergreen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HRI</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="357" to="358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Human mesh recovery from monocular images via a skeleton-disentangled representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenpeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yili</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="5349" to="5358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antti</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harri</forename><surname>Valpola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1195" to="1204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Learning to adapt for stereo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessio</forename><surname>Tonioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Rahnama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Joy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luigi</forename><forename type="middle">Di</forename><surname>Stefano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thalaiyasingam</forename><surname>Ajanthan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip Hs</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9661" to="9670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Real-time self-adaptive deep stereo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessio</forename><surname>Tonioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Tosi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Poggi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Mattoccia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luigi</forename><forename type="middle">Di</forename><surname>Stefano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="195" to="204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Self-supervised learning of motion capture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsiao-Yu</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsiao-Wei</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ersin</forename><surname>Yumer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katerina</forename><surname>Fragkiadaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5242" to="5252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Online adaptation of convolutional neural networks for video object segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Voigtlaender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Leibe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Generalizing to unseen domains via adversarial data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Riccardo</forename><surname>Volpi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongseok</forename><surname>Namkoong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>Sener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vittorio</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Murino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In NeurIPS</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Recovering accurate 3d human pose in the wild using IMUs and a moving camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Timo Von Marcard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Henschel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Bodo Rosenhahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pons-Moll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Predicting camera viewpoint improves cross-dataset generalization for 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daeyun</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charless</forename><forename type="middle">C</forename><surname>Fowlkes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="523" to="540" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Group Normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Denserac: Joint 3D pose and shape estimation by dense render-and-compare</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanlu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Song-Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tony</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="7760" to="7770" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Monocular 3D pose and shape estimation of multiple people in natural scenes-the importance of multiple scene constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Zanfir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisabeta</forename><surname>Marinoiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2148" to="2157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Inference stage optimization for cross-scenario 3D human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuecheng</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Online depth learning against forgetting in monocular videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephane</forename><surname>Lathuiliere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisa</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicu</forename><surname>Sebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4494" to="4503" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
