<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DOSED: a deep learning approach to detect multiple sleep micro-events in EEG signal</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chambon</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Sleep Sciences and Medicine</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<settlement>Stanford</settlement>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Research &amp; Algorithms Team</orgName>
								<address>
									<settlement>Dreem, Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">LTCI Télécom ParisTech</orgName>
								<orgName type="institution" key="instit2">Université Paris-Saclay</orgName>
								<address>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Thorey</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Research &amp; Algorithms Team</orgName>
								<address>
									<settlement>Dreem, Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Arnal</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Research &amp; Algorithms Team</orgName>
								<address>
									<settlement>Dreem, Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Mignot</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Sleep Sciences and Medicine</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<settlement>Stanford</settlement>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gramfort</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">LTCI Télécom ParisTech</orgName>
								<orgName type="institution" key="instit2">Université Paris-Saclay</orgName>
								<address>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">Inria</orgName>
								<orgName type="institution" key="instit2">Université Paris-Saclay</orgName>
								<address>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution" key="instit1">CEA Neurospin</orgName>
								<orgName type="institution" key="instit2">Université Paris-Saclay</orgName>
								<address>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">DOSED: a deep learning approach to detect multiple sleep micro-events in EEG signal</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T17:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Deep learning</term>
					<term>machine learning</term>
					<term>EEG</term>
					<term>event detection</term>
					<term>sleep</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Background : Electroencephalography (EEG) monitors brain activity during sleep and is used to identify sleep disorders. In sleep medicine, clinicians interpret raw EEG signals in so-called sleep stages, which are assigned by experts to every 30 s window of signal. For diagnosis, they also rely on shorter prototypical micro-architecture events which exhibit variable durations and shapes, such as spindles, K-complexes or arousals. Annotating such events is traditionally performed by a trained sleep expert, making the process time consuming, tedious and subject to interscorer variability. To automate this procedure, various methods have been developed, yet these are event-specific and rely on the extraction of hand-crafted features.</p><p>New method : We propose a novel deep learning architecure called Dreem One Shot Event Detector (DOSED).</p><p>DOSED jointly predicts locations, durations and types of events in EEG time series. The proposed approach, applied here on sleep related micro-architecture events, is inspired by object detectors developed for computer vision such as YOLO and SSD. It relies on a convolutional neural network that builds a feature representation from raw EEG signals, as well as two modules performing localization and classification respectively.</p><p>Results and comparison with other methods: The proposed approach is tested on 4 datasets and 3 types of events (spindles, K-complexes, arousals) and compared to the current state-of-the-art detection algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusions:</head><p>Results demonstrate the versatility of this new approach and improved performance compared to the current state-of-the-art detection methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Sleep is a behavioral state associated with specific changes in physiology and brain activity patterns <ref type="bibr" target="#b0">[1]</ref>. The most common and practical way to monitor brain activity during sleep is to use electroencephalography (EEG).</p><p>EEG measures hundreds of times per second the electrical potentials at several locations over the scalp. Identifying in EEG signals microarchitectural events of variable duration like sleep spindles and K-complexes (0.5 -2 s duration) or arousals (∼ 10 s duration), is of strong interest for sleep research <ref type="bibr" target="#b1">[2]</ref>. Such events are typically used to determine sleep stages, which are scored by 30 s epochs. In other cases however, when one needs to go beyond sleep scoring, they must be counted and specifically annotated. It is notably the case when the aim is to understand sleep physiology <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b4">4]</ref> or to study the pathophysiology of specific sleep or neuropsychiatric disorders <ref type="bibr" target="#b5">[5,</ref><ref type="bibr" target="#b6">6,</ref><ref type="bibr" target="#b7">7]</ref>. The identification of micro-architectural events in the EEG is traditionally performed by trained sleep experts, also called scorers, who visually investigate the recorded signals over a night and annotate the relevant events with their respective start times and durations. This is a tedious, imprecise, costly and time consuming task. Furthermore, this process exhibits a low inter-scorer agreement, which may be improved by taking the consensus of multiple sleep experts <ref type="bibr" target="#b2">[3]</ref>.</p><p>Multiple automatic algorithms for the detection of micro-events in the sleep EEG, such as spindles or Kcomplexes, have been proposed in the literature. These typically rely on band-pass filtering (typically 11 − 16 Hz for spindles, 0.5 − 5 Hz for K-complexes), and the extraction of hand-crafted features. Four categories of algorithms can be distinguished. Methods from the first category extract the envelope of the filtered signal and threshold it <ref type="bibr" target="#b8">[8,</ref><ref type="bibr" target="#b9">9,</ref><ref type="bibr" target="#b10">10,</ref><ref type="bibr" target="#b11">11,</ref><ref type="bibr" target="#b12">12,</ref><ref type="bibr" target="#b13">13]</ref>. The thresholding level is then either fixed or tuned. The threshold can be applied to the rectified filtered signal <ref type="bibr" target="#b13">[13]</ref>, to the instantaneous amplitude obtained by Hilbert transform <ref type="bibr" target="#b12">[12]</ref>, to the root mean square of the filtered signal <ref type="bibr" target="#b11">[11]</ref>, or alternatively to the moving average of the rectified filtered signal <ref type="bibr" target="#b9">[9]</ref>.</p><p>In order to identify the start and end times of events, it was for example proposed to look at inflexion points of the envelope of the filtered signal <ref type="bibr" target="#b10">[10]</ref>. This process is typically done after signal pre-processing to remove ocular artifacts and environmental noise such as the spurious signals due to electrical current (notch filtering around 50 Hz or 60 Hz). One limitation of this first category of methods is that they should be employed during specific sleep stages <ref type="bibr" target="#b13">[13,</ref><ref type="bibr" target="#b12">12,</ref><ref type="bibr" target="#b11">11,</ref><ref type="bibr" target="#b9">9,</ref><ref type="bibr" target="#b8">8]</ref>. Therefore they require preliminary visual inspections of the data and/or a preliminary manual sleep stage scoring.</p><p>The second type of approaches decomposes the EEG signals into an oscillatory component and a transient component prior to filtering and thresholding the resulted signals <ref type="bibr" target="#b14">[14,</ref><ref type="bibr" target="#b15">15,</ref><ref type="bibr" target="#b16">16]</ref>. These methods can detect both spindles and K-complexes, provided some changes are made to hyper-parameters. Also, they are not sleep stage specific which make them more attractive and efficient. The third type of methods employ unsupervised learning techniques such as clustering. For the clustering step, Patti et al. <ref type="bibr" target="#b17">[17]</ref> use a Gaussian Mixture Model (GMM). First the input signal is a band-pass filtered in 3 frequency bands <ref type="bibr">(10.5 -16</ref> Hz, 4 -10 Hz, 20 -40 Hz), then 2 features called sigma ratio and sigma index are extracted from sliding windows of 1 s: the sigma ratio is the ratio of energy in the spindle frequency band <ref type="bibr">(10.5 -16</ref> Hz) during the window of interest over the energy in previous and following windows, while the sigma index is the ratio of power in the spindle band <ref type="bibr">(10.5 -16</ref> Hz) over the sum of energy in the neighboring frequency bands (4 -10 Hz and 20 -40 Hz). The GMM is then applied on extracted features to cluster samples into potential spindles versus non spindles. This approach has the following advantages: it is unsupervised, hence does not rely on human annotations and it is not sleep stage specific. Yet, as the technique is unsupervised the algorithm may not discriminate the events of interest, performance cannot be easily quantified, and the setting of hyper-parameters cannot be automated thanks to cross-validation. The fourth type of methods are supervised machine learning approaches which consist in training a classifier to predict whether a window of signal is an event of interest or not. For such a binary decision, classifiers such as a Support Vector Machine (SVM) classifier <ref type="bibr" target="#b18">[18]</ref> or a Random Forest Classifier <ref type="bibr" target="#b19">[19]</ref> can be trained on manually extracted signal features, such as amplitude variance, number of peaks or zero crossings etc. <ref type="bibr" target="#b18">[18]</ref>.</p><p>The methods mentioned above suffer from several limitations. First, they rely on pre-defined parameters, such as frequency bands for filtering, which may not be optimal for some recordings or subjects. Second, they are intrinsically event-specific. Third, their hyper-parameters, such as thresholds, are often selected on the recording(s) used for evaluating detection performances, introducing a positive and optimistic bias in reported results. To address these limitations, possible solutions can be found in the computer vision literature, and more specificaly in the state-of-the-art object detection literature which relies on deep convolutional neural networks <ref type="bibr" target="#b20">[20,</ref><ref type="bibr" target="#b21">21,</ref><ref type="bibr" target="#b22">22,</ref><ref type="bibr" target="#b23">23,</ref><ref type="bibr" target="#b24">24]</ref>. Such approaches learn a feature representation that is used by a prediction module that outputs both bounding boxes of detected objects as well as their classes. These approaches can handle objects of multiple classes at any scale and make predictions based on features drawn from entire or subsection of images <ref type="bibr" target="#b23">[23,</ref><ref type="bibr" target="#b24">24,</ref><ref type="bibr" target="#b21">21,</ref><ref type="bibr" target="#b22">22]</ref>. Besides, they may make predictions from different features maps of the underlying neural network <ref type="bibr" target="#b21">[21,</ref><ref type="bibr" target="#b22">22]</ref> allowing to handle different resolutions and scales of objects. Translating such methods to detect micro-architectural events in EEG time series is of great interest as it would provide the community with a non-event specific and a non sleep stage specific method that predicts locations, durations and types of any micro-event at the same time. Nonetheless, the translation from images to EEG time series is not straightforward for two reasons. First, when working on EEG recordings, one needs to process chunks of signals: processing entire nights of signal is not tractable. Second, in a recording, most of these chunks of signals do not contain any true event. This implies that a successful method has to predict not only the absence of any event in the majority of the signal, but start times, durations and classes of events accurately when they occur. In machine learning terms, the method needs to cope with the problem of learning from imbalanced data.</p><p>In this paper we propose the Dreem One Shot Event Detector (DOSED), a deep learning architecture algorithm to detect any type of micro-events in multivariate EEG signals. The proposed approach builds on a convolutional neural network which extracts high-level features from raw non-preprocessed EEG time series. A localization module predicts centers and durations of potential events over the input signals while a classification module predicts their labels. The whole network architecture is trained end-to-end by back-propagation. In the following sections, we first detail this general approach and the associated training procedure. We then present a detailed and extensive benchmark comparing the proposed method with multiple state-of-the-art algorithms, on 3 event detection tasks and over 4 datasets. We also address technical questions pertaining to the influences of hyper-parameters on detection performances. This work extends on a recent short communication <ref type="bibr" target="#b25">[25]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Methods</head><p>Notation. We denote by n the set of integers {1, . . . , n} for n ∈ N. Let X = R C×T be the set of EEG input samples where C stands for the number of EEG channels and T for the number of time steps. Let L ∈ N be the number of different labels or types of events to be predicted. We denote L = L the set of events labels, and 0 the label associated to no event or background signal. An event e = t c , t d , l ∈ E = R 2 × L ∪ {0} is defined by a center location time t c , a duration t d and an event label (or type) l ∈ L ∪ {0}. A true event is an event with label in L detected by a human scorer or a group of human scorers, a.k.a. consensus. A predicted event is an event with label in L detected by an algorithm or a group of algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Method overview</head><p>The general principle of DOSED is as follows. Let x ∈ X be an EEG sample, i.e. a short window of signal (∼ 30 s duration) coming from a PSG recording (∼ 8 h). First, the method is initialized with N d default events</p><formula xml:id="formula_0">d i = (t c i , t d i )</formula><p>, which are parameterized with a center time t c i and a duration t d i , and which are positioned over each input signal x. For example, 1 s default events every 0.5 s if this corresponds to a typical duration of events to be detected, see <ref type="figure">Figure 1</ref> -A. Note that, centers, durations and overlaps of such default events can be adjusted depending on the type(s) of event(s) to be detected. Second, the network predicts a potential event associated to each default event: it predicts an adjusted center and an adjusted duration, as well as the probability for this event to have any label l ∈ L ∪ {0}, cf. <ref type="figure">Figure 1</ref> -B. Finally, potential events for which the highest probability label l ∈ L, and for which the probability is higher than a specific (cross-validated) threshold θ l ∈ [0, 1], are selected.</p><p>Then, non-maximum suppression is applied to remove overlapping events, cf. <ref type="figure">Figure 1</ref> -C <ref type="bibr" target="#b22">[22,</ref><ref type="bibr" target="#b23">23]</ref>. <ref type="figure">Figure 1</ref>: Prediction procedure for DOSED. A: N d default events, d i , i ∈ N d , are generated over the EEG sample. B: the network predicts potential events, i.e. adjusted centers and durations with respect to default events centers and durations, and potential events labels. C: non-maximum suppression is applied to merge overlapping potential events with label l different from 0. The network finally returns the center(s), duration(s) and label(s) of the remaining merged event(s).</p><formula xml:id="formula_1">A B C d1 d2 dN d</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Loss function</head><p>Supervised machine learning boils down to the minimization of a specific loss function that quantifies the prediction errors from the model on the training database. Here the default events are parameterized by a center and a duration, so the method predicts an adjusted center and an adjusted duration for any default event. It also returns the probabilities of each event type as well as the probability of belonging to the background signal (l = 0).</p><p>To quantify the overlap in time between two events, a commonly used metric is the Jaccard index, a.k.a.</p><p>Intersection over Union (IoU) <ref type="bibr" target="#b23">[23]</ref>. For two time intervals, it is defined as the ratio of size between their intersection and their union. This metric takes values between zero and one. It is zero if the events do not overlap in time, and one if they perfectly overlap.</p><p>The goal is to learn a prediction functionf from X to Y where y ∈ Y is a set of elements from E. Given N d ∈ N default events generated over the input EEG sample x ∈ X . Let D(x) = d i = (t c i , t d i ), i ∈ N d be the set of centers and durations of the N d default events generated over x. Let E(x) = e j = (t c j , t d j , l j ) : j ∈ N e be the list of the N e true events annotated over the signal x.</p><p>At training time, we want to map the default events and the true events. Following SSD <ref type="bibr" target="#b22">[22]</ref> we use per-prediction matching. First, bipartite matching is applied: each true event is matched with the default event presenting the highest IoU. The remaining default events are then matched to the ground truth event presenting the highest IoU with IoU(d i , e j ) &gt; η ∈ [0, 1]. We denote by γ the function which returns, if it exists, the index j of the true event matching with the default event d i , and ∅ otherwise. The unmatched default events are assigned with the label l = 0 related to the absence of event.</p><p>Let e j be a true event matching with the default event d i . d i 's center and duration are then encoded with <ref type="bibr" target="#b24">[24]</ref>. This encoding function quantifies the relative variations in centers and durations between the default event d i and the true event e j .</p><formula xml:id="formula_2">φ ej : R 2 −→ R 2 , d i = (t c i , t d i ) −→ t c j − t c i t d i , log t d j t d i</formula><p>Letf (x) ∈ Y be the prediction made by the modelf over the sample x. We define it asf (</p><formula xml:id="formula_3">x) = {(t c i ,t d i ,l i ) ∈ E, i ∈ N d }.τ i = (t c i ,t d i )</formula><p>are the predicted coordinates of encoded default event d i andl i is its predicted label. In practice, the model will output the probability of each label l ∈ L ∪ {0} for default event d i sol i is replaced by a vector of probabilitiesπ i ∈ [0, 1] |L|+1 . As it is a probability vector, we have l∈L∪{0}π l i = 1. The loss between the true annotation E(x) and the model predictionf (x) over signal x is a function :</p><formula xml:id="formula_4">Y × Y → R + defined as E(x),f (x) = + norm + − norm where + = i∈ N d γ(i) =∅ L1 smooth φ e γ(i) (d i ) −τ i − log(π l γ(i) i ) (1) − = − i∈ N d γ(i)=∅ log(π 0 i )<label>(2)</label></formula><p>and the normalized losses + norm and − norm are obtained by dividing + and − by the numbers of terms involved in the sums (1) and (2) respectively. In (1), the sum considers the localization and classification losses for any default event d i matching a true event e γ(i) . The L1 smooth loss applies coordinate-wise the real valued function:</p><p>x → (x 2 /2)1 |x|&lt;1 + (|x| − 1/2)1 |x|≥1 , a.k.a. the Huber loss <ref type="bibr" target="#b24">[24]</ref>. The purpose of (1) is to promote accurate localization and classification on default events matching a true event (l ∈ L). Equation (2) corresponds to the classification loss for default events which do not match any true event (l = 0).</p><p>One particular difficulty for the proposed approach, is that most of the default events do not match any true event. This is due to the facts that (1) EEG signals contain few events over long time periods, and that (2) the parameterization of default events implies using as many overlapping default events as necessary to maximize the number of true events matched over a window x. To address the issue of label imbalance between default events matching a true event and default events not matching any true event (l = 0), we employed a negative-mining step: during training only a fraction of default events with label l = 0 were used. Let us remark that this negative mining step is omitted in (2) for simplicity. The process first boils down to sorting default events which do not match any true event based on their classification errors. The events which exhibit the worst classification errors are then considered, and a fraction of them is finally selected to compute the loss (2). This fraction is set such that the ratio between default events matching a true event and default events matching no true event is equal to 1/3, while ensuring that a minimum number of 10 default events matching no true event is selected.</p><p>Remark that the parameterization of default events is important to ensure a successful training process. In particular the parameterization of the duration t d i of the default events is critical. Indeed, a bad choice for t d i might lead to a small number of matched true events during the training process thus hurting the detection performances of the proposed approach. The influence of the default events durations is investigated and discussed in a specific experiment in Section 3.</p><p>To conclude, training the event detection methodf boils down to solving the following minimization problem:</p><formula xml:id="formula_5">f ∈ arg min f ∈F E x∈X [ (E(x), f (x))]<label>(3)</label></formula><p>Note that the loss function is differentiable with respect to the parameters of the considered model f , so it becomes possible to learn a neural network f with (stochastic) gradient methods and back-propagation. Also note that in practice, one minimizes the empirical version of (3) computed over a finite number of labeled training samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Model architecture</head><p>What remains to be defined is the form of the function f , i.e. the architecture of the network. We use for f a deep convolutional neural network that predicts at most N d potential events with label different from 0 given a set</p><formula xml:id="formula_6">of default events D(x) = {d i = (t c i , t d i ) : i ∈ N d }.</formula><p>The architecture of the network is as follows. First, following the work in <ref type="bibr" target="#b25">[25,</ref><ref type="bibr" target="#b26">26]</ref>, it starts with a spatial filtering of the input signals. This corresponds to a matrix multiplication similar to Independent Component Analysis (ICA) that increases the signal to noise ratio <ref type="bibr" target="#b25">[25,</ref><ref type="bibr" target="#b26">26]</ref>. Then, it performs some temporal processing with convolutions to build a feature representation of the input signals, and finally it outputs the prediction of intervals and labels of potential events.</p><p>Let K, F, C, T ∈ N. The network can be written as the composition of three functions, f (x) = ψ(φ T (φ C (x))).</p><p>The module φ C : X −→ X stands for the spatial filtering operation which performs C linear combinations of the C input time series and returns a new tensorx ∈ X . This module is implemented by a 2D convolution layer with C kernels of size (C, 1) (space, time) followed by a transpose operation. When C = 1 this module becomes the identity function: φ C = Id.</p><p>The module φ T : X −→ R F ×C×T performs the temporal feature extraction. The module φ T is composed of K blocks. Each block k is composed of a 2D convolution layer with batch normalization <ref type="bibr" target="#b27">[27]</ref> and ReLU activation</p><p>x → max(x, 0) <ref type="bibr" target="#b28">[28]</ref>, followed by a temporal max-pooling. Block k first convolves the previous feature maps x k−1 with 4 × 2 k kernels of size (1, 3) (space, time), using a stride of 1. Zero padding is used to maintain the dimension of the tensor through the convolution layer. Then, the ReLU activation is applied. Finally a temporal max pooling operation with kernel of size (1, 2) and stride 2 is applied to divide by 2 the temporal dimension. Each Block k does not process the spatial dimension. Thus, the output of φ T is a tensor of shape (F, C,T ) with F = 4 × 2 K and</p><formula xml:id="formula_7">T = T /2 K . The module ψ : R F ×C×T ←→ (R 2 × L ∪ {0}) N d ,</formula><p>stands for the prediction part of the model: it predicts for each of the N d default events its corresponding potential event, i.e. its adjusted center and duration in R 2 as well as the label of this potential event in L ∪ {0}. In practice it predicts a probability vector which encodes the probability of that event to belong to any of the classes L ∪ {0}. The prediction of locations is implemented by a convolution layer with 2 × N d kernels of dimension (C,T ) and a linear activation. The prediction of classes is implemented with a 2D convolution layer with (L + 1) × N d kernels of dimension (C,T ). A softmax activation is applied on every L + 1 output feature maps to obtain a probability vector π i for any potential event i. The general architecture is summarized in <ref type="table">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Module</head><p>Layer Type kernel size kernel # output dim activation stride <ref type="table">Table 1</ref>: General architecture of the proposed approach. The network f (x) = ψ(φ T (φ C (x))) processes an input tensor of shape (1, C, T ) corresponding to C time series of T time steps. φ C stands for the spatial processing module that performs spatial filtering. When C = 1, φ C = Id. φ T stands for the temporal processing module that builds the temporal feature representation and outputs a tensor of shape (F, C,T ) with F = 4 × 2 K andT = T /2 K . ψ stands for the prediction module that predicts locations of potential events and their classes, i.e. it outputs two tensors: the localization tensor of shape (2 × N d ) and the classification tensor of shape ((L + 1) × N d ).</p><formula xml:id="formula_8">Conv. 2D (C, 1) C (C, 1, T ) linear 1 φ C Transpose - - (1, C, T ) - - Conv. 2D (1, 3) 4 × 2 k (4 × 2 k , C, T /2 k−1 ) relu 1 φ T k blocks, k ∈ K Max P. 2D (1, 2) - (4 × 2 k , C, T /2 k ) - (1, 2) ψ -localization Conv. 2D (C,T ) 2 × N d (2 × N d , 1, 1) linear ψ -classification Conv. 2D (C,T ) (L + 1) × N d ((L + 1) × N d , 1, 1) softmax every (L + 1) kernels</formula><p>Note that the predictions exploit the full spatio-temporal data: they are based on convolutions of the whole output of φ T</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Datasets</head><p>The experiments were performed on 4 datasets described below. Details on the datasets are summarized in <ref type="table" target="#tab_3">Table 2</ref>.  <ref type="table" target="#tab_3">Table 2</ref>.</p><p>Metrics. By event metrics were used to quantify detector performances for detection and localization of events <ref type="bibr" target="#b2">[3]</ref>.</p><p>These metric rely on the following IoU criterion: for a given δ &gt; 0, a predicted event was considered as a true positive if it exhibited an IoU ≥ δ with a true event, otherwise it was considered as a false positive. The numbers of positives and true positives were evaluated to compute precision, recall and F1 scores of detectors for different overlapping criterion δ ∈ {0.1, 0.2, . . . , 0.9}. When δ = 0.1 a predicted event which exhibits at least some small overlap with a true event might be considered a true positive, and when δ = 0.9 only a predicted event which exhibits a high overlap with a true event is considered a true positive. Evaluation was performed for δ ∈ {0.1, 0.2, . . . , 0.9}, on entire PSGs, each being taken individually. Reported performances were averaged by values of δ over PSG recordings from the testing set.</p><p>Compared methods. For spindles detection, 3 state-of-the-art alternative methods were compared: Parekh et al.</p><p>2017 <ref type="bibr" target="#b14">[14]</ref>, Lajnef et al. 2017 <ref type="bibr" target="#b15">[15]</ref> and Lachner-Piza et al. 2018 <ref type="bibr" target="#b18">[18]</ref>. Benchmarks relied on codes provided by the original authors 2 . For K-complexes detection, Lajnef et al. 2017 <ref type="bibr" target="#b15">[15]</ref> was considered as the baseline comparator.</p><p>This algorithm was designed to detect negative peaks of K-complexes without detecting precisely start times and end times of these events. The convention employed by the authors was therefore used: start time was predicted as 0.1 s before the negative peak and end time as 1.3 s after the negative peak. Hyper-parameters were selected by grid search on the training and validation PSG recordings at hand. The selection was performed in order to maximize F1 scores. More precisely, for a given overlapping criterion δ ∈ {0.1, . . . , 0.9} of interest, F1-scores associated to every set of hyper-parameters were evaluated on validation PSG recordings. The set achieving the highest F1-score was selected to predict PSG metrics of the testing set, computed with respect to this specific δ. The process is repeated for every δ ∈ {0.1, 0.2, . . . , 0.9}, meaning that for each δ a potentially different set of optimal hyper-parameters is selected. Proposed approach. For detection of spindles and K-complexes, the network was provided with 20 s EEG samples, sampled at a sampling frequency F s specific to each dataset. Furthermore, the feature extraction module φ T was built with K = 8 blocks. Thus, x ∈ R C×T , with T = 20 × F s . Only the case C = 1 was considered for spindles and K-complexes. For arousals detection, the network was provided with 2 min samples, down-sampled to 128 Hz.</p><p>For this task, if not mentioned, C = 1. For every task, a normalization was applied to each sample x: centering and standardization by dividing each centered signal by its standard deviation computed on the full recording. We summarize the training details of the proposed approach on each dataset in <ref type="table" target="#tab_3">Table 2</ref>.   Duration stands for the duration of the input windows used in the the proposed approach. T is the resulting number of time steps. C stands for the number of channels that was considered. lr stands for the learning rate used during stochastic gradient descent training. * : Note that PSG recordings from MESA were down-sampled to 128 Hz, which is in practice performed at the level of batch-sampling This approach was implemented using the PyTorch library <ref type="bibr" target="#b33">[33]</ref>. Minimizing (3) was achieved using a stochastic gradient descent, with a learning rate of lr = 10 −4 on MASS (lr = 10 −3 on SSC, WSC, MESA), a momentum µ = 0.9 and a batch size of 32. 200 training epochs were considered. If not explicitly mentioned, each batch was balanced i.e., containing 50% of samples with at least one true event and 50% of samples without any true event.</p><p>In practice, samples were drawn at a random time location in the record until they match the condition of having at least one event or not. When a true event was partially included in a sample, its label l was set to 0 if less than 50% of this event was part of that sample. Early stopping was used to stop the training process when no improvement was observed on the loss evaluated on the validation data over 10 consecutive epochs. Furthermore, a learning rate decrease procedure was used: when no progress was observed on the validation loss after 5 consecutive epochs, the learning rate was divided by 2. Learning rate decrease on plateau is commonly used for training neural networks <ref type="bibr" target="#b34">[34]</ref>. At prediction time, consecutive EEG samples were sampled from entire PSG recordings, and the network predicted on each of these samples.</p><p>Matching hyper-parameter η was fixed to η = 0.5. The proportion of default events containing a true event versus the defaults events containing no true event was fixed to 1/3, and the minimum number of default events containing no true event was fixed to 10. This ensures that class unbalance between default events matching a true event and those which do not is limited to 1/3 which is assumed to be better for the classification module of the network. Selecting a minimal number of default events matching no true event ensures that the network learns something on each sample, even if it does not contain a true event. Non-maximum suppression was applied to merge potential events exhibiting at least an IoU ≥ 0.4. Default events for spindles and K-complexes detection were fixed as 1 s sliding windows with 75% overlap between two consecutive default events, resulting in N d = 80 default events.</p><p>Default event hyper-parameters for arousals detection were investigated in a dedicated experiment. A potential event (t c i ,t d i ,π i ) was considered a positive event of label l ifπ l i ≥ θ l , θ l ∈ [0, 1] being a detection threshold specific to label l. This means that a predicted event was considered as a positive event of label l ∈ L if the probability of this labelπ l i is higher than a certain cross-validated detection threshold θ l . The detection threshold θ l for detecting events of label l ∈ L was selected by cross-validation for any overlapping criterion of interest δ ∈ {0.1, . . . , 0.9} following a process similar to the one used for the baselines. For every δ, hyper-parameter θ l was selected by grid search over the validation data to maximize the F1 score. More precisely, for a given δ, the network was used to predict on the validation PSG recordings with different detection thresholds θ l ∈ [0, 1] leading to different precision, recall and F1 scores. The detection threshold achieving the highest F1 score with respect to this criterion δ was used for performance evaluation on the testing set. The process was repeated for any δ ∈ {0.1, . . . , 0.9}.</p><p>In summary, to use the proposed approach one needs to select the following parameters: (1) the default events parameters depending on the events to detect (a priori knowledge), (2) the learning rate by monitoring the training and validation losses (experimental knowledge) (3) the detection threshold θ l by cross-validation (experimental knowledge).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Results</head><p>We now provide the results on the different detection tasks (spindles, K-complexes, arousals).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Spindles detection.</head><p>In this experiment, we compare the proposed approach with three alternative methods on the spindle detection task over 3 different datasets: SS2, SSC and WSC. We perform 3 intra-dataset benchmarks. We report the detection performances of every approach obtained on each dataset in <ref type="figure" target="#fig_3">Figure 2</ref>. We also report some statistics about the datasets in <ref type="figure">Figure 3</ref>.</p><p>A first observation is that, on every dataset, the proposed approach outperforms the compared methods in terms of precision / recall at IoU = 0.3 and in terms of F1 score for any IoU. One can also see on SS2, that the detection performances are quite stable for any IoU in [0.1, 0.7].</p><p>A second major observation is that the learning task appears more difficult on SSC and WSC datasets than on SS2. Indeed, performances reported on SS2 are higher than those reported on SSC and WSC. Also, the standard deviations obtained on SS2 are smaller than those obtained on SSC and WSC. Finally the losses obtained on SS2 are smaller than the ones obtained on SSC and WSC, see <ref type="figure" target="#fig_17">Figure 13</ref> and <ref type="figure" target="#fig_18">Figure 14</ref>  samples, see <ref type="figure">Figure 3</ref>. Yet, the frequency analysis indicates that the spindles from SS2 exhibit a more salient frequency content in the 11 − 16 Hz frequency band compared to SSC / WSC, see Spindle detection and consensus level. In this experiment, we benchmark the proposed approach on the spindles detection task, on SSC and WSC datasets. Annotations built with 3 different consensus levels are considered:</p><p>κ ∈ {0.2, 0.4, 0.6}. We report in <ref type="figure">Figure 4</ref> the statistics of annotated events depending on the consensus level considered. The obtained performances are reported in <ref type="figure">Figure 5</ref>.</p><p>One can first observe in <ref type="figure">Figure 4</ref> that the numbers and the durations of events decrease as the consensus level increases. This leads to fewer training and validation events for learning when κ increases. The changes induced by the consensus level on the annotated events statistics induce significant changes in the obtained performances, see <ref type="figure">Figure 5</ref>. Indeed, at constant testing level, the F1 score at IoU = 0.3 decreases when the training consensus level increases. This might be due to the fact that fewer training and validation samples are available. Note that, at constant training consensus level, the F1 score at IoU = 0.3 decreases when the testing consensus level increases on SSC. This might be explained by the fact that the events used for training are of poor quality compared to the events used for testing. This will be further commented in the discussion of this work.</p><p>Finally, on WSC, at constant training consensus level, the higher F1 score is always reached for a testing K-complexes detection. In this experiment, we perform a general benchmark on MASS SS2 dataset, on K-complexes detection and demonstrate that the proposed approach outperforms current state-of-the-art methods Lajnef et al.</p><p>2017 <ref type="bibr" target="#b15">[15]</ref>. We report the obtained performances in <ref type="figure" target="#fig_7">Figure 6</ref>. We furthermore report some statistics about the K-complexes annotations over SS2 in <ref type="figure" target="#fig_8">Figure 7</ref>.  The proposed approach outperforms the approach from Lajnef et al. 2017 <ref type="bibr" target="#b15">[15]</ref> in terms of Precision / Recall at IoU = 0.3, and in terms of F1 score for any IoU. Furthermore, the proposed approach seems to predict start and end times quite precisely. Indeed, the F1 score as a function of IoU is rather stable for IoU ∈ [0.1, 0.7]. Note however, that Lajnef et al. 2017 is not able to predict accurately the start and end times of events and can only detect the negative peaks of K-complexes. Indeed, the start and end times are predicted empirically as occurring 0.1 s before and 1.3 s after the negative peaks of the K-complexes following the authors' pipeline <ref type="bibr" target="#b15">[15]</ref>. This penalizes negatively this approach as it assumes that the duration of predicted events is always of 1.4 s whereas the duration of true events is around 0.8 s on average (see <ref type="figure" target="#fig_8">Figure 7</ref>). This may explain the drop of F1 score for IoU ≥ 0.3. Joint spindles and K-complexes detection. In this experiment, we perform a general benchmark on joint Kcomplexes and spindles detection and we demonstrate that detecting both events at the same time leads to detection performances similar to the ones obtained when performing each detection task separately. We report the results in <ref type="figure" target="#fig_10">Figure 8</ref>.  Learning to detect both events jointly or separately leads to similar performances in terms of precision and recall at IoU = 0.3 and F1 score as a function of IoU.</p><p>Sampling. In this experiment, we investigate the influence of the batch sampling strategy. We vary the proportion of samples in a training batch which contains a true event from 0.1 to 1. and we quantify its influence on the F1 score at IoU = 0.3. In other words, setting the proportion to 0.5 means that half of the samples present in the batch contains a true event. We report the obtained performances on SS2 dataset in <ref type="figure" target="#fig_12">Figure 9</ref>.  to lower performances than using batches composed of a mix of samples with a true events and "empty samples".</p><p>One can observe that the proportion of samples in a training batch, which contain a true event does not influence significantly the proposed approach's performance on spindles detection.</p><p>However, for K-complexes detection, a higher proportion of samples containing a true event in a batch leads to a significantly lower detection performance. This might be due to the following facts. First, K-complexes are events with a low frequency content arising in N2 sleep stage <ref type="bibr" target="#b1">[2]</ref> and similar low frequency content events also occur in N3 sleep stage under the form of grouped slow oscillations. Second, with high proportions of samples containing a true event the proposed approach is likely to never learn to differentiate a K-complex from a slow oscillation.</p><p>The analysis of predictions with respect to sleep stages (not shown) agrees with this explanation. Indeed, a higher proportion (in training batches) of samples with a true event leads to a higher number of predicted K-complexes in period of N3 sleep. However no K-complex has been annotated over these periods of N3. To prevent such an issue, a 0.5 proportion of samples containing a true event appears as a good compromise.</p><p>The same observations apply for the proposed approach when it is trained to detect jointly spindles and Kcomplexes (not shown).</p><p>Learning curves: Do we have enough data?. In this experiment, we investigate the influence of the quantity of labeled events used for training on the performances of the proposed approach on SS2, SSC and WSC. We report the F1 scores at IoU = 0.3 when the number of training PSG recordings varies from 1 to 20 <ref type="table" target="#tab_3">(SS2: 1</ref>   The learning curves on SS2 demonstrate that learning from few PSG recordings leads to quite good performances.</p><p>Indeed, the proposed approach exhibits high F1 at IoU = 0.3, even when trained on events from a single PSG.</p><p>On the other hand, the learning curves on SSC and WSC lead to slightly different observations: learning from just a couple of PSGs is not sufficient to get good performances. Indeed, the performance reached when using the maximum number of training PSGs available is much higher than the performance obtained when using a few training PSGs. This experiment first indicates that the spindle detection task is more complex on SSC and WSC than on SS2 which agrees with observations previously made. Second, it suggests that we might lack of labeled data on SSC and WSC to obtain detection performances similar to the ones obtained on SS2.</p><p>Arousal detection. In this section, we apply and demonstrate that the proposed approach can be used to detect other types of events, here arousals. We investigate the following technical questions: (1) the influence of the duration of default events (2) the influence of the quantity of training data and (3) the influence of the number of channels considered.</p><p>To do so, we first train the proposed approach while varying the duration t d i of default events from 2 s up to 40 s and keeping an overlapping of 50% between two consecutive default events: default events are generated every t d i /2 s ensuring that only 2 default events overlap. We report the obtained results in <ref type="figure">Figure 11</ref> -A. We furthermore investigate the influence of the quantity of training data available modulated by the quantity of spatial information that is processed, <ref type="figure">Figure 11</ref> -B. We additionally report some statistics about the events annotated over MESA in  <ref type="figure">Figure 11</ref> -B demonstrates that the more data the better, yet for this task and with the chosen network architecture, the metric increases at a limited pace after 100 training PSG recordings. Finally, using more channels leads to a significant boost in detection performances and may also be used to balance a potential lack of training PSGs as shown in <ref type="figure">Figure 11</ref>. This positive impact of the number of channels was also reported in <ref type="bibr" target="#b26">[26]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Discussion</head><p>This work reports on the successful use of a novel approach to simultaneously detect multiple EEG microarchitectural features in EEG signals. It is based on object recognition approaches developped for computer vision and is inspired by SSD <ref type="bibr" target="#b22">[22]</ref> and YOLO approaches <ref type="bibr" target="#b23">[23]</ref>. The model builds by back-propagation a feature representation of the data relevant for the task to perform and learns how to predict centers, durations and classes of events of interest. The approach is versatile enough to detect any type of events provided some labeled samples are available.</p><p>A major advantage of the proposed approach compared to state-of-the-art baselines is that it can detect multiple events of multiple time scales simultaneously. It could therefore easily be extended to detect other types of events in other modalities or concurrent signals (for example sleep disordered breathing events on breathing channels or Periodic Leg Movements during sleep on leg EMGs), provided labeled events are available. This work also raises interesting technical issues that are essential to a successful application of this algorithm, such as the importance of including an heterogeneous set of clinical PSGs of different origins, having sufficient data available for training, the importance of correct labeling and of defining optimal duration for default events.</p><p>Impact of clinical population and labeling errors. The importance of datasets and of proper labeling is best illustated by the significant gap in performances observed between SS2 and SSC / WSC datasets in detecting spindles using all considered methods (see also <ref type="figure" target="#fig_18">Figure 14</ref> in Appendix). One factor that may explain the differences in performance is related to the saliency of the frequency content inside the 11 − 16 Hz band. Indeed, power spectrum in this band is much higher for SS2 than SSC / WSC, see <ref type="figure">Figure 3</ref> -E. The frequency difference might be due to population differences between SS2 and SSC / WSC datasets. Indeed, subjects in SSC / WSC are older, and it is known that age affects spindle frequency, duration, density and amplitude <ref type="bibr" target="#b4">[4]</ref>. These age dependent changes may make spindle detection harder for experts and for algorithms. It also illustrates the need to test performance for any new method on multiple datasets.</p><p>Another likely factor that affects performance across datasets is quality of experts annotations. Indeed, some scorers using the SSC and WSC data were unable to precisely mark start and end times of events (up to a 0.5 s precision) due to PSG viewer limitations. Annotations can depend on guidelines given to scorers, their interpretations, and other technical issues such as the viewer used <ref type="bibr" target="#b2">[3]</ref>. Taking the union of scorers annotations allowed us to partially cope with this problem but not entirely. Indeed, there is no strong guarantees that a consensus strategy will improve annotations quality. Besides, a higher consensus level leads to fewer annotated events making it harder to train using the proposed approach (see <ref type="figure">Figure 4</ref>). One possible strategy to improve on this issue could be to use a larger number N s of scorers, as previously performed <ref type="bibr" target="#b2">[3]</ref>, and selecting only the K ∈ N best scorers depending on overall performances compared to a consensus of N s − 1 scorers.</p><p>Quantity of available data for training. More data can mean different things. It can mean more PSG recordings or more channels, for example with more modalities than just EEG. To address the question of the impact of the number of PSGs, we computed learning curves which present the prediction performance as a function of the number of training samples ( <ref type="figure" target="#fig_15">Figure 10)</ref>. Surprisingly, this analysis shows that training with the proposed approach to detect spindles or K-complexes on just 1 PSG already leads to decent performances on SS2. This result is likely explained by the sampling strategy used in the training process. During training, windows are sampled at random time in the PSG recording. This process is thus unlikely to input twice the exact same signal to the network while training, hence limiting the risk of over-fitting. <ref type="figure" target="#fig_15">Figures 10 -B</ref> / C also demonstrate that the proposed approach benefits significantly more from the availability of additional PSGs for SSC and WSC. This suggests that the learning task is more difficult on these two datasets. This can be explained, as already discussed above, by the clinical nature of the population and annotations present in these two datasets. A similar comment applies to the detection of arousals, as F1 score at IoU = 0.3 increases as a function of the number of training PSG recordings, and reaches a smaller increase pace from 100 training PSGs in <ref type="figure">Figure 11</ref> -B.</p><p>Regarding the quantity of spatial information, using multiple EEG and EOG channels for arousals detection delivers a significant gain of performance. This demonstrates that increasing the number of channels can compensate for a potential lack of training PSG recordings (see <ref type="figure">Figure 11</ref> -B). Investigating the joint processing of multiple modalities, such as electro-myography, breathing, or pulse-oxymetry signals remains to be done for event detection, although one can expect an increase in performance <ref type="bibr" target="#b26">[26,</ref><ref type="bibr" target="#b35">35,</ref><ref type="bibr" target="#b36">36]</ref>. In particular, such a perspective might prove successful to detect specific types of events occurring through multiple modalities like sleep-apnea.</p><p>Impact of default event duration and joint detection of multiple events with variable durations. The parameterization of default events is a crucial step of the proposed approach. While the parameterization of default events for spindles and K-complexes detection was quite straightforward because these events exhibit a 1 s averaged duration, experiments on arousals detection show that default duration and overlap factor must be carefully selected. Indeed, bad parameterization compromises training, as some true events are never matched during training and are thus never used to train the network localization and prediction modules. This reduces the effective number of samples considered for training and makes recognition of such events more difficult. The selection of a good default duration is a crucial first step when investigating the use of the proposed approach for a new type of event. A good heuristic though is to set the duration of default events to the averaged duration of events in the training set. Of note, detecting jointly multiple events is possible with the proposed model as demonstrated by <ref type="figure" target="#fig_10">Figure 8</ref>. However it shall be stressed that in this experiment, we explored the joint detection of spindles and K-complexes, features which exhibit about the same durations. To detect events of different durations, e.g. spindles and arousals for example, one would need to parameterize default events of multiple scales which was not investigated in this work.</p><p>The influence of the model architecture and of balanced sampling on performance. The proposed approach exhibits a VGG-like architecture <ref type="bibr" target="#b37">[37]</ref>, where for each convolution block, the number of feature maps is multiplied by 2 while the temporal resolution is divided by 2. Such a choice enables to extract relevant features for the considered tasks, although more complex architectures remain to be investigated. The proposed approach exhibits much higher performances than our earlier work <ref type="bibr" target="#b25">[25]</ref>. This stems from two major changes.</p><p>The first major change is related to the network architecture. The implementation of prediction modules in this work differs from the one embraced in our previous work <ref type="bibr" target="#b25">[25]</ref> as we have opted for predicting locations and classes of default events from the whole feature maps returned by φ T . This choice had three positive impacts: <ref type="bibr" target="#b0">(1)</ref> it boosted the detection performances of K-complexes and (2) it allowed for a simpler parameterization of defaults events, making them independent of the size of the feature maps returned by φ T , also allowing to freely choose numbers, durations and overlaps of defaults events to use. Finally, (3) it also allowed to predict a wide range of events durations: 1 s spindles as well as 10 s arousals with the same architecture -provided one took care of the parameterization of default events as mentioned above. Our previous approach was predicting potential events by processing 3 consecutive time steps of the feature maps returned by φ T which may not give access to a sufficiently large temporal context for the prediction of long events like arousals.</p><p>The second change is the use of a balanced sampling strategy during training. The current approach, training batches are composed of 50% of samples containing no event of interest. This led to a significant increase in performance for the detection of K-complexes (see <ref type="figure" target="#fig_12">Figure 9</ref>). It also contributed to a reduction of false positives predicted in N3 sleep, which resulted in a boost of F1 score.</p><p>Comparison with YOLO and SSD and Perspectives. Our algorithm is inspired by both the SSD <ref type="bibr" target="#b22">[22]</ref> and YOLO approaches <ref type="bibr" target="#b23">[23]</ref>. Similarities between our work and these approaches include the fact that we employ an SSD loss function which is a combination of a smooth L1 loss and a classification loss. Furthermore, the same matching strategy as SSD is used during training. Finally, the prediction module ψ makes predictions from the whole feature map returned by the feature extractor φ T (φ C ). This is similar to YOLO. To that end, the proposed approach relies on a grid of default events independent of the temporal size of this latter features maps. This allows for more flexibility in the definition of default event.</p><p>Our proposed approach howewer also differs from SSD and YOLO because it predicts on large objects, such as a 10 h PSG containing mostly no events. The approach was thus further developed to processes chunks of signals and trained both on samples containing true events and on samples containing no event of interest (see balanced sampling strategy discussed above).</p><p>The proposed approach could be extended into several directions. First, the model actually predicts from a single level of feature maps. Exploiting several levels of feature maps containing multiple temporal resolutions and associated with several scales of default events as performed by SSD <ref type="bibr" target="#b22">[22]</ref>, or more recent approaches such as Feature Pyramid Networks <ref type="bibr" target="#b20">[20]</ref> or RetinaNet <ref type="bibr" target="#b21">[21]</ref> could be considered. This would likely boost detection performances by leveraging detection of events which exhibit a wide range of durations (from 1 s to possibly several minutes events), this being espacially useful in the context of full PSG automatic scoring of both macro and microarchitectural events.</p><p>Second, exploiting more complex prediction modules, combining several convolution layers and non-linearities, could enhance detection performances <ref type="bibr" target="#b21">[21,</ref><ref type="bibr" target="#b20">20]</ref>. Third, minimizing a different loss function like Focal Loss <ref type="bibr" target="#b21">[21]</ref> should also be considered as a direction of investigation. Finally, events of interests such as spindles might exhibit specific temporal dynamic patterns, with the likelihood of a spindle occurring in a sample being related to the occurrence of spindles in a previous sample. Integrating a temporal context using a recurrent neural network as performed for EEG processing <ref type="bibr" target="#b38">[38]</ref> or for sleep stage classification <ref type="bibr" target="#b39">[39,</ref><ref type="bibr" target="#b40">40,</ref><ref type="bibr" target="#b41">41,</ref><ref type="bibr" target="#b5">5,</ref><ref type="bibr" target="#b42">42]</ref> might enhance detection performance for some events. In all cases, however, the proposed approach has the considerable advantage of simultaneous multi-event detection, a crucial feature that should allow to build more easily additional event detection methods on the same architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Benchmark spindles -learning losses</head><p>In this paragraph, we investigate further the performances obtained by the proposed approach on the spindles detection task, over the 3 considered dataset: SS2, SSC and WSC. We demonstrate that the spindle detection task is easier for the proposed approach on SS2 compared to SSC and WSC. We report in <ref type="figure" target="#fig_17">Figure 13</ref> the F1 scores at IoU = 0.3 and the standard deviations in scores obtained by each method. In <ref type="figure" target="#fig_18">Figure 14</ref> The detection scores reached by the proposed approach exhibit large differences between the 3 considered datasets: the averaged scores are higher on SS2 than on SSC and WSC, and the standard deviations are smaller.</p><p>The fact that the state-of-the-art baselines suffer also some decreases in their detection performances suggests that the spindles detection task is more difficult on SSC and WSC than on SS2.</p><p>The classification and localization losses during training agree with this assumption. Indeed, the classification and localization losses exhibited by the proposed approach on SS2 reach much lower asymptotic values than on SSC or WSC. This indicates that the events are much easier to identify and localize on SS2 than on SSC or WSC. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>For</head><label></label><figDesc>Lacher-Piza et al. 2018, the code provided by the authors came as a stand-alone software allowing neither retraining of the underlying detector nor hyper-parameter tuning. We therefore asked for Lachner-Piza et al. 2018 ' detector to perform well across unknown datasets without hyper-parameter selection, a more difficult task referred to as inter dataset generalization. This likely led to lower performances than the ones this approach could potentially deliver if training and hyper-parameters tuning had been possible.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>F</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>2</head><label></label><figDesc>Lajnef et al. 2017 : https://github.com/TarekLaj/SPINKY, Parekh et al. 2017 : https://github.com/aparek/mcsleep, Lachner-Piza et al. 2018 : https://github.com/mossdet/Mossdet</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>F1Figure 2 :</head><label>2</label><figDesc>in Appendix. This observation is made, although the statistics about the datasets are quite similar, especially regarding the quantity of training Spindle detection: general benchmark on 3 different datasets: SS2, SSC and WSC. First row: averaged precision / recall at IoU = 0.3. Second row: F1 score as a function of IoU. Standard deviation at each IoU are provided as errorbars. The proposed approach outperforms the 3 alternative methods on each metric (Precision, recall and F1 score).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 -Figure 3 :</head><label>33</label><figDesc>E. This might explain the lower performances obtained on SSC and WSC compared to the ones obtained on SS2. Statistics about spindles over the different datasets: the datasets contain comparable amounts of labeled events, yet the frequency content corresponding to spindles 11 − 16 Hz is more salient on SS2 than on SSC / WSC. A: total number of spindles. B: averaged number of spindles per PSG recording. C: averaged numbers of events used for training and validation. D: averaged durations of events. E: normalized spectrum of 2 s of signal centered on spindles. This is actually the spectrum averaged over all the spindles annotated on a dataset. The normalization is obtained by dividing the power of each frequency bin by the total power between [0, Fs/2]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :Figure 5 :</head><label>45</label><figDesc>Statistics about spindles on SSC and WSC as functions of the consensus level: the consensus level influences greatly the number and the duration of the events annotated by the consensus of scorers. A: total number of spindles. B: averaged number of spindles per PSG recording. C: averaged numbers of events used for training. D: averaged numbers of events used for validation Benchmark on spindles detection as a function of the consensus levels used for training and testing on WSC and SSC: the F1 score at IoU = 0.3 is greatly impacted by both the consensus level used for training and the consensus level used for testing consensus level equal to the training one. This might be explained by the fact that the quality of annotated events for training and testing are similar.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>K-complexes detection: the proposed approach outperforms the alternative approach<ref type="bibr" target="#b15">[15]</ref>. A: Precision / Recall at IoU = 0.3. B: F1 score as a function of IoU.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Statistics about K-complexes on MASS SS2. A: total number of events. B: averaged number of events per PSG recording. C: averaged numbers of events used for training and validation. D: averaged duration of events.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 8 :</head><label>8</label><figDesc>Joint spindles and K-complexes detection: learning to detect both events jointly or separately leads to the same performances.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>0.0 0.2 0.4 0.6 0.8 1.0 Proportion of samples containing a true event in training batches 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 9 :</head><label>9</label><figDesc>Influence of batch sampling on detection performances: using batches only composed of samples containing a true event leads</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>, 2, 4, 6, 8, 10, SSC: 1, 2, 4, 6, 8, 10, 15, WSC: 1, 2, 4, 6, 8, 10, 15, 20) in Figure 10. While computing these so-called learning curves, the number of validation PSGs was kept fixed for each dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 10 :</head><label>10</label><figDesc>Learning curves on SS2, SSC and WSC: more training PSG recordings leads to higher detection performances especially on SSC and WSC. A: SS2 -training separately. B: SSC. C: WSC. D: numbers of training events as a function of numbers of training PSGs for each dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 12 .Figure 11 :Figure 12 :</head><label>121112</label><figDesc>Three observations can be made from the reported results. First, scaling the duration of default events onto the averaged duration of true events leads to the best performances, seeFig 11 -A. This strategy shall be considered as Application of the proposed approach on arousals detection: the parameterization of default events appears as important as the quantity of training data or the quantity of spatial information. A: F1 score at IoU = 0.3 as a function of default event duration. B: F1 score at IoU = 0.3 as a function of the quantity of training PSG recordings and the number of channels Statistics about arousals in the 1000 PSG recordings from MESA used for this detection task. A: total number of annotated events in the 1000 PSGs. B: averaged number of events per record. C: distribution of events durations the preliminary step when investigating the detection of new types of events with the proposed approach. Second,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 13 :</head><label>13</label><figDesc>, we present the classification and the localization losses (on the training and the validation sets) during the learning for the first split over each dataset. Averaged F1 scores at IoU = 0.3 and standard deviations: on SSC and WSC the proposed approach exhibits lower detection performances and larger standard deviations</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 14 :</head><label>14</label><figDesc>Classification and localization losses for spindles detection, on training and validation sets, over the first split of crossvalidation for each dataset: the losses agree with the assumption that the spindles detection task is easier on SS2 than on SSC / WSC</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Montreal Archives of Sleep Studies dataset. The publicly available dataset Montreal Archives of Sleep Studiessession 2 (MASS SS2)<ref type="bibr" target="#b29">[29]</ref> was used. This dataset contains 19 polysomnography (PSG) recordings (11 females, 8 males, 23.6 ± 3.7 years old). These were sampled at 256 Hz. Spindles and K-complexes have been manually annotated by a first expert (E1) over 19 PSGs, and spindles have been annotated by a second expert (E2) over 15PSGs using different guidelines<ref type="bibr" target="#b15">[15]</ref>. All annotations have been performed over the EEG channel C3. In this work, only annotations produced by scorer E1 and data from channel C3 were used.Stanford Sleep Cohort dataset. The second dataset includes 26 PSGs from the patient-based Stanford Sleep Cohort (SSC), see [30] for a description of this dataset. These PSGs are from 26 subjects (9 females, 17 males, 52.2 ± 14.3 years old) and were sampled at 128 Hz. For each PSG recording, spindles have been scored by 5 different sleep experts through visual investigation of central channels. Experts were randomly selected from a pool of 9 scorers. For each PSG recording, annotations made by 5 experts were merged to build a consensus. To do so, annotations of each expert j were first encoded as binary vectors y j ∈ {0, 1} T containing as many time steps T as in the considered PSG recording. A time step i was considered as a spindle, y j [i] = 1, if it belonged to a spindle annotated by the expert j, otherwise it was considered as background signal and y j [i] = 0. The binary vectors corresponding to the five annotations were then averaged to build a vectorȳ ∈ [0, 1] T , taking values in {0, 0.2, 0.4, 0.6, 0.8, 1}. The consensus annotations were obtained by thresholding the vectorȳ to get a binary vector. Let κ ∈ [0, 1] stand for the desired level of consensus. The binary vector y κ ∈ {0, 1} T was built as follows. Start times and durations for all events were then estimated from y κ . Unless otherwise mentioned, we used the consensus κ = 0.2 (union of scorers) annotations from channel C4 (C3 if C4 not available), using as reference the mastoid electrode. Wisconsin Sleep Cohort dataset. Third, 30 PSG recordings from 30 subjects of the Wisconsin Sleep Cohort (WSC), were considered [31] (16 females, 14 males, 65.2 ± 8.2 years old). The PSGs were sampled at 200 Hz. Similarly toSSC, each PSG was scored by 5 different sleep experts from the same pool of 9 possible scorers. All experts followed the same scoring guidelines. Unless otherwise mentioned, we used consensus κ = 0.2 (union of scorers) annotations on signals from channel C4 (C3 if C4 not available), using as reference the mastoid electrode.One reason for using a consensus vector on SSC and WSC is the quality of some annotations. Indeed some annotations are questionable as certain experts were only able to annotate start times and durations up to a 0.5 s precision.MESA dataset. A fourth dataset, publicly available, was finally used: MESA<ref type="bibr" target="#b32">[32]</ref>. 1000 PSG recordings from 1000 subjects (528 females, 472 males, 69.3 ± 9.0 years old) originally sampled at 256 Hz were used for the experiments.The signals from the 3 EEG channels (Fz-Cz, Cz-Oz, C4), and the 2 EOG channels (EOG left and right) were considered in this work. MESA dataset was used to study the detection of arousals which have been annotated based on visual investigation of C4 channel.</figDesc><table><row><cell>y κ [i] =</cell><cell> </cell><cell>1 ifȳ ≥ κ</cell><cell>∀i ∈ T</cell></row><row><cell></cell><cell></cell><cell>0 otherwise</cell><cell></cell></row></table><note>3.2. Evaluation methodology Cross-validation. A 5 split cross-validation was used on SS2, SSC and WSC. On SS2, a split stands for 10 training, 5 validation and 4 testing PSG recordings. On SSC, a split corresponds to 15 training, 5 validation and 6 testing PSGs. For WSC, a split stands for 19 training, 5 validation and 6 testing PSGs. On MESA, a single split was performed, using 400 PSGs for training, 100 for validation and 500 for testing. Cross-validation details are summarized in</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Hyper-parameters of Parekh et al. 2017, λ 3 and threshold were searched over {10, 20, 30, 40, 50} × {0.5, 1, 1.5, 2, 2.5, 3}. Threshold parameter of Lajnef et al. 2017 was selected in {0, 25, . . . , 250} for spindles detection and in {−100, −95, −90, . . . , 0} for K-complexes detection.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>Datasets properties and training parameters we considered per dataset. Fs is the sampling frequency of the given dataset.</note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported in part by the french Association Nationale de la Recherche et de la Technologie </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Sleep, its regulation and possible mechanisms of sleep disturbances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Porkka-Heiskanen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Zitting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">K</forename><surname>Wigren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Physiologica</title>
		<imprint>
			<biblScope unit="volume">208</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="311" to="328" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">The AASM Manual for the Scoring of Sleep and Associated Events: Rules, Terminology and Technical Specifications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Iber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ancoli-Israel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chesson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">F</forename><surname>Quan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>American Academy of Sleep Medicine</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Warby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Wendt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">G S</forename><surname>Munk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Carrillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">B D</forename><surname>Sorensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Jennum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Sleep spindle detection: crowdsourcing and evaluating performance of experts, non-experts, and automated methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Peppard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mignot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature methods</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="385" to="392" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Characterizing sleep spindles in 11,630 individuals from the National Sleep Research Resource</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Purcell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Manoach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Demanuele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">E</forename><surname>Cade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mariani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Panagiotaropoulou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Q</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Smoller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Redline</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Stickgold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">15930</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Stephansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ambati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Leary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">E</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Carrillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hogl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Stefani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pizza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Plazzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Antelmi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Perrin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Kuna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Schweitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kushida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Peppard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Jennum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">B D</forename><surname>Sørensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Mignot</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.02094</idno>
		<title level="m">The use of neural networks in the analysis of sleep stages and the diagnosis of narcolepsy</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Reduced sleep spindles in schizophrenia: A treatable endophenotype that links risk genes to impaired cognition?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Manoach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Q</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Purcell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Stickgold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological psychiatry</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="599" to="608" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">S</forename><surname>Musiek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">D</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Holtzman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sleep, circadian rhythms, and the pathogenesis of Alzheimer Disease</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Expert and crowd-sourced validation of an individualized sleep spindle detection method employing complex demodulation and individualized normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">B</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sockeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Soon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Myhr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Stojanoski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cusack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Owen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Doyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Fogel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Human Neuroscience</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">507</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Reduced sleep spindles and spindle coherence in schizophrenia: Mechanisms of impaired memory consolidation?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Wamsley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Shinn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">E</forename><surname>Ono</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Mckinley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V</forename><surname>Ely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Goff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Stickgold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Manoach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological psychiatry</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="154" to="161" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Validation of a novel automatic sleep spindle detector with high performance during sleep in middle aged subjects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Wendt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A E</forename><surname>Christensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kempfner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">L</forename><surname>Leonthin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Jennum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">B D</forename><surname>Sorensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE EMBC</title>
		<meeting>IEEE EMBC</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="4250" to="4253" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Fast and Slow Spindles during the Sleep Slow Oscillation: Disparate Coalescence and Engagement in Memory Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mölle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">O</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Marshall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Born</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sleep</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1411" to="1421" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Nir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Staba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Andrillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vyazovskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cirelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Fried</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tononi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Regional Slow Waves and Spindles in Human Sleep</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="153" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Reduced sleep spindle activity in schizophrenia patients</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ferrarelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Massimini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Riedner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Watson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tononi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am J Psychiatry</title>
		<imprint>
			<biblScope unit="volume">164</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="483" to="492" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multichannel sleep spindle detection using sparse low-rank optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Parekh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">W</forename><surname>Selesnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Osorio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W</forename><surname>Varga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Rapoport</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Ayappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci. Methods</title>
		<imprint>
			<biblScope unit="volume">288</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">An Open-Source Spindle and K-Complex Detection Toolbox Validated on the Open-Access Montreal Archive of Sleep Studies (MASS)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lajnef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>O&amp;apos;reilly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Combrisson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chaibi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-B</forename><surname>Eichenlaub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Ruby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-E</forename><surname>Aguera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Samet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kachouri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Frenette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carrier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Jerbi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meet</forename><surname>Spinky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Neuroinformatics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">15</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Detection of K-complexes and sleep spindles (DETOKS) using sparse optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Parekh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">W</forename><surname>Selesnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Rapoport</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Ayappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci. Methods</title>
		<imprint>
			<biblScope unit="volume">251</biblScope>
			<biblScope unit="page" from="37" to="46" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Sleep spindle detection using multivariate gaussian mixture models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Patti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Penzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cvetkovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Sleep Research</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">12614</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A single channel sleep-spindle detector based on multivariate classification of EEG epochs: MUSSDET</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lachner-Piza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Epitashvili</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Schulze-Bonhage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Stieglitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dümpelmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci. Methods</title>
		<imprint>
			<biblScope unit="volume">297</biblScope>
			<biblScope unit="page" from="31" to="43" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Application of random forest classifier for automatic sleep spindle detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Patti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Shahrbabaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dissanayaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cvetkovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE Biomedical Circuits and Systems Conference (BioCAS)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Feature pyramid networks for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.02002</idno>
		<title level="m">Focal loss for dense object detection</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.02325</idno>
		<title level="m">SSD: single shot multibox detector</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">You Only Look Once: Unified, Real-Time Object Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Divvala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="779" to="788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R-Cnn</forename><surname>Faster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chambon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Thorey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Arnal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Mignot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Workshop on Machine Learning for Signal Processing</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A Deep Learning Architecture for Temporal Sleep Stage Classification Using Multivariate and Multimodal Time Series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chambon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Galtier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Arnal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wainrib</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Neural Syst Rehabil Eng</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="758" to="769" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Rectified Linear Units Improve Restricted Boltzmann Machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="807" to="814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Montreal archive of sleep studies: an open-access resource for instrument benchmarking and exploratory research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>O&amp;apos;reilly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gosselin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carrier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nielsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Sleep Research</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="628" to="635" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Nocturnal Rapid Eye Movement Sleep Latency for Identifying Patients With Narcolepsy/Hypocretin Deficiency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Andlauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jouhier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Drake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Peppard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-C</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Poli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Plazzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>O&amp;apos;hara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Haffen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Mignot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAMA neurology</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="891" to="902" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Peppard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Szklo-Coxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">J</forename><surname>Nieto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Stubbs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Hla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sleep Disordered Breathing and Mortality: Eighteen-Year Follow-up of the Wisconsin Sleep Cohort</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="1071" to="1078" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Scaling up scientific discovery in sleep medicine: The national sleep research resource</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rueschman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Sahoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">P</forename><surname>Jayapandian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Morrical</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Surovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Redline</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sleep</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1151" to="1164" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Automatic differentiation in PyTorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deep</forename><surname>Learning</surname></persName>
		</author>
		<ptr target="http://www.deeplearningbook.org" />
		<imprint>
			<date type="published" when="2016" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Olesen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Jennum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Peppard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Mignot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">B D</forename><surname>Sorensen</surname></persName>
		</author>
		<title level="m">Deep residual networks for automatic sleep stage classification of raw polysomnographic waveforms</title>
		<editor>proc. EMBC</editor>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Andreotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cooray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T M</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">De</forename><surname>Vos</surname></persName>
		</author>
		<title level="m">Multichannel Sleep Stage Classification and Transfer Learning using Convolutional Neural Networks</title>
		<imprint>
			<publisher>EMBC</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<title level="m">Very deep convolutional networks for large-scale image recognition</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bashivan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Rish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yeasin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Codella</surname></persName>
		</author>
		<title level="m">Learning Representations from EEG with Deep Recurrent-Convolutional Neural Networks, ICLR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Supratak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.06421v11.arXiv:1610.06421</idno>
		<title level="m">Mixed Neural Network Approach for Temporal Sleep Stage Classification</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">DeepSleepNet: a model for automatic sleep stage scoring based on raw single-channel EEG</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Supratak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Neural Syst Rehabil Eng</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Andreotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cooray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">Y</forename><surname>Chén</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">De</forename><surname>Vos</surname></persName>
		</author>
		<title level="m">Automatic Sleep Stage Classification Using Single-Channel EEG: Learning Sequential Features with Attention-Based Recurrent Neural Networks, in: Int. Conf. of the IEEE Engineering in Medicine and Biology Society</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Andreotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cooray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">De</forename><surname>Vos</surname></persName>
		</author>
		<idno>ArXiv:1809.10932</idno>
		<title level="m">SeqSleepNet: End-to-End Hierarchical Recurrent Neural Network for Sequence-to-Sequence Automatic Sleep Staging</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
