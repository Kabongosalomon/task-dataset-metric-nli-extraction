<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Noisy Differentiable Architecture Search</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chu</forename><surname>Xiangxiang</surname></persName>
							<email>chuxiangxiang@xiaomi.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">I</forename><surname>Xiaomi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lab</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhang</surname></persName>
							<email>zhangbo11@xiaomi.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Li</surname></persName>
							<email>lixudong16@mails.ucas.edu.cn</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Xiaomi AI Lab</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Academy of Sciences</orgName>
								<orgName type="institution">University of Chinese</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Noisy Differentiable Architecture Search</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T22:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Simplicity is the ultimate sophistication. Differentiable Architecture Search (DARTS) has now become one of the mainstream paradigms of neural architecture search. However, it largely suffers from several disturbing factors of the optimization process whose results are unstable to reproduce. <ref type="bibr" target="#b0">Chu et al. [2019a]</ref> point out that skip connections natively have an unfair advantage in exclusive competition which primarily leads to dramatic performance collapse. While Fair-DARTS <ref type="bibr" target="#b0">(Chu et al. [2019a]</ref>) turns the unfair competition into a collaborative one, we instead impede such unfair advantage by injecting unbiased random noise into skip operations' output. In effect, the optimizer should perceive this difficulty at each training step and refrain from overshooting on skip connections, but in a long run, it still converges to the right solution area since no bias is added to the gradient in terms of expectation. We name this novel approach as NoisyDARTS. Our experiments on CIFAR-10 and ImageNet attest that it can effectively break the skip connections' unfair advantage and yield better performance. It generates a series of models that achieve state-of-the-art results on both datasets. Code will be made available here 2 . * Work done as an intern. † Equal Contribution.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Performance collapse from an excessive number of skip connections in the inferred model is a fatal drawback for the differentiable architecture search approaches , <ref type="bibr" target="#b2">Chen et al. [2019a]</ref>, <ref type="bibr">Zela et al. [2020]</ref>, <ref type="bibr" target="#b0">Chu et al. [2019a]</ref>). Quite an amount of previous research has focused on addressing this issue. FairDARTS <ref type="bibr" target="#b0">(Chu et al. [2019a]</ref>) concludes the cause of this collapse to be an unfair advantage in an exclusively competitive environment. Under this perspective, they summarize several current effective approaches as different ways of avoiding the unfair advantage. Inspired by their empirical observations, we adopt quite a different and straightforward approach by injecting unbiased noise to skip connections' output. The underlying philosophy is simple: the injected noise would bring perturbations into the gradient flow via skip connections so that its unfair advantage doesn't comfortably take effect.</p><p>Our contributions can be summarized in the following aspects.</p><p>• We propose a simple but effective approach to address the performance collapse issue in the differentiable architecture search: injecting noise into the gradient flow of skip connections.</p><p>• We dive into the requirements of the desired noise, which should be of small variance as well as unbiased for the gradient flow in terms of expectation. Particularly, we found that Gaussian noise with zero mean and small variance is a handy solution.</p><p>• Our research corroborates the root cause analysis of performance collapse in FairDARTS <ref type="bibr" target="#b0">(Chu et al. [2019a]</ref>) since suppressing the unfairness from skip connections does generate substantial results.</p><p>• We performed extensive experiments on two widely used search spaces and two standard datasets to verify the effectiveness and robustness of the proposed approach. With efficient search, we achieve state-of-the-art results on both CIFAR-10 (97.61%) and ImageNet (77.9%). Good transferability is also verified on object detection tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Performance collapse in DARTS. The notorious performance collapse of DARTS is unanimously confirmed by many <ref type="bibr" target="#b2">(Chen et al. [2019a]</ref>, <ref type="bibr">Zela et al. [2020]</ref>, <ref type="bibr" target="#b0">Chu et al. [2019a]</ref>). To remedy this failure, <ref type="bibr" target="#b2">Chen et al. [2019a]</ref> carefully set a hard constraint to limit the number of skip connections. This is a strong prior since architectures within this regularized search space generally perform well, as indicated by <ref type="bibr" target="#b0">Chu et al. [2019a]</ref>. Meantime, <ref type="bibr">Zela et al. [2020]</ref> devised several search spaces to prove that DARTS leads to degenerate models where skip connections are dominant. To robustify the searching process, they proposed to monitor the sharpness of validation loss curvature, which correlates with the induced model's performance. This, however, adds too much extra computation, as it needs to calculate the eigenspectrum of the Hessian matrix. <ref type="bibr" target="#b0">Chu et al. [2019a]</ref> instead relaxes the search space to avoid exclusive competition. They allow each operation to have independent architecture weight by using sigmoid to mimic a multi-hot encoding other than the original softmax for a one-hot encoding. This modification enlarges the search space as it allows multiple choices between every two nodes, whereas the intrinsic collapse in the original DARTS search space still calls for a better solution.</p><p>Noise tricks. Noise injection is a common and effective trick in many deep learning scenarios. <ref type="bibr" target="#b4">Vincent et al. [2008]</ref> add noises into auto-encoders to extract robust features. <ref type="bibr" target="#b5">Fortunato et al. [2018]</ref> propose NoisyNet which utilizes random noise to perform exploration in reinforcement learning. <ref type="bibr" target="#b6">Chen et al. [2015]</ref> make use of noises to handle network expansion on knowledge transfer tasks. Meanwhile, Injecting noise to gradients has been proved to greatly facilitate the training of deep neural networks <ref type="bibr" target="#b7">(Neelakantan et al. [2015]</ref>, ). Most recently, a noisy student is also devised to progressively manipulate unlabelled data ).</p><p>3 Noisy DARTS</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Motivation</head><p>FairDARTS <ref type="bibr" target="#b0">(Chu et al. [2019a]</ref>) proves that skip connections usually overperform during searching under the competitive environment, resulting in a degenerate model where they contribute less. In view of this, <ref type="bibr" target="#b0">Chu et al. [2019a]</ref> convert the competition into collaboration by giving each operation an independent coefficient (applying sigmoid instead of softmax over architectural parameter α) so that each α obtains gain not at the cost of suppressing others, but profiting from the collaborative work according to its proper share. Enlightened by their perspective, we propose a more natural approach to suppress skip connection from overshooting. Straightforwardly, injecting noise into the skip connection operations would simply do. The added noise will play a role of troubling the overwhelming gradient flow via skip connections so that the unfair advantage is directly weakened. The remaining problem, however, is to study what type of noise will be more effective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Requirements for the Injected Noise</head><p>We letx be the noise injected into the skip operation, and α skip be the corresponding architectural weight. The loss of skip operation can then be written as,</p><formula xml:id="formula_0">L = g(y), y = f (α skip ) · (x +x)<label>(1)</label></formula><p>where g(y) is the validation loss function and f (α skip ) is the softmax operation for α skip . Approximately, when the noise is much smaller than the output features, we also have</p><formula xml:id="formula_1">y ≈ f (α) · x whenx x.</formula><p>(2)</p><p>In the noisy scenario, the gradient of the architectural parameters via the skip connection operation becomes,</p><formula xml:id="formula_2">∂L ∂α skip = ∂L ∂y ∂y ∂α skip = ∂L ∂y ∂f (α skip ) ∂α skip (x +x) .<label>(3)</label></formula><p>As random noisex brings uncertainty to the gradient update, skip connections have to overcome this difficulty in order to win over other operations. Their unfair advantage is then much weakened. However, not all types of noise are equally effective in this regard. A basic requirement is that, while assuring suppression on the unfair advantage, it shouldn't bring in any bias to the gradient in terms of its expectation. Formally, the expectation of the gradient can be written as,</p><formula xml:id="formula_3">E [∇ skip ] = E ∂L ∂y ∂f (α skip ) ∂α skip (x +x) ≈ ∂L ∂y ∂f (α skip ) ∂α skip (E [x] + E [x]) .<label>(4)</label></formula><p>Based on the premise stated in Equation 2, we take ∂L ∂y out of the expectation in Equation 4 to make an approximation. As there is still an extra E [x] in the gradient of skip connection, to keep the gradient unbiased, E [x] must be 0. It's thus natural to introduce small and unbiased noise, i.e. with zero mean and small variance. For simplicity, we just use Gaussian noise and other options should work as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Stepping out of the Performance Collapse by Noise</head><p>Based on the above analysis, we propose NoisyDARTS to step out of the performance collapse of DARTS. In practice, we inject Gaussian noisex ∼ N (µ, σ) into skip connections to weaken the unfair advantage.</p><p>Formally, the edge e i,j from node i to j in each cell operates on th input feature x i and its output is denoted as o i,j (x i ). The intermediate node j gathers all inputs from the incoming edges:</p><formula xml:id="formula_4">x j = i&lt;j o i,j (x i ) (5) Let O = {o 0 i,j , o 1 i,j , · · · , o M −1 i,j</formula><p>} be the set of M candidate operations on edge e i,j . Specially, let o 0 i,j be the skip connection o skip i,j . NoisyDARTS injects the additive noisex into skip operation o skip i,j to get a mixed output,</p><formula xml:id="formula_5">o i,j (x) = M −1 k=1 f (α o k )o k (x) + f (α o skip )o skip (x +x).<label>(6)</label></formula><p>To ensure the gradient of a skip connection is unbiased and the noisex ∼ N (µ, σ) is small enough, we set µ = 0 and σ = λ · std(x), where λ is a positive coefficient. That is to say, the standard deviation of the noise changes accordingly with a mini-batch of samples x, i.e., λ times that of x. Setting a low λ, we meetx x as required by Equation 2.</p><p>Compared with DARTS, the only modification is injecting the noise into the skip connections. The architecture search problem remains the same as the original DARTS, which is to interleavely learn α * and network weights w * that minimize the validation loss L val (α * , w * ), as shown in Equation <ref type="formula" target="#formula_6">7</ref>.</p><formula xml:id="formula_6">min α L val (α * , w * ) s.t. w * (α) = arg min w L train (w, α)<label>(7)</label></formula><p>The modified optimization process codenamed NoisyDARTS is shown in Algorithm 1. Inject random Gaussian noisex into the skip connections' output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4:</head><p>Update weights w by ∇ w L train (w, α)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>Update architecture parameters α by ∇ α L val (w, α) 6: end while 7: Derive the final architecture according to arg max(α).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Search Space</head><p>To verify the validity of our method, we adopt two widely used search spaces: the DARTS search space  and MobileNetV2's search space as in <ref type="bibr" target="#b10">Cai et al. [2019]</ref>. The former consists of a stack of duplicate normal cells and reduction cells, which are represented by a DAG of 7 nodes with each edge among intermediate nodes having 7 possible operations (max pooling, average pooling, skip connection, separable convolution 3×3 and 5×5, dilation convolution 3×3 and 5×5). The latter comprises 19 layers and each contains 7 choices: inverted bottleneck blocks denoted as Ex_Ky (expansion rate x ∈ {3, 6}, kernel size y ∈ {3, 5, 7}) and a skip connection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Searching on CIFAR-10</head><p>In the search phase, we use similar hyperparameters and tricks as . All experiments are done on a Tesla V100 with PyTorch 1.0 <ref type="bibr" target="#b11">(Paszke et al. [2019]</ref>). The search phase takes about 7 GPU hours, which is less than the previously reported cost (12 GPU hours) due to a better implementation. We only use the first-order approach for optimization since it is more effective. The best models are selected under the noise with a zero mean and λ = 0.2. An example of the evolution of the architectural weights during the search phase is exhibited in <ref type="figure">Figure 1</ref>.</p><p>For training a single model, we use the same strategy and data processing tricks as <ref type="bibr" target="#b2">Chen et al. [2019a]</ref>, , and it takes about 16 GPU hours. The results are shown in <ref type="table" target="#tab_1">Table 1</ref>. The best NoisyDARTS model achieves a new state-of-the-art result of 97.61% with only 534M FLOPS and 3.25M parameters. The searched cells are shown in <ref type="figure">Figure 2</ref> and <ref type="table">Table 7</ref> (supplementary). It's interesting to see that this model chooses as many as 4 skip connections for reduction cells, it still obtains highly competitive result. However, we can attribute it to the elimination of the unfair advantage <ref type="bibr" target="#b0">(Chu et al. [2019a]</ref>). In other words, the unfair advantage is suppressed to a level that the activated skip connections indeed contribute to the performance of the selected model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Searching Proxylessly on ImageNet</head><p>For ImageNet experiments, we use exactly the same space as <ref type="bibr" target="#b10">Cai et al. [2019]</ref>, <ref type="bibr" target="#b19">Chu et al. [2019b]</ref>. In the search phase, the Gaussian noise with zero mean and a variance of 0.2 is injected to the skip connection operations. We split the original training set into two datasets with equal capacity to act as our training and validation dataset. The original validation set is treated as the test set. We use the SGD optimizer with a batch size of 768. The learning rate for the network weights is initialized as 0.045 and it decays to 0 within 30 epochs following the cosine decay strategy. Besides, we utilize Adam optimizer (β 1 = 0.5, β 2 = 0.999) and a constant learning rate of 0.001. This stage takes about 12 GPU days on Tesla V100 machines. In the training phase for inferred standalone models, we use similar training tricks as EfficientNet ). Similar to <ref type="bibr" target="#b21">Liu et al. [ , 2018</ref>, the objective of this experiment is to find the best model without considering other constraints on FLOPS or the number of parameters. The evolution of dominating operations during the search is illustrated in <ref type="figure">Figure 4</ref>. Compared with DARTS, the injected noise in NoisyDARTS successfully eliminates the unfair advantage.</p><p>The ImageNet classification results are shown in <ref type="table" target="#tab_2">Table 2</ref>. Our model NoisyDARTS-A obtains the new state of the art results: 76.1% top-1 accuracy on ImageNet validation dataset with 4.9M number of parameters. After being equipped with more tricks as in EfficientNet, namely, squeeze and excitation  <ref type="figure">Figure 5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Transferring to CIFAR-10</head><p>We transferred our NoisyDARTS-A model searched on ImageNet to CIFAR-10. The model is trained for 200 epochs with a batch size of 256 and a learning rate of 0.05. We set the weight decay to be 0.0, a dropout rate of 0.1 and a drop connect rate of 0.1. In addition, we also use AutoAugment to avoid overfitting. Specifically, the transferred model NoisyDARTS-A-t achieved 98.28% top-1 accuracy with only 447M FLOPS, as shown in <ref type="table" target="#tab_1">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Transferred Results on Object Detection</head><p>We further evaluate the transferability of our searched models on the COCO objection task <ref type="bibr" target="#b32">(Lin et al. [2014]</ref>). Particularly, we utilize a drop-in replacement for the backbone based on the Retina framework <ref type="bibr" target="#b33">(Lin et al. [2017]</ref>). Besides, we use the MMDetection tool box since it provides a good implementation for various detection algorithms <ref type="bibr" target="#b34">(Chen et al. [2019b]</ref>). Following the same training   setting as <ref type="bibr" target="#b33">Lin et al. [2017]</ref>, all models in <ref type="table" target="#tab_3">Table 3</ref> are trained and evaluated on the COCO dataset for 12 epochs. The learning rate is initialized as 0.01 and decayed by 0.1× at epoch 8 and 11. As shown in <ref type="table" target="#tab_3">Table 3</ref>, our model obtains the best transferability than other models under the mobile settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Ablation Study</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.1">With vs Without Noise</head><p>We compare the searched models with and without noises on two commonly used search spaces in <ref type="table" target="#tab_4">Table 4</ref>. NoisyDARTS robustly escape from the performance collapse across different search spaces and datasets. Note that without noise, such differentiable approach performs severely worse and obtains only 66.4% top-1 on the ImageNet classification task. In constract, our simple yet effective method can find a state-of-the-art model with 76.1% top-1 accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.2">Zero-mean (unbiased) Noise vs. Biased Noise</head><p>According to Equation 4, good noise should interfere little with overall gradient flow in terms of global expectation but prevent skip connections from benefiting too much locally. Our ablation experiments confirm this hypothesis, as shown in <ref type="table" target="#tab_5">Table 5</ref>. The searched cells are shown in <ref type="table" target="#tab_7">Table 8</ref> (supplementary). When a non-zero mean noise is injected, it brings in a deterministic bias that  <ref type="table" target="#tab_1">BOTTLE_K3  MBE6_K3  MBE3_K3  MBE6_K5  MBE6_K3  MBE6_K3  MBE6_K3  MBE6_K5  MBE6_K7  MBE6_K3  MBE6_K3  MBE6_K3  MBE6_K3  MBE6_K3  MBE6_K3  MBE6_K3  MBE6_K7  MBE6_K7   224x224x3  112x112x32  112x112x16  56x56x32  28x28x40  56x56x32  28x28x40  28x28x40  28x28x40  14x14x80  14x14x80  14x14x80  14x14x86  14x14x96  14x14x96  14x14x96  14x14x96  7x7x192  7x7x192  7x7x192</ref> MBE6_K7 MBE6_K7 7x7x192 7x7x320</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CONV_K1</head><p>Global_Pooling + FC 7x7x1280 <ref type="figure">Figure 5</ref>: NoisyDARTS-A searched on ImageNet. Colors represent different stages. overshoots the gradient and misguides the whole optimization process. <ref type="figure">Figure 3</ref> visualizes the NoisyDARTS-b cells. According to the analysis of Section 3.2, Gaussian noise is an appropriate choice. It can be unbiased and satisfies Equation 4. In the same vein, unbiased uniform noise should be equally useful. We compare Gaussian noise with uniform noise in terms of searching effectiveness in <ref type="table" target="#tab_6">Table 6</ref>. Both have improved performance while Gaussian is slightly better. We run each group of experiments eight independent times.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.4">Additive Noise vs. Multiplicative Noise</head><p>To further testify that NoisyDARTS is robust regardless of noise mixture, we blend the noise by multiplying it with the output x of skip connection, which should be approximately effective as additive noise. We also give a similar theoretical proof in Section 3.2 that multiplicative noise can tackle with performance collapse, see Appendix A. Experiment results are shown in <ref type="table" target="#tab_6">Table 6</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we proposed a novel differentiable architecture search approach, NoisyDARTS. By injecting unbiased Gaussian noise into skip connections' output, we successfully let the optimization process be perceptible about the disturbed gradient flow. In such a way, the unfair advantage is largely attenuated. Experiments show that NoisyDARTS can work both effectively and robustly. The searched models achieved state-of-the-art results on CIFAR-10 and ImageNet. NoisyDARTS-a and NoisyDARTS-b also confirm that our proposed method can allow many skip connections as long as they do substantially contribute to the performance of the derived model. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Analysis of Multiplicative Noise</head><p>We set the output of skip connection with multiplicative noise isx = x ·x, wherex is sampled from a certain distribution. Similar to Section 3.2, the expectation of the gradient under multiplicative noise can be written as:</p><formula xml:id="formula_7">E [∇ skip ] = E ∂L ∂y ∂f (α skip ) ∂α skip (x) ≈ ∂L ∂y ∂f (α skip ) ∂α skip (E [x] · E [x]) .<label>(8)</label></formula><p>Again notice that taking ∂L ∂y out of the expectation in Equation 8 requires Equation 2 be satisfied. To keep the gradient unbiased,x should be close to 1. We use Gaussian distributionx <ref type="figure">∼ N (1, σ)</ref> with a small σ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B NoisyDARTS Architectures</head><p>Following tables give the genotypes of best models searched under noise of various settings. <ref type="table">Table 7</ref>: Best NoisyDARTS architecture genotypes searched on CIFAR-10 with unbiased noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Architecture Genotype</p><p>NoisyDARTS-a Genotype(normal=[('sep_conv_3x3', 1), ('sep_conv_3x3', 0), ('skip_connect', 0), ('dil_conv_3x3', 2), ('dil_conv_3x3', 3), ('sep_conv_3x3', 1), ('dil_conv_5x5', 4), ('dil_conv_3x3', 3)], nor-mal_concat=range(2, 6), reduce=[('max_pool_3x3', 0), ('dil_conv_5x5', 1), ('skip_connect', 2), ('max_pool_3x3', 0), ('skip_connect', 2), ('skip_connect', 3), ('skip_connect', 2), ('dil_conv_5x5', 4)], re-duce_concat=range(2, 6)) NoisyDARTS-b Genotype(normal=[('sep_conv_3x3', 1), ('sep_conv_3x3', 0), ('skip_connect', 2), ('sep_conv_3x3', 0), ('dil_conv_3x3', 3), ('skip_connect', 0), ('dil_conv_3x3', 3), ('dil_conv_3x3', 4)], nor-mal_concat=range(2, 6), reduce=[('max_pool_3x3', 0), ('skip_connect', 1), ('max_pool_3x3', 0), ('skip_connect', 2), ('skip_connect', 2), ('max_pool_3x3', 0), ('skip_connect', 2), ('avg_pool_3x3', 0)], re-duce_concat=range(2, 6)) Architecture Genotype <ref type="table" target="#tab_1">Table 10</ref>: Best NosiyDARTS architecture genotypes searched on CIFAR-10 with multiplicative noise.</p><p>(µ, λ) Architecture Genotype</p><p>(1.0, 0.1) Genotype(normal=[('sep_conv_3x3', 1), ('sep_conv_3x3', 0), ('skip_connect', 0), ('skip_connect', 2), ('skip_connect', 0), ('dil_conv_3x3', 2), ('dil_conv_3x3', 4), ('dil_conv_5x5', 3)], normal_concat=range(2, 6), reduce=[('max_pool_3x3', 1), ('max_pool_3x3', 0), ('skip_connect', 2), ('max_pool_3x3', 0), ('dil_conv_5x5', 3), ('skip_connect', 2), ('skip_connect', 2), ('skip_connect', 4)], re-duce_concat=range(2, 6)) (1.0, 0.2) Genotype(normal=[('sep_conv_3x3', 1), ('sep_conv_3x3', 0), ('sep_conv_5x5', 1), ('skip_connect', 0), ('dil_conv_3x3', 3), ('sep_conv_3x3', 0), ('dil_conv_5x5', 4), ('skip_connect', 2)], normal_concat=range(2, 6), reduce=[('max_pool_3x3', 0), ('max_pool_3x3', 1), ('skip_connect', 2), ('avg_pool_3x3', 0), ('skip_connect', 3), ('skip_connect', 2), ('skip_connect', 3), ('skip_connect', 2)], re-duce_concat=range(2, 6))</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :Figure 2 :</head><label>12</label><figDesc>Evolution of architectural weights during the NoisyDARTS searching phase on CIFAR-10. Skip connections in normal cells are largely suppressed. NoisyDARTS-a cells searched on CIFAR-10. (Hu et al. [2018]), Swish activation, and AutoAugment (Cubuk et al. [2019]), it obtains 77.9% top-1 accuracy with 5.5M parameters. The searched architecture is shown in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>NoisyDARTS-b cells searched on CIFAR-10 with λ = 0.1. Stacked plot of dominant operations during searching on ImageNet. The inferred model of DARTS (left) obtains 66.4% top-1 accuracy on ImageNet validation dataset. The inferred model of NoisyDARTS (right) obtains 76.1% top-1 accuracy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Algorithm 1 NoisyDARTS-Noisy Differentiable Architecture Search 1: Input: Architecture parameters α i,j , network weights w , noise control parameter λ, Epoch max .</figDesc><table /><note>2: while not reach Epoch max do3:</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Results on CIFAR-10. † : MultAdds computed using the genotypes provided by the authors. : Averaged on training the best model for several times. GD: Gradient-based, TF: Transferred from ImageNet.</figDesc><table><row><cell>Models</cell><cell cols="3">Params (M) ×+ (M) Top-1 (%)</cell><cell>Type</cell></row><row><cell>NASNet-A (Zoph et al. [2018])</cell><cell>3.3</cell><cell>608  †</cell><cell>97.35</cell><cell>RL</cell></row><row><cell>ENAS (Pham et al. [2018])</cell><cell>4.6</cell><cell>626  †</cell><cell>97.11</cell><cell>RL</cell></row><row><cell>MdeNAS (Zheng et al. [2019])</cell><cell>3.6</cell><cell>599  †</cell><cell>97.45</cell><cell>MDL</cell></row><row><cell cols="2">DARTS(first order) (Liu et al. [2019]) 3.3</cell><cell>528  †</cell><cell cols="2">97.00±0.14 GD</cell></row><row><cell>SNAS ( Xie et al. [2019b])</cell><cell>2.8</cell><cell>422  †</cell><cell cols="2">97.15±0.02 GD</cell></row><row><cell>GDAS (Dong and Yang [2019])</cell><cell>3.37</cell><cell>519  †</cell><cell>97.07</cell><cell>GD</cell></row><row><cell>SGAS (Cri.2 avg.) (Li et al. [2019])</cell><cell>3.9</cell><cell>-</cell><cell cols="2">97.33±0.21 GD</cell></row><row><cell>P-DARTS (Chen et al. [2019a])</cell><cell>3.4</cell><cell>532  †</cell><cell>97.5</cell><cell>GD</cell></row><row><cell>PC-DARTS (Xu et al. [2020])</cell><cell>3.6</cell><cell>558  †</cell><cell>97.43</cell><cell>GD</cell></row><row><cell>RDARTS (Zela et al. [2020])</cell><cell>-</cell><cell>-</cell><cell>97.05</cell><cell>GD</cell></row><row><cell>FairDARTS (Chu et al. [2019a])</cell><cell>3.32±0.46</cell><cell cols="3">458±61 97.46±0.05 GD</cell></row><row><cell>NoisyDARTS-a (Ours)</cell><cell>3.25</cell><cell>534</cell><cell>97.61</cell><cell>GD</cell></row><row><cell>NoisyDARTS-b (Ours)</cell><cell>3.01</cell><cell>494</cell><cell>97.53</cell><cell>GD</cell></row><row><cell>NoisyDARTS-A-t (Ours)</cell><cell>4.3</cell><cell>447</cell><cell>98.28</cell><cell>TF</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Classification results on ImageNet. : Based on its published code.</figDesc><table><row><cell>Models</cell><cell cols="4">×+ (M) Params (M) Top-1 (%) Top-5 (%)</cell></row><row><cell cols="2">MobileNetV2(1.4) (Sandler et al. [2018]) 585</cell><cell>6.9</cell><cell>74.7</cell><cell>92.2</cell></row><row><cell>NASNet-A (Zoph et al. [2018])</cell><cell>564</cell><cell>5.3</cell><cell>74.0</cell><cell>91.6</cell></row><row><cell>AmoebaNet-A(Real et al. [2018])</cell><cell>555</cell><cell>5.1</cell><cell>74.5</cell><cell>92.0</cell></row><row><cell>MnasNet-92 (Tan et al. [2019])</cell><cell>388</cell><cell>3.9</cell><cell>74.79</cell><cell>92.1</cell></row><row><cell>MdeNAS(Zheng et al. [2019])</cell><cell>-</cell><cell>6.1</cell><cell>74.5</cell><cell>92.1</cell></row><row><cell>DARTS (Liu et al. [2019])</cell><cell>574</cell><cell>4.7</cell><cell>73.3</cell><cell>91.3</cell></row><row><cell>SNAS (Xie et al. [2019b])</cell><cell>522</cell><cell>4.3</cell><cell>72.7</cell><cell>90.8</cell></row><row><cell>GDAS (Dong and Yang [2019])</cell><cell>581</cell><cell>5.3</cell><cell>74.0</cell><cell>91.5</cell></row><row><cell>PNAS (Liu et al. [2018])</cell><cell>588</cell><cell>5.1</cell><cell>74.2</cell><cell>91.9</cell></row><row><cell>FBNet-C (Wu et al. [2019])</cell><cell>375</cell><cell>5.5</cell><cell>74.9</cell><cell>92.3</cell></row><row><cell>FairNAS-C  ‡ (Chu et al. [2019c])</cell><cell>321</cell><cell>4.4</cell><cell>74.7</cell><cell>92.1</cell></row><row><cell>P-DARTS  † † (Chen et al. [2019a])</cell><cell>577</cell><cell>5.1</cell><cell>74.9  *</cell><cell>92.3  *</cell></row><row><cell>FairDARTS-B (Chu et al. [2019a])</cell><cell>541</cell><cell>4.8</cell><cell>75.1</cell><cell>92.5</cell></row><row><cell>NoisyDARTS-A (Ours)</cell><cell>446</cell><cell>4.9</cell><cell>76.1</cell><cell>93.0</cell></row><row><cell>MobileNetV3 (Howard et al. [2019])</cell><cell>219</cell><cell>5.4</cell><cell>75.2</cell><cell>92.2</cell></row><row><cell>MoGA-A (Chu et al. [2020])</cell><cell>304</cell><cell>5.1</cell><cell>75.9</cell><cell>92.8</cell></row><row><cell>MixNet-M (Tan and Le. [2019])</cell><cell>360</cell><cell>5.0</cell><cell>77.0</cell><cell>93.3</cell></row><row><cell>EfficientNet B0 (Tan and Le [2019])</cell><cell>390</cell><cell>5.3</cell><cell>76.3</cell><cell>93.2</cell></row><row><cell>NoisyDARTS-A (Ours)</cell><cell>449</cell><cell>5.5</cell><cell>77.9</cell><cell>94.0</cell></row></table><note>† : Searched on CIFAR-10.† † : Searched on CIFAR-100.‡ : Searched on ImageNet. : w/ SE and Swish</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Object detection of various drop-in backbones. † : w/ SE and Swish</figDesc><table><row><cell>Backbones</cell><cell cols="2">×+ Acc AP</cell><cell cols="5">AP50 AP75 APS APM APL</cell></row><row><cell></cell><cell>(M) (%)</cell><cell>(%)</cell><cell>(%)</cell><cell>(%)</cell><cell>(%)</cell><cell>(%)</cell><cell>(%)</cell></row><row><cell>MobileNetV2 (Sandler et al. [2018])</cell><cell cols="3">300 72.0 28.3 46.7</cell><cell>29.3</cell><cell cols="2">14.8 30.7</cell><cell>38.1</cell></row><row><cell cols="4">SingPath NAS (Stamoulis et al. [2019]) 365 75.0 30.7 49.8</cell><cell>32.2</cell><cell cols="2">15.4 33.9</cell><cell>41.6</cell></row><row><cell>MnasNet-A2 (Tan et al. [2019])</cell><cell cols="3">340 75.6 30.5 50.2</cell><cell>32.0</cell><cell cols="2">16.6 34.1</cell><cell>41.1</cell></row><row><cell>MobileNetV3 (Howard et al. [2019])</cell><cell cols="3">219 75.2 29.9 49.3</cell><cell>30.8</cell><cell cols="2">14.9 33.3</cell><cell>41.1</cell></row><row><cell>MixNet-M (Tan and Le. [2019])</cell><cell cols="3">360 77.0 31.3 51.7</cell><cell>32.4</cell><cell cols="2">17.0 35.0</cell><cell>41.9</cell></row><row><cell>NoisyDARTS-A (Ours)</cell><cell cols="3">449 77.9 33.1 53.4</cell><cell>34.8</cell><cell cols="2">18.5 36.6</cell><cell>44.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>NoisyDARTS can robustly escape from the performance collapse across different search spaces and datasets.</figDesc><table><row><cell>Type</cell><cell>Dataset</cell><cell>Top-1 (%)</cell></row><row><cell>w/ Noise</cell><cell cols="2">CIFAR-10 97.6</cell></row><row><cell cols="3">w/o Noise CIFAR-10 97.0</cell></row><row><cell>w/ Noise</cell><cell cols="2">ImageNet 76.1</cell></row><row><cell cols="3">w/o Noise ImageNet 66.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Ablation experiments on Gaussian noise of different standard deviations.</figDesc><table><row><cell cols="2">Noise Type µ</cell><cell>λ</cell><cell>Avg. Top-1(%) Best Top-1 (%)</cell></row><row><cell>Gaussian</cell><cell cols="3">0.0 0.1 97.21±0.21</cell><cell>97.53</cell></row><row><cell>Gaussian</cell><cell cols="3">0.5 0.1 97.02±0.21</cell><cell>97.28</cell></row><row><cell>Gaussian</cell><cell cols="3">1.0 0.1 96.89±0.26</cell><cell>97.21</cell></row><row><cell>Gaussian</cell><cell cols="3">0.0 0.2 97.30±0.23</cell><cell>97.61</cell></row><row><cell>Gaussian</cell><cell cols="3">0.5 0.2 97.16±0.15</cell><cell>97.49</cell></row><row><cell>Gaussian</cell><cell cols="3">1.0 0.2 96.82±0.57</cell><cell>97.35</cell></row><row><cell cols="3">4.6.3 Gaussian Noise vs. Uniform Noise</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Ablation experiments on different types of noise and mixing operations. : σ for multiplicative noise.</figDesc><table><row><cell cols="2">Noise Type µ</cell><cell>λ</cell><cell>Avg. Top-1 (%)</cell><cell cols="2">Noise Mixture µ</cell><cell>λ|σ</cell><cell>Top-1 (%)</cell></row><row><cell>Gaussian</cell><cell cols="3">0.0 0.1 97.21±0.21</cell><cell>Additive</cell><cell cols="2">0.0 0.1</cell><cell>97.21±0.21</cell></row><row><cell>Uniform</cell><cell cols="3">0.0 0.1 97.12±0.15</cell><cell cols="3">Multiplicative 1.0 0.1</cell><cell>97.15±0.23</cell></row><row><cell>Gaussian</cell><cell cols="3">0.0 0.2 97.30±0.23</cell><cell>Additive</cell><cell cols="2">0.0 0.2</cell><cell>97.30±0.23</cell></row><row><cell>Uniform</cell><cell cols="3">0.0 0.2 97.15±0.23</cell><cell cols="3">Multiplicative 1.0 0.2</cell><cell>97.22±0.23</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 8 :</head><label>8</label><figDesc>Best NosiyDARTS architecture genotypes searched on CIFAR-10 under biased noise.</figDesc><table><row><cell>(µ, λ)</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Fair darts: Eliminating unfair advantages in differentiable architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangxiang</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianbao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jixiang</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.12126</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">DARTS: Differentiable Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Progressive Differentiable Architecture Search: Bridging the Depth Gap between Search and Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Understanding and robustifying differentiable architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arber</forename><surname>Zela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Elsken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tonmoy</forename><surname>Saikia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yassine</forename><surname>Marrakchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=H1gDNyrKDS" />
	</analytic>
	<monogr>
		<title level="m">ICLR, 2020</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Extracting and composing robust features with denoising autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre-Antoine</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th international conference on Machine learning</title>
		<meeting>the 25th international conference on Machine learning</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1096" to="1103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Noisy networks for exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meire</forename><surname>Fortunato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">Gheshlaghi</forename><surname>Azar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bilal</forename><surname>Piot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Menick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matteo</forename><surname>Hessel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Osband</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volodymyr</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remi</forename><surname>Munos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Demis</forename><surname>Hassabis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Pietquin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shane</forename><surname>Legg</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=rywHCPkAW" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Net2Net: Accelerating Learning via Knowledge Transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Adding Gradient Noise Improves Learning for Very Deep Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Vilnis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karol</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Kurach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Martens</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06807</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Calibrated Stochastic Gradient Descent for Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baochang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixiang</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianzhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Doermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="9348" to="9355" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.04252</idno>
		<title level="m">Self-training with Noisy Student improves ImageNet classification</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ligeng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">PyTorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning Transferable Architectures for Scalable Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Efficient Neural Architecture Search via Parameter Sharing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Melody</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multinomial Distribution Learning for Effective Neural Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiawu</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongrong</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baochang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianzhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1304" to="1313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sirui</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hehui</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
		<title level="m">SNAS: Stochastic Neural Architecture Search. ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Searching for a Robust Neural Architecture in Four GPU Hours</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanyi</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1761" to="1770" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guohao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guocheng</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Itzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Delgadillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Thabet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ghanem</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.00195</idno>
		<title level="m">SGAS: Sequential Greedy Architecture Search</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">PC-DARTS: Partial Channel Connections for Memory-Efficient Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhui</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaopeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guo-Jun</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongkai</forename><surname>Xiong</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=BJlS634tPr" />
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangxiang</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jixiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruijun</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.06022</idno>
		<title level="m">Scarletnas: Bridging the gap between scalability and fairness in neural architecture search</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Rethinking Model Scaling for Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Efficientnet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Progressive Neural Architecture Search. In ECCV</title>
		<imprint>
			<biblScope unit="page" from="19" to="34" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Squeeze-and-Excitation Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7132" to="7141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dandelion</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Mane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Autoaugment</surname></persName>
		</author>
		<title level="m">Learning Augmentation Policies from Data. CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Zhmoginov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<title level="m">Mo-bileNetV2: Inverted Residuals and Linear Bottlenecks. In CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4510" to="4520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esteban</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alok</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanping</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Regularized Evolution for Image Classifier Architecture Search. International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Mnasnet: Platform-Aware Neural Architecture Search for Mobile</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruoming</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bichen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoliang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanghan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuandong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Vajda</surname></persName>
		</author>
		<title level="m">Yangqing Jia, and Kurt Keutzer. FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search. CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">FairNAS: Rethinking Evaluation Fairness of Weight Sharing Neural Architecture Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangxiang</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruijun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jixiang</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.01845</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grace</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijun</forename><surname>Wang</surname></persName>
		</author>
		<title level="m">Yukun Zhu, Ruoming Pang, Vijay Vasudevan, et al. Searching for MobileNetV3. ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">MoGA: Searching Beyond MobileNetV3</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangxiang</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruijun</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4042" to="4046" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mixconv</surname></persName>
		</author>
		<title level="m">Mixed Depthwise Convolutional Kernels. BMVC</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Microsoft COCO: Common Objects in Context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lubomir</forename><forename type="middle">D</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Kaiming He, and Piotr Dollár. Focal Loss for Dense Object Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2980" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangmiao</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuyang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wansen</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiarui</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.07155</idno>
		<title level="m">Open mmlab detection toolbox and benchmark</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Single-Path NAS: Designing Hardware-Efficient ConvNets in less than 4 Hours</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><surname>Stamoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruizhou</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><surname>Lymberopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodhi</forename><surname>Priyantha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Marculescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECML PKDD</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>0.5, 0.1) Genotype(normal=[(&apos;sep_conv_3x3&apos;, 0), (&apos;sep_conv_3x3&apos;, 1), (&apos;skip_connect&apos;, 0), (&apos;dil_conv_3x3&apos;, 2), (&apos;dil_conv_5x5&apos;, 3), (&apos;dil_conv_3x3&apos;, 2), (&apos;dil_conv_3x3&apos;, 4), (&apos;dil_conv_3x3&apos;, 3)], normal_concat=range(2, 6), reduce=[(&apos;max_pool_3x3&apos;, 1), (&apos;skip_connect&apos;, 0), (&apos;skip_connect&apos;, 2), (&apos;avg_pool_3x3&apos;, 1), (&apos;skip_connect&apos;, 2), (&apos;avg_pool_3x3&apos;, 1), (&apos;dil_conv_5x5&apos;, 3), (&apos;skip_connect&apos;, 4)], re-duce_concat=range(2, 6)</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Best NosiyDARTS architecture genotypes searched on CIFAR-10 with uniform noise. (µ, λ) Architecture Genotype</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">(&apos;sep_conv_3x3&apos;, 2), (&apos;sep_conv_3x3&apos;, 1), (&apos;dil_conv_3x3&apos;, 3), (&apos;dil_conv_3x3&apos;, 2), (&apos;dil_conv_3x3&apos;, 2), (&apos;dil_conv_3x3</title>
	</analytic>
	<monogr>
		<title level="m">Genotype(normal=[(&apos;skip_connect&apos;, 0), (&apos;sep_conv_3x3&apos;, 1)</title>
		<imprint/>
	</monogr>
	<note>3)], normal_concat=range(2, 6), reduce=[(&apos;avg_pool_3x3&apos;, 0), (&apos;max_pool_3x3&apos;, 1), (&apos;skip_connect&apos;, 2), (&apos;max_pool_3x3&apos;, 0), (&apos;skip_connect&apos;, 3), (&apos;skip_connect&apos;, 2), (&apos;skip_connect&apos;, 3), (&apos;avg_pool_3x3&apos;, 0)], re-duce_concat=range(2, 6)</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">(&apos;skip_connect&apos;, 2), (&apos;skip_connect&apos;, 0), (&apos;dil_conv_5x5&apos;, 3), (&apos;sep_conv_3x3&apos;, 1), (&apos;sep_conv_3x3&apos;, 1), (&apos;dil_conv_3x3</title>
	</analytic>
	<monogr>
		<title level="m">Genotype(normal=[(&apos;sep_conv_3x3&apos;, 0), (&apos;sep_conv_5x5&apos;, 1)</title>
		<imprint/>
	</monogr>
	<note>4)], normal_concat=range(2, 6), reduce=[(&apos;avg_pool_3x3&apos;, 0), (&apos;sep_conv_5x5&apos;, 1), (&apos;avg_pool_3x3&apos;, 0), (&apos;skip_connect&apos;, 2), (&apos;dil_conv_5x5&apos;, 3), (&apos;avg_pool_3x3&apos;, 0), (&apos;avg_pool_3x3&apos;, 0), (&apos;skip_connect&apos;, 3)], re-duce_concat=range(2, 6)</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
