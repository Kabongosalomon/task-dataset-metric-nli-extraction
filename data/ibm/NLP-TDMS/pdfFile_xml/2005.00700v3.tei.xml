<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">EMNLP-Findings&apos;20 UNIFIEDQA: Crossing Format Boundaries with a Single QA System</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Allen Institute for AI</orgName>
								<address>
									<settlement>Seattle</settlement>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Washington</orgName>
								<address>
									<settlement>Seattle</settlement>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tushar</forename><surname>Khot</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Allen Institute for AI</orgName>
								<address>
									<settlement>Seattle</settlement>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Allen Institute for AI</orgName>
								<address>
									<settlement>Seattle</settlement>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Allen Institute for AI</orgName>
								<address>
									<settlement>Seattle</settlement>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Allen Institute for AI</orgName>
								<address>
									<settlement>Seattle</settlement>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Allen Institute for AI</orgName>
								<address>
									<settlement>Seattle</settlement>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Washington</orgName>
								<address>
									<settlement>Seattle</settlement>
									<country key="US">U.S.A</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">EMNLP-Findings&apos;20 UNIFIEDQA: Crossing Format Boundaries with a Single QA System</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T08:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Question answering (QA) tasks have been posed using a variety of formats, such as extractive span selection, multiple choice, etc. This has led to format-specialized models, and even to an implicit division in the QA community. We argue that such boundaries are artificial and perhaps unnecessary, given the reasoning abilities we seek to teach are not governed by the format. As evidence, we use the latest advances in language modeling to build a single pre-trained QA model, UNIFIEDQA, that performs well across 20 QA datasets spanning 4 diverse formats. UNIFIEDQA performs on par with 8 different models that were trained on individual datasets themselves. Even when faced with 12 unseen datasets of observed formats, UNIFIEDQA performs surprisingly well, showing strong generalization from its out-offormat training data. Finally, fine-tuning this pre-trained QA model into specialized models results in a new state of the art on 10 factoid and commonsense QA datasets, establishing UNIFIEDQA as a strong starting point for building QA systems. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Question answering is a common tool for assessing how well can computers understand language and reason with it. To this end, the NLP community has introduced several distinct datasets, with four popular QA formats illustrated in <ref type="figure">Fig. 1</ref>. For instance, some datasets expect the answer to be "yes" or "no", or a unique answer span in the associated paragraph (as opposed to multiple or no spans). These differences have motivated their study in silos, often encoding QA format into the model architecture itself. Efforts to exploit multiple datasets remain largely restricted to a single format. For example, <ref type="bibr" target="#b8">Clark et al. (2019c)</ref> limit consideration to Figure 1: Four formats (color-coded throughout the paper) commonly used for posing questions and answering them: Extractive (EX) , Abstractive (AB) , Multiple-Choice (MC) , and Yes/No (YN) . Sample dataset names are shown in square brackets. We study generalization and transfer across these formats. multiple-choice datasets, while  focus their generalization study on extractive span prediction models. To the best of our knowledge, no single QA system targets, not to mention excels at, all of these formats.</p><p>This raises the question: Can QA models learn linguistic reasoning abilities that generalize across formats? Our intuition is simple: while question format and relevant knowledge may vary across QA datasets, the underlying linguistic understanding and reasoning abilities are largely common. A multiple-choice model may, therefore, benefit from training on an extractive answers dataset. Building upon this intuition, we present a single pre-trained QA system, named UNIFIEDQA, that exploits information across 4 different QA formats to achieve strong performance across 20 different factoid and  <ref type="figure">Figure 2</ref>: Properties of various QA datasets included in this study: 5 extractive (EX), 3 abstractive (AB), 9 multiplechoice (MC), and 3 yes/no <ref type="bibr">(YN)</ref>. 'idk' denotes 'I don't know' or unanswerable questions. BoolQ represents both the original dataset and its contrast-sets extension BoolQ-CS; similarly for ROPES, Quoref, and DROP.</p><p>commonsense QA datasets listed in <ref type="figure">Fig. 2</ref>. In this work, we advocate for a unifying view of QA formats by building a format-agnostic QA system. Our work leverages recent progress in text-to-text pre-trained neural models, specifically T5  and BART <ref type="bibr" target="#b26">(Lewis et al., 2020)</ref>, but with a strong focus on differing QA formats. This paradigm allows unifying many NLP models, which formerly had task-specific designs, into a single text-to-text framework. Previous work uses textual prefixes to explicitly define the task associated with each input instance <ref type="bibr" target="#b38">Radford et al., 2019b)</ref>; often such attempts to build a single model for multiple NLP tasks underperform the standard pre-training plus finetuning setup (a model per task) .</p><p>Our work narrows down the scope to tasks that stay within the boundaries of QA, demonstrating that a unified text-to-text paradigm can, in fact, be successful across different QA tasks and formats. We develop a single pre-trained QA model by training text-to-text models on a set of seed QA datasets of multiple formats, taking natural text as input, without using format-specific prefixes. Our experiments show that UNIFIEDQA can be applied as-is to different QA tasks, generalizes well to other unseen datasets (zero-shot), and with further finetuning achieves state-of-the-art results on many QA tasks including commonsense and factual datasets.</p><p>Contributions. This work advocates for a unified view of different QA formats, and for building format-agnostic QA systems. To support this view, we present UNIFIEDQA, a single pre-trained QA system that works well on and generalizes to datasets with different formats ( §6.2), while performing on par with state-of-the-art dedicated systems tailored to each dataset ( §6.1). Additionally, fine-tuning UNIFIEDQA into specialized systems sets a new state of the art for 10 datasets ( §6.3), establishing it as a powerful starting point for QA research. Our findings demonstrate that crossing QA format boundaries is not only qualitatively de-sirable but also quantitatively beneficial.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Several QA efforts have studied generalization across datasets of a single format. For instance, in MultiQA,  study generalization and transfer, but only across extractive span selection datasets. Further, while they show strong leave-one-out style results, they find a single system performs substantially worse than one tuned to each dataset. In ORB, <ref type="bibr" target="#b12">Dua et al. (2019a)</ref> propose a multi-dataset evaluation benchmark spanning extractive and abstractive formats. However, that study is limited to an evaluation of systems, falling short of addressing how to build such generalized models. The MRQA shared task <ref type="bibr" target="#b14">(Fisch et al., 2019)</ref> focuses on span-prediction datasets. Unlike all these efforts, our goal is to investigate transfer and generalization across different QA formats, as well as to build a single system that does this well.</p><p>Exploiting commonality across machine learning tasks has a rich history studied under transfer learning <ref type="bibr" target="#b3">(Caruana, 1997;</ref><ref type="bibr" target="#b5">Clark et al., 2019b)</ref>. <ref type="bibr">Mc-Cann et al. (2018)</ref> and <ref type="bibr" target="#b17">Keskar et al. (2019)</ref> study transfer among various NLP tasks by casting them into a single QA format-an elegant transfer learning approach but orthogonal to the goal of this work. As noted earlier,  investigate the transfer between several diverse NLP tasks (machine translation, summarization, etc). Their key contribution is a text-to-text framework, and a powerful model called T5, that makes it easier to mix multiple tasks by encoding both inputs and outputs as text. They rely on textual prefixes to explicitly define the task corresponding to each input instance. While we build upon their framework, we narrow our focus to variations of QA. This allows us to achieve strong results while avoiding reliance on any format-specific prefixes. Our models learn to infer the format of each input question based on its content (e.g., whether the phrasing of the question demands a yes/no answer). Moreover, we are able to demonstrate generalization across QA tasks, which prior work failed to achieve presumably due to its focus on too broad a set of NLP tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">UNIFIEDQA: Multi-format Training</head><p>Suppose we would like to train a unified QA model that can operate over k formats F 1 , F 2 , . . . , F k . For each format F i , suppose we have i datasets sets</p><formula xml:id="formula_0">D i 1 , D i 2 , . . . , D i i where D i j = (T i j , E i j )</formula><p>includes both training and evaluation examples. In some cases, the training set T i j may be empty or we may want to ignore it in order to treat D i j as an 'unseen', evaluation-only dataset and assess a model's generalization to it.</p><p>We use the text-to-text paradigm to convert each training question q in format F i into a plain-text input representation enc i (q). This conversion uses a natural encoding process that will be described shortly ( §3.1) for four common QA formats, and is easily extensible to other formats as well. We follow a simple approach of creating a mixed training pool consisting of all available training instances:</p><formula xml:id="formula_1">T = k i=1 i j=1 enc i (q) | q ∈ T i j</formula><p>Training batches are drawn from this pooled data, T , by including each q ∈ T i j with a probability proportional 1/|T i j |. Each batch thus, on average, contains the same number of instances from each training set, regardless of its size. Similar treatments of task mixing have also been adopted by <ref type="bibr" target="#b0">Arivazhagan et al. (2019)</ref> and . As our experiments will show, our multi-format mixing approach works well. It clearly highlights the value of training on out-of-format data and confirms our intuition that there are strong ties across QA formats in terms of the underlying reasoning abilities. <ref type="bibr">2</ref> Our unified question-answering system is based on the recent text-to-text frameworks, particularly, T5  and BART <ref type="bibr" target="#b26">(Lewis et al., 2020)</ref>. We first define a unifying encoding of the instances across various formats ( §3.1). We then introduce UNIFIEDQA ( §3.2) that is a QA system trained on datasets in multiple formats, indicating new state-of-the-art results on 10 datasets and generalization to unseen datasets. 2 A more sophisticated teaching curriculum <ref type="bibr" target="#b44">(Sachan and Xing, 2016)</ref> or approaches such as model distillation and teacher annealing <ref type="bibr" target="#b5">(Clark et al., 2019b)</ref> are likely to further improve the performance of the resulting unified model, bolstering the strength of our advocacy for a unified view of all QA formats. We leave their exploration to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Text-to-Text Encoding</head><p>We convert each of our target datasets into a textin/text-out format <ref type="bibr" target="#b26">Lewis et al., 2020;</ref><ref type="bibr" target="#b38">Radford et al., 2019b)</ref>. The question always comes first, followed by some additional information (context paragraph or candidate answers, or both). We use "\n" separators between different parts of the input. This ensures having a humanlike encoding while not making it overly-specific to a certain format.</p><p>Our unified model incorporates the following four common question-answering formats. Specific datasets within them are deferred to Section 4.1. Extractive (EX) questions Q include a context paragraph C (typically a paragraph) and require models to extract the answer as a substring from the context. In some datasets, 'unanswerable' can sometimes be the correct response.</p><p>Abstractive (AB) questions Q require models to produce answers that are often not mere substrings of the provided context paragraph C.</p><p>Multiple-choice (MC) questions Q come with a set of candidate answers {A i }, of which generally exactly one is correct. In some cases, they also include a context paragraph C.</p><p>Yes/No (YN) questions Q expect a 'yes' or 'no' answer as the response and may include a context paragraph C. <ref type="table">Table 1</ref> provides examples of the natural input and output encoding for each of these formats, where both input and output representations are raw text. There is no explicit information regarding a question being an MC question or having exactly four candidate answers. Specifically, MC questions without any context paragraph are encoded as question \n (A) c1 (B) c2 . . . where c1, c1, . . . are the set of candidate answers (see the example from ARC dataset). If the question includes a context paragraph, it is appended after the candidate answers: question \n (A) c1 (B) c2 . . . \n paragraph, as shown in the example from the MCTest dataset. Questions in the other three formats (EX, AB, and YN) are encoded simply as question \n paragraph.</p><p>To re-emphasize, unlike prior work , we do not specify any task-, dataset-, or format-specific prefixes in the input representation. Whether the answer should be extracted or abstracted, and whether from the provided context paragraph or candidate answers (or the fact that </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input</head><p>What does a drink from narcissus's spring cause the drinker to do? \n Mercury has awakened Echo, who weeps for Narcissus, and states that a drink from Narcissus's spring causes the drinkers to ``Grow dotingly enamored of themselves.'' ...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Output fall in love with themselves</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MC</head><p>Dataset ARC-challenge</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input</head><p>What does photosynthesis produce that helps plants grow? \n (A) water (B) oxygen (C) protein (D) sugar</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Output sugar</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset MCTest</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input</head><p>Who was Billy? \n (A) The skinny kid (B) A teacher (C) A little kid (D) The big kid \n Billy was like a king on the school yard. A king without a queen. He was the biggest kid in our grade, so he made all the rules during recess. ...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Output The big kid</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>YN</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset BoolQ</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input</head><p>Was America the first country to have a president? \n (President) The first usage of the word president to denote the highest official in a government was during the Commonwealth of England ... <ref type="table">Table 1</ref>: Example text-to-text encoding of instances. these even are candidate answers) is expected to be inferred by the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Output no</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">UNIFIEDQA: The Pre-Trained Model</head><p>The specific pre-trained QA model we provide and use in all our experiments is trained on representative datasets for each of the 4 formats discussed earlier. We empirically chose the following 8 seed datasets for training UNIFIEDQA, 3 based on their effectiveness in our pilot study (details deferred to Section 5) assessing which datasets are most valuable for out-of-format training:</p><p>• EX: SQuAD 1.1, SQuAD 2.0 • AB: NarrativeQA • MC: RACE, ARC, OBQA, MCTest • YN: BoolQ One can easily use other combinations of formats and datsets to create variants of our UNI-FIEDQA model, or extend it as future datasets become available or new formats are introduced.</p><p>Unless otherwise noted, we use the largest available T5 model (11B parameters) as the starting point for training our model and call the system UNIFIEDQA. We also report results of training our system with BART large , referred to as UNI-FIEDQA BART (see §6.3). Details on the parameters of the models used are deferred to Appendix A.2.</p><p>Similar to pre-trained language models, the resulting pre-trained QA model can be used as a starting point for fine-tuning on other QA datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Formats and Datasets</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>We evaluate UNIFIEDQA on 20 existing datasets that target different formats as well as various complex linguistic phenomena. <ref type="figure">Fig. 2</ref> summarizes key properties of our datasets (whether it comes with a paragraph or answer candidates, whether the paragraph explicitly contains the answer, etc). Most importantly, they are grouped into several formats/categories as described below. <ref type="table" target="#tab_3">Table 2</ref> gives certain statistics of these datasets. We next provide a summary enumerating these datasets, with additional details deferred to Appendix A.1.</p><p>Extractive QA (EX). Among the datasets in this popular format, we adopt SQuAD 1.1 <ref type="bibr" target="#b41">(Rajpurkar et al., 2016)</ref>, SQuAD 2 <ref type="bibr" target="#b40">(Rajpurkar et al., 2018)</ref>, NewsQA <ref type="bibr" target="#b50">(Trischler et al., 2017)</ref>, Quoref <ref type="bibr" target="#b10">(Dasigi et al., 2019)</ref>, ROPES <ref type="bibr" target="#b28">(Lin et al., 2019)</ref>.</p><p>Abstractive QA (AB). The datasets used from this format are: NarrativeQA/NarQA <ref type="bibr" target="#b21">(Kociský et al., 2018)</ref>, the open-domain version of Natu-ralQuestions/NatQA <ref type="bibr" target="#b22">(Kwiatkowski et al., 2019)</ref>, and DROP <ref type="bibr" target="#b13">(Dua et al., 2019b)</ref>.</p><p>Multiple-choice QA (MC). We use the following MC datasets: MCTest (Richardson et al., 2013), RACE <ref type="bibr" target="#b23">(Lai et al., 2017)</ref>, OpenBookQA/OBQA <ref type="bibr" target="#b31">(Mihaylov et al., 2018)</ref>, ARC <ref type="bibr" target="#b9">(Clark et al., , 2016</ref>, QASC <ref type="bibr" target="#b20">(Khot et al., 2019)</ref>, CommonsenseQA/CQA , PIQA <ref type="bibr" target="#b2">(Bisk et al., 2020)</ref>, SIQA <ref type="bibr" target="#b46">(Sap et al., 2019)</ref>, and Winogrande <ref type="bibr" target="#b45">(Sakaguchi et al., 2020)</ref>. Several of the MC datasets do not come with accompanying paragraphs (such as ARC, QASC, OBQA). For most of this the work, we keep the questions as is with no additional retrieval (unless otherwise mentioned). One other variability among these datasets is their number of candidate answers. While many datasets have four candidates (see <ref type="figure">Fig. 2</ref>), others have more. Later (in §6.2) we will see that our approach generalizes to datasets with different numbers of candidates, even if such questions have not been seen during training.  naturally-perturbed version of this dataset, BoolQ-NP , and the binary (yes/no) subset of MultiRC .</p><p>Contrast-sets. Additionally, we use contrastsets <ref type="bibr" target="#b15">(Gardner et al., 2020)</ref> for several of our datasets (denoted with "CS"): BoolQ-CS, ROPES-CS, Quoref-CS, DROP-CS. These evaluation sets are expert-generated perturbations that deviate from the patterns common in the original dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation Metrics for Textual Output</head><p>We evaluate each dataset using the metric used most often for it in prior work. For the EX format, it's the F1 score of the extracted span relative to the gold label. For the AB format, we use ROUGE-L metric <ref type="bibr" target="#b27">(Lin et al., 2006;</ref><ref type="bibr" target="#b32">Min et al., 2019;</ref><ref type="bibr" target="#b35">Nishida et al., 2019)</ref>. For NatQA we use the exact-match metric, following . For the MC format, we match the generated text with the closest answer candidate based token overlap and compute the accuracy. For the YN format, we follow <ref type="bibr" target="#b4">Clark et al. (2019a)</ref> to measure if the generated output matches the correct 'yes' or 'no' label. In rare cases where the output is longer than one word (e.g., 'yes it is'), we check if it contains the correct label but not the incorrect one. 4</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Pilot Study: Can Out-of-Format Training Help?</head><p>We first answer the question: Is the broad idea of benefiting from out-of-format training even viable? For instance, is our intuition correct that an MC dataset can, in practice, benefit from training on an EX dataset? Before discussing our main experimental results, we briefly report on a pilot study that assesses the following basic question: Given a training set T i 1 (the anchor dataset) of QA format F i , is there an out-of-format training set T j 1 of format F j such that training jointly on T i 1 ∪ T j 1 improves performance relative to training only on T i 1 ? To this end, we evaluate both on the matching evaluation set E i 1 as well as on 'unseen' data E i 2 , E i 3 , . . . of the same format. The results are summarized in <ref type="table" target="#tab_5">Table 3</ref>. The two rows in each individual table correspond to training on T i 1 (the anchor dataset) and on T i 1 ∪ X, where X is an out-of-format dataset corresponding to T j 1 above. The columns represent various evaluation sets of format F i . For each column, 'X = . . .' at the very bottom indicates the out-of-format dataset X that was the most helpful in improving performance on the evaluation set in that column. <ref type="bibr">5</ref> Consider the case of the anchor set T i 1 being BoolQ and the evaluation set being NP-BoolQ, both of format YN. Here, including out-of-format training data X=SQuAD2 boosts performance from 51% to as much as 59%. The gain may be less in other cases, but across all anchor and evaluation datasets, we generally observe that there is at least one out-of-format training set whose inclusion improves performance.</p><p>This pilot study thus provides a proof of concept that out-of-format training can indeed help a QA model in nearly every case. Of course, this study only shows the existence of such an out-of-format dataset, rather than provide a single unified model. Nevertheless, it helps identify representative training sets from each format that were most helpful. As alluded to earlier, we used this empirical data to guide which training sets to include when building UNIFIEDQA in Section 3.2.</p><p>The experimental results from this case study are summarized in the aggregated plot shown in   <ref type="table">)</ref> with training also on an out-of-format dataset denoted 'X'. Evaluation is on the anchor dataset as well as unseen datasets of that format. The last row identifies the out-of-format dataset that helped most on each evaluation dataset. All results are based on the "small" size T5 model. Color denotes QA format (see <ref type="table" target="#tab_3">Table 2</ref>). where S(d, r) is the score achieved on r after training on d. Since we only focus on gains from out-offormat training, we drop the edges that are negative or between two datasets of the same format.</p><p>As expected, there are strong connections between the AB and EX datasets in <ref type="figure" target="#fig_0">Fig. 3</ref> since their definitions are quite similar. Apart from the edge weight, the overall width of a dataset on the left also depicts how much it contributes to out-of-format datasets. E.g., NQA (NarrativeQA) is the most helpful dataset and even helps multiple formats. Similarly our extractive datasets (SQuAD11.1, SQuAD 2, and NewsQA) are also relatively more helpful. While large datasets generally appear to help, RACE, another large-scale dataset, doesn't help that much. The least helpful dataset in the mix is BoolQ which focuses on yes/no questions.</p><p>In a similar vein, the wider the dataset on the right hand side, the more it can be benefit from out-of-format datasets. Among these beneficiary datasets, all four formats are equally represented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experimental Results</head><p>We now discuss our main experimental results, evaluating UNIFIEDQA on seed datasets (used for training the system) as well as unseen datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">UNIFIEDQA vs. 8 Dedicated Models</head><p>Is UNIFIEDQA, a single pre-trained multi-format QA system, as good as dedicated systems trained for individual datasets? We emphasize that the answer to this question is not as simple as it may seem, since earlier works have observed that a system addressing multiple tasks often underperforms a focused system . <ref type="figure">Fig. 4</ref> summarizes the results of the relevant experiment. The gray bars belong to UNIFIEDQA (a single system for multiple datasets of different formats). The colored bars are different T5-based systems tailored to individual datasets (a different system for each dataset). The results show that UNIFIEDQA performs almost as good as individual T5 models targeted to each dataset. In some cases UNIFIEDQA performs even better than the  </p><formula xml:id="formula_2">S Q u A D 1 . 1 S Q u A D 2 R A C E O B Q A A R C - E a s y A R C - C h a l M C T e s t B o o l Q N a r Q A A v g .</formula><p>Dedicated Models UnifiedQA <ref type="figure">Figure 4</ref>: UNIFIEDQA is on-par with, and often outperforms, 9 different equally-sized T5-based systems tailored to individual datasets. The figure contains separate models for each of the two subsets of the ARC and Regents datasets.</p><p>single-dataset experts (e.g., on OBQA or NQA). On average (last column) UNIFIEDQA clearly outperforms the ensemble of dataset/format-specific systems. UNIFIEDQA thus offers flexibility across multiple QA formats while compromising almost nothing compared to dataset-specific experts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Generalization to Unseen Datasets</head><p>We now explore whether UNIFIEDQA generalizes well to other, unseen datasets. For completeness, we include the highest previous scores for each dataset; one must be careful when reading these numbers as the best previous numbers follow the fully supervised protocol (for NewsQA <ref type="bibr" target="#b51">(Zhang et al., 2020)</ref>, Quoref <ref type="bibr" target="#b47">(Segal et al., 2019)</ref>, DROP <ref type="bibr" target="#b24">(Lan et al., 2019)</ref>, ROPES <ref type="bibr" target="#b28">(Lin et al., 2019)</ref>, QASC <ref type="bibr" target="#b20">(Khot et al., 2019)</ref>, CommonsenseQA <ref type="bibr" target="#b52">(Zhu et al., 2020</ref>) and x-CS datasets <ref type="bibr" target="#b15">(Gardner et al., 2020)</ref>.)</p><p>We make three key observations: (1) On average (last column), UNIFIEDQA shows much stronger generalization across a wide range of datasets. (2) on 9 (out of 12) datasets, UNIFIEDQA shows a better generalization than any single-format expert. For example, while the system is trained on multiple-choice questions with 4 candidate answers, it works quite well on datasets with more than 4 candidate answers (QASC and Common-senseQA have has 8 and 5 candidate answers per question, respectively). (3) Single-format experts are better at generalization only when the source and target datasets are very similar (for instance SQuAD and Quoref).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">State-of-the-Art via Simple Fine-tuning</head><p>Fine-tuning of pre-trained language models has become the standard paradigm for building datasetspecific stat-of-the-art systems . The question we address here is: when it comes to QA, is there a value in using UNIFIEDQA as a starting point for fine-tuning, as opposed to a vanilla language model that has not seen other QA datasets before?</p><p>To address this question, we fine-tune each of UNIFIEDQA, T5, and BART on several datasets by selecting the best check point on the dev set, and evaluating on the test set.  <ref type="bibr" target="#b8">(Clark et al.,2019c)</ref> KF+SIR <ref type="bibr">(Mitra et al., 2020)</ref> RoBERTa <ref type="bibr" target="#b8">(Clark et al.,2019c)</ref> FreeLB-RoBERTa <ref type="bibr" target="#b52">(Zhu et al., 2020)</ref> RoBERTa <ref type="bibr" target="#b8">(Clark et al.,2019c)</ref> FreeLB-RoBERTa <ref type="bibr" target="#b52">(Zhu et al., 2020)</ref> --KF+SIR +2Step <ref type="bibr">(Mitra et al., 2020)</ref>   <ref type="bibr" target="#b24">(Lan et al.,2019)</ref> FreeLB-RoBERTa <ref type="bibr" target="#b52">(Zhu et al.,2020)</ref> RoBERTa <ref type="bibr">(Sakaguchi et al.,2019)</ref> RoBERTa <ref type="bibr">(Bisk et al., 2019)</ref> RoBERTa <ref type="bibr">(Mitra et al., 2020)</ref> RoBERTa <ref type="bibr" target="#b28">(Lin et al., 2019)</ref> DPR+BART    <ref type="bibr" target="#b8">(Clark et al.,2019c)</ref> KF+SIR <ref type="bibr">(Mitra et al., 2020)</ref> RoBERTa <ref type="bibr" target="#b8">(Clark et al.,2019c)</ref> FreeLB-RoBERTa <ref type="bibr" target="#b52">(Zhu et al., 2020)</ref> RoBERTa <ref type="bibr" target="#b8">(Clark et al.,2019c)</ref> FreeLB-RoBERTa <ref type="bibr" target="#b52">(Zhu et al., 2020)</ref> --KF+SIR +2Step <ref type="bibr">(Mitra et al., 2020)</ref>   <ref type="bibr" target="#b24">(Lan et al.,2019)</ref> FreeLB-RoBERTa <ref type="bibr" target="#b52">(Zhu et al.,2020)</ref> RoBERTa <ref type="bibr">(Sakaguchi et al.,2019)</ref> RoBERTa <ref type="bibr">(Bisk et al., 2019)</ref> RoBERTa <ref type="bibr">(Mitra et al., 2020)</ref> RoBERTa <ref type="bibr" target="#b28">(Lin et al., 2019)</ref> DPR+BART     <ref type="table">Table 6</ref>: The results of a leave-one-out ablation. The first row indicates the performance of UNIFIEDQA on each dataset it was trained on. The rest of the rows exclude one dataset at a time. The rows are sorted based on the last column: the dataset with biggest contribution appear first. The red highlights indicate the top 3 performance drops for each column.</p><p>reports the best previously published work. For several MC datasets that do not come with evidence paragraphs, we include two variants: one where we use them as-is and another that uses paragraphs fetched via an Information Retrieval (IR) system as additional evidence, indicated with "w/ IR" tags. We use the same IR sentences as used by the baselines: Aristo corpus for ARC and OBQA datasets <ref type="bibr" target="#b8">(Clark et al., 2019c)</ref>, and 2-step IR for QASC <ref type="bibr" target="#b20">(Khot et al., 2019)</ref>. For NatQA, following , we use the DPR retrieval engine <ref type="bibr" target="#b16">(Karpukhin et al., 2020)</ref> to augment each question with additional paragraphs. We see that fine-tuning on UNIFIEDQA consistently dominates fine-tuning on T5 and BART, respectively. It also dominates the best previous scores on the datasets. Intuitively, since UNI-FIEDQA has seen different formats, it should be positioned to achieve higher scores after a little fine-tuning, compared to fine-tuning on a vanilla T5 or BART model. This could be especially effective when a user has limited training data for a target QA task (also shown in Appendix A.6.) This also highlights that the effectiveness of crossformat training is not limited only to T5, but is rather a general trend for text-to-text architectures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Ablation: Training Set Contributions</head><p>We now perform a leave-one-out experiment to better understand the contribution of each seed dataset to UNIFIEDQA. We take the system from §3.2 and assess how strong the model is when individual seed training datasets are dropped from the union. The result of this experiment is summarized in <ref type="table">Table 6</ref>. It compares the performance of full UNIFIEDQA (the first row) with ablated variants that exclude one seed dataset at a time. The rows are sorted based on the last column: datasets with higher contributions appear first.</p><p>Looking at first few rows of the table, BoolQ, SQuAD 2.0, OBQA, NarQA are the top four contributing datasets, each with a different format. SQuAD 1.1 has the least importance, presumably because it is mostly covered by SQuAD 2.0.</p><p>This study suggests that in order to build an effective unified QA system, it suffices to have a relatively small set of datasets as long as the set includes representatives from each format.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Discussion</head><p>The key motivation for this work is the observation that nearly all prior efforts on QA research were limited to the boundaries defined by narrow formats. A format-specific design would not generalize across QA datasets with slightly different definitions (e.g., a model built for SQuAD would not work for RACE). Additionally, such a design would prevent us from benefiting from the labeled data available in other formats. We challenge this view by advocating for approaches that combine seemingly different datasets. We believe that developing QA systems targeted to a specific format is a conceptual barrier for progress in the field.</p><p>Factors affecting generalization. Format is not the only factor affecting generalization across datasets. We additionally studied the value of other factors including dataset size and domain (vocabulary, topic, and style) in improving generalization. We observed that larger datasets often help with generalization, but not always ( §5); e.g., RACE or OBQA show similar benefits <ref type="figure" target="#fig_0">(Fig. 3)</ref>, even though RACE is much larger than OBQA. We observed a similar phenomenon with domain: similar domains help with transfer, but that is not always the case. For example, while BoolQ questions, similar to SQuAD, are accompanied with Wiki paragraphs, they barely benefit each other. Overall, the factors affecting generalization are not well-understood, leaving room for future investigations.</p><p>Unifying QA formats and text-to-text models. While UNIFIEDQA is built based using existing text-to-text models <ref type="bibr" target="#b37">(Radford et al., 2019a;</ref>, we emphasize that the choice of tasks for multi-task learning plays a crucial role in achieving successful results. Previous studies  did not observe gains when mixing tasks that are very different. The key intuition is that a more coherent choice of tasks is more likely to succeed. Further, focusing on a coherent space of QA tasks/formats allows us to simplify the input by not requiring "prefixes" to explicitly define tasks/formats.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>The question-answering community has fruitfully explored the design of strong models, but while staying within the boundaries of individual QA formats. We argued that such boundaries are artificial and can even limit the performance of systems, because the desired reasoning abilities being taught and probed are not tied to specific formats. Training data in one format should, in principle, help QA systems perform better even on questions in another format.</p><p>With this intuition in mind, we presented UNI-FIEDQA, a single pre-trained QA system based on the text-to-text paradigm, seeking to bring unification across four common QA formats. We showed that even with its simple multi-format training methodology, UNIFIEDQA achieves performance on par with 8 dataset-specific expert models ( §6.1), while also generalizing well to many unseen datasets of seen formats ( §6.2). At the same time, we demonstrated that UNIFIEDQA is a strong starting point for building QA systems: it can achieve state-of-the-art performance by simply fine-tuning on target datasets (6.3).</p><p>We hope this effort will inspire a future line of work in the QA and NLP communities, moving towards more general and broader system designs. We leave extensions of UNIFIEDQA to other formats such as to direct-answer questions  as a promising avenue for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 UNIFIEDQA: Different Sizes</head><p>For completeness we're also showing the scores of UNIFIEDQA of different sizes on each dataset. For these systems each row is a single system.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Comparison with the Dedicated Models: extended results</head><p>Here we summarize an extension of the results in §6.1.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5 Pairwise Mixing: extended results</head><p>Here we summarize an extension of the results in §5. The question addressed here is whether there is value in mixing datasets with different formats. We evaluated this by adding one dataset of a different format to four different datasets (one for each format). The results are summarized in The results show that one can achieve gains for question-answering in a certain format by incorporating resources in other formats. In the first two sub-tables, we see that NarQA (AB) and OBQA (MC) help a SQuAD models generalize better to other EX datasets. In the third table where the anchor dataset is NQA   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Bipartite graph showing the value of various datasets. The datasets on the left were used for training and on the right for evaluation. The wider the edge from a dataset (on the left) to a dataset r (on the right), the higher the contribution of adding the out-of-format dataset to the training set of questions in r's format.Fig. 3. In this bipartite graph, the datasets used for training are on the left hand side and the evaluation datasets are on the right hand side. The weight of each edge w( , r) indicates the contribution of a dataset when used for training jointly with an anchor dataset d, when evaluated on r (d and r have the same format.) Specifically, w( , r) = avg d S ∪ d; r − S d; r ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>SQuAD11 SQuAD2 NewsQA Quoref ROPES NarQA DROP NatQA RACE MCTest OBQA ARC QASC CQA WG PIQA SIQA BoolQ NP-BoolQ MultiRC</head><label></label><figDesc>arXiv:2005.00700v3 [cs.CL] 7 Oct 2020</figDesc><table><row><cell>Datasets</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Format</cell><cell></cell><cell cols="2">Extractive QA (EX)</cell><cell></cell><cell></cell><cell cols="2">Abstractive QA (AB)</cell><cell></cell><cell></cell><cell cols="4">Multiple-choice QA (MC)</cell><cell>Yes/NO QA (YN)</cell></row><row><cell>Has paragraphs?</cell><cell>✓</cell><cell>✓</cell><cell>✓</cell><cell>✓</cell><cell>✓</cell><cell>✓</cell><cell>✓</cell><cell>✓</cell><cell>✓</cell><cell></cell><cell></cell><cell></cell><cell>✓</cell><cell>✓</cell><cell>✓</cell></row><row><cell>Has explicit candidate ans?</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>✓</cell><cell>✓</cell><cell>✓</cell><cell>✓</cell><cell>✓</cell><cell>✓</cell><cell>✓</cell><cell>✓</cell><cell>✓</cell></row><row><cell># of explicit candidates</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>4</cell><cell>4</cell><cell>4</cell><cell>4</cell><cell>8</cell><cell>5</cell><cell>2</cell><cell>2</cell><cell>3</cell></row><row><cell>Para contains ans as substring?</cell><cell>✓</cell><cell>✓</cell><cell>✓</cell><cell>✓</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Has idk questions?</cell><cell></cell><cell>✓</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Yes/No QA (YN). The YN datasets we use are BoolQ<ref type="bibr" target="#b4">(Clark et al., 2019a</ref>) and a</figDesc><table><row><cell>Dataset</cell><cell>Train set size</cell><cell>Eval. set size</cell><cell>Best published</cell><cell>95% CI (%)</cell><cell>Input length</cell><cell>Output length</cell></row><row><cell>SQuAD 1.1</cell><cell>87k</cell><cell>10k</cell><cell>95.6</cell><cell>0.4</cell><cell>136.2</cell><cell>3.0</cell></row><row><cell>SQuAD 2.0</cell><cell>130k</cell><cell>11k</cell><cell>91.2</cell><cell>0.5</cell><cell>139.9</cell><cell>2.6</cell></row><row><cell>NewsQA</cell><cell>76k</cell><cell>4k</cell><cell>66.8</cell><cell>1.4</cell><cell>606.6</cell><cell>4.0</cell></row><row><cell>Quoref</cell><cell>22k</cell><cell>2k</cell><cell>86.1</cell><cell>1.5</cell><cell>352.7</cell><cell>1.7</cell></row><row><cell>Quoref-CS</cell><cell>-</cell><cell>700</cell><cell>55.4</cell><cell>3.6</cell><cell>324.1</cell><cell>2.2</cell></row><row><cell>ROPES</cell><cell>10k</cell><cell>1.4k</cell><cell>61.1</cell><cell>2.5</cell><cell>169.1</cell><cell>1.4</cell></row><row><cell>ROPES-CS</cell><cell>-</cell><cell>974</cell><cell>32.5</cell><cell>3.0</cell><cell>182.7</cell><cell>1.3</cell></row><row><cell>NarQA</cell><cell>65k</cell><cell>21k</cell><cell>58.9</cell><cell>0.7</cell><cell>563.6</cell><cell>6.2</cell></row><row><cell>NatQA</cell><cell>79k</cell><cell>3.6k</cell><cell>42.2</cell><cell>1.6</cell><cell>607.0</cell><cell>2.2</cell></row><row><cell>DROP</cell><cell>77k</cell><cell>9k</cell><cell>89.1</cell><cell>0.6</cell><cell>189.1</cell><cell>1.6</cell></row><row><cell>DROP-CS</cell><cell>-</cell><cell>947</cell><cell>54.2</cell><cell>3.2</cell><cell>206.0</cell><cell>2.1</cell></row><row><cell>RACE</cell><cell>87k</cell><cell>4k</cell><cell>89.5</cell><cell>0.9</cell><cell>317.9</cell><cell>6.9</cell></row><row><cell>OBQA</cell><cell>4k</cell><cell>501</cell><cell>80.0</cell><cell>3.3</cell><cell>28.7</cell><cell>3.6</cell></row><row><cell>MCTest</cell><cell>1.4k</cell><cell>320</cell><cell>86.5</cell><cell>3.4</cell><cell>245.4</cell><cell>4.0</cell></row><row><cell>ARC (easy)</cell><cell>2k</cell><cell>2k</cell><cell>80.0</cell><cell>1.7</cell><cell>39.4</cell><cell>3.7</cell></row><row><cell>ARC (chal.)</cell><cell>1k</cell><cell>1k</cell><cell>67.8</cell><cell>2.9</cell><cell>47.4</cell><cell>5.0</cell></row><row><cell>CQA</cell><cell>9.7k</cell><cell>1.2k</cell><cell>79.1</cell><cell>2.2</cell><cell>26.8</cell><cell>1.5</cell></row><row><cell>WG</cell><cell>40.3k</cell><cell>1.7k</cell><cell>67.5</cell><cell>2.2</cell><cell>25.2</cell><cell>3.0</cell></row><row><cell>PIQA</cell><cell>16.1k</cell><cell>3k</cell><cell>79.4</cell><cell>1.4</cell><cell>49.6</cell><cell>20.2</cell></row><row><cell>SIQA</cell><cell>33.4k</cell><cell>2.2k</cell><cell>78.0</cell><cell>1.7</cell><cell>37.3</cell><cell>4.7</cell></row><row><cell>BoolQ</cell><cell>9k</cell><cell>3k</cell><cell>91.0</cell><cell>1.0</cell><cell>105.1</cell><cell>1.0</cell></row><row><cell>BoolQ-CS</cell><cell>-</cell><cell>461</cell><cell>71.1</cell><cell>4.0</cell><cell>108.9</cell><cell>1.0</cell></row><row><cell>NP-BoolQ</cell><cell>10k</cell><cell>3k</cell><cell>78.4</cell><cell>1.4</cell><cell>106.2</cell><cell>1.0</cell></row><row><cell>MultiRC</cell><cell>-</cell><cell>312</cell><cell>91.7</cell><cell>2.6</cell><cell>293.3</cell><cell>1.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Dataset Statistics. CQA, OBQA, WG, and NarQA refer to CommonsenseQA, OpenBookQA, Winogrande, and NarrativeQA, respectively. The CI column shows the upper 95% confidence interval for the evaluation set as a percentage, based on the Wilson test around the mean score listed as a percentage in the best known performance column. Input and output representation lengths are measured in the number of tokens and averaged across the dataset.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Pilot study showing that out-of-format training can help improve performance. Each table compares training on just the anchor dataset (e.g., BoolQ in the top-left table</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>Generalization to unseen datasets: Multi-format training (UNIFIEDQA) often outperforms models trained the same way but solely on other in-format datasets (e.g., UNIFIEDQA[EX], which is trained on all extractive training sets of UNIFIEDQA. When averaged across all evaluation datasets (last column), UNIFIEDQA shows strong generalization performance across all formats. Notably, the "Previous best" models (last row) were trained on the target dataset's training data, but are even then outperformed by UnifiedQA (which has never seen these datasets during training) on the YN tasks.</figDesc><table><row><cell>100</cell></row><row><cell>90</cell></row><row><cell>80</cell></row><row><cell>70</cell></row><row><cell>60</cell></row><row><cell>50</cell></row><row><cell>40</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell>summarizes</cell></row><row><cell>the results of experiments where we evaluate var-</cell></row><row><cell>ious models on datasets that are not used to train</cell></row><row><cell>them. It compares UNIFIEDQA (training on mul-</cell></row><row><cell>tiple formats) with training on various datasets of</cell></row><row><cell>a single format (e.g., UNIFIEDQA [EX], built by</cell></row><row><cell>training the model on only extractive datasets).</cell></row><row><cell>The first few rows of the table show T5 models</cell></row><row><cell>trained for individual formats, followed by UNI-</cell></row><row><cell>FIEDQA.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5</head><label>5</label><figDesc>summarizes the results of the experiments. The table shows two variants: UNIFIEDQA T5 and UNIFIEDQA BART .All results are based on the 11B version of T5.The columns indicate the evaluation on the test set corresponding to the data that was used for training. For each dataset, the first line of the table</figDesc><table><row><cell>Model ↓ -Eval. →</cell><cell>OBQA *</cell><cell>OBQA (w/ IR)</cell><cell>ARC-easy *</cell><cell>ARC-easy (w/ IR)</cell><cell>ARC-chal *</cell><cell>ARC-chal (w/ IR)</cell><cell>QASC</cell><cell>QASC (w/ IR)</cell></row><row><cell></cell><cell>RoBERTa</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Previous best published</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 5</head><label>5</label><figDesc></figDesc><table><row><cell cols="12">: Fine-tuning UNIFIEDQA (last row) results in new state-of-the-art performance on 11 datasets. Further,</cell></row><row><cell cols="12">it consistently improves upon fine-tuned T5 (2nd last row) by a margin ranging from 1% for CommonsenseQA</cell></row><row><cell cols="12">(CQA) to as much as 13% for ARC-challenge. '(w/ IR)' denotes relevant information is retrieved and appended as</cell></row><row><cell cols="11">context sentences in the input encoding. Datasets marked with * are used in UNIFIEDQA's original training.</cell><cell></cell></row><row><cell>Model ↓ -Evaluated on →</cell><cell cols="10">SQuAD11 SQuAD2 NarQA RACE OBQA ARC-easy ARC-hard MCTest BoolQ Avg</cell><cell>Δ</cell></row><row><cell>UnifiedQA</cell><cell>93.4</cell><cell>89.6</cell><cell>65.2</cell><cell>87.3</cell><cell>86.0</cell><cell>85.7</cell><cell>75.6</cell><cell>95.0</cell><cell>90.2</cell><cell>85.4</cell><cell></cell></row><row><cell>excluding BoolQ</cell><cell>93.1</cell><cell>90.1</cell><cell>65.0</cell><cell>87.7</cell><cell>85.0</cell><cell>86.1</cell><cell>75.2</cell><cell>94.7</cell><cell>8.3</cell><cell cols="2">77.0 -8.4</cell></row><row><cell>excluding SQuAD 2</cell><cell>95.3</cell><cell>47.3</cell><cell>65.4</cell><cell>87.7</cell><cell>84.8</cell><cell>85.9</cell><cell>75.5</cell><cell>95.3</cell><cell>90.5</cell><cell cols="2">81.3 -4.2</cell></row><row><cell>excluding OBQA</cell><cell>93.6</cell><cell>89.3</cell><cell>65.2</cell><cell>87.4</cell><cell>77.8</cell><cell>85.7</cell><cell>74.0</cell><cell>94.7</cell><cell>90.1</cell><cell cols="2">84.2 -1.3</cell></row><row><cell>excluding NarQA</cell><cell>93.6</cell><cell>89.8</cell><cell>52.5</cell><cell>87.7</cell><cell>85.6</cell><cell>86.3</cell><cell>75.9</cell><cell>95.6</cell><cell>89.9</cell><cell cols="2">84.2 -1.2</cell></row><row><cell>excluding RACE</cell><cell>93.9</cell><cell>89.0</cell><cell>65.0</cell><cell>78.5</cell><cell>85.2</cell><cell>85.6</cell><cell>74.7</cell><cell>95.9</cell><cell>90.1</cell><cell cols="2">84.3 -1.2</cell></row><row><cell>excluding ARC-easy</cell><cell>93.4</cell><cell>89.8</cell><cell>65.0</cell><cell>87.0</cell><cell>83.8</cell><cell>84.0</cell><cell>75.9</cell><cell>94.7</cell><cell>89.9</cell><cell cols="2">84.9 -0.6</cell></row><row><cell>excluding ARC-hard</cell><cell>93.6</cell><cell>90.1</cell><cell>64.9</cell><cell>87.3</cell><cell>85.2</cell><cell>85.1</cell><cell>73.8</cell><cell>95.6</cell><cell>90.5</cell><cell cols="2">85.1 -0.4</cell></row><row><cell>excluding MCTest</cell><cell>92.8</cell><cell>90.6</cell><cell>65.0</cell><cell>87.1</cell><cell>84.6</cell><cell>85.6</cell><cell>75.4</cell><cell>95.6</cell><cell>90.2</cell><cell cols="2">85.2 -0.2</cell></row><row><cell>excluding SQuAD 1.1</cell><cell>92.6</cell><cell>90.3</cell><cell>65.3</cell><cell>87.4</cell><cell>85.8</cell><cell>86.5</cell><cell>75.9</cell><cell>95.3</cell><cell>90.7</cell><cell>85.6</cell><cell>0.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head></head><label></label><figDesc>Trained on ↓ -Evaluated on → SQuAD11 SQuAD2 NewsQA Quoref Quoref-CS ROPES ROPES-CS NarQA DROP DROP-CS BoolQ MultiRC NP-BoolQ BoolQ-CS</figDesc><table><row><cell>Small</cell><cell>79.4</cell><cell>67.6</cell><cell>51.1</cell><cell>25.6</cell><cell>27.6</cell><cell>31.0</cell><cell>32.9</cell><cell>53.7</cell><cell>14.6</cell><cell>17.2</cell><cell>77.1</cell><cell>46.9</cell><cell>59.4</cell><cell>58.1</cell></row><row><cell>Base</cell><cell>88.2</cell><cell>78.1</cell><cell>54.2</cell><cell>40.0</cell><cell>38.5</cell><cell>33.9</cell><cell>28.4</cell><cell>58.7</cell><cell>19.7</cell><cell>23.7</cell><cell>82.5</cell><cell>64.8</cell><cell>66.3</cell><cell>61.9</cell></row><row><cell>Large</cell><cell>91.1</cell><cell>85.9</cell><cell>48.5</cell><cell>45.5</cell><cell>42.1</cell><cell>47.7</cell><cell>37.9</cell><cell>60.8</cell><cell>24.6</cell><cell>30.7</cell><cell>86.1</cell><cell>54.2</cell><cell>72.6</cell><cell>73.0</cell></row><row><cell>3B</cell><cell>93.2</cell><cell>87.4</cell><cell>59.6</cell><cell>60.4</cell><cell>54.7</cell><cell>48.7</cell><cell>43.1</cell><cell>63.3</cell><cell>28.5</cell><cell>33.9</cell><cell>89.3</cell><cell>62.6</cell><cell>78.4</cell><cell>77.0</cell></row><row><cell>11B</cell><cell>93.4</cell><cell>89.6</cell><cell>58.9</cell><cell>63.5</cell><cell>55.3</cell><cell>67.0</cell><cell>45.6</cell><cell>65.2</cell><cell>32.5</cell><cell>40.9</cell><cell>90.2</cell><cell>59.9</cell><cell>81.3</cell><cell>80.4</cell></row><row><cell cols="4">Trained on ↓ -Evaluated on → RACE OBQA</cell><cell>OBQA (w/ IR)</cell><cell>ARC-easy</cell><cell cols="2">ARC-easy (w/ IR)</cell><cell>ARC-chal</cell><cell>ARC-hard (w/ IR)</cell><cell cols="2">MCTest QASC</cell><cell>QASC (w/ IR)</cell><cell>CQA</cell><cell></cell></row><row><cell>Small</cell><cell></cell><cell>56.0</cell><cell>50.4</cell><cell>35.4</cell><cell>42.9</cell><cell>59.5</cell><cell></cell><cell>35.9</cell><cell>35.8</cell><cell>80.0</cell><cell>19.1</cell><cell>37.9</cell><cell>32.8</cell><cell></cell></row><row><cell>Base</cell><cell></cell><cell>70.3</cell><cell>59.0</cell><cell>38.4</cell><cell>53.0</cell><cell>69.4</cell><cell></cell><cell>42.4</cell><cell>44.2</cell><cell>86.9</cell><cell>25.8</cell><cell>50.8</cell><cell>45.0</cell><cell></cell></row><row><cell>Large</cell><cell></cell><cell>78.1</cell><cell>68.4</cell><cell>54.6</cell><cell>65.9</cell><cell>77.4</cell><cell></cell><cell>54.4</cell><cell>54.8</cell><cell>90.0</cell><cell>43.3</cell><cell>62.6</cell><cell>60.9</cell><cell></cell></row><row><cell>3B</cell><cell></cell><cell>83.2</cell><cell>80.8</cell><cell>63.2</cell><cell>78.7</cell><cell>86.2</cell><cell></cell><cell>66.7</cell><cell>64.8</cell><cell>95.0</cell><cell>62.2</cell><cell>76.6</cell><cell>71.3</cell><cell></cell></row><row><cell>11B</cell><cell></cell><cell>87.3</cell><cell>86.0</cell><cell>71.2</cell><cell>85.7</cell><cell>89.2</cell><cell></cell><cell>75.6</cell><cell>74.7</cell><cell>95.0</cell><cell>68.5</cell><cell>80.1</cell><cell>76.2</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 7 :</head><label>7</label><figDesc>UNIFIEDQA of different sizes on our datasets.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 8</head><label>8</label><figDesc>summarizes the results of the relevant experiment. In the top portion of the table we have evaluations of T5 model fine-tuned for individual datasets, followed by UNIFIEDQA. As it can be observed from the table, UNIFIEDQA performs almost as good as the best single dataset experts. In some cases UNIFIEDQA performs even better than than the single-dataset experts (e.g., on OBQA or NQA.) On average (last column) UNIFIEDQA is doing much better dataset/format-specific systems. In conclusion, UNIFIEDQA offers flexibility across multiple QA formats while compromising almost nothing compared to dataset-specific experts.</figDesc><table><row><cell>Seen dataset?</cell><cell cols="8">Model ↓ -Evaluated on → NewsQA Quoref Quoref-CS DROP DROP-CS ROPES ROPES-CS</cell><cell>QASC</cell><cell>Commonsen seQA</cell><cell cols="4">NP-BoolQ BoolQ-CS MultiRC Avg</cell></row><row><cell></cell><cell>T5 (SQuAD11)</cell><cell>62.5</cell><cell>71.5</cell><cell>61.0</cell><cell>31.5</cell><cell>37.0</cell><cell>62.0</cell><cell>39.9</cell><cell>64.5</cell><cell>70.4</cell><cell>1.6</cell><cell>0.0</cell><cell>2.4</cell><cell>42.0</cell></row><row><cell></cell><cell>T5 (SQuAD2)</cell><cell>55.7</cell><cell>54.7</cell><cell>46.0</cell><cell>20.3</cell><cell>20.1</cell><cell>29.4</cell><cell>23.9</cell><cell>39.3</cell><cell>52.6</cell><cell>22.2</cell><cell>18.2</cell><cell>9.5</cell><cell>32.7</cell></row><row><cell></cell><cell>T5 (RACE)</cell><cell>49.9</cell><cell>70.7</cell><cell>56.6</cell><cell>29.2</cell><cell>36.5</cell><cell>72.1</cell><cell>48.2</cell><cell>64.1</cell><cell>73.1</cell><cell>2.5</cell><cell>4.5</cell><cell>3.3</cell><cell>42.6</cell></row><row><cell>No</cell><cell>T5 (OBQA)</cell><cell>9.3</cell><cell>20.7</cell><cell>14.3</cell><cell>7.7</cell><cell>9.4</cell><cell>20.6</cell><cell>5.4</cell><cell>52.2</cell><cell>67.4</cell><cell>0.2</cell><cell>0.1</cell><cell>0.1</cell><cell>17.3</cell></row><row><cell></cell><cell>T5 (BoolQ)</cell><cell>0.6</cell><cell>1.7</cell><cell>1.4</cell><cell>0.4</cell><cell>0.1</cell><cell>0.0</cell><cell>0.7</cell><cell>14.8</cell><cell>20.8</cell><cell>79.1</cell><cell>78.6</cell><cell cols="2">91.7 24.2</cell></row><row><cell></cell><cell>T5 (NarQA)</cell><cell>58.0</cell><cell>68.2</cell><cell>57.6</cell><cell>30.7</cell><cell>36.8</cell><cell>48.1</cell><cell>41.7</cell><cell>54.1</cell><cell>59.0</cell><cell>27.2</cell><cell>39.9</cell><cell cols="2">28.4 45.8</cell></row><row><cell></cell><cell>UnifiedQA</cell><cell>58.9</cell><cell>63.5</cell><cell>55.3</cell><cell>32.5</cell><cell>40.1</cell><cell>67.0</cell><cell>45.5</cell><cell>68.5</cell><cell>76.2</cell><cell>81.3</cell><cell>80.4</cell><cell cols="2">59.9 60.7</cell></row><row><cell>Yes</cell><cell>Previous best</cell><cell cols="2">66.8 Retro Reader XLNet 70.5</cell><cell>55.4 XLNet</cell><cell>89.1 ALBERT</cell><cell>54.2 MTMSN</cell><cell>61.1 ROBERTa</cell><cell>32.5 RoBERTa</cell><cell cols="3">85.2 KF+SIR+2Step FreeLB-RoBERTa RoBERTa 79.1 78.4</cell><cell>71.1 RoBERTa</cell><cell>----</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 8 :</head><label>8</label><figDesc>UNIFIEDQA is on-par with systems tailored to individual datasets (the diagonal cells vs the last row) while functioning across a wide range of datasets (the last column).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 9 .</head><label>9</label><figDesc>The goal of each sub-table is to measure the within-format generalization one can gain via out-of-format training. Each sub-table has an anchor dataset, indicated in the first column. For example in the first table the anchor dataset is SQuAD. Rows of the table: Each table combines datasets of other formats with the anchor dataset (e.g., SQuAD + RACE, etc). The columns of the sub-tables contain evaluations on the dataset with the same format as the anchor dataset. For example, on the first table, the evaluation is done on SQuAD 1.1/2.0, NewsQA, Quoref which have the same format as SQuaD 1.1, the anchor dataset.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head></head><label></label><figDesc>(AB), EX datasets help a NQA model generalize better to other AB datasets. In the 4th/5th subtable, EX and AB datasets help a RACE/OBQA (MC) models generalize better to other MC datasets. Similarly, in the final sub-table, MC dataset helps improve the scores on a YN datasets.</figDesc><table><row><cell>Anchor</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Dataset /</cell><cell></cell><cell>Trained on ↓ -Evaluated on →</cell><cell cols="2">SQuAD11</cell><cell>SQuAD2</cell><cell cols="2">NewsQA</cell><cell cols="2">Quoref</cell><cell>Quoref-CS</cell><cell>Avg</cell></row><row><cell>Format</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>SQuAD11</cell><cell cols="2">85.9</cell><cell>42.8</cell><cell>51.7</cell><cell></cell><cell cols="2">28.2</cell><cell>28.11</cell><cell>47.4</cell></row><row><cell></cell><cell></cell><cell>SQuAD11 + RACE</cell><cell cols="2">85.6</cell><cell>42.6</cell><cell>51.7</cell><cell></cell><cell cols="2">26.6</cell><cell>27.43</cell><cell>46.8</cell></row><row><cell>SQuAD11</cell><cell></cell><cell>SQuAD11 + OBQA</cell><cell cols="2">85.7</cell><cell>42.8</cell><cell>52.1</cell><cell></cell><cell cols="2">27.7</cell><cell>29.84</cell><cell>47.6</cell></row><row><cell></cell><cell></cell><cell>SQuAD11 + BoolQ</cell><cell cols="2">85.8</cell><cell>42.7</cell><cell>52.1</cell><cell></cell><cell cols="2">27.7</cell><cell>29.42</cell><cell>47.5</cell></row><row><cell></cell><cell></cell><cell>SQuAD11 + NarQA</cell><cell cols="2">85.6</cell><cell>42.7</cell><cell>51.3</cell><cell></cell><cell cols="2">29.4</cell><cell>26.56</cell><cell>47.1</cell></row><row><cell></cell><cell></cell><cell>SQuAD2</cell><cell cols="2">76.5</cell><cell>70.7</cell><cell>46.0</cell><cell></cell><cell cols="2">17.7</cell><cell>22.04</cell><cell>46.6</cell></row><row><cell></cell><cell></cell><cell>SQuAD2 + RACE</cell><cell cols="2">76.5</cell><cell>70.6</cell><cell>47.9</cell><cell></cell><cell cols="2">18.6</cell><cell>20.40</cell><cell>46.8</cell></row><row><cell>SQuAD2</cell><cell></cell><cell>SQuAD2 + OBQA</cell><cell cols="2">76.7</cell><cell>70.8</cell><cell>48.4</cell><cell></cell><cell cols="2">16.9</cell><cell>19.80</cell><cell>46.5</cell></row><row><cell></cell><cell></cell><cell>SQuAD2 + BoolQ</cell><cell cols="2">75.9</cell><cell>72.0</cell><cell>45.4</cell><cell></cell><cell cols="2">16.3</cell><cell>20.35</cell><cell>46.0</cell></row><row><cell></cell><cell></cell><cell>SQuAD2 + NarQA</cell><cell cols="2">72.5</cell><cell>70.9</cell><cell>47.3</cell><cell></cell><cell cols="2">20.0</cell><cell>23.39</cell><cell>46.8</cell></row><row><cell>Anchor</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Dataset /</cell><cell cols="2">Trained on ↓ -Evaluated on →</cell><cell cols="2">NarQA</cell><cell>DROP</cell><cell cols="2">DROP-CS</cell><cell cols="2">ROPES</cell><cell>ROPES-CS</cell><cell>Avg</cell></row><row><cell>Format</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>NarQA</cell><cell>51.5</cell><cell></cell><cell>10.2</cell><cell>11.1</cell><cell></cell><cell>22.8</cell><cell></cell><cell>15.3</cell><cell>22.2</cell></row><row><cell></cell><cell></cell><cell>NarQA + SQuAD11</cell><cell>52.7</cell><cell></cell><cell>14.1</cell><cell>14.6</cell><cell></cell><cell>30.5</cell><cell></cell><cell>33.2</cell><cell>29.0</cell></row><row><cell></cell><cell></cell><cell>NarQA + SQuAD2</cell><cell>53.0</cell><cell></cell><cell>14.4</cell><cell>14.6</cell><cell></cell><cell>31.3</cell><cell></cell><cell>33.2</cell><cell>29.3</cell></row><row><cell>NQA</cell><cell></cell><cell>NarQA + NewsQA</cell><cell>52.5</cell><cell></cell><cell>10.4</cell><cell>12.3</cell><cell></cell><cell>16.6</cell><cell></cell><cell>15.6</cell><cell>21.5</cell></row><row><cell></cell><cell></cell><cell>NarQA + RACE</cell><cell>52.0</cell><cell></cell><cell>10.7</cell><cell>13.5</cell><cell></cell><cell>20.0</cell><cell></cell><cell>17.9</cell><cell>22.8</cell></row><row><cell></cell><cell></cell><cell>NarQA + OBQA</cell><cell>51.8</cell><cell></cell><cell>10.1</cell><cell>11.3</cell><cell></cell><cell>15.4</cell><cell></cell><cell>17.0</cell><cell>21.1</cell></row><row><cell></cell><cell></cell><cell>NarQA + BoolQ</cell><cell>51.8</cell><cell></cell><cell>10.2</cell><cell>10.9</cell><cell></cell><cell>20.7</cell><cell></cell><cell>10.9</cell><cell>20.9</cell></row><row><cell>Anchor</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Dataset /</cell><cell cols="9">Trained on ↓ -Evaluated on → RACE OBQA ARC-easy ARC-hard MCTest QASC</cell><cell>CQA</cell><cell>Avg</cell></row><row><cell>Format</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>RACE</cell><cell>55.8</cell><cell>26.6</cell><cell>31.8</cell><cell>28.0</cell><cell></cell><cell>62.5</cell><cell>17.9</cell><cell>28.3</cell><cell>35.8</cell></row><row><cell></cell><cell></cell><cell>RACE + SQuAD11</cell><cell>59.1</cell><cell>28.0</cell><cell>32.4</cell><cell>28.1</cell><cell></cell><cell>69.4</cell><cell>23.5</cell><cell>36.1</cell><cell>39.5</cell></row><row><cell>RACE</cell><cell></cell><cell>RACE + NewsQA</cell><cell>57.5</cell><cell>28.0</cell><cell>31.6</cell><cell>28.4</cell><cell></cell><cell>65.0</cell><cell>19.9</cell><cell>32.1</cell><cell>37.5</cell></row><row><cell></cell><cell></cell><cell>RACE + BoolQ</cell><cell>57.4</cell><cell>26.8</cell><cell>31.8</cell><cell>27.9</cell><cell></cell><cell>63.1</cell><cell>18.0</cell><cell>29.6</cell><cell>36.4</cell></row><row><cell></cell><cell></cell><cell>RACE + NarQ</cell><cell>55.7</cell><cell>32.2</cell><cell>30.6</cell><cell>28.4</cell><cell></cell><cell>60.9</cell><cell>17.9</cell><cell>28.1</cell><cell>36.3</cell></row><row><cell></cell><cell></cell><cell>OBQA</cell><cell>28.8</cell><cell>51.8</cell><cell>26.1</cell><cell>34.8</cell><cell></cell><cell>33.1</cell><cell>6.9</cell><cell>17.3</cell><cell>28.4</cell></row><row><cell></cell><cell></cell><cell>OBQA + SQuAD11</cell><cell>29.6</cell><cell>51.6</cell><cell>27.2</cell><cell>33.3</cell><cell></cell><cell>46.3</cell><cell>9.5</cell><cell>23.3</cell><cell>31.5</cell></row><row><cell>OBQA</cell><cell></cell><cell>OBQA + SQuAD2 OBQA + NewsQA</cell><cell>29.5 30.7</cell><cell>53.2 49.4</cell><cell>27.2 26.1</cell><cell>33.5 32.3</cell><cell></cell><cell>46.6 37.8</cell><cell>9.3 8.9</cell><cell>23.1 22.9</cell><cell>31.8 29.7</cell></row><row><cell></cell><cell></cell><cell>OBQA + BoolQ</cell><cell>25.0</cell><cell>50.4</cell><cell>26.0</cell><cell>34.3</cell><cell></cell><cell>27.2</cell><cell>7.1</cell><cell>18.3</cell><cell>26.9</cell></row><row><cell></cell><cell></cell><cell>OBQA + NarQA</cell><cell>29.7</cell><cell>52.8</cell><cell>25.6</cell><cell>33.0</cell><cell></cell><cell>49.1</cell><cell>8.9</cell><cell>19.1</cell><cell>31.2</cell></row><row><cell cols="2">Anchor</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Dataset /</cell><cell cols="2">Trained on ↓ -Evaluated on →</cell><cell>BoolQ</cell><cell cols="2">MultiRC</cell><cell cols="2">NP-BoolQ</cell><cell cols="2">BoolQ-CS</cell><cell>Avg</cell></row><row><cell cols="2">Format</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>BoolQ</cell><cell></cell><cell>76.36</cell><cell cols="2">64.10</cell><cell></cell><cell>51.33</cell><cell cols="2">53.37</cell><cell>61.3</cell></row><row><cell></cell><cell></cell><cell>BoolQ + SQuAD11</cell><cell></cell><cell>78.41</cell><cell cols="2">51.28</cell><cell></cell><cell>54.33</cell><cell cols="2">58.36</cell><cell>60.6</cell></row><row><cell></cell><cell></cell><cell>BoolQ + SQuAD2</cell><cell></cell><cell>78.93</cell><cell cols="2">56.89</cell><cell></cell><cell>59.38</cell><cell cols="2">58.06</cell><cell>63.3</cell></row><row><cell cols="2">BoolQ</cell><cell>BoolQ + NewsQA</cell><cell></cell><cell>77.61</cell><cell cols="2">54.17</cell><cell></cell><cell>55.46</cell><cell cols="2">59.82</cell><cell>61.8</cell></row><row><cell></cell><cell></cell><cell>BoolQ + RACE</cell><cell></cell><cell>75.69</cell><cell cols="2">61.22</cell><cell></cell><cell>54.59</cell><cell cols="2">56.89</cell><cell>62.1</cell></row><row><cell></cell><cell></cell><cell>BoolQ + OBQA</cell><cell></cell><cell>76.42</cell><cell cols="2">66.03</cell><cell></cell><cell>52.03</cell><cell cols="2">57.77</cell><cell>63.1</cell></row><row><cell></cell><cell></cell><cell>BoolQ + NarQA</cell><cell></cell><cell>78.90</cell><cell cols="2">59.02</cell><cell></cell><cell>55.33</cell><cell cols="2">61.00</cell><cell>63.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head>Table 9 :</head><label>9</label><figDesc>Pairwise mixing of formats: mixing with QA of datasets with different formats helps.A.6 Extended Results of Fine-tuning on WinograndeHere we provide extended result for the Winogrande dataset. The results are summarized inTable 10. The table include results of fine-tuning UNIFIEDQA T5 and UNIFIEDQA BART , as well as fine-tuning of the vanilla language models, T5 and BART. As it can be observed, on this dataset, fine-tuning UNIFIEDQA gives stronger results when the size of the training data is limited. With respect to the overall metric AUC, UNIFIEDQA has a slight edge over fine-tuning the vanilla language models.</figDesc><table><row><cell>Model ↓ -Eval. →</cell><cell>Acc. (XS)</cell><cell>Acc. (S)</cell><cell>Acc. (M)</cell><cell>Acc. (L)</cell><cell>Acc. (XL)</cell><cell>AUC</cell></row><row><cell>Previous best published</cell><cell>55.4</cell><cell>62.4</cell><cell cols="2">RoBERTa 66.7 74.2</cell><cell>78.2</cell><cell>67.5</cell></row><row><cell>BARTlarge -FT</cell><cell>54.2</cell><cell>57.8</cell><cell>59.7</cell><cell>68.9</cell><cell>72.0</cell><cell>62.4</cell></row><row><cell>UnifiedQABART -FT</cell><cell>56.0</cell><cell>59.5</cell><cell>61.6</cell><cell>68.6</cell><cell>73.3</cell><cell>63.6</cell></row><row><cell>T5 -FT</cell><cell>75.6</cell><cell>79.8</cell><cell>86.4</cell><cell>90.3</cell><cell>90.2</cell><cell>84.8</cell></row><row><cell>UnifiedQAT5 -FT</cell><cell>78.8</cell><cell>83.4</cell><cell>86.9</cell><cell>88.5</cell><cell>89.4</cell><cell>85.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head>Table 10 :</head><label>10</label><figDesc>Extended results on the Winogrande dataset</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Future references to 'seed dataset' point to the QA datasets used in this section.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">The evaluation code is available at the URL in Footnote 1. 5 Appendix A.5 reports extended results, including the performance with various choices of X.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors would like to thank Collin Raffel, Adam Roberts, and Nicholas Lourie for their help with the T5 framework and for providing feedback on an earlier version of this work. The authors would like to acknowledge grants by ONR N00014-18-1-2826 and DARPA N66001-19-2-403, and gifts from the Sloan Foundation and the Allen Institute for AI. Moreover, the authors would like to thank members of the Allen Institute for AI, UW-NLP, and the H2Lab at the University of Wash-ington for their valuable feedback and comments. TPU machines for conducting experiments were provided by Google.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendices</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Datasets: Details</head><p>We evaluate our UNIFIEDQA on 19 existing datasets that target various formats, as well as various complex linguistic phenomena. <ref type="table">Table 2</ref> shows different properties for our datasets (whether it comes with a paragraph, whether the paragraph explicitly contains the answer, whether there are candidate-answers as part of the input, etc.) Most importantly, they are grouped into several formats/categories described below. <ref type="table">Table 2</ref> gives summary statistics of these datasets.</p><p>Extractive QA (EX). All the datasets in this format require models to extract the answer to a given question as a substring from a context paragraph. SQuAD 1.1 <ref type="bibr" target="#b41">(Rajpurkar et al., 2016)</ref> contains questions about Wikipedia paragraphs. A later version of this dataset, SQuAD 2 <ref type="bibr" target="#b40">(Rajpurkar et al., 2018)</ref>, includes unanswerable questions which empirically makes the task much harder. For our evaluation, we use the development sets of SQuAD 1.1 and SQuAD 2. NewsQA <ref type="bibr" target="#b50">(Trischler et al., 2017)</ref> dataset focuses on paraphrased questions with predicate-argument structure understanding collected from news articles from CNN/DailyMail articles. Quoref <ref type="bibr" target="#b10">(Dasigi et al., 2019)</ref> contains questions that require coreference resolution in Wikipedia articles and can even have disjoint spans as answers. ROPES <ref type="bibr" target="#b28">(Lin et al., 2019)</ref> centers around situation understanding, where the model must under the causes and effects implicit in the given situation.</p><p>Abstractive QA (AB). All the datasets in this format require models to produce answers that are often not mere substrings of the given context paragraph. NarrativeQA <ref type="bibr" target="#b21">(Kociský et al., 2018)</ref> focuses on understanding various events that happen in a given movie plot, based on summaries of their movie adaptations from various web resources. Many of the answers do not have high overlap with the context. DROP <ref type="bibr" target="#b13">(Dua et al., 2019b)</ref> contains questions that involve rudimentary mathematical skills (such as counting, addition, subtraction, maximum, minimum, etc.) and questions query multiple parts of the paragraph. The answer can be either a number or a date that can be inferred from the paragraph, or several spans from the context paragraph. Finally, we use an open-domain version of NaturalQuestions <ref type="bibr" target="#b22">(Kwiatkowski et al., 2019)</ref> where the paragraph that was used for creating the question is eliminated, and only the questions with short answers up to five tokens are taken. Instead, we follow  to use a DPR retrieval <ref type="bibr" target="#b16">(Karpukhin et al., 2020)</ref> engine to augment each question with an additional context paragraph. We call this dataset NatQA.</p><p>Multiple-choice QA (MC). All the datasets in this format contain questions that come with candidate answers. MCTest <ref type="bibr" target="#b42">(Richardson et al., 2013)</ref> contains questions about simple, fictional stories. RACE <ref type="bibr" target="#b23">(Lai et al., 2017)</ref> is a challenging set of English comprehension multiple choice exams given in Chinese middle and high schools. OpenBookQA <ref type="bibr" target="#b31">(Mihaylov et al., 2018)</ref>, ARC <ref type="bibr" target="#b9">(Clark et al., , 2016</ref>, QASC <ref type="bibr" target="#b20">(Khot et al., 2019)</ref> are different MC tests focusing on elementary/high school-style science exams. We use several othern datasets that are often framed as commonsense reasoning benchmarks: CommonsenseQA  is geared towards activity/concept questions, PIQA <ref type="bibr" target="#b2">(Bisk et al., 2020)</ref> addresses physical interaction reasoning, SIQA <ref type="bibr" target="#b46">(Sap et al., 2019)</ref> contains question that require social reasoning (motivations, reactions, event orders) and finally Winogrande <ref type="bibr" target="#b45">(Sakaguchi et al., 2020)</ref> which a benchmark for hard pronoun resolution problems <ref type="bibr">(Levesque et al., 2011;</ref><ref type="bibr" target="#b36">Peng et al., 2015)</ref>.</p><p>Other than MCTest and RACE, the rest of the datasets do not come with accompanying paragraphs. On such datasets, occasionally a retrieval system is used to supplement each question with a relevant retrieved context paragraph. For most of this the work, we keep the questions as is with no additional retrieval (unless otherwise mentioned), except in §6.3 where we use IR to get numbers comparable to earlier work. One other variability among these datasets is their number of candidate answers. While many datasets have four candidates (see <ref type="figure">Figure 2)</ref>, others have more. Later, in §6.2 we will see that our approach generalizes to datasets with different number of candidates, even if it's not seen during training.</p><p>Yes/No QA (YN). All the datasets in this format contain questions that could be responded with yes/no answers. One can think of these as multiple-choice questions with 2 candidates; however, they're usually treated differently. Several examples we use are BoolQ <ref type="bibr" target="#b4">(Clark et al., 2019a</ref>) and a version of this dataset</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Massively multilingual neural machine translation in the wild: Findings and challenges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naveen</forename><surname>Arivazhagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Bapna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Lepikhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melvin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mia</forename><forename type="middle">Xu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Knowledge fusion and semantic knowledge ranking for open domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pratyay</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chitta</forename><surname>Baral</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.03101</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Piqa: Reasoning about physical commonsense in natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rowan</forename><surname>Zellers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Ronan Le Bras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Multitask learning. Machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Caruana</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="41" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Boolq: Exploring the surprising difficulty of natural yes/no questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Urvashi</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">BAM! Born-again multi-task networks for natural language understanding</title>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<biblScope unit="page" from="5931" to="5937" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Think you have solved question answering? Try ARC, the AI2 reasoning challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isaac</forename><surname>Cowhey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carissa</forename><surname>Schoenick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<idno>abs/1803.05457</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">From &apos;F&apos; to &apos;A&apos; on the NY Regents science exams: An overview of the Aristo project</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyle</forename><surname>Bhavana Dalvi Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carissa</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oyvind</forename><surname>Schoenick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niket</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumithra</forename><surname>Tandon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bhakthavatsalam</surname></persName>
		</author>
		<idno>abs/1909.01958</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Combining retrieval, statistics, and inference to answer elementary science questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Etzioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Turney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Quoref: A reading comprehension dataset with questions requiring coreferential reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pradeep</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nelson</forename><forename type="middle">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ana</forename><surname>Marasović</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP/IJCNLP</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Comprehensive multi-dataset evaluation of reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dheeru</forename><surname>Dua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ananth</forename><surname>Gottumukkala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd Workshop on Machine Reading for Question Answering</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dheeru</forename><surname>Dua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pradeep</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Stanovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">MRQA 2019 shared task: Evaluating generalization in reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd Workshop on Machine Reading for Question Answering</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>at EMNLP</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Evaluating models&apos; local decision boundaries via contrast sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victoria</forename><surname>Basmova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Bogin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sihao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pradeep</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dheeru</forename><surname>Dua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanai</forename><surname>Elazar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ananth</forename><surname>Gottumukkala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP -Findings</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Dense passage retrieval for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barlas</forename><surname>Oguz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ledell</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Unifying question answering, text classification, and regression via span extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Nitish Shirish Keskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Socher</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.09286</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Looking beyond the surface: A challenge set for reading comprehension over multiple sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Snigdha</forename><surname>Chaturvedi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shyam</forename><surname>Upadhyay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">More bang for your buck: Natural perturbation for robust question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">QASC: A dataset for question answering via sentence composition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Guerquin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The narrativeqa reading comprehension challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomás</forename><surname>Kociský</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><forename type="middle">Moritz</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gábor</forename><surname>Melis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TACL</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="317" to="328" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennimaria</forename><surname>Palomaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivia</forename><surname>Redfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><forename type="middle">P</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danielle</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<title level="m">Natural questions: A benchmark for question answering research. TACL</title>
		<editor>Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov</editor>
		<meeting><address><addrLine>Kenton Lee</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="453" to="466" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">RACE: Large-scale reading comprehension dataset from examinations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guokun</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Albert: A lite bert for self-supervised learning of language representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenzhong</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingda</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piyush</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Ernest Davis, and Leora Morgenstern. 2011. The winograd schema challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hector</forename><forename type="middle">J</forename><surname>Levesque</surname></persName>
			<affiliation>
				<orgName type="collaboration">KR</orgName>
			</affiliation>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">BART: Denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal ; Abdelrahman Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ves</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">An information-theoretic approach to automatic evaluation of summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guihong</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Reasoning over paragraph effects in situations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd Workshop on Machine Reading for Question Answering</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>at EMNLP</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The natural language decathlon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Shirish Keskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.08730</idno>
	</analytic>
	<monogr>
		<title level="m">Multitask learning as question answering</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Can a suit of armor conduct electricity? a new dataset for open book question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todor</forename><surname>Mihaylov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tushar</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Sabharwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A discrete hard EM approach for weakly supervised question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP/IJCNLP</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">AmbigQA: Answering ambiguous open-domain questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Kuntal Kumar Pal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arindam</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pratyay</forename><surname>Banerjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Swaroop Mishra, and Chitta Baral. 2020. How additional knowledge can improve natural language commonsense question answering. arXiv: Computation and Language</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Answering while summarizing: Multi-task learning for multi-hop qa with evidence extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kosuke</forename><surname>Nishida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyosuke</forename><surname>Nishida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masaaki</forename><surname>Nagata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atsushi</forename><surname>Otsuka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Itsumi</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hisako</forename><surname>Asano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junji</forename><surname>Tomita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Solving hard coreference problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoruo</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="809" to="819" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OpenAI Blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter J</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Know what you don&apos;t know: Unanswerable questions for squad</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">SQuAD: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Mctest: A challenge dataset for the open-domain machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erin</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Renshaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">How much knowledge can you pack into the parameters of a language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Easy questions first? a case study on curriculum learning for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mrinmaya</forename><surname>Sachan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="453" to="463" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">WINOGRANDE: an adversarial winograd schema challenge at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keisuke</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Ronan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chandra</forename><surname>Bras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Social iqa: Commonsense reasoning about social interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannah</forename><surname>Rashkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Ronan Le Bras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-IJCNLP</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4453" to="4463" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A simple and effective model for answering multi-span questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Segal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avia</forename><surname>Efrat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mor</forename><surname>Shoham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Globerson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Multiqa: An empirical investigation of generalization and transfer in reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Commonsenseqa: A question answering challenge targeting commonsense knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Lourie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Newsqa: A machine comprehension dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingdi</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaheer</forename><surname>Suleman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Rep4NLP@ACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Retrospective reader for machine reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuosheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<idno>abs/2001.09694</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Freelb: Enhanced adversarial training for natural language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siqi</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Np (</forename><surname>Boolq</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Khashabi</surname></persName>
		</author>
		<title level="m">the subset of MultiRC</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>with natural-perturbations. that have binary(yes/no) answers</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">2020) for several of our datasets (denoted with</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gardner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Contrast-sets. Additionally, we use contrast-sets</title>
		<imprint/>
	</monogr>
	<note>These evaluation sets are expert. generated perturbations that deviate from the patterns common in the original dataset</note>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
				<title level="m">A.2 Details on the experiments: Below is several details on the experiments: • Models: we use two text-to-text frameworks: T5 and BART</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">• Model sizes: Most of the experiments are done on T5(11B) which has 11 billion parameters. We also report experiments with BART (large) with 440 million parameters</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">• Input/output size: For all experiments, we use token-limits of size 512 and 100 for inputs and outputs sequences</title>
		<imprint/>
	</monogr>
	<note>respectively</note>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">• # of iterations for pretraining on the seed datasets ( §3): All models are trained for 100k steps on the seed datasets</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
				<title level="m">• Learning rates: we use 1e-3 and 1e-5, for T5 and BART, following the original works on each framework</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">We use batches of 8 and 120, for the T5 (11B) and BART models, respectively. • Infrastructure: In the experiments, we use v3-8 TPUs for T5 models, and eight 32GB GPUs for BART models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Batch</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
				<title level="m">• Time spent to build UNIFIEDQA: pretraining UNIFIEDQA approximately takes about 36 and 55 hours, on T5(11B) and BART models</title>
		<imprint/>
	</monogr>
	<note>respectively</note>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Each model was fine-tuned for 60k steps and checkpoints were saved every 2k steps. The model with the highest score on the dev set is our selected model</title>
		<imprint/>
	</monogr>
	<note>): the only hyperparameter we iterated over is the training steps</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
