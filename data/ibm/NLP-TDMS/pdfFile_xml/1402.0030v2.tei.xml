<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Neural Variational Inference and Learning in Belief Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014-06-04">4 Jun 2014</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">AMNIH@GOOGLE.COM</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karol</forename><surname>Gregor</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">KAROLG@GOOGLE.COM Google DeepMind</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Neural Variational Inference and Learning in Belief Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2014-06-04">4 Jun 2014</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T22:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Highly expressive directed latent variable models, such as sigmoid belief networks, are difficult to train on large datasets because exact inference in them is intractable and none of the approximate inference methods that have been applied to them scale well. We propose a fast non-iterative approximate inference method that uses a feedforward network to implement efficient exact sampling from the variational posterior. The model and this inference network are trained jointly by maximizing a variational lower bound on the log-likelihood. Although the naive estimator of the inference network gradient is too high-variance to be useful, we make it practical by applying several straightforward modelindependent variance reduction techniques. Applying our approach to training sigmoid belief networks and deep autoregressive networks, we show that it outperforms the wake-sleep algorithm on MNIST and achieves state-of-the-art results on the Reuters RCV1 document dataset.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Compared to powerful globally-normalized latent variable models, such as deep belief networks <ref type="bibr" target="#b8">(Hinton et al., 2006)</ref> and deep Boltzmann machines <ref type="bibr" target="#b18">(Salakhutdinov &amp; Hinton, 2009a)</ref>, which can now be trained on fairly large datasets, their purely directed counterparts have been left behind due to the lack of efficient learning algorithms. This is unfortunate, because their modularity and ability to generate observations efficiently make them better suited for integration into larger systems.</p><p>Training highly expressive directed latent variable models on large datasets is a challenging problem due to the difficulties posed by inference. Although the generality of Markov Chain Monte Carlo (MCMC) methods makes them straightforward to apply to models of this type <ref type="bibr" target="#b14">(Neal, 1992)</ref>, they tend to suffer from slow mixing and are usually too computationally expensive to be practical in all but the simplest models. Such methods are also difficult to scale to large datasets because they need to store the current state of the latent variables for all the training observations between parameter updates.</p><p>Variational methods <ref type="bibr" target="#b9">(Jordan et al., 1999)</ref> provide an optimization-based alternative to the sampling-based Monte Carlo methods, and tend to be more efficient. They involve approximating the exact posterior using a distribution from a more tractable family, often a fully factored one, by maximizing a variational lower bound on the loglikelihood w.r.t. the parameters of the distribution. For a small class of models, using such variational posteriors allows the expectations that specify the parameter updates to be computed analytically. However, for highly expressive models such as the ones we are interested in, these expectations are intractable even with the simplest variational posteriors. This difficulty is usually dealt with by lower bounding the intractable expectations with tractable one by introducing more variational parameters, as was done for sigmoid belief nets by <ref type="bibr" target="#b22">Saul et al. (1996)</ref>. However, this technique increases the gap between the bound being optimized and the log-likelihood, potentially resulting in a poorer fit to the data. In general, variational methods tend to be more model-dependent than sampling-based methods, often requiring non-trivial model-specific derivations.</p><p>We propose a new approach to training directed graphical models that combines the advantages of the samplingbased and variational methods. Its central idea is using a feedforward network to implement efficient exact sampling from the variational posterior for the given observation. We train this inference network jointly with the model by maximizing the variational lower bound on the log-likelihood, estimating all the required gradients using samples from the inference network. Although naive estimate of the gradient for the inference network parameters is unusable due to its high variance, we make the approach practical by applying several straightforward and general variance reduc-tion techniques. The resulting training procedure for the inference network can be seen as an instance of the RE-INFORCE algorithm <ref type="bibr" target="#b25">(Williams, 1992)</ref>. Due to our use of stochastic feedforward networks for performing inference we call our approach Neural Variational Inference and Learning (NVIL).</p><p>Compared to MCMC methods, where many iterations over the latent variables are required to generate a sample from the exact posterior and successive samples tend to be highly correlated, NVIL does not suffer from mixing issues as each forward pass through the inference network generates an independent exact sample from the variational posterior. In addition to being much faster than MCMC, our approach has the additional advantage of not needing to store the latent variables for each observation and thus is not only more memory efficient but also applicable to the pure online learning setting, where each training case is seen once before being discarded.</p><p>In contrast to other work on scaling up variational inference, NVIL can handle both discrete and continuous latent variables (unlike <ref type="bibr" target="#b11">Kingma &amp; Welling (2013)</ref>; <ref type="bibr" target="#b17">Rezende et al. (2014)</ref>) as well variational posteriors with complex dependency structures (unlike <ref type="bibr" target="#b16">Ranganath et al. (2013)</ref>). Moreover, the variance reduction methods we employ are simple and model-independent, unlike the more sophisticated model-specific control variates of <ref type="bibr" target="#b15">Paisley et al. (2012)</ref>.</p><p>Though the idea of training an inference model by following the gradient of the variational bound has been considered before, it was dismissed as infeasible <ref type="bibr" target="#b1">(Dayan &amp; Hinton, 1996)</ref>. Our primary contribution is to show how to reduce the variance of the naive gradient estimator to make it practical without narrowing its range of applicability. We also show that the resulting method trains sigmoid belief networks better than the wake-sleep algorithm , which is the only algorithm we are aware of that is capable of training the same range of models efficiently. Finally, we demonstrate the effectiveness and scalability of NVIL by using it to achieve stateof-the-art results on the Reuters RCV1 document dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Neural variational inference and learning</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Variational objective</head><p>Suppose we are interested in training a latent variable model P θ (x, h) with parameters θ. We assume that exact inference in the model is intractable and thus maximum likelihood learning is not an option. For simplicity, we will also assume that all the latent variables in the model are discrete, though essentially the same approach applies if some or all of the variables are continuous.</p><p>We will train the model by maximizing a variational lower bound on the marginal log-likelihood. Following the standard variational inference approach <ref type="bibr" target="#b9">(Jordan et al., 1999)</ref>, given an observation x, we introduce a distribution Q φ (h|x) with parameters φ, which will serve as an approximation to its exact posterior P θ (h|x). The variational posterior Q will have a simpler form than the exact posterior and thus will be easier to work with.</p><p>The contribution of x to the log-likelihood can then be lower-bounded as follows <ref type="bibr" target="#b9">(Jordan et al., 1999)</ref>:</p><formula xml:id="formula_0">log P θ (x) = log h P θ (x, h) ≥ h Q φ (h|x) log P θ (x, h) Q φ (h|x) = E Q [log P θ (x, h) − log Q φ (h|x)] (1) = L(x, θ, φ).</formula><p>By rewriting the bound as</p><formula xml:id="formula_1">L(x, θ, φ) = log P θ (x) − KL(Q φ (h|x), P θ (h|x)),<label>(2)</label></formula><p>we see that its tightness is determined by the Kullback-Leibler (KL) divergence between the variational distribution and the exact posterior. Maximizing the bound with respect to the parameters φ of the variational distribution makes the distribution a better approximation to the posterior (w.r.t. the KL-divergence) and tightens the bound.</p><p>In contrast to most applications of variational inference where the variational posterior for each observation is defined using its own set of variational parameters, our approach does not use any local variational parameters. Instead, we use a flexible feedforward model to compute the variational distribution from the observation. We call the model mapping x to Q φ (h|x) the inference network. The architecture of the inference network is constrained only by the requirement that Q φ (h|x) it defines has to be efficient to evaluate and sample from. Using samples from the inference network we will be able to compute gradient estimates for the model and inference network parameters for a large class of highly expressive architectures, without having to deal with architecture-specific approximations.</p><p>Given a training set D, consisting of observations x 1 , ..., x D , we train the model by (locally) maximizing L(D, θ, φ) = i L(x i , θ, φ) using gradient ascent w.r.t. to the model and inference network parameters. To ensure scalability to large datasets, we will perform stochastic optimization by estimating gradients on small minibatches of randomly sampled training cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Parameter gradients</head><p>The gradient of the variational bound for a single observation x w.r.t. to the model parameters is straightforward to derive and has the form</p><formula xml:id="formula_2">∇ θ L(x) = E Q [∇ θ log P θ (x, h)] ,<label>(3)</label></formula><p>where we left θ and φ off the list of the arguments of L to simplify the notation. The corresponding gradient w.r.t. to the inference network parameters is somewhat more involved:</p><formula xml:id="formula_3">∇ φ L(x) = E Q [(log P θ (x, h) − log Q φ (h|x)) × ∇ φ log Q φ (h|x)],<label>(4)</label></formula><p>We give its derivation in the supplementary material.</p><p>As both gradients involve expectations which are intractable in all but a handful of special cases, we will estimate them with Monte Carlo integration, using samples from the inference network. Having generated n samples</p><formula xml:id="formula_4">h (1) , ..., h (n) from Q φ (h|x), we compute ∇ θ L(x) ≈ 1 n n i=1 ∇ θ log P θ (x, h (i) )<label>(5)</label></formula><p>and</p><formula xml:id="formula_5">∇ φ L(x) ≈ 1 n n i=1 (log P θ (x, h (i) ) − log Q φ (h (i) |x)) × ∇ φ log Q φ (h (i) |x).<label>(6)</label></formula><p>The above gradient estimators are unbiased and thus can be used to perform stochastic maximization of the variational objective using a suitable learning rate annealing schedule. The speed of convergence of this procedure, however, depends heavily on the variance of the estimators used, as we will see in Section 4.2.</p><p>The model gradient estimator <ref type="formula" target="#formula_4">(5)</ref> is well-behaved and does not pose a problem. The variance of the inference network gradient estimator <ref type="formula" target="#formula_5">(6)</ref>, however, can be very high due to the scaling of the gradient inside the expectation by a potentially large term. As a result, learning variational parameters with updates based on this estimator can be unacceptably slow. In fact, it is widely believed that learning variational parameters using gradient estimators of the form (6) is infeasible <ref type="bibr" target="#b6">(Hinton &amp; Zemel, 1994;</ref><ref type="bibr" target="#b1">Dayan &amp; Hinton, 1996;</ref><ref type="bibr" target="#b11">Kingma &amp; Welling, 2013)</ref>. In the next section we will show how to make this approach practical by applying variance reduction techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Variance reduction techniques</head><p>Though gradient estimates computed using Eq. 6 are usually too noisy to be useful in practice, it is easy to reduce their variance to a manageable level with the following model-independent techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1.">CENTERING THE LEARNING SIGNAL</head><p>Inspecting Eq. 4, we see that we are using</p><formula xml:id="formula_6">l φ (x, h) = log P θ (x, h) − log Q φ (h|x)<label>(7)</label></formula><p>as the learning signal for the inference network parameters, and thus are effectively fitting log Q φ (h|x) to log P θ (x, h). This might seem surprising, given that we want the inference network Q φ (h|x) to approximate the posterior distribution P θ (x|h), as opposed to the joint distribution P θ (x, h). It turns out however that using the joint instead of the posterior distribution in Eq. 4 does not affect the value of the expectation. To see that we start by noting that</p><formula xml:id="formula_7">E Q [∇ φ log Q φ (h|x)] = E Q ∇ φ Q φ (h|x) Q φ (h|x) = ∇ φ E Q [1] = 0.<label>(8)</label></formula><p>Therefore we can subtract any c that does not depend on h from the learning signal in Eq. 4 without affecting the value of the expectation:</p><formula xml:id="formula_8">E Q [(l φ (x, h) − c)∇ φ log Q φ (h|x)] = E Q [l φ (x, h)∇ φ log Q φ (h|x)] − cE Q [∇ φ log Q φ (h|x)] = E Q [l φ (x, h)∇ φ log Q φ (h|x)].<label>(9)</label></formula><p>And as log P θ (x, h) = log P θ (h|x) + log P θ (x) and log P θ (x) does not depend on h, using P θ (h|x) in Eq. 4 in place of P θ (x, h) does not affect the value of the expectation.</p><p>This equivalence allows us to compute the learning signal efficiently, without having to evaluate the intractable P θ (h|x) term. The price we pay for this tractability is the much higher variance of the estimates computed using Eq. 6. Fortunately, Eq. 9 suggests that we can reduce the variance by subtracting a carefully chosen c from the learning signal. The simplest option is to make c a parameter and adapt it as learning progresses. However, c will not be able capture the systematic differences in the learning signal for different observations x, which arise in part due to the presence of the log P θ (x) term. Thus we can reduce the gradient variance further by subtracting an observation-dependent term C ψ (x) to minimize those differences. Doing this does not affect the expected value of the gradient estimator because C ψ (x) does not depend on the latent variables. Borrowing a name from the reinforcement learning literature we will refer to c and C ψ (x) as baselines. We will elaborate on this connection in Section 3.4.</p><p>We implement the input-dependent baseline C ψ (x) using a neural network and train it to minimize the expected square of the centered learning signal</p><formula xml:id="formula_9">E Q [(l φ (x, h)−C ψ (x)−c) 2 ].</formula><p>Though this approach to fitting the baseline does not result in the maximal variance reduction, it is simpler and in our experience works as well as the optimal approach of <ref type="bibr" target="#b24">Weaver &amp; Tao (2001)</ref> which requires taking into account the magnitude of the gradient of the inference network parameters. We also experimented with per-parameter baselines but found that they did not improve on the global ones. Finally, we note that incorporating baselines into the learning signal can be seen as using simple control variates.</p><p>In contrast to the more elaborate control variates (e.g. of <ref type="bibr" target="#b15">Paisley et al. (2012)</ref>), baselines do not depend on the form of the model or of the variational distribution and thus are easier to use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2.">VARIANCE NORMALIZATION</head><p>Even after centering, using l φ (x, h) as the learning signal is non-trivial as its average magnitude can change dramatically, and not necessarily monotonically, as training progresses. This variability makes training an inference network using a fixed learning rate difficult. We address this issue by dividing the centered learning signal by a running estimate of its standard deviation. This normalization ensures that the signal is approximately unit variance, and can be seen as a simple and efficient way of adapting the learning rate. To ensure that we stop learning when the magnitude of the signal approaches zero, we apply variance normalization only when the estimate of the standard deviation is greater than 1. The algorithm for computing NVIL parameter updates using the variance reduction techniques described so far is provided in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3.">LOCAL LEARNING SIGNALS</head><p>So far we made no assumptions about the structure of the model or the inference network. However, by taking advantage of their conditional independence properties we can train the inference network using simpler and less noisy local learning signals instead of the monolithic global learning signal l φ (x, h). Our approach to deriving a local signal for a set of parameters involves removing all the terms from the global signal that do not affect the value of the resulting gradient estimator.</p><p>We will derive the layer-specific learning signals for the common case of both the model and the inference network having n layers of latent variables. The model and the variational posterior distributions then naturally factor as</p><formula xml:id="formula_10">P θ (x, h) =P θ (x|h 1 ) n−1 i=1 P θ (h i |h i+1 )P θ (h n ), (10) Q φ (h|x) =Q φ 1 (h 1 |x) n−1 i=1 Q φ i+1 (h i+1 |h i ),<label>(11)</label></formula><p>where h i denotes the latent variables in the i th layer and φ i the parameters of the variational distribution for that layer. We will also use h i:j to denote the latent variables in layers i through j.</p><p>To learn the parameters of the the variational distribution for layer i , we need to compute the following gradient:</p><formula xml:id="formula_11">∇ φi L(x) = E Q(h|x) [l φ (x, h)∇ φi log Q φi (h i |h i−1 )].</formula><p>Using the law of iterated expectation we can rewrite the expectation w.r.t. Q(h|x) as</p><formula xml:id="formula_12">∇ φi L(x) = E Q(h 1:i−1 |x) [ E Q(h i:n |h i−1 ) [l φ (x, h)∇ φi log Q φi (h i |h i−1 )]|h i−1 ]],</formula><p>where we also used the fact that under the variational posterior, h i:n is independent of h 1:i−2 and x, given h i−1 . As a consequence of Eq. 9, when computing the expectation w.r.t. Q(h i:n |h i−1 ), all the terms in the learning signal that do not depend on h i:n can be safely dropped without affecting the result. This gives us the following local learning signal for layer i:</p><formula xml:id="formula_13">l i φ (x, h) = log P θ (h i−1:n ) − log Q φ (h i:n |h i−1 )</formula><p>. <ref type="formula" target="#formula_1">(12)</ref> To get the signal for the first hidden layer we simply use x in place of h 0 , in which case we simply recover the global learning signal. For hidden layers i &gt; 1, however, the local signal involves fewer terms than l φ (x, h) and thus can be expected to be less noisy. As we do not assume any withinlayer structure, Eq. 12 applies to models and inference networks whether or not Q φ (h i |h i−1 ) and P θ (h i |h i+1 ) are factorial.</p><p>Since local signals can be significantly different from each other, we use separate baselines and variance estimates for each signal. For layers i &gt; 1, the input-dependent baseline C ψ (x) is replaced by C i ψi (h i−1 ). In some cases, further simplification of the learning signal is possible, yielding a different signal per latent variable. We leave exploring this as future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Related work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Feedforward approximations to inference</head><p>The idea of training an approximate inference network by optimizing a variational lower bound is not new. It goes back at least to <ref type="bibr" target="#b6">Hinton &amp; Zemel (1994)</ref>, who derived the variational objective from the Minimum Description Length (MDL) perspective and used it to train linear autoencoders. Their probabilistic encoder and decoder correspond to our inference network and model respectively. However, they computed the gradients analytically, which was possible due to the simplicity of their model, and dismissed the sampling-based approach as infeasible due to noise. <ref type="bibr" target="#b20">Salakhutdinov &amp; Larochelle (2010)</ref> proposed using a feedforward "recognition" model to perform efficient inputdependent initialization for the mean field inference algorithm in deep Boltzmann machines. As the recognition model is trained to match the marginal probabilities produced by mean field inference, it inherits the limitations of the inference procedure, such as the inability to model structured posteriors. In contrast, in NVIL the inference net is trained to match the true posterior directly, without involving an approximate inference algorithm, and thus the accuracy of the fit is limited only by the expressiveness of the inference network itself.</p><p>Recently a method for training nonlinear models with continuous latent variables, called Stochastic Gradient Variational Bayes (SGVB), has been proposed by <ref type="bibr" target="#b11">Kingma &amp; Welling (2013)</ref> and <ref type="bibr" target="#b17">Rezende et al. (2014)</ref>. Like NVIL, it involves using feedforward models to perform approximate inference and trains them by optimizing a sampling-based estimate of the variational bound on the log-likelihood. However, SGVB is considerably less general than NVIL, because it uses a gradient estimator obtained by taking advantage of special properties of realvalued random variables and thus is not applicable to models with discrete random variables. Moreover, unlike NVIL, SGVB method cannot handle inference networks with nonlinear dependencies between latent variables. The ideas of the two methods are complementary however, and NVIL is likely to benefit from the SGVB-style treatment of continuous-valued variables, while SGVB might converge faster using the variance reduction techniques we proposed. <ref type="bibr" target="#b5">Gregor et al. (2013)</ref> have recently proposed a related algorithm for training sigmoid belief network like models based on the MDL framework. They also use a feedforward model to perform approximate inference, but concentrate on the case of a deterministic inference network and can handle only binary latent variables. The inference network is trained by backpropagating through binary thresholding units, ignoring the thresholding nonlinearities, to approximately minimize the coding cost of the joint latentvisible configurations. This approach can be seen as approximately maximizing a looser variational lower bound than (2) due to the absence of the entropy term.</p><p>An inference network for efficient generation of samples from the approximate posterior can also be seen as a probabilistic generalization of the approximate feedforward inference methods developed for sparse coding models in the last few years <ref type="bibr" target="#b10">(Kavukcuoglu et al., 2008;</ref><ref type="bibr" target="#b0">Bradley &amp; Bagnell, 2008;</ref><ref type="bibr" target="#b4">Gregor &amp; LeCun, 2010)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Sampling-based variational inference</head><p>Like NVIL, Black Box Variational Inference (BBVI, <ref type="bibr" target="#b16">Ranganath et al., 2013)</ref> learns the variational parameters of the posterior by optimizing the variational bound using sampling-based gradient estimates, which makes it applicable to a large range of models. However, unlike NVIL, BBVI follows the traditional approach of learning a sepa-rate set of variational parameters for each observation and does not use an inference network. Moreover, BBVI uses a fully-factorized mean field approximation to the posterior, which limits its power.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">The wake-sleep algorithm</head><p>NVIL shares many similarities with the wake-sleep algorithm , which enjoys the same scalability and applicability to a wide range of models. This algorithm was introduced for training Helmholtz machines , which are multi-layer belief networks augmented with recognition networks. These recognition networks are used for approximate inference and are directly analogous to NVIL inference networks. Wake-sleep alternates between updating the model parameters in the wake phase and the recognition network parameters in the sleep phase. The model parameter update is based on the samples generated from the recognition network on the training data and is identical to the NVIL one (Eq. 5). However, in contrast to NVIL, the recognition network parameters are learned from samples generated by the model. In other words, the recognition network is trained to recover the hidden causes corresponding to the samples from the model distribution by following the gradient</p><formula xml:id="formula_14">∇ φ L(x) = E P θ (x,h) [∇ φ log Q φ (h|x)] .<label>(13)</label></formula><p>Unfortunately, this update does not optimize the same objective as the model parameter update, which means that the wake-sleep algorithm does not optimize a well-defined objective function and is not guaranteed to converge. This is the algorithm's main weakness, compared to NVIL, which optimizes a variational lower bound on the loglikelihood.</p><p>The wake-sleep gradient for recognition network parameters does have the advantage of being much easier to estimate than the corresponding gradient of the variational bound. In fact, the idea of training the recognition networks using the gradient of the bound was mentioned in <ref type="bibr" target="#b6">(Hinton &amp; Zemel, 1994)</ref> and <ref type="bibr" target="#b1">(Dayan &amp; Hinton, 1996)</ref> but not seriously considered due concerns about the high variance of the estimates. In Section 4.2 we show that while the naive estimator of the gradient given in Eq. 6 does exhibit high variance, the variance reduction techniques from Section 2.3 improve it dramatically and make it practical.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">REINFORCE</head><p>Using the gradient (4) to train the inference network can be seen as an instance of the REINFORCE algorithm <ref type="bibr" target="#b25">(Williams, 1992)</ref> from reinforcement learning (RL), which adapts the parameters of a stochastic model to maximize the external reward signal which depends on the model's output. Given a model P θ (x) and a reward signal r(x), REINFORCE updates the model parameters using the rule</p><formula xml:id="formula_15">∆θ ∝ E P [(r(x) − b)∇ θ log P θ (x)].<label>(14)</label></formula><p>We can view NVIL as an application of REINFORCE on the per-training-case basis, with the inference network corresponding to the stochastic model, latent state h to the output, and the learning signal l φ (x, h) to the reward. The term b in Eq. 14, called a baseline in the RL literature, is a hyperparameter that can be adapted to reduce the variance of the parameter update. Thus it serves the same function as c and C ψ (x) that we subtract from the learning signal to center it in Section 2.3.1. The considerable body of work on baselines and other variance reduction methods done in the RL community (e.g. <ref type="bibr" target="#b3">Greensmith et al., 2004)</ref> is likely to contain additional techniques relevant for training inference networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental results</head><p>We performed two sets of experiments, with the first set intended to evaluate the effectiveness of our variance reduction techniques and to compare NVIL's performance to that of the wake-sleep algorithm. In the second set of experiments, we demonstrate NVIL's ability to handle larger real-world datasets by using it to train generative models of documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental protocol</head><p>We trained all models using stochastic gradient ascent using minibatches of 20 observations sampled randomly from the training data. The gradient estimates were computed using a single sample from the inference network. For each dataset, we created a validation set by removing a random subset of 100 observations from the training set. The only form of regularization we used was early stopping based on the validation bound, implemented by keeping track of the parameter configuration with the best validation score seen so far. We implemented each input-dependent baseline using a neural network with a single hidden layer of 100 tanh units.</p><p>We used fixed learning rates because we found them to produce superior results to the annealing schedules we experimented with. The learning rates we report were selected based on the validation set performance in preliminary experiments with smaller models. We always make the learning rate for inference network five times smaller than for the model (which is the one we report), as we found this to improve performance. We used inference networks with layered structure given by Eq. 11, without dependencies within each layer except in the experiment with autoregressive inference networks. All multi-layer inference networks were trained using layer-specific learning signals from Section 2.3.3.</p><p>As the models we train are intractable, we cannot compute the exact log-likelihoods for them. Instead we report the estimates of the variational bound (2) computed using 10 samples from the inference network, which we found to be sufficient to get the accurate bound estimates. We expect this approach to underestimate the log-likelihood considerably, but leave finding more direct and thus less pessimistic evaluation methods as future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Modelling images of digits</head><p>Our first set of experiments was performed on the binarized version of the MNIST dataset, which has become the standard benchmark for evaluating generative models of binary data. The dataset consists of 70,000 28 × 28 binary images of handwritten digits, partitioned into a 60,000-image training set and 10,000-image test set. We used the binarization of <ref type="bibr" target="#b21">Salakhutdinov &amp; Murray (2008)</ref>, which makes our scores directly comparable to those in the literature.</p><p>We used 3 × 10 −4 as the learning rate for training models with NVIL on this dataset. Centering the input vectors by subtracting the mean vector was essential for making the inference networks and input-dependent baselines work well.</p><p>To demonstrate the importance of variance reduction techniques, we trained two SBNs using a range of variance control settings. The first SBN had a single layer of 200 latent variables, while the second one had two layers of 200 variables each. <ref type="figure" target="#fig_1">Figure 1</ref> shows the estimate of the variational objective on the validation set plotted against the number of parameter updates. For both models, it is clear that using all three techniques -the input-dependent and inputindependent baselines along with variance normalizationis essential for best performance. However, of the three techniques, the input-dependent baseline appears to be the least important. Comparing the plots for the two models suggests that variance reduction becomes more important for larger models, with the gap between the best combination and the others (excluding the very worst one) widening. For both models, learning with all three variance reduction techniques disabled makes barely any progress and is clearly infeasible.</p><p>We found that disabling layer-specific learning signals had little effect on the performance of the resulting model. The difference was about 0.4 nats for an SBN with two or three layers of latent variables.</p><p>We next compared NVIL to the wake-sleep algorithm, which is its closest competitor in terms of scalability and breadth of applicability, by training a range of models using both algorithms. Wake-sleep training used a learning rate of 1 × 10 −4 , as we found this algorithm to be more sensitive to the choice of the learning rate than NVIL,   performing considerably better with lower learning rates. The results, along with some baselines from the literature, are shown in <ref type="table" target="#tab_1">Table 1</ref>. We report only the means of the bound estimates as their standard deviations were all very small, none exceeding 0.1 nat. We can see that models trained with NVIL have considerably better bounds on the log-likelihood, compared to their wake-sleep counterparts, with the difference ranging from 3.4 to 8.6 nats. Additional layers make SBNs perform better, independently of the training method. Interestingly, single-layer fDARN <ref type="bibr" target="#b5">(Gregor et al., 2013</ref>) models, which have autoregressive connections between the latent variables, perform better than any of the SBN models trained using the same algorithm. Comparing to results from the literature, we see that all the SBN and fDARN models we trained per-form much better than a mixture of 500 factorial Bernoulli distributions (MoB) but not as well as the deterministic Neural Autoregressive Distribution Estimator (NADE) <ref type="bibr" target="#b13">(Larochelle &amp; Murray, 2011)</ref>. The NVIL-trained fDARN models with 200 and 500 latent variables also outperform the fDARN (as well as the more expressive DARN) model with 400 latent variables from <ref type="bibr" target="#b5">(Gregor et al., 2013)</ref>, which were trained using an MDL-based algorithm. The fDARN and multi-layer SBN models trained using NVIL also outperform a 500-hidden-unit RBM trained with 3-step contrastive divergence (CD), but not the one trained with 25step CD <ref type="bibr" target="#b21">(Salakhutdinov &amp; Murray, 2008)</ref>. However, both sampling and CD-25 training in an RBM is considerably more expensive than sampling or NVIL training for any of our models.</p><p>The sampling-based approach to computing gradients allows NVIL to handle variational posteriors with complex dependencies. To demonstrate this ability, we retrained several of the SBN models using inference networks with autoregressive connections within each layer. These networks can capture the dependencies between variables within layers and thus are considerably more expressive than the ones with factorial layers. Results in <ref type="table" target="#tab_2">Table 2</ref> indicate that using inference networks with autoregressive connections produces better models, with the single-layer models exhibiting large gains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Document modelling</head><p>We also applied NVIL to the more practical task of document modelling. The goal is to train a generative model of documents which are represented as vectors of word counts, also known as bags of words. We trained two sim- We experimented with two simple document models, based on the SBN and DARN architectures. Both models had a single layer of latent variables and a multinomial visible layer and can be seen as directed counterparts of the Replicated Softmax model <ref type="bibr" target="#b19">(Salakhutdinov &amp; Hinton, 2009b)</ref>. We used the same training procedure as on MNIST with the exception of the learning rates which were 3 × 10 −5 on 20 Newsgroups and 10 −3 on RCV1.</p><p>The established evaluation metric for such models is the perplexity per word, computed as exp − 1 N n 1 Ln log P (x n ) , where N is the number of documents, L n is the length of document n, and P (x n ) the probability of the document under the model. As we cannot compute log P (x n ), we use the variational lower bound in its place and thus report an upper bound on perplexity.</p><p>The results for our models, along with ones for the Replicated Softmax and DocNADE models from <ref type="bibr" target="#b19">(Salakhutdinov &amp; Hinton, 2009b)</ref> and <ref type="bibr" target="#b12">(Larochelle &amp; Lauly, 2012)</ref> respectively, are shown in <ref type="table" target="#tab_3">Table 3</ref>. We can see that the SBN and fDARN models with 50 latent variables perform well, producing better scores than LDA and Replicated Softmax on both datasets. Their performance is also competitive with that of Doc-NADE on 20 Newsgroups. The score of 724 for fDARN with 50 latent variables on RCV1 is already better than DocNADE's 742, the best published result on that dataset. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Discussion and future work</head><p>We developed, NVIL, a new training method for intractable directed latent variable models which is general and easy to apply to new models. We showed that NVIL consistently outperforms the wake-sleep algorithm at training sigmoidbelief-network-like models. Finally, we demonstrated the potential of our approach by achieving state-of-the-art results on a sizable dataset of documents (Reuters RCV1).</p><p>As the emphasis of this paper is on the training method, we applied it to some of the simplest possible model and inference network architectures, which was sufficient to obtain promising results. We believe that considerable performance gains can be made by using more expressive architectures, such as those with nonlinearities between layers of stochastic variables. Applying NVIL to models with continuous latent variables is another promising direction since binary latent variables are not always appropriate.</p><p>We expect NVIL to be also applicable to training conditional latent variable models for modelling the distribution of observations given some context, which would require making the inference network take both the context and the observation as input. This would make it an alternative to the importance-sampling training method of <ref type="bibr" target="#b23">Tang &amp; Salakhutdinov (2013)</ref> for conditional models with structured high-dimensional outputs.</p><p>We hope that the generality and flexibility of our approach will make it easier to apply powerful directed latent variable models to real-world problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Algorithm for computing NVIL gradients</head><p>Algorithm 1 provides an outline of our implementation of NVIL gradient computation for a minibatch of n randomly chosen training cases. The exponential smoothing factor α used for updating the estimates of the mean c and variance v of the inference network learning signal was set to 0.8 in our experiments.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Proceedings of the 31 st International Conference on Machine Learning, Beijing, China, 2014. JMLR: W&amp;CP volume 32. Copyright 2014 by the author(s).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 .</head><label>1</label><figDesc>Bounds on the validation set log-likelihood for an SBN with (Left) one and (Right) two layers of 200 latent variables. Baseline and IDB refer to the input-independent and the input-dependent baselines respectively. VN is variance normalization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Results on the binarized MNIST dataset. "Dim" is the number of latent variables in each layer, starting with the deepest one. NVIL and WS refer to the models trained with NVIL and wake-sleep respectively. NLL is the negative log-likelihood for the tractable models and an estimate of it for the intractable ones.</figDesc><table><row><cell>MODEL</cell><cell>DIM</cell><cell cols="2">TEST NLL</cell></row><row><cell></cell><cell></cell><cell>NVIL</cell><cell>WS</cell></row><row><cell>SBN</cell><cell cols="3">200 113.1 120.8</cell></row><row><cell>SBN</cell><cell cols="3">500 112.8 121.4</cell></row><row><cell>SBN</cell><cell>200-200</cell><cell cols="2">99.8 107.7</cell></row><row><cell>SBN</cell><cell>200-200-200</cell><cell cols="2">96.7 102.2</cell></row><row><cell>SBN</cell><cell>200-200-500</cell><cell cols="2">97.0 102.3</cell></row><row><cell>FDARN</cell><cell>200</cell><cell>92.5</cell><cell>95.9</cell></row><row><cell>FDARN</cell><cell>500</cell><cell>90.7</cell><cell>97.2</cell></row><row><cell>FDARN</cell><cell>400</cell><cell>96.3</cell><cell></cell></row><row><cell>DARN</cell><cell>400</cell><cell>93.0</cell><cell></cell></row><row><cell>NADE</cell><cell>500</cell><cell>88.9</cell><cell></cell></row><row><cell>RBM (CD3)</cell><cell>500</cell><cell cols="2">105.5</cell></row><row><cell>RBM (CD25)</cell><cell>500</cell><cell>86.3</cell><cell></cell></row><row><cell>MOB</cell><cell>500</cell><cell cols="2">137.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>The effect of using autoregressive connections in the inference network. "Dim" is the number of latent variables in each layer, starting with the deepest one. "Test NLL" is an estimate of the lower bound on the log-likelihood on the MNIST test set. "Autoreg" and "Factorial" refer to using inference networks with and without autoregressive connections respectively.</figDesc><table><row><cell>MODEL</cell><cell>DIM</cell><cell>TEST NLL</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">AUTOREG FACTORIAL</cell></row><row><cell>SBN</cell><cell>200</cell><cell>103.8</cell><cell>113.1</cell></row><row><cell>SBN</cell><cell>500</cell><cell>104.4</cell><cell>112.8</cell></row><row><cell>SBN</cell><cell>200-200-200</cell><cell>94.5</cell><cell>96.7</cell></row><row><cell>SBN</cell><cell>200-200-500</cell><cell>96.0</cell><cell>97.0</cell></row><row><cell cols="4">ple models on the 20 Newsgroups and Reuters Corpus Vol-</cell></row><row><cell cols="4">ume I (RCV1-v2) datasets, which have been used to eval-</cell></row><row><cell cols="4">uate similar models in (Salakhutdinov &amp; Hinton, 2009b;</cell></row><row><cell cols="4">Larochelle &amp; Lauly, 2012). 20 Newsgroups is a fairly</cell></row><row><cell cols="4">small dataset of Usenet newsgroup posts, consisting of</cell></row><row><cell cols="4">about 11K training and 7.5K test documents. RCV1 is</cell></row><row><cell cols="4">a much larger dataset of Reuters newswire articles, with</cell></row><row><cell cols="4">about 794.4K training and 10K test documents. We use</cell></row><row><cell cols="4">the standard preprocessed versions of the datasets from</cell></row><row><cell cols="4">Salakhutdinov &amp; Hinton (2009b), which have vocabularies</cell></row><row><cell cols="3">of 2K and 10K words respectively.</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Document modelling results. "Dim" is the number of latent variables in the model. The third and the fourth columns report the estimated test set perplexity on the 20 Newsgroups and Reuters RCV1 datasets respectively.</figDesc><table><row><cell>MODEL</cell><cell cols="3">DIM 20 NEWS REUTERS</cell></row><row><cell>SBN</cell><cell>50</cell><cell>909</cell><cell>784</cell></row><row><cell>FDARN</cell><cell>50</cell><cell>917</cell><cell>724</cell></row><row><cell>FDARN</cell><cell>200</cell><cell></cell><cell>598</cell></row><row><cell>LDA</cell><cell>50</cell><cell>1091</cell><cell>1437</cell></row><row><cell>LDA</cell><cell>200</cell><cell>1058</cell><cell>1142</cell></row><row><cell>REPSOFTMAX</cell><cell>50</cell><cell>953</cell><cell>988</cell></row><row><cell>DOCNADE</cell><cell>50</cell><cell>896</cell><cell>742</cell></row><row><cell cols="4">fDARN with 200 hidden units, however, performs even</cell></row><row><cell cols="3">better, setting a new record with 598.</cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>We thank Koray Kavukcuoglu, Volodymyr Mnih, and Nicolas Heess for their helpful comments. We thank Ruslan Salakhutdinov for providing us with the preprocessed document datasets.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Algorithm 1 Compute gradient estimates for the model and the inference network ∆θ ← 0, ∆φ ← 0, ∆ψ ← 0 L ← 0 {Compute the learning signal and the bound} for i ← 1 to n do</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Inference network gradient derivation</head><p>Differentiating the variational lower bound w.r.t. to the inference network parameters gives</p><p>where we used the fact that</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Differential sparse coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bagnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Andrew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">20</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Varieties of helmholtz machine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1385" to="1403" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The helmholtz machine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Neal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zemel</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="889" to="904" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Variance reduction techniques for gradient estimates in reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Greensmith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">L</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Baxter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1471" to="1530" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning fast approximations of sparse coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karol</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Machine learning (ICML&apos;10)</title>
		<meeting>International Conference on Machine learning (ICML&apos;10)</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karol</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1310.8499</idno>
		<title level="m">Deep autoregressive networks</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Autoencoders, minimum description length, and Helmholtz free energy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The &quot;wake-sleep&quot; algorithm for unsupervised neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Frey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Brendan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neal</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">268</biblScope>
			<biblScope unit="issue">5214</biblScope>
			<biblScope unit="page" from="1158" to="1161" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A fast learning algorithm for deep belief nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Whye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1527" to="1554" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An introduction to variational methods for graphical models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zoubin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommi</forename><forename type="middle">S</forename><surname>Jaakkola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><forename type="middle">K</forename><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="183" to="233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Fast inference in sparse coding algorithms with applications to object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Marc&amp;apos;aurelio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
		<respStmt>
			<orgName>Courant Institute, NYU</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<title level="m">Auto-encoding variational bayes</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A neural autoregressive topic model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislas</forename><surname>Lauly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2717" to="2725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The neural autoregressive distribution estimator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iain</forename><surname>Murray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR: W&amp;CP</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="29" to="37" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Connectionist learning of belief networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Neal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Radford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial intelligence</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="113" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Variational bayesian inference with stochastic search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Paisley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajesh</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Gerrish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1401.0118</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">Black box variational inference. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Stochastic back-propagation and variational inference in deep latent gaussian models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jimenez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shakir</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1401.4082</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="448" to="455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Replicated softmax: an undirected topic model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Efficient learning of deep boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="693" to="700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">On the quantitative analysis of Deep Belief Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iain</forename><surname>Murray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Annual International Conference on Machine Learning</title>
		<meeting>the 25th Annual International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Mean field theory for sigmoid belief networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><forename type="middle">K</forename><surname>Saul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommi</forename><surname>Jaakkola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="61" to="76" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning stochastic feedforward neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichuan</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The optimal reward baseline for gradient-based reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lex</forename><surname>Weaver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nigel</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence</title>
		<meeting>the Seventeenth Conference on Uncertainty in Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Simple statistical gradient-following algorithms for connectionist reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="229" to="256" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
