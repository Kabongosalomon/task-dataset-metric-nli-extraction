<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING 1 Subgraph Networks with Application to Structural Feature Space Expansion</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Qi</forename><surname>Xuan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinhuan</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghao</forename><surname>Zhao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junkun</forename><surname>Yuan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenbo</forename><surname>Fu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyuan</forename><surname>Ruan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Fellow, IEEE</roleName><forename type="first">Guanrong</forename><surname>Chen</surname></persName>
						</author>
						<title level="a" type="main">IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING 1 Subgraph Networks with Application to Structural Feature Space Expansion</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/TKDE.2019.2957755</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T21:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-subgraph</term>
					<term>motif</term>
					<term>network classification</term>
					<term>structural feature</term>
					<term>learning algorithm</term>
					<term>biological network</term>
					<term>social network !</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Real-world networks exhibit prominent hierarchical and modular structures, with various subgraphs as building blocks. Most existing studies simply consider distinct subgraphs as motifs and use only their numbers to characterize the underlying network. Although such statistics can be used to describe a network model, or even to design some network algorithms, the role of subgraphs in such applications can be further explored so as to improve the results. In this paper, the concept of subgraph network (SGN) is introduced and then applied to network models, with algorithms designed for constructing the 1st-order and 2nd-order SGNs, which can be easily extended to build higher-order ones. Furthermore, these SGNs are used to expand the structural feature space of the underlying network, beneficial for network classification. Numerical experiments demonstrate that the network classification model based on the structural features of the original network together with the 1st-order and 2nd-order SGNs always performs the best as compared to the models based only on one or two of such networks. In other words, the structural features of SGNs can complement that of the original network for better network classification, regardless of the feature extraction method used, such as the handcrafted, network embedding and kernel-based methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>indeed provide unique insights for identifying both social structure and graph structure in a large network. Similarly, Vohra <ref type="bibr" target="#b10">[12]</ref> summarized the network by stacking subgraph frequencies into a vector as a global network property and then classified networks into different groups, where these frequency statistics are implemented through two schemes <ref type="bibr" target="#b9">[11]</ref>, <ref type="bibr" target="#b11">[13]</ref>. Moreover, in the study of biological networks, Grochow et al. <ref type="bibr" target="#b12">[14]</ref> proposed a novel algorithm for identifying larger network elements and functional motifs, revealing the clustering properties of motifs through subgraph enumeration and symmetry-breaking. Without any interaction dependencies between them, these studies simply acquired a sequence of discrete motif entities with feature information such as counting, weight, etc. to describe the underlying network. Except for subgraph frequency statistics, Benson et al. <ref type="bibr" target="#b13">[15]</ref> obtained the corresponding embedding representation through laplacian matrix analysis method. Moreover, in <ref type="bibr" target="#b14">[16]</ref>, an incremental subgraph join feature selection algorithm was designed, which forces graph classifiers to join short-pattern subgraphs so as to generate long-pattern subgraph features. Similarly, Yang et al. <ref type="bibr" target="#b15">[17]</ref> proposed the NEST method which combined the motifs and convolutional neural network.</p><p>The studies mentioned above try to reveal subgraphlevel patterns, which can be considered as network building blocks of particular functions, to capture mesoscopic structure. However, most of them ignored the interaction between these subgraphs, which could be of particular importance to represent the global structure of subgraphlevel. In order to address this, we propose a method to establish Subgraph Networks (SGNs) of different orders. It can be expected that such SGNs can capture the structural features of different aspects and thus may benefit the followup tasks, such as network classification. Briefly, there are arXiv:1903.09022v3 [cs.SI] 15 Dec 2019 three steps to build an SGN from an original network: first, detect subgraphs in the original network; second, choose appropriate subgraphs for a task; third, utilize the chosen subgraphs to build an SGN. Line graph <ref type="bibr" target="#b16">[18]</ref> thus can be considered as a special SGN, where a link connecting two nodes in the original network is considered as a subgraph, and two subgraphs are connected in the SGN if the corresponding two links share a same terminal node. Clearly more complicated subgraphs can be considered, e.g., three nodes with two links, so as to get a higher-order SGN, as will be further discussed in Sec. <ref type="bibr" target="#b2">3</ref>. The key point here is that the SGN extracts the representative parts of the original network and then assembles them to reconstruct a new network that preserves the relationship among subgraphs. Our method thus implicitly maintains the higher-order structures under the premise of providing the information of local structures. And, the network structure of SGN can complement the original network and, as a result, the integration of their features will benefit the subsequent structure-based algorithms design and applications.</p><p>The main contributions of this work are summarized as follows.</p><p>• A new concept of SGN is introduced, along with algorithms designed for constructing the 1st-order and 2nd-order SGNs from a given network. These algorithms can be easily extended to construct higherorder SGNs.</p><p>• SGN is used to obtain a series of handcrafted structural features which, together with the features automatically extracted by using some advanced network-embedding methods, kernel-based methods and depth model, provide complementary features to those extracted from the original network.</p><p>• SGN is applied to network classification. Experiments on seven groups of networks are carried out, showing that integrating the features obtained from SGN can indeed significantly improve the classification accuracy in most cases, as compared to the same feature extraction and classification methods based only on the original networks.</p><p>The rest of the paper is organized as follows. In Sec. 2, some related work about subgraph and network representation methods are briefly introduced. In Sec. 3, the definition of SGN is provided and algorithms for constructing the 1st-order and 2nd-order SGNs are designed. In Sec. 4, handcrafted structural features are characterized, for both the original network and SGNs. In Sec. 5, several automatic feature extraction methods are discussed, whereas SGNs are applied to graph classification for some real-world networks. Finally, Sec. 6 concludes the investigation, with a future research outlook.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>In this section, we review the related work of subgraph in graph mining applications and the network representation methods combined with depth models in recent years.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Subgraph in Graph Mining</head><p>Recently, subgraphs have been widely applied in the study between entities in networks. For example, in [19]- <ref type="bibr" target="#b19">[21]</ref>, different algorithms were designed for detecting network subgraphs. In <ref type="bibr" target="#b20">[22]</ref>, a method for detecting strong ties was proposed using frequent subgraphs in a social network, where it was observed that frequent subgraphs as network structural features could lead to good performances in alleviating the sparse problem for detecting strong ties on the network. By adding time stamp to the topology, temporal frequent subgraphs <ref type="bibr" target="#b21">[23]</ref>- <ref type="bibr" target="#b23">[25]</ref> were studied for some timedependent networks, such as social and communication networks, as well as biological and neural networks. Furthermore, subgraphs were also applied to graph clustering. In <ref type="bibr" target="#b24">[26]</ref>, a graph clustering method was developed based on frequent subgraphs, which can effectively detect communities in a network. Network subgraphs deeply depict the local structural features of the network and have important research value in the application of graph mining.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Network Representation</head><p>The combination of subgraph structures and depth models enriches the research methods of the network and brings inspiration to researchers. With the rapid development of deep learning, many graph mining and representation methods have been proposed and tested, with practical applications to, e.g., drug design (through studying chemical compound and proteins data) <ref type="bibr" target="#b25">[27]</ref>, <ref type="bibr" target="#b26">[28]</ref> and market analysis (through purchase history) <ref type="bibr" target="#b27">[29]</ref>. Methods like word2vec <ref type="bibr" target="#b28">[30]</ref> and doc2vec <ref type="bibr" target="#b29">[31]</ref> have shown good performances in natural language processing (NLP), bringing some new insights to the field of graph representation. Inspired by these algorithms, graph2vec <ref type="bibr" target="#b30">[32]</ref> was proposed, which was shown to be outstanding for graph representation. Among the existing graph mining methods, graph kernel <ref type="bibr" target="#b31">[33]</ref>- <ref type="bibr" target="#b33">[35]</ref> has obtained unanimous praise in recent years, whereas the bottleneck is its high computational cost. As a winner from competitions on a plenty of machine learning problems, convolutional neural network (CNN) has attracted lots of attention, especially in the area of computer vision <ref type="bibr" target="#b34">[36]</ref>, and it has been reformulated by the new convolution operator for graph structure data <ref type="bibr" target="#b35">[37]</ref>. It was put forward in <ref type="bibr" target="#b36">[38]</ref>, referred to as graphconv, the first trial of an analogy of CNN on graphs. Then, graph convolutional network (GCN), designed in <ref type="bibr" target="#b37">[39]</ref> as an extension to the k-localized kernel, resolved the problem of over localization as compared with graphconv. Based on graph neural network (GNN) and capsule, Zhang et al. <ref type="bibr" target="#b38">[40]</ref> designed the CapsGNN, which can generate multiple embeddings for each graph to capture network properties from different aspects. This method was extensively tested, and achieve the state-of-the-art results.</p><p>Network algorithms benefit from graph embedding by automatically extracting features of arbitrary dimensions. However, such methods still largely rely on the original network, and thus may ignore important hidden structural features. To bridge the gap, we map the original network to different structural spaces, in terms of different SGNs. Different from those existing subgraph-based methods <ref type="bibr" target="#b10">[12]</ref>, <ref type="bibr" target="#b13">[15]</ref>, <ref type="bibr" target="#b15">[17]</ref> that only enumerate a set of motifs as functional building blocks and then match them in the original network for subsequent representation, our SGN model maps the subgraphs in the original network to the nodes in a higher-order structural space, addressing the connections between the subgraphs. Therefore, it can be considered that SGN provides a general framework to expand the structural feature space, which can be naturally integrated into many graph representation methods to further improve their effectiveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">SUBGRAPH NETWORKS</head><p>Generally, SGN can be considered as a mapping in network space, which maps the original node-level network to subgraph-level networks. In this section, SGN is first introduced, followed by algorithms for constructing the 1storder and 2nd-order SGNs. <ref type="bibr">DEFINITION 1 (Network)</ref>. An undirected network is represented by G(V, E), where V and E ⊆ (V × V ) denote the sets of nodes and links, respectively. The element (v i , v j ) in E is an unordered pair of nodes v i and v j , i.e., (v i , v j ) = (v j , v i ), for all i, j = 1, 2, ..., N , where N is the number of nodes, namely the size of the network.</p><formula xml:id="formula_0">DEFINITION 2 (Subgraph). Given a network G(V, E), g i = (V i , E i ) is a subgraph of G, denoted by g i ⊆ G if and only if V i ⊆ V and E i ⊆ E.</formula><p>The sequence of subgraphs is denoted as g = {g i ⊆ G|i = 1, 2, ..., n}, n ≤ N . DEFINITION 3 (SGN: Subgraph Network). Given a network G(V, E), the SGN, denoted by G * = L(G), is a mapping from G to G * (V * , E * ), with the sets of nodes and links denoted by V * = {g j |j = 0, 1, ..., n} and E * ⊆ (V * × V * ), respectively. Two subgraphs g i and g j are connected if they share some common nodes or links in the original network, i.e., V i ∩ V j = ∅. Similarly, the element (g i , g j ) in E * is an unordered pair of subgraphs g i and g j , i.e., (g i , g j ) = (g j , g i ), i = 1, 2, ..., n with n ≤ N .</p><p>According to the definition of SGN, one can see that: (i) subgraph is a part of the original network; (ii) SGN is derived from a higher-order mapping of the original network G; (iii) the connecting rule between two subgraphs needs to be clarified. Following the approach of <ref type="bibr" target="#b39">[41]</ref>, where the problem of graph representation in a domain with higherorder relations is discussed, constructing sets of nodes as pchains, corresponding to points (0-chains), lines (1-chains), triangles (2-chains), etc., here the new framework constructs subgraphs as 1st order, 2nd order, etc. For clarity, three steps in building the new framework are outlined as follows.</p><p>• Detecting subgraphs from the original network. Networks are rich of subgraph structures, with some subgraphs occurring frequently, e.g., motifs <ref type="bibr" target="#b18">[20]</ref>. Different kinds of networks may have different local structures, captured by different distributions of various subgraphs.</p><p>• Choosing appropriate subgraphs. Generally, subgraphs should not be too large, since in this case SGN may only contain a very small number of nodes, making the subsequent analysis less meaningful. Moreover, the chosen subgraphs should be connected to each other, i.e., they should share some common part (nodes or links) of the original network, so that higher-order structural information can emerge.</p><p>• Utilizing the subgraphs to build SGN. After extracting enough subgraphs from the original network,  connections among them are established following certain rules so as to build SGN. Here, for simplicity, consider two subgraphs. They are connected if and only if they share the same nodes or links from the original network. There certainly can be other connecting rules, leading to totally different SGNs, which will be discussed elsewhere in the future.</p><p>In this paper, the most fundamental subgraphs, i.e., line and triangle, are chosen as subgraphs, since they are simple and relatively frequently appearing in most networks. Thus, two kinds of SGNs of different orders are constructed as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">First-Order SGN</head><p>In the case of first-order, a line, or a link, is chosen as a subgraph, based on which SGN is built, denoted by SGN (1) . The 1st-order SGN is also known as a line graph, where the nodes are the links in the original network, and two nodes are connected if the corresponding links share a same end node.</p><p>The process to build SGN (1) from a given network is shown in <ref type="figure" target="#fig_1">Fig. 1</ref>. In this example, the original network has 6 nodes connected by 6 links. First, extract lines as subgraphs, labeled them by their corresponding end nodes, as shown in <ref type="figure" target="#fig_1">Fig. 1 (b)</ref>. These lines are treated as nodes in SGN. Then, connect these lines based on their labels, i.e., two lines are connected if they share one same end node, as shown in <ref type="figure" target="#fig_1">Fig. 1 (c)</ref>. Finally, obtain SGN with 6 nodes and 8 links, as shown in <ref type="figure" target="#fig_1">Fig. 1 (d)</ref>. A pseudocode of constructing SGN (1) is given in Algorithm 1. The input of this algorithm is the original network G(V ,E) and the output is the constructed SGN (1) , denoted by G (V ,E ), where V and E represent the sets of nodes and links in the SGN (1) , respectively.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Second-Order SGN</head><p>Now, construct higher-order subgraphs by considering the connection patterns among three nodes. There are more diverse connection patterns among three nodes than the case of two nodes. In theory, there are 13 possible nonisomorphic connection patterns among three nodes <ref type="bibr" target="#b18">[20]</ref> in a directed network, as shown in <ref type="figure" target="#fig_3">Fig. 2</ref> (a). This number decreases to 2 in an undirected network, namely only open and closed triangles, as shown in <ref type="figure" target="#fig_3">Fig. 2 (b)</ref>. Here, only connected subgraphs are considered, while those with less than two links are ignored. Compared with lines, triangles can provide more insights about the local structure of a network <ref type="bibr" target="#b40">[42]</ref>. For instance, in <ref type="bibr" target="#b41">[43]</ref>, the evolution of triangles in a Google+ online social network was studied, obtaining some valuable information during the emerging and pruning of various triangles. The open triangles are defined as subgraphs to establish the 2nd-order SGN, denoted by SGN <ref type="bibr" target="#b1">(2)</ref> . Here, second-order means that there are two links in each open triangle, and two open triangles are connected in SGN (2) if they share a same link. Note that same link rather than same node is used here to avoid obtaining a very dense SGN <ref type="bibr" target="#b1">(2)</ref> . This is because a dense network, with each pair of nodes connected with a higher probability, tends to provide less structural information in general. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2: Constructing SGN (2) .</head><p>Input: The iterative process to build SGN (2) from an original network is shown in <ref type="figure" target="#fig_4">Fig. 3</ref>. First, extract lines, labeled by their corresponding end nodes, as shown in <ref type="figure" target="#fig_4">Fig. 3</ref> (b), to establish SGN <ref type="bibr" target="#b0">(1)</ref> . Then, in the line graph SGN (1) , further extract lines to obtain open triangles as subgraphs, labeled by their corresponding three nodes, as shown in <ref type="figure" target="#fig_4">Fig. 3 (c)</ref>. Finally, obtain SGN (2) with 8 nodes and 14 links, as shown in <ref type="figure" target="#fig_4">Fig. 3 (d)</ref>. A pseudocode of constructing SGN (2) is given in Algorithm 2. The input of this algorithm is the original network G(V ,E) and the output is the constructed SGN (2) , denoted by G (V ,E ), where V and E represent the sets of nodes and links in the SGN (2) , respectively.</p><formula xml:id="formula_1">A network G(V ,E) with node set V and link set E ⊆ (V × V ). Output: SGN (2) , denoted by G (V ,E ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Original network</head><p>Benzene ring SGN <ref type="figure">Fig. 4</ref>. A compound network, where each node denotes an atom and its corresponding SGN obtained by taking benzene rings as subgraphs.</p><p>Clearly, the new method can be easily extended to construct higher-order SGNs by choosing proper subgraphs and connecting rules. For instance, based on Algorithms 1 and 2, for the network shown in <ref type="figure" target="#fig_4">Fig. 3 (d)</ref>, one can further label each link by the 4 numbers from the end nodes, i.e., these numbers correspond to the 4 nodes in the original network. Then, one can treat each link with a different label as a node, and connect them if they share 3 same numbers, so as to establish the 3rd-order SGN.</p><p>It is interesting to investigate such a higher-order SGN. However, as subgraphs become too large, the SGN may contain only few nodes, making the network structure less informative. It may be argued that there might be some functional subgraphs in certain networks, which could be better blocks to be used to build SGNs. However, this may not be true. Take the compound networks in chemistry as examples, e.g. benzene ring, and other functional groups such as hydroxyl group, carboxyl group and aldehyde group, which play an important role in the properties of organic substances. In such networks, however, one usually cannot choose the benzene ring as a building block, since most of these networks are of small sizes and contain a small number of benzene rings, as shown in <ref type="figure">Fig. 4</ref>. In this case, if one uses benzene rings as subgraphs, an SGN will be built containing only three nodes, with one isolated from the other two. As such, this SGN can hardly provide sufficient information to distinguish itself from the other substances, hence will not be useful.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">NETWORK ATTRIBUTES</head><p>Now, besides the original network, denoted by SGN (0) for simplicity, there are two SGNs, i.e., SGN (1) and SGN (2) . These networks together may provide more comprehensive structural information for subsequent applications. In this paper, the focus is on its application to network classification. A typical procedure for accomplishing the task consists of two steps: first, extract network structural features; second, design a machine learning method based on these features to realize the classification. In network science, there are many classic topological attributes, which have been widely used in link prediction <ref type="bibr" target="#b42">[44]</ref>, graph classification <ref type="bibr" target="#b43">[45]</ref> and so on. Here, the following handcrafted network features are used to design the classifier. • Average degree (K): The mean value of links connected to a node in the network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Percentage of leaf nodes (P ):</head><p>A node of degree 1 is defined as a leaf node. Suppose there are totally F leaf nodes in the network. Then,</p><formula xml:id="formula_2">P = F N .</formula><p>(1)</p><p>• Average clustering coefficient (C): For node v i , the clustering coefficient represents the probability of a connection between any two neighbors of v i . Suppose that there are k i neighbors of v i and these nodes are connected by L i links. Then, the average clustering coefficient is defined as</p><formula xml:id="formula_3">C = 1 N N i=1 2L i k i (k i − 1)</formula><p>.</p><p>• Largest eigenvalue of the adjacency matrix (λ): The adjacency matrix A of the network is an N × N matrix, with its element a ij = 1 if nodes v i and v j are connected, and a ij = 0 otherwise. In this step, calculate all the eigenvalues of A and choose the largest one.</p><p>•</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Network density (D):</head><p>Given the number of nodes N and the number of links L, network density is defined as</p><formula xml:id="formula_5">D = 2L N (N − 1)</formula><p>.</p><p>• Average betweenness centrality (C B ): Betweenness centrality is a centrality metric based on shortest paths. The average betweenness centrality of the network is defined as</p><formula xml:id="formula_7">C B = 1 N N i=1 s =i =t n i st g st ,<label>(4)</label></formula><p>where g st is the number of shortest paths between v s and v t , and n i st is the number of shortest paths between v s and v t that pass through v i .</p><p>• Average closeness centrality (C C ): The closeness centrality of a node in a connected network is defined as the reciprocal of the average shortest path length between this node and the others. The average closeness centrality is defined as</p><formula xml:id="formula_8">C C = 1 N N i=1 n − 1 n j=1 d ij ,<label>(5)</label></formula><p>where d ij is the shortest path length between nodes v i and v j .</p><p>• Average eigenvector centrality (C E ): Usually, the importance of a node depends not only on its degree but also on the importance of its neighbors. Eigenvector centrality is another measure of the importance of a node based on its neighbors, which is defined as</p><formula xml:id="formula_9">C E = 1 N N i=1 x i ,<label>(6)</label></formula><p>where x i represents the importance of node v i and is calculated based on the following equation:</p><formula xml:id="formula_10">x i = α N j=1 a ij x j ,<label>(7)</label></formula><p>where α is a preset parameter, which should be less than the reciprocal of the maximum eigenvalue of the adjacency matrix A.</p><p>• Average neighbor degree (D N ): Neighbor degree of a node is the average degree of all the neighbors of this node, which is defined as</p><formula xml:id="formula_11">D N = 1 N N i=1 1 k i vj ∈Ωi k j ,<label>(8)</label></formula><p>where Ω i is a set of the neighbors of node v i , and k j is the degree of node v j ∈ Ω i .</p><p>Note that, among the above 11 features, number of nodes (N ), number of links (L), average degree (K) and network density (D) are the most basic properties of a network <ref type="bibr" target="#b44">[46]</ref>. Average clustering coefficient (C) <ref type="bibr" target="#b45">[47]</ref> is also a very popular metric to quantify the link density in ego networks. The percentage of leaf nodes (P ) can distinguish whether a network is tree-like or rich with rings. The largest eigenvalue of the adjacency matrix (λ) is chosen since the eigenvalues are the isomorphic invariant of a graph, which can be used to estimate many static attributes, such as connectivity, diameter, etc. Average neighbor degree (D N ) captures the 2-hop information. Also, centrality measures are indicators of the importance (status, prestige, standing, and the like) of a node in a network, therefore, we also use average betweenness centrality (C B ), average closeness centrality (C C ), and average eigenvector centrality (C E ) to describe the global structure of a network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>Experiments were conducted on 7 real-world network datasets, as introduced in the following, with each containing two classes of networks. The first 5 datasets are about bio-and chemo-informatics, while the last two are social networks. The basic statistics of these datasets are presented in TABLE 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MUTAG:</head><p>This dataset is about heteroaromatic nitro and mutagenic aromatic compounds, with nodes and TABLE 1 Basic statistics of the 7 datasets. #Graphs is the number of graphs. #Classes is the number of classes. #Positive and #Negative are the numbers of graphs in the two different classes. <ref type="table" target="#tab_0">MUTAG  188  2  125  63  PTC  344  2  152  192  PROTEINS  1113  2  663  450  NCI1  4110  2  2057  2053  NCI109  4127  2  2079  2048  IMDB-B  1000  2  500  500  REDDIT-B  2000  2  1000  1000</ref> links representing atoms and the chemical bonds between them, respectively. They are labeled according to whether there is a mutagenic effect on a special bacteria <ref type="bibr" target="#b46">[48]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset #Graphs #Classes #Positive #Negative</head><p>• PTC: This dataset includes 344 chemical compound graphs, with nodes and links representing atoms and the chemical bonds between them, respectively. Their labels are determined by their carcinogenicity for rats <ref type="bibr" target="#b47">[49]</ref>.</p><p>• PROTEINS: This dataset comprises of 1113 graphs. The nodes are Secondary Structure Elements (SSEs) and the links are neighbors in the amino-acid sequence or in the 3D space. These graphs represent either enzyme or non-enzyme proteins <ref type="bibr" target="#b48">[50]</ref>.</p><p>• NCI1 &amp; NCI109: These two datasets comprise of 4110 and 4127 graphs, respectively. The nodes and links represent atoms and chemical bonds between them, respectively. They are two balanced subsets of the datasets of chemical compounds screened for the activities against non-small cell lung cancer and ovarian cancer cell lines, respectively. The positive and negative samples are distinguished according to whether they are effective against cancer cells <ref type="bibr" target="#b1">[2]</ref>.</p><p>•</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IMDB-B:</head><p>This dataset is about movie collaboration, which is collected from IMDB, containing lots of information about different movies. Each graph is an ego-network, where nodes represent actors or actresses and links indicate whether they appear in the same movie. Each graph is categorized into one of the two genres (Action and Romance) <ref type="bibr" target="#b2">[3]</ref>.</p><p>•</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>REDDIT-B:</head><p>This dataset is crawled from Reddit, which is composed of submission graphs from popular subreddits. Each graph corresponds to an online discussion thread, where nodes are users, and there is an link between two nodes if one of them responded to the other's comments. The four popular subreddits are IAmA, AskReddit, TrollXChromosomes and atheism. There are also two categories of graphs: IAmA and AskReddit are two QA-based subreddits and TrollXChromosomes and atheism are two discussion-based subreddits <ref type="bibr" target="#b33">[35]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Benefits of SGN</head><p>Here, take the MUTAG dataset as an example to show that SGNs of different orders may capture different aspects of a network structure. First, a positive sample and a negative one are chosen from the MUTAG dataset, with their SGN (0) , SGN (1) and SGN (2) visualized in <ref type="figure">Fig. 5</ref>. To facilitate a comparison, the numbers of nodes and links of these networks are also presented in the figure. Here, a positive sample means that this compound has mutagenic effect on the bacteria; otherwise, it is negative. As can be seen, although the original networks of the two samples have quite similar sizes, their difference is seemingly enlarged in the higher-order SGNs; more precisely, the numbers of nodes and links in SGN increase faster for the positive sample than the negative one as the order increases.</p><p>Then, the handcrafted network features are visualized by using t-SNE in <ref type="figure">Fig. 6</ref>, where the networks in MUTAG can indeed be distinguished to a certain extent by these features of the original network, the 1st-order SGN and the 2nd-order SGN, respectively. Moreover, when all the features are put together, it appears that these networks can be better distinguished, indicating that SGNs of different orders and the original network may complement to each other. Therefore, integrating the structural information of all these networks may significantly improve the performances of the subsequent algorithms designed based on network structures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>With the rapid growth of real-world graph data, network classification is becoming more and more important, and a number of effective network classification methods [51]- <ref type="bibr" target="#b51">[53]</ref> have been proposed in recent years. Along this line of research, as an application of the proposed SGN, classifiers are designed based on the structural features obtained from SGNs as well as from the original networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Automatic Feature Extraction Methods</head><p>Besides those handcrafted features, one can also use some advanced methods, such as network embedding methods, to automatically generate a feature vector of certain dimension from the given network. Under the present framework, such automatically generated feature vectors can also be further expanded based on SGNs.</p><p>Network embedding method, graph2vec, and two graph kernel-based methods, subtree kernel WL and deep WL methods, and depth model algorithm CapsGNN, are chosen as automatic feature extraction methods.</p><p>• Graph2vec <ref type="bibr" target="#b30">[32]</ref>: This is the first unsupervised embedding approach for an entire network, which is based on the extending word-and-document embedding techniques that has shown great advantages in NLP. Similarly, graph2vec establishes the relationship between a network and the rooted subgraphs using a similar model to doc2vec <ref type="bibr" target="#b29">[31]</ref>. Graph2vec first extracts rooted subgraphs and provides corresponding labels into the vocabulary, and then trains a skipgram model to obtain the representation of the entire network.</p><p>• WL <ref type="bibr" target="#b32">[34]</ref>: This is a rapid feature extraction scheme based on the Weisfeiler-Lehman (WL) test for isomorphism on graphs. It maps the original network to a sequence of graphs, with node attributes capturing both topological and label information. The key idea of the algorithm is to augment the node labels by the sorted set of node labels of neighboring nodes, and compress these augmented labels into new and short labels. These steps are then repeated until the node label sets of the two compared networks differ, or the number of iterations reaches a preset value. It should be noted that, to facilitate the expansion of the new model, the sub-structure frequency vectors, instead of the kernel matrix K, are used as the inputs to the new classifier.</p><p>• Deep WL <ref type="bibr" target="#b33">[35]</ref>: This provides a unified framework that leverages the dependency information of sub-structures by learning latent representations. The differences from the WL kernel generate a corpus of sub-structures by integrating languagemodeling and deep-learning techniques <ref type="bibr" target="#b52">[54]</ref>, where a co-occurrence relationship of sub-structures is preserved and sub-structure vector representations are obtained before the kernel is computed. Then, a sub-structure similarity matrix, M, is calculated by the matrix V with each column representing a substructure vector. Denote by P the matrix with each column representing a sub-structure frequency vector. Then, according to the definition of kernel:</p><formula xml:id="formula_12">K = PMP T = PVV T P T = HH T ,<label>(9)</label></formula><p>one can use the columns in the matrix H = PV as the inputs to the classifier.</p><p>• CapsGNN <ref type="bibr" target="#b38">[40]</ref>: This method was inspired by Cap-sNet, which adopted the concept of capsules to overcome the weakness of existing GNN-based graph embedding algorithms. In particular, CapsGNN extracts node features in the form of capsules and utilizes the routing mechanism to capture important information at the graph level. The model generates multiple embeddings for each graph so as to capture graph properties from different aspects.</p><p>In this study, for graph2vec, the embedding dimension is adopted according to <ref type="bibr" target="#b30">[32]</ref>. Graph2vec is based on the rooted subgraphs which are adopted in the WL kernel. The parameter height of WL kernel is set to 3. Since the embedding dimension is predominant for learning performances, a commonly-used value of 1024 is adopted. The other parameters are set to defaults: the learning rate is set to 0.5, the batch size is set to 512 and the epochs is set to 1000. For WL and Deep WL, according to <ref type="bibr" target="#b33">[35]</ref>, the Weisfelier-Lehman subtree kernel is used to built the corpus and the height of which is set to 2. Then, the Maximum Likelihood Estimation (MLE) is used to compute the kernel in the WL method. Furthermore, the same parameter setting as WL is chosen, with the embedding dimension equal to 10, window size equal to 5 and skip-gram used for the word2vec model in the deep WL method. We adopt the default parameters for CapsGNN and flatten the multiple embeddings of each graph as the input. Without loss of generality, the well-known logistic regression is chosen as the new classification model. Meanwhile, for each feature extraction method, the feature space is first expanded by using SGNs, and then the dimension of the feature vectors is reduced to the same value as that of the feature vector obtained from the original network using PCA in the experiments, for a fair comparison. Each dataset is randomly split into 9 folds for training and 1 fold for testing. Here, the F 1 -Score is adopted as the metric to evaluate the classification performance:</p><formula xml:id="formula_13">F 1 = 2P R P + R ,<label>(10)</label></formula><p>where P and R are the precision and recall, respectively. To exclude the random effect of the fold assignment, experiment is repeated for 500 times and then the average F 1 -Score and its standard deviation are recorded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Computational Complexity</head><p>Now, the computational complexity in building SGNs is analyzed. Denote by |V | and |E| the numbers of nodes and links, respectively, in the original network. The average degree of the network is calculated by</p><formula xml:id="formula_14">K = 1 |V | |V | i=1 k i = 2|E| |V | ,<label>(11)</label></formula><p>where k i is the degree of node v i . Based on Algorithm 1, the time complexity in transforming the original network to SGN (1) is</p><formula xml:id="formula_15">T 1 = O(K|V | + |E| 2 ) = O(|E| 2 + |E|) = O(|E| 2 ) . (12)</formula><p>Then, the number of nodes in SGN (1) is equal to |E| and the number of links is <ref type="bibr" target="#b16">[18]</ref>. Similarly, one can get the time complexity in transforming SGN (1) to SGN (2) , as</p><formula xml:id="formula_16">|V | i=1 k 2 i −|E| ≤ |E| 2 −|E|</formula><formula xml:id="formula_17">T 2 ≤ O((|E| 2 − |E|) 2 ) = O(|E| 4 ) .<label>(13)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Experiment Results</head><p>As described in Sec. 3, the proposed SGNs can be used to expand structural feature spaces. To investigate the effectiveness of the 1st-order and the 2nd-order SGNs, i.e., SGN (1) and SGN (2) , for each feature extraction method, the classification results are compared on the basis of only one network, i.e., SGN (0) , SGN (1) and SGN (2) , respectively; on the basis of two networks, i.e., SGN (0) together with SGN (1) and SGN (0) together with SGN (2) , denoted by SGN (0,1) and SGN (0,2) , respectively; and on the basis of three networks, i.e., SGN (0) together with SGN (1) and SGN (2) , denoted <ref type="figure" target="#fig_1">as  SGN (0,1,2)</ref> . For a fair comparison, PCA is used to compress the feature vectors to the same dimension for each feature extraction method, before they are input into the logistic regression model. The results are shown in TABLE 2, where one can see that, for a single network case, the original network seems to provide more structural information, i.e., the classification model based on SGN (0) performs better, in terms of higher F 1 -Score, than those based on SGN <ref type="bibr" target="#b0">(1)</ref>  <ref type="figure" target="#fig_3">or SGN (2)</ref> , in most cases. This is reasonable, because there must be information loss in the processes to build SGNs. However, it still appears to be dependent on the feature extraction method used. For instance, when the Deep WL is adopted, better classification results can be obtained based on SGN (1) or SGN (2) than SGN (0) for 2 datasets, while when handcrafted features are used, even better classification performance is realized based on the 1st-order or 2nd-order SGNs than the original network in 3 datasets. More interestingly, the classification models based on two networks, i.e. <ref type="figure" target="#fig_1">, SGN (0,1) and SGN (0,2)</ref> , perform better than those based on a single network, while the model based on three networks, i.e. <ref type="figure" target="#fig_1">, SGN (0,1,2)</ref> , performs the best in most cases.</p><p>The gain G on F 1 -Score is calculated, when all the three networks are used together, i.e. <ref type="figure" target="#fig_1">, SGN (0,1,2)</ref> , compared with that when only the original network is used, i.e., SGN (0) , which is defined to be the relatively difference between their corresponding F 1 -Score:</p><formula xml:id="formula_18">G = F (0,1,2) 1 − F (0) 1 F (0) 1 × 100% .<label>(14)</label></formula><p>The gains are also presented in TABLE 2, where one can see that the classification performance is indeed significantly improved in all the 35 cases. Particularly, in 17 cases, the gains are larger than 5%, while in 7 cases, they are  <ref type="figure" target="#fig_1">SGN (0,1,2</ref>  even larger than 10%. These results indicate that the 1storder and the 2nd-order SGNs can indeed complement the original network regarding the structural information, thus benefiting network classification. Surprisingly, it is found that the chosen handcrafted features based <ref type="figure" target="#fig_1">on SGN (0,1,2)</ref> outperforms the other automatically generated features that use more advanced network-embedding or graph-kernel based methods even depth model, in 3 out of 7 datasets, i.e., PTC, PROTEINS and IMDB-B. This phenomenon indicates that, compared with those automatically generated ones, properly chosen traditional structural features are of particular advantage in the proposed framework, in the sense that they are not only more interpretable due to their clear physical meanings, but also equally effective in designing subsequent structure-based algorithms, e.g., for network classification.</p><p>In addition, the feature importance for the task of network classification is investigated by using logistic regression. Denote by β i the coefficient of feature x i in the model, and suppose that there are M features in total. Then, the importance of feature x i is defined as</p><formula xml:id="formula_19">I = |β i | M k=1 |β k | × 100% .<label>(15)</label></formula><p>Taking MUTAG for example, the results are visualized in <ref type="figure">Fig. 7</ref>. Overall, the features in SGN (0) are most important, since they determine 37.68% of the model, while the features in SGN (2) are more important than those in SGN (1) , since they determine 35.01% and 27.31% of the model, respectively. When focusing on a single feature, it is found that the clustering coefficient C, the percentage of leaf nodes P , and the average neighbor degree D N , are the top three most important features, and they together determine more than 50% of the model. Interestingly, it appears that different SGNs address different aspects of the network structure in the classification task. For instance, the most important feature in SGN (2) is the clustering coefficient, while the coefficient for this feature in SGN (0) is zero since there is no triangle in the networks in MUTAG dataset. Moreover, the largest eigenvalue of the adjacency matrix λ and the average degree K in SGN (0) are relatively important, while those in SGN (1) and SGN (2) have less effect on the model. These results confirm once again that SGNs indeed complement the original network to achieve better network classification performance.</p><p>Furthermore, we also visualize the average F1-Scores obtained by using different feature extraction methods under different combinations of SGNs, as shown in <ref type="figure" target="#fig_9">Fig. 8</ref>. Note that here we also consider the third-order SGNs, in order to present the changing trends of F1-Scores with the number of SGNs more clearly. Indeed, we can find that integrating higher-order SGNs generally helps to capture more structural information, leading to higher classification performance. However, such benefit seems to be shrunk when we go further, i.e., the improvement of F1-Score <ref type="figure" target="#fig_1">from SGN (0,1,2) to SGN (0,1,2,3)</ref> is relatively small, while the computational complexity increases quite fast. And this is the reason why we only consider first-order and secondorder SGNs in most parts of this work.</p><p>To address the computational complexity of our method, we record the average execution time to establish SGNs of different orders on the seven datasets, including MUTAG, PTC, PROTEINS, NCI1, NCI109, IMDB-B and REDDIT-B. The results are shown in <ref type="figure" target="#fig_10">Fig. 9</ref>, where we can see that execution time increases fast as the order of SGN and the network size increase. One possible reason is that here the subgraph we chose is relatively simple, making the SGNs of higher-order even more complicated than those of lowerorder. Therefore, one way to decrease the computational complexity is to choose more complex subgraphs to establish simpler higher-order SGNs. Another way to accelerate this process is to adopt parallel computing mechanism, which will be our focus in future work.</p><p>To address the robustness of the classification model against the size variation of the training set, the F 1 -Score is calculated for the network classification task, using various sizes of training sets (from 10 to 90 percent, within a 10 percent interval). For each size, the training and test sets are randomly divided, which is repeated for 500 times with the average result recorded. The results are shown in <ref type="figure" target="#fig_1">Fig. 10</ref> for various feature extraction methods on different datasets. It can be seen that the classification results based on SGN (0) , SGN (1) and SGN (2) together are always the best, and the results based on SGN (0) and SGN (1) together, or SGN (0) and SGN (2) together, are always better than those based only on the original network SGN (0) . This confirms that the simulation results are quite robust to the variation of the training set size. For further study, our source codes are available online. 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSIONS</head><p>In this paper, the concept of subgraph network (SGN) is introduced, along with algorithms developed for constructing the 1st-order and 2nd-order SGNs, which can expand the 1. https://github.com/GalateaWang structural feature space. As a multi-order graph representation method, various orders of SGNs can significantly enrich the structural information and thus benefit the network feature extraction methods to capture various aspects of the network structure. Also, the effectiveness of the 1st-order and 2nd-order SGNs are verified. Moreover, the handcrafted features, as well as the features automatically generated by network representation methods including graph2vec and kernel-based methods including Weisfeiler-Lehman (WL) and deep WL methods and CapsGNN method, are used in experiments for network classification on seven real-world datasets.</p><p>The experimental results show that the classification model based on the features of the original network together with the 1st-order and 2nd-order SGNs always performs the best, compared with those based only on a single network, either the original one, the 1st-order or the 2nd-order SGN, or those based on a pair of them. This demonstrates that SGNs can indeed complement the original network on structural information and thus benefit the subsequent network classification algorithms, no matter which feature extraction method is adopted. More interestingly, it is found that the model based on handcrafted features performs even better than those based on the features automatically generated by more advanced methods, such as graph2vec, for most datasets. This finding suggests that, in general, properly chosen structural features with clear physical meanings may be effective in designing structure-based algorithms.</p><p>Future research may focus on extracting more types of subgraphs to establish SGNs of higher diversity for both static and temporal networks, so as to capture the network structural information more comprehensively, to design consequent algorithms for network classification and perhaps other tasks as well.  <ref type="figure" target="#fig_1">and SGN (0,1,2)</ref> , respectively.</p><p>[5] Q. Xuan, A. Okano, P. Devanbu, and V. Filkov, "Focus-shifting patterns of oss developers and their congruence with call graphs," in Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering. ACM, 2014, pp. 401-412.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>The process of building SGN (1) from a given network: (a) the original network, (b) extracting lines as subgraphs, (c) establishing connections among these lines, and (d) forming SGN (1) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Algorithm 1 : 4 for</head><label>14</label><figDesc>Constructing SGN<ref type="bibr" target="#b0">(1)</ref> . Input: A network G(V ,E) with node set V and link set E ⊆ (V × V ). Output: SGN (1) , denoted by G (V ,E ). 1 Initialize a node set V and a link set E ; 2 for each v ∈ V do<ref type="bibr" target="#b2">3</ref> get the neighbor set Ω of v; each ω ∈ Ω do 5 = sorted([v, ω]); 6 str ← merge the nodes in list into a string; 7 add the new node str into V ; j ∈ V and i = j do<ref type="bibr" target="#b8">10</ref> add the link (i, j) into E ;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2 .</head><label>2</label><figDesc>The connection patterns among three nodes for (a) directed and (b) undirected networks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>The process to build SGN (2) from a given network: (a) the original network, (b) extracting lines, (b) building SGN (1) and extracting open triangles as subgraphs, and (d) establishing connections among these open triangles to obtain SGN (2) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>1 4 Ω 5 for each (ω 1 , ω 2 ) ∈ Ω do 6 = [v, ω 1 , ω 2 ]; 7 str</head><label>14512617</label><figDesc>Initialize a node set V and a link set E ; 2 for each v ∈ V do 3 get the neighbors set Ω of v; ← get the full combination of node pairs in the neighbor collection; ← merge the nodes in list into a string; 8 add the new node str into V ; j ∈ V and i = j do 11 add the edge (i, j) into E ;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>•</head><label></label><figDesc>Number of Nodes (N ):Total number of nodes in the network.• Number of links (L): Total number of links in the network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>N = 11 ,</head><label>11</label><figDesc>L = 14 N = 14, L = 25 N = 11, L = 11Fig. 5. SGN (0) , SGN (1) and SGN (2) as well as the numbers of nodes and links for (a) positive and (b) negative samples in the MUTAG dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>2 Fig. 6 .</head><label>26</label><figDesc>The t-SNE visualization of handcrafted network features. The same color of points represent the same class of networks in MUTAG.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 8 .</head><label>8</label><figDesc>Average F1-Scores obtained by using different feature extraction methods under different combinations of SGNs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 9 .</head><label>9</label><figDesc>Average execution time to establish SGNs of different orders on the seven datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>2 Fig. 10 .</head><label>210</label><figDesc>Average F 1 -Score as functions of the size of the training set (represented by the fraction of samples in the training set), for various feature extraction methods on different datasets, based on SGN (0), SGN (0,1) , SGN (0,2)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE 2</head><label>2</label><figDesc>Classification results on the 7 datasets, in terms of F 1 -Score, based on different feature extraction methods and combinations of SGNs.86.58 ± 3.61 63.52 ± 4.55 78.30 ± 2.49 67.48 ± 0.87 67.34 ± 1.25 73.00 ± 3.68 78.68 ± 1.66 SGN (1) 88.20 ± 3.62 65.29 ± 6.93 76.79 ± 3.41 65.72 ± 1.41 66.25 ± 2.14 73.30 ± 4.82 76.50 ± 2.73 SGN (2) 85.53 ± 4.47 65.00 ± 6.09 75.45 ± 5.04 65.35 ± 2.32 64.15 ± 2.20 74.24 ± 3.38 74.37 ± 3.14 SGN (01) 87.89 ± 4.58 66.47 ± 6.73 78.83 ± 3.12 68.76 ± 2.24 68.88 ± 2.17 73.38 ± 3.94 79.15 ± 2.32 SGN (0,2) 88.42 ± 4.22 65.59 ± 7.09 78.92 ± 3.17 69.39 ± 1.82 68.09 ± 1.74 75.42 ± 3.34 78.80 ± 2.07 SGN (1,2) 88.95 ± 3.37 67.06 ± 6.14 78.21 ± 3.60 68.13 ± 1.30 68.48 ± 1.42 74.94 ± 2.81 77.23 ± 1.98</figDesc><table><row><cell>Algorithm</cell><cell></cell><cell></cell><cell></cell><cell>Dataset</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Handcraft</cell><cell>MUTAG</cell><cell>PTC</cell><cell>PROTEINS</cell><cell>NCI1</cell><cell>NCI109</cell><cell>IMDB-B</cell><cell>REDDIT-B</cell></row><row><cell>SGN (0)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>(0,1) 87(0,2) 87(1,2) 78</head><label></label><figDesc>± 9.25 60.17 ± 6.86 73.30 ± 2.05 73.22 ± 1.81 74.26 ± 1.47 62.47 ± 3.99 76.00 ± 2.20 SGN (1) 63.16 ± 4.68 56.80 ± 5.39 60.27 ± 2.05 54.56 ± 1.38 56.35 ± 1.52 63.06 ± 6.72 75.34 ± 2.55 SGN (2) 68.95 ± 8.47 57.35 ± 3.83 59.82 ± 4.11 61.31 ± 2.13 53.54 ± 1.43 64.35 ± 6.63 74.50 ± 2.71 SGN ± 3.07 56.91 ± 2.79 72.92 ± 0.56 66.19 ± 0.97 69.26 ± 1.14 70.90 ± 4.18 75.15 ± 2.39 SGN (1) 76.05 ± 2.73 61.76 ± 6.17 67.04 ± 1.58 58.24 ± 1.87 57.68 ± 1.28 69.20 ± 3.87 74.83 ± 2.64 SGN (2) 74.21 ± 7.33 59.41 ± 5.22 64.01 ± 1.58 52.62 ± 0.53 58.26 ± 0.72 66.10 ± 4.18 74.34 ± 2.65 SGN (0,1) 87.11 ± 5.45 62.50 ± 4.15 76.19 ± 2.29 72.49 ± 1.79 69.50 ± 1.76 73.05 ± 4.75 76.90 ± 1.51 SGN (0,2) 86.57 ± 4.31 59.71 ± 3.96 74.99 ± 1.56 70.11 ± 1.22 69.67 ± 1.34 72.23 ± 3.13 75.40 ± 4.73 SGN (1,2) 76.11 ± 7.75 60.88 ± 3.11 64.81 ± 3.05 56.00 ± 2.35 57.92 ± 1.30 70.45 ± 3.22 74.15 ± 4.17 SGN ± 2.68 59.04 ± 1.09 73.30 ± 0.82 67.06 ± 1.91 67.04 ± 1.36 67.50 ± 2.45 77.25 ± 2.52 SGN (1) 67.89 ± 6.84 58.53 ± 3.23 69.43 ± 2.57 55.45 ± 1.43 57.63 ± 2.07 73.30 ± 2.38 76.93 ± 3.68 SGN (2) 68.42 ± 6.65 62.65 ± 4.17 68.57 ± 2.42 55.22 ± 1.45 55.68 ± 1.12 71.48 ± 2.48 75.29 ± 4.35 SGN (0,1) 92.11 ± 5.39 64.41 ± 1.87 74.62 ± 2.51 70.10 ± 1.24 69.39 ± 1.35 73.50 ± 2.87 77.35 ± 2.47 SGN (0,2) 93.15 ± 5.28 64.70 ± 4.88 75.89 ± 2.99 70.12 ± 1.31 68.61 ± 1.11 74.36 ± 2.22 76.92 ± 3.13 SGN (1,2) 73.68 ± 5.77 64.16 ± 4.92 69.43 ± 2.26 59.95 ± 1.12 56.24 ± 1.62 71.90 ± 2.51 76.20 ± 5.06 SGN ± 7.52 62.06 ± 4.25 75.89 ± 3.51 78.30 ± 1.80 72.99 ± 2.15 72.71 ± 4.36 76.12 ± 3.82 SGN (1) 83.68 ± 8.95 61.76 ± 5.00 74.64 ± 3.55 74.70 ± 1.54 69.82 ± 2.24 74.35 ± 4.61 75.64 ± 4.15 SGN (2) 82.63 ± 7.08 58.82 ± 3.95 72.39 ± 6.03 69.82 ± 1.89 67.04 ± 2.45 73.64 ± 4.77 72.41 ± 3.97 SGN .37 ± 8.55 63.53 ± 4.40 76.25 ± 3.53 78.42 ± 2.92 73.28 ± 3.11 74.58 ± 4.80 78.49 ± 2.93 SGN .89 ± 5.29 62.20 ± 6.14 73.00 ± 3.17 73.78 ± 2.32 71.52 ± 2.09 74.94 ± 4.56 78.17 ± 5.13 SGN .95 ± 8.49 59.11 ± 5.65 70.09 ± 2.45 70.53 ± 2.45 70.64 ± 2.30 75.29 ± 4.08 75.73 ± 4.97 SGN</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>MUTAG</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">PTC</cell><cell></cell><cell></cell><cell>PROTEINS</cell></row><row><cell></cell><cell></cell><cell>)</cell><cell cols="2">91.58 ± 4.21</cell><cell cols="2">67.94 ± 6.36</cell><cell cols="2">79.46 ± 2.96</cell><cell cols="3">69.84 ± 1.59</cell><cell cols="2">69.73 ± 1.97</cell><cell>77.65 ± 4.50</cell><cell>79.23 ± 1.62</cell></row><row><cell></cell><cell cols="2">Gain (0)</cell><cell>5.78% (0,1)</cell><cell>(0,1,2)</cell><cell>6.96% (0,1,2,3)</cell><cell></cell><cell cols="2">1.71% (0)</cell><cell>(0,1)</cell><cell>3.50%</cell><cell>(0,1,2)</cell><cell cols="2">3.55% (0,1,2,3)</cell><cell>6.37% (0)</cell><cell>(0,1)</cell><cell>0.70% (0,1,2)</cell><cell>(0,1,2,3)</cell></row><row><cell>F1-Score</cell><cell cols="13">Graph2vec SGN (0) 83.15 (0,1) MUTAG 83.42 ± 5.40 59.03 ± 3.36 74.12 ± 1.57 73.65 ± 1.38 73.18 ± 1.26 66.59 ± 4.54 77.63 ± 1.25 PTC PROTEINS NCI1 NCI109 IMDB-B REDDIT-B NCI1 IMDB-B REDDIT-B</cell></row><row><cell></cell><cell cols="2">SGN (0,2)</cell><cell cols="6">81.32 ± 3.80 61.76 ± 3.73 73.09 ± 1.28</cell><cell cols="3">77.54 ± 2.52</cell><cell cols="2">75.39 ± 1.33</cell><cell>66.53 ± 4.45 77.39 ± 3.10</cell></row><row><cell></cell><cell cols="2">SGN (1,2)</cell><cell cols="11">72.63 ± 4.08 59.42 ± 5.84 62.76 ± 3.49 67.47 ± 3.84 68.12 ± 1.86 66.24 ± 2.58 76.00 ± 3.18</cell></row><row><cell></cell><cell cols="2">SGN (0,1,2)</cell><cell cols="2">86.84 ± 5.70</cell><cell cols="2">63.24 ± 6.70</cell><cell cols="2">74.44 ± 3.09</cell><cell cols="5">76.64 ± 3.21 74.86 ± 2.76</cell><cell>70.65 ± 5.55</cell><cell>78.04 ± 2.61</cell></row><row><cell></cell><cell cols="2">Gain</cell><cell>4.44%</cell><cell></cell><cell>5.10%</cell><cell></cell><cell cols="2">1.56%</cell><cell></cell><cell>5.90%</cell><cell></cell><cell cols="2">1.52%</cell><cell>13.73%</cell><cell>2.68%</cell></row><row><cell></cell><cell>WL</cell><cell></cell><cell>MUTAG</cell><cell></cell><cell>PTC</cell><cell></cell><cell cols="2">PROTEINS</cell><cell></cell><cell>NCI1</cell><cell></cell><cell cols="2">NCI109</cell><cell>IMDB-B</cell><cell>REDDIT-B</cell></row><row><cell></cell><cell cols="4">SGN (0) (0) 80.63 (0,1,2) (0,1) 88.94 ± 3.28 (0,1,2)</cell><cell cols="2">(0,1,2,3) 63.53 ± 4.80</cell><cell cols="2">(0) 78.08 ± 1.41</cell><cell cols="3">(0,1) 77.03 ± 2.73 (0,1,2) Model</cell><cell cols="2">(0,1,2,3) 72.92 ± 1.25</cell><cell>(0) 75.00 ± 4.49</cell><cell>(0,1) 77.03 ± 2.73 (0,1,2)</cell><cell>(0,1,2,3)</cell></row><row><cell></cell><cell cols="2">Gain</cell><cell>10.31%</cell><cell></cell><cell>11.63%</cell><cell></cell><cell cols="2">7.08%</cell><cell cols="3">11.63%</cell><cell cols="2">5.28%</cell><cell>5.78%</cell><cell>2.50%</cell></row><row><cell></cell><cell cols="2">Deep WL</cell><cell>MUTAG</cell><cell></cell><cell>PTC</cell><cell></cell><cell cols="2">PROTEINS</cell><cell></cell><cell>NCI1</cell><cell></cell><cell cols="2">NCI109</cell><cell>IMDB-B</cell><cell>REDDIT-B</cell></row><row><cell></cell><cell cols="4">SGN (0) 82.95 (0,1,2) 93.68 ± 5.15</cell><cell cols="2">65.88 ± 5.05</cell><cell cols="2">76.78 ± 2.41</cell><cell cols="3">70.26 ± 1.24</cell><cell cols="2">71.06 ± 1.61</cell><cell>75.70 ± 1.55</cell><cell>78.41 ± 1.70</cell></row><row><cell></cell><cell cols="2">Gain</cell><cell>12.93%</cell><cell></cell><cell>11.58%</cell><cell></cell><cell cols="2">4.75%</cell><cell></cell><cell>4.77%</cell><cell></cell><cell cols="2">6.00%</cell><cell>11.85%</cell><cell>1.50%</cell></row><row><cell></cell><cell cols="2">CapsGNN</cell><cell>MUTAG</cell><cell></cell><cell>PTC</cell><cell></cell><cell cols="2">PROTEINS</cell><cell></cell><cell>NCI1</cell><cell></cell><cell cols="2">NCI109</cell><cell>IMDB-B</cell><cell>REDDIT-B</cell></row><row><cell></cell><cell cols="4">SGN (0) 86.32 (0,1,2) 89.47 ± 7.44</cell><cell cols="2">64.12 ± 3.67</cell><cell cols="2">76.34 ± 4.13</cell><cell cols="3">78.61 ± 1.87</cell><cell cols="2">73.72 ± 2.39</cell><cell>76.47 ± 5.74</cell><cell>79.68 ± 5.34</cell></row><row><cell></cell><cell cols="2">Gain</cell><cell>4.65%</cell><cell></cell><cell>3.32%</cell><cell></cell><cell cols="2">0.59%</cell><cell></cell><cell>0.40%</cell><cell></cell><cell cols="2">1.00%</cell><cell>5.17%</cell><cell>4.87%</cell></row><row><cell>C</cell><cell></cell><cell cols="2">6.16%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>14.43%</cell><cell>20.59%</cell></row><row><cell>P</cell><cell></cell><cell></cell><cell>8.63%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">6.22%</cell><cell></cell><cell>1.58%</cell><cell>16.42%</cell></row><row><cell>DN</cell><cell>2.15%</cell><cell></cell><cell cols="2">5.15%</cell><cell></cell><cell></cell><cell></cell><cell cols="2">6.15%</cell><cell></cell><cell></cell><cell>13.46%</cell></row><row><cell>λ</cell><cell></cell><cell></cell><cell>7.53%</cell><cell></cell><cell></cell><cell></cell><cell>2.45%</cell><cell></cell><cell>1.32%</cell><cell cols="2">11.30%</cell><cell></cell></row><row><cell>K</cell><cell></cell><cell cols="2">6.10%</cell><cell></cell><cell>1.23%</cell><cell cols="2">1.68%</cell><cell>9.10%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>35.01%</cell><cell>37.68%</cell></row><row><cell>CE</cell><cell cols="2">3.57%</cell><cell>1.39%</cell><cell></cell><cell>3.73%</cell><cell></cell><cell cols="2">8.70%</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>CB</cell><cell cols="2">4.84%</cell><cell cols="2">0.50%</cell><cell>1.79%</cell><cell>7.13%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>L</cell><cell>1.49%</cell><cell>1.93%</cell><cell cols="2">2.24%</cell><cell>5.67%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Rest</cell><cell>3.28%</cell><cell></cell><cell cols="2">2.28%</cell><cell>2.07%</cell><cell cols="2">7.63%</cell><cell></cell><cell cols="2">SGN (0)</cell><cell cols="2">SGN (1)</cell><cell>SGN (2)</cell><cell>27.31%</cell></row></table><note>Fig. 7. The importance of handcrafted features in logistic regression model for network classification using SGN (0) , SGN (1) and SGN (2) together in MUTAG dataset.</note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The authors would like to thank all the members in the IVSN Research Group, Zhejiang University of Technology for the valuable discussion about the ideas and technical details presented in this paper. This work was partially supported by the National Natural Science </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Visualization of protein interactions in living plant cells using bimolecular fluorescence complementation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Walter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chaban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schütze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Batistic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Weckermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Näke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Blazevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Grefen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schumacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Oecking</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Harter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kudla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Plant Journal</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="428" to="438" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Comparison of descriptor spaces for chemical compound retrieval and classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">A</forename><surname>Watson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Karypis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge and Information Systems</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="347" to="375" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning graph representation via frequent subgraphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Phung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 SIAM International Conference on Data Mining. SIAM</title>
		<meeting>the 2018 SIAM International Conference on Data Mining. SIAM</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="306" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Social synchrony on complex networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Filkov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on cybernetics</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1420" to="1431" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Two case studies of open source software development: Apache and mozilla</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mockus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Fielding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Herbsleb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Software Engineering and Methodology</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="309" to="346" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Social network analysis: Characteristics of online social networks after a disaster</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hastak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Information Management</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="86" to="96" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Link weight prediction using supervised learning methods and its application to yelp layered network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1507" to="1518" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An algorithm for subgraph isomorphism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Ullmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM (JACM)</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="31" to="42" />
			<date type="published" when="1976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Topological units of environmental signal processing in the transcriptional regulatory network of escherichia coli</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Balazsi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A.-L</forename><surname>Barabási</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Oltvai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page" from="7841" to="7846" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Subgraph frequencies: Mapping the empirical and extremal geography of large graph collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ugander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Backstrom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd international conference on World Wide Web</title>
		<meeting>the 22nd international conference on World Wide Web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1307" to="1318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Subgraph frequencies and network classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Vohra</surname></persName>
		</author>
		<ptr target="http://snap.stanford.edu/class/cs224w-2014/projects2014/cs224w-76-final.pdf" />
		<imprint/>
	</monogr>
	<note>Online</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Path sampling: A fast and provable method for estimating 4-vertex subgraph counts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Seshadhri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pinar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee</title>
		<meeting>the 24th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="495" to="505" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Network motif discovery using subgraph enumeration and symmetry-breaking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Grochow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kellis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual International Conference on Research in Computational Molecular Biology</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="92" to="106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Higher-order organization of complex networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Benson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Gleich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">353</biblScope>
			<biblScope unit="issue">6295</biblScope>
			<biblScope unit="page" from="163" to="166" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Incremental subgraph feature selection for graph classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">W</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">.-H</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="128" to="142" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Node, motif and subgraph: Leveraging network functional blocks through structural convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">W</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="47" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Some properties of line digraphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Harary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">Z</forename><surname>Norman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Rendiconti del Circolo Matematico di Palermo</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="161" to="168" />
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Discriminative frequent subgraph mining with optimality guarantees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Thoma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical Analysis and Data Mining: The ASA Data Science Journal</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="302" to="318" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Efficient detection of network motifs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wernicke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on Computational Biology and Bioinformatics (TCBB)</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="347" to="359" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A faster algorithm for detecting network motifs</title>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Algorithms in Bioinformatics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="165" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Detecting strong ties using network motifs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rotabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kamath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sharma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on World Wide Web Companion. International World Wide Web Conferences Steering Committee</title>
		<meeting>the 26th International Conference on World Wide Web Companion. International World Wide Web Conferences Steering Committee</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="983" to="992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Temporal motifs in time-dependent networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kovanen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Karsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kaski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kertész</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Saramäki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Mechanics: Theory and Experiment</title>
		<imprint>
			<biblScope unit="volume">2011</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">11005</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Temporal motifs reveal collaboration patterns in online task-oriented networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Filkov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review E</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">52813</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Motifs in temporal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paranjape</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Benson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth ACM International Conference on Web Search and Data Mining</title>
		<meeting>the Tenth ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="601" to="610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Scalable motif-aware graph clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Tsourakakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pachocki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mitzenmacher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee</title>
		<meeting>the 26th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1451" to="1460" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deep learning for drug design: An artificial intelligence paradigm for drug discovery in the big data era</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-Q</forename><forename type="middle">S</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The AAPS journal</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">58</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Comparing and validating machine learning models for mycobacterium tuberculosis drug discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Russo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Zorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Korotcov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Tkachenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Perryman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Freundlich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ekins</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Molecular pharmaceutics</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Wide &amp; deep learning for recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-T</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Koc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Harmsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Shaked</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Aradhye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ispir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Workshop on Deep Learning for Recommender Systems</title>
		<meeting>the 1st Workshop on Deep Learning for Recommender Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="7" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Distributed representations of sentences and documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1188" to="1196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chandramohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Venkatesan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1707.05005</idno>
		<title level="m">graph2vec: Learning distributed representations of graphs</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Graph kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">V N</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">N</forename><surname>Schraudolph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kondor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1201" to="1242" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Weisfeiler-lehman graph kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shervashidze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Schweitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Leeuwen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mehlhorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2539" to="2561" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Deep graph kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Yanardag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1365" to="1374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Automatic pearl classification machine based on a multistream convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Electronics</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="6538" to="6547" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Convolutional networks on graphs for learning molecular fingerprints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maclaurin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Iparraguirre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bombarell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hirzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Aspuru-Guzik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2224" to="2232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6203</idno>
		<title level="m">Spectral networks and locally connected networks on graphs</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Convolutional neural networks on graphs with fast localized spectral filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3844" to="3852" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Capsule graph neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xinyi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Higher order learning with graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd international conference on Machine learning</title>
		<meeting>the 23rd international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="17" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Curvature of co-links uncovers hidden thematic layers in the world wide web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-P</forename><surname>Eckmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Moses</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the national academy of sciences</title>
		<meeting>the national academy of sciences</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="5825" to="5829" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Evolution of directed triangle motifs in the google+ osn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Schiöberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Uhlig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Feldmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.04321</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Link prediction in social networks: the state-of-the-art</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science China Information Sciences</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Graph classification via topological and label attributes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Semerci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Zaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th international workshop on mining and learning with graphs (MLG)</title>
		<meeting>the 9th international workshop on mining and learning with graphs (MLG)<address><addrLine>San Diego, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Network science: an introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="87" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Network clustering coefficient without degree-correlation biases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">N</forename><surname>Soffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vazquez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review E</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">57101</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Structure-activity relationship of mutagenic aromatic and heteroaromatic nitro compounds. correlation with molecular orbital energies and hydrophobicity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Debnath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Lopez De Compadre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Debnath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Shusterman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hansch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of medicinal chemistry</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="786" to="797" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Statistical evaluation of the predictive toxicology challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Toivonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kramer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Helma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1183" to="1193" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Protein function prediction via graph kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schönauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="47" to="56" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Predicting structured objects with support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-N</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="97" to="104" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">An application of boosting to graph classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Maeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="729" to="736" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Substructure assembling network for graph classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A neural probabilistic language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ducharme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jauvin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1137" to="1155" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
