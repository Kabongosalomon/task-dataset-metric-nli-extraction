<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Pruning the Index Contents for Memory Efficient Open-Domain QA</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Fajcik</surname></persName>
							<email>ifajcik@fit.vutbr.cz</email>
							<affiliation key="aff0">
								<orgName type="institution">Brno University of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Docekal</surname></persName>
							<email>idocekal@fit.vutbr.cz</email>
							<affiliation key="aff0">
								<orgName type="institution">Brno University of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karel</forename><surname>Ondrej</surname></persName>
							<email>ondrej@fit.vutbr.cz</email>
							<affiliation key="aff0">
								<orgName type="institution">Brno University of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Smrz</surname></persName>
							<email>smrz@fit.vutbr.cz</email>
							<affiliation key="aff0">
								<orgName type="institution">Brno University of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Pruning the Index Contents for Memory Efficient Open-Domain QA</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T21:46+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work presents a novel pipeline that demonstrates what is achievable with a combined effort of state-of-the-art approaches. Specifically, it proposes the novel R2-D2 (RANK TWICE, READ TWICE) pipeline composed of retriever, passage reranker, extractive reader, generative reader and a simple way to combine them. Furthermore, previous work often comes with a massive index of external documents that scales in the order of tens of GiB. This work presents a simple approach for pruning the contents of a massive index such that the open-domain QA system altogether with index, OS, and library components fits into 6GiB docker image while retaining only 8% of original index contents and losing only up to 3% EM accuracy 1 .</p><p>2 Leaderboard available at https</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recent advances in neural passage retrieval <ref type="bibr" target="#b17">(Karpukhin et al., 2020;</ref><ref type="bibr" target="#b12">Izacard and Grave, 2020a;</ref><ref type="bibr">Luan et al., 2021, inter alia)</ref> greatly improved the performance of open-domain question answering systems (open-QA). The goal of these systems is to provide an answer to factoid questions. Traditional open-QA systems <ref type="bibr" target="#b3">(Chen et al., 2017)</ref> seek evidence for answering these questions inside the knowledge source. This is often a large corpus of short snippets of natural language, so-called passages, with information-rich contents (e.g., taken from an encyclopedia). The current state-of-the-art systems can be scaled to millions or even billions <ref type="bibr" target="#b43">(Seo et al., 2019)</ref> of natural language passages. With the ongoing progress, and ever-growing sources of information, it can be expected that the open-QA will play a major role in everyday human life, e.g., in complementing or even replacing document search, as we know it <ref type="bibr" target="#b7">(Etzioni, 2011)</ref>. Therefore a natural question arises: Is all of this information relevant for current open-QA systems?</p><p>To gain evidence towards answering this question we experiment with our simple content-based pruning approach -a binary classifier which selects whether the passage is irrelevant or not without seeing any question -on popular open-QA datasets NaturalQuestions, TriviaQA and Efficien-tQA. Surprisingly, we find that most (about 92%) of the information content can be pruned away with only minor (3 EM) performance degradation to be seen in the current open-domain pipelined QA systems.</p><p>As our second contribution, we present a novel pipelined open-QA baseline composed of retriever, passage reranker, extractive reader, generative reader, and a simple component fusion approach.</p><p>Our system sets a new state-of-the-art on Natu-ralQuestions dataset. Furthermore it ended up among the top performing systems in the Efficien-tQA competition <ref type="bibr" target="#b32">(Min et al., 2021)</ref> 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Pruning Approach</head><p>To reduce the size of the index, we resort to an apriori relevance classifier, which selects the relevant content without seeing a question. Note this is in contrast with the retriever, which considers a question when assigning the relevance. Consider the Wikipedia corpus split into 100-word passages. The recent work of <ref type="bibr" target="#b17">Karpukhin et al. (2020)</ref> indicates that the distribution of golden passages -the passages containing an answer from the dataset -differs from the distribution of all passages. This is implicated by the fact that golden passages perform as better negative samples than just any randomly sampled passages when training the retriever. Therefore, given a passage p i from Wikipedia, we propose an apriori relevance classifier (we call pruner) into relevance class r that models the Bernoulli distribution P (r|p i ). The input of this classifier is the concatenation of Wikipedia passage (sometimes referred to as context) and its article's title separated with the special SEP token. The classifier is trained via binary cross-entropy on the set of golden passages and non-golden passages extracted from Wikipedia. In test-time, we collect the probabilities P (r|p i ) for each passage p i in the corpus. We keep only passages p i that satisfy the threshold constraint P (r|p i ) &gt; τ ; τ ∈ (0, 1). Furthermore, we empirically verify in Section 5 that the passage embeddings from <ref type="bibr" target="#b17">Karpukhin et al. (2020)</ref> contain strong features that capture the very same apriori relevance as this classifier does.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Open-QA Pipeline</head><p>To estimate the impact of corpus pruning on various open-QA components, we propose a pipelined system R2-D2 (RANK TWICE, READ TWICE). The parameters of each component are estimated separately. It is composed of DPR passage retriever <ref type="bibr" target="#b17">(Karpukhin et al., 2020)</ref>, passage reranker (see subsection 3.1), and two readers. <ref type="figure">Figure 1</ref> shows the diagram of our system. The first reader performs an extractive span-selection similar to <ref type="bibr">Fajcik et al. (2020)</ref>. The second reader is based on Fusion-In-Decoder (FiD) <ref type="bibr" target="#b13">(Izacard and Grave, 2020b)</ref>.</p><p>Formally, given a question q ∈ Q from the set of all possible questions Q and the corpus C = {p 1 , p 2 , ..., p n } composed of passages p i , the retriever learns a ranking function rank : Q×C → R that assigns a score to each passage. Note each passage contains its passage title.</p><p>Taking a top-K scoring passages C r , reranker again re-scores C r scoring passages by learning a reranking function rerank : Q×C r → R. Note that while rank and rerank have similar signatures, the computational cost of rerank over the same amount of passages is drastically higher, as it computes finegrained interaction between tokens of question and passage.</p><p>Next, we experiment with two readers: the extractive reader reads top-V passages C rr independently and assigns probability P e (a e |q, C rr ) to each span a e in the passages (see subsection 3.2). The FiD generative reader reads top-V 2 passages C rr and generates an answer from probability space P g (a g |q, C rr ) via greedy search.</p><p>Finally, R2-D2 aggregates the outputs from all</p><p>In which Czech city is the brewery of its largest beer exporter?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Passage Reranker</head><p>The proposed passage reranker is based on transformer cross-encoder similar to ; <ref type="bibr" target="#b28">Luan et al. (2021)</ref>. The input is the concatenation of question q ∈ Q and passage p ∈ C r with a special SEP token between them. The passage consists of a title and context that are prepended with special start tokens and concatenated together. We denote the contextual representation of input token w obtained by the crossencoder as En(p, q)[w] ∈ R d . Now we can define the reranking function to the re-score passage as</p><formula xml:id="formula_0">rerank(q, p) = En(p, q)[CLS] w<label>(1)</label></formula><p>where w ∈ R d is a trainable vector and CLS is the special token added at the start of an input sequence. Finally, we define the following formula 3 P rr (p|q, C r ) = softmax p∈Cr (rerank (q, p)) p <ref type="formula">(2)</ref> to assign a probability to the case that passage p contains answer to the question q.</p><p>Training. The model input for each question is exactly one positive sample supplemented with hard negatives from retriever. The ground truth passage, annotated the same way as in <ref type="bibr" target="#b17">Karpukhin et al. (2020)</ref>, is primarily used as a positive sample. If the ground truth is unknown, the positive sample is the best retriever passage containing the answer. The hard negatives are uniformly sampled from retriever top-k results that do not contain the answer. The used loss function is the cross-entropy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Extractive Reader</head><p>Extractive reader estimates the probability P e (a e |q, C rr ). It is the probability of a span a e from top-V passage p ∈ C rr being an answer to a question q. We decompose the P e (a e |q, C rr ) into four probabilities of:</p><p>• token s being starting token of an answer span,</p><p>• token e being ending token of an answer span,</p><p>• tokens s and e being boundary tokens of an answer span <ref type="bibr">(Fajcik et al., 2020)</ref>,</p><p>• passage p containing an answer for the question q (inner reranker) as in <ref type="bibr" target="#b17">Karpukhin et al. (2020)</ref>.</p><p>3 Formal definition of softmax over a set is described in the Apendix E.</p><p>To obtain the final probability used in test-time, we multiply them all together 4 . These probabilities are defined as:</p><formula xml:id="formula_1">P * ( * |q, C rr ) = softmax(s * ) i ,<label>(3)</label></formula><p>where * may stand for a start, end, joint, and a passage. The i is an index of a given element, and the s * is a vector of scores for each element among all passages in C rr . So the softmax normalization sum goes through all the passages. On the other hand, the s * scores are estimated by the model with just a single passage on its input <ref type="bibr" target="#b5">(Clark and Gardner, 2018)</ref>. The scores are as follows:</p><formula xml:id="formula_2">s i start = En(p, q)[s] w start<label>(4)</label></formula><formula xml:id="formula_3">s i end = En(p, q)[e] w end<label>(5)</label></formula><formula xml:id="formula_4">s i joint = (W j En(p, q)[s] + b j ) En(p, q)[e] (6) s i passage = En(p, q)[CLS] w p .<label>(7)</label></formula><p>Where</p><formula xml:id="formula_5">w * , b j ∈ R h , En(p, q)[·] ∈ R h , and W j ∈ R h×h are all trainable.</formula><p>We omit the spans of a title and question for answer span selection. Therefore the final answer can be selected only from the context.</p><p>The following training objective with independently marginalized components is used:</p><formula xml:id="formula_6">− log s∈starts(Crr) P start (s|q, C rr ) − log e∈ends(Crr) P end (e|q, C rr ) − log j∈boundaries(Crr) P joint (j|q, C rr ) − log p∈Crr P passage (p|q, C rr ) .<label>(8)</label></formula><p>The sums are going through target annotations (starts, ends, etc.) obtained by the distant supervision approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Component Fusion</head><p>To produce the final answer, R2-D2 aggregates the log-probabilities of all system components via linear combinations tuned on validation data.</p><p>Firstly, the log-probabilities of all system components for top-M answer spans proposed by the extractive reader are aggregated. Formally, assume the A q is the set of top-M answer spans from P e (a|q, C rr ) for question q. The generative model performs the answer reranking evaluating the logprobability of the answer spans</p><formula xml:id="formula_7">{log P g (a|q, C rr ) : a ∈ A q }.<label>(9)</label></formula><p>Next a logistic regression loss (11) is minimized to perform score aggregation. It combines the scores across the R2-D2 components to maximize the correct answer span probability over dataset D. This dataset is composed of the top-M outputs of the extractive reader with the correct answer.</p><p>x(a) = [P e (a) P g (a) P r (p a ) P rr (p a )] (10)</p><formula xml:id="formula_8">− (Aq,gt)∈D softmax a∈Aq w log x(a) + b gt (11)</formula><p>Here p a denotes the passage containing the answer span a, A q is a set of proposed answer spans, gt is the correct answer span, distribution dependencies are dropped for clarity and only the logistic regression parameters w, b are tuned in this step.</p><p>Finally, we theorized the correct answer span might not always be available in the passage set C rr , but the generative reader might be able to generate the answer from its parameters and the evidence given in passages. We introduce the binary classifier, which decides whether to select the best span answer from answer aggregation step or a free-form answer generated via FiD. Given that s agg (q) = max a∈Aq w x(a) + b is the best span score and s * g (q) = log P g (a * q |q, C rr ) is the logprobability of the answer a * q obtained via greedy decoding for question q, a classifier is trained via binary cross-entropy BCE(l, t) with log-odds ratio l and target t to do the binary decision Here, the training dataset D contains only cases where either the extractive or the abstractive prediction is correct (but not both).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Setup</head><p>We implement models in PyTorch <ref type="bibr" target="#b39">(Paszke et al., 2019)</ref> using Transformers <ref type="bibr">(Wolf et al., 2020)</ref>. We use 12GB GPU to train the passage reranker, 48GB GPU for the generative reader, and 16x 32GB GPUs to train the extractive reader with V = 128 passages at its input. The inference runs on 12GB GPU. In all experiments, we used Adam optimizer with a decoupled weight decay <ref type="bibr" target="#b27">(Loshchilov and Hutter, 2017)</ref>. Our models are evaluated by two metrics:</p><p>Exact match (EM) measures the proportion of examples, for which the system prediction matched at least one annotated ground-truth answer. We use the script from <ref type="bibr">Lee et al. (2019) 5</ref> .</p><p>Accuracy@K measures the proportion of examples, for which the ground-truth answer string is present in top-K retrieved passages. We match the string exactly as <ref type="bibr" target="#b17">Karpukhin et al. (2020)</ref>  <ref type="bibr">6</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets and Data Pre-processing</head><p>We evaluate our models on three datasets. Their statistics are available in <ref type="table">Table 1</ref>. To train the reranker we filter out examples, which do not contain golden passage or exact match in top-K retrieved passages. To train the extractive reader, only examples with exact match in golden passage or top-1 retrieved passage are kept. Both filtering strategies are closely described in Appendix D.</p><p>NQ-Open  or NaturalQuestions-Open, consists of real user queries obtained from Google search engine.</p><p>The maximum length of each answer is at most 5 tokens. Each training and development sample contains 1 annotated answer, while test data contain 5-way answer annotation.</p><p>TQ-Open <ref type="bibr" target="#b16">(Joshi et al., 2017)</ref> or TriviaQA-Open consists of question-answer pairs from 14 different trivia quiz websites. Each question contains human annotated answer and a set of answer aliases gathered from Wikipedia. We use the unfiltered version.</p><p>EfficientQA <ref type="bibr" target="#b32">(Min et al., 2021</ref>) is a dataset collected the same way as NQ-Open through 2019, and thus may contain more questions without evidence in our corpus than NQ-Open. Furthermore, it doesn't suffer from dev/test discrepancy, as it was collected for open-domain QA directly (see Appendix B in ). We use the officially released dev set for testing. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Models and Pipeline</head><p>Pruner and Pruning. We fine-tune the base version of ELECTRA <ref type="bibr" target="#b6">(Clark et al., 2020)</ref> with a 2layer feed-forward network on top of it (the same way as authors do it in classification tasks) as binary classifier. To train the pruner, we create training set with 2 negative passages per positive passage from dataset's training examples with golden passage annotation. The negative passages are uniformly sampled from all non-golden Wikipedia's passages.</p><p>To create development and test sets for pruner, we split the subset of dataset's development set, with examples containing golden passage annotation, using a 1 : 2 ratio. We sample only one negative passage per positive sample for development and test sets so that datasets are balanced. We further refer to these datasets as Golden. The procedure is same for both datasets. The system is trained via cross-entropy in 2 epochs using batch size 12 and learning rate 3 · 10 −5 linearly decreasing to 0. The τ threshold is tuned so that we pool top 1.7M passages to fit the 6GiB limit. We combine these relevant passages with missing golden passages from the training data, obtaining 1,702,133 passages in total for NQ-Open and EfficientQA and 1,706,676 passages for TQ-Open.</p><p>Retriever. We use BERT-based DPR from the official checkpoint 7 . Each passage is represented via 768-dimensional embedding. We use multi-7 https://github.com/facebookresearch/DPR set checkpoint for TQ-Open, as the checkpoint for TQ directly isn't officialy released. We use the same knowledge corpus containing 21,015,320 passages based on 12-20-2018 Wikipedia snapshot as <ref type="bibr" target="#b17">Karpukhin et al. (2020)</ref>. In inference time, the retriever passes K = 200 passages C r to reranker.</p><p>Passage reranker. We use the RoBERTa-base  and truncate the inputs to maximum length 256. The linear scheduler with 0.1 warmup proportion is used, the number of epochs is 5 and the model is validated every 40,000 optimization steps. The initial learning rate is 1.6 · 10 −4 , batch size equals to 8 and model reranks 24 passages per question from top-400 DPR retrieved passages. During the inference, top-K retriever passages are rescored and passed to readers.</p><p>Extractive reader. The extractive reader encoder is based on pre-trained ELECTRA-large. Its inputs are truncated if they are longer than the allowed maximum size (512 tokens). During the training phase, all spans from all p ∈ C r 8 that match 9 with at least one of the known answers are selected as target annotations. Therefore the annotations might appear in the wrong context.</p><p>The extractive reader reads top 128 passages during the training phase and when it is used without the reranker. To demonstrate the effect of reranker, the reader reads only top 24 passages if the reranker is used.</p><p>We used a linear scheduler with a warmup for the first 20,000 steps for all models. The maximum number of training steps was 200,000. The model was validated every 20,000 steps, and the best checkpoint among validations was selected. The initial learning rate was 2 · 10 −5 and the optimization step was done after each training example.</p><p>Generative reader. We utilize T5-large  and use a concatenation of question, passages and their respective titles at the Fusionin-Decoder's input the same way as <ref type="bibr" target="#b12">Izacard and Grave (2020a)</ref>. We truncate each passage to length 250 tokens for NQ. For TQ, as questions are significantly longer, we truncate whole inputs to the same size. Following FiD for TQ, we use only human-generated answer. In training, the golden passage always comes first, if available, and we take the rest of passages as ranked from previous step up to V 2 passages. Due to the large memory  <ref type="bibr" target="#b33">(Min et al., 2019a)</ref> 28.1 50.9 110M Path Retriever <ref type="bibr" target="#b0">(Asai et al., 2019)</ref> 32.6 -447M Graph Retriever <ref type="bibr" target="#b34">(Min et al., 2019b)</ref> 34.5 56.0 110M ORQA  33.3 45.0 220M REALM  40.4 -660M ProQA <ref type="bibr" target="#b48">(Xiong et al., 2020)</ref> 34.3 -220M DPR <ref type="bibr" target="#b17">(Karpukhin et al., 2020)</ref> 41.5 56.8 220M DPR-subset * <ref type="bibr" target="#b32">(Min et al., 2021)</ref> 34.8 -220M RDR <ref type="bibr" target="#b49">(Yang and Seo, 2020)</ref> 42.1 57.0 110M GAR+DPR <ref type="bibr" target="#b30">(Mao et al., 2020)</ref> 43.8 -626M ColBERT (large)  48.2 63.2 − 440M RIDER (GAR+DPR) <ref type="bibr" target="#b31">(Mao et al., 2021)</ref> </p><formula xml:id="formula_9">48.3 - 626M</formula><p>Generative BM25+SSG <ref type="bibr" target="#b30">(Mao et al., 2020)</ref> 35.3 58.6 406M T51.1+SSM  35.2 61.6 11B RAG <ref type="bibr">(Lewis et al., 2020)</ref> 44.5 56.8 516M DPR+SSG  42.2 -516M FiD-base <ref type="bibr" target="#b13">(Izacard and Grave, 2020b)</ref> 48.2 65.0 333M FiD-large <ref type="bibr" target="#b13">(Izacard and Grave, 2020b)</ref> 51.4 67.6 848M FiD-large++ * <ref type="bibr" target="#b14">(Izacard et al., 2020)</ref> 53.6 71.3 848M FiD-large++ <ref type="bibr" target="#b14">(Izacard et al., 2020)</ref> 54 requirements of the original approach, we use only V 2 = 25 passages. We use the similar hyperparameters as the original work -batch size 64, learning rate 5 · 10 −5 but no learning rate schedule. In test time, we decode an answer via greedy decoding.</p><formula xml:id="formula_10">.7 73.3 848M Ours R1-D1 (Generative) 49.9 65.4 848M R1-D1 (Extractive) 50.8 65.0 445M R2-D2 (1.7M) 52.6 68.0 1.29B R2-D2 (21M) 55.0 69.9 1.29B R2-D2 (21M) w/ HN-DPR 55.9 - 1.29B</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Compressing the image size</head><p>We save models and index in half-precision without significant loss of performance. Furthermore, we use off-the-shelf ZIP 10 compression to reduce the size of the models and the corpus. To fit the 6GiB limit, we use 100MB CentOS8 docker image 11 and we also compress python's site-packages to reduce the size of PyTorch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Analysis</head><p>Overall results. The effectiveness of our approach is compared with the state-of-the-art in <ref type="table" target="#tab_2">Table 2</ref>.</p><p>Our system composed of just the retriever and FiD reader R1-D1 (Generative) shows inferior performance compared to FiD-large. This is most likely caused by 4 times fewer passages at its input, as in Izacard and Grave (2020b). In contrast, our ELEC-TRA based extractive reader R1-D1 (Extractive) shows large gains compared to extractive state-ofthe-art, while having the same retriever as DPR. We hypothesize this may be caused by its better pretraining method, which shows strong performance through variety of tasks, but also due to training and inference with extra large input size of 128 passages and better objective. Finally, notice that our pruned system R2-D2 (1.7M) is competitive with FiD even when using just 1.7M knowledge corpus, and our full system R2-D2 (21M) is competitive even with FiD++, which uses DPR retriever improved via knowledge distillation and 26M passage corpus which also includes lists. Additionally, we evaluate our model with better retrieval model (HN-DPR) based on DPR checkpoint where hard negatives are mined using the retrieval model itself 12 .</p><p>Reranker performance. Next, we analyze the performance of our retriever and reranker with Ac-curacy@K in <ref type="figure" target="#fig_1">Figure 2</ref>. The reranker improves the accuracy consistently for both, pruned and full version of our pipeline. Remarkably, the pruned version of our pipeline with reranker (rerankedpruned) performs better than the full version only with retriever (retrieved-full) up to K = 26 paragraphs. We observe the similar trend on other datasets, e.g. for TQ-Open test the reranked-pruned improves over retrieved-full up to K = 116 paragraphs (the analyses are in Appendix B). We also include analysis, where we rerank each passage p i according its s i passage score from extractive reader.  We observe results similar to reranker for K &gt; 10, indicating the reader reranks well on its own.</p><p>Pruner. Our simple pruning approach achieved 90.63% accuracy on NQ-Golden test data and 86.94% accuracy on TQ-Golden test data. This indicates that there exists a strong prior over the passages of Wikipedia in these open-domain QA datasets. Interestingly, pruner still missed 2,133/40,670 (5.2%) golden passages from the NQ-Golden training data and 6,676/50,502 (13.2%) from the TQ-Golden training data.</p><p>Memory footprint. Furthermore, we compare the memory footprint of our pruned and compressed system's docker image (pruned system) with the image of the full system on NQ-open in <ref type="figure" target="#fig_2">Figure 3</ref>. The total uncompressed size of an image is 81.01GiB while the size of the pruned image is 5.96GiB (92.6% less). Here, codes are python code and configurations, corpus is an sqlite3 database of passages, and binaries are the OS with python libraries. We save dense index as a raw h5 matrix. Interestingly, the dense corpus has a similar space requirements as the parameters of all 4 models used in this work.</p><p>Ablations. The ablations are listed in <ref type="table" target="#tab_4">Table 3</ref>. We ablate results with and without using passage reranker (first column), with separate readers and their combination (second column) and with different stages of component fusion (third column). Namely, performing a naive answer re-ranking by generative reader means the system chooses the most probable answer span among the top-M spans provided by the extractive reader according to generative reader log-probabilities as shown in equation (9). Analogously, the aggr fusion denotes that the system chooses the most probable answer span according to aggregated scores, as in equation <ref type="formula" target="#formula_0">(11)</ref>. Finally, the aggr+bd fusion denotes the binary de- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.28</head><p>Size in GiB pruned system full system cision, as shown in equation <ref type="formula" target="#formula_0">(12)</ref>. As expected, we observe that reranker improves the results consistently for generative model in all but one case (NQ-Open (1.7M)). The gains are especially large for TQ-Open (over 3 EM, underscored in <ref type="table">Table)</ref>. In fact, the results are very close or better to <ref type="bibr" target="#b13">Izacard and Grave (2020b)</ref>, suggesting that using the FiD reader with smaller context window and reranker is a reasonable alternative to memory inefficient FiD with large input size. Furthermore as expected, the extractive reader without reranker already has top-128 passages at the input, and improvements from the passage reranking are only negligible if any (less than 1 EM).</p><p>Finally, the results on NQ-Open and EfficientQA suggest applying the binary decision does not bring large improvements over the score aggregation if any. However, notice that this is not the case for TriviaQA, where the generative reader performs significantly better compared to extractive reader, suggesting both component fusions play important role in the system.    <ref type="table" target="#tab_7">Table 4</ref> shows all relevant combinations of ranker r, reranker rr, extractive reader e and generative reader g probabilities used in score aggregation. In overall, we observe minor improvements up to 1EM when combining retriever and reranker scores with reader. The impact of adding a binary decision after the score aggregation is shown in <ref type="table" target="#tab_8">Table 5</ref>. Interestingly, the binary decision component significantly improves the performance only without reranked answer scores (first row in both tables), which probably corresponds to an ensemble effect. However, fusing the generative and extractive reader via binary decision performs significantly worse on NQ-Open than fusing both readers together with score aggregation (first row in <ref type="table" target="#tab_8">Table 5</ref> vs. last row in <ref type="table" target="#tab_7">Table 4</ref>). As already noted in ablations, we find this to be quite the opposite for TQ-Open. We hypothesize that the binary decision is strong in cases, where generative reader performs better to extractive reader (the case of TQ-Open).</p><p>Effect of index size. Next we analyze the effect of index size. We start by including all the golden passages from the training data (40,670 for NQ-Open, 50,502 for TQ-Open). We find the difference between using the full index and only golden passages is about 21EM (21.27 for NQ-Open, 21.01 for TQ-Open). Next, we consider adding the passages according to ranking produced by pruner. We Note the R2-D1 system uses retriever and reranker (R2) but only one reader (D1).</p><p>plot the system performance on NQ-Open test data as a function of index size in <ref type="figure" target="#fig_3">Figure 4</ref>. Results on TQ-Open follow the same trends and can be found in Appendix A.</p><p>Connection between retrieval embeddings and pruner. Finally, we analyze whether the DPR embeddings capture the same phenomena as our pruner does. Starting with basic statistics we compute the mean and the variance vectors of d-dimensional embeddings representing pruned (1.7M) set of documents P and those which represent the rest of the knowledge base N . We find that computing the L2 distance between mean and variance yields order of magnitude different results than the distance between randomly permuted splits of P ∪ N with the same size. Next we found the significant difference between average length of embedding vectors from P and N . Conclusively, we train a logistic regression classifier on balanced dataset constructed from P and subset of N , which predicts whether the passage belongs into the pruned set P or not based on its embedding. We found the classifier achieves 84.1% accuracy on the dev set, confirming our hypothesis that the apriori relevance is indeed captured in these embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>Pruning the document space. <ref type="bibr" target="#b32">Min et al. (2021)</ref> presented a simple baseline which includes an index containing 1.65M passages. These include all passages from the Wikipedia articles assigned to top-5 positive passages from DPR training data for NQ <ref type="bibr" target="#b17">(Karpukhin et al., 2020)</ref> (therefore golden pas-sage, and highest-ranking BM25 passages to each question). However this pruning approach led to -6.7 decrease in exact match, while ours led to at most -3 EM with similar amount of passages.</p><p>Similar to our work, <ref type="bibr" target="#b14">Izacard et al. (2020)</ref> employed three strategies to reduce the size of the index: the first is to learn a DPR encoder with embeddings projected to lower dimension, the second is to use product quantization <ref type="bibr" target="#b9">(Gray and Neuhoff, 1998)</ref>, and the third is a linear classifier (a pruner) which filters articles based on their title and list of categories. Nonetheless, their pruning approach leads to~4 EM loss in performance with FiD-large, while still retaining 10M passages.</p><p>Dense retrieval.  proposed the unsupervised pretraining method named inverzecloze task. Fine-tuning such pretrained system via distant supervision surpassed the BM25 baseline for the first time in open-QA.  demonstrated pre-training retriever and reader from scratch using an unsupervised masked language model. <ref type="bibr" target="#b48">Xiong et al. (2020)</ref> demonstrated a pre-training method that does not require massive computational resources for unsupervised pre-training. <ref type="bibr" target="#b17">Karpukhin et al. (2020)</ref> adopted supervised-only approach based on dual-encoder architecture, which surprisingly overtook the unsupervised approaches.  adopted COLBERT , an approach introduced in IR that models fine-grained interaction between question and passage, for opendomain QA. <ref type="bibr">Lewis et al. (2021)</ref> generated a colossal corpus of 65M questions and their respective answers. Given a question, they showed it is possible to match the state-of-the-art performance by picking an answer of the most similar question according to the learned model. <ref type="bibr" target="#b12">Izacard and Grave (2020a)</ref> demonstrated a way of distilling FiD reader knowledge into retriever, improving its retrieval significantly, while also allowing to train retriever from scratch without any passage relevance supervision.</p><p>Passage reranker. Previous work in QA based on neural nets used bi-LSTM encoders <ref type="bibr" target="#b44">(Wang et al., 2018;</ref><ref type="bibr" target="#b21">Lee et al., 2018)</ref> that score each document independently. Over time, bi-LSTM were replaced by BERT-like transformer encoders <ref type="bibr" target="#b40">(Qiao et al., 2019;</ref><ref type="bibr" target="#b45">Wang et al., 2019)</ref>. For document ranking,  proposed a multi-stage architecture. The first stage scores each document independently, and the second estimates the more relevant document from all document pairs. Another document ranking approach uses the seq2seq model to generate a true or false answer to the document's relevance to the query . Recent works have often focused on effective reranking. <ref type="bibr" target="#b47">Xin et al. (2020)</ref> achieved inference speedup using early exiting, <ref type="bibr" target="#b15">Jang and Kim (2020)</ref> proposed a smaller and faster model, and <ref type="bibr" target="#b31">Mao et al. (2021)</ref> came up with a method which uses reader's predictions to rerank the passages. <ref type="bibr" target="#b11">Iyer et al. (2020)</ref> marked answer predictions from reader in passages and learned to re-rank top answers along with their passage context. Our reranker is most similar to ; <ref type="bibr" target="#b28">Luan et al. (2021)</ref>, except that unlike in IR, we assume there is just one correct passage and thus train our model via categorical cross-entropy.</p><p>Reader. Recent work considers two approaches towards modeling the reader -generative and extractive. The generative reader generates an answer while conditioned on question or relevant passages <ref type="bibr">Lewis et al., 2020)</ref>.  proposed to concatenate a question with top retriever passages as the input of pretrained seq2seq generative model. <ref type="bibr" target="#b13">Izacard and Grave (2020b)</ref> showed its suffices to concatenate the passages in the decoder of seq2seq model, increasing the amount of top-passages the model can depend on dramatically. The extractive reader used in open-QA assumes that the answer is a continuous span string in multiple paragraphs <ref type="bibr" target="#b3">(Chen et al., 2017)</ref>. <ref type="bibr" target="#b5">Clark and Gardner (2018)</ref> proposed to aggregate the probabilities of distantly supervised answer matches via maximum marginal likelihood (MML). <ref type="bibr" target="#b25">Lin et al. (2018)</ref> proposed to denoise distantly supervised answer string matches in MML via paragraph-ranker. <ref type="bibr" target="#b33">Min et al. (2019a)</ref> introduced a learning objective, which decides randomly whether to use MML objective or hard expectationminimization via continuous annealing scheme during the training. <ref type="bibr" target="#b4">Cheng et al. (2020)</ref> experimented with different assumptions for MML, showing improvement when marginalizing over components of span probability independently. <ref type="bibr">Fajcik et al. (2020)</ref> proposed to model joint span probability directly via compound objective, instead of modeling the probability of span's start and end independently. <ref type="bibr" target="#b17">Karpukhin et al. (2020)</ref> incorporated an independent passage classifier loss to his MML objective.</p><p>Unlike others, our work incorporates both, the generative and the extractive approach. While our generative reader follows <ref type="bibr" target="#b13">Izacard and Grave (2020b)</ref>, our extractive reader uses a novel loss function, which includes marginalizing over target passages independently of its other components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>This work proposed R2-D2, a novel state-of-the-art pipeline for open-domain QA based on 4 components: retriever, reranker, generative reader and extractive reader. Furthermore, it proposed an approach for reducing the pipeline size to fit 6GiB Docker Image. The core idea of our approach was to drastically reduce the colossal number of passages commonly used within the knowledge-base of retrieval-based open-domain QA systems (by 92%) with only minor loss of performance (-3 EM). We believe our pipeline composed of multiple heterogeneous components is an ideal benchmark system for future research. Additionally, the pruned index size opens up new possibilities, as it now fits to most modern GPUs. However, with such a drastic reduction of knowledge-base, more questions arise: What is it that makes the passage being apriori relevant? Does this strong prior over passages suggest that these open-domain answering datasets aren't really "open"?. We would like to address these questions in our future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Additional Index Size Analysis</head><p>This section contains additional index size analysis analogous to <ref type="figure" target="#fig_3">Figure 4</ref> on Trivia-Open test data shown in <ref type="figure" target="#fig_4">Figure 5</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Additional Accuracy Analysis</head><p>Analysis of Accuracy@K on EfficientQA data is shown in <ref type="figure" target="#fig_7">Figure 7</ref>, on NQ-open validation data in <ref type="figure" target="#fig_6">Figure 6</ref> and on TriviaQA validation data in <ref type="figure" target="#fig_8">Figure 8</ref> and test data in <ref type="figure" target="#fig_9">Figure 9</ref>. The pruned version of our pipeline with reranker (rerankedpruned) performs better than the full version only with retriever (retrieved-full):      <ref type="table" target="#tab_7">This section includes results analogical to Tables  4, 5 on validation data of NQ-Open (Tables 6, 7)</ref>, EfficientQA <ref type="table" target="#tab_12">(Tables 8, 9</ref>) and TQ-Open <ref type="table" target="#tab_14">(Tables 10,</ref>  <ref type="bibr">11,</ref><ref type="bibr">12,</ref><ref type="bibr">13</ref>         </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Additional Component Fusion Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Data Pre-processing</head><p>This section describes how the training datasets for reranker and extractive reader are filtered, and how the distant supervision labeling is generated. Note not each example contains golden passage, as not each example can be mapped to the used dump of Wikipedia. We use the same golden passage mapping as <ref type="bibr" target="#b17">Karpukhin et al. (2020)</ref>. For passage reranking, the input must contain at least one positive example. We meet this condition either by adding a golden passage or searching for the passage with an answer in the top-400 results retrieved by DPR. In detail about the search, first the Simple tokenizer proposed in DrQA 13 tokenizes each passage and golden answer. The positive example is the best-scored tokenized passage that contains an exact match with one of the tokenized answers. Note the search proceeds in the same way as in DPR 14 implementation.</p><p>The extractive reader is trained only on samples which contain exact match to at least one of the annotated answers in the top-1 passage, or golden passage if it is available. The exact match is performed on the subword token level (i.e. in ELEC-TRA's tokenization).</p><p>Next, the span annotations are extracted from the passages at the reader's input. Note each sample may contain multiple answers. The annotations for each answer in each sample are obtained differently in retrieved passages and in the golden passage. For retrieved passages, we search for the answer's exact matches in passages, and use each match as target annotation. For golden passage, we also search for the answer's exact matches in it. If there is none, the answer is soft-matched with single sub-sequence of golden passage, which yields highest non-zero F1 score. The F1 soft-match is also performed on the subword token level. Therefore answers with zero highest F1 soft-match with golden passage and no exact match in any of the reader's input passages are discarded.</p><p>Because the brute-force computation of a span with the greatest nonzero F1 score is potentially very demanding, we found the length limit for spans that are worth searching (see Theorem D.2).</p><p>To compare brute-force with upper bound implementation, we run an experiment on 16,741 passages (retrieved for NQ-Open dev). The average time per passage for brute-force was 121 ms and only 9 ms for implementation with an upper bound.</p><p>The soft match is described in Algorithm 1. It assumes that there is no exact match.</p><p>Algorithm 1 Soft match Require: set of spans S and answer span a 1: function SOFTMATCH(S, a) for all t ∈ S of size actSize do 8:</p><p>score ← F1(t, a) 9:</p><p>if score &gt; bestScore then 10:</p><p>bestSpan ← t 11:</p><p>bestScore ← score 12:</p><p>lenLimit ← |a| |t|+|a|−sta sta 13:</p><p>actSize ← actSize + 1 14:</p><p>return bestSpan Lemma D.1. Let t and a be non-empty spans and 0 &lt; s ta ≤ |a| number of shared tokens for them. Then 15 |t| ≤ |a| |t| + |a| − s ta s ta .</p><p>Proof. To prove it by contradiction assume that |t| &gt; |a| |t| + |a| − s ta s ta ,</p><p>then s ta |t| &gt; |a||t| + |a||a| − |a|s ta ,</p><p>and also 0 &lt; s ta ≤ |a|, thus |a||a| − |a|s ta ≥ 0. Therefore even if we assume that 15 |x| symbolises number of tokens in span x |a||a| − |a|s ta = 0. We get s ta |t| &gt; |a||t|</p><formula xml:id="formula_14">s ta &gt; |a| ,<label>(16)</label></formula><p>which is in contradiction with 0 &lt; s ta ≤ |a|.</p><p>Theorem D.2. Let S be a set of non-empty spans, a an non-empty answer span, t non-empty trial span, 0 &lt; s ta ≤ |a| is number of shared tokens for t and a, and S b = {z|z ∈ S ∧ |z| ≥ |a| |t|+|a|−sta sta }. Then the theorem states that ∀x ∈ S b <ref type="figure">(F1(x, a) ≤ F1(t, a)</ref>) .</p><p>(17)</p><p>Proof. To prove it by contradiction assume that ∃x ∈ S b (F1(x, a) &gt; F1(t, a)) .</p><p>F1 score can be expressed as: </p><formula xml:id="formula_16">F1(b, c) = 2s bc |b| + |c| ,<label>(19)</label></formula><p>which is in contradiction with x ∈ S b .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Softmax Notation</head><p>Usually, softmax function σ : R K → R K is defined as:</p><formula xml:id="formula_18">σ(v) i = e v i K j=1 e v j .<label>(22)</label></formula><p>However, some parts of this work used variant of softmax that is defined as follows:</p><formula xml:id="formula_19">softmax x∈D f (x) y = e f (y) x∈D e f (x) ,<label>(23)</label></formula><p>where D is the input set, f : D → R, y ∈ D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Decoding the Distributions from the Extractive Reader</head><p>We analyzed the subsets of joint probability space over spans obtained via multiplication of distributions as explained in section 3.2 in <ref type="table" target="#tab_7">Table 14</ref>.</p><p>The factors of this space are the distribution given by the outer product of independent probability distributions P start (.)P end (.) denoted as I, joint probability distribution P joint (.) denoted as J, and passage distribution P passage (.) denoted as C.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G Passage Reranker Revision</head><p>In previous version of this work we used a Longformer encoder <ref type="bibr" target="#b1">(Beltagy et al., 2020)</ref> with concatenated passages at it's input to benefit from the early fusion between passages. Therefore each passage was scored not only according to the question but also according to other passages. However, we did not observe any significant benefits when we used the Longformer setup over a RoBERTa which scores each passage independently (see <ref type="table" target="#tab_8">Table 15</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H LDA Analysis of Pruned Passages</head><p>We apply LDA <ref type="bibr" target="#b2">(Blei et al., 2003)</ref> with 100 topics to random subset of 1M passages from knowledge base. Then we apply T-SNE (Van der Maaten and Hinton, 2008) and project LDA vectors into 2 dimensions. The results are shown in <ref type="figure">Figure 10</ref>. The pruned passages seem to be evenly distributed through the topics.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>[s agg (e); s * g (e)] + b, t).(12)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>10 https://launchpad.net/ubuntu/+source/zip 11 nvidia/cuda:10.2-base-centos8 Accuracy@K on test-data of NQ-Open.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Component sizes inside the docker image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Index size analysis on NQ-Open test data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Index size analysis on TQ-Open test data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>•</head><label></label><figDesc>on NQ-open (dev) up to K = 32 paragraphs, • on NQ-open (test) up to K = 26 paragraphs, • on EfficientQA up to K = 43 paragraphs, • on TriviaQA (dev) up to K = 110 paragraphs, • on TriviaQA (test) up to K = 116 paragraphs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Analysis of Accuracy@K on NQ-Open (dev).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Analysis of Accuracy@K on EfficientQA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 :</head><label>8</label><figDesc>Analysis of Accuracy@K on TriviaQA (dev).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 :</head><label>9</label><figDesc>Analysis of Accuracy@K on TriviaQA (test).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Comparison with the state-of-the-art in EM. #θ denotes the estimated amount of model parameters. Symbol</figDesc><table /><note>* denotes systems with pruned or compressed index. Symbol − reports the result only for smaller system with 220M parameters.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>48.12 -1.59 48.64 50.78 -2.14 63.18 65.01 -1.83 44.50 47.00 -2.50 -gen -46.23 48.30 -2.07 48.39 49.92 -1.53 63.72 65.38 -1.66 43.50 44.83 -1.33 -ext+gen naive 47.05 49.14 -2.09 50.00 51.88 -1.88 64.04 66.17 -2.13 45.61 47.06 -1.45 -ext+gen aggr 49.05 50.87 -1.82 51.94 54.13 -2.19 65.41 67.42 -2.01 47.50 50.44 -2.94 -ext+gen aggr+bd 49.35 51.18 -1.83 51.88 54.07 -2.19 65.69 67.37 -1.68 47.28 49.72 -2.44 .91 52.38 54.90 -2.52 66.86 68.66 -1.80 49.44 52.00 -2.56 ext+gen aggr+bd 50.25 52.07 -1.82 52.58 54.99 -2.41 67.96 69.94 -1.98 49.22 52.22 -3.00</figDesc><table><row><cell>Passage reranking</cell><cell cols="2">Readers Fusion</cell><cell>NQ-Open (dev) 1.7M 21M ∆</cell><cell>NQ-Open 1.7M 21M</cell><cell>∆</cell><cell>TriviaQA 1.7M 21M</cell><cell>∆</cell><cell>EfficientQA 1.7M 21M</cell><cell>∆</cell></row><row><cell>-</cell><cell cols="9">ext 46.53 ext --46.64 48.38 -1.74 48.92 50.72 -1.80 63.51 65.46 -1.95 45.06 47.56 -2.50</cell></row><row><cell></cell><cell>gen</cell><cell>-</cell><cell cols="7">47.11 49.40 -2.29 48.31 50.69 -2.38 67.18 69.14 -1.96 45.22 47.33 -2.11</cell></row><row><cell></cell><cell>ext+gen</cell><cell>naive</cell><cell cols="7">47.78 49.99 -2.21 50.33 52.44 -2.11 66.02 68.01 -1.99 46.78 49.11 -2.33</cell></row><row><cell></cell><cell>ext+gen</cell><cell>aggr</cell><cell>49.89 51.80 -1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Ablation study. The ∆ column shows the exact match difference caused by pruning.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Component fusion. Furthermore, we analyze the</figDesc><table><row><cell>P  *</cell><cell>∅</cell><cell>{r}</cell><cell cols="2">{rr} {r, rr}</cell></row><row><cell>{e}</cell><cell cols="3">50.72 51.41 51.55</cell><cell>51.69</cell></row><row><cell>{g}</cell><cell cols="3">52.44 52.88 53.35</cell><cell>53.19</cell></row><row><cell cols="4">{e, g} 54.63 55.10 54.82</cell><cell>54.90</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>Results for different pipeline components used for score aggregation on NQ. See text below for details.</figDesc><table><row><cell>P  *</cell><cell>∅</cell><cell>{r}</cell><cell cols="2">{rr} {r, rr}</cell></row><row><cell>{e}</cell><cell cols="3">52.85 53.30 53.10</cell><cell>52.94</cell></row><row><cell>{g}</cell><cell cols="3">52.44 52.77 53.21</cell><cell>53.07</cell></row><row><cell cols="4">{e, g} 54.35 55.10 54.46</cell><cell>54.99</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>Results for binary decision on NQ for different aggregated pipeline components fromTable 4.</figDesc><table /><note>performance of each component combination in the score aggregation and its impact on the component fusion via binary decision. Both fusions are tuned on validation data and reported on test data of the NQ-Open dataset with full index. See Appendix C for analysis on additional datasets.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 6 :</head><label>6</label><figDesc>Score aggregation -NQ-Open (dev).</figDesc><table><row><cell>P  *</cell><cell>∅</cell><cell>{r}</cell><cell cols="2">{rr} {r, rr}</cell></row><row><cell>{e}</cell><cell cols="3">50.65 51.24 51.01</cell><cell>51.17</cell></row><row><cell>{g}</cell><cell cols="3">50.36 50.91 50.68</cell><cell>50.90</cell></row><row><cell cols="4">{e, g} 52.24 52.29 52.27</cell><cell>52.07</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 7 :</head><label>7</label><figDesc>Binary decision -NQ-Open (dev).</figDesc><table><row><cell>P  *</cell><cell>∅</cell><cell>{r}</cell><cell cols="2">{rr} {r, rr}</cell></row><row><cell>{e}</cell><cell cols="3">47.56 48.33 48.89</cell><cell>48.72</cell></row><row><cell>{g}</cell><cell cols="3">49.11 49.56 50.22</cell><cell>50.11</cell></row><row><cell cols="4">{e, g} 50.78 51.67 50.89</cell><cell>52.00</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 8 :</head><label>8</label><figDesc>Score aggregation -EfficientQA.</figDesc><table><row><cell>P  *</cell><cell>∅</cell><cell>{r}</cell><cell cols="2">{rr} {r, rr}</cell></row><row><cell>{e}</cell><cell cols="3">48.33 50.06 49.39</cell><cell>49.67</cell></row><row><cell>{g}</cell><cell cols="3">48.94 49.50 50.06</cell><cell>49.72</cell></row><row><cell cols="4">{e, g} 50.78 51.83 50.94</cell><cell>52.22</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 9 :</head><label>9</label><figDesc>Binary decision -EfficientQA.</figDesc><table><row><cell>P  *</cell><cell>∅</cell><cell>{r}</cell><cell cols="2">{rr} {r, rr}</cell></row><row><cell>{e}</cell><cell cols="3">65.07 65.21 65.16</cell><cell>65.24</cell></row><row><cell>{g}</cell><cell cols="3">67.68 67.72 67.73</cell><cell>67.76</cell></row><row><cell cols="4">{e, g} 68.13 68.19 68.17</cell><cell>68.12</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 10 :</head><label>10</label><figDesc>Score aggregation -TQ-Open (dev).</figDesc><table><row><cell>P  *</cell><cell>∅</cell><cell>{r}</cell><cell cols="2">{rr} {r, rr}</cell></row><row><cell>{e}</cell><cell cols="3">69.03 69.03 69.01</cell><cell>68.99</cell></row><row><cell>{g}</cell><cell cols="3">69.54 69.46 69.62</cell><cell>69.70</cell></row><row><cell cols="4">{e, g} 69.77 69.79 69.67</cell><cell>69.61</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 11 :</head><label>11</label><figDesc>Binary decision -TQ-Open (dev).</figDesc><table><row><cell>P  *</cell><cell>∅</cell><cell>{r}</cell><cell cols="2">{rr} {r, rr}</cell></row><row><cell>{e}</cell><cell cols="3">65.54 65.64 65.60</cell><cell>65.61</cell></row><row><cell>{g}</cell><cell cols="3">68.25 68.17 68.21</cell><cell>68.26</cell></row><row><cell cols="4">{e, g} 68.45 68.57 68.66</cell><cell>68.66</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 12 :</head><label>12</label><figDesc>Score aggregation -TQ-Open (test).</figDesc><table><row><cell>P  *</cell><cell>∅</cell><cell>{r}</cell><cell cols="2">{rr} {r, rr}</cell></row><row><cell>{e}</cell><cell cols="3">69.34 69.28 69.23</cell><cell>69.26</cell></row><row><cell>{g}</cell><cell cols="3">69.76 69.71 69.65</cell><cell>69.77</cell></row><row><cell cols="4">{e, g} 69.80 69.89 69.88</cell><cell>69.94</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 13 :</head><label>13</label><figDesc>Binary decision -TQ-Open (test).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head></head><label></label><figDesc>From Lemma D.1 |t| ≤ |x|. Therefore s ta &lt; s xa , to satisfy the inequality (in equation 20), and we know that 0 &lt; s xa ≤ |a|. So let the s xa = |a| (the maximum) then 2|a| |x| + |a| &gt; 2s ta |t| + |a| |a|(|t| + |a|) &gt; s ta |x| + s ta |a| |x| &lt; |a| |t| + |a| − s ta s</figDesc><table><row><cell>thus</cell><cell>2s xa |x| + |a|</cell><cell>&gt;</cell><cell>2s ta |t| + |a|</cell><cell>.</cell><cell>(20)</cell></row></table><note>ta ,</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head>Table 14 :</head><label>14</label><figDesc>The results of extractive reader with different types of distribution used for decoding. See text for details.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Our demo is available at http://r2d2.fit.vutbr.cz/. Code and preprocessed data are available at https://github.com/ KNOT-FIT-BUT/R2-D2.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">We tried decoding from the subsets of these probabilities in Appendix F not observing significant difference.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">https://cutt.ly/rkZNIer 6 https://cutt.ly/0luNhx4</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">Note that we use the retriever output directly. 9 Matching strategies are described in Appendix D.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12">https://cutt.ly/Ux5Yt4h</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank Jan Doležal for implementing an R2-D2 demo. This work was supported by the Czech Ministry of Education, Youth and Sports, subprogram INTERCOST, project code: LTC18006. The computation used the infrastructure supported by the Czech Ministry of Education, Youth and Sports from the Large Infrastructures for Research, Experimental Development and Innovations project "IT4Innovations National Supercomputing Center -LM2018140".</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Red points are pruned passages from the 1.7M set. Other colors mark passages by their most dominant topic found by LDA. We remove passages with maximum topic weight lesser than 0.2 to clusterize the plot data.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akari</forename><surname>Asai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuma</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.10470</idno>
		<title level="m">Learning to retrieve reasoning paths over wikipedia graph for question answering</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Longformer: The long-document transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.05150</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Latent dirichlet allocation. the Journal of machine Learning research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Reading wikipedia to answer open-domain questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1870" to="1879" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Probabilistic assumptions matter: Improved models for distantlysupervised document-level question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5657" to="5667" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Simple and effective multi-paragraph reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1078</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="845" to="855" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">ELECTRA: Pretraining text encoders as discriminators rather than generators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Search needs a shake-up</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><forename type="middle">Etzioni</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">476</biblScope>
			<biblScope unit="issue">7358</biblScope>
			<biblScope unit="page" from="25" to="26" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Fajcik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Jon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.12804</idno>
		<title level="m">Santosh Kesiraju, and Pavel Smrz. 2020. Rethinking the objectives of extractive question answering</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Neuhoff</surname></persName>
		</author>
		<title level="m">Quantization. IEEE transactions on information theory</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="2325" to="2383" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zora</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panupong</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.08909</idno>
		<title level="m">Realm: Retrieval-augmented language model pretraining</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Reconsider: Re-ranking using span-focused cross-attention for open domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinivasan</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yashar</forename><surname>Mehdad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.10757</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Distilling knowledge from reader to retriever for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.04584</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Leveraging passage retrieval with generative models for open domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.01282</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">A memory efficient baseline for open domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><forename type="middle">De</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.15156</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Document re-ranking model for machine-reading and comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngjin</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harksoo</forename><surname>Kim</surname></persName>
		</author>
		<idno type="DOI">10.3390/app10217547</idno>
	</analytic>
	<monogr>
		<title level="j">Applied Sciences</title>
		<imprint>
			<biblScope unit="issue">21</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1147</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1601" to="1611" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Dense passage retrieval for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barlas</forename><surname>Oguz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ledell</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.04906</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Relevance-guided supervision for openQA with colBERT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omar</forename><surname>Khattab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matei</forename><surname>Zaharia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.00814</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Colbert: Efficient and effective passage search via contextualized late interaction over bert</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omar</forename><surname>Khattab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matei</forename><surname>Zaharia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="39" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Natural questions: a benchmark for question answering research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennimaria</forename><surname>Palomaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivia</forename><surname>Redfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danielle</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="453" to="466" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Ranking paragraphs for improving answer recall in opendomain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinhyuk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seongjun</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunjae</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miyoung</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaewoo</forename><surname>Kang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1053</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="565" to="569" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Latent retrieval for weakly supervised open domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1612</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6086" to="6096" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandara</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heinrich</forename><surname>Küttler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.11401</idno>
		<title level="m">Tim Rocktäschel, et al. 2020. Retrievalaugmented generation for knowledge-intensive nlp tasks</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linqing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pasquale</forename><surname>Minervini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heinrich</forename><surname>Küttler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.07033</idno>
		<title level="m">Aleksandra Piktus, Pontus Stenetorp, and Sebastian Riedel. 2021. PAQ: 65 million probably-asked questions and what you can do with them</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Denoising distantly supervised opendomain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haozhe</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1736" to="1745" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.05101</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">Decoupled weight decay regularization. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<title level="m">Sparse, dense, and attentional representations for text retrieval. Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Generation-augmented retrieval for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuning</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengcheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yelong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.08553</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuning</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengcheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yelong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.00294</idno>
		<title level="m">Reader-guided passage reranking for open-domain question answering</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennimaria</forename><surname>Palomaki</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.00133</idno>
	</analytic>
	<monogr>
		<title level="m">EfficientQA competition: Systems, analyses and lessons learned</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A discrete hard EM approach for weakly supervised question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2844" to="2857" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Knowledge guided text retrieval and reading for open domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.03868</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Ambigqa: Answering ambiguous open-domain questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5783" to="5797" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.04085</idno>
		<title level="m">Passage re-ranking with bert</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Document ranking with a pretrained sequence-to-sequence model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiying</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronak</forename><surname>Pradeep</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.findings-emnlp.63</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="708" to="718" />
		</imprint>
	</monogr>
	<note>Online</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.14424</idno>
		<title level="m">Multi-stage document ranking with BERT</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="8026" to="8037" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Understanding the behaviors of BERT in ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenghao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.07531</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">How much knowledge can you pack into the parameters of a language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5418" to="5426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Real-time open-domain question answering with dense-sparse phrase index</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinhyuk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankur</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4430" to="4441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">R3: Reinforced ranker-reader for opendomain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Klinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerry</forename><surname>Tesauro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5981" to="5988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Multi-passage BERT: A globally normalized BERT model for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofei</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xiang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1599</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5878" to="5882" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Transformers: State-of-theart natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rémi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joe</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clara</forename><surname>Patrick Von Platen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yacine</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Canwen</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teven</forename><forename type="middle">Le</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gugger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
	<note>Mariama Drame, Quentin Lhoest, and Alexander M. Rush. 2020</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Early exiting BERT for efficient document ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaoliang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.sustainlp-1.11</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SustaiNLP: Workshop on Simple and Efficient Natural Language Processing</title>
		<meeting>SustaiNLP: Workshop on Simple and Efficient Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="83" to="88" />
		</imprint>
	</monogr>
	<note>Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Progressively pretrained dense corpus index for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">Yang</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.00038</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Is retriever merely an approximator of reader?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sohee</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.10999</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
