<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Point Cloud Oversegmentation with Graph-Structured Deep Metric Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Loic</forename><surname>Landrieu</surname></persName>
							<email>loic.landrieu@ign.fr</email>
							<affiliation key="aff1">
								<orgName type="laboratory">STRUDEL</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Boussaha</surname></persName>
							<email>mohamed.boussaha@ign.fr</email>
							<affiliation key="aff2">
								<orgName type="laboratory">ACTE</orgName>
								<address>
									<settlement>Saint-Mandé</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Univ. Paris-Est</orgName>
								<orgName type="institution" key="instit2">IGN-ENSG</orgName>
								<address>
									<settlement>LaSTIG</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Point Cloud Oversegmentation with Graph-Structured Deep Metric Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose a new supervized learning framework for oversegmenting 3D point clouds into superpoints. We cast this problem as learning deep embeddings of the local geometry and radiometry of 3D points, such that the border of objects presents high contrasts. The embeddings are computed using a lightweight neural network operating on the points' local neighborhood. Finally, we formulate point cloud oversegmentation as a graph partition problem with respect to the learned embeddings.</p><p>This new approach allows us to set a new state-of-the-art in point cloud oversegmentation by a significant margin, on a dense indoor dataset (S3DIS) and a sparse outdoor one (vKITTI). Our best solution requires over five times fewer superpoints to reach similar performance than previously published methods on S3DIS. Furthermore, we show that our framework can be used to improve superpoint-based semantic segmentation algorithms, setting a new state-ofthe-art for this task as well.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The interest of segmenting point clouds into sets of points known as superpoints-the 3D equivalent of superpixels-as a preprocessing step to their analysis has been extensively demonstrated <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b55">56]</ref>. However, these unsupervized methods rely on the assumption that segments which are geometrically and/or radiometrically homogeneous are also semantically homogeneous. This assertion should be challenged, especially since the quality of any further analysis is limited by the quality of the initial oversegmentation. Our objective in this paper is to formulate a supervized framework for oversegmentating 3D point clouds into semantically pure superpoints in order to facilitate their semantic segmentation.</p><p>Although superpixel-based methods and deep learning have both been around for a long time in computer vision, convolutional neural networks have only recently been used for superpixel oversegmentation. Notably, <ref type="bibr" target="#b36">[37]</ref> introduced a loss function emulating oversegmentation metrics, and which is compatible with graph-based clustering methods. <ref type="bibr" target="#b27">[28]</ref> propose a fully differentiable version of the SLIC superpixel algorithm <ref type="bibr" target="#b0">[1]</ref>, allowing for end-to-end training of spatial clustering methods. Both approaches have shown promising results, displaying significant improvement upon methods relying on handcrafted descriptors. In this paper, we build upon these ideas, albeit in the 3D setting.</p><p>We propose formulating point cloud oversegmentation as a deep metric learning problem structured by an adjacency graph defined on an input 3D point cloud. We introduce the graph-structured contrastive loss, a loss function which learns to embed 3D points homogeneously within objects and with high contrast at their interface. This loss can be adapted to the non-differentiable task of oversegmentation by using our cross-partition weighting strategy. The points' embeddings themselves are computed from the points' local geometry and radiometry by a lightweight model inspired from PointNet <ref type="bibr" target="#b40">[41]</ref> and called Local Point Embedder (LPE). Finally, the superpoints are defined as a piecewise-constant approximation of the learned embedding in the adjacency graph, in the manner of <ref type="bibr" target="#b20">[21]</ref>.</p><p>Furthermore, we define the end-goal of our point cloud oversegmentation as assisting semantic segmentation methods by providing semantically pure superpoints. We show that our approach can be integrated with the superpoint graph approach of <ref type="bibr" target="#b31">[32]</ref> to significantly improve the partition step, and consequently the resulting semantic segmentation. The contributions of this paper are as follows:</p><p>• We present the first supervized framework for 3D point cloud oversegmentation;</p><p>• We introduce the graph-structured contrastive loss, which can be combined with our cross-partition weighting strategy to produce point embeddings with high contrast at objects' borders;</p><p>• We introduce the local point embedder, a lightweight architecture, inspired by <ref type="bibr" target="#b40">[41]</ref>, to embed the local geometry and radiometry of 3D points in a compact way;</p><p>• We significantly improve the state-of-the-art of point cloud oversegmentation for two well-known and very different datasets;</p><p>(a) Input Point Cloud (b) Learned Embedding (c) Oversegmentation (d) True Objects <ref type="figure">Figure 1</ref>: Illustration of our framework on a hard-to-segment scene with a white board on a white wall: a colored point cloud is given as input (a), an embedding is computed for each point (b), which allows a clustering technique to compute an oversegmentation (c), which closely follows the ground truth (d). Throughout the figures of this paper, the embeddings are projected into a 3-dimensional space to allow color visualization.</p><p>• When combined with the superpoint graph semantic segmentation method, our approach improves upon the state-of-the-art for this task as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Superpixels/ Supervoxels: There is a large body of literature on the oversegmentation of images into superpixels <ref type="bibr" target="#b48">[49]</ref> and videos into supervoxels <ref type="bibr" target="#b56">[57]</ref>. These methods can be divided into two groups: graph-based, which exploit the pixels' connectivity <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b35">36]</ref>, and cluster-based, which use the pixels' relative positions <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b32">33]</ref>. Recently, deep learning methods have been successfully used to develop supervized superpixels oversegmentation approaches, either graph-based <ref type="bibr" target="#b36">[37]</ref>, or cluster-based <ref type="bibr" target="#b27">[28]</ref>.</p><p>Oversegmentation of 3D Point Clouds: The aforementioned methods perform well on images, but rely on the regular structure of pixels. 3D point clouds, as unordered point sets with irregular distributions, require special attention. <ref type="bibr" target="#b3">[4]</ref> propose three extensions of 2D local variation graphbased method <ref type="bibr" target="#b13">[14]</ref> to 3D oversegmentation and study different strategies for constructing the graph, edge weights, and subgraph merging. <ref type="bibr" target="#b47">[48]</ref> introduce a graph-structured approach which exploits the structure of LiDAR sensors to remove edges corresponding to boundary points. <ref type="bibr" target="#b38">[39]</ref> propose a cluster-based method based on the k-means algorithm and octrees. However, this method remains sensitive to the clusters' initialization. <ref type="bibr" target="#b14">[15]</ref> use the visual saliency of RGBD images to initialize clustering. <ref type="bibr" target="#b34">[35]</ref> propose a clustering method which does not require such initialization, and is therefore less sensitive to the irregular densities of LiDAR point clouds. Likewise, <ref type="bibr" target="#b20">[21]</ref> introduce an initialization-free segmentation model formulated as a graph-structured optimization problem. All these methods rely on hand-crafted geometric and/or colorimetric features.</p><p>Deep Learning for 3D Point Clouds: The work in <ref type="bibr" target="#b40">[41]</ref> has pioneered the use of deep learning for 3D point cloud processing. However, this usage has so far only been used for semantic segmentation <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b53">54]</ref>, object detection <ref type="bibr" target="#b61">[62]</ref>, or reconstruction <ref type="bibr" target="#b18">[19]</ref>. To the best of our knowledge, no supervised 3D point oversegmentation technique that leverages deep learning-based embeddings to generate superpoints has been developed yet.</p><p>Metric Learning: Metric learning aims to learn a similarity function between data points with properties corresponding to a given task <ref type="bibr" target="#b29">[30]</ref>. In practice, an embedding function associates each data point with a feature vector attuned to a given objective. These objectives can be related to classification <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b44">45]</ref>, or clustering <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b22">23]</ref>, among many other applications (see <ref type="bibr" target="#b1">[2]</ref> for a useful taxonomy). In the context of deep learning, this can be achieved by using a well-chosen loss, such as the contrastive loss <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b4">5]</ref>; the triplet loss <ref type="bibr" target="#b23">[24]</ref> or some of its variants <ref type="bibr" target="#b52">[53]</ref>. Notably, metric learning has recently been used to improve the quality of learned features for a 3D point semantic segmentation task <ref type="bibr" target="#b11">[12]</ref>. However, our task is different in the sense that our embeddings are related to oversegmentation through a graph partition problem rather than classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>Our goal is to produce a high-quality 3D-point cloud oversegmentation, so that it can be in turn used by superpoint-based semantic segmentation algorithms. This translates into the following three properties:</p><p>(P1) object-purity: superpoints must not overlap over objects, especially if their semantics are different; (P2) border recall: the interface between superpoints must coincide with the borders between objects; (P3) regularity: the shape and contours of the superpoints must be simple.</p><p>Our approach can be broken down into two steps: in Section 3.1 we present the local cloud embedder, a simple neural network which associates each point with a compact embedding that captures its local geometry and radiometry. In Section 3.2, we describe how we compute a point cloud oversegmentation from this embedding using either graph or cluster-based oversegmentation algorithms.  <ref type="figure">Figure 3</ref>: Architecture of the local point embedder (LPE) <ref type="bibr" target="#b6">(7)</ref>, which computes an embedding set-feature X i and point-feature x i encoding the local radiometry and the normalized geometry. The L 2 block normalizes the output on the unit sphere <ref type="bibr" target="#b5">(6)</ref>.</p><formula xml:id="formula_0">X i x i MLP 1 maxpool MLP 2 L2 e i</formula><p>Throughout this paper we will stress the difference between set-features, which are unordered sets of descriptors (such as information related to the neighbors of a point), and point-features, which characterize a specific point. Set features will always be capitalized, while point-features will use lowercase.</p><p>Let us consider a point cloud C, with each point i defined with its position p i ∈ R 3 and d-dimensional radiometric information r i ∈ R d (this can be colors if available, or intensity for LiDAR scans, or be ignored if none is available). Each point i is associated with the set-features P i and R i , respectively comprised of the position and radiometry of its k nearest neighbors N i in the input cloud:</p><formula xml:id="formula_1">P i = {p j | j ∈ N i } , R i = {r j | j ∈ N i }.</formula><p>For ease of notation, any operator or function f applied to a set-feature X is to be understood as being applied to all its elements:</p><formula xml:id="formula_2">f (X) = {f (x) | x ∈ X}.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Local Point Embedding</head><p>Our objective is to associate to each point a compact mdimensional embedding e i characterizing its point-features (position, color, etc.) and the geometry and radiometry of its local neighborhood. The embeddings are constrained to be within the m-unit sphere S m , as suggested by <ref type="bibr" target="#b51">[52]</ref>, to prevent collapse during the training phase, and to normalize their distance with one another.</p><p>To this end, we introduce the Local Point Embedder (LPE), a lightweight network inspired by PointNet <ref type="bibr" target="#b40">[41]</ref>. However, unlike PointNet, LPE does not try to extract information from the whole input point cloud, but rather encodes each point based on purely local information. Here, we describe the different units of our network. Spatial Transform: This unit takes the positions of a target point p i and its local k-neighborhood P i , as represented in <ref type="figure">Figure 2</ref>. It normalizes the neighbors' coordinates around p i , and such that the standard deviation of the point's position is equal to 1 (3). Then, this neighborhood is rotated around the z axis with a 2 × 2 rotation matrix computed by small PointNet network PTN <ref type="bibr" target="#b3">(4)</ref>. As advocated by <ref type="bibr" target="#b26">[27]</ref>, these steps aim to standardize the position of the neighborhood clouds of each point. This helps the next network to learn position distribution. Along the normalized neighborhood positionP i , this unit also outputs geometric point-featuresp i describing the elevation p (z) i , the neighborhood radius, as well as its original orientation (through the 4 values of the rotation matrix:</p><p>[Ω x,x , Ω x,y , Ω y,x , Ω y,y ]) <ref type="bibr" target="#b4">(5)</ref>. By keeping track of the normalization operations, the embedding can stay covariant with the original neighborhood's radius, height, and original orientation, even though the points' positions have been normalized and rotated.</p><formula xml:id="formula_3">rad = std (P i ) (1) Ω = PTN(P i ) (2) P i = (P i − p i )/rad (3)P i = {p × Ω | p ∈ P i } (4) p i = [p (z) i , rad, Ω]<label>(5)</label></formula><p>Local Point Embedder: The LPE network, represented in <ref type="figure">Figure 3</ref>, computes a normalized embedding from two inputs: a point-feature x i and a set-feature X i . As in PointNet <ref type="bibr" target="#b40">[41]</ref>, the set-features are first processed independently by a multi-layer perceptron (denoted MLP 1 ) comprised of a succession of layers in the following order: linear, activation (ReLu <ref type="bibr" target="#b37">[38]</ref>), normalization (batch <ref type="bibr" target="#b25">[26]</ref>), and so on. The resulting set-features are then maxpooled into a point-feature, which is concatenated with the input point-feature. The resulting vector is processed through another multi-layer perceptron MLP 2 <ref type="bibr" target="#b6">(7)</ref>, and finally normalized on the unit sphere.</p><p>The embeddings e i are computed for each point i of C through a shared LPE <ref type="bibr" target="#b7">(8)</ref>. The input set-feature X i is set as the concatenation of the neighbour's transformed posi-tionP i and their radiometric information R i , while the input point-feature x i is composed of the neighborhood geometric point-featurep i and the radiometry r i of point i.</p><formula xml:id="formula_4">L 2 (·) = ·/ ·<label>(6)</label></formula><formula xml:id="formula_5">LPE(X i , x i ) = L 2 (MLP 2 ([max (MLP 1 (X i )) , x i ])) (7) e i = LPE([P i , R i ], [p i , r i ])<label>(8)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Graph-Based Point Cloud Oversegmentation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">The Generalized Minimal Partition Problem</head><p>Once the embeddings are computed, we define the superpoints with respect to an adjacency graph G = (C, E) derived from the point cloud C. Note that E can be obtained from the neighbors' structure used for the LPE. However, we find that much smaller neighborhoods are needed to capture the cloud's adjacency structure than to describe the local neighborhood of points. As proposed by <ref type="bibr" target="#b20">[21]</ref>, we define the superpoints as the constant connected components in G of a piecewise-constant approximation of the embeddings e ∈ S C m . This approximation is the solution f of the following optimization problem:</p><formula xml:id="formula_6">f = arg min f ∈R C×m i∈C f i − e i 2 + (i,j)∈E w i,j [f i = f j ] , (9)</formula><p>with w ∈ R E + the edges' weight and [x = y] equal to 0 if x = y and 1 otherwise. To encourage the network to split along high contrast areas, we define the edge weight as</p><formula xml:id="formula_7">w i,j = λ exp −1 σ e i − e j 2 ,</formula><p>with parameters λ, σ ∈ R + . Problem <ref type="bibr" target="#b8">(9)</ref>, known as the generalized minimal partition (GMP) and introduced by <ref type="bibr" target="#b30">[31]</ref>, is neither continuous, differentiable, nor convex, and therefore the global minimum cannot be realistically retrieved. However, the 0 -cut pursuit algorithm <ref type="bibr" target="#b30">[31]</ref> allows for fast approximate solutions.</p><p>The contour penalty automatically implements (P3) for reasonable parameterization of the problem. Note that the optimization variable f can take its values in R C×m , while each embedding e i is constrained on the m-sphere. This is a limitation of our approach due to efficiency concerns. It can lead to some suboptimal approximate solutions. However, we show in the numerical experiments that the learned embeddings lead to satisfactory partitions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Graph-Structured Contrastive Loss</head><p>As mentioned earlier, the semantic purity property (P1) is the first quality of superpoints. Once could imagine taking a metric estimating the semantic purity of the solution of (9) as a loss function. However, the GMP is a noncontinuous non-convex optimization problem, and computing connected components on a graph is inherently nondifferentiable. This makes optimizing directly with respect to properties of the partition very hard, if not impossible.</p><p>Instead, we note that if the border recall property (P2) is implemented (i.e. superpoints and objects share the same boundaries), then (P1) ensues. Therefore, we propose a surrogate loss called graph-structured contrastive loss focusing on correctly detecting the borders between objects. To this end, we define E intra (resp. E inter ) the set of intraedges (resp. inter-edges) as the set of edges of G between points within the same object (resp. point from different adjacent objects).</p><p>In the spirit of the original contrastive loss <ref type="bibr" target="#b7">[8]</ref>, our loss encourages embeddings of vertices linked by an intra-edge to be similar, while rewarding different embeddings when linked by an inter-edge:</p><formula xml:id="formula_8">(e) = 1 |E|   (i,j)∈Eintra φ (e i − e j ) + (i,j)∈Einter µ i,j ψ (e i − e j )   ,</formula><p>with φ (resp. ψ) a function minimal (resp. maximal) at 0, and µ i,j ∈ R Einter a weight on inter-edges. A point embedding function minimizing this loss will be uniform within objects and have stark contrasts at their interface. Consequently, the components of the piece-wise constant approximation of (9) should follow the objects' borders. This loss differs from the triplet loss <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b51">52]</ref>, as it involves all vertices within a graph (or a sub-graph) at once, and not just an anchor and related positive/negative examples. In this way, it bypasses the problem of example picking altogether. Indeed, the positive and negative examples are directly given by the adjacency structure set by E intra and E inter . It differs from <ref type="bibr" target="#b11">[12]</ref> as it does not try to learn semantic information, but rather to compute a signal on a graph such that its constant approximation respects certain properties, with no attention to semantics. Indeed, objects of different classes can share the same embeddings as long as they are never adjacent, such as floors and ceilings for indoor scenes. We chose φ, the function promoting intra-object homogeneity as φ(x) <ref type="figure" target="#fig_1">Figure 4</ref>). This means that the first term of is the (pseudo)-Huber graph-total variation on the E intra edge <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b5">6]</ref>, promoting smooth homogeneity of embeddings within the same object.</p><formula xml:id="formula_9">= δ( x 2 /δ 2 + 1 − 1) with δ = 0.3 (repre- sented in</formula><p>With ψ(x) = max (1 − x , 0), the second part of is the opposite of the truncated graph-total variation <ref type="bibr" target="#b60">[61]</ref> on the inter-edges. It penalizes similar embeddings at the border between objects. Conscious that our embeddings are restricted to the unit sphere, we threshold this function for differences larger than 1 (corresponding to a 60 degree angle). In other words, ψ(x) encourages vertices linked by an inter-edge to take embeddings with an euclidean distance of 1, but does not push for a larger difference.</p><p>Note that any embeddings that are constant within ob-jects, and with a difference of at least 1 between adjacent objects, will have 0 loss. The four-color theorem <ref type="bibr" target="#b16">[17]</ref> tells us that it is always possible as long as the dimension of our embedding is at least 3. However, because embeddings are computed by the LPE, borders which do not present recognizable geometric or radiometric configurations cannot be recovered by our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Cross-Partition Weighting</head><p>The choice of µ i,j plays a crucial role in the efficiency of the graph-structured contrastive loss. Although (P2) does imply (P1), small errors in the former can have drastic consequences in the latter. Indeed, a single missed edge can erroneously fuse two large superpoints covering different objects. Therefore, we need to incorporate the induced partition's purity into the loss. <ref type="bibr" target="#b36">[37]</ref> introduced the segmentation-aware affinity loss (SEAL) implementing this idea. They propose weighting intra-edges as 1, and inter-edges as µ i,j = 1+|S | −|S\O S | for i and j within the same superpoint S, with O S the majority-object, i.e. the object for which most points of S belongs to. Although <ref type="bibr" target="#b36">[37]</ref> boasts impressive results for superpixel oversegmentation, we were not able to extend this success within our framework. We believe this stems from three reasons: (i) all border edges of a superpoint are weighted identically regardless of their influence on the purity and the size of the interface; (ii) as soon as a superpoint no longer overlaps an object's border, its weight decreases dramatically to 1, making the loss very unstable; (iii) <ref type="bibr" target="#b36">[37]</ref> uses a different graph-based clustering <ref type="bibr" target="#b35">[36]</ref>.</p><p>To overcome these limitations, we introduce the crosspartition weighting strategy. We first compute the crosssegmentation graph G = (C, E), defined as the adjacency graph of the cross-partition C of C between the superpoints partition S and the object partition O. In other words, C is the set of connected components of the graph G when all edges either between objects or between superpoints are removed, and the super-edge (i.e. set of edges) (U, V ) ∈ E is the set of inter-edges of E inter between U and V in C:</p><formula xml:id="formula_10">C = {O ∩ S | O ∈ O, S ∈ S} E = {{(i, j) ∈ (U × V ) ∩ E inter } | U, V ∈ C} .</formula><p>We associate the following weight µ U,V to each superedge (U, V ) and µ i,j to each edge:</p><formula xml:id="formula_11">µ U,V = µ min (| U |, | V |) | (U, V ) | for (U, V ) ∈ E µ i,j = µ U,V for all (i, j) ∈ (U, V )</formula><p>with µ a parameter of the model. Such weights simultaneously take into account the influence of the edges in the purity and the shape of the interfaces. Indeed, should an superpoint majority object trespassing interface µ LW,LD = µ RW,RD = <ref type="figure">Figure 5</ref>: Illustration of the cross-partition weighting strategy on a scene comprised of a door (D) and a wall (W). Two superpoints L (left) and R (right) overlap the door. The superedge (LW, LD)(resp. (RW, RD)) represent the adjacency between the part of the left (resp. right) superpoint covering the wall and the part covering the door. With fewer trespassing points and a longer interface than (RW, RD), the weights of the edges constituting (LW, LD) are smaller. edge of the superedge (U, V ) be missed as a border, the superpoints U and V would be merged. Since U and V cover different objects (by definition of E), such a merger would induce at least min (| U |, | V |) vertices trespassing, i.e. not being in the majority-object of the merged superpoint.The weights are also divided by the number of edges constituting the interface between U and V in order to distribute evenly the penalty over the number of edges constituting an interface. This prevents long borders from being over-represented in the loss. See <ref type="figure">Figure 5</ref> for an illustration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Cluster-Based Oversegmentation</head><p>We also implemented a generalization of the method of <ref type="bibr" target="#b27">[28]</ref> to the 3D setting. The main advantage of this approach is that the loss can directly implement (P1) through the cross-entropy of the averaged semantic classes within superpoints. However, this approach remains hindered by its sensitivity to the superpoint initialization, and its inability to adapt the superpoints' size to the local complexity of the scene. Furthermore, as it bypasses (P3), it produces superpoints with complicated contour.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Implementation Details</head><p>We use a modified version of the 0 -cut pursuit algorithm 1 <ref type="bibr" target="#b30">[31]</ref>, with two main differences:</p><p>• to prevent the creation of many small superpoints in regions of high contrast, we merge components greedily with respect to the objective energy defined in (9), as long as they are smaller than a given threshold ;</p><p>• we heuristically improved the forward step (8) from <ref type="bibr" target="#b30">[31]</ref>, such that the regularization strength increases geometrically by a factor (of 0.7) along the iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input cloud</head><p>Ground truth objects LPE embeddings SSP (ours) VCCS <ref type="bibr" target="#b38">[39]</ref> Lin in <ref type="bibr" target="#b34">[35]</ref> (b) vKITTI scene with 233 objects. Superpoint count: SSP 420, VCCS 422, Lin 425. <ref type="figure">Figure 6</ref>: Illustration of the oversegmentations of our framework, and from competing algorithms.</p><p>This helps improve the quality of the lower optima retrieved, and consequently the oversegmentation's.</p><p>To limit the size of the superpoints we concatenate to the points' embeddings their 3D coordinates in (9) multiplied by a parameter α spatial , in the manner of <ref type="bibr" target="#b0">[1]</ref>. This determines the maximum size that superpoints can reach.</p><p>In all our experiments, we set m the dimension of our embeddings to 4. We choose a light architecture for the LPE, with less than 15, 000 parameters. The exact network configurations for each dataset are detailed in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Numerical Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets</head><p>We evaluate our approach on two datasets of different natures. The first one is S3DIS <ref type="bibr" target="#b2">[3]</ref>, composed of dense indoor scans of rooms in an office setting. The second one is vKITTI <ref type="bibr" target="#b9">[10]</ref>, an outdoor dataset of urban scenes that mimics sparse LiDAR acquisitions. Note that only S3DIS has individual object annotation. We consider the objects of vKITTI to be the connected components of the semantic labels in the adjacency graph G. For vKITTI, we consider the performance of our algorithm with and without color information. Both datasets are large scale (close to 600 million points for S3DIS and close to 15 million for vKITTI). We subsample them using a regular grid of voxels (3cm wide for S3DIS and 5cm wide for vKITTI). In each voxel, we average the position and color of the contained points. This allows us to decrease the computation time and memory load.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Point Cloud Oversegmentation</head><p>Evaluation Metrics: There are many standard metrics which assess the quality of point cloud oversegmentations with respect to properties (P1), (P2), and (P3). In particular, the Boundary Recall (BR) and Precision (BP) are used to evaluate the ability of the superpoints to adhere to, and not cross, object boundaries ((P2), (P3)). In the literature, these measures are defined with respect to boundary pixels <ref type="bibr" target="#b38">[39]</ref> or points <ref type="bibr" target="#b34">[35]</ref>. However, we argue that transition occurs between points and not at points for point clouds. Consequently, we define E pred inter the set of predicted transition, i.e. the subset of edges of E that connect two points of C in two different superpoints. These metrics are often given with respect to a tolerance, i.e. the distance at which a predicted transition must take place from an actual object's border for the latter to be considered retrieved. We set this distance to 1 edge, which leads us to define E <ref type="bibr" target="#b0">(1)</ref> inter the set of inter-edges expanded to all directly adjacent edges in E:</p><formula xml:id="formula_12">E (1) inter = {(i, j) ∈ E | ∃(i, k) or (j, k) ∈ E inter } .</formula><p>This allows us to define the boundary recall and precision with 1 edge tolerance for a set of predicted transition E pred inter :</p><formula xml:id="formula_13">BR = | E pred inter ∩ E (1) inter | | E inter | , BP = | E pred inter ∩ E (1) inter | | E pred inter | .</formula><p>Since the end-goal of our point cloud oversegmentation framework is to provide useful superpoints for semantic segmentation, we define the Oracle Overall Accuracy (OOA). To assess object purity (P1), this metric characterizes the accuracy of the labeling that associates each superpoint S of a segmentation S with its majority ground-truth label. Formally, let l ∈ K C be the semantic labels of each point within a set of classes K, we define the OOA of a point cloud segmentation S as:  with [x = y] the function equal to 1 if x = y and 0 otherwise. Note that the OOA is closely related to the ASA <ref type="bibr" target="#b35">[36]</ref>, but consider the majority labels of all points within a superpixel rather than the label of the objects with most overlap. In this sense, it is a tighter upper bound to the achievable accuracy of a superpoint-based semantic classification algorithm using S. This metric is also more fair than the undersegmentation error <ref type="bibr" target="#b32">[33]</ref> for other methods such as <ref type="bibr" target="#b20">[21]</ref>, or our cluster-based approach, as they do not try to retrieve objects directly, but rather regions of C with homogeneous semantic labeling.</p><formula xml:id="formula_14">l oracle (S) = mode {l i | i ∈ S} OOA = 1 | C | S∈S i∈S l i = l oracle (S) ,</formula><p>Competing algorithms: We denote by SSP (Supervized SuperPoint) our method when using LPE to learn point embeddings and then derive the superpoints using the graphbased methods described in Section 3.2.2, and SSP-Cluster when using the cluster-based method defined in Section 3.3 instead. We first assess the benefit of learning embeddings by comparing our results to those of <ref type="bibr" target="#b20">[21]</ref>, dubbed here Geom-Graph. This method computes superpoints by solving the generalized minimal partition problem as well, but with handcrafted geometric features in place of our learned embeddings. We illustrate in <ref type="figure" target="#fig_2">Figure 7</ref> the oversegmentations produced by our approach and two state-of-the-art algorithms: VCCS <ref type="bibr" target="#b38">[39]</ref> and the work of Lin in <ref type="bibr" target="#b34">[35]</ref>.</p><p>We observe that our approach significantly outperforms the other approaches on all metrics. In particular, we remark that SSP only requires under 350 superpoints to reach a performance comparable with VCCS with over 1, 800 superpoints on S3DIS. Furthermore, the quality of the border is unmatched in our range of superpoints. The improvement is less significant on vKITTI, which could be due to the difficulty of constructing an adjacency graph on such a sparse acquisition. The performance is degraded further without color information, as some transition are not predictable with purely from the geometry. Geom-Graph performs well on the accuracy, but not on the boundary. This is expected as the handcrafted geometric features cannot detect some borders, such as adjacent walls. SSP-Cluster performs better than the unsupervized cluster-based method of Lin et al. , but still suffer from the typical limitations of clustering methods, such as sensitivity to initialization.</p><p>In terms of computational speed, the embeddings can be computed very efficiently in parallel on a GPU with over 3 million embeddings per second on a 1080Ti GPU. The bottleneck remains solving the graph partition problem in <ref type="bibr" target="#b8">(9)</ref>, which can process around 100, 000 points per second.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Semantic Segmentation</head><p>In <ref type="table" target="#tab_1">Table 1 and Table 2</ref>, we show how our point cloud oversegmentation framework can be successfully used by the superpoint-based semantic segmentation technique of [32] 2 (SPG). We replace the unsupervized superpoint computation with our best-performing approach, SSP. We evaluate the resulting semantic segmentation using standard classification metrics: overall accuracy (OA), mean perclass accuracy (mAcc) and mean per-class intersectionover-union (mIOU). We observe a significant increase in the performance of SPG, beating concurrent methods on both datasets. In particular, we observe that our method allows for better retrieval of small objects (see detailed IoU in the appendix), which translates into much better per-class metrics, although the overall accuracy is not necessarily better than the latest state-of-the-art algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Ablation Study</head><p>In <ref type="table">Table 3</ref>, we present an ablation study to empirically justify some of our design choices. To make things more legible, we present the increase/decrease of the 3 performance metrics at 500 superpoints (linearly interpolated) of alternative methods compared to ours, on the first cross-validation fold of the S3DIS dataset. In particular we present Prop-weight, an alternative version in which the cross-partition weighting is replaced by a simple inversely-proportional weighting of the inter/intra edges. Predictably, this method gives lesser results as the edges are not weighted according to their influence in the partition. However, since the weights of the intra-edge are proportionally higher, the border precision is improved. We implemented the weights of the segmentation-aware affinity loss of <ref type="bibr" target="#b36">[37]</ref> as well for method SEAL-weights, with comparable results to the Prop-weight. In +TV-TV, we replace our choice of function φ and ψ in the loss by respectively | · | and − | · |, so that our loss is closer to the pairwise affinity loss used by <ref type="bibr" target="#b11">[12]</ref> (but still structured by the graph). However, this approach wouldn't give meaningful partition as the intra-edge term conflicts with the constraint that the embeddings are constrained on the sphere. Removing this restriction leads the collapse of the embeddings around 0. We also tried to stack the LPE in layers, using or not a residual structure comparable to the one used in <ref type="bibr" target="#b21">[22]</ref> to increase their receptive fields (more details are given in the appendix). The best results were achieved with two layers: 2-Layers and 2-Residuals. However, we observe that when compared with LPE of a similar number of parameters, the gains are insignificant if not null. We conclude that to embed points in order to detect borders, a small receptive field with a shallow architecture is sufficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we presented the first supervized 3D point cloud oversegmentation framework. Using a simple point</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>OA mAcc mIoU 6-fold cross validation PointNet <ref type="bibr" target="#b40">[41]</ref> in <ref type="bibr" target="#b9">[10]</ref>    <ref type="table">Table 3</ref>: Impact of some of our design choice on S3DIS.</p><p>Best is the SSP method with cross-partition weights.</p><p>embedding network and a new graph-structured loss function, we were able to achieve significant improvements compared to the state-of-the-art of point cloud oversegmentation. When combined with a superpoint-based semantic segmentation method, our method sets a new state-of-theart of semantic segmentation as well. A video illustration is accessible at https://youtu.be/bKxU03tjLJ4. The source code will be made available to the community as well as trained networks in an update to the superpointgraph repository 2 . Future work will focus on improving the solving method for the generalized minimum minimal partition problem to better handle spherically-bounded variables, and to improve its computational performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Material</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Models configuration</head><p>In this section, we give the full hyper-parameterization of all the networks used in the paper, for both oversegmentation and semantic segmentation tasks, and for both datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1. Models configuration for oversegmentation</head><p>Our supervized oversegmentation model has a number of critical hyper-parameters to tune, given in <ref type="table" target="#tab_4">Table 4</ref>. We detail here the rationale behind our choices. Local neighborhood and adjacency graphs: For both datasets, we find that setting the local neighborhood size to 20 was enough for embeddings to successfully detect objects' border. Combined with our lightweight structure, this results in a very low memory load overall. The adjacency graph G requires more attention depending on the dataset. For the dense scans of S3DIS, the 5-nearest neighbors adjacency structure was enough to capture the connectivity of the input clouds. For the sparse scans of vKITTI, we added Delaunay edges <ref type="bibr" target="#b8">[9]</ref> (pruned at 50 cm) such that parallel scans lines would be connected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Networks configuration:</head><p>For the LPE and the PointNet structure in the spatial transform, we find that shallow and wide architectures works better than deeper networks. We give in <ref type="table" target="#tab_4">Table 4</ref> the size of the linear layers, before and after the maxpool operation. Over 250, 000 points can be embedded simultaneously on 11GB RAM in the training step, while keeping track of gradients.</p><p>Intra-edge factor: The graph-structured contrastive loss presented in 3.2.2 requires setting a weight µ determining the influence of inter-edges with respect to intra-edge. Since most edges of G are intra-edges in practice, we defineμ such that µ =μc with c = | E |/| V | the average connectivity of G. Note that c can be determined directly from the construction of the adjacency graph (it is equal to k in a k-nearest neighbor graph for example). A value ofμ = 1 means that the total influence in of inter-edges and intra-edges are identical. Since we are interested in oversegmentation, we setμ to 5 in all our experiments, but note that the network is not very sensitive to this parameter, as demonstrated experimentally: a value ofμ = 3 gives a relative performance of (−0.2, −0.6, +1.5) while a value of 8 gives (+0.1, −0.5, +1.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Regularization Strength:</head><p>The generalized minimal partition problem defined in 3.2.1 requires setting the regularization strength factor λ, determining the cost of edges crossing superpoints. We remark that the LPE produces embeddings of points with an euclidean distance of at least 1 over predicted objects' borders. Some calculus shows us that for a λ ≤ 1/(2c), the solution f of (8) should predict superpoints borders at all edges whose vertices have a difference of embeddings of at least 1 (note that there is no guarantee that the greedy 0-cut pursuit algorithm will indeed predict a border). We use this value to define a normalized regularization strengthλ such that λ =λ/(4c), whose default value is 1.</p><p>Regularization path: To obtain the regularization paths in <ref type="figure" target="#fig_2">Figure  7</ref>, we first train the network with a regularization strength of λ = 1 (see 3.2.2). We then compute partitions withλ varying from 0.2 to 6 with no fine-tuning required.</p><p>Smallest superpoint: To automatically select a minimal superpoint size (in number of points) appropriate to the coarseness of the segmentation, we heuristically set:</p><formula xml:id="formula_15">nλ min = (max 1 2 n (1) min , n (1) min + 1 2 n (1) min log(λ)</formula><p>where n <ref type="bibr" target="#b0">(1)</ref> min is a dataset-specific minimum superpoints size for λ = 1. For example, for n (1) min = 50, the smallest superpoint allowed for a small regularization strengthλ = 0.2 will be 33, while it is 70 for the coarse partition obtained withλ = 6. While specific applications may require setting up this variable manually, this allowed us to produce the regularization paths in <ref type="figure" target="#fig_2">Figure 7</ref> while only varyingλ.</p><p>Optimization: Given the small size of our network, we train our network for a short number of epochs (see <ref type="table" target="#tab_4">Table 4</ref>), with decay events set at 0.7. We use Adam optimizer <ref type="bibr" target="#b28">[29]</ref> with gradient clipping at 1 <ref type="bibr" target="#b17">[18]</ref>. Training takes around 2 hours per fold on our 11GB VRAM 1080Ti GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mini-batches:</head><p>For graph-based clustering, the training phase processes batches of 16 point clouds at once, for which a subgraph of size 10 000 points is extracted. For the clustering-based segmentation, which is more memory intensive, and since subgraphs have to be larger to be meaningfully covered by the initial voxels, we set a batch size of 1 and a subgraph of 100 000. As a consequence, we replace the batchnorm layers of the LPEs by group norms with 4 groups <ref type="bibr" target="#b54">[55]</ref>.</p><p>Augmentation: In order to build more robust networks, we added Gaussian noise of deviation 0.03 clamped at 0.1 on the normalized position and color of neighborhood clouds. We also added random rotation of the input clouds for the network to learn rotation invariance. To preserve orientation information, the clouds are rotated as a whole instead of each neighborhood. This allows the spatial transform to detect change in orientation, which can be used to detect borders.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Models configuration for semantic segmentation</head><p>We used the open-source superpoint-graph implementation github/loicland/superpoint-graph without any modification beyond changing the oversegmentation step and some changes in the hyper-parameters. The full parameterization is given in <ref type="table" target="#tab_5">Table 5</ref>.</p><p>To compensate for the edges missed by the 0-cut pursuit approximation, due in part to its ignoring the spherical nature of the embeddings, we set the regularization strengthλ lower than 1 for both datasets. This help improve the accuracy and border recall. The subsequent decrease in border precision is compensated by the fact that the SPG, through its context leveraging module, can learn to propagate the semantic information to small superpoints.    <ref type="table">Table 6</ref>: Results on the S3DIS dataset on fold "Area 5" (top) and micro-averaged over all 6 folds (bottom). Intersection over union is shown split per class, with the highest value over all methods in bold.</p><p>For the same reason, we chose a lower superpoint size for S3DIS from the segmentation experiments. We extended the superpoint graph subsampling threshold to 4hops instead of 3, because our method SSP tends to produce thin components near interfaces. Since the vKITTI dataset is much smaller than S3DIS, we chose smaller networks to mitigate overfitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Residual Point Embedder</head><p>We have tested an alternative configuration for the local point embedded, in which they were stacked in layers, similarly to the classical convolutional architecture for images. We first introduce a slightly changed architecture, the Residual Point Embedder RPE, whose design is based on an LPE but takes a supplementary input eini. Instead of computing a new embedding, the RPE computes a residual <ref type="bibr" target="#b9">(10)</ref> which is added to this initial embedding before normalization <ref type="formula" target="#formula_16">(11)</ref> </p><p>The second change is the layers architecture. The RPEs in the first layer compute the embeddings from the local geometric and radiometric information alone, and their initial embedding is set to 0 (12) (such that they behave exactly like LPEs). The RPEs in subsequent layers compute new embeddings from the local radiometry and geometry as well as the embeddings computed at the previous layer of the points neighbors E t i <ref type="bibr" target="#b12">(13)</ref>. Note that for a point to be processed by a layer, all its neighbors must have been embedded by the previous layer. This allows the RPEs to have increasingly broader receptive fields, and to correct errors that might have been done by previous layers. Note that the geometric information are only processed by the spatial transform once, cascading its values to all residual layers. </p><p>Alternatively, all initial embeddings can be set to 0, which means that each layer computes a new embedding from the local position and the embeddings of the previous layers. As mentioned in the ablation study, while these networks did perform well, their benefits shrink when a simple LPE is given as many parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Detailed results and illustration</head><p>We present in <ref type="table">Table 6</ref> the per-class IoU for the S3DIS dataset. We illustrate the semantic segmentation results in <ref type="figure">Figure 8</ref>. We also made a video illustration which can be accessed at https: //youtu.be/bKxU03tjLJ4.  <ref type="figure">Figure 8</ref>: Illustration of the results on the semantic segmentation. In the first row we show a successful semantization for a complex scene of S3DIS. In the second row, we show a failure case in which a white board is oversegmented in too many small superpoints. This makes their classification harder by the semantic segmentation network. In the third row we see a successful semantization of an urban outdoor scene from vKITTI. On the fourth row, we can observe in the background road signs with high color contrasts, which are segmented in small superpoints. This makes them very hard to classify and they are missed by the semantic segmentation algorithm.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>3 Figure 2 :</head><label>32</label><figDesc>Architecture of the spatial transform network. It takes a point's coordinate as point-input p i and the coordinates of its neighbors as set-input P i . The vertex r computes the radius of a point cloud (1), the vertex z extract the vertical coordinate of a point's position, and the vertex PTN is a small PointNet-like network (2) which outputs a 2 × 2 rotation matrix around the z axis<ref type="bibr" target="#b3">(4)</ref>. In this and subsequent figures, set-features (respectively point-features) are represented by a dotted line (respectively a solid line). The numbers above the lines represent the size of the channels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>The functions φ (in blue) and ψ (in red) used in the graph-structured contrastive loss.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 7 :</head><label>7</label><figDesc>Performance of the different algorithms on the 6-fold S3DIS dataset (a, b, c), and the 6-fold vKITTI dataset (d, e, f). The results of the method annotated with an asterix * have not been reported before. SSP-Cluster and VCCS are not represented for vKITTI for the sake of legibility as their performance is too low.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>:R(Xi, xi) = MLP2 ([max (MLP1(Xi)) , xi])(10)RPE(xi, Xi, eini) = L2 (eini + R(Xi, xi))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>78.5 66.2 47.6 Engelmann et al. in [10] 81.1 66.4 49.7 Performance of different methods for the semantic segmentation task on the S3DIS dataset. The top table is for the 6-fold cross validation, the bottom table on the fifth fold only.</figDesc><table><row><cell>PointNet++ [42]</cell><cell cols="2">81.0 67.1 54.5</cell></row><row><cell cols="3">Engelmann et al. in [12] 84.0 67.8 58.3</cell></row><row><cell>SPG [32]</cell><cell cols="2">85.5 73.0 62.1</cell></row><row><cell>PointCNN [34]</cell><cell cols="2">88.1 75.6 65.4</cell></row><row><cell>SSP + SPG (ours)</cell><cell cols="2">87.9 78.3 68.4</cell></row><row><cell>Fold 5</cell><cell></cell><cell></cell></row><row><cell>PointNet [41] in [12]</cell><cell>-</cell><cell>49.0 41.1</cell></row><row><cell cols="3">Engelmann et al. in [12] 84.2 61.8 52.2</cell></row><row><cell>pointCNN [34]</cell><cell cols="2">85.9 63.9 57.3</cell></row><row><cell>SPG [32]</cell><cell cols="2">86.4 66.5 58.0</cell></row><row><cell>PCCN [54]</cell><cell>-</cell><cell>67.0 58.3</cell></row><row><cell>SSP + SPG (ours)</cell><cell cols="2">87.9 68.2 61.7</cell></row><row><cell>Method</cell><cell></cell><cell>OA mAcc mIoU</cell></row><row><cell>PointNet [41]</cell><cell></cell><cell>79.7 47.0 34.4</cell></row><row><cell cols="3">Engelmann et al. in [12] 79.7 57.6 35.6</cell></row><row><cell cols="3">Engelmann et al. in [10] 80.6 49.7 36.2</cell></row><row><cell>3P-RNN [60]</cell><cell></cell><cell>87.8 54.1 41.6</cell></row><row><cell cols="2">SSP + SPG (ours)</cell><cell>84.3 67.3 52.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Performance of different methods for the semantic segmentation task on the vKITTI dataset with 6-fold cross validation.</figDesc><table><row><cell>Method</cell><cell cols="2"># parameters OOA BR</cell><cell>BP</cell></row><row><cell>Best</cell><cell>13,816</cell><cell cols="2">96.2 73.3 22.1</cell></row><row><cell>Prop-weights</cell><cell>13,816</cell><cell cols="2">-2.6 -12.2 +10.4</cell></row><row><cell>SEAL-weights</cell><cell>13,816</cell><cell cols="2">-1.3 -11.3 +3.8</cell></row><row><cell>2-Layers</cell><cell>14,688</cell><cell cols="2">-0.1 -0.7 -0.3</cell></row><row><cell>2-Residuals</cell><cell>14,688</cell><cell cols="2">+0.0 -0.2 -0.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Configuration of the embedding network for the S3DIS and vKITTI datasets.</figDesc><table><row><cell>parameter</cell><cell>S3DIS</cell><cell>vKITTI</cell></row><row><cell># parameters</cell><cell>278,897</cell><cell>118,737</cell></row><row><cell cols="3">Superpoint embedders configuration [[64,64,128,128,256], [256,64,32]] [[64,64,128,256], [128,32,32]]</cell></row><row><cell>STN configuration</cell><cell>[[64,64,128], [128,64]]</cell><cell>[[32,32,64], [64,32]</cell></row><row><cell>subsampling hops</cell><cell>4</cell><cell></cell></row><row><cell>max SPgraph size</cell><cell cols="2">768</cell></row><row><cell>λ</cell><cell>0.1</cell><cell>0.5</cell></row><row><cell>n min</cell><cell>25</cell><cell>15</cell></row><row><cell>epochs</cell><cell>350</cell><cell>100</cell></row><row><cell>decay event</cell><cell>180,250,280,320</cell><cell>40,50,60,70,80</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Configuration of the semantic segmentation network. All values not mentioned in this table use default parameters from [32] 34] 85.9 63.9 57.3 92.3 98.2 79.4 0.0 17.6 22.8 62.1 80.6 74.4 66.7 31.7 62.2 56.7 A5 SPG [32] 86.4 66.5 58.0 89.4 96.9 78.1 0.0 42.8 48.9 61.6 84.7 75.4 69.8 52.6 2.1 52.2 A5 SSP + SPG (ours) 87.9 68.2 61.7 91.9 96.7 80.8 0.0 28.8 60.3 57.2 85.5 76.4 70.5 49.1 51.6 53.3 PointNet [41] in [11] 78.5 66.2 47.6 88.0 88.7 69.3 42.4 23.1 47.5 51.6 42.0 54.1 38.2 9.6 29.4 35.2 Engelmann et al. [11] 81.1 66.4 49.7 90.3 92.1 67.9 44.7 24.2 52.3 51.2 47.4 58.1 39.0 6.9 30.0 41.9 Engelamnn in [13] 84.0 67.8 58.3 92.1 90.4 78.5 37.8 35.7 51.2 65.4 61.6 64.0 51.6 25.6 49.9 53.7 SPG [32] 85.5 73.0 62.1 89.9 95.1 76.4 62.8 47.1 55.3 68.4 73.5 69.2 63.2 45.9 8.7 52.9 PointCNN [34] 88.1 75.6 65.4 94.8 97.3 75.8 63.3 51.7 58.4 57.2 69.1 71.6 61.2 39.1 52.2 58.6 SSP + SPG (ours) 87.9 78.3 68.4 91.7 95.5 80.8 62.2 54.9 58.8 68.4 78.4 69.2 64.3 52.0 54.2 59.2</figDesc><table><row><cell>Method</cell><cell cols="5">OA mAcc mIoU ceilingfloor wall beam column windowdoor chair table bookcasesofa board clutter</cell></row><row><cell>A5 PointNet [41]</cell><cell>-</cell><cell>49.0 41.1 88.8 97.3 69.8 0.1</cell><cell>3.9</cell><cell>46.3 10.8 52.6 58.9 40.3</cell><cell>5.9 26.4 33.2</cell></row><row><cell>A5 SEGCloud [50]</cell><cell>-</cell><cell cols="4">57.4 48.9 90.1 96.1 69.9 0.0 18.4 38.4 23.1 75.9 70.4 58.4 40.9 13.0 41.6</cell></row><row><cell>A5 PointCNN [</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>= RPE (0) ([Pi, Ri], [pi, ri], 0)</figDesc><table><row><cell>e</cell><cell>(0) i</cell><cell></cell><cell></cell><cell></cell><cell>(12)</cell></row><row><cell>e</cell><cell>(t+1) i</cell><cell>= RPE (t) ([Pi, E</cell><cell>(t) i ], [pi, ri, e</cell><cell>(t) i ], e</cell><cell>(t)</cell></row></table><note>i )</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/loicland/cut-pursuit (a) S3DIS scene with 58 objects. Superpoint count : SSP 442, VCCS 436, Lin 423.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://github.com/loicland/superpoint-graph</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Slic superpixels compared to state-ofthe-art superpixel methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Achanta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lucchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Süsstrunk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">11</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Aljalbout</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Golkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Siddiqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.07648</idno>
		<title level="m">Clustering with deep learning: Taxonomy and new methods</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">3d semantic parsing of largescale indoor spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Armeni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Sener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">K</forename><surname>Brilakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR 2016</title>
		<meeting><address><addrLine>Las Vegas, NV, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Graph based over-segmentation methods for 3d point clouds. Computer Vision and Image Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ben-Shabat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Avraham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lindenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fischer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Signature verification using a&quot; siamese&quot; time delay neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bromley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Säckinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deterministic edge-preserving regularization in computed imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Charbonnier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Blanc-Féraud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Aubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Barlaud</surname></persName>
		</author>
		<idno>1997. 4</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Architectural modeling from sparsely scanned range data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning a similarity metric discriminatively, with application to face verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Sur la sphere vide</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Delaunay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Otdelenie Matematicheskii i Estestvennyka Nauk</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="1934" />
		</imprint>
	</monogr>
	<note>Izv. Akad. Nauk SSSR</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Exploring spatial context for 3d semantic segmentation of point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Engelmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kontogianni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Leibe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV Workshops</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Exploring spatial context for 3d semantic segmentation of point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Engelmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kontogianni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Leibe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV, 3DRMS Workshop</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Know what your neighbors do: 3d semantic segmentation of point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Engelmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kontogianni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schult</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Leibe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">GMDL Workshop, ECCV</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Know what your neighbors do: 3d semantic segmentation of point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Engelmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kontogianni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schult</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Leibe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.01151</idno>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Efficient graphbased image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">F</forename><surname>Felzenszwalb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Huttenlocher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Saliency-guided adaptive seeding for supervoxel segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lauri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Frintrop</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ International Conference on Intelligent Robots and Systems</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Neighbourhood components analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Formal proof-the four-color theorem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gonthier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Notices of the AMS</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">11</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<title level="m">Deep learning</title>
		<imprint>
			<publisher>MIT press Cambridge</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Atlasnet: A papier-maché approach to learning 3d surface generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Groueix</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Aubry</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Efficient hierarchical graph-based video segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Grundmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kwatra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">A</forename><surname>Essa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Weakly supervised segmentation-aided classification of urban scenes from 3d lidar point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guinard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Landrieu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISPRS Workshop</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Deep clustering: Discriminative embeddings for segmentation and separation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Hershey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Le</forename><surname>Roux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Watanabe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>IEEE</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep metric learning using triplet network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hoffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ailon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Similarity-Based Pattern Recognition</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Robust regression: asymptotics, conjectures and monte carlo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Huber</surname></persName>
		</author>
		<idno>1973. 4</idno>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Spatial transformer networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jaderberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Superpixel sampling networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Jampani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Metric learning: A survey. Foundations and Trends in Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Cut pursuit: Fast algorithms to learn piecewise constant functions on general weighted graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Landrieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Obozinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Imaging Sciences</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Large-scale point cloud semantic segmentation with superpoint graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Landrieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Simonovsky</surname></persName>
		</author>
		<editor>CVPR. IEEE</editor>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Turbopixels: Fast superpixels using geometric flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Levinshtein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Stere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">N</forename><surname>Kutulakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Dickinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Siddiqi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pointcnn</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.07791</idno>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Toward better boundary preserved supervoxel segmentation for 3d point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS Journal of Photogrammetry and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Entropy rate superpixel segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Tuzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ramalingam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR. IEEE</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Learning superpixels with segmentation-aware affinity loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-C</forename><forename type="middle">T</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">J D S</forename><surname>Shao-Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR. IEEE</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Voxel cloud connectivity segmentation -supervoxels for point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Papon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Abramov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schoeler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wörgötter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Automatic extraction of building features from terrestrial laser scanning. International Archives of Photogrammetry, Remote Sensing and Spatial Information Sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Vosselman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">36</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Pointnet: Deep learning on point sets for 3d classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2003" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">PointNet++: Deep hierarchical feature learning on point sets in a metric space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">OctNet: Learning deep 3D representations at high resolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">O</forename><surname>Ulusoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Towards 3d point cloud based object maps for household environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">C</forename><surname>Marton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Blodow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dolha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Beetz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robotics and Autonomous Systems</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">56</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Learning a nonlinear embedding by preserving class neighbourhood structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Dynamic edgeconditioned filters in convolutional neural networks on graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Simonovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Learnable structured clustering framework for deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">O</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Rathod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<idno>abs/1612.01213</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Boundary-enhanced supervoxel segmentation for sparse outdoor lidar data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electronics Letters</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">25</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Superpixels: An evaluation of the state-of-the-art</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Stutz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Leibe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">166</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">P</forename><surname>Tchapmi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">B</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Armeni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Segcloud</surname></persName>
		</author>
		<title level="m">Semantic segmentation of 3D point clouds. International Conference on 3D Vision</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">SEEDS: superpixels extracted via energy-driven sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Van Den Bergh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Boix</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Roig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Learning fine-grained image similarity with deep ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Philbin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Deep metric learning with angular loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Deep parametric continuous convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Suo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-C</forename><forename type="middle">M A</forename><surname>Pokrovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In CVPR</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<title level="m">Group normalization. ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">3-d scene analysis via sequenced predictions over points and regions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Munoz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Bagnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICRA IEEE. IEEE</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Evaluation of super-voxel methods for early video processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Corso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Real-time coarse-to-fine topologically preserving segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Boben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">3D recurrent neural networks with context fusion for point cloud semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">3d recurrent neural networks with context fusion for point cloud semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ECCV</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Some sharp performance bounds for least squares regression with l1 regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<idno>2009. 4</idno>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">5A</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Voxelnet: End-to-end learning for point cloud based 3d object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Tuzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
