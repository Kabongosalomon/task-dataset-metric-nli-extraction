<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Sentence Embeddings in NLI with Iterative Refinement Encoders</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aarne</forename><surname>Talman</surname></persName>
							<email>aarne.talman@helsinki.fi</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Digital Humanities</orgName>
								<orgName type="institution">University of Helsinki</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anssi</forename><surname>Yli-Jyrä</surname></persName>
							<email>anssi.yli-jyra@helsinki.fi</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Digital Humanities</orgName>
								<orgName type="institution">University of Helsinki</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörg</forename><surname>Tiedemann</surname></persName>
							<email>jorg.tiedemann@helsinki.fi</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Digital Humanities</orgName>
								<orgName type="institution">University of Helsinki</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Sentence Embeddings in NLI with Iterative Refinement Encoders</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T17:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Sentence-level representations are necessary for various NLP tasks. Recurrent neural networks have proven to be very effective in learning distributed representations and can be trained efficiently on natural language inference tasks. We build on top of one such model and propose a hierarchy of BiLSTM and max pooling layers that implements an iterative refinement strategy and yields state of the art results on the SciTail dataset as well as strong results for SNLI and MultiNLI. We can show that the sentence embeddings learned in this way can be utilized in a wide variety of transfer learning tasks, outperforming InferSent on 7 out of 10 and SkipThought on 8 out of 9 SentEval sentence embedding evaluation tasks. Furthermore, our model beats the InferSent model in 8 out of 10 recently published SentEval probing tasks designed to evaluate sentence embeddings' ability to capture some of the important linguistic properties of sentences.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Neural networks have been shown to provide a powerful tool for building representations of natural languages on multiple levels of linguistic abstraction. Perhaps the most widely used representations in natural language processing are word embeddings <ref type="bibr" target="#b17">(Mikolov, Sutskever, Chen, Corrado, and</ref><ref type="bibr">Dean 2013, Pennington, Socher, and</ref><ref type="bibr" target="#b21">Manning 2014)</ref>. Recently there has been a growing interest in models for sentencelevel representations using a range of different neural network architectures. Such sentence embeddings have been generated using unsupervised learning approaches <ref type="bibr" target="#b15">(Kiros, Zhu, Salakhutdinov, Zemel, Urtasun, Torralba, and</ref><ref type="bibr">Fidler 2015, Hill, Cho, and</ref><ref type="bibr" target="#b12">Korhonen 2016)</ref>, and supervised learning <ref type="bibr" target="#b2">(Bowman, Gauthier, Rastogi, Gupta, Manning, and</ref><ref type="bibr">Potts 2016, Conneau, Kiela, Schwenk, Barrault, and</ref><ref type="bibr" target="#b8">Bordes 2017)</ref>.</p><p>Supervision typically comes in the form of an underlying semantic task with labeled data to train the model. The most prominent task for that purpose is natural language inference (NLI) that tries to model the inferential relationship between two or more given sentences. In particular, given two sentences -the premise p and the hypothesis h -the task is to determine whether h is entailed by p, whether the sentences are in contradiction with each other or whether there is no inferential relationship between the sentences (neutral). There are two main neural approaches arXiv:1808.08762v2 [cs.CL] 3 Jun 2019 to NLI. Sentence encoding-based models focus on building separate embeddings for the premises and the hypothesis and then combine those using a classifier <ref type="bibr" target="#b1">(Bowman, Angeli, Potts, and Manning 2015</ref><ref type="bibr" target="#b2">, Bowman et al. 2016</ref><ref type="bibr" target="#b8">, Conneau et al. 2017</ref>. Other approaches do not treat the two sentences separately but utilize e.g. cross-sentence attention <ref type="bibr" target="#b24">(Tay, Tuan, and</ref><ref type="bibr">Hui 2018, Chen, Zhu, Ling, Wei, Jiang, and</ref><ref type="bibr" target="#b5">Inkpen 2017a)</ref>.</p><p>With the goal of obtaining general-purpose sentence representations in mind, we opt for the sentence encoding approach. Motivated by the success of the InferSent architecture <ref type="bibr" target="#b8">(Conneau et al. 2017)</ref> we extend their architecture with a hierarchylike structure of bidirectional LSTM (BiLSTM) layers with max pooling. All in all, our model improves the previous state of the art for SciTail <ref type="bibr" target="#b13">(Khot, Sabharwal, and Clark 2018)</ref> and achieves strong results for the SNLI and Multi-Genre Natural Language Inference corpus (MultiNLI; <ref type="bibr" target="#b27">Williams, Nangia, and Bowman 2018)</ref>.</p><p>In order to demonstrate the semantic abstractions achieved by our approach, we also apply our model to a number of transfer learning tasks using the SentEval testing library <ref type="bibr" target="#b8">(Conneau et al. 2017)</ref>, and show that it outperforms the InferSent model on 7 out of 10 and SkipThought <ref type="bibr" target="#b15">(Kiros et al. 2015)</ref> on 8 out of 9 tasks, comparing to the scores reported by <ref type="bibr" target="#b8">Conneau et al. (2017)</ref>. Moreover, our model outperforms the InferSent model in 8 out of 10 recently published SentEval probing tasks designed to evaluate sentence embeddings' ability to capture some of the important linguistic properties of sentences <ref type="bibr" target="#b9">(Conneau, Kruszewski, Lample, Barrault, and Baroni 2018)</ref>. This highlights the generalization capability of the proposed model, confirming that its architecture is able to learn sentence representations with strong performance across a wide variety of different NLP tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>There is a wide variety of approaches to sentence-level representations that can be used in natural language inference. <ref type="bibr" target="#b1">Bowman et al. (2015)</ref> and <ref type="bibr" target="#b2">Bowman et al. (2016)</ref> explore <ref type="bibr">RNN and LSTM architectures, Mou, Men, Li, Xu, Zhang, Yan, and Jin (2016)</ref> convolutional neural networks and <ref type="bibr" target="#b25">Vendrov, Kiros, Fidler, and Urtasun (2016)</ref> GRUs, to name a few. The basic idea behind these approaches is to encode the premise and hypothesis sentences separately and then combine those using a neural network classifier. <ref type="bibr" target="#b8">Conneau et al. (2017)</ref> explore multiple different sentence embedding architectures ranging from LSTM, BiLSTM and intra-attention to convolution neural networks and the performance of these architectures on NLI tasks. They show that, out of these models, BiLSTM with max pooling achieves the strongest results not only in NLI but also in many other NLP tasks requiring sentence level meaning representations. They also show that their model trained on NLI data achieves strong performance on various transfer learning tasks.</p><p>Although sentence embedding approaches have proven their effectiveness in NLI, there are multiple studies showing that treating the hypothesis and premise sentences together and focusing on the relationship between those sentences yields better results <ref type="bibr" target="#b24">(Tay et al. 2018</ref><ref type="bibr" target="#b5">, Chen et al. 2017a</ref>). These methods are focused on the inference relations rather than the internal semantics of the sentences. Therefore, they do not offer similar insights about the sentence level semantics, as individual sentence embeddings do, and they cannot straightforwardly be used outside of the NLI context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model Architecture</head><p>Our proposed architecture follows a sentence embedding-based approach for NLI introduced by <ref type="bibr" target="#b1">Bowman et al. (2015)</ref>. The model illustrated in <ref type="figure">Figure 1</ref> contains sentence embeddings for the two input sentences, where the output of the sentence embeddings are combined using a heuristic introduced by <ref type="bibr" target="#b18">Mou et al. (2016)</ref>, putting together the concatenation (u, v), absolute element-wise difference |u − v|, and element-wise product u * v. The combined vector is then passed on to a 3layered multi-layer perceptron (MLP) with a 3-way softmax classifier. The first two layers of the MLP both utilize dropout and a ReLU activation function.</p><p>We use a variant of ReLU called Leaky ReLU <ref type="bibr" target="#b16">(Maas, Hannun, and Ng 2013)</ref>, defined by:</p><formula xml:id="formula_0">LeakyReLU (x) = max(0, x) + y * min(0, x)</formula><p>where we set y = 0.01 as the negative slope for x &lt; 0. This prevents the gradient from dying when x &lt; 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 1. Overall NLI Architecture</head><p>For the sentence representations we first embed the individual words with pretrained word embeddings. The sequence of the embedded words is then passed on to the sentence encoder which utilizes BiLSTM with max pooling. Given a sequence T of words (w 1 . . . , w T ), the output of the bi-directional LSTM is a set of vectors (h 1 , . . . , h T ), where each h t ∈ (h 1 , . . . , h T ) is the concatenation</p><formula xml:id="formula_1">h t = [ − → h t , ← − h t ]</formula><p>of a forward and backward LSTMs</p><formula xml:id="formula_2">− → h t = −−−−→ LST M t (w 1 , . . . , w t ) ← − h t = ←−−−− LST M t (w T , . . . , w t ).</formula><p>The max pooling layer produces a vector of the same dimensionality as h t , returning, for each dimension, its maximum value over the hidden units (h 1 , . . . , h T ). Motivated by the strong results of the BiLSTM max pooling network by <ref type="bibr" target="#b8">Conneau et al. (2017)</ref>, we experimented with combining BiLSTM max pooling networks in a hierarchy-like structure. 1 To improve the BiLSTM layers' ability to remember the input words, we let each layer of the network re-read the input embeddings instead of stacking the layers in a strict hierarchical model. In this way, our model acts as an iterative refinement architecture that reconsiders the input in each layer while being informed by the previous layer through initialisation. This creates a hierarchy of refinement layers and each of them contributes to the NLI classification by max pooling the hidden states. In the following we refer to that architecture with the abbreviation HBMP. Max pooling is defined in the standard way of taking the highest value over each dimension of the hidden states and the final sentence embedding is the concatenation of those vectors coming from each BiLSTM layer. The overall architecture is illustrated in <ref type="figure" target="#fig_0">Figure 2</ref>.</p><p>To summarize the differences between our model and traditional stacked BiLSTM architectures we can list the following three main aspects: setup that does not transfer knowledge between layers but also combines information from three separate BiLSTM layers for the final classification. The second model (BiLSTM-Ens-Train) adds a trainable initialization to each layer to study the impact of the hierarchical initialization that we propose in our architecture. The third model (BiLSTM-Ens-Tied) connects the three layers by tying parameters to each other. Finally, the fourth model (BiLSTM-Stack) implements a standard hierarchical network with stacked layers that do not re-read the original input.</p><p>We apply the standard SNLI data for the comparison of these different architectures (see Section 5 for more information about the SNLI benchmark). <ref type="table">Table 1</ref>  The results show that HBMP performs better than each of the other models, which supports the use of our setup in favor of alternative architectures. Furthermore, we can see that the different components all contribute to the final score. Ensembling information from three separate BiLSTM layers (with independent parameters) improves the performance as we can see in the comparison between BiLSTM-Ens and BiLSTM-Ens-Tied. Trainable initialization does not seem to add to the model's capacity and indicates that the hierarchical initialization that we propose is indeed beneficial. Finally, feeding the same input embeddings to all Bi-LSTMs of HBMP leads to an improvement over the stacked model that does not re-read the input information.</p><p>Using these initial findings, we will now look at a more detailed analyses of the performance of HBMP on various datasets and tasks. But before, we first give some more details about the implementation of the model and the training procedures we use. Note, that the same specifications also apply to the experiments that we already discussed above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Training Details</head><p>The architecture was implemented using PyTorch. We have published our code in GitHub: https://github.com/Helsinki-NLP/HBMP.</p><p>For all of our models we used a gradient descent optimization algorithm based on the Adam update rule <ref type="bibr" target="#b14">(Kingma and Ba 2015)</ref>, which is pre-implemented in PyTorch. We used a learning rate of 5e-4 for all our models. The learning rate was decreased by the factor of 0.2 after each epoch if the model did not improve. We used a batch size of 64. The models were evaluated with the development data after each epoch and training was stopped if the development loss increased for more than 3 epochs. The model with the highest development accuracy was selected for testing.</p><p>We use pre-trained GloVe word embeddings of size 300 dimensions (GloVe 840B 300D; <ref type="bibr" target="#b21">Pennington et al. 2014)</ref>, which were fine-tuned during training. The sentence embeddings have hidden size of 600 for both direction (except for SentEval test, where we test models with 600D and 1200D per direction) and the 3-layer multilayer perceptron (MLP) have the size of 600 dimensions. We use a dropout of 0.1 between the MLP layers (except just before the final layer). Our models were trained using one NVIDIA Tesla P100 GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation Benchmarks</head><p>To further study the performance of HBMP, we train our architecture with three common NLI datasets:</p><p>• the Stanford Natural Language Inference (SNLI) corpus, • the Multi-Genre Natural Language Inference (MultiNLI) corpus, • the Textual Entailment Dataset from Science Question Answering (SciTail).</p><p>Note that we treat them as separate tasks and do not mix any of the training, development and test data in our NLI experiments. We further perform additional linguistic error analyses using the MultiNLI Annotation Dataset and the Breaking NLI dataset. Finally, in order to test the ability of the model to learn generalpurpose representations, we apply the downstream tasks that are bundled in the SentEval package for sentence embedding evaluation. Note that we combine SNLI and MultiNLI data in those experiments in order to be compatible with related work. Below we provide a few more details about each of the evaluation frameworks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SNLI:</head><p>The Stanford Natural Language Inference (SNLI) corpus <ref type="bibr" target="#b1">(Bowman et al. 2015</ref>) is a dataset of 570k human-written sentence pairs manually labeled with the gold labels entailment, contradiction, and neutral. The dataset is divided into training (550,152 pairs), development (10,000 pairs) and test sets (10,000 pairs). The source for the premise sentences in SNLI were image captions taken from the Flickr30k corpus <ref type="bibr" target="#b29">(Young, Lai, Hodosh, and Hockenmaier 2014)</ref>.</p><p>MultiNLI: The Multi-Genre Natural Language Inference (MultiNLI) corpus <ref type="bibr" target="#b27">(Williams et al. 2018</ref>) is a broad-coverage corpus for natural language inference, consisting of 433k human-written sentence pairs labeled with entailment, contradiction and neutral. Unlike the SNLI corpus, which draws the premise sentence from image captions, MultiNLI consists of sentence pairs from ten distinct genres of both written and spoken English. The dataset is divided into training (392,702 pairs), development (20,000 pairs) and test sets (20,000 pairs).</p><p>Only five genres are included in the training set. The development and test sets have been divided into matched and mismatched, where the former includes only sentences from the same genres as the training data, and the latter includes sentences from the remaining genres not present in the training data.</p><p>In addition to the training, development and test sets, MultiNLI provides a smaller annotation dataset, which contains approximately 1000 sentence pairs annotated with linguistic properties of the sentences and is split between the matched and mismatched datasets. 2 This dataset provides a simple way to assess what kind of sentence pairs an NLI system is able to predict correctly and where it makes errors. We use the annotation dataset to perform linguistic error analysis of our model and compare the results to results obtained with InferSent. For our experiment with the annotation dataset we use the annotations for the MultiNLI mismatched dataset.</p><p>SciTail: SciTail <ref type="bibr" target="#b13">(Khot et al. 2018</ref>) is an NLI dataset created from multiple-choice science exams consisting of 27k sentence pairs. Each question and the correct answer choice have been converted into an assertive statement to form the hypothesis. The dataset is divided into training (23,596 pairs), development (1,304 pairs) and test sets (2,126 pairs). Unlike the SNLI and MultiNLI datasets, SciTail uses only two labels: entailment and neutral.</p><p>Breaking NLI: Breaking NLI <ref type="bibr" target="#b10">(Glockner, Shwartz, and Goldberg 2018)</ref> is a test set <ref type="bibr">(8,193 pairs)</ref> which is constructed by taking premises from the SNLI training set and constructing several hypotheses from them by changing at most one word within the premise. It was constructed to highlight how poorly current neural network models for NLI can handle lexical meaning.</p><p>SentEval: SentEval <ref type="bibr" target="#b8">(Conneau et al. 2017, Conneau and</ref><ref type="bibr" target="#b7">Kiela 2018</ref>) is a library for evaluating the quality of sentence embeddings. 3 It contains 17 downstream tasks as well as 10 probing tasks. The downstream datasets included in the tests were MR movie reviews, CR product reviews, SUBJ subjectivity status, MPQA opinion-polarity, SST binary sentiment analysis, TREC question-type classification, MRPC paraphrase detection, SICK-Relatedness (SICK-R) semantic textual similarity, SICK-Entailment (SICK-E) natural language inference and STS14 semantic textual similarity. The probing tasks evaluate how well the sentence encodings are able to capture the following linguistic properties: Length prediction, Word Content analysis, Tree depth prediction, Top Constituents prediction, Word order analysis, Verb tense prediction, Subject number prediction, Object number prediction, Semantic odd man out and Coordination Inversion.</p><p>For the SentEval tasks we trained our model on NLI data consisting of the concatenation of the SNLI and MultiNLI training sets consisting of 942,854 sentence pairs in total. This allows us to compare our results to the InferSent results which were obtained using a model trained on the same data <ref type="bibr" target="#b8">(Conneau et al. 2017)</ref>. <ref type="bibr" target="#b8">Conneau et al. (2017)</ref> have shown that including all the training data from SNLI and MultiNLI improves significantly the model performance on transfer learning tasks, compared to training the model only on SNLI data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Model Performance on the NLI task</head><p>In this section, we discuss the performance of the proposed sentence-encoding approach in common natural language inference benchmarks. From the experiments, we can conclude that the model provides strong results on all of the three NLI datasets. It clearly outperforms the similar but non-hierarchical BiLSTM models reported in the literature and fares well in comparison to other state of the art architectures in the sentence encoding category. In particular, our results are close to the current state of the art on SNLI in this category and strong on both, the matched and mismatched test sets of MultiNLI. Finally, on SciTail, we achieve the new state of the art with an accuracy of 86.0%.</p><p>Below, we provide additional details on our results for each of the benchmarks. We compare our model only with other state-of-the-art sentence encoding models and exclude cross-sentence attention models, except for SciTail where previous sentence encoding model-based results have not been published.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">SNLI</head><p>For the SNLI dataset, our model provides the test accuracy of 86.6% after 4 epochs of training. The comparison of our results with the previous state of the art and selected other sentence embedding based results are reported in <ref type="table">Table 2</ref>.  <ref type="formula">(2018)</ref> and c by Yoon, Lee, and Lee (2018).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">MultiNLI</head><p>For the MultiNLI matched test set (MultiNLI-m) our model achieves a test accuracy of 73.7% after 3 epochs of training, which is 0.8% points lower than the state of the art 74.5% by <ref type="bibr" target="#b19">Nie and Bansal (2017)</ref>. For the mismatched test set (MultiNLI-mm) our model achieves a test accuracy of 73.0% after 3 epochs of training, which is 0.6% points lower than the state of the art 73.6% by Chen, Zhu, Ling, Wei, Jiang, and Inkpen (2017b). A comparison of our results with the previous state of the art and selected other approaches are reported in <ref type="table" target="#tab_3">Table 3</ref>.</p><p>Although we did not achieve state of the art results for the MultiNLI dataset, we believe that a systematic study of different BiLSTM max pooling structures could reveal an architecture providing the needed improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">SciTail</head><p>On the SciTail dataset we compared our model also against non-sentence embedding-based models, as no results have been previously published which are based on independent sentence embeddings. We obtain a score of 86.0% after 4 epochs of training, which is +2.7% points absolute improvement on the previous published state of the art by <ref type="bibr" target="#b24">Tay et al. (2018)</ref>. Our model also outperforms In-ferSent which achieves an accuracy of 85.1% in our experiments. The comparison of our results with the previous state of the art results are reported in <ref type="table">Table 4</ref>.</p><p>The results achieved by our proposed model are significantly higher than the previously published results. It has been argued that the lexical similarity of the sentences in SciTail sentence pairs make it a particularly difficult dataset <ref type="bibr" target="#b13">(Khot et al. 2018</ref>). If this is the case, we hypothesize that our model is indeed better  at identifying entailment relations beyond focusing on the lexical similarity of the sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Error Analysis of NLI Predictions</head><p>To better understand what kind of inferential relationships our model is able to identify, we conducted an error analysis for the three datasets. We report the results below. <ref type="table">Table 5</ref> shows the accuracy of predictions per label (in terms of F-scores) for the HBMP model and compares them to the InferSent model. This analysis shows that our model leads to a significant improvement over the outcome of the nonhierarchical model from previous work in almost all categories on all the three benchmarks. The only exception is the entailment score on SciTail, which is slightly below the performance of InferSent.</p><p>To see in more detail how our HBMP model is able to classify sentence pairs with different labels and what kind of errors it makes, we summarize error statistics as confusion matrices for the different datasets. They highlight the HBMP model's strong performance across all the labels.  <ref type="table">Table 6</ref>. SNLI confusion matrices for HBMP and InferSent.</p><p>On the SNLI dataset our model clearly outperforms InferSent on all labels in terms of precision and recall. <ref type="table">Table 6</ref> contains the confusion matrices for that dataset comparing HBMP to InferSent. The precision on contradiction exceeds 90% for our model and reaches high recall values for both, entailment and contradiction. The performance is lower for neutral and the confusion of that label with both, contradiction and entailment is higher. However, HBMP still outperforms InferSent by a similar margin as for the other two labels.</p><p>Unlike for the SNLI and both of the MultiNLI datasets, on the SciTail dataset our model is most accurate on sentence pairs labeled neutral, having an F-score 88.9% compared to pairs marked with entailment, where the F-score was 81.0%. InferSent has slightly higher accuracy on entailment, whereas HBMP outperforms InferSent on neutral. <ref type="table">Table 7</ref> contains the confusion matrices for the SciTail dataset comparing the HBMP to InferSent. This analysis reveals that our model mainly suffers in recall on entailment detection whereas it performs well for neutral with respect to recall. It is difficult to say what the reason might be for the mismatch between the two systems but the overall performance of our architecture suggests that it is superior to the InferSent model even though the balance between precision and recall on individual labels is different.</p><p>The error analysis of the MultiNLI dataset is not standard as it cannot be based on test data. As the labeled test data is not openly available for MultiNLI, we analyzed the error statistics for this dataset based on the development data.</p><p>For the matched dataset (MultiNLI-m) our model had a development accuracy of 74.1%. For MultiNLI-m our model has the best accuracy on sentence pairs labeled with entailment, having an F-score of 77.2%. The model is also almost as accurate in predicting contradictions, with an F-score of 75.3%. Similar to SNLI, our model is less effective on sentence pairs labeled with neutral, having an F-score of 68.2% but, again, the HBMP model outperforms the InferSent on all the labels.  For the MultiNLI mismatched dataset (MultiNLI-mm) our model had a development accuracy of 73.7%. or MultiNLI-mm our model has very similar performance as with the MultiNLI-m dataset, having the best accuracy on sentence pars labeled with entailment, having an F-score of 77.9%. The model is also almost as accurate in predicting contradictions, with an F-score of 75.6%. Our model is less effective on sentence pairs labeled with neutral, having an F-score of 68.6%. <ref type="table">Table 9</ref> contains the confusion matrices for the MultiNLI Mismatched dataset comparing the HBMP to InferSent and the picture is similar to the result of the matched dataset. Substantial improvements can be seen again, in particular in the precision of contradiction detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Evaluation of Linguistic Abstractions</head><p>The most interesting part of the sentence encoder approach to NLI is the ability of the system to learn generic sentence embeddings that capture abstractions, which can be useful for other downstream tasks as well. In order to understand the capabilities of our model we first look at the type of linguistic reasoning that the NLI system is able to learn using the MultiNLI annotation set and the Breaking NLI test set. Thereafter, we evaluate downstream tasks using the SentEval library to study the use of our NLI-based sentence embeddings in transfer learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Linguistic Error Analysis of NLI Classifications</head><p>The MultiNLI annotation set makes it possible to conduct a detailed analysis of different linguistic phenomena when predicting inferential relationships. We use this to compare our model to InferSent with respect to the type of linguistic properties  <ref type="table">Table 9</ref>. MultiNLI-mismatched confusion matrices for HBMP and InferSent.</p><p>that are present in the given sentence pairs. <ref type="table">Table 10</ref> contains the comparison for the MultiNLI-mm dataset. The analysis shows that our HBMP model outperforms InferSent with antonyms, coreference links, modality, negation, paraphrases and tense differences. It also produces improved scores for most of the other categories in entailment detection. InferSent gains especially with conditionals in contradiction and in the word overlap catehory for entailments. This seems to suggest that InferSent relies a lot on matching words to find entailment and specific constructions indicating contradictions. HBMP does not seem to use word overlap as an indication for entailment that much and is better on detecting neutral sentences in this category. This outcome may indicate that our model works with stronger lexical abstractions than InferSent. However, due to the small number of examples per annotation category and small differences in the scores in general, it is hard to draw reliable conclusions from this experiment. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Tests with the Breaking NLI dataset</head><p>In the second experiment we conducted testing of the proposed sentence embedding architecture using the Breaking NLI test set recently published by <ref type="bibr" target="#b10">Glockner et al. (2018)</ref>. The test set is designed to highlight the lack of lexical reasoning capability of NLI systems. For the Breaking NLI experiment, we trained our HBMP model and the InferSent model using the SNLI training data. We compare our results with the results published by <ref type="bibr" target="#b10">Glockner et al. (2018)</ref> and to results obtained with InferSent sentence encoder (our implementation).</p><p>The results show that our HBMP model outperforms the InferSent model in 7 out of 14 categories, receiving an overall score of 65.1% (InferSent: 65.6%). Our model is especially strong with handling antonyms, which shows a good level of semantic abstraction on the lexical level. InferSent fares well in narrow categories like drinks, instruments and planets, which may indicate a problem of overfitting to prominent examples in the training data. The strong result on the synonyms class may also come from a significant representation of related examples in training. However, more detailed investigations are necessary to verify this hypothesis.</p><p>Our model also compares well against the other models, outperforming Decomposable Attention model (51.90%) <ref type="bibr" target="#b20">(Parikh, Täckström, Das, and Uszkoreit 2016)</ref> and Residual Encoders (62.20%) <ref type="bibr" target="#b19">(Nie and Bansal 2017)</ref> in the overall score. As these models are not based purely on sentence embeddings, the obtained result highlights that sentence embedding approaches can be competitive when handling inferences requiring lexical information. The results of the comparison are summarized in <ref type="table">Table 11</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">Transfer Learning</head><p>In this section, we focus on transfer learning experiments that apply sentence embeddings trained on NLI to other downstream tasks. In order to better understand how well the sentence encoding model generalizes to different tasks, we conducted various tests implemented in the SentEval sentence embedding evaluation library <ref type="bibr" target="#b8">(Conneau et al. 2017</ref>) and compared our results to the results published for In-ferSent and SkipThought <ref type="bibr" target="#b15">(Kiros et al. 2015)</ref>.</p><p>We used the SentEval library with the default settings recommended on their website, with a logistic regression classifier, Adam optimizer with learning rate of 0.001, batch size of 64 and epoch size of 4. <ref type="table" target="#tab_11">Table 12</ref> lists the transfer learning results for our models with 600D and 1200D hidden dimensionality and compares it to the InferSent and SkipThought scores reported by <ref type="bibr" target="#b8">Conneau et al. (2017)</ref>. Our 1200D model outperforms the InferSent model on 7 out of 10 tasks. The model achieves higher score on 8 out of 9 tasks reported for SkipThought, having equal score on the SUBJ dataset. No MRPC results have been reported for SkipThought.</p><p>To study in more detail the linguistic properties of our proposed model, we also ran the recently published SentEval probing tasks   <ref type="table">Table 11</ref>. Breaking NLI scores (accuracy %). Results marked with * as reported by <ref type="bibr" target="#b10">Glockner et al. (2018)</ref>. InferSent results obtained with our implementation using the training set-up described in <ref type="bibr" target="#b8">(Conneau et al. 2017</ref>   <ref type="bibr" target="#b8">Conneau et al. (2017)</ref>. To remain consistent with other work using SentEval, we report the accuracies as they are provided by the SentEval library.</p><p>model outperforms the InferSent model in 8 out of 10 probing tasks. The results are listed in <ref type="table" target="#tab_3">Table 13</ref>. Looking at both the downstream and the probing tasks we can observe strong results of our model compared to the InferSent model that already demonstrated good general abstractions on the sentence level according to the original publication by <ref type="bibr" target="#b8">Conneau et al. (2017)</ref>. Hence, HBMP does not only provide competitive NLI  .</p><p>scores but also produces improved sentence embeddings that are useful for other tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusion</head><p>In this paper we have introduced an iterative refinement architecture (HBMP) based on BiLSTM layers with max pooling that achieves a new state of the art for SciTail and strong results in the SNLI and MultiNLI sentence-encoding category. We carefully analyzed the performance of our model with respect to the label categories and the errors it produces in the various NLI benchmarks. We demonstrate that our model outperforms InferSent in nearly all cases with substantially reduced confusion between classes of inferential relationships. The linguistic analysis on MultiNLI also reveals that our approach is robust across the various categories and outperforms InferSent on, for example, antonyms and negations that require a good level of semantic abstraction. Furthermore, we tested our model using the SentEval sentence embedding evaluation library, showing that it achieves great generalization capability. The model outperforms InferSent on 7 out of 10 downstream and 8 out of 10 probing tasks, and SkipThought on 8 out of 9 downstream tasks. Overall, our model performs well across all the conducted experiments, which highlights its applicability for various NLP tasks and further demonstrates the general abstractions that it is able to pick up from the NLI training data.</p><p>Although the neural network approaches to NLI have been hugely successful, there has also been a number of concerns raised about the quality of current NLI datasets. <ref type="bibr">Gururangan, Swayamdipta, Levy, Schwartz, Bowman, and Smith (2018)</ref> and <ref type="bibr" target="#b22">Poliak, Naradowsky, Haldar, Rudinger, and Van Durme (2018)</ref> show that datasets like SNLI and MultiNLI contain annotation artifacts which help neural network models in classification, allowing decisions only based on the hypothesis sentences as their input. On a theoretical and methodological level, there is an ongoing discussion on the nature of various NLI datasets, as well as the definition of what counts as NLI and what does not. For example, <ref type="bibr" target="#b3">Chatzikyriakidis, Cooper, Dobnik, and Larsson (2017)</ref> present an overview of the most standard datasets for NLI and show that the definitions of inference in each of them are actually quite different. <ref type="bibr" target="#b23">Talman and Chatzikyriakidis (2019)</ref> further highlight this by testing different state-of-the-art neural network models by training them on one dataset and then testing on another, leading to a significant drop in performance for all models.</p><p>In addition to the concerns related to the quality of NLI datasets, the success of the proposed architecture raises a number of other interesting questions. First of all, it would be important to understand what kind of semantic information the different layers are able to capture and how they differ from each other. Secondly, we would like to ask whether other architecture configurations could lead to even stronger results in NLI and other downstream tasks. A third question is concerned with other languages and cross-lingual settings. Does the result carry over to multilingual setups and applications? The final question is whether NLI-based sentence embeddings could successfully be combined with other supervised and also unsupervised ways of learning sentence-level representations. We will look at all those questions in our future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Architecture of the HBMP sentence encoder (where T = 4).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>lists the results of the experiment.</figDesc><table><row><cell>Model</cell><cell cols="2">Accuracy Confidence Interval (95%)*</cell></row><row><cell>600D HBMP (our model)</cell><cell>86.6</cell><cell>[84.6%, 88.7%]</cell></row><row><cell>600D BiLSTM-Ens</cell><cell>86.3</cell><cell>[84.4%, 88.3%]</cell></row><row><cell>600D BiLSTM-Ens-Train</cell><cell>86.3</cell><cell>[84.3%, 88.4%]</cell></row><row><cell>600D BiLSTM-Ens-Tied</cell><cell>86.1</cell><cell>[83.8%, 87.9%]</cell></row><row><cell>600D BiLSTM-Stack</cell><cell>86.3</cell><cell>[84.2%, 88.3%]</cell></row><row><cell cols="3">Table 1. SNLI test accuracies (%) of different architectures. *Confidence intervals</cell></row><row><cell cols="3">calculated over 1000 random samples of 1000 sentence pairs.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>MultiNLI test accuracies (%). Results marked with a are baseline results by<ref type="bibr" target="#b27">Williams et al. (2018)</ref>, b by Vu(2017),</figDesc><table><row><cell>Model</cell><cell>Accuracy</cell></row><row><cell>DecompAtt a</cell><cell>72.3</cell></row><row><cell>ESIM a</cell><cell>70.6</cell></row><row><cell>Ngram a</cell><cell>70.6</cell></row><row><cell>DGEM w/o edges a</cell><cell>70.8</cell></row><row><cell>DGEM a</cell><cell>77.3</cell></row><row><cell>CAFE b</cell><cell>83.3</cell></row><row><cell>InferSent</cell><cell>85.1</cell></row><row><cell>600D HBMP</cell><cell>86.0</cell></row></table><note>c by Balazs, Marrese-Taylor, Loyola, and Matsuo (2017), d by Chen et al. (2017b) and e by Nie and Bansal (2017). Our results for the MultiNLI test sets were obtained by submitting the predictions to the respective Kaggle competitions.Table 4. SciTail test accuracies (%). Results marked with a are baseline results reported by Khot et al. (2018) and b by Tay et al. (2018).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 8</head><label>8</label><figDesc>contains the confusion matrices for the MultiNLI matched dataset comparing the</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">HBMP</cell><cell cols="3">InferSent</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">entail neutral recall entail neutral recall</cell></row><row><cell></cell><cell>Gold</cell><cell>entail neutral</cell><cell>632 88</cell><cell>210 75.0% 1196 93.1%</cell><cell></cell><cell>673 140</cell><cell>169 79.9% 1144 89.1%</cell></row><row><cell></cell><cell></cell><cell cols="3">precision 88.0% 85.0%</cell><cell cols="3">82.8% 87.1%</cell></row><row><cell></cell><cell cols="8">Table 7. SciTail confusion matrices for HBMP and InferSent based on the</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">development set.</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="3">Predicted -HBMP</cell><cell></cell><cell cols="3">Predicted -InferSent</cell></row><row><cell></cell><cell></cell><cell cols="7">entail contradict neutral recall entail contradict neutral recall</cell></row><row><cell>Gold</cell><cell>entail contradict neutral</cell><cell>2781 372 528</cell><cell>196 2354 443</cell><cell cols="2">486 80.3% 514 72.7% 2158 69.0%</cell><cell>2614 449 477</cell><cell>278 2241 507</cell><cell>587 75.1% 523 69.7% 2139 68.5%</cell></row><row><cell></cell><cell cols="4">precision 75.6% 78.7% 68.3%</cell><cell cols="4">73.8% 74.1% 65.8%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 8 .</head><label>8</label><figDesc>MultiNLI-matched confusion matrices for HBMP and InferSent based on the development set.</figDesc><table /><note>HBMP to InferSent. Our model improves upon InferSent in all values of precision and recall, in some cases by a wide margin.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>). Scores highlighted with bold are top scores when comparing the InferSent and our HBMP model.</figDesc><table><row><cell>Task</cell><cell cols="4">InferSent SkipThought 600D HBMP 1200D HBMP</cell></row><row><cell>MR</cell><cell>81.1</cell><cell>79.4</cell><cell>81.5</cell><cell>81.7</cell></row><row><cell>CR</cell><cell>86.3</cell><cell>83.1</cell><cell>86.4</cell><cell>87.0</cell></row><row><cell>SUBJ</cell><cell>92.4</cell><cell>93.7</cell><cell>92.7</cell><cell>93.7</cell></row><row><cell>MPQA</cell><cell>90.2</cell><cell>89.3</cell><cell>89.8</cell><cell>90.3</cell></row><row><cell>SST</cell><cell>84.6</cell><cell>82.9</cell><cell>83.6</cell><cell>84.0</cell></row><row><cell>TREC</cell><cell>88.2</cell><cell>88.4</cell><cell>86.4</cell><cell>88.8</cell></row><row><cell cols="2">MRPC 76.2/83.1</cell><cell>-</cell><cell>74.6/82.0</cell><cell>76.7/83.4</cell></row><row><cell>SICK-R</cell><cell>0.884</cell><cell>0.858</cell><cell>0.876</cell><cell>0.876</cell></row><row><cell>SICK-E</cell><cell>86.3</cell><cell>79.5</cell><cell>85.3</cell><cell>84.7</cell></row><row><cell>STS14</cell><cell>.70/.67</cell><cell>.44/.45</cell><cell>.70/.66</cell><cell>.71/.68</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 12 .</head><label>12</label><figDesc>Transfer learning test results for the HBMP model on a number of Sent-Eval downstream sentence embedding evaluation tasks. InferSent and SkipThought results as reported by</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1"><ref type="bibr" target="#b8">Conneau et al. (2017)</ref> explore a similar architecture using convolutional neural networks, called Hierarchical ConvNet.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">The annotated dataset and description of the annotations are available at http://www. nyu.edu/projects/bowman/multinli/multinli_1.0_annotations.zip</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">The SentEval test suite is available online at https://github.com/facebookresearch/ SentEval.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The work in this paper was supported by the Academy of Finland through project 314062 from the ICT 2023 call on Computation, Machine Learning and Artificial Intelligence, and through projects 270354/273457/313478. This project has also received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme (grant agreement No 771113).</p><p>We would also like to acknowledge NVIDIA and their GPU grant.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Refining raw sentence representations for textual entailment recognition via attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Balazs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Marrese-Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Loyola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Matsuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Evaluating Vector Space Representations for NLP. ACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A large annotated corpus for learning natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A fast unified model for parsing and sentence understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gauthier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">An overview of natural language inference data collection: The way forward?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chatzikyriakidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dobnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Larsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computing Natural Language Inference Workshop</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Enhancing Sentence Embedding with Generalized Pooling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-H</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Enhanced lstm for natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-H</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Inkpen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Recurrent neural network-based sentence encoder with gated attention for natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-H</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Inkpen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Evaluating Vector Space Representations for NLP. ACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">SentEval: An evaluation toolkit for universal sentence representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kiela</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC 2018, Eleventh International Conference on Language Resources and Evaluation</title>
		<editor>N. Calzolari</editor>
		<meeting><address><addrLine>Miyazaki, Japan</addrLine></address></meeting>
		<imprint>
			<publisher>Phoenix Seagaia Conference Center</publisher>
			<date type="published" when="2018-05-07" />
			<biblScope unit="page" from="1699" to="1704" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Supervised learning of universal sentence representations from natural language inference data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">What you can cram into a single vector: Probing sentence embeddings for linguistic properties</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kruszewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Breaking nli systems with sentences that require simple lexical inferences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Glockner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Shwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Annotation artifacts in natural language inference data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gururangan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Swayamdipta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename></persName>
		</author>
		<editor>NAACL. ACL</editor>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning distributed representations of sentences from unlabelled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Scitail: A textual entailment dataset from science question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Skip-thought vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Rectifier nonlinearities improve neural network acoustic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Maas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Hannun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intl. Conf. on Machine Learning</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<pubPlace>NeurIPS, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Natural language inference by tree-based convolution and heuristic matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Men</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Shortcut-stacked sentence encoders for multi-domain inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bansal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Evaluating Vector Space Representations for NLP. ACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A decomposable attention model for natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Täckström</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Hypothesis only baselines in natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Poliak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Naradowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Haldar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rudinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint Conference on Lexical and Computational Semantics. ACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Testing the generalization power of neural network models across nli benchmarks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Talman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chatzikyriakidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP</title>
		<meeting>the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Compare, compress and propagate: Enhancing neural architectures with alignment factorization for natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Tuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Hui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Order-embeddings of images and language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Vendrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Lct-malta&apos;s submission to repeval 2017 shared task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Vu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Evaluating Vector Space Representations for NLP. ACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A broad-coverage challenge corpus for sentence understanding through inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Dynamic Self-Attention : Computing Attention over Words Dynamically for Sentence Embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.07383</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hodosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hockenmaier</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
