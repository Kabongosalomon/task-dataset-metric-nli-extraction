<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Predicting Biomedical Interactions with Higher-Order Graph Convolutional Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="20151">AUGUST 2015 1</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Journal Of L A T E X Class</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Files</surname></persName>
						</author>
						<title level="a" type="main">Predicting Biomedical Interactions with Higher-Order Graph Convolutional Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">14</biblScope>
							<biblScope unit="issue">8</biblScope>
							<date type="published" when="20151">AUGUST 2015 1</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T21:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Higher-Order Graph Convolution</term>
					<term>Interaction Prediction</term>
					<term>Biomedical interaction networks !</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Biomedical interaction networks have incredible potential to be useful in the prediction of biologically meaningful interactions, identification of network biomarkers of disease, and the discovery of putative drug targets. Recently, graph neural networks have been proposed to effectively learn representations for biomedical entities and achieved state-of-the-art results in biomedical interaction prediction. These methods only consider information from immediate neighbors but cannot learn a general mixing of features from neighbors at various distances. In this paper, we present a higher-order graph convolutional network (HOGCN) to aggregate information from the higher-order neighborhood for biomedical interaction prediction. Specifically, HOGCN collects feature representations of neighbors at various distances and learns their linear mixing to obtain informative representations of biomedical entities. Experiments on four interaction networks, including protein-protein, drug-drug, drug-target, and gene-disease interactions, show that HOGCN achieves more accurate and calibrated predictions. HOGCN performs well on noisy, sparse interaction networks when feature representations of neighbors at various distances are considered. Moreover, a set of novel interaction predictions are validated by literature-based case studies.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>A Biological system is a complex network of various molecular entities such as genes, proteins, and other biological molecules linked together by the interactions between these entities. The complex interplay between various molecular entities can be represented as interaction networks with molecular entities as nodes and their interactions as edges. Such a representation of a biological system as a network provides a conceptual and intuitive framework to investigate and understand direct or indirect interactions between different molecular entities in a biological system. Study of such networks lead to systemlevel understanding of biology <ref type="bibr" target="#b0">[1]</ref> and discovery of novel interactions including protein-protein interactions (PPIs) <ref type="bibr" target="#b1">[2]</ref>, drug-drug interactions (DDIs) <ref type="bibr" target="#b2">[3]</ref>, drug-target interactions (DTIs) <ref type="bibr" target="#b3">[4]</ref> and gene-disease associations (GDIs) <ref type="bibr" target="#b4">[5]</ref>.</p><p>Recently, the generalization of deep learning to the network-structured data <ref type="bibr" target="#b5">[6]</ref> has shown great promise across various domains such as social networks <ref type="bibr" target="#b6">[7]</ref>, recommendation systems <ref type="bibr" target="#b7">[8]</ref>, chemistry <ref type="bibr" target="#b8">[9]</ref>, citation networks <ref type="bibr" target="#b9">[10]</ref>. These approaches are under the umbrella of graph convolutional networks (GCNs). GCNs repeatedly aggregate feature representations of immediate neighbors to learn the informative representation of the nodes for link prediction. Although GCN based methods show great success in biomedical interaction prediction <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b10">[11]</ref>, the issue with such methods is that they only consider information from immediate neighbors. SkipGNN <ref type="bibr" target="#b11">[12]</ref>  second-order neighbors and demonstrated improvements over GCN methods in biomedical interaction prediction. However, SkipGNN cannot be applied to aggregate information from higher-order neighbors and thus fail to capture information that resides farther away from a particular interaction <ref type="bibr" target="#b12">[13]</ref>.</p><p>To address the challenge, we propose an end-to-end deep graph representation learning framework named higher-order graph convolutional networks (HOGCN) for predicting interactions between pairs of biomedical entities. HOGCN learns a representation for every biomedical entity using an interaction network structure G and/or features X. In particular, we define a higher-order graph convolution (HOGC) layer where the feature representations from korder neighbors are considered to obtain the representation of biomedical entities. The layer can thus learn to mix feature representations of neighbors at various distances for interaction prediction. Furthermore, we define a bilinear decoder to reconstruct the edges in the input interaction network G by relying on feature representations produced by HOGC layers. The encoder-decoder approach makes HOGCN an end-to-end trainable model for interaction prediction.</p><p>We compare HOGCN's performance with that of stateof-the-art network similarity-based methods <ref type="bibr" target="#b13">[14]</ref>, network embedding methods <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>, and graph convolutionbased methods <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b16">[17]</ref> for biomedical link prediction. We experiment with various interaction datasets and show that our method makes accurate and calibrated predictions. HOGCN outperforms alternative methods based on network embedding by up to 30%. Furthermore, HOGCN outperforms graph convolution-based methods by up to 6%, alluding to the benefits of aggregating information from higher-order neighbors.</p><p>We perform a case study on the DDI network and arXiv:2010.08516v1 [cs.</p><p>LG] <ref type="bibr" target="#b15">16</ref> Oct 2020 observe that aggregating information from higher-order neighborhood allows HOGCN to learn meaningful representation for drugs. Moreover, literature-based case studies illustrate that the novel predictions are supported by evidence, suggesting that HOGCN can identify interactions that are highly likely to be a true positive. In summary, our study demonstrates the ability of HOGCN to identify potential interactions between biomedical entities and opens up the opportunities to use the biological and physicochemical properties of biomedical entities for a follow-up analysis of these interactions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORKS</head><p>With the increasing coverage of the interactome, various network-based approaches have been proposed to exploit already available interactions to predict missing interactions <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b17">[18]</ref>- <ref type="bibr" target="#b19">[20]</ref>. These methods can be broadly classified into (1) network similarity-based methods (2) network embedding methods (3) graph convolution-based methods. We next summarize these categories of methods for biomedical interaction prediction.</p><p>Given a network of known interactions, various similarity metrics are used to measure the similarity between the biomedical entities <ref type="bibr" target="#b17">[18]</ref> with an assumption that higher similarity indicates interaction. Triadic closure principle (TCP) has been explored in biomedical interaction prediction with the hypothesis that biomedical entities with common interaction partners are likely to interact with each other <ref type="bibr" target="#b18">[19]</ref>. TCP relies on a common neighbor algorithm to count the number of shared neighbors between the nodes and is quantified by A 2 where A is the adjacency matrix. Recently, L3 heuristic <ref type="bibr" target="#b13">[14]</ref> shows the common neighbor hypothesis fails for most protein pairs in PPI prediction and proposes to consider nodes that are similar to the neighbors of the nodes and can be quantified by A 3 . This indicates that higher-order neighbors are important for interaction prediction.</p><p>Next, network embedding methods embed the existing networks to low-dimensional space that preserves the structural proximity such that the nodes in the original network can be represented as low-dimensional vectors. Deepwalk <ref type="bibr" target="#b14">[15]</ref> is a popular approach that generates the truncated random walks in the network and defines a neighborhood for each node as a set of nodes within a window of size k in each random walk. Similarly, node2vec performs a biased random walk by balancing the breadth-first and depth-first search in the network. The random walks generated by these methods can be considered as a combination of nodes from various order of neighborhoods such as 1-hop to khop neighborhood. In other words, DeepWalk and node2vec learn the embeddings for the nodes in the network from the combination of A 1 , A 2 , A 3 , . . . A k where A i is the i th power of the adjacency matrix. These embeddings can then be fed into a classifier to predict the interaction probability. These methods are only limited to the structure of the biomedical networks and cannot incorporate additional information about the biomedical entities. Also, they cannot learn the feature difference between nodes at various distances.</p><p>Furthermore, graph convolution-based methods use a message-passing mechanism to receive and aggregate information from neighbors to generate representations for the nodes in the network. Graph convolutional networks (GCNs) <ref type="bibr" target="#b16">[17]</ref> and variational graph convolutional autoencoder (VGAE) <ref type="bibr" target="#b9">[10]</ref> aggregate feature representation from immediate neighbors to learn the representation of biomedical entities in an end-to-end manner using link prediction objective. These methods are only limited to the average pooling of the neighborhood features <ref type="bibr" target="#b12">[13]</ref>. SkipGNN <ref type="bibr" target="#b11">[12]</ref> therefore proposes to use skip similarity between the biomedical entities to aggregate information from secondorder neighbors. However, these methods cannot aggregate feature representations from higher-order neighbors and also cannot learn feature differences between neighbors at various distances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PRELIMINARIES</head><p>A biomedical network is defined as G = (V, E, X) where V denotes the set of nodes representing biomedical entities (e.g. proteins, genes, drugs, diseases) and |V| denotes the number of nodes. E ⊆ (V × V) denotes a set of interactions between biomedical entities. X ∈ R |V|×F is the features of biomedical entities where F is the dimension of features.</p><p>Let A denote the adjacency matrix of G, where A ij indicates an edge between nodes v i and v j . We assume the case of binary adjacency matrix A ij ∈ {0, 1} n×n where A ij represents the existence of edge between the nodes v i and v j , indicating the presence of the experimental evidence for their interaction (i.e. A ij = 1) or the absence of the experimental evidence for their interaction (i.e. A ij = 0). Note that the same notation of adjacency matrix can be used to represent weighted graphs such that A ij = [0, 1]. <ref type="table" target="#tab_1">Table 1</ref> shows the notations and their definitions used in the paper. </p><formula xml:id="formula_0">A ∈ R |V|×|V| Adjacency matrix of graph G D ∈ R |V|×|V| Degree matrix with D ii = i A ij I ∈ R |V|×|V| Identity matrix A ∈ R |V|×|V| Symmetrically normalized adjacency matrix X ∈ R |V|×F F -dimensional feature matrix A ij ∈ {0, 1}</formula><p>Ground-truth interaction between nodes i and j p ij ∈ [0, <ref type="bibr" target="#b0">1]</ref> Probability of interaction between nodes i and j Z ∈ R |V|×d * Final node embeddings W Representation of neighbors at distance j in layer l Problem Statement. (Biomedical interaction prediction) Given a biomedical interaction network G = (V, E, X) and the set of potential biomedical interactions E , we aim to learn a interaction prediction model f to predict the interaction probabilities of E , f : E → [0, 1].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Message Passing</head><p>Given a biomedical network G, message passing algorithms learn the representation of biomedical entities in the network by aggregating information from immediate neighbors <ref type="bibr" target="#b8">[9]</ref>. Additional information about biomedical entities The decoder takes the representation z i and z j of nodes v i and v j to learn the representation e ij for the edge (denoted by ?) and predict probability p ij of its existence.</p><p>can be used to initialize the feature matrix X. These algorithms involve the message passing step in which each biomedical entity sends its current representation to, and aggregates incoming messages from its immediate neighbors. Representation for each biomedical entity can be obtained after L steps of message passing and feature aggregation. However, such message passing operation is limited to average pooling of features from immediate neighbors and thus is unable to learn feature differences among neighbors at various distances <ref type="bibr" target="#b12">[13]</ref>. Neighborhood nodes at various distances provide network structure information at different granularities <ref type="bibr" target="#b20">[21]</ref>- <ref type="bibr" target="#b24">[25]</ref>. Taking k-hop neighborhoods into consideration, we aim at aggregating information from various distances at every message passing step. Different powers of adjacency matrices such as A 1 , A 2 , A 3 , . . . , A k provide information about the network structure at different scales. Higherorder message passing operations can therefore learn to mix their representations using various powers of the adjacency matrix at each message passing step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Graph Convolutional Networks (GCNs)</head><p>Graph convolutional networks (GCNs) are the generalization of convolution operation from regular grids such as images or texts to graph structured data <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b25">[26]</ref>. The key idea of GCNs is to learn the function to generate the node's representation by repeatedly aggregating information from immediate neighbors. The graph convolutional layer is defined as:</p><formula xml:id="formula_1">H (l) = σ(ÂH (l−1) W (l) )<label>(1)</label></formula><p>where H (l−1) and H (l) are the input and output activations, W (l) is a trainable weight matrix of the layer l, σ is the element-wise activation, andÂ is a symmetrically normalized adjacency matrix with self-connectionŝ</p><formula xml:id="formula_2">A = D − 1 2 (A + I |V| )D − 1 2 .</formula><p>A GCN model with L layers is then defined as:</p><formula xml:id="formula_3">H (l) = X if l = 0 σ(ÂH (l−1) W (l) ) if l ∈ [1, . . . , L]</formula><p>and H (L) can be used to predict the probability of interactions between biomedical entities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">HIGHER-ORDER GRAPH CONVOLUTION NET-WORK (HOGCN)</head><p>In this work, we develop a higher-order graph convolutional network (HOGCN) that takes an interaction network G as input and reconstruct the edges in the interaction network ( <ref type="figure" target="#fig_1">Fig. 1</ref>). HOGCN has two main components:</p><p>• Encoder: a higher-order graph convolution encoder that operates on an interaction graph G and produces representations for biomedical entities by aggregating features from the neighborhood at various distances and • Decoder: a bilinear decoder that relies on these representations to reconstruct the interactions in G.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Higher-Order Graph Encoder</head><p>We first describe the higher-order graph encoder, that operates on an undirected interaction graph G = (V, E, X) and learns the representations for biomedical entities. We develop an encoder with higher-order Graph Convolution (HOGC) layer to mix feature representations from neighbors at k-distances. Specifically, HOGC layer considers the neighborhood information at different granularities and is defined as:</p><formula xml:id="formula_4">H (l) = j∈P σ A j H (l−1) W (l) j (2)</formula><p>where P is a set of integer adjacency powers, A j denotes the adjacency matrix A multiplied j times, and denotes column-wise concatenation <ref type="bibr" target="#b12">[13]</ref>. Graph convolutional network <ref type="bibr" target="#b16">[17]</ref> only considers the 1 st power of adjacency matrix and can be exactly recovered by setting P = {1} in Equation <ref type="bibr" target="#b1">(2)</ref>. Similarly, SkipGNN <ref type="bibr" target="#b11">[12]</ref> considers direct and skip similarity and can be recovered by setting P = {1, 2} in Equation <ref type="formula">(2)</ref>. <ref type="figure" target="#fig_2">Fig. 2</ref> shows a HOGC layer with P = {0, 1, . . . , k} where k is maximum order of neighborhood considered in The feature representation H (l) is a linear combination of the neighbors</p><formula xml:id="formula_5">! ! (#$%) ! (#) ! % (#$%) % (#) (#) ! ' (#$%) ' (#) (#$%) ! (#) % (#) ' (#)</formula><formula xml:id="formula_6">A j H (l−1) at multiple distances j. O (l)</formula><p>j represents feature representation of neighbors at j distances for layer l. each HOGC layer. If k = 0, HOGC layer only considers the features of the biomedical entities and can capture the feature similarity between various biological entities. This is equivalent to a fully connected network with features of biomedical entities as input. For the HOGC layer, A 0 is the identity matrix I |V| where |V| is the number of nodes in the network. This allows the HOGC layer to learn the transformation of node features separately and mix it with feature representations from neighbors.</p><p>The maximum order of neighborhood k and the number of trainable weight matrices |P |, one per each adjacency power, can vary across layers. However, we set the same k for neighborhood aggregation and the same dimension d for all the weight matrices across all layers.</p><p>Neighborhood features from different adjacency powers j ∈ {0, 1, . . . , k} at layer (l − 1) are column-wise concatenated to obtain feature representation H (l−1) . As shown in (·) at layer l can learn the arbitrary linear combination of the concatenated features to obtain H (l) . Specifically, the layer can assign different coefficients to different columns in the concatenated matrix. For instance, the layer can assign positive coefficients to the columns produced by certain power of A and assign negative coefficients to other powers. This allows the model to learn feature differences among neighbors at various distances. We apply L HOGC layers to learn the latent representation Z ∈ R |V|×d * for biomedical entities in the network, where d * = d×|P | and d is the dimension of node's representation for each adjacency power.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Interaction Decoder</head><p>We introduced the encoder based on HOGC layers that learns feature representation Z for biomedical entities by mixing neighborhood information at multiple distances. Next, we discuss the decoder that reconstructs the interactions in G based on the representation Z.</p><p>We adopt a bilinear layer to fuse the representation of biomedical entities v i and v j and learn the edge representation e ij . More precisely, we define a simple bilinear layer that takes the representation z i and z j as input:</p><formula xml:id="formula_7">e ij = ELU(z T i W b z j + b)<label>(3)</label></formula><p>where W b ∈ R d×d * ×d * represents the learnable fusion matrix, e ij is the representation of edge e ij between nodes v i and v j , b denotes the bias of the bilinear layer. ELU is nonlinearity.</p><p>The edge representation e ij is then fed into 2-layered fully connected neural network to predict probability p ij for edge e ij :</p><formula xml:id="formula_8">p ij = sigmoid(FC 2 (ELU(FC 1 (e ij ))))<label>(4)</label></formula><p>where FC 1 (e ij ) = W 1 ·e ij +b 1 denotes fully connected layer with weight W 1 and bias b 1 , p ij represents the probability that biomedical entities v i and v j interact. So far, we have discussed the encoder and decoder of our proposed approach. Next, we describe the training procedure of our proposed HOGCN model. In particular, we explain how to optimize the trainable neural network weights in an end-to-end manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Training HOGCN</head><p>During HOGCN training, we employ binary cross entropy loss to optimize the model parameters</p><formula xml:id="formula_9">L(v i , v j ) = −A ij log(p ij ) − (1 − A ij ) log (1 − p ij )<label>(5)</label></formula><p>and encourage the model to assign higher probability to observed interactions (v i , v j ) than to randomly selected non-interactions. p ij is the predicted interaction probability between v i and v j and A ij denotes the ground-truth interaction label between these nodes. The final loss function considering all interactions is</p><formula xml:id="formula_10">L = (i,j)∈E L(v i , v j )<label>(6)</label></formula><p>We follow an end-to-end approach to jointly optimize over all trainable parameters and backpropagate the gradients through encoder and decoder of HOGCN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Algorithm</head><p>HOGCN leverages biomedical network structure A along with additional information about biomedical entities as the initial feature representation X. In this paper, we initialize the initial features X to be one-hot encoding i.e. I |V| .</p><p>The feature matrix X can be initialized with properties of biomedical entities or pre-trained embeddings from other network-based approaches such as DeepWalk, node2vec. Given an adjacency matrix A and the initial node representations X, higher-order neighborhood indicated by the higher power of the adjacency matrix is iteratively computed that makes the model more efficient. By adopting right-to-left multiplication, for instance, we can calculatê</p><formula xml:id="formula_11">A 3 H (i) asÂ(Â(ÂH (i) )) (Line 8 in Algorithm 1). Repre- sentation O (l)</formula><p>j learned for the neighborhood at j distances are concatenated to obtain the representation H (l) as shown in <ref type="figure" target="#fig_2">Fig. 2</ref> (Line 11 in Algorithm 1). After passing through Algorithm 1 Training of HOGCN for biomedical interaction prediction 1: Inputs:Â, X, k 2: H (0) = X 3: for t = 1 to T do <ref type="bibr">4:</ref> Sample mini-batch of training edges and their interaction labels <ref type="bibr">5:</ref> for l = 1 to L do <ref type="bibr">6:</ref> B := H (l−1)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7:</head><p>for j = 1 to k do p ij := Interaction Decoder(Z) <ref type="bibr">15:</ref> Compute loss in <ref type="formula" target="#formula_10">(6)</ref> 16:</p><p>Update model parameters via gradient descent 17: end for L HOGC layers, we obtain the final representation Z for biomedical entities. With the final representations Z and the mini-batch of training edges, we retrieve the embeddings for the nodes in training edges and feed them into the interaction decoder to compute their interaction probabilities.</p><p>The parameters of HOGCN are optimized with a binary cross-entropy loss (Equation <ref type="formula" target="#formula_10">(6)</ref>) in an end-to-end manner. Given two biomedical entities v i and v j , the trained model can predict the probability of their interactions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTAL DESIGN</head><p>We view the problem of biomedical interaction prediction as solving a link prediction task on an interaction network. We consider various interaction datasets and compare our proposed method with the state-of-the-art methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets</head><p>We conduct interaction prediction experiments on four publicly-available biomedical network datasets:</p><p>• BioSNAP-DTI <ref type="bibr" target="#b26">[27]</ref>: DTI network contains 15,139 drugtarget interactions between 5,018 drugs and 2,325 proteins. • BioSNAP-DDI <ref type="bibr" target="#b26">[27]</ref>: DDI network contains 48,514 drugdrug interactions between 1,514 drugs extracted from drug labels and biomedical literature. • HuRI-PPI <ref type="bibr" target="#b1">[2]</ref>: HI-III human PPI network contains 5,604 proteins and 23,322 interactions generated by multple orthogonal high-throughput yeast two-hybrid screens. • DisGeNET-GDI <ref type="bibr" target="#b27">[28]</ref>: GDI network consists of 81,746 interactions between 9,413 genes and 10,370 diseases curated from GWAS studies, animal models and scientific literature. <ref type="table" target="#tab_2">Table 2</ref> provides summary of datasets used in our experiments. We provide the number of interactions used for training, validation, and testing for each interaction datasets. Also, the table includes the average number of interactions for each biomedical entity which can be computed as 2|E| |V| .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Baselines</head><p>We compare our proposed model with the following network-based baselines for interaction prediction:</p><p>• network similarity-based methods -L3 <ref type="bibr" target="#b13">[14]</ref> counts the number of paths with length-3 normalized by the degree for all the node pairs.</p><p>• Network embedding methods -DeepWalk <ref type="bibr" target="#b14">[15]</ref> performs truncated random walk exploring the network neighborhood of nodes and applies skip-gram model to learn the d-dimensional embedding for each node in the network. Node features are concatenated to form edge representation and train a logistic regression classifier. -node2vec <ref type="bibr" target="#b15">[16]</ref> extends DeepWalk by running biased random walk based on breadth/depth-first search to capture both local and global network structure.</p><p>• Graph convolution-based methods -VGAE <ref type="bibr" target="#b9">[10]</ref> uses graph convolutional encoder with two GCN layers to learn representation for each node in the network and adopts inner product decoder to reconstruct adjacency matrix. -GCN <ref type="bibr" target="#b16">[17]</ref> uses normalized adjacency matrix to learn node representations. The representation for nodes are concatenated to form feature representation for the edges and fully connected layer use these edge representation to reconstruct edges, similar to HOGCN. Setting P = {1} in our proposed HOGCN is equivalent to GCN. -SkipGNN <ref type="bibr" target="#b11">[12]</ref> learns the node embeddings by combining direct and skip similarity between nodes. Setting P = {1, 2} in our proposed HOGCN is equivalent to SkipGNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Experimental setup</head><p>We split the interaction dataset into training, validation, and testing interactions in a ratio of 7:1:2 as shown in <ref type="table" target="#tab_2">Table 2</ref>.</p><p>Since the available interactions are positive samples, the negative samples are generated by randomly sampling from the complement set of positive examples. Five independent runs of the experiments with different random splits of the dataset are conducted to report the prediction performance. We use (1) area under the precision-recall curve (AUPRC) and <ref type="formula">(2)</ref> area under the receiver operating characteristics (AUROC) as the evaluation metrics. With these evaluation metrics, we expect positive interactions to have higher interaction probability compared to negative interactions. So, the higher value of AUPRC and AUROC indicates better performance.</p><p>We implement HOGCN using PyTorch <ref type="bibr" target="#b28">[29]</ref> and perform all experiments on a single NVIDIA GeForce RTX 2080Ti GPU. We construct a 2-layered HOGC network with k = 3 for each layer. At each HOGC layer, the node mixes the feature representations from neighbors at distances P = {0, 1, 2 and 3}. The dimension of all weight matrices in HOGC layers is set to d = 32. All the weight matrices are initialized using Xavier initialization <ref type="bibr" target="#b29">[30]</ref>. We train our model using mini-batch gradient descent with Adam optimizer <ref type="bibr" target="#b30">[31]</ref> for a maximum of 50 epochs, with a fixed learning rate of 5 × 10 −4 . We set the mini-batch size to 256 and the dropout probability <ref type="bibr" target="#b31">[32]</ref> to 0.1 for all layers. Early stopping is adopted to stop training if validation performance does not improve for 10 epochs. The dimension of the edge feature e ij from the bilinear layer is 64 followed by linear layers to project the edge features to edge probabilities. For baseline methods, we follow the same experimental settings discussed in <ref type="bibr" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RESULTS</head><p>In this section, we investigate the performance and flexibility of HOGCN on interaction prediction using four different datasets. We further explore the robustness of HOGCN to sparse networks. Finally, we demonstrate the ability of HOGCN to make novel predictions with literature-based case studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Biomedical interaction prediction</head><p>We compare HOGCN against various baselines on biomedical interaction prediction tasks using four different types of interaction datasets including protein-protein interactions (PPIs), drug-target interactions (DTIs), drug-drug interactions (DDIs) and gene-disease associations (GDIs). We randomly mask 20% of interactions from the network as a test set and 10% as a validation set. We train all models with 70% of interactions and evaluate their performances on test sets. The best set of hyperparameters is selected based on their performances on the validation dataset. Finally, the experiment is repeated for five independent random splits of the interaction dataset and the results with ± one standard deviation are reported in <ref type="table" target="#tab_3">Table 3</ref>. All of our models used for the reported results are of same capacity (i.e. P = {0, 1, 2, 3} and d = 32). <ref type="table" target="#tab_3">Table 3</ref> shows that HOGCN achieves huge improvement over network embedding methods such as DeepWalk and node2vec across all datasets. Specifically, HOGCN outperforms Deepwalk on AUPRC by 24.44% in DTI, 28.51% in DDI, 30.07% in PPI, and 13.79% in GDI. Although node2vec achieves better performance compared to DeepWalk by adopting a biased random walk, HOGCN still outperforms node2vec by a significant margin. DeepWalk and node2vec consider different orders of neighborhood defined by the window size and learns similar representations for the nodes in that window. In contrast, HOGCN learns feature differences between neighbors at various distances to obtain feature representation for the node and thus achieves superior performance. The improved performance suggests that feature differences between different order neighbors provide important information for interaction prediction.</p><p>A network similarity-based method, L3 <ref type="bibr" target="#b13">[14]</ref> outperforms network embedding methods across four datasets but is limited to a single aspect of network similarity i.e. the number of paths of length 3 connecting two nodes. So, L3 cannot be applied when other similarities between nodes such as similarity in features and common neighbors at various distances need to be considered. HOGCN overcomes these limitations and outperforms L3 across all interaction datasets with huge gain. In particular, HOGCN gains 3.5% AUPRC and 7.09% AUROC on PPI over L3 <ref type="bibr" target="#b13">[14]</ref>, which recently outperformed 20 network science methods in the PPI prediction problem.</p><p>Graph convolution-based methods such as GCN and VGAE achieves significant improvements over network embedding approaches but achieves comparable performance with L3. SkipGNN shows improvement over all other methods by incorporating skip similarity to aggregate information from second-order neighbors. Moreover, HOGCN with k = 3 achieves an improvement over all graph convolution-   <ref type="table" target="#tab_3">Table 3</ref> demonstrate that our approach with higherorder neighborhood mixing outperforms the state-of-the-art methods on real interaction datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Exploration of HOGCN's drug representations</head><p>Next, we evaluate if HOGCN learns meaningful representation when feature representations of higher-order neighbors are aggregated. To this aim, we train GCN, SkipGNN, and HOGCN models on the DDI network to obtain the drug representations Z. The learned drug representations are mapped to 2D space using t-SNE <ref type="bibr" target="#b32">[33]</ref> and visualize them in <ref type="figure" target="#fig_5">Fig. 3</ref>.</p><p>Drugbank <ref type="bibr" target="#b33">[34]</ref> provides information about drugs and their categories based on different characteristics such as involved metabolic enzymes, class of drugs, side effects of drugs, and the like. For this experiment, we collect drug categories from Drugbank and limit the selection of drug categories such that the training set doesn't contain any interactions between the drugs in the same category. The selected drug categories are ACE Inhibitors and Diuretics (DBCAT002175), Penicillins (DBCAT000702), and Antineoplastic Agents (DBCAT000592) with 10, 24, and 16 drugs respectively. Although these drugs don't have direct interactions in the training set, we assume that these drugs share neighborhoods at various distances and can be explored accordingly with HOGCN. <ref type="figure" target="#fig_5">Fig. 3</ref> shows the clustering structure in drugs' representations as neighborhood information at multiple distances are considered. Examining the figure, we observe that drugs in the same category are embedded close to each other in the 2D space when the model aggregates information from farther neighbors. For example, 24 drugs in the Penicillins (DBCAT000702) category (marked with blue triangles in <ref type="figure" target="#fig_5">Fig. 3</ref>) are scattered in the representation space learned by GCN that only considers feature aggregation from immediate neighbors <ref type="figure" target="#fig_5">(Fig. 3a)</ref>. Note that these drugs don't have any direct interaction between themselves in the training set. Since GCN-based models can only average the representation from immediate neighbors, these drugs are mapped relatively farther to each other and closer to other interacting drugs. SkipGNN considers skip similarity to aggregate features from second-order neighbors and show relatively compact clusters compared to GCNs <ref type="figure" target="#fig_5">(Fig. 3b</ref>). On the other hand, HOGCN considers the higher-order neighborhood and learns similar representations for drugs that belong to the same category demonstrated by compact clustering structure in <ref type="figure" target="#fig_5">Fig. 3c</ref> even though no information about categorical similarity is provided to the model. This analysis demonstrates that HOGCN learns meaningful representation for drugs by aggregating feature representations from the neighborhood at various distances.</p><p>Next, we test if the clustering pattern in <ref type="figure" target="#fig_5">Fig. 3</ref> holds across many drug categories. With this aim, we consider all drug categories in DrugBank and compute the average Euclidean distance between each drug's representation and representations of other drugs within the same drug category. We then perform 2-sample Kolmogorov-Smirnov tests and found that HOGCN learns significantly more similar representations of drugs than expected by chance (p-value = 4.93e − 106), GCNs (p-value = 5.05e − 56) and SkipGNN (1.29e − 12). Thus, this analysis indicates that HOGCN learns meaningful representations for drugs by aggregating neighborhood information at various distances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Robustness to network sparsity</head><p>We next explore the robustness of network-based interaction prediction models to network sparsity. To this aim, we evaluate the performance with respect to the percentage of training edges varying from 10% to 70%. We make predictions on the rest of the interactions. We further use 10% of test edges for validation to select the best hyperparameter settings. For a fair comparison, we compare with graph convolution-based methods that aggregate information from direct and/or second-order neighbors.  <ref type="figure" target="#fig_6">Fig. 4</ref> shows the robustness of HOGCN to network sparsity. HOGCN achieves strong performance in all tasks with different network sparsity. The performance of HOGCN steadily improves with the increase in training edges. The mixing of features from a higher-order neighborhood in HOGCN and SkipGNN shows improvement over GCN and VGAE that only consider direct neighbors. Since HOGCN can learn the linear combination of features from a 3-hop neighborhood for this experiment, it shows improvement over SkipGNN in almost all cases. This demonstrates that features from farther distances are informative for interaction prediction in sparse networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Calibrating model's prediction</head><p>All graph convolution-based model proposed for biomedical link prediction predicts the confidence estimate p ij for interaction between two biomedical entities v i and v j . We thus test if a predicted confidence p ij represents the likelihood of being true interaction. In other words, we expect the confidence estimate p ij to be calibrated, i.e. p ij represents true interaction probability <ref type="bibr" target="#b34">[35]</ref>. For example, given 100 predictions, each with the confidence of 0.9, we expect that 90 interactions should be correctly classified as true interactions.</p><p>To evaluate the calibration performance, we use reliability diagrams <ref type="bibr" target="#b34">[35]</ref> and Brier score <ref type="bibr" target="#b35">[36]</ref>. In particular, the reliability diagram provides a visual representation of model calibration. These diagrams plot the expected fraction of positives as a function of predicted probability <ref type="bibr" target="#b34">[35]</ref>. A model with perfectly calibrated predictions is represented by a diagonal in <ref type="figure" target="#fig_7">Fig. 5</ref>. In addition to reliability diagrams, it is more convenient to have a scalar summary statistics of calibration. Brier score <ref type="bibr" target="#b35">[36]</ref> is a proper scoring rule for measuring the accuracy of predicted probabilities. Lower Brier score indicates better calibration of a set of predictions. It is computed as the mean squared error of a predicted probability p ij and the ground-truth interaction label A ij . Mathematically, the Brier score can be computed as:</p><formula xml:id="formula_12">Brier score = 1 |E | |E | (i,j)=1 (p ij − A ij ) 2<label>(7)</label></formula><p>where |E | denotes the number of test edges. <ref type="figure" target="#fig_7">Fig. 5</ref> shows the calibration plots for GCN, SkipGNN and HOGCN (k = 3). For DTI dataset, SkipGNN show better calibration compared to GCN and HOGCN <ref type="figure" target="#fig_7">(Fig. 5a</ref>), indicating that second-order neighborhood information is appropriate and aggregating features from farther away makes model overconfident. For other datasets, GCNs are relatively overconfident for all predicted confidence. For example, approximately 20% − 30% of interactions are true positives among the interactions with high predicted confidence 0.8 in PPI <ref type="figure" target="#fig_7">(Fig. 5c</ref>) and GDI dataset <ref type="figure" target="#fig_7">(Fig. 5d</ref>). In contrast, HOGCN achieves a lower Brier score in comparison to the GCN and SkipGNN across DDI, PPI, and GDI datasets, alluding to the benefits of aggregating higher-order neighborhood features for calibrated prediction. This analysis demonstrates that HOGCN with higher-order neighborhood mixing makes accurate and calibrated predictions for biomedical interaction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">Impact of higher-order neighborhood mixing</head><p>In Section 6.3, we contrast HOGCN's performance with that of alternative graph convolution-based methods in varying fraction of edges. In this experiment, we aim to observe the performance of HOGCN when the order k is increased to allow the model to aggregate neighborhood information from farther away. We follow a similar setup as discussed in 6.3.  show that HOGCN's performances are not sensitive to the hyperparameter settings of k for all datasets since for settings k = {3, 4, 5}, we achieve comparable performances across the datasets. This analysis indicates that the 3-hop neighborhood provides sufficient information for interaction prediction across all datasets and the performance remains stable even with a large value for k.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6">Investigation of novel predictions</head><p>Next, we perform the literature-based validation of novel predictions. Our goal is to evaluate the quality of HOGCN's novel predictions compared to that of GCN and SkipGNN and show that HOGCN predicts novel interactions with higher confidence. We consider GDIs and DDIs for this evaluation.</p><p>We first evaluate the potential of the HOGCN to make novel GDI predictions. We collect 1,134,942 GDIs and their scores from DisGeNET <ref type="bibr" target="#b27">[28]</ref>. The score corresponds to the number and types of sources and the number of publications supporting the associations. With the score threshold of 0.18, we obtain 17,893 new GDIs that are not in the training set. We make predictions on these 17,893 GDIs with GCN, SkipGNN, and HOGCN (k = 3). Out of 17,893 GDIs, HOGCN predicts a higher probability than GCN for 17,356 (96.99%) GDIs and than SkipGNN for 11,418 (63.8%) GDIs. <ref type="table" target="#tab_5">Table 4</ref> shows the top 5 GDIs with a significant increase in interaction probabilities when higher-order neighborhood mixing is considered. We also provide the number of evidence from DisGenNet <ref type="bibr" target="#b27">[28]</ref> to support these predictions. Improvement in predicted probabilities by HOGCN models shows that aggregating feature representations from higherorder neighbors make HOGCN more confident about the potential interactions as discussed in Section 6.4. We select two predicted GDIs with a large number of supporting evidence and investigate the reason for the improvement in predicted confidence with HOGCN. Specifically, we choose gene-disease pairs (a) ABO and Pancreatic carcinoma (26 pieces of evidence) and (b) GPC3 and Hepatoblastoma ((17 pieces of evidence). To explain the prediction, the subnetworks containing all shortest paths between these pairs are selected. In particular, there are 49 shortest paths of length 3 between ABO and Pancreatic carcinoma including 6 diseases and 15 genes <ref type="figure" target="#fig_10">(Fig. 7a)</ref>. Similarly, there are 20 shortest paths of length 3 between GPC3 and Hepatoblastoma including 6 diseases and 9 genes <ref type="figure" target="#fig_10">(Fig. 7b</ref>). Since these nodes are 3-hop away from each other and GCNs can only consider immediate neighbors, GCNs assign low confidence to these interactions.</p><p>Examining the subnetwork in <ref type="figure" target="#fig_10">Fig. 7a</ref>, we found that most of the diseases are related to a cancerous tumor in the pancreas and the prostate. Furthermore, pancreatic carcinoma is associated with other diseases such as Pancreatic neoplasm, malignant neoplasm of pancreas, and malignant neoplasm of prostate <ref type="bibr" target="#b27">[28]</ref>. Since ABO is linked with diseases that are related to pancreatic carcinoma and other genes are related to these diseases as well, HOGCN captures such association <ref type="figure" target="#fig_10">(Fig 7a)</ref> even though they are farther away in the network. Similarly, HOGCN predicts association for GPC3 and Hepatoblastoma <ref type="figure" target="#fig_10">(Fig. 7b</ref>).</p><p>Next, we perform a similar case study for DDIs and evaluate the predictions against DrugBank <ref type="bibr" target="#b33">[34]</ref>. For this experiment, we make a prediction for every drug pair with GCN, SkipGNN and HOGCN and exclude the interactions that are already in the training set. <ref type="table" target="#tab_6">Table 5</ref> shows the top 5 interactions with an increase in interaction probabilities when highers orders of the neighborhood are considered. As discussed in Section 6.4, HOGCN makes predictions with higher confidence compared to GCN and SkipGNN for the interactions that are likely to be a true positive.</p><p>Moreover, we validate the false positive DDI predictions of GCNs and investigate the subnetwork for these drugs in DDI networks to reason the predictions. <ref type="table" target="#tab_7">Table 6</ref> shows the top 5 interactions with a significant decrease in predicted confidence compared to GCN-based models. Since these DDIs are false positives <ref type="bibr" target="#b33">[34]</ref>, GCN-based models make overconfident predictions for such DDIs. In contrast, HOGCN  Tobramycin 0.663 0.760 0.823 <ref type="bibr" target="#b40">[41]</ref> significantly reduces the predicted confidence for these DDIs to be true positive, indicating that the higher-order neighborhood allows HOGCN to identify false positive predictions. In particular, HOGCN can identity false positive DDI between Belimumab and Estazolam even though they are 3-hop away from each other. We select subnetwork involving the drugs to investigate the reason for such predictions. <ref type="figure" target="#fig_11">Fig. 8</ref> shows the subnetwork with all shortest paths between the drugs in <ref type="table" target="#tab_7">Table 6</ref>. Examining the figure, we observe that the drugs in these false positive DDIs have common immediate neighbors for all cases. GCN makes wrong predictions for these DDIs with high confidence. However, SkipGNN becomes less confident about the interaction being true positive by considering the skip similarity. HOGCN further reduces the predicted confidence for Tranylcypromine and Melphalan to 0.065, indicating that there is no association between these drugs. These case studies show that HOGCN with higher-order neighborhood mixing not only provide information for the identification of novel interactions but also help HOGCN to reduce false positive predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>We present a novel deep graph convolutional network (HOGCN) for biomedical interaction prediction. Our proposed model adopts a higher-order graph convolutional layer to learn to mix the feature representation of neighbors at various scales. Experimental results on four interaction datasets demonstrate the superior and robust performance of the proposed model. Furthermore, we show that HOGCN makes accurate and calibrated predictions by considering higher-order neighborhood information.</p><p>There are several directions for future study. Our approach only considers the known interactions to flag potential interactions. There are other sources of biomedical information such as various physicochemical and biological properties of biomedical entities that can provide additional information about the interaction and we plan to investigate the integration of such features into the model. As HOGCN aggregates the neighborhood information at various distances and can flag novel interactions, it would be interesting to provide interpretable explanations for the predictions in the form of a small subgraph of the input interaction network G that are most influential for the predictions <ref type="bibr" target="#b41">[42]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Weight matrix for i th adjacency power for layer l L Number of HOGC layers TNumber of training epochs kThe order of neighborhood P A set of integer adjacency powers P = {0, 1, . . . , k} O (l) j</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Block diagram of proposed HOGCN model with 2 HOGC layers. Given a biomedical interaction network G with initial features X for biomedical entities, the encoder mixes the feature representation of neighbors at various distances and learn final representation Z.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>High-order graph convolution (HOGC) Layer with P = {0, . . . , k}.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 3 .</head><label>3</label><figDesc>Visualization of learned representation for drugs with (a) GCN (b) SkipGNN (c) HOGCN. Drugs are mapped to the 2D space using t-SNE package [33] with learned drug representations. Drugs categories such as DBCAT002175, DBCAT000702 and DBCAT000592 are highlighted. The number of drugs in each categroy is reported in legend. Best viewed on screen.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 4 .</head><label>4</label><figDesc>AUPRC comparison of HOGCN's performance with that of alternative approaches with respect to network sparsity. HOGCN consistently achieves better performance in various fraction of training edges.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 5 .</head><label>5</label><figDesc>Reliability diagrams for different graph convolution-based methods. The calibration performance is evaluated with Brier score, reported in the legend (lower is better).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 6 .</head><label>6</label><figDesc>AUPRC comparison for higher-order message passing with different fractions of training edges. The values of k for different HOGCN models are reported in the legend.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 6</head><label>6</label><figDesc>shows the comparison of HOGCN with higherorder neighborhood mixing k = {3, 4, 5}. The prediction performance of HOGCN improves with the increase in the number of training interactions for all cases. The results</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 7 .</head><label>7</label><figDesc>Subnetwork with predicted interactions (marked by bold dashed lines) between (a) ABO and Pancreatic carcinoma (b) GPC3 andHepatoblastoma and all shortest paths between these pairs. The known interactions are presented as gray lines. Diseases are presented as dark circles and genes are presented as white circles.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 8 .</head><label>8</label><figDesc>Subnetwork containing false positive predictions (marked by dark dashed lines) and all shortest paths between (a) Tranylcypromine and Melphalan (b) Methotrimeprazine and Cloxacillin (c) Hydrocodone and Melphalan and (d) Ibrutinib and Mecamylamine. Other known interactions are presented as gray gray lines. Dark circles denotes drugs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>leverages skip graph to aggregate feature representations from direct and • K. KC, R. Li, and A. Haake are with the Department of Computing and Information Sciences, Rochester Institute of Technology, Rochester, NY, 14623.</figDesc><table /><note>E-mail: {kk3671, arhics, rxlics}@rit.edu• F. Cui is with Thomas H. Gosnell School of Life Sciences, Rochester Institute of Technology, Rochester, NY, 14623. E-mail: fxcsbi@rit.edu</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE 1 Terms</head><label>1</label><figDesc></figDesc><table><row><cell></cell><cell>and notations</cell></row><row><cell>Notation</cell><cell>Definition</cell></row><row><cell>G : {V, E, X}</cell><cell>Graph with nodes V, edges E and features X</cell></row><row><cell>E</cell><cell>Test edges</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE 2</head><label>2</label><figDesc>Summary of the datasets used in our experiments.</figDesc><table><row><cell>Dataset</cell><cell># Nodes</cell><cell cols="3"># Edges Training (70%) Validation (10%) Testing (20%)</cell><cell>Total</cell><cell>Avg. node degree</cell></row><row><cell>DTI</cell><cell>5,018 drugs, 2,325 proteins</cell><cell>10,597</cell><cell>1,514</cell><cell>3,028</cell><cell>15,139</cell><cell>4.12</cell></row><row><cell>DDI</cell><cell>1,514 drugs</cell><cell>33,960</cell><cell>4,852</cell><cell>9,702</cell><cell>48,514</cell><cell>64.09</cell></row><row><cell>PPI</cell><cell>5,604 proteins</cell><cell>16,326</cell><cell>2,332</cell><cell>4,664</cell><cell>23,322</cell><cell>8.32</cell></row><row><cell>GDI</cell><cell>9,413 genes, 10,370 diseases</cell><cell>57,222</cell><cell>8,175</cell><cell>16,349</cell><cell>81,746</cell><cell>8.26</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE 3 941 ± 0.001 0.936 ± 0.001</head><label>3</label><figDesc>Average AUPRC and AUROC with ± one standard deviation on biomedical interaction prediction</figDesc><table><row><cell>Dataset</cell><cell>Method</cell><cell>AUPRC</cell><cell>AUROC</cell></row><row><cell></cell><cell>DeepWalk</cell><cell>0.753 ± 0.008</cell><cell>0.735 ± 0.009</cell></row><row><cell></cell><cell>node2vec</cell><cell>0.771 ± 0.005</cell><cell>0.720 ± 0.010</cell></row><row><cell></cell><cell>L3</cell><cell>0.891 ± 0.004</cell><cell>0.793 ± 0.006</cell></row><row><cell></cell><cell>VGAE</cell><cell>0.853 ± 0.010</cell><cell>0.800 ± 0.010</cell></row><row><cell>DTI</cell><cell>GCN</cell><cell>0.904 ± 0.011</cell><cell>0.899 ± 0.010</cell></row><row><cell></cell><cell>SkipGNN</cell><cell>0.928 ± 0.006</cell><cell>0.922 ± 0.004</cell></row><row><cell></cell><cell>HOGCN</cell><cell cols="2">0.937 ± 0.001 0.934 ± 0.001</cell></row><row><cell></cell><cell>DeepWalk</cell><cell>0.698 ± 0.012</cell><cell>0.712 ± 0.009</cell></row><row><cell></cell><cell>node2vec</cell><cell>0.801 ± 0.004</cell><cell>0.809 ± 0.002</cell></row><row><cell></cell><cell>L3</cell><cell>0.860 ± 0.004</cell><cell>0.869 ± 0.003</cell></row><row><cell></cell><cell>VGAE</cell><cell>0.844 ± 0.076</cell><cell>0.878 ± 0.008</cell></row><row><cell>DDI</cell><cell>GCN</cell><cell>0.856 ± 0.005</cell><cell>0.875 ± 0.004</cell></row><row><cell></cell><cell>SkipGNN</cell><cell>0.866 ± 0.006</cell><cell>0.886 ± 0.003</cell></row><row><cell></cell><cell>HOGCN</cell><cell cols="2">0.897 ± 0.003 0.911 ± 0.002</cell></row><row><cell></cell><cell>DeepWalk</cell><cell>0.715 ± 0.008</cell><cell>0.706 ± 0.005</cell></row><row><cell></cell><cell>node2vec</cell><cell>0.773 ± 0.010</cell><cell>0.766 ± 0.005</cell></row><row><cell></cell><cell>L3</cell><cell>0.899 ± 0.003</cell><cell>0.861 ± 0.003</cell></row><row><cell></cell><cell>VGAE</cell><cell>0.875 ± 0.004</cell><cell>0.844 ± 0.006</cell></row><row><cell>PPI</cell><cell>GCN</cell><cell>0.909 ± 0.002</cell><cell>0.907 ± 0.006</cell></row><row><cell></cell><cell>SkipGNN</cell><cell>0.921 ± 0.003</cell><cell>0.917 ± 0.004</cell></row><row><cell></cell><cell>HOGCN</cell><cell cols="2">0.930 ± 0.002 0.922 ± 0.001</cell></row><row><cell></cell><cell>DeepWalk</cell><cell>0.827 ± 0.007</cell><cell>0.832 ± 0.003</cell></row><row><cell></cell><cell>node2vec</cell><cell>0.828 ± 0.006</cell><cell>0.834 ± 0.003</cell></row><row><cell></cell><cell>L3</cell><cell>0.899 ± 0.001</cell><cell>0.832 ± 0.001</cell></row><row><cell></cell><cell>VGAE</cell><cell>0.902 ± 0.006</cell><cell>0.873 ± 0.009</cell></row><row><cell>GDI</cell><cell>GCN</cell><cell>0.909 ± 0.002</cell><cell>0.906 ± 0.006</cell></row><row><cell></cell><cell>SkipGNN</cell><cell>0.915 ± 0.003</cell><cell>0.912 ± 0.004</cell></row><row><cell></cell><cell>HOGCN</cell><cell>0.</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE 4</head><label>4</label><figDesc>Novel prediction of GDIs with the number of evidence from DisGenNet<ref type="bibr" target="#b27">[28]</ref> supporting the interaction. GCN, SkipGNN and HOGCN are denoted by 1, 2 and 3 respectively.</figDesc><table><row><cell>Probability</cell><cell>No. of</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE 5</head><label>5</label><figDesc>Novel prediction of DDIs with the literature evidence supporting the interaction. GCN, SkipGNN and HOGCN are denoted by 1, 2 and 3 respectively.</figDesc><table><row><cell>Drug 1</cell><cell>Drug 2</cell><cell>1</cell><cell>Probability 2 3</cell><cell>Evidence</cell></row><row><cell>Nelfinavir</cell><cell cols="3">Acenocoumarol 0.192 0.318 0.417</cell><cell>[37]</cell></row><row><cell>Praziquantel</cell><cell>Itraconazole</cell><cell cols="2">0.609 0.721 0.811</cell><cell>[38]</cell></row><row><cell>Cisapride</cell><cell>Droperidol</cell><cell cols="2">0.618 0.725 0.823</cell><cell>[39]</cell></row><row><cell>Dapsone</cell><cell>Warfarin</cell><cell cols="2">0.632 0.720 0.885</cell><cell>[40]</cell></row><row><cell>Levofloxacin</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE 6</head><label>6</label><figDesc>Predicted probability for negative DDIs. GCN, SkipGNN and HOGCN are denoted by 1, 2 and 3 respectively.</figDesc><table><row><cell>Drug 1</cell><cell>Drug 2</cell><cell>Probability with k 1 2 3</cell></row><row><cell>Tranylcypromine</cell><cell>Melphalan</cell><cell>0.925 0.478 0.065</cell></row><row><cell>Belimumab</cell><cell>Estazolam</cell><cell>0.912 0.477 0.178</cell></row><row><cell>Methotrimeprazine</cell><cell>Cloxacillin</cell><cell>0.907 0.406 0.065</cell></row><row><cell>Hydrocodone</cell><cell>Melphalan</cell><cell>0.905 0.193 0.012</cell></row><row><cell>Ibrutinib</cell><cell>Mecamylamine</cell><cell>0.899 0.398 0.353</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Network propagation: a universal amplifier of genetic associations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cowen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ideker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Raphael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Genetics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">551</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A reference map of the human binary protein interactome</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Luck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lambourne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Spirohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">E</forename><surname>Begg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Brignall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cafarelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">J</forename><surname>Campos-Laborie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Charloteaux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">580</biblScope>
			<biblScope unit="issue">7803</biblScope>
			<biblScope unit="page" from="402" to="408" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Modeling polypharmacy side effects with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="457" to="466" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A network integration approach for drug-target interaction prediction and computational drug repositioning from heterogeneous information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature communications</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Large-scale analysis of disease pathways in the human interactome</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PSB. World Scientific</title>
		<imprint>
			<biblScope unit="page" from="111" to="122" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Geometric deep learning: going beyond euclidean data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="18" to="42" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deepinf: Social influence prediction with deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2110" to="2119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Graph convolutional neural networks for web-scale recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Eksombatchai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="974" to="983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Neural message passing for quantum chemistry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Schoenholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">F</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1263" to="1272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Variational graph auto-encoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.07308</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Parthasarathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moosavinasab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Graph embedding on biomedical networks: Methods, applications and evaluations</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1241" to="1251" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Skipgnn: Predicting molecular interactions with skip-graph networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Glass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.14949</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Mixhop: Higherorder graph convolutional architectures via sparsified neighborhood mixing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Abu-El-Haija</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Alipourfard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Harutyunyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Steeg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Galstyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="21" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Network-based prediction of protein interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">A</forename><surname>Kovács</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Luck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Spirohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pollis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schlabach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kishore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature communications</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deepwalk: Online learning of social representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 20th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="701" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">node2vec: Scalable feature learning for networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="855" to="864" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Missing link prediction using common neighbor and centrality based parameterized algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">U</forename><surname>Akhtar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Noor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shahnaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Predicting protein-protein interactions from the molecular to the proteome level</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Keskin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tuncbag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gursoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chemical reviews</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="4884" to="4909" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Gne: a deep learning framework for gene network inference by aggregating biological information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kishan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Haake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC systems biology</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">38</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Simplicial closure and higher-order link prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Benson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Abebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Schaub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jadbabaie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kleinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">48</biblScope>
			<biblScope unit="page" from="11" to="221" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Grarep: Learning graph representations with global structural information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM international on conference on information and knowledge management</title>
		<meeting>the 24th ACM international on conference on information and knowledge management</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="891" to="900" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">High-order proximity preserved embedding for dynamic networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2134" to="2144" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Republic and Canton of Geneva, CHE: International World Wide Web Conferences Steering Committee</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">K</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Koh</surname></persName>
		</author>
		<idno type="DOI">10.1145/3184558.3186900</idno>
		<ptr target="https://doi.org/10.1145/3184558.3186900" />
	</analytic>
	<monogr>
		<title level="m">Companion Proceedings of the The Web Conference 2018, ser. WWW &apos;18</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3" to="4" />
		</imprint>
	</monogr>
	<note>Higher-order network representation learning</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Hone: higher-order network embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">K</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">A</forename><surname>Yadkori</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.09303</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A comprehensive survey on graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Y</forename><surname>Philip</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Rok</forename><surname>Sosic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<ptr target="http://snap.stanford.edu/biodata" />
		<title level="m">Biosnap datasets: Stanford biomedical network dataset collection</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The disgenet knowledge platform for disease genomics: 2019 update</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Piñero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Ramírez-Anguita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Saüch-Pitarch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ronzano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Centeno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sanz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">I</forename><surname>Furlong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic acids research</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">D1</biblScope>
			<biblScope unit="page" from="845" to="855" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8026" to="8037" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the thirteenth international conference on artificial intelligence and statistics</title>
		<meeting>the thirteenth international conference on artificial intelligence and statistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Adam (2014), a method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Conference on Learning Representations (ICLR), arXiv preprint arXiv</title>
		<meeting>the 3rd International Conference on Learning Representations (ICLR), arXiv preprint arXiv</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1412</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V D</forename><surname>Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Drugbank: a comprehensive resource for in silico drug discovery and exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Wishart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Knox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hassanali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Stothard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Woolsey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic acids research</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="668" to="672" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note>suppl 1</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Predicting good probabilities with supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Niculescu-Mizil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd international conference on Machine learning</title>
		<meeting>the 22nd international conference on Machine learning</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="625" to="632" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Verification of forecasts expressed in terms of probability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Brier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Monthly weather review</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="3" />
			<date type="published" when="1950" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Sequential interaction of ritonavir and nelfinavir with acenocoumarol (abstract 1069)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Juana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bermejo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gómez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rondon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">Garcia</forename><surname>Plaza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Seventh European Conference on Clinical Aspects and Treatment of HIV Infection</title>
		<meeting><address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Clinically relevant drug interactions with antiepileptic drugs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Perucca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British journal of clinical pharmacology</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="246" to="255" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Drug interactions with cisapride</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">L</forename><surname>Michalets</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clinical pharmacokinetics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="49" to="75" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Probable warfarin and dapsone interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Truong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Haley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clinical and Applied Thrombosis/Hemostasis</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="107" to="109" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Post-antibiotic effect of levofloxacin and tobramycin alone or in combination with cefepime against pseudomonas aeruginosa</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ozbek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Otuk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chemotherapy</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="446" to="450" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Gnnexplainer: Generating explanations for graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bourgeois</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9244" to="9255" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
