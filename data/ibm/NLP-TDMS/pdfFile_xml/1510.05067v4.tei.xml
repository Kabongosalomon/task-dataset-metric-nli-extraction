<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">How Important Is Weight Symmetry in Backpropagation?</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qianli</forename><surname>Liao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Brains, Minds and Machines</orgName>
								<orgName type="institution">McGovern Institute Massachusetts Institute of Technology</orgName>
								<address>
									<addrLine>77 Massachusetts Ave</addrLine>
									<postCode>02139</postCode>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><forename type="middle">Z</forename><surname>Leibo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Brains, Minds and Machines</orgName>
								<orgName type="institution">McGovern Institute Massachusetts Institute of Technology</orgName>
								<address>
									<addrLine>77 Massachusetts Ave</addrLine>
									<postCode>02139</postCode>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomaso</forename><surname>Poggio</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Brains, Minds and Machines</orgName>
								<orgName type="institution">McGovern Institute Massachusetts Institute of Technology</orgName>
								<address>
									<addrLine>77 Massachusetts Ave</addrLine>
									<postCode>02139</postCode>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">How Important Is Weight Symmetry in Backpropagation?</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T18:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Gradient backpropagation (BP) requires symmetric feedforward and feedback connections-the same weights must be used for forward and backward passes. This "weight transport problem" (Grossberg 1987) is thought to be one of the main reasons to doubt BP's biologically plausibility. Using 15 different classification datasets, we systematically investigate to what extent BP really depends on weight symmetry. In a study that turned out to be surprisingly similar in spirit to Lillicrap et al.'s demonstration (Lillicrap et al. 2014) but orthogonal in its results, our experiments indicate that: (1) the magnitudes of feedback weights do not matter to performance (2) the signs of feedback weights do matter-the more concordant signs between feedforward and their corresponding feedback connections, the better (3) with feedback weights having random magnitudes and 100% concordant signs, we were able to achieve the same or even better performance than SGD. (4) some normalizations/stabilizations are indispensable for such asymmetric BP to work, namely Batch Normalization (BN) (Ioffe and Szegedy 2015) and/or a "Batch Manhattan" (BM) update rule.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Deep Neural Networks (DNNs) have achieved remarkable performance in many domains <ref type="bibr" target="#b8">(Krizhevsky, Sutskever, and Hinton 2012;</ref><ref type="bibr" target="#b0">Abdel-Hamid et al. 2012;</ref><ref type="bibr" target="#b12">Mikolov et al. 2013;</ref><ref type="bibr" target="#b15">Taigman et al. 2014;</ref><ref type="bibr" target="#b3">Graves, Wayne, and Danihelka 2014)</ref>. The simple gradient backpropagation (BP) algorithm has been the essential "learning engine" powering most of this work.</p><p>Deep neural networks are universal function approximators <ref type="bibr" target="#b6">(Hornik, Stinchcombe, and White 1989)</ref>. Thus it is not surprising that solutions to real-world problems exist within their configuration space. Rather, the real surprise is that such configurations can actually be discovered by gradient backpropagation.</p><p>The human brain may also be some form of DNN. Since BP is the most effective known method of adapting DNN parameters to large datasets, it becomes a priority to answer: could the brain somehow be implementing BP? Or some approximation to it?</p><p>For most of the past three decades since the invention of BP, it was generally believed that it could not be implemented by the brain <ref type="bibr" target="#b2">(Crick 1989;</ref><ref type="bibr" target="#b12">Mazzoni, Andersen, and Jordan 1991;</ref><ref type="bibr" target="#b14">O'Reilly 1996;</ref><ref type="bibr" target="#b1">Chinta and Tweed 2012;</ref><ref type="bibr" target="#b1">Bengio et al. 2015)</ref>. BP seems to have three biologically implausible requirements: (1) feedback weights must be the same as feedforward weights (2) forward and backward passes require different computations, and (3) error gradients must somehow be stored separately from activations.</p><p>One biologically plausible way to satisfy requirements <ref type="formula" target="#formula_0">(2)</ref> and <ref type="formula" target="#formula_1">(3)</ref> is to posit a distinct "error network" with the same topology as the main (forward) network but used only for backpropagation of error signals. The main problem with such a model is that it makes requirement (1) implausible. There is no known biological way for the error network to know precisely the weights of the original network. This is known as the "weight transport problem" <ref type="bibr">(Grossberg 1987)</ref>. In this work we call it the "weight symmetry problem". It is arguably the crux of BP's biological implausibility.</p><p>In this report, we systematically relax BP's weight symmetry requirement by manipulating the feedback weights. We find that some natural and biologically plausible schemes along these lines lead to exploding or vanishing gradients and render learning impossible. However, useful learning is restored if a simple and indeed more biologically plausible rule called Batch Manhattan (BM) is used to compute the weight updates. Another technique, called Batch Normalization (BN) <ref type="bibr" target="#b8">(Ioffe and Szegedy 2015)</ref>, is also shown effective. When combined together, these two techniques seem complementary and significantly improve the performance of our asymmetric version of backpropagation.</p><p>The results are somewhat surprising: if the aforementioned BM and/or BN operations are applied, the magnitudes of feedback weights turn out not to be important. A muchrelaxed sign-concordance property is all that is needed to attain comparable performance to mini-batch SGD on a large number of tasks.</p><p>Furthermore, we tried going beyond sign concordant feedback. We systematically reduced the probability of feedforward and feedback weights having the same sign (the sign concordance probability). We found that the effectiveness of backpropagation is strongly dependent on high sign concordance probability. That said, completely random and fixed feedback still outperforms chance e.g., as in the recent work of <ref type="bibr">Lillicrap et al. (Lillicrap et al. 2014)</ref>.</p><p>Our results demonstrate that the perfect forwardbackward weight symmetry requirement of backpropagation can be significantly relaxed and strong performance can still be achieved. To summarize, we have the following conclusions: (I) The magnitudes of feedback weights do not matter to performance. This surprising result suggests that our theoretical understanding of why backpropagation works may be far from complete. (II) Magnitudes of the weight updates also do not matter. (III) Normalization / stabilization methods such as Batch Normalization and Batch Manhattan are necessary for these asymmetric backpropagation algorithms to work. Note that this result was missed by previous work on random feedback weights <ref type="bibr">(Lillicrap et al. 2014)</ref>.</p><p>(IV) Asymmetric backpropagation algorithms evade the weight transport problem. Thus it is plausible that the brain could implement them. (V) These results indicate that sign-concordance is very important for achieving strong performance. However, even fixed random feedback weights with Batch Normalization significantly outperforms chance. This is intriguing and motivates further research. (VI) Additionally, we find Batch Manhattan to be a very simple but useful technique in general. When used with Batch Normalization, it often improves the performance. This is especially true for smaller training sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Asymmetric Backpropagations</head><p>A schematic representation of backpropagation is shown in <ref type="figure" target="#fig_0">Fig. 1</ref>. Let E be the objective function. Let W and V denote the feedforward and feedback weight matrices respectively. Let X denote the inputs and Y the outputs. W ij and V ij are the feedforward and feedback connections between the j-th output Y j and the i-th input X i , respectively. f (.) and f (.) are the transfer function and its derivative. Let the derivative of the i-th input with respect to the objective function be ∂E ∂Xi , the formulations of forward and back propagation are as follows:</p><formula xml:id="formula_0">Y j = f (N j ), where N j = i W ij X i (1) ∂E ∂X i = j V ij f (N j ) ∂E ∂Y j<label>(2)</label></formula><p>The standard BP algorithm requires V = W . We call that case symmetric backpropagation. In this work we systematically explore the case of asymmetric backpropagation where V = W .</p><p>By varying V , one can test various asymmetric BPs. Let sign() denote the function that takes the sign (-1 or 1) of each element. Let • indicate element-wise multiplication. M, S are matrices of the same size as W . M is a matrix of uniform random numbers ∈ [0, 1] and S p is a matrix where each element is either 1 with probability 1 − p or −1 with probability p. We explored the following choices of feedback weights V in this paper: The results are summarized in the Section 5. The performances of 1, 2 and 3, which we call strict sign-concordance cases, are shown in Experiment A. The performances of 4 and 5 with different choices of p, which we call partial signconcordance cases, are shown in Experiment B. The performances and control experiments about setting 6, which we call no concordance cases, are shown in Experiments C1 and C2.</p><p>3 Normalizations/stabilizations are necessary for "asymmetric" backpropagations Batch Normalization (BN) Batch Normalization (BN) is a recent technique proposed by <ref type="bibr" target="#b8">(Ioffe and Szegedy 2015)</ref> to reduce "internal covariate shift" <ref type="bibr" target="#b8">(Ioffe and Szegedy 2015)</ref>. The technique consists of element-wise normalization to zero mean and unit standard deviation. Means and standard deviations are separately computed for each batch. Note that in <ref type="bibr" target="#b8">(Ioffe and Szegedy 2015)</ref>, the authors proposed the use of additional learnable parameters after the whitening. We found the effect of this operation to be negligible in most cases. Except for the "BN" and "BN+BM" entries (e.g., in <ref type="table" target="#tab_2">Table 2</ref>), we did not use the learnable parameters of BN. Note that batch normalization may be related to the homeostatic plasticity mechanisms (e.g., Synaptic Scaling) in the brain <ref type="bibr" target="#b15">(Turrigiano and Nelson 2004;</ref><ref type="bibr" target="#b15">Stellwagen and Malenka 2006;</ref><ref type="bibr" target="#b15">Turrigiano 2008)</ref>. Batch Manhattan (BM) We were first motivated by looking at how BP could tolerate noisy operations that could be seen as more easily implementable by the brain. We tried relaxing the weight updates by discarding the magnitudes of the gradients. Let the weight at time t be w(t), the update rule is:</p><formula xml:id="formula_1">w(t + 1) = w(t) + η * τ (t)<label>(3)</label></formula><p>where η is the learning rate. We tested several settings of τ (t) as follows:</p><formula xml:id="formula_2">Setting 0 (SGD): τ (t) = − b ∂E ∂w + m * τ (t − 1) − d * w(t) Setting 1: τ (t) = −sign( b ∂E ∂w ) + m * τ (t − 1) − d * w(t) Setting 2: τ (t) = sign(−sign( b ∂E ∂w ) + m * τ (t − 1) − d * w(t)) Setting 3: τ (t) = sign(κ(t)) where κ(t) = −sign( b ∂E ∂w ) + m * κ(t − 1) − d * w(t)</formula><p>where m and d are momentum and weight decay rates respectively. sign() means taking the sign (-1 or 1), E is the objective function, and b denotes the indices of samples in the mini-batch. Setting 0 is the SGD algorithm (by "SGD" in this paper, we always refer to the mini-batch version with momentum and weight decay). Setting 1 is same as 0 but rounding the accumulated gradients in a batch to its sign. Setting 2 takes an extra final sign after adding the gradient term with momentum and weight decay terms. Setting 3 is something in between 1 and 2, where an final sign is taken, but not accumulated in the momentum term.</p><p>We found these techniques to be surprisingly powerful in the sense that they did not lower performance in most cases (as long as learning rates were reasonable). In fact, sometimes they improved performance. This was especially true for smaller training sets. Recall that asymmetric BPs tend to have exploding/vanishing gradients, these techniques are immune to such problems since the magnitudes of gradients are discarded.</p><p>We also found that the performance of this technique was influenced by batch size on some experiments. In the cases of very small batch sizes, discarding the magnitudes of the weight updates was sometimes detrimental to performance.</p><p>This class of update rule is very similar to a technique called the Manhattan update rule, which can be considered as a simplified version of <ref type="bibr">Rprop (Riedmiller and Braun 1993)</ref>. We suggest calling it "Batch Manhattan" (BM) to distinguish it from the stochastic version <ref type="bibr" target="#b16">(Zamanidoost et al. 2015)</ref>. By default, we used setting 1 for BM throughout the Experiments A, B, C1 and C2. The "miscellaneous experiment" at the end of the Section 5 demonstrates that settings 1, 2 and 3 give similar performances, so the conclusions we draw broadly apply to all of them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related Work</head><p>Since the invention of backpropagation (BP) (Rumelhart, <ref type="bibr" target="#b15">Hinton, and Williams 1988)</ref>, its biological plausibility has been a long-standing controversy. Several authors have argued that BP is not biologically plausible <ref type="bibr" target="#b2">(Crick 1989;</ref><ref type="bibr" target="#b12">Mazzoni, Andersen, and Jordan 1991;</ref><ref type="bibr" target="#b14">O'Reilly 1996;</ref><ref type="bibr" target="#b1">Chinta and Tweed 2012;</ref><ref type="bibr" target="#b1">Bengio et al. 2015)</ref>. Various biologically plausible modifications have been proposed. Most involve bidirectional connections e.g. Restricted Boltzmann Machines <ref type="bibr" target="#b5">(Hinton and Salakhutdinov 2006;</ref><ref type="bibr" target="#b15">Smolensky 1986</ref>) and so-called recirculation algorithms <ref type="bibr" target="#b5">(Hinton and McClelland 1988;</ref><ref type="bibr" target="#b14">O'Reilly 1996)</ref> which despite their name provided, in the case of an autoencoder, an elegant early demonstration that adaptive backwards weight can work without being identical to the forward ones. Recently, there have also been BP-free auto-encoders (Bengio 2014) based on "target propagation" <ref type="bibr" target="#b9">(Le Cun 1986)</ref>.</p><p>The most relevant work to ours is a recent paper by Lillicrap et al. <ref type="bibr">(Lillicrap et al. 2014</ref>) of which we became aware after most of this work was done. Lillicrap et al. showed that fixed random feedback weights can support the learning of good representations for several simple tasks: (i) approximating a linear function, (ii) digit recognition on MNIST and (iii) approximating the outputs of a random 3 or 4 layer nonlinear neural network. Our work is very similar in spirit but rather different and perhaps complementary in its results, since we conclude that signs must be concordant between feedforward and corresponding feedback connections for consistent good performance, whereas the magnitudes do not matter, unlike Lilicrap et al. experiments in which both signs and magnitudes were random (but fixed). To explain the difference in our conclusions, it is useful to consider the following points: 1. We systematically explored performance of the algorithms using 15 different datasets because simple tasks like MNIST by themselves do not always reveal differences between algorithms. 2. We tested deeper networks, since the accuracy of asymmetric BP's credit assignment may critically attenuate with depth (for task (i) and (ii) Lillicrap et al. used a 3-layer (1 hidden layer) fully-connected network, and for task (iii) they used a 3 or 4 layer fully-connected network, whereas in most of our experiments, we use deeper and larger CNNs as shown in <ref type="table">Table 1</ref>). 3. We found that local normalizations/stabilizations is critical for making asymmetric BP algorithms work. As shown by our results in <ref type="table" target="#tab_6">Table 4</ref>, the random feedbacks scheme (i.e. the "RndF" column) suggested by Lillicrap et al. seem to work well only on one or two tasks, performing close to chance on most of them. Only when combined with Batch Normalization ("RndF+BN" or "RndF+BN+BM" in <ref type="table" target="#tab_6">Table  4</ref>), it appears to become competitive. 4. We investigated several variants of asymmetric BPs such as sign-concordance <ref type="table" target="#tab_2">(Table 2</ref> and 3), batchwise-random vs. fixed-random feedbacks ( </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments Method</head><p>We were interested in relative differences between algorithms, not absolute performance. Thus we used common values for most parameters across all datasets to facilitate comparison. Key to our approach was the development of software allowing us to easily evaluate the "cartesian product" of models (experimental conditions) and datasets (tasks). Each experiment was a {model,dataset} pair, which was run 5 times using different learning rates (reporting the best performance). We used MatConvNet <ref type="bibr" target="#b16">(Vedaldi and Lenc 2015)</ref> to implement our models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Datasets</head><p>We extensively test our algorithms on 15 datasets of 5 Categories as described below. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training Details</head><p>The network architectures for various experiments are listed in <ref type="table">Table 1</ref>. The input sizes of networks are shown in the second row of the table. All images are resized to fit the network if necessary. Momentum was used with hyperparameter 0.9 (a conventional setting). All experiments were run for 65 epochs. The base learning rate: 1 to 50 epochs 5 * 10 −4 , 51 to 60 epochs 5 * 10 −5 , and 61 to 65 epochs 5 * 10 −6 . All models were run 5 times on each dataset with base learning rate multiplied by 100, 10, 1, 0.1, 0.01 respectively. This is because different learning algorithms favor different magnitudes of learning rates. The best validation error among all epochs of 5 runs was recorded as each model's final performance. The batch sizes were all set to 100 unless stated otherwise. All experiments used a softmax for classification and the crossentropy loss function. For testing with batch normalization, we compute exponential moving averages (alpha=0.05) of training means and standard deviations over 20 mini batches after each training epoch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Experiment A: sign-concordant Feedback In this experiment, we show the performances of setting 1, 2 and 3 in Section 2, which we call strict sign-concordance cases: while keeping the signs of feedbacks the same as feedforward ones, the magnitudes of feedbacks are either randomized or set to uniform. The results are shown in   <ref type="table" target="#tab_6">Table 4</ref>: RndF: fixed random feedbacks. RndF+BN, RndF+BN+BM: some combinations of RndF, BN and BM. uSF+BN+BM: one of our best algorithms, for reference. The "RndF" setting is the same as the one proposed by <ref type="bibr">(Lillicrap et al. 2014)</ref>. Apparently it does not perform well on most datasets. However, combining it with Batch Normalization makes it significantly better. Although it remains somewhat worse than its sign concordant counterpart. Another observation is that random feedback does not work well with BM alone (but better with BN+BM).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment C2: Control experiments for Experiment C1</head><p>The fact that random feedback weights can learn meaningful representations is somewhat surprising. We explore this phenomenon by running some control experiments, where we run two control models for each model of interest: 1.</p><p>(.)Bottom: The model's last layer is initialized randomly and clamped/frozen. All learning happens in the layers before the last layer. 2. (.)Top: The model's layers before the last layer are initialized randomly and clamped/frozen. All learning happens in the last layer. Results are shown in <ref type="table" target="#tab_6">Table 4</ref>.</p><p>There are some observations: (i) When only the last layer was allowed to adapt, all models behaved similarly. This was expected since the models only differed in the way they backpropagate errors. (ii) With the last layer is clamped, random feedback cannot learn meaningful representations. (iii) In contrast, the models with sign concordant feedback can learn surprisingly good representations even with the last layer locked. We can draw the following conclusions from such observations: sign concordant feedback ensures that meaningful error signals reach lower layers by itself, while random feedback is not sufficient. If all layers can learn, random feedback seems to work via a "mysterious co-    <ref type="table">Table 5</ref>: Different settings of Batch Manhattan (as described in Section 3) seem to give similar performances. SGD: setting 0, BM1: setting 1, BM2: setting 2, BM3: setting 3. The interaction of BM with sign concordant feedback weights (uSF) and Batch Normalization are shown in "uSF+BN+(.)" entries. Numbers are error rates (%). Yellow: performances worse than baseline (SGD) by 3% or more. Blue: performances better than baseline(SGD) by 3% or more.</p><p>adaptation" between the last layer and the layers before it. This "mysterious co-adaptation" was first observed by <ref type="bibr">(Lillicrap et al. 2014)</ref>, where it was called "feedback alignment" and some analyses were given. Note that our Experiment C shows that the effect is more significant if Batch Normalization is applied.</p><p>Miscellaneous Experiment: different settings of Batch Manhattan We show that the 3 settings of BM (as described in Section 3) produce similar performances. This is the case for both symmetric and asymmetric BPs. Results are in <ref type="table">Table 5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>This work aims to establish that there exist variants of the gradient backpropagation algorithm that could plausibly be implemented in the brain. To that end we considered the question: how important is weight symmetry to backpropagation? Through a series of experiments with increasingly asymmetric backpropagation algorithms, our work complements a recent demonstration <ref type="bibr">(Lillicrap et al. 2014</ref>) that perfect weight symmetry can be significantly relaxed while still retaining strong performance. These results show that Batch Normalization and/or Batch Manhattan are crucial for asymmetric backpropagation to work. Furthermore, they are complementary operations that are better used together than individually. These results highlight the importance of sign-concordance to asymmetric backpropagation by systematically exploring how performance declines with its relaxation.</p><p>Finally, let us return to our original motivation. How does all this relate to the brain? Based on current neuroscientific understanding of cortical feedback, we cannot make any claim about whether such asymmetric BP algorithms are actually implemented by the brain. Nevertheless, this work shows that asymmetric BPs, while having less constraints, are not computationally inferior to standard BP. So if the brain were to implement one of them, it could obtain most of the benefits of the standard algorithm.</p><p>This work suggests a hypothesis that could be checked by empirical neuroscience research: if the brain does indeed implement an asymmetric BP algorithm, then there is likely to be a high degree of sign-concordance in cortical forwardbackward connections.</p><p>These empirical observations concerning Batch Man-hattan updating may shed light on the general issue of how synaptic plasticity may implement learning algorithms. They show that changes of synaptic strength can be rather noisy. That is, the sign of a long term accumulation of synaptic potentiation or depression, rather than precise magnitude, is what is important. This scheme seems biologically implementable.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>A simple illustration of backpropagation 1. Uniform Sign-concordant Feedbacks (uSF): V = sign(W ) 2. Batchwise Random Magnitude Sign-concordant Feedbacks (brSF): V = M • sign(W ), where M is redrawn after each update of W (i.e., each mini-batch). 3. Fixed Random Magnitude Sign-concordant Feedbacks (frSF): V = M • sign(W ), where M is initialized once and fixed throughout each experiment. 4. Batchwise Random Magnitude p-percent-signconcordant Feedbacks (brSF-p): V = M • sign(W ) • S p , where M and S p is redrawn after each update of W (i.e., each mini-batch). 5. Fixed Random Magnitude p-percent-sign-concordant Feedbacks (frSF-p): V = M • sign(W ) • S p , where M and S p is initialized once and fixed throughout each experiment. 6. Fixed Random Feedbacks (RndF): Each feedback weight is drawn from a zero-mean gaussian distribution and fixed throughout each experiment: V ∼ N (0, σ 2 ), where σ was chosen to be 0.05 in all experiments.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 3</head><label>3</label><figDesc>) and learning with clamped layers(Table 4Exp. C2). Network architectures used in the experiments: AxBxC/D means C feature maps of size AxB, with stride D. The CIFAR10&amp;100 architecture has a 2 units zero-padding for every convolution layer and 1 unit right-bottom zero-padding for every pooling layer. The other models do not have paddings. "FC X" denotes Fully Connected layer of X feature maps. In the first model, the number of hidden units in FC layers are chosen according to the number of classes (denoted by "#Class") in the classification task. " max(256,#Class*3)" denotes 256 or #Class*3, whichever is larger. Rectified linear units (ReLU) are used as nonlinearities for all models.</figDesc><table><row><cell></cell><cell>All others</cell><cell>MNIST</cell><cell>CIFAR10&amp;100</cell><cell>SVHN</cell><cell>TIMIT-80</cell></row><row><cell>InputSize</cell><cell>119x119x3</cell><cell>28x28x1</cell><cell>32x32x3</cell><cell>32x32x3</cell><cell>1845x1x1</cell></row><row><cell>1</cell><cell>Conv 9x9x48/2</cell><cell>Conv 5x5x20/1</cell><cell>Conv 5x5x32/1</cell><cell>Conv 5x5x20/1</cell><cell>FC 512</cell></row><row><cell>2</cell><cell>Max-Pool 2x2/2</cell><cell cols="3">Max-Pool 2x2/2 Max-Pool 3x3/2 Max-Pool 2x2/2</cell><cell>FC 256</cell></row><row><cell>3</cell><cell>Conv 5x5x128/1</cell><cell>Conv 5x5x50/1</cell><cell cols="2">Conv 5x5x64/1 Conv 7x7x512/1</cell><cell>FC 80</cell></row><row><cell>4</cell><cell>Max-Pool 2x2/2</cell><cell cols="3">Max-Pool 2x2/2 Avg-Pool 3x3/2 Max-Pool 2x2/2</cell><cell></cell></row><row><cell>5</cell><cell>FC max(256,#Class*3)</cell><cell>FC 500</cell><cell>Conv 5x5x64/1</cell><cell>FC 40</cell><cell></cell></row><row><cell>6</cell><cell>FC #Class*2</cell><cell>FC 10</cell><cell>Avg-Pool 3x3/2</cell><cell>FC 10</cell><cell></cell></row><row><cell>7</cell><cell>FC #Class</cell><cell></cell><cell>FC 128</cell><cell></cell><cell></cell></row><row><cell>8</cell><cell></cell><cell></cell><cell>FC 10/100</cell><cell></cell><cell></cell></row><row><cell>Table 1:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Plus sign (+) denotes combination of methods. For example, uSF+BM means Batch Manhattan with uniform sign-concordant feedback. SGD: Stochastic gradient descent, the baseline algorithm. BM: SGD + Batch Manhattan. BN: SGD + Batch Normalization. BN+BM: 40.60 26.25 19.48 19.29 18.44 19.02 CIFAR100 55.15 58.44 49.44 51.45 99.00 71.51 65.28 57.19 53.12 50.74 52.</figDesc><table><row><cell cols="2">Experiment A SGD</cell><cell>BM</cell><cell>BN</cell><cell>BN+BM</cell><cell>uSF</cell><cell>NuSF</cell><cell>uSF +BM</cell><cell>uSF +BN</cell><cell>uSF +BN +BM</cell><cell>brSF +BN +BM</cell><cell>frSF +BN +BM</cell></row><row><cell>MNIST</cell><cell>0.67</cell><cell>0.99</cell><cell>0.52</cell><cell>0.73</cell><cell cols="2">88.65 0.60</cell><cell>0.95</cell><cell>0.55</cell><cell>0.83</cell><cell>0.80</cell><cell>0.91</cell></row><row><cell>CIFAR</cell><cell cols="3">22.73 23.98 16.75</cell><cell>17.94</cell><cell cols="7">90.00 25</cell></row><row><cell>SVHN</cell><cell cols="3">9.06 10.77 7.50</cell><cell>9.88</cell><cell cols="3">80.41 14.55 9.78</cell><cell>8.73</cell><cell>9.67</cell><cell cols="2">9.95 10.16</cell></row><row><cell>STL10</cell><cell cols="3">48.01 44.14 45.19</cell><cell>43.19</cell><cell cols="7">90.00 56.53 46.41 48.49 41.55 42.74 42.68</cell></row><row><cell>Cal101</cell><cell cols="3">74.08 66.70 66.07</cell><cell>61.75</cell><cell cols="7">98.95 70.50 75.24 63.33 60.70 59.54 60.27</cell></row><row><cell>Cal256-101</cell><cell cols="3">87.06 83.43 82.94</cell><cell>81.96</cell><cell cols="7">99.02 85.98 86.37 82.16 80.78 78.92 80.59</cell></row><row><cell>iCub</cell><cell cols="3">57.62 55.57 46.43</cell><cell>37.08</cell><cell cols="7">89.96 66.57 70.61 61.37 48.38 47.33 46.08</cell></row><row><cell>Flowers17</cell><cell cols="3">35.29 31.76 36.76</cell><cell>32.35</cell><cell cols="7">94.12 42.65 38.24 35.29 32.65 29.41 31.47</cell></row><row><cell>Flowers102</cell><cell cols="3">77.30 77.57 75.78</cell><cell>74.92</cell><cell cols="7">99.67 77.92 79.25 71.74 73.20 73.31 73.57</cell></row><row><cell cols="4">PubFig83-ID 63.25 54.42 51.08</cell><cell>41.33</cell><cell cols="7">98.75 78.58 65.83 54.58 40.67 42.67 40.33</cell></row><row><cell>SUFR-W-ID</cell><cell cols="3">80.00 74.25 75.00</cell><cell>65.00</cell><cell cols="7">98.75 83.50 79.50 72.00 65.75 66.25 66.50</cell></row><row><cell>LFW-ID</cell><cell cols="3">79.25 74.25 73.75</cell><cell>55.75</cell><cell cols="7">98.75 85.75 80.75 73.75 56.25 57.25 55.75</cell></row><row><cell>Scene67</cell><cell cols="3">87.16 85.37 86.04</cell><cell>82.46</cell><cell cols="7">98.51 88.21 87.09 87.09 81.87 82.31 81.79</cell></row><row><cell>TIMIT80</cell><cell cols="3">23.04 25.92 23.92</cell><cell>24.40</cell><cell cols="7">23.60 29.28 25.84 25.04 25.12 25.24 24.92</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Experiment A: The magnitudes of feedbacks do not matter. Sign concordant feedbacks can produce strong perfor-NuSF: same as uSF, but with feedback weights normalized by dividing the number of inputs of the feedforward filter (filter width * filter height * input feature number). This scheme avoids the exploding gradients but still suffers from vanishing gradients. uSF+BM: this setting is somewhat unstable for small batch sizes. M • sign(W ) • S p depend on the matrix S p as defined in Section 2.Table 3Part 1 reports results from setting 4, the case where a new M and S p is sampled for each batch.Table 3Part 2 reports results of setting 5, the case where M and S p are fixed. The main observation from this experiment is that the performance declines as the level of sign-concordance decreases.</figDesc><table><row><cell>Two training procedures were explored: (1) batch size 100 for all epochs (2) batch size 100 for 3 epochs and then batch size 500 for the remaining epochs. The best performance was reported. While this gives a little advantage to this model since more settings were tried, we believe it is informative to isolate the stability issue and show what can be achieved if the model converges well. Note that uSF+BM is the only entry with slightly different training procedures. All other models share exactly the same training procedure &amp; parameters. uSF+BN, uSF+BN+BM, brSF+BN+BM, frSF+BN+BM: These are some combinations of uSF, brSF, frSF, BN and BM. The last three are the most robust, well-performing ,and biologically-plausible algorithms. Experiment B: Violating Sign-Concordance with prob-ability p In this experiment, we test the effect of partial sign-concordance. That is, we test settings 4 and 5 as de-scribed in Section 2. In these cases, the feedback weight magnitudes were all random. Strict sign-concordance was relaxed by manipulating the probability p of concordance between feedforward and feedback weight signs. Feedback weights V = Experiment C1: Fixed Random Feedback are shown in</cell><cell>Results</cell></row></table><note>mance. Numbers are error rates (%). Yellow: performances worse than baseline(SGD) by 3% or more. Blue: performances better than baseline(SGD) by 3% or more.SGD + Batch Normalization + Batch Manhattan. uSF: Uni- form sign-concordant feedback. This condition often had exploding gradients.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3</head><label>3</label><figDesc>Same as part 1, but The M and S were fixed throughout each experiment.</figDesc><table><row><cell cols="9">: Experiment B Part 1 (left): Feedbacks have random magnitudes, varing probability of having different signs (per-</cell></row><row><cell cols="9">centages in second row, column 3-7) from the feedforward ones. The M and S redrawn in each mini-batch. Numbers are error</cell></row><row><cell cols="9">rates (%). Yellow: performances worse than baseline(SGD) by 3% or more. Blue: performances better than baseline(SGD) by</cell></row><row><cell cols="4">3% or more. Experiment B Part 2 (right): Experiment C1 SGD RndF NuSF</cell><cell>BN</cell><cell>RndF+BN</cell><cell>RndF+BM</cell><cell cols="2">RndF+BN+BM uSF+BN+BM</cell></row><row><cell>MNIST</cell><cell>0.67</cell><cell>1.81</cell><cell>0.60</cell><cell>0.52</cell><cell>0.83</cell><cell>1.89</cell><cell>1.07</cell><cell>0.83</cell></row><row><cell>CIFAR</cell><cell>22.73</cell><cell>42.69</cell><cell>40.60</cell><cell>16.75</cell><cell>24.35</cell><cell>62.71</cell><cell>25.75</cell><cell>19.29</cell></row><row><cell>CIFAR100</cell><cell>55.15</cell><cell>90.88</cell><cell>71.51</cell><cell>49.44</cell><cell>60.83</cell><cell>97.11</cell><cell>64.69</cell><cell>53.12</cell></row><row><cell>SVHN</cell><cell>9.06</cell><cell>12.35</cell><cell>14.55</cell><cell>7.50</cell><cell>12.63</cell><cell>13.63</cell><cell>12.79</cell><cell>9.67</cell></row><row><cell>STL10</cell><cell>48.01</cell><cell>57.80</cell><cell>56.53</cell><cell>45.19</cell><cell>51.60</cell><cell>80.39</cell><cell>47.39</cell><cell>41.55</cell></row><row><cell>Cal101</cell><cell>74.08</cell><cell>88.51</cell><cell>70.50</cell><cell>66.07</cell><cell>72.81</cell><cell>98.42</cell><cell>67.12</cell><cell>60.70</cell></row><row><cell>Cal256-101</cell><cell>87.06</cell><cell>94.12</cell><cell>85.98</cell><cell>82.94</cell><cell>85.49</cell><cell>98.14</cell><cell>83.63</cell><cell>80.78</cell></row><row><cell>iCub</cell><cell>57.62</cell><cell>67.87</cell><cell>66.57</cell><cell>46.43</cell><cell>58.82</cell><cell>84.41</cell><cell>59.02</cell><cell>48.38</cell></row><row><cell>Flowers17</cell><cell>35.29</cell><cell>69.41</cell><cell>42.65</cell><cell>36.76</cell><cell>43.53</cell><cell>91.18</cell><cell>38.24</cell><cell>32.65</cell></row><row><cell>Flowers102</cell><cell>77.30</cell><cell>92.31</cell><cell>77.92</cell><cell>75.78</cell><cell>81.22</cell><cell>96.13</cell><cell>78.99</cell><cell>73.20</cell></row><row><cell>PubFig83-ID</cell><cell>63.25</cell><cell>95.42</cell><cell>78.58</cell><cell>51.08</cell><cell>67.00</cell><cell>97.67</cell><cell>55.25</cell><cell>40.67</cell></row><row><cell>SUFR-W-ID</cell><cell>80.00</cell><cell>94.75</cell><cell>83.50</cell><cell>75.00</cell><cell>77.75</cell><cell>97.25</cell><cell>69.00</cell><cell>65.75</cell></row><row><cell>LFW-ID</cell><cell>79.25</cell><cell>95.75</cell><cell>85.75</cell><cell>73.75</cell><cell>79.25</cell><cell>97.75</cell><cell>67.50</cell><cell>56.25</cell></row><row><cell>Scene67</cell><cell>87.16</cell><cell>95.75</cell><cell>88.21</cell><cell>86.04</cell><cell>87.84</cell><cell>97.69</cell><cell>87.09</cell><cell>81.87</cell></row><row><cell>TIMIT80</cell><cell>23.04</cell><cell>26.76</cell><cell>29.28</cell><cell>23.92</cell><cell>26.52</cell><cell>33.12</cell><cell>26.32</cell><cell>25.12</cell></row><row><cell>Experiment C2</cell><cell>SGD Bottom</cell><cell>SGD Top</cell><cell>RndF Bottom</cell><cell>RndF Top</cell><cell>RndF+BN+BM Bottom</cell><cell>RndF+BN+BM Top</cell><cell>uSF+BN+BM Bottom</cell><cell>uSF+BN+BM Top</cell></row><row><cell>MNIST</cell><cell>0.65</cell><cell>3.85</cell><cell>85.50</cell><cell>3.81</cell><cell>86.74</cell><cell>3.81</cell><cell>0.66</cell><cell>3.85</cell></row><row><cell>CIFAR</cell><cell>23.12</cell><cell>56.80</cell><cell>89.71</cell><cell>56.77</cell><cell>78.90</cell><cell>58.54</cell><cell>16.72</cell><cell>57.84</cell></row><row><cell>CIFAR100</cell><cell>59.49</cell><cell>80.71</cell><cell>98.79</cell><cell>80.65</cell><cell>98.69</cell><cell>84.34</cell><cell>61.61</cell><cell>84.10</cell></row><row><cell>SVHN</cell><cell>8.31</cell><cell>75.22</cell><cell>82.86</cell><cell>75.12</cell><cell>84.84</cell><cell>69.99</cell><cell>10.96</cell><cell>71.89</cell></row><row><cell>STL10</cell><cell>49.96</cell><cell>74.69</cell><cell>88.36</cell><cell>72.44</cell><cell>81.31</cell><cell>76.11</cell><cell>52.18</cell><cell>76.09</cell></row><row><cell>Cal101</cell><cell>71.97</cell><cell>82.72</cell><cell>98.63</cell><cell>79.14</cell><cell>98.21</cell><cell>80.40</cell><cell>63.86</cell><cell>79.98</cell></row><row><cell>Cal256-101</cell><cell>86.08</cell><cell>89.71</cell><cell>98.43</cell><cell>88.92</cell><cell>98.14</cell><cell>89.02</cell><cell>82.84</cell><cell>89.12</cell></row><row><cell>iCub</cell><cell>46.73</cell><cell>83.96</cell><cell>87.56</cell><cell>83.26</cell><cell>80.36</cell><cell>84.31</cell><cell>49.33</cell><cell>84.16</cell></row><row><cell>Flowers17</cell><cell>38.24</cell><cell>70.59</cell><cell>92.35</cell><cell>70.00</cell><cell>87.35</cell><cell>77.06</cell><cell>45.00</cell><cell>77.06</cell></row><row><cell>Flowers102</cell><cell>78.99</cell><cell>86.57</cell><cell>97.89</cell><cell>86.84</cell><cell>98.11</cell><cell>84.24</cell><cell>78.09</cell><cell>84.57</cell></row><row><cell>PubFig83-ID</cell><cell>66.75</cell><cell>89.58</cell><cell>97.67</cell><cell>89.58</cell><cell>97.67</cell><cell>89.67</cell><cell>43.83</cell><cell>89.50</cell></row><row><cell>SUFR-W-ID</cell><cell>80.50</cell><cell>90.50</cell><cell>97.50</cell><cell>90.50</cell><cell>97.50</cell><cell>89.50</cell><cell>71.50</cell><cell>89.50</cell></row><row><cell>LFW-ID</cell><cell>79.75</cell><cell>92.50</cell><cell>98.25</cell><cell>93.00</cell><cell>97.00</cell><cell>89.50</cell><cell>65.00</cell><cell>89.50</cell></row><row><cell>Scene67</cell><cell>88.73</cell><cell>91.57</cell><cell>97.84</cell><cell>91.49</cell><cell>97.54</cell><cell>91.19</cell><cell>85.97</cell><cell>91.04</cell></row><row><cell>TIMIT80</cell><cell>23.52</cell><cell>46.20</cell><cell>95.00</cell><cell>46.20</cell><cell>93.00</cell><cell>39.76</cell><cell>24.96</cell><cell>40.16</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Experiment C1: fixed random feedbacks. Experiment C2: (.)Bottom: The model's last layer is initialized randomly and clamped/frozen. All learning happens in the layers before the last layer. (.)Top: The model's layers before the last layer are initialized randomly and clamped/frozen. All learning happens in the last layer. Numbers are error rates (%). Yellow: performances worse than baseline(SGD) by 3% or more. Blue: performances better than baseline(SGD) by 3% or more.</figDesc><table><row><cell></cell><cell cols="8">SGD BM1 BM2 BM3 uSF+BN uSF+BN+BM1 uSF+BN+BM2 uSF+BN+BM3</cell></row><row><cell>MNIST</cell><cell>0.67</cell><cell>0.99</cell><cell>1.30</cell><cell>1.09</cell><cell>0.55</cell><cell>0.83</cell><cell>0.72</cell><cell>0.61</cell></row><row><cell>CIFAR</cell><cell cols="4">22.73 23.98 23.09 20.47</cell><cell>19.48</cell><cell>19.29</cell><cell>18.87</cell><cell>18.38</cell></row><row><cell cols="5">CIFAR100 55.15 58.44 58.81 52.82</cell><cell>57.19</cell><cell>53.12</cell><cell>52.38</cell><cell>54.68</cell></row><row><cell>SVHN</cell><cell cols="4">9.06 10.77 12.31 12.23</cell><cell>8.73</cell><cell>9.67</cell><cell>10.54</cell><cell>9.20</cell></row><row><cell>STL10</cell><cell cols="4">48.01 44.14 44.74 45.23</cell><cell>48.49</cell><cell>41.55</cell><cell>47.71</cell><cell>46.45</cell></row><row><cell>Cal101</cell><cell cols="4">74.08 66.70 65.96 70.28</cell><cell>63.33</cell><cell>60.70</cell><cell>64.38</cell><cell>62.59</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Copyright c 2016, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Acknowledgements</head><p>We thank G. Hinton for useful comments. This work was supported by the Center for Brains, Minds and Machines (CBMM), funded by NSF STC award CCF 1231216.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Applying convolutional neural networks concepts to hybrid NN-HMM model for speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdel-Hamid</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="4277" to="4280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">How auto-encoders could provide credit assignment in deep networks via target propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.04156</idno>
		<idno>arXiv:1407.7906</idno>
	</analytic>
	<monogr>
		<title level="m">Towards biologically plausible deep learning</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1487" to="1518" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Adaptive optimal control without weight transport</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An analysis of single-layer networks in unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ng</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lee</forename><forename type="middle">;</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Crick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on artificial intelligence and statistics</title>
		<imprint>
			<date type="published" when="1989" />
			<biblScope unit="volume">337</biblScope>
			<biblScope unit="page" from="129" to="132" />
		</imprint>
	</monogr>
	<note>The recent excitement about neural networks</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning generative visual models from few training examples: An incremental bayesian approach tested on 101 object categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Fanello</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.5401</idno>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition Workshops (CVPRW), 2013 IEEE Conference on</title>
		<meeting><address><addrLine>Fergus, and Perona</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007" />
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page" from="59" to="70" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Neural turing machines</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Competitive learning: From interactive activation to adaptive resonance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holub</forename><surname>Griffin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Griffin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Holub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive science</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="23" to="63" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>Caltech-256 object category dataset</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Sainath</surname></persName>
		</author>
		<idno>Hinton et al. 2012</idno>
	</analytic>
	<monogr>
		<title level="m">Neural information processing systems</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>American Institute of Physics</publisher>
			<date type="published" when="1988" />
			<biblScope unit="volume">313</biblScope>
			<biblScope unit="page" from="82" to="97" />
		</imprint>
	</monogr>
	<note>IEEE</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Multilayer feedforward networks are universal approximators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stinchcombe</forename><surname>Hornik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>White ; Hornik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stinchcombe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural networks</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="359" to="366" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Labeled faces in the wild: A database for studying face recognition in unconstrained environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on faces in real-life images: Detection</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>alignment and recognition (ECCV</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sutskever</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hinton ; Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03167</idno>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>ImageNet classification with deep convolutional neural networks. Krizhevsky 2009] Krizhevsky, A. 2009. Learning multiple layers of features from tiny images</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning process in an asymmetric threshold network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Le Cun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Disordered systems and biological organization</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1986" />
			<biblScope unit="page" from="233" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">The mnist database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cortes</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Burges ] Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Burges</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Subtasks of Unconstrained Face Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liao</forename><surname>Leibo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Z</forename><surname>Leibo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">; D B</forename><surname>Poggio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Akerman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1411.0247</idno>
	</analytic>
	<monogr>
		<title level="m">Random feedback weights support learning in deep neural networks</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>International Joint Conference on Computer Vision</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andersen</forename><surname>Mazzoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename><forename type="middle">;</forename><surname>Mazzoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Andersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
	<note>A more biologically plausible learning rule for neural networks</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Reading digits in natural images with unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Netzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS workshop on deep learning and unsupervised feature learning</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006" />
			<biblScope unit="volume">2011</biblScope>
		</imprint>
	</monogr>
	<note>Computer Vision, Graphics &amp; Image Processing. ICVGIP&apos;08. Sixth Indian Conference on</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Biologically plausible error-driven learning using local activation differences: The generalized recirculation algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>O&amp;apos;reilly ; O&amp;apos;reilly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="895" to="938" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Scaling up biologically-inspired computer vision: A case study in unconstrained face recognition on facebook</title>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on</title>
		<meeting><address><addrLine>Torralba; Nelson</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1986" />
			<biblScope unit="volume">440</biblScope>
			<biblScope unit="page" from="422" to="435" />
		</imprint>
	</monogr>
	<note>Cell</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Manhattan rule training for memristive crossbar circuit pattern classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lenc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zamanidoost</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Bayat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Strukov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kataeva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zamanidoost</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Bayat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Strukov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kataeva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MatConvNet -Convolutional Neural Networks for MAT-LAB</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Zamanidoost et al. 2015. Zamanidoost et al. 2015. Manhattan rule training for memristive crossbar circuit pattern classifiers</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
