<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning Deep CNN Denoiser Prior for Image Restoration</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
							<email>cskaizhang@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Dept. of Computing</orgName>
								<orgName type="institution">The Hong Kong Polytechnic University</orgName>
								<address>
									<settlement>Hong Kong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
							<email>wmzuo@hit.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuhang</forename><surname>Gu</surname></persName>
							<email>shuhanggu@gmail.com</email>
							<affiliation key="aff1">
								<orgName type="department">Dept. of Computing</orgName>
								<orgName type="institution">The Hong Kong Polytechnic University</orgName>
								<address>
									<settlement>Hong Kong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
							<email>cslzhang@comp.polyu.edu.hk</email>
							<affiliation key="aff1">
								<orgName type="department">Dept. of Computing</orgName>
								<orgName type="institution">The Hong Kong Polytechnic University</orgName>
								<address>
									<settlement>Hong Kong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Learning Deep CNN Denoiser Prior for Image Restoration</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T21:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Model-based optimization methods and discriminative learning methods have been the two dominant strategies for solving various inverse problems in low-level vision. Typically, those two kinds of methods have their respective merits and drawbacks, e.g., model-based optimization methods are flexible for handling different inverse problems but are usually time-consuming with sophisticated priors for the purpose of good performance; in the meanwhile, discriminative learning methods have fast testing speed but their application range is greatly restricted by the specialized task. Recent works have revealed that, with the aid of variable splitting techniques, denoiser prior can be plugged in as a modular part of model-based optimization methods to solve other inverse problems (e.g., deblurring). Such an integration induces considerable advantage when the denoiser is obtained via discriminative learning. However, the study of integration with fast discriminative denoiser prior is still lacking. To this end, this paper aims to train a set of fast and effective CNN (convolutional neural network) denoisers and integrate them into model-based optimization method to solve other inverse problems. Experimental results demonstrate that the learned set of denoisers not only achieve promising Gaussian denoising results but also can be used as prior to deliver good performance for various low-level vision applications.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Image restoration (IR) has been a long-standing problem for its highly practical value in various low-level vision applications <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b46">47]</ref>. In general, the purpose of image restoration is to recover the latent clean image x from its degraded observation y = Hx + v, where H is a degradation matrix, v is additive white Gaussian noise of standard deviation σ. By specifying different degradation matrices, one can correspondingly get different IR tasks. Three classical IR tasks would be image denoising when H is an identity matrix, image deblurring when H is a blurring operator, image super-resolution when H is a composite operator of blurring and down-sampling.</p><p>Since IR is an ill-posed inverse problem, the prior which is also called regularization needs to be adopted to constraint the solution space <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b65">66]</ref>. From a Bayesian perspective, the solutionx can be obtained by solving a Maximum A Posteriori (MAP) problem,</p><formula xml:id="formula_0">x = arg max x log p(y|x) + log p(x)<label>(1)</label></formula><p>where log p(y|x) represents the log-likelihood of observation y, log p(x) delivers the prior of x and is independent of y. More formally, Eqn. (1) can be reformulated aŝ x = arg min</p><formula xml:id="formula_1">x 1 2 y − Hx 2 + λΦ(x)<label>(2)</label></formula><p>where the solution minimizes an energy function composed of a fidelity term 1 2 y − Hx 2 , a regularization term Φ(x) and a trade-off parameter λ. The fidelity term guarantees the solution accords with the degradation process, while the regularization term enforces desired property of the output.</p><p>Generally, the methods to solve Eqn. <ref type="bibr" target="#b1">(2)</ref> can be divided into two main categories, i.e., model-based optimization methods and discriminative learning methods. The modelbased optimization methods aim to directly solve Eqn. <ref type="bibr" target="#b1">(2)</ref> with some optimization algorithms which usually involve a time-consuming iterative inference. On the contrary, discriminative learning methods try to learn the prior parameters Θ and a compact inference through an optimization of a loss function on a training set containing degraded-clean image pairs <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b56">57]</ref>. The objective is generally given by (3) Because the inference is guided by the MAP estimation, we refer to such methods as MAP inference guided discriminative learning methods. By replacing the MAP inference with a predefined nonlinear functionx = f (y, H; Θ), one can treat the plain discriminative learning methods as general case of Eqn. <ref type="bibr" target="#b2">(3)</ref>. It can be seen that one obvious difference between model-based optimization method and discriminative learning method is that, the former is flexible to handle various IR tasks by specifying degradation matrix H, whereas the later needs to use the training data with certain degradation matrices to learn the model. As a consequence, different from model-based optimization methods which have flexibility to handle different IR tasks, discriminative learning methods are usually restricted by specialized tasks. For example, model-based optimization methods such as NCSR <ref type="bibr" target="#b21">[22]</ref> are flexible to handle denoising, superresolution and deblurring, whereas discriminative learning methods MLP <ref type="bibr" target="#b7">[8]</ref>, SRCNN <ref type="bibr" target="#b20">[21]</ref>, DCNN <ref type="bibr" target="#b61">[62]</ref> are designed for those three tasks, respectively. Even for a specific task such as denoising, model-based optimization methods (e.g., BM3D <ref type="bibr" target="#b16">[17]</ref> and WNNM <ref type="bibr" target="#b28">[29]</ref>) can handle different noise levels, whereas discriminative learning method of <ref type="bibr" target="#b33">[34]</ref> separately train a different model for each level.</p><p>With the sacrifice of flexibility, however, discriminative learning methods can not only enjoy a fast testing speed but also tend to deliver promising performance due to the joint optimization and end-to-end training. On the contrary, model-based optimization methods are usually timeconsuming with sophisticated priors for the purpose of good performance <ref type="bibr" target="#b26">[27]</ref>. As a result, those two kinds of methods have their respective merits and drawbacks, and thus it would be attractive to investigate their integration which leverages their respective merits. Fortunately, with the aid of variable splitting techniques, such as alternating direction method of multipliers (ADMM) method <ref type="bibr" target="#b4">[5]</ref> and halfquadratic splitting (HQS) method <ref type="bibr" target="#b27">[28]</ref>, it is possible to deal with fidelity term and regularization term separately <ref type="bibr" target="#b43">[44]</ref>, and particularly, the regularization term only corresponds to a denoising subproblem <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b60">61]</ref>. Consequently, this enables an integration of any discriminative denoisers into model-based optimization methods. However, to the best of our knowledge, the study of integration with discriminative denoiser is still lacking. This paper aims to train a set of fast and effective discriminative denoisers and integrate them into modelbased optimization methods to solve other inverse problems. Rather than learning MAP inference guided discriminative models, we instead adopt plain convolutional neural networks (CNN) to learn the denoisers, so as to take advantage of recent progress in CNN as well as the merit of GPU computation. Particularly, several CNN techniques, including Rectifier Linear Units (ReLU) <ref type="bibr" target="#b36">[37]</ref>, batch normalization <ref type="bibr" target="#b31">[32]</ref>, Adam <ref type="bibr" target="#b35">[36]</ref>, dilated convolution <ref type="bibr" target="#b62">[63]</ref> are adopted into the network design or training. As well as providing good performance for image denoising, the learned set of denoisers are plugged in a model-based optimization method to tackle various inverse problems.</p><p>The contribution of this work is summarized as follows:</p><p>• We trained a set of fast and effective CNN denoisers.</p><p>With variable splitting technique, the powerful denoisers can bring strong image prior into model-based optimization methods.</p><p>• The learned set of CNN denoisers are plugged in as a modular part of model-based optimization methods to tackle other inverse problems. Extensive experiments on classical IR problems, including deblurring and super-resolution, have demonstrated the merits of integrating flexible model-based optimization methods and fast CNN-based discriminative learning methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Image Restoration with Denoiser Prior</head><p>There have been several attempts to incorporate denoiser prior into model-based optimization methods to tackle with other inverse problems. In <ref type="bibr" target="#b18">[19]</ref>, the authors used Nash equilibrium to derive an iterative decoupled deblurring BM3D (IDDBM3D) method for image debluring. In <ref type="bibr" target="#b23">[24]</ref>, a similar method which is equipped with CBM3D denoiser prior was proposed for single image super-resolution (SISR). By iteratively updating a back-projection step and a CBM3D denoising step, the method has an encouraging performance for its PSNR improvement over SRCNN <ref type="bibr" target="#b20">[21]</ref>. In <ref type="bibr" target="#b17">[18]</ref>, the augmented Lagrangian method was adopted to fuse the BM3D denoiser into an image deblurring scheme. With a similar iterative scheme to <ref type="bibr" target="#b18">[19]</ref>, a plug-and-play priors framework based on ADMM method was proposed in <ref type="bibr" target="#b60">[61]</ref>. Here we note that, prior to <ref type="bibr" target="#b60">[61]</ref>, a similar idea of plugand-play is also mentioned in <ref type="bibr" target="#b65">[66]</ref> where a half quadratic splitting (HQS) method was proposed for image denoising, deblurring and inpainting. In <ref type="bibr" target="#b30">[31]</ref>, the authors used an alternative to ADMM and HQS, i.e., the primal-dual algorithm <ref type="bibr" target="#b10">[11]</ref>, to decouple fidelity term and regularization term. Some of the other related work can be found in <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b57">58]</ref>. All the above methods have shown that the decouple of the fidelity term and regularization term can enable a wide variety of existing denoising models to solve different image restoration tasks.</p><p>We can see that the denoiser prior can be plugged in an iterative scheme via various ways. The common idea behind those ways is to decouple the fidelity term and regularization term. For this reason, their iterative schemes generally involve a fidelity term related subproblem and a denoising subproblem. In the next subsection, we will use HQS method as an example due to its simplicity. It should be noted that although the HQS can be viewed as a general way to handle different image restoration tasks, one can also incorporate the denoiser prior into other convenient and proper optimization methods for a specific application.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Half Quadratic Splitting (HQS) Method</head><p>Basically, to plug the denoiser prior into the optimization procedure of Eqn. <ref type="bibr" target="#b1">(2)</ref>, the variable splitting technique is usually adopted to decouple the fidelity term and regularization term. In half quadratic splitting method, by introducing an auxiliary variable z, Eqn. (2) can be reformulated as a constrained optimization problem which is given bŷ</p><formula xml:id="formula_2">x = arg min x 1 2 y − Hx 2 + λΦ(z) s.t. z = x (4)</formula><p>Then, HQS method tries to minimize the following cost function</p><formula xml:id="formula_3">L µ (x, z) = 1 2 y − Hx 2 + λΦ(z) + µ 2 z − x 2 (5)</formula><p>where µ is a penalty parameter which varies iteratively in a non-descending order. Eqn. <ref type="bibr" target="#b4">(5)</ref> can be solved via the following iterative scheme,</p><formula xml:id="formula_4">   x k+1 = arg min x y − Hx 2 + µ x − z k 2 (6a) z k+1 = arg min z µ 2 z − x k+1 2 + λΦ(z)<label>(6b)</label></formula><p>As one can see, the fidelity term and regularization term are decoupled into two individual subproblems. Specifically, the fidelity term is associated with a quadratic regularized least-squares problem (i.e., Eqn. (6a)) which has various fast solutions for different degradation matrices. A direct solution is given by</p><formula xml:id="formula_5">x k+1 = (H T H + µI) −1 (H T y + µz k )<label>(7)</label></formula><p>The regularization term is involved in Eqn. (6b) which can be rewritten as z k+1 = arg min</p><formula xml:id="formula_6">z 1 2( λ/µ) 2 x k+1 − z 2 + Φ(z) (8)</formula><p>According to Bayesian probability, Eqn. (8) corresponds to denoising the image x k+1 by a Gaussian denoiser with noise level λ/µ. As a consequence, any Gaussian denoisers can be acted as a modular part to solve Eqn. <ref type="bibr" target="#b1">(2)</ref>. To address this, we rewrite Eqn. (8) by following</p><formula xml:id="formula_7">z k+1 = Denoiser(x k+1 , λ/µ)<label>(9)</label></formula><p>It is worth noting that, according to Eqns. <ref type="formula">(8)</ref> and <ref type="formula" target="#formula_7">(9)</ref>, the image prior Φ(·) can be implicitly replaced by a denoiser prior. Such a promising property actually offers several advantages. First, it enables to use any gray or color denoisers to solve a variety of inverse problems. Second, the explicit image prior Φ(·) can be unknown in solving Eqn. <ref type="bibr" target="#b1">(2)</ref>. Third, several complementary denoisers which exploit different image priors can be jointly utilized to solve one specific problem. Note that this property can be also employed in other optimization methods (e.g., iterative shrinkage/thresholding algorithms ISTA <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b13">14]</ref> and FISTA <ref type="bibr" target="#b2">[3]</ref>) as long as there involves a denoising subproblem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Learning Deep CNN Denoiser Prior</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Why Choose CNN Denoiser?</head><p>As the regularization term of Eqn. (2) plays a vital role in restoration performance, the choice of denoiser priors thus would be pretty important in Eqn. <ref type="bibr" target="#b8">(9)</ref>. Existing denoiser priors that have been adopted in model-based optimization methods to solve other inverse problems include total variation (TV) <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b42">43]</ref>, Gaussian mixture models (GMM) <ref type="bibr" target="#b65">[66]</ref>, K-SVD <ref type="bibr" target="#b24">[25]</ref>, non-local means <ref type="bibr" target="#b6">[7]</ref> and BM3D <ref type="bibr" target="#b16">[17]</ref>. Such denoiser priors have their respective drawbacks. For example, TV can create watercolor-like artifacts; K-SVD denoiser prior suffers high computational burden; non-local means and BM3D denoiser priors may over-smooth the irregular structures if the image does not exhibit self-similarity property. Thus, strong denoiser prior which can be implemented efficiently is highly demanded.</p><p>Regardless of the speed and performance, color image prior or denoiser is also a key factor that needs to be taken into account. This is because most of the images acquired by modern cameras or transmitted in internet are in RGB format. Due to the correlation between different color channels, it has been acknowledged that jointly handling the color channels tends to produce better performance than independently dealing with each color channel <ref type="bibr" target="#b25">[26]</ref>. However, existing methods mainly focus on modeling gray image prior and there are only a few works concentrating on modeling color image prior (see, e.g., <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b45">46]</ref>). Perhaps the most successful color image prior modeling method is CBM3D <ref type="bibr" target="#b15">[16]</ref>. It first decorrelates the image into a luminance-chrominance color space by a hand-designed linear transform and then applies the gray BM3D method in each transformed color channels. While CBM3D is promising for color image denoising, it has been pointed out that the resulting transformed luminance-chrominance color channels still remain some correlation <ref type="bibr" target="#b41">[42]</ref> and it is preferable to jointly handle RGB channels. Consequently, instead of utilizing the hand-designed pipeline, using discriminative learning methods to automatically reveal the underlying color image prior would be a good alternative.</p><p>By considering the speed, performance and discriminative color image prior modeling, we choose deep CNN to learn the discriminative denoisers. The reasons of using CNN are four-fold. First, the inference of CNN is very efficient due to the parallel computation ability of GPU. Second, CNN exhibits powerful prior modeling capacity with deep architecture. Third, CNN exploits the external prior which is complementary to the internal prior of many existing denoisers such as BM3D. In other words, a combination with BM3D is expected to improve the performance. Fourth, great progress in training and designing CNN have been made during the past few years and we can take advantage of those progress to facilitate discriminative learning.  <ref type="figure">Figure 1</ref>. The architecture of the proposed denoiser network. Note that "s-DConv" denotes s-dilated convolution <ref type="bibr" target="#b62">[63]</ref>, here s = 1, 2, 3 and 4; "BNorm" represents batch normalization <ref type="bibr" target="#b31">[32]</ref>; "ReLU" is the rectified linear units (max(·, 0)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">The Proposed CNN Denoiser</head><p>The architecture of the proposed CNN denoiser is illustrated in <ref type="figure">Figure 1</ref>. It consists of seven layers with three different blocks, i.e., "Dilated Convolution+ReLU" block in the first layer, five "Dilated Convolution+Batch Normal-ization+ReLU" blocks in the middle layers, and "Dilated Convolution" block in the last layer. The dilation factors of (3×3) dilated convolutions from first layer to the last layer are set to 1, 2, 3, 4, 3, 2 and 1, respectively. The number of feature maps in each middle layer is set to 64. In the following, we will give some important details in our network design and training.</p><p>Using Dilated Filter to Enlarge Receptive Field. It has been widely acknowledged that the context information facilitates the reconstruction of the corrupted pixel in image denoising. In CNN, to capture the context information, it successively enlarges the receptive field through the forward convolution operations. Generally, there are two basic ways to enlarge the receptive field of CNN, i.e., increasing the filter size and increasing the depth. However, increasing the filter size would not only introduce more parameters but also increase the computational burden <ref type="bibr" target="#b52">[53]</ref>. Thus, using 3×3 filter with a large depth is popularized in existing CNN network design <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b55">56]</ref>. In this paper, we instead use the recent proposed dilated convolution to make a tradeoff between the size of receptive filed and network depth. Dilated convolution is known for its expansion capacity of the receptive field while keeping the merits of traditional 3×3 convolution. A dilated filter with dilation factor s can be simply interpreted as a sparse filter of size (2s+1)×(2s+1) where only 9 entries of fixed positions can be non-zeros. Hence, the equivalent receptive field of each layer is 3, 5, 7, 9, 7, 5 and 3. Consequently, it can be easily obtained that the receptive filed of the proposed network is 33×33. If the traditional 3×3 convolution filter is used, the network will either have a receptive filed of size 15×15 with the same network depth (i.e., <ref type="bibr" target="#b6">7)</ref> or have a depth of 16 with the same receptive filed (i.e., 33×33). To show the advantage of our design over the above two cases, we have trained three different models on noise level 25 with same training settings. It turns out that our designed model can have an average PSNR of 29.15dB on BSD68 dataset <ref type="bibr" target="#b49">[50]</ref>, which is much better than 28.94dB of 7 layers network with traditional 3×3 convolution filter and very close to 29.20dB of 16 layers network.</p><p>Using Batch Normalization and Residual Learning to Accelerate Training. While advanced gradient optimization algorithms can accelerate training and improve the performance, the architecture design is also an important factor. Batch normalization and residual learning which are two of the most influential architecture design techniques have been widely adopted in recent CNN architecture designs. In particular, it has been pointed out that the combination of batch normalization and residual learning is particularly helpful for Gaussian denoising since they are beneficial to each other. To be specific, it not only enables fast and stable training but also tends to result in better denoising performance <ref type="bibr" target="#b64">[65]</ref>. In this paper, such strategy is adopted and we empirically find it also can enable fast transfer from one model to another with different noise level.</p><p>Using Training Samples with Small Size to Help Avoid Boundary Artifacts. Due to the characteristic of convolution, the denoised image of CNN may introduce annoying boundary artifacts without proper handling. There are two common ways to tackle with this, i.e., symmetrical padding and zero padding. We adopt the zero padding strategy and wish the designed CNN has the capacity to model image boundary. Note that the dilated convolution with dilation factor 4 in the fourth layer pads 4 zeros in the boundaries of each feature map. We empirically find that using training samples with small size can help avoid boundary artifacts. The main reason lies in the fact that, rather than using training patches of large size, cropping them into small patches can enable CNN to see more boundary information. For example, by cropping an image patch of size 70×70 into four small non-overlap patches of size 35×35, the boundary in-formation would be largely augmented. We also have tested the performance by using patches of large size, we empirically find this does not improve the performance. However, if the size of the training patch is smaller than the receptive field, the performance would decrease.</p><p>Learning Specific Denoiser Model with Small Interval Noise Levels. Since the iterative optimization framework requires various denoiser models with different noise levels, a practical issue on how to train the discriminative models thus should be taken into consideration. Various studies have shown that if the exact solutions of subproblems (i.e., Eqn. (6a) and Eqn. (6b)) are difficult or time-consuming to optimize, then using an inexact but fast subproblem solution may accelerate the convergence <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b65">66]</ref>. In this respect, their is no need to learn many discriminative denoiser models for each noise level. On the other hand, although Eqn. (9) is a denoiser, it has a different goal from the traditional Gaussian denoising. The goal of traditional Gaussian denoising is to recover the latent clean image, however, the denoiser here just acts its own role regardless of the noise type and noise level of the image to be denoised. Therefore, the ideal discriminative denoiser in Eqn. <ref type="bibr" target="#b8">(9)</ref> should be trained by current noise level. As a result, there is tradeoff to set the number of denoisers. In this paper, we trained a set of denoisers on noise level range [0, 50] and divided it by a step size of 2 for each model, resulting in a set of 25 denoisers for each gray and color image prior modelling. Due to the iterative scheme, it turns out the noise level range of [0, 50] is enough to handle various image restoration problems. Especially noteworthy is the number of the denoisers which is much less than that of learning different models for different degradations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>The Matlab source code of the proposed method can be downloaded at https://github.com/cszn/ircnn.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Image Denoising</head><p>It is widely acknowledged that convolutional neural networks generally benefit from the availability of large training data. Hence, instead of training on a small dataset consisting of 400 Berkeley segmentation dataset (BSD) images of size 180×180 <ref type="bibr" target="#b12">[13]</ref>, we collect a large dataset which includes 400 BSD images, 400 selected images from validation set of ImageNet database <ref type="bibr" target="#b19">[20]</ref> and 4,744 images of Waterloo Exploration Database <ref type="bibr" target="#b39">[40]</ref>. We empirically find using large dataset does not improve the PSNR results of BSD68 dataset <ref type="bibr" target="#b49">[50]</ref> but can slightly improve the performance of other testing images. We crop the images into small patches of size 35×35 and select N =256×4,000 patches for training. As for the generation of corresponding noisy patches, we achieve this by adding additive Gaussian noise to the clean patches during training. Since the residual learning strategy is adopted, we use the following loss function,</p><formula xml:id="formula_8">(Θ) = 1 2N N i=1 f (y i ; Θ) − (y i − x i ) 2 F (10) where {(y i , x i )} N i=1</formula><p>represents N noisy-clean patch pairs. To optimize the network parameters Θ, the Adam solver <ref type="bibr" target="#b35">[36]</ref> is adopted. The step size is started from 1e−3 and then fixed to 1e−4 when the training error stops decreasing. The training was terminated if the training error was fixed in five sequential epochs. For the other hyperparameters of Adam, we use their default setting. The minibatch size is set to 256. Rotation or/and flip based data augmentation is used during mini-batch learning. The denoiser models are trained in Matlab (R2015b) environment with MatConvNet package <ref type="bibr" target="#b59">[60]</ref> and an Nvidia Titan X GPU. To reduce the whole training time, once a model is obtained, we initialize the adjacent denoiser with this model. It takes about three days to train the set of denoiser models.</p><p>We compared the proposed denioser with several stateof-the-art denoising methods, including two model-based optimization methods (i.e., BM3D <ref type="bibr" target="#b16">[17]</ref> and WNNM <ref type="bibr" target="#b28">[29]</ref>), two discriminative learning methods (i.e., MLP <ref type="bibr" target="#b7">[8]</ref> and TNRD <ref type="bibr" target="#b12">[13]</ref>). The gray image denoising results of different methods on BSD68 dataset are shown in <ref type="table" target="#tab_1">Table 1</ref>. It can be seen that WNNM, MLP and TNRD can outperform BM3D by about 0.3dB in PSNR. However, the proposed CNN denoiser can have a PSNR gain of about 0.2dB over those three methods. <ref type="table">Table 2</ref> shows the color image denoising results of benchmark CBM3D and our proposed CNN denoiser, it can be seen that the proposed denoiser consistently outperforms CBM3D by a large margin. Such a promising result can be attributed to the powerful color image prior modeling capacity of CNN.</p><p>For the run time, we compared with BM3D and TNRD due to their potential value in practical applications. Since the proposed denoiser and TNRD support parallel computation on GPU, we also give the GPU run time. To make a further comparison with TNRD under similar PSNR perfor-mance, we additionally provide the run time of the proposed denoiser where each middle layer has 24 feature maps. We use the Nvidia cuDNN-v5 deep learning library to accelerate the GPU computation and the memory transfer time between CPU and GPU is not considered. <ref type="table" target="#tab_2">Table 3</ref> shows the run times of different methods for denoising images of size 256×256, 512×512 and 1024×1024 with noise level 25. We can see that the proposed denoiser is very competitive in both CPU and GPU implementation. It is worth emphasizing that the proposed denoiser with 24 feature maps of each layer has a comparable PSNR of 28.94dB to TNRD but delivers a faster speed. Such a good compromise between speed and performance over TNRD is properly attributed to the following three reasons. First, the adopted 3×3 convolution and ReLU nonlinearity are simple yet effective and efficient. Second, in contrast to the stage-wise architecture of TNRD which essentially has a bottleneck in each immediate output layer, ours encourages a fluent information flow among different layers, thus having larger model capacity. Third, batch normalization which is beneficial to Gaussian denoising is adopted. According to the above discussions, we can conclude that the proposed denoiser is a strong competitor against BM3D and TNRD. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Image Deblurring</head><p>As a common setting, the blurry images are synthesized by first applying a blur kernel and then adding additive Gaussian noise with noise level σ. In addition, we assume the convolution is carried out with circular boundary conditions. Thus, an efficient implementation of Eqn. (7) by using Fast Fourier Transform (FFT) can be employed. To make a thorough evaluation, we consider three blur kernels, including a commonly-used Gaussian kernel with standard deviation 1.6 and the first two of the eight real blur kernels from <ref type="bibr" target="#b37">[38]</ref>. As shown in <ref type="table" target="#tab_3">Table 4</ref>, we also consider Gaussian noise with different noise levels. For the compared methods, we choose one discriminative method named MLP <ref type="bibr" target="#b51">[52]</ref> and three model based optimization methods, including ID-DBM3D <ref type="bibr" target="#b18">[19]</ref>, NCSR <ref type="bibr" target="#b21">[22]</ref> and EPLL. Among the testing images, apart from three classical gray images as shown in <ref type="figure" target="#fig_1">Figure 2</ref>, three color images are also included such that we can test the performance of learned color denoiser prior.</p><p>In the meanwhile, we note that the above methods are designed for gray image deblurring. Specially, NCSR tackles the color input by first transforming it into YCbCr space and then conducting the main algorithm in the luminance component. In the following experiments, we simply plug the color denoisers into the HQS framework, whereas we separately handle each color channel for IDDBM3D and MLP. Note that MLP trained a specific model for the Gaussian blur kernel with noise level 2.</p><p>Once the denoisers are provided, the subsequent crucial issue would be parameter setting. From Eqns. (6), we can note that there involve two parameters, λ and µ, to tune. Generally, for a certain degradation, λ is correlated with σ 2 and keeps fixed during iterations, while µ controls noise level of denoiser. Since the HQS framework is denoiserbased, we instead set the noise level of denoiser in each iteration to implicitly determine µ. Note that the noise level of denoiser λ/µ should be set from large to small. In our experimental settings, it is decayed exponentially from 49 to a value in <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b14">15]</ref> depending on the noise level. The number of iterations is set to 30 as we find it is large enough to obtain a satisfying performance.</p><p>The PSNR results of different methods are shown in Table 4. As one can see, the proposed CNN denoiser prior based optimization method achieves very promising PSNR results. <ref type="figure">Figure 3</ref> illustrates deblurred Leaves image by different methods. We can see that IDDBM3D, NCSR and MLP tend to smooth the edges and generate color artifacts. In contrast, the proposed method can recover image sharpness and naturalness.  <ref type="figure">Figure 3</ref>. Image deblurring performance comparison for Leaves image (the blur kernel is Gaussian kernel with standard deviation 1.6, the noise level σ is 2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Single Image Super-Resolution</head><p>In general, the low-resolution (LR) image can be modeled by a blurring and subsequent down-sampling operation on a high-resolution one. The existing super-resolution models, however, mainly focus on modeling image prior and are trained for specific degradation process. This makes the learned model deteriorates seriously when the blur kernel adopted in training deviates from the real one <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b63">64]</ref>. Instead, our model can handle any blur kernels without retraining. Thus, in order to thoroughly evaluate the flexibility of the CNN denoiser prior based optimization method as well as the effectiveness of the CNN denoisers, following <ref type="bibr" target="#b44">[45]</ref>, this paper considers three typical image degradation settings for SISR, i.e., bicubic downsampling (default setting of Matlab function imresize) with two scale factors 2 and 3 <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b20">21]</ref> and blurring by Gaussian kernel of size 7×7 with standard deviation 1.6 followed by downsampling with scale factor 3 <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b44">45]</ref>.</p><p>Inspired by the method proposed in <ref type="bibr" target="#b23">[24]</ref> which iteratively updates a back-projection <ref type="bibr" target="#b32">[33]</ref> step and a denoising step for SISR, we use the following back-projection iteration to solve Eqn. (6a), <ref type="bibr" target="#b10">(11)</ref> where ↓ sf denotes the degradation operator with downscaling factor sf, ↑ sf bicubic represents bicubic interpolation operator with upscaling factor sf, and α is the step size. It is worthy noting that the iterative regularization step of methods such as NCSR and WNNM actually corresponds to solving Eqn. (6a). From this viewpoint, those methods are optimized under HQS framework. Here, note that only the bicubic downsampling is considered in <ref type="bibr" target="#b23">[24]</ref>, whereas Eqn. <ref type="bibr" target="#b10">(11)</ref> is extended to deal with different blur kernels. To obtain a fast convergence, we repeat Eqn. <ref type="bibr" target="#b10">(11)</ref> five times before applying the denoising step. The number of main iterations is set to 30, the step size α is fixed to 1.75 and the noise levels of denoiser are decayed exponentially from 12×sf to sf.</p><formula xml:id="formula_9">x k+1 = x k − α(y − x k ↓ sf ) ↑ sf bicubic</formula><p>The proposed deep CNN denoiser prior based SISR method is compared with five state-of-the-art methods, in-cluding two CNN-based discriminative learning methods (i.e., SRCNN <ref type="bibr" target="#b20">[21]</ref> and VDSR <ref type="bibr" target="#b34">[35]</ref>), one statistical prediction model based discriminative learning method <ref type="bibr" target="#b44">[45]</ref> which we refer to as SPMSR, one model based optimization method (i.e., NCSR <ref type="bibr" target="#b21">[22]</ref>) and one denoiser prior based method (i.e., SRBM3D <ref type="bibr" target="#b23">[24]</ref>). Except for SRBM3D, all the existing methods conducted their main algorithms on Y channel (i.e., luminance) of transformed YCbCr space. In order to evaluate the proposed color denoiser prior, we also conduct experiments on the original RGB channels and thus the PSNR results of super-resolved RGB images of different methods are also given. Since the source code of SRBM3D is not available, we also compare two methods which replace the proposed CNN denoiser with BM3D/CBM3D denoiser. Those two methods are denoted by SRBM3D G and SRBM3D C , respectively. <ref type="table" target="#tab_4">Table 5</ref> shows the average PSNR(dB) results of different methods for SISR on Set5 and Set14 <ref type="bibr" target="#b58">[59]</ref>. Note that SRCNN and VDSR are trained with bicubic blur kernel, thus it is unfair to use their models to super-resolve the low-resolution image with Gaussian kernel. As a matter of fact, we give their performances to demonstrate the limitations of such discriminative learning methods. From Table 5, we can have several observations. First, although SRCNN and VDSR achieve promising results to tackle the case with bicubic kernel, their performance deteriorates seriously when the low-resolution image are not generated by bicubic kernel (see <ref type="figure">Figure 4</ref>). On the other hand, with the accurate blur kernel, even NCSR and SPMSR outperform SRCNN and VDSR for Gaussian blur kernel. In contrast, the proposed methods (denoted by Proposed G and Proposed C ) can handle all the cases well. Second, the proposed methods have a better PSNR result than SRBM3D C and SRBM3D G which indicates good denoiser prior facilitates to solve super-resolution problem. Third, both of the gray and color CNN denoiser prior based optimization methods can produce promising results. As an example for the testing speed comparison, our method can super-resolve the Butterfly image in 0.5 second on GPU and 12 seconds on CPU, whereas NCSR spends 198 seconds on CPU.  <ref type="figure">Figure 4</ref>. Single image super-resolution performance comparison for Butterfly image from Set5 (the blur kernel is 7×7 Gaussian kernel with standard deviation 1.6, the scale factor is 3). Note that the comparison with SRCNN and VDSR is unfair. The proposed deep CNN denoiser prior based optimization method can super-resolve the LR image by tuning the blur kernel and scale factor without training, whereas SRCNN and VDSR need additional training to deal with such cases. As a result, this figure is mainly used to show the flexibility advantage of the proposed deep CNN denoiser prior based optimization method over discriminative learning methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we have designed and trained a set of fast and effective CNN denoisers for image denoising. Specially, with the aid of variable splitting technique, we have plugged the learned denoiser prior into a model-based optimization method of HQS to solve the image deblurring and super-resolution problems. Extensive experimental results have demonstrated that the integration of model-based optimization method and discriminative CNN denoiser results in a flexible, fast and effective framework for various image restoration tasks. On the one hand, different from conventional model-based optimization methods which are usually time-consuming with sophisticated image priors for the purpose of achieving good results, the proposed deep CNN denoiser prior based optimization method can be implemented effectively due to the plug-in of fast CNN denoisers. On the other hand, different from discriminative learning methods which are specialized for certain image restoration tasks, the proposed deep CNN denoiser prior based optimization method is flexible in handling various tasks while can produce very favorable results. In summary, this work highlights the potential benefits of integrating flexible modelbased optimization methods and fast discriminative learning methods. In addition, this work has shown that learning expressive CNN denoiser prior is a good alternative to model image prior.</p><p>While we have demonstrated various merits of plugging powerful CNN denoiser into model-based optimization methods, there also remain room for further study. Some research directions are listed as follows. First, it will be interesting to investigate how to reduce the number of the discriminative CNN denoisers and the number of whole iterations. Second, extending the proposed CNN denoiser based HQS framework to other inverse problems such as inpainting and blind deblurring would be also interesting. Third, utilizing multiple priors which are complementary to improve performance is certainly one promising direction. Finally, and perhaps most interestingly, since the HQS framework can be treated as a MAP inference, this work also provides some insights into designing CNN architecture for task-specific discriminative learning. Meanwhile, one should be aware that CNN has its own design flexibility and the best CNN architecture is not necessarily inspired by MAP inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Acknowledgements</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Six testing images for image deblurring. (a) Cameraman; (b) House; (c) Lena; (d) Monarch; (e) Leaves; (f) Parrots.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>The average PSNR(dB) results of different methods on (gray) BSD68 dataset.</figDesc><table><row><cell>Methods</cell><cell>BM3D</cell><cell>WNNM</cell><cell>TNRD</cell><cell>MLP</cell><cell>Proposed</cell></row><row><cell>σ = 15</cell><cell>31.07</cell><cell>31.37</cell><cell>31.42</cell><cell>-</cell><cell>31.63</cell></row><row><cell>σ = 25</cell><cell>28.57</cell><cell>28.83</cell><cell>28.92</cell><cell>28.96</cell><cell>29.15</cell></row><row><cell>σ = 50</cell><cell>25.62</cell><cell>25.87</cell><cell>25.97</cell><cell>26.03</cell><cell>26.19</cell></row><row><cell cols="6">Table 2. The average PSNR(dB) results of CBM3D and proposed</cell></row><row><cell cols="4">CNN denoiser on (color) BSD68 dataset.</cell><cell></cell><cell></cell></row><row><cell>Noise Level</cell><cell>5</cell><cell>15</cell><cell>25</cell><cell>35</cell><cell>50</cell></row><row><cell>CBM3D</cell><cell>40.24</cell><cell>33.52</cell><cell>30.71</cell><cell>28.89</cell><cell>27.38</cell></row><row><cell>Proposed</cell><cell>40.36</cell><cell>33.86</cell><cell>31.16</cell><cell>29.50</cell><cell>27.86</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Run time (in seconds) of different methods on images of size 256×256, 512×512 and 1024×1024 with noise level 25.</figDesc><table><row><cell>Size</cell><cell>Device</cell><cell>BM3D</cell><cell>TNRD</cell><cell cols="2">Proposed 24 Proposed 64</cell></row><row><cell>256×256</cell><cell>CPU GPU</cell><cell>0.66 -</cell><cell>0.47 0.010</cell><cell>0.10 0.006</cell><cell>0.310 0.012</cell></row><row><cell>512×512</cell><cell>CPU GPU</cell><cell>2.91 -</cell><cell>1.33 0.032</cell><cell>0.39 0.016</cell><cell>1.24 0.038</cell></row><row><cell>1024×1024</cell><cell>CPU GPU</cell><cell>11.89 -</cell><cell>4.61 0.116</cell><cell>1.60 0.059</cell><cell>4.65 0.146</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>Deblurring results of different methods.</figDesc><table><row><cell>Methods</cell><cell>σ</cell><cell>C.man House</cell><cell>Lena</cell><cell>Monar. Leaves Parrots</cell></row><row><cell></cell><cell cols="4">Gaussian blur with standard deviation 1.6</cell></row><row><cell>IDDBM3D</cell><cell></cell><cell cols="2">27.08 32.41 30.28</cell><cell>27.02 26.95 30.15</cell></row><row><cell>NCSR MLP</cell><cell>2</cell><cell cols="2">27.99 33.38 30.99 27.84 33.43 31.10</cell><cell>28.32 27.50 30.42 28.87 28.91 31.24</cell></row><row><cell>Proposed</cell><cell></cell><cell cols="2">28.12 33.80 31.17</cell><cell>30.00 29.78 32.07</cell></row><row><cell></cell><cell></cell><cell cols="2">Kernel 1 (19×19) [38]</cell><cell></cell></row><row><cell>EPLL Proposed</cell><cell>2.55</cell><cell cols="2">29.43 31.48 31.68 32.07 35.17 33.88</cell><cell>28.75 27.34 30.89 33.62 33.92 35.49</cell></row><row><cell>EPLL Proposed</cell><cell>7.65</cell><cell cols="2">25.33 28.19 27.37 28.11 32.03 29.51</cell><cell>22.67 21.67 26.08 29.20 29.07 31.63</cell></row><row><cell></cell><cell></cell><cell cols="2">Kernel 2 (17×17) [38]</cell><cell></cell></row><row><cell>EPLL Proposed</cell><cell>2.55</cell><cell cols="2">29.67 32.26 31.00 31.69 35.04 33.53</cell><cell>27.53 26.75 30.44 33.13 33.51 35.17</cell></row><row><cell>EPLL Proposed</cell><cell>7.65</cell><cell cols="2">24.85 28.08 27.03 27.70 31.94 29.27</cell><cell>21.60 21.09 25.77 28.73 28.63 31.35</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>Average PSNR(dB) results of different methods for single image super-resolution on Set5 and Set14. SRBM3D C Proposed G Proposed C</figDesc><table><row><cell cols="10">Dataset SRBM3D G Set5 Scale Kernel Channel SRCNN VDSR NCSR SPMSR SRBM3D 2 Bicubic Y 36.65 37.56 -36.11 37.10 36.34 RGB 34.45 35.16 -33.94 -34.11 3 Y 32.75 33.67 -32.31 33.30 32.62 Bicubic RGB 30.72 31.50 -30.32 -30.57</cell><cell>36.25 34.22 32.54 30.69</cell><cell>37.43 35.05 33.39 31.26</cell><cell>37.22 35.07 33.18 31.25</cell></row><row><cell></cell><cell>3</cell><cell>Gaussian</cell><cell>Y RGB</cell><cell>30.42 28.50</cell><cell>30.54 28.62</cell><cell>33.02 30.00</cell><cell>32.27 30.02</cell><cell>--</cell><cell>32.66 30.31</cell><cell>32.59 30.74</cell><cell>33.38 30.92</cell><cell>33.17 31.21</cell></row><row><cell></cell><cell>2</cell><cell>Bicubic</cell><cell>Y RGB</cell><cell>32.43 30.43</cell><cell>33.02 30.90</cell><cell>--</cell><cell>31.96 30.05</cell><cell>32.80 -</cell><cell>32.09 30.15</cell><cell>32.25 30.32</cell><cell>32.88 30.79</cell><cell>32.79 30.78</cell></row><row><cell>Set14</cell><cell>3</cell><cell>Bicubic</cell><cell>Y RGB</cell><cell>29.27 27.44</cell><cell>29.77 27.85</cell><cell>--</cell><cell>28.93 27.17</cell><cell>29.60 -</cell><cell>29.11 27.32</cell><cell>29.27 27.47</cell><cell>29.61 27.72</cell><cell>29.50 27.67</cell></row><row><cell></cell><cell>3</cell><cell>Gaussian</cell><cell>Y RGB</cell><cell>27.71 26.02</cell><cell>27.80 26.11</cell><cell>29.26 26.98</cell><cell>28.89 27.01</cell><cell>--</cell><cell>29.18 27.24</cell><cell>29.39 27.60</cell><cell>29.63 27.59</cell><cell>29.55 27.70</cell></row><row><cell cols="3">(a) Ground-truth</cell><cell cols="2">(b) Zoomed LR image</cell><cell></cell><cell cols="2">(c) SRCNN (24.46dB)</cell><cell cols="2">(d) VDSR (24.73dB)</cell><cell></cell><cell cols="2">(e) Proposed G (29.32dB)</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work is supported by HK RGC General Research Fund (PolyU 5313/13E) and National Natural Science Foundation of China (grant no. 61672446, 61671182). We gratefully acknowledge the support from NVIDIA Corporation for providing us the Titan X GPU used in this research.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">C</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Hunt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Digital image restoration. Prentice-Hall Signal Processing Series</title>
		<imprint>
			<date type="published" when="1977" />
			<publisher>Prentice-Hall</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Training an active random field for real-time image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Barbu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2451" to="2462" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A fast iterative shrinkagethresholding algorithm for linear inverse problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Teboulle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM journal on imaging sciences</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="183" to="202" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A new TwIST: Two-step iterative shrinkage/thresholding algorithms for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Bioucas-Dias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Figueiredo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2992" to="3004" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Distributed optimization and statistical learning via the alternating direction method of multipliers. Foundations and Trends in Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Peleato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Eckstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Turning a denoiser into a super-resolver using plug and play priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Brifman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Romano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Image Processing</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1404" to="1408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A non-local algorithm for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="60" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Image denoising: Can plain neural networks compete with BM3D</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">C</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Schuler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Harmeling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2392" to="2399" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Blind image deconvolution: theory and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Campisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CRC press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An algorithm for total variation minimization and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chambolle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical imaging and vision</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="89" to="97" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A first-order primal-dual algorithm for convex problems with applications to imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chambolle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Imaging and Vision</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="120" to="145" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Plug-and-Play ADMM for image restoration: Fixed-point convergence and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">A</forename><surname>Elgendy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computational Imaging</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="84" to="98" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Trainable nonlinear reaction diffusion: A flexible framework for fast and effective image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Signal recovery by proximal forward-backward splitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Combettes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">R</forename><surname>Wajs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multiscale Modeling &amp; Simulation</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1168" to="1200" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep network cascade for image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="49" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Color image denoising via sparse 3D collaborative filtering with grouping constraint in luminance-chrominance space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dabov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Image Processing</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">313</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Image denoising by sparse 3-D transform-domain collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dabov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2080" to="2095" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Image deblurring by augmented lagrangian with BM3D frame prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Danielyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Information Theoretic Methods in Science and Engineering</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="16" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">BM3D frames and variational image deblurring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Danielyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1715" to="1728" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Image super-resolution using deep convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="295" to="307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Nonlocally centralized sparse representation for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1620" to="1630" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Accurate blur models vs. image priors in single image superresolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Efrat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Glasner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Apartsin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Nadler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2832" to="2839" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Single image superresolution via BM3D sparse coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Katkovnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Signal Processing Conference</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2849" to="2853" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Image denoising via sparse and redundant representations over learned dictionaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Aharon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image processing</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3736" to="3745" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Pointwise shape adaptive DCT denoising with structure preservation in luminance-chrominance space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Video Processing and Quality Metrics for Consumer Electronics</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">How well do filter-based MRFs model natural images?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint DAGM (German Association for Pattern Recognition) and OAGM Symposium</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="62" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Nonlinear image recovery with halfquadratic regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="932" to="946" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Weighted nuclear norm minimization with application to image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2862" to="2869" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Flexisp: A flexible camera image processing framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Heide</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-T</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rouf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pajak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Gallo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Heidrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">231</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Motion analysis for image enhancement: Resolution, occlusion, and transparency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Irani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Peleg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Visual Communication and Image Representation</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="324" to="335" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Natural image denoising with convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Seung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="769" to="776" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Accurate image superresolution using very deep convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1646" to="1654" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference for Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Understanding and evaluating blind deconvolution algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1964" to="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">The augmented lagrange multiplier method for exact recovery of corrupted low-rank matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1009.5055</idno>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Waterloo exploration database: New challenges for image quality assessment models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Duanmu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1004" to="1016" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Sparse representation for color image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="53" to="69" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Inter-channel relation based vectorial total variation for color image recovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miyata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Image Processing</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2251" to="2255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">An iterative regularization method for total variation-based image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Goldfarb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multiscale Modeling &amp; Simulation</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="460" to="489" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Proximal algorithms. Foundations and Trends in optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Boyd</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="127" to="239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A statistical prediction model based on sparse representations for single image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Peleg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2569" to="2582" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Image denoising using the higher order singular value decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rajwade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rangarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Banerjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="849" to="862" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Bayesian-based iterative method of image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">H</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JOSA</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="59" />
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">The little engine that could regularization by denoising (RED)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Romano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Milanfar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.02862</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Poisson inverse problems by the plug-and-play scheme</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Giryes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Visual Communication and Image Representation</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="96" to="108" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Fields of experts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="205" to="229" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Shrinkage fields for effective image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2774" to="2781" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A machine learning approach for non-blind image deconvolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Schuler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">Christopher</forename><surname>Burger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Harmeling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Scholkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1067" to="1074" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference for Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Plug-and-play priors for bright field electron tomography and sparse interpolation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sreehari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Venkatakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wohlberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">F</forename><surname>Drummy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Simmons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Bouman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.07331</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Separable markov random field model and its applications in low level vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Tappen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="402" to="407" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2015-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Utilizing variational optimization to learn markov random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Tappen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Image restoration and reconstruction using variable splitting and class-adapted image priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Teodoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Bioucas-Dias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Figueiredo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Image Processing</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3518" to="3522" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">A+: Adjusted anchored neighborhood regression for fast super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Timofte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">De</forename><surname>Smet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="111" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">MatConvNet: Convolutional neural networks for matlab</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lenc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Conference on Multimedia Conference</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="689" to="692" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Plug-and-play priors for model based reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">V</forename><surname>Venkatakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Bouman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wohlberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Global Conference on Signal and Information Processing</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="945" to="948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Deep convolutional neural network for image deconvolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1790" to="1798" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.07122</idno>
		<title level="m">Multi-scale context aggregation by dilated convolutions</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Revisiting single image super-resolution under internet environment: blur kernels and reconstruction algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pacific Rim Conference on Multimedia</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="677" to="687" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Beyond a Gaussian denoiser: Residual learning of deep CNN for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Image Processing</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">From learning models of natural image patches to whole image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zoran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="479" to="486" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
