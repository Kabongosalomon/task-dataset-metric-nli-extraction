<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Automatic Dialect Detection in Arabic Broadcast Speech</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2016-08-11">11 Aug 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><surname>Ali</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Qatar Computing Research Institute</orgName>
								<orgName type="institution" key="instit2">HBKU</orgName>
								<address>
									<settlement>Doha</settlement>
									<country key="QA">Qatar</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Centre for Speech Technology Research</orgName>
								<orgName type="institution">University of Edinburgh</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Najim</forename><surname>Dehak</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">MIT Computer Science and Artificial Intelligence Laboratory (CSAIL)</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">JHU Center for Language and Speech Processing (CLSP)</orgName>
								<orgName type="department" key="dep2">Département de Génie Logiciel et des TI</orgName>
								<orgName type="institution">4É cole de technologie supérieure</orgName>
								<address>
									<settlement>Baltimore, Montréal</settlement>
									<region>MD</region>
									<country>USA, Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Cardinal</surname></persName>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Khurana</surname></persName>
							<email>skhurana@qf.org.qa</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Qatar Computing Research Institute</orgName>
								<orgName type="institution" key="instit2">HBKU</orgName>
								<address>
									<settlement>Doha</settlement>
									<country key="QA">Qatar</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sree</forename><surname>Harsha Yella</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">MIT Computer Science and Artificial Intelligence Laboratory (CSAIL)</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Glass</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">MIT Computer Science and Artificial Intelligence Laboratory (CSAIL)</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Bell</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Centre for Speech Technology Research</orgName>
								<orgName type="institution">University of Edinburgh</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Renals</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Centre for Speech Technology Research</orgName>
								<orgName type="institution">University of Edinburgh</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Automatic Dialect Detection in Arabic Broadcast Speech</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2016-08-11">11 Aug 2016</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Index Terms: Dialect Identification, Vector Space Modelling</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we investigate different approaches for dialect identification in Arabic broadcast speech. These methods are based on phonetic and lexical features obtained from a speech recognition system, and bottleneck features using the i-vector framework. We studied both generative and discriminative classifiers, and we combined these features using a multi-class Support Vector Machine (SVM). We validated our results on an Arabic/English language identification task, with an accuracy of 100%. We also evaluated these features in a binary classifier to discriminate between Modern Standard Arabic (MSA) and Dialectal Arabic, with an accuracy of 100%. We further reported results using the proposed methods to discriminate between the five most widely used dialects of Arabic: namely Egyptian, Gulf, Levantine, North African, and MSA, with an accuracy of 59.2%. We discuss dialect identification errors in the context of dialect code-switching between Dialectal Arabic and MSA, and compare the error pattern between manually labeled data, and the output from our classifier. All the data used on our experiments have been released to the public as a language identification corpus.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The task of Dialect Identification (DID) is a special case of the more general problem of Language Identification (LID). LID refers to the process of automatically identifying the language class for given speech segment or text document. DID is arguably a more challenging problem than LID, since it consists of identifying the different dialects within the same language class. The importance of addressing DID can be gauged from its growing interest in the Automatic Speech Recognition (ASR) community <ref type="bibr" target="#b0">[1]</ref>. A good DID system can facilitate the identification of dialectal segments from an untranscribed mixed-speech dataset. This process can help reduce the ASR word error rate (WER) for dialectal data by training ASR systems for each dialect, or by adapting the ASR models to a particular dialect.</p><p>The natural language processing (NLP) community has aggregated dialectal Arabic into five regional language groups: Egyptian (EGY), North African or Maghrebi (NOR), Gulf or Arabian Peninsula (GLF), Levantine (LAV), and Modern Standard Arabic (MSA). An objective comparison of the varieties of Arabic dialects could potentially lead to the conclusion that Arabic dialects are historically related, but not synchronically, and are mutually unintelligible languages like English and Dutch. Normal vernacular can be difficult to understand across different Arabic dialects <ref type="bibr">[?]</ref>. Arabic dialects are thus sufficiently distinctive, and it is reasonable to regard the DID task in Arabic as similar to the LID task in other languages. <ref type="table" target="#tab_1">Table 1</ref> shows two phrases across the different dialects, it is clear from this example that there are lexical variations across the different dialects which motivates us to consider it.</p><p>Two broad LID approaches have been investigated in the literature: low-level acoustic features, and high-level phonetic and lexical features. In the lexical area, words, roots, morphology, and grammars <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref> have been studied. Acoustic features such as shifted delta cepstral coefficients <ref type="bibr" target="#b16">[17]</ref> and prosodic features <ref type="bibr" target="#b4">[5]</ref> using Gaussian mixture models (GMMs), i-vector representations and support vector machine (SVM) classifiers <ref type="bibr" target="#b16">[17]</ref> have been shown to be effective for LID. More recent work explored the use of frame-by-frame phone posteriors (PLLRs) <ref type="bibr" target="#b5">[6]</ref> as new features for LID. New subspace approaches based on non-negative factor analysis (NFA) for GMM weight decomposition and adaptation <ref type="bibr" target="#b6">[7]</ref> were also applied to both LID and DID tasks. GMM weight adaptation subspaces seem to provide complementary information to the classical i-vector framework. Finally, phoneme sequence modeling and its n-gram subspace have been studied for both Arabic DID <ref type="bibr" target="#b7">[8]</ref> and LID <ref type="bibr" target="#b8">[9]</ref>.  In this paper we investigate three Vector Subspace Models (VSMs) for Arabic DID based on 1) lexical, 2) phonetic, and 3) i-vectors. We conduct a thorough feature selection study of these models to better understand their interaction. A further contribution of this work is the release of an Arabic DID system so others can extend and improve DID performance on this task. 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Vector Space Models</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Senone based Utterance VSM</head><p>Senone refers to an n-gram phone sequence. In our case n ≤ 4. VSM construction takes place in two steps: first, a phoneme recognizer is used to extract the senone <ref type="bibr" target="#b9">[10]</ref> sequence for a given speech utterance. The phoneme sequence is obtained by automatic vowelization of the training text, followed by vowelization to phonetization (V2P). The 36 chosen phonemes cover all the dialectal Arabic sounds. Further details about the speech recognition pipeline, training data, and phoneme set is given in <ref type="bibr" target="#b10">[11]</ref>. For the phoneme sequence, we process the phoneme lattice, and obtain the one-best transcription, ignoring silences as well as noisy silences. Each speech utterance (u) is then represented as a high dimensional sparse vector ( #» u ):</p><formula xml:id="formula_0">#» u = (A(f (u, s1)), A(f (u, s2)), . . . , A(f (u, s d ))) , (1)</formula><p>where f (u, si) is the number of times a senone si occurs in the speech utterance u, and A is the scaling function. We experiment with both an identity scaling function and tf.idf scaling function, commonly used in the field of Natural Language Processing <ref type="bibr" target="#b11">[12]</ref> to downweight the contribution of the words (in our case senones) that occur in almost all documents (in our case utterances), as these words (senones) do not provide any discriminative information about the documents (utterances).</p><p>The vector space is then represented by the matrix, Us ∈ R d×N (see <ref type="figure" target="#fig_0">Fig 1)</ref>. This approach and the notation used to define a VSM is directly inspired by the seminal works in the area of VSM of Natural Language in <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15]</ref> and in LID <ref type="bibr">[?]</ref>. </p><formula xml:id="formula_1">Us =      u 1 u 2 ... u N s 1 A(f (s1, u1) A(f (s1, u2) . . . A(f (s1, uN ) s 2 A(f (s2, u1) A(f (s2, u2) . . . A(f (s2, uN ) . . . . . . . . . . . . . . . s d A(f (s d , u1) A(f (s d , u2) . . . A(f (s d , uN )     </formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Word based Utterance VSM</head><p>The word-based utterance VSM (Uw) is constructed in two steps in a manner similar to the senone features: An ASR system is used to extract the word sequence for each utterance in the speech database. Details about the ASR system can be found in <ref type="bibr" target="#b10">[11]</ref>. Each speech utterance (u) is then represented as a high-dimensional sparse vector ( #» u ):</p><formula xml:id="formula_2">#» u = (A(f (u, w1)), A(f (u, w2)), . . . , A(f (u, w d ′ ))) ,<label>(2)</label></formula><p>where f (u, wi) is the number of times a word wi occurs in the speech utterance u and A is the scaling function which has the same interpretation as for Us (above). Vocabulary size was 55k. The tri-gram dictionary size was 580k which we used to construct the word based VSM</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">i-vector-based Utterance VSM</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1.">Bottleneck Features (BN)</head><p>Recently, bottleneck features extracted from an ASR DNNbased model were applied successfully to language identification <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b27">28]</ref>. In this paper, we used a similar bottleneck features configurations as in our previous ASR-DNN system for MSA speech recognition <ref type="bibr" target="#b26">[27]</ref>. This system is based on two successive DNN models. Both DNNs use the same setup of 5 hidden sigmoid layers and 1 linear BN layer, and they were both based on tied-states as target outputs. The senone labels of dimension 3040 are generated by a forced alignment from an HMM-GMM baseline trained on 60 hours of manually transcribed Al-Jazeera MSA news recordings <ref type="bibr" target="#b10">[11]</ref>. The input to the first DNN consists of 23 critical-band energies that are obtained from Mel filter-bank. Pitch and voicing probability are then added. 11 consecutive frames are then stacked together. The second DNN is used for correcting the posterior outputs of the first DNN. In this architecture, the input features of the second DNN are the outputs of the BN layer from the first DNN. Context expansion is achieved by concatenating frames with time offsets of -10, -5, 0, 5, and 10. Thus, the overall time context seen by the second DNN is 31 frames.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2.">Modeling</head><p>An effective and well-studied method in language and dialect recognition is the i-vector approach <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17]</ref>. The i-vector involves modeling speech using a universal background model (UBM) -typically a large GMM -trained on a large amount of data to represent general feature characteristics, which plays a role of a prior on how all dialects look like. The i-vector approach is a powerful technique that summarizes all the updates happening during the adaptation of the UBM mean components to a given utterance. All this information is modeled in a low dimensional subspace referred to as the total variability space.</p><p>In the i-vector framework, each speech utterance can be represented by a GMM supervector, which is assumed to be generated as follows:</p><formula xml:id="formula_3">M = u + T v</formula><p>Where u is the channel and dialect independent supervector (which can be taken to be the UBM supervector), T spans a low-dimensional subspace and v are the factors that best describe the utterance-dependent mean offset. The vector v is treated as a latent variable with the i-vector being its maximuma-posteriori (MAP) point estimate. The subspace matrix T is estimated using maximum likelihood on large training dataset. An efficient procedure for training and for MAP adaptation of ivector can be found in <ref type="bibr" target="#b17">[18]</ref>. In this approach, the i-vector is the low-dimensional representation of an audio recording that can be used for classification and estimation purposes. In our experiments, the UBM was a GMM with 2048 components, BN features were used, and the i-vectors were 400-dimensional. In order to maximize the discrimination between the different dialect classes in the i-vector space, we combine Linear Discriminant Analysis (LDA) and Within Class Co-variance Normalization <ref type="bibr" target="#b16">[17]</ref>. This intersession compensation method has been used with both SVM <ref type="bibr" target="#b16">[17]</ref> and cosine scoring <ref type="bibr" target="#b6">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Dataset</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Train Data</head><p>The training corpus was collected from the Broadcast News domain in four Arabic dialects (EGY, LAV, GLF, and NOR) as well as MSA. Data recordings were carried out at 16Khz. The recordings were segmented to avoid speaker overlap, removing any non-speech parts such as music and background noise. More details about the training data can be found in <ref type="bibr" target="#b6">[7]</ref>. Although the test database came from the same broadcast domain, the recording setup is different. The test data was downloaded directly from the high quality video server for Aljazeera (bright-cove) over the period of July 2104 until January 2015, as part of QCRI Advanced Transcription Service (QATS) <ref type="bibr" target="#b18">[19]</ref>. <ref type="bibr">Data</ref>  <ref type="table" target="#tab_1">EGY GLF LAV NOR MSA ENG   Train 13  9.5  11  9  10  10   Test  2  2  2  2  2  2   Table 2</ref>: Number of hours of speech available for each dialect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Test Data</head><p>The test set was labeled using the crowdsource platform Crowd-Flower, with the criteria to have a minimum of three judges per file and up to nine judges, or 75% inter-annotator agreement (whichever comes first). More details about the test set and crowdsourcing experiment can be found in <ref type="bibr" target="#b19">[20]</ref>. The test set used in this paper differs from that used in <ref type="bibr" target="#b6">[7]</ref> for two reasons: First, the crowdsourced data is available to reproduce the results, and thus can be used as a standard test set for Arabic DID; second, the new test set has been collected using different channels, and recording setup compared to the training data, which makes our experiments less sensitive to channel/speaker characteristics. The train and test data can be found on the QCRI web portal 2 . <ref type="table">Table 2</ref> and <ref type="table" target="#tab_3">Table 3</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Choosing the Best Classifier</head><p>We first studied the best classification approach for the DID task from a set of two generative models: n-gram language model <ref type="bibr" target="#b20">[21]</ref> and Naive Bayes <ref type="bibr" target="#b21">[22]</ref>, and two discriminative classifiers: linear SVM <ref type="bibr" target="#b22">[23]</ref> and Maximum Entropy <ref type="bibr" target="#b23">[24]</ref>. We measured the performance of each model on the DID task, in the word or lexical-based utterance vector space, which is constructed using the approach mentioned in section 2, using identity scaling function A, and performing no dimensionality reduction. Hence, the dimensionality of an utterance vector, #» u , is the same as the size of the lexicon, which in our case was 55k.</p><p>Results can be seen in table 4. As the linear SVM performs the best, it is our choice of classifier for the rest of the experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Feature Selection Study</head><p>Here we examine the dialect information captured by the three utterance VSMs explained in section 2. We also explore the concatenation of the utterance vector representations, and report the results in <ref type="table" target="#tab_7">Tables 5 and 6</ref>. Details about the terms in the results table are given below:</p><p>• U i w : Refers to the utterance VSM in which each utterance is represented by a vector given by equation 2, where A is chosen to be the identity function. The bases 2 http://alt.qcri.org/resources/ArabicDialectIDCorpus/  of the vectors are the words in the lexicon. SVD is used to reduce the dimensionality of the utterance Vector Space from 55k originally, to 300, 600, 1200, 1600 at which point increase the gain in the classification performance tends to saturate.</p><p>• U tf .idf w : Same as the previous Utterance VSM, except that A is chosen via tf.idf <ref type="bibr" target="#b11">[12]</ref> instead of identity function, which gives us significant improvement in accuracy over the previous vector space.</p><p>• U i s : Refers to the utterance VSM in which each utterance is represented by a vector given by equation 1, where A is chosen to be the identity function. Utterance vector bases corresponds to senones. Just as with the word-based utterance VSM, we use SVD on the vector space and experiment with different dimensions. The utterance Vector Space constructed using senone features is more discriminative than word-based Vector space.</p><p>• U tf .idf s : Refers to the same vector space as the previous one, except that A is chosen to be the tf.idf function. tf.idf , does not help in the case of senone features.</p><p>• Feature Combination: Combining the best senonebased utterance VSM, U i s (600d), and the best lexicalbased utterance VSM, U tf idf w (1200d), to form a concatenated feature vector representation. SVD is performed to reduce the dimensions of the feature space. Feature combination does not help and hence we conclude that the two vector spaces are capturing similar information.</p><p>• U bnf iVec : Refers to the utterance VSM, where each utterance is represented by a compact 400d i-vector (section 2.3). We use the bottleneck features to train the UBM, which is then used to extract the i-vector. We do not experiment with different i-vector dimensions and take the best dimension reported in <ref type="bibr" target="#b16">[17]</ref> for the LID task. The i-vector feature space is significantly more discriminative than previously defined feature spaces.</p><p>• U bnf iVec+LDA+WCNN : Reducing the dimensionality of the i-vector space using LDA and performing WCNN has been reported to do well in LID tasks <ref type="bibr" target="#b16">[17]</ref> and we use the same technique and see a significant improvement in the DID results.</p><p>• U bnf iVec+LDA+WCNN + U i s (600d): Finally we concatenate the best senone-based VSM with the best ivector-based VSM, to form a concatenated vector representation for each utterance and see slight improvements in the results. As the lexical and senone-based representations encode the same information about the dialect, we do not experiment with concatenated lexical and ivector representations.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">One Vs All classification (Sanity Check)</head><p>We constructed a senone-based utterance VSM (section 2.1) based on 20 hours of speech; 10 hours English (which we got from [?]) and 10 hours Arabic (randomly sampled from our training data, section 3). Binary classification (English vs Arabic) using an SVM classifier, was then performed and it yielded 100% accuracy on the 1.5 hour test set. The reason to choose the senone-based feature space and not the i-vector-based feature space for classification is to avoid channel mismatch, as the English data came from a different source domain. We did a similar experiment to classify MSA versus all dialectal Arabic and again obtained 100% classification accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">System Output Combination</head><p>We fused the scores of the best senone system and the SVMbased i-vector system. In the fusion steps, the original scores of each system were normalized and combined using the same fusion weights for both systems. This approach yielded a final accuracy of 60.2%, which is the best performance we achieved. One explanation for this gain is that the error patterns for the two feature spaces are quite different, and we were able to confirm that by analyzing the confusion matrix for each system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Discussion</head><p>We infer from the confusion matrix in <ref type="table">Table 7</ref> that GLF and LAV are the most confusable dialect pair. We believe that this is related to the greater lexical similarity between these two dialects (see <ref type="table" target="#tab_1">Table 1</ref>). Note, the confusion matrix is from the best DID system. We borrowed <ref type="table" target="#tab_9">Table 8</ref> from previous work <ref type="bibr" target="#b19">[20]</ref> on the test set, which shows the amount of time the same speakers switch between dialect and another (mainly MSA, and their own native dialect). For example, in the second row of  <ref type="table">Table 7</ref>: Confusion Matrix for DID.</p><p>82(41%) validated as GLF, 8(4%) as LAV, and 4 segments were not identified with enough confidence to be considered. This means more than 50% of the random GLF speakers data is infact MSA speech segments. This is strong evidence for the amount of code-switching between one dialect and MSA from the same speaker.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>This paper presents our efforts on automatic dialect identification for Arabic broadcast speech. We have demonstrated a dialect classifier with an accuracy of 60.2% using system combination. We also achieved 100% accuracy on two binary classification tasks; MSA vs Dialectal Arabic and English vs Arabic. We studied the potential code-switching pattern in our classifier and its correlation with the manual annotation. Further work for this research is to study the code-switch between MSA and dialectal Arabic without considering speaker diarization or silence between speech segments in what can be called dialect diarization. We shall also study deep neural network approaches of classification to learn a more complex non-linear decision boundary.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Senone-based utterance VSM. Column vectors of the matrix correspond to the speech utterance vector representation formed using equation 1. d is the size of the senone dictionary, and N is the total number of speech utterances in the dialectal speech database.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table /><note>Lexical examples in Arabic and Buckwalter format.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>present some statistics about the train and the test data.</figDesc><table><row><cell cols="7">Data EGY GLF LAV NOR MSA ENG</cell></row><row><cell cols="7">Train 1720 1907 1059 1934 1820 1649</cell></row><row><cell>Test</cell><cell>315</cell><cell>348</cell><cell>238</cell><cell>355</cell><cell>265</cell><cell>452</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table /><note>Number of speech utterances for each dialect.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Performance of different classifiers using lexical features, with lexicon size of 55K. ACC, PRC and RCL correspond to accuracy, precision and recall on the test set.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Accuracy, Precision and Recall for different senone and lexical feature based Vector Spaces. d is the dimensionality of the Vector Space. Boldfaced numbers are the best accuracy for the corresponding vector space, for a corresponding vector space dimensionality d. A detailed explanation of feature spaces is given in the feature selection study(section 4.2)    </figDesc><table><row><cell>Feature Space</cell><cell>d</cell><cell cols="3">ACC PRC RCL</cell></row><row><cell>U bnf iVec</cell><cell cols="2">400 55.3</cell><cell>61</cell><cell>55.9</cell></row><row><cell>U bnf iVec+LDA+WCNN</cell><cell>4</cell><cell>58.5</cell><cell>62.3</cell><cell>58.9</cell></row><row><cell>U bnf iVec+LDA+WCNN+LNORM</cell><cell>4</cell><cell>58.7</cell><cell>61.9</cell><cell>59.3</cell></row><row><cell>U bnf iVec+LDA+WCNN + U i s(600d)</cell><cell cols="2">604 59.2</cell><cell>62.7</cell><cell>59.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc>Accuracy</figDesc><table><row><cell>, Precision and Recall for different i-vector</cell></row><row><cell>based feature spaces. d refers to the dimensionality of the Vec-</cell></row><row><cell>tor Space. A detailed explanation of feature spaces is given in</cell></row><row><cell>the feature selection study (section 4.2).</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 8 ,</head><label>8</label><figDesc>there are 200 samples from potential Gulf speakers. After manually labeling, there were 106(53%) segments labeled as MSA,</figDesc><table><row><cell></cell><cell>EGY</cell><cell>GLF</cell><cell>LAV</cell><cell>MSA</cell><cell>NOR</cell><cell cols="2">Total Truth PRC</cell></row><row><cell>EGY</cell><cell>221</cell><cell>15</cell><cell>57</cell><cell>13</cell><cell>9</cell><cell>315</cell><cell>50.3%</cell></row><row><cell>GLF</cell><cell>45</cell><cell>121</cell><cell>82</cell><cell>12</cell><cell>5</cell><cell>265</cell><cell>55.8%</cell></row><row><cell>LAV</cell><cell>74</cell><cell>43</cell><cell>199</cell><cell>18</cell><cell>14</cell><cell>348</cell><cell>46.9%</cell></row><row><cell>MSA</cell><cell>19</cell><cell>17</cell><cell>20</cell><cell>218</cell><cell>5</cell><cell>279</cell><cell>77%</cell></row><row><cell>NOR</cell><cell>80</cell><cell>21</cell><cell>66</cell><cell>22</cell><cell>166</cell><cell>355</cell><cell>83.4%</cell></row><row><cell cols="2">#class 439</cell><cell>217</cell><cell>424</cell><cell>283</cell><cell>199</cell><cell></cell><cell></cell></row><row><cell>RCL</cell><cell cols="5">70.2% 45.7% 57.2% 78.1% 46.8%</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 8 :</head><label>8</label><figDesc>Expected dialect of each speech segment from particular dialectal speakers.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/Qatar-Computing-Research-Institute/dialectID</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">http://arxiv.org/ps/1509.06928v2 http://arxiv.org/ps/1509.06928v2</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Dialect identification: Impact of differences between read versus spontaneous speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EUSIPCO-2010: European Signal Processing Conference</title>
		<meeting><address><addrLine>Aalborg, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Automatic language recognition via spectral and token based approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">M</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Springer Handbook of Speech Processing</title>
		<editor>J. Benesty, M. M. Sondhi, and Y. Huang</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Language identification: A tutorial</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ambikairajah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sethu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="82" to="108" />
		</imprint>
	</monogr>
	<note>Circuits and Systems Magazine</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Comparison of four approaches to automatic language identification of telephone speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zissman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Speech and Audio Processing</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="31" to="44" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">ivector-based prosodic system for language identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Martínez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Burget</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ferrer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Scheffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICASSP</title>
		<imprint>
			<biblScope unit="page" from="4861" to="4864" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Pllr features in language recognition system for rats</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Plchot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Diez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Soufifar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Burget</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fifteenth Annual Conference of the International Speech Communication Association</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Nonnegative factor analysis for gmm weight adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Bahari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dehak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Burget</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Glass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Audio Speech and Language Processing</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">From modern standard arabic to levantine asr: Leveraging gale for dialects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Soltau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mangu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Biadsy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>ASRU</publisher>
			<biblScope unit="page" from="266" to="271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Discriminative classifiers for phonotactic language recognition with ivectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Soufifar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cumani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Burget</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Černocky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICASSP</title>
		<imprint>
			<biblScope unit="page" from="4853" to="4856" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Subphonetic Modeling for Speech Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-Y</forename><surname>Hwang</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="174" to="179" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A complete kaldi recipe for building arabic speech recognition systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cardinal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dahak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Glass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SLT</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Using TF-IDF to Determine Word Relevance in Document Queries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Eden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Edu</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A Vector Space Model for Automatic Indexing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Magazine Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="613" to="620" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Division of Informatics , University of Edinburgh Institute for Adaptive and Neural Computation The Direct Route : Mediated Priming in Semantic Space by The Direct Route : Mediated Priming in Semantic Space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mcdonald</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Dependency-Based Construction of Semantic Space Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Padó</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="161" to="199" />
			<date type="published" when="2004-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Front-end factor analysis for speaker verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dehak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kenny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dehak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dumouchel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ouellet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Audio, Speech, and Language Processing</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="788" to="798" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Language recognition via i-vectors and dimensionality reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dehak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Torres-Carrasquillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dehak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="857" to="860" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A study of interspeaker variability in speaker verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kenny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ouellet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dehak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dumouchel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="page" from="980" to="988" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>Audio, Speech, and Language Processing</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">QCRI advanced transcription ssystem (QATS)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vogel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SLT</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Crowdsource a little to label a lot: Labeling a speech corpus of dialectal arabic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ali</surname></persName>
		</author>
		<editor>INTERSPEECH</editor>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Language Modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">CS229 Lecture notes Generative Learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Support vector machines for spam categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">N</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1048" to="1054" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
	<note>Neural Networks</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Using Maximum Entropy for Text Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nigam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Lium spkdiarization: an open source toolkit for diarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Meignier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Merlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CMU SPUD Workshop</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Code-Switching Event Detection by Using a Latent Language Space Model and the Delta-Bayesian</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-S</forename><surname>Hsu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="1892" to="1903" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Speaker Adaptation Using the I-Vector Technique for Bottleneck Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cardinal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dehak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Glass</surname></persName>
		</author>
		<editor>INTERSPEECH</editor>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A Unified Deep Neural Network for Speaker and Language Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dehak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTER-SPEECH</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">I-vector representation based on bottleneck features for language identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">R</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Electronics Letters</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Neural network bottleneck features for language identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Matejka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Mallidi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Glembek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Odyssey</title>
		<meeting>of Odyssey</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
