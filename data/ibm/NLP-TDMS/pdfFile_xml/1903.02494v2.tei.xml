<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Object Counting and Instance Segmentation with Image-level Supervision</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hisham</forename><surname>Cholakkal</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Inception Institute of Artificial Intelligence</orgName>
								<address>
									<country key="AE">UAE</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guolei</forename><surname>Sun</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Inception Institute of Artificial Intelligence</orgName>
								<address>
									<country key="AE">UAE</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shahbaz</forename><surname>Fahad</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Inception Institute of Artificial Intelligence</orgName>
								<address>
									<country key="AE">UAE</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Khan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Inception Institute of Artificial Intelligence</orgName>
								<address>
									<country key="AE">UAE</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Inception Institute of Artificial Intelligence</orgName>
								<address>
									<country key="AE">UAE</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Object Counting and Instance Segmentation with Image-level Supervision</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T18:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Common object counting in a natural scene is a challenging problem in computer vision with numerous realworld applications. Existing image-level supervised common object counting approaches only predict the global object count and rely on additional instance-level supervision to also determine object locations. We propose an imagelevel supervised approach that provides both the global object count and the spatial distribution of object instances by constructing an object category density map. Motivated by psychological studies, we further reduce image-level supervision using a limited object count information (up to four). To the best of our knowledge, we are the first to propose image-level supervised density map estimation for common object counting and demonstrate its effectiveness in image-level supervised instance segmentation. Comprehensive experiments are performed on the PASCAL VOC and COCO datasets. Our approach outperforms existing methods, including those using instance-level supervision, on both datasets for common object counting. Moreover, our approach improves state-of-the-art image-level supervised instance segmentation [33] with a relative gain of 17.8% in terms of average best overlap, on the PASCAL VOC 2012 dataset. 1 arXiv:1903.02494v2 [cs.CV] 13 May 2019</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Chattopadhyay et al.</p><p>[4] investigated regression-based common object counting, using image-level (per-category count) and instance-level (bounding box) supervisions. The image-level supervised strategy, denoted as glancing, used count annotations from both within and beyond the subitizing range to predict the global count of objects, without providing information about their location. The instance-level</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Common object counting, also referred as generic object counting, is the task of accurately predicting the number of different object category instances present in natural scenes (see <ref type="figure">Fig. 1</ref>). The common object categories in natural scenes can vary from fruits to animals and the counting must be performed in both indoor and outdoor scenes (e.g. COCO or PASCAL VOC datasets). Existing works employ a localization-based strategy or utilize regressionbased models directly optimized to predict object count, * Equal contribution <ref type="bibr" target="#b0">1</ref> Code is publicly available at github.com/GuoleiSun/CountSeg  <ref type="figure">Figure 1</ref>. Object counting on COCO dataset. The ground-truth and our predictions are shown in black and green, respectively. Despite being trained using image-level object counts within the subitizing range <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref>, it accurately counts objects beyond the subitizing range <ref type="bibr">(11 persons)</ref> under heavy occlusion (marked with blue arrow to show two persons) in the left image and diverse object categories in the right.</p><p>where the latter has been shown to provide superior results <ref type="bibr" target="#b3">[4]</ref>. However, regression-based methods only predict the global object count without determining object locations. Beside global counts, the spatial distribution of objects in the form of a per-category density map is helpful in other tasks, e.g., to delineate adjacent objects in instance segmentation (see <ref type="figure">Fig. 2</ref>). The problem of density map estimation to preserve the spatial distribution of people is well studied in crowd counting <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b30">31]</ref>. Here, the global count for the image is obtained by summing over the predicted density map. Standard crowd density map estimation methods are required to predict large number of person counts in the presence of occlusions, e.g., in surveillance applications. The key challenges of constructing a density map in natural scenes are different to those in crowd density estimation, and include large intra-class variations in generic objects, co-existence of multiple instances of different objects in a scene (see <ref type="figure">Fig. 1</ref>), and sparsity due to many objects having zero count on multiple images.</p><p>Most methods for crowd density estimation use instancelevel (point-level or bounding box) supervision that requires manual annotation of each instance location. Image- Instance segmentation examples using the PRM method <ref type="bibr" target="#b32">[33]</ref> (b) and our approach (c), on the PASCAL VOC 2012. Top row:</p><p>The PRM approach <ref type="bibr" target="#b32">[33]</ref> fails to delineate spatially adjacent two sheep category instances. Bottom row: single person parts predicted as multiple persons along with inaccurate mask separation results in over-prediction (7 instead of 5). Our approach produces accurate masks by exploiting the spatial distribution of object count in per-category density maps (d). Density map accumulation for each predicted mask is shown inside the contour drawn for clarity. In the top row, density maps for sheep and dog categories are overlaid.</p><p>level supervised training alleviates the need for such userintensive annotation by requiring only the count of different object instances in an image. We propose an imagelevel supervised density map estimation approach for natural scenes, that predicts the global object count while preserving the spatial distribution of objects.</p><p>Even though image-level supervised object counting reduces the burden of human annotation and is much weaker compared to instance-level supervisions, it still requires each object instance to be counted sequentially. Psychological studies <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b19">20]</ref> have suggested that humans are capable of counting objects non-sequentially using holistic cues for fewer object counts, termed as a subitizing range (generally 1-4). We utilize this property to further reduce image-level supervision by only using object count annotations within the subitizing range. For short, we call this image-level lower-count (ILC) supervision. Chattopadhyay et al. <ref type="bibr" target="#b3">[4]</ref> also investigate common object counting, where object counts (both within and beyond the subitizing range) are used to predict the global object count. Alternatively, instance-level (bounding box) supervision is used to count objects by dividing an image into non-overlapping regions, assuming each region count falls within the subitizing range. Different to these strategies <ref type="bibr" target="#b3">[4]</ref>, our ILC supervised approach requires neither bounding box annotation nor information beyond the subitizing range to predict both the count and the spatial distribution of object instances.</p><p>In addition to common object counting, the proposed ILC supervised density map estimation is suitable for other scene understanding tasks. Here, we investigate its effectiveness for image-level supervised instance segmentation, where the task is to localize each object instance with pixellevel accuracy, provided image-level category labels. Recent work of <ref type="bibr" target="#b32">[33]</ref>, referred as peak response map (PRM), tackles the problem by boosting the local maxima (peaks) in the class response maps <ref type="bibr" target="#b22">[23]</ref> of an image classifier using a peak stimulation module. A scoring metric is then used to rank off-the-shelf object proposals <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b24">25]</ref> corresponding to each peak for instance mask prediction. However, PRM struggles to delineate spatially adjacent object instances from the same object category (see <ref type="figure">Fig. 2(b)</ref>). We introduce a penalty term into the scoring metric that assigns a higher score to object proposals with a predicted count of 1, providing improved results ( <ref type="figure">Fig. 2(c)</ref>). The predicted count is obtained by accumulating the density map over the entire object proposal region ( <ref type="figure">Fig. 2(d)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contributions:</head><p>We propose an ILC supervised density map estimation approach for common object counting. A novel loss function is introduced to construct per-category density maps with explicit terms for predicting the global count and spatial distribution of objects. We also demonstrate the applicability of the proposed approach for image-level supervised instance segmentation. For common object counting, our ILC supervised approach outperforms state-of-the-art instance-level supervised methods with a relative gain of 6.4% and 2.9%, respectively, in terms of mean root mean square error (mRMSE), on the PASCAL VOC 2007 and COCO datasets. For image-level supervised instance segmentation, our approach improves the state of the art from 37.6 to 44.3 in terms of average best overlap (ABO), on the PASCAL VOC 2012 dataset. <ref type="figure">Figure 3</ref>. Overview of our overall architecture. Our network has an image classification and a density branch, trained jointly using ILC supervision. The image classification branch predicts the presence and absence of objects. This branch is used to generate pseudo groundtruth for training the density branch. The density branch has two terms (spatial and global) in the loss function and produces a density map to predict the global object count and preserve the spatial distribution of objects.</p><p>(bounding box) supervised strategy, denoted as subitizing, estimated a large number of objects by dividing an image into non-overlapping regions, assuming the object count in each region falls within the subitizing range. Instead, our ILC supervised approach requires neither bounding box annotation nor beyond subitizing range count information during training. It then predicts the global object count, even beyond the subitizing range, together with the spatial distribution of object instances.</p><p>Recently, Laradji et al. <ref type="bibr" target="#b13">[14]</ref> proposed a localizationbased counting approach, trained using instance-level (point) supervision <ref type="bibr" target="#b0">[1]</ref>. During inference, the model outputs blobs indicating the predicted locations of objects of interest and uses <ref type="bibr" target="#b28">[29]</ref> to estimate object counts from these blobs. Different to <ref type="bibr" target="#b13">[14]</ref>, our approach is image-level supervised and directly predicts the object count through a simple summation of the density map without requiring any post-processing <ref type="bibr" target="#b28">[29]</ref>. Regression-based methods generally perform well in the presence of occlusions <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b14">15]</ref>, while localization-based counting approaches <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b13">14]</ref> generalize well with a limited number of training images <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15]</ref>. Our method aims to combine the advantages of both approaches through a novel loss function that jointly optimizes the network to predict object locations and global object counts in a density map.</p><p>Reducing object count supervision for salient object subitizing was investigated in <ref type="bibr" target="#b29">[30]</ref>. However, their task is class-agnostic and subitizing is used to only count within the subitizing range. Instead, our approach constructs category-specific density maps and accurately predicts object counts both within and beyond the subitizing range. Common object counting has been previously used to improve object detection <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b7">8]</ref>. Their approach only uses the count information during detector training with no explicit component for count prediction. In contrast, our approach explicitly learns to predict the global object count.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed method</head><p>Here, we present our image-level lower-count (ILC) supervised density map estimation approach. Our approach is built upon an ImageNet pre-trained network backbone (ResNet50) <ref type="bibr" target="#b10">[11]</ref>. The proposed network architecture has two output branches: image classification and density branch (see <ref type="figure">Fig. 3</ref>). The image classification branch estimates the presence or absence of objects, whereas the density branch predicts the global object count and the spatial distribution of object instances by constructing a density map. We remove the global pooling layer from the backbone and adapt the fully connected layer with a 1 × 1 convolution having 2P channels as output. We divide these 2P channels equally between the image classification and density branches. We then add a 1 × 1 convolution having C output channels in each branch, resulting in a fully convolutional network <ref type="bibr" target="#b18">[19]</ref>. Here, C is the number of object categories and P is empirically set to be proportional to C. In each branch, the convolution is preceded by a batch normalization and a ReLU layer. The first branch provides object category maps and the second branch produces a density map for each object category.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">The Proposed Loss Function</head><p>Let I be a training image and t = {t 1 , t 2 , ..., t c , ..., t C } be the corresponding vector for the ground-truth count of C object categories. Instead of using an absolute object count, we employ a lower-count strategy to reduce the amount of image-level supervision. Given an image I, object categories are divided into three non-overlapping sets based on their respective instance counts. The first set, A, indicates object categories which are absent in I (i.e., t c = 0). The second set, S, represents categories within the subitizing range (i.e, 0 &lt; t c ≤ 4). The final set,S, indicates categories beyond the subitizing range (i.e, t c ≥t, wheret = 5).</p><p>Let</p><formula xml:id="formula_0">M = {M 1 , M 2 , ..., M c , ..., M C } denote the object category maps in the image classification branch, where M c ∈ R H×W . Let D = {D 1 , D 2 , ..., D c , ..., D C } rep- resent density maps produced by the density branch, where D c ∈ R H×W .</formula><p>Here, H × W is the spatial size of both the object category and density maps. The image classification and density branches are jointly trained, in an end-to-end fashion, given only ILC supervision with the following loss function:</p><formula xml:id="formula_1">L = L class + L spatial + L global Density map branch .</formula><p>(1)</p><p>Here, the first term refers to multi-label image classification loss <ref type="bibr" target="#b12">[13]</ref> (see Sec. 3.1.1). The last two terms, L spatial and L global , are used to train the density branch (Sec. 3.1.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Image Classification Branch</head><p>Generally, training a density map requires instance-level supervision, such as point-level annotations <ref type="bibr" target="#b14">[15]</ref>. Such information is unavailable in our ILC supervised setting. To address this issue, we propose to generate pseudo ground-truth by exploiting the coarse-level localization capabilities of an image classifier <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b31">32]</ref> via object category maps. These object category maps are generated from a fully convolutional architecture shown in <ref type="figure">Fig. 3</ref>. While specifying classification confidence at each image location, class activation maps (CAMs) struggle to delineate multiple instances from the same object category <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b31">32]</ref>. Recently, the local maxima of CAMs are further boosted, to produce object category maps, during an image-classifier training for image-level supervised instance segmentation <ref type="bibr" target="#b32">[33]</ref>. Boosted local maxima aim at falling on distinct object instances. For details on boosting local maxima, we refer to <ref type="bibr" target="#b32">[33]</ref>. Here, we use local maxima locations to generate pseudo ground-truth for training the density branch.</p><p>As described earlier, object categories in I are divided into three non-overlapping sets: A, S andS. To train a oneversus-rest image classifier, we derive binary labels from t c that indicate the presence ∀c ∈ {S,S} or absence ∀c ∈ A of object categories. LetM c ∈ R H×W be the peak map derived from c th object category map (M c ) of M such that:</p><formula xml:id="formula_2">M c (i, j) = M c (i, j), if M c (i, j) &gt; M c (i − ri, j − rj), 0, otherwise.</formula><p>Here, −r ≤ r i ≤ r, −r ≤ r j ≤ r where r is the radius for the local maxima computation. We set r = 1, as in <ref type="bibr" target="#b32">[33]</ref>. The local maxima are searched at all spatial locations with a stride of one. To train an image classifier, a class confidence score s c of the c th object category is computed as the average of non-zero elements ofM c . In this work, we use the multi-label soft-margin loss <ref type="bibr" target="#b12">[13]</ref> for binary classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Density Branch</head><p>The image classification branch described above predicts the presence or absence of objects by using the class confidence scores derived from the peak mapM c . However, it struggles to differentiate between multiple objects and single object parts due to the lack of prior information about the number of object instances (see <ref type="figure">Fig. 2(b)</ref>). This causes a large number of false positives in the peak map M c . Here, we utilize the count information and introduce a pseudo ground-truth generation scheme that prevents training a density map at those false positive locations.</p><p>When constructing a density map, it is desired to estimate accurate object counts at any image sub-region. Our spatial loss term L spatial in Eq. 1 ensures that individual object instances are localized while the global term L global constrains the global object count to that of the groundtruth. This enables preservation of the spatial distribution of object counts in a density map. Later, we show that this property helps to improve instance segmentation. Spatial Loss: The spatial loss L spatial is divided into the loss L sp+ which enhances the positive peaks corresponding to instances of object categories within S, and the loss L sp− which suppresses false positives of categories within A. Due to the unavailability of absolute object count, the setS is not used in the spatial loss and treated separately later. To enable ILC supervised density map training using L spatial , we generate a pseudo ground-truth binary mask from peak mapM c . Pseudo Ground-truth Generation: To compute the spatial loss L sp+ , a pseudo ground-truth is generated for set S. For all object categories c ∈ S, the t c -th highest peak value of peak mapM c is computed using the heap-max algorithm <ref type="bibr" target="#b4">[5]</ref>. The t c -th highest peak value h c is then used to generate a pseudo ground-truth binary mask B c as,</p><formula xml:id="formula_3">B c = u(M c − h c ).<label>(2)</label></formula><p>Here, u(n) is the unit step function which is 1 only if n ≥ 0.</p><p>Although the non-zero elements of the pseudo ground-truth mask B c indicate object locations, its zero elements do not necessarily point towards the background. Therefore, we construct a masked density mapD </p><formula xml:id="formula_4">D c = D c B c .<label>(3)</label></formula><p>The spatial loss L sp+ for object categories within the subitizing range S is computed between B c andD c using a logistic binary cross entropy (logistic BCE) <ref type="bibr" target="#b23">[24]</ref> loss for positive ground-truth labels. The logistic BCE loss transfers the network prediction (D c ) through a sigmoid activation layer σ and computes the standard BCE loss as,</p><formula xml:id="formula_5">L sp+ (D c , B c ) = − ∀c∈S B c log(σ(D c )) sum |S| · B c sum .<label>(4)</label></formula><p>Here, |S| is the cardinality of the set S and the norm sum is computed by taking the summation over all elements in a matrix. For example, B c sum = 1 h B c 1 w , where 1 h and 1 w are all-ones vectors of size 1 × H and W × 1, respectively. Here, the highest t c peaks inM c are assumed to fall on t c instances of object category c ∈ S. Due to the unavailability of ground-truth object locations, we use this assumption and observe that it holds in most scenarios.</p><p>The spatial loss L sp+ for the positive ground-truth labels enhances positive peaks corresponding to instances of object categories within S. However, the false positives of the density map for c ∈ S are not penalized in this loss. We therefore introduce another term, L sp− , into the loss function to address the false positives of c ∈ A. For c ∈ A, positive activations of D c indicate false detections. A zerovalued mask 0 H×W is used as ground-truth to reduce such false detections using logistic BCE loss,</p><formula xml:id="formula_6">L sp− (D c , 0 H×W ) = − c∈A log(1 − σ(D c ) sum |A| · H · W .<label>(5)</label></formula><p>Though the spatial loss ensures the preservation of spatial distribution of objects, only relying on local information may result in deviations in the global object count. Global Loss: The global loss penalizes the deviation of the predicted countt c from the ground-truth. It has two components: ranking loss L rank for object categories beyond the subitizing range (i.e., ∀c ∈S) and mean-squared error (MSE) loss L M SE for the rest of the categories. L M SE penalizes the predicted density map, if the global count prediction does not match with the ground-truth count. i.e.,</p><formula xml:id="formula_7">L M SE (t c , t c ) = c∈{A,S} (t c − t c ) 2 |A| + |S| .<label>(6)</label></formula><p>Here, the predicted countt c is the accumulation of the density map for a category c over its entire spatial region. i.e. t c = D c sum . Note that object categories inS were not previously considered in the computation of spatial loss L spatial and mean-squared error loss L M SE . Here, we introduce a ranking loss <ref type="bibr" target="#b27">[28]</ref> with a zero margin that penalizes under-counting for object categories withinS,</p><formula xml:id="formula_8">L rank (t c ,t) = c∈S max(0,t −t c )</formula><p>|S| .</p><p>The ranking loss penalizes the density branch if the predicted object countt c is less thant for c ∈S. Recall, the beyond subitizing rangeS starts fromt = 5.</p><p>Within the subitizing range S, the spatial loss term L spatial is optimized to locate object instances while the global MSE loss (L M SE ) is optimized for accurately predicting the corresponding global count. Due to the joint optimization of both these terms within the subitizing range, the network learns to correlate between the located objects and the global count. Further, the network is able to locate object instances, generalizing beyond the subitizing rangẽ S (see <ref type="figure">Fig. 2</ref>). Additionally, the ranking loss L rank term in the proposed loss function ensures the penalization of under counting beyond the subitizing rangeS. Mini-batch Loss:Normalized loss termsL sp+ ,L sp− , L M SE andL rank are computed by averaging respective loss terms over all images in the mini-batch. The L spatial is computed byL sp+ +L sp− . For categories beyond the subitizing range,L rank can lead to over-estimation of the count. Hence, L global is computed by assigning a relatively lower weight (λ = 0.1) toL rank (see <ref type="table">Table.</ref> 2). i.e., L global =L M SE + λ * L rank .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Training and Inference</head><p>Our network is trained in two stages. In the first stage, the density branch is trained with only L M SE and L rank losses using S andS respectively. The spatial loss L spatial in Eq. 1 is excluded in the first stage, since it requires a pseudo ground-truth generated from the image classification branch. The second stage includes the spatial loss. Backpropagation: We use B c derived from the image classification branch as a pseudo ground-truth to train the density branch. Therefore, the backproapation of gradients through B c to the classifier branch is not required (shown with green arrows in <ref type="figure">Fig. 3</ref>). The image classification branch is backpropagated as in <ref type="bibr" target="#b32">[33]</ref>. In the density branch, we use Hadamard product of the density map with B c in Eq. 3 to compute L sp+ for c ∈ S. Hence, the gradients (δ c ) for the c th channel of the last convolution layer of the density branch, due to L sp+ , are computed as,</p><formula xml:id="formula_10">δ c sp+ = ∂L sp+ ∂D c B c .<label>(8)</label></formula><p>Since L M SE , L rank and L sp− are computed using MSE, ranking and logistic BCE losses on convolution outputs, their respective gradients are computed using off-the-shelf pytorch implementation <ref type="bibr" target="#b23">[24]</ref>. Inference: The image classification branch outputs a class confidence score s c for each class, indicating the presence (t c &gt; 0, if s c &gt; 0) or absence (t c = 0, if s c ≤ 0 ) of the object category c. The predicted countt c is obtained by summing the density map D c for category c over its entire spatial region. The proposed approach only utilizes subitizing annotations (t c ≤ 4) and accurately predicts object counts for both within and beyond subitizing range (see <ref type="figure">Fig. 6</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Image-level Supervised Instance Segmentation</head><p>The proposed ILC supervised density map estimation approach can also be utilized for instance segmentation. Note that the local summation of an ideal density map over a ground-truth segmentation mask is one. We use this property to improve state-of-the-art image-level supervised instance segmentation (PRM) <ref type="bibr" target="#b32">[33]</ref>. PRM employs a scoring metric that combines instance level cues from peak response maps R, class aware information from object category maps and spatial continuity priors from off-the-shelf object proposals <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b24">25]</ref>. Here, the peak response maps are generated from local maxima (peaks ofM c ) through a peak backpropagation process <ref type="bibr" target="#b32">[33]</ref>. The scoring metric is then used to rank object proposals corresponding to each peak for instance mask prediction. We improve the scoring metric by introducing an additional term d p in the metric. The term d p penalizes an object proposal P r , if the predicted count in those regions of the density map D c is different from one, as d p = |1 − D c · P r sum |. Here, | | is the absolute value operator. For each peak, the new scoring metric Score selects the highest scoring object proposal P r .</p><formula xml:id="formula_11">Score = α · R * P r + R * P r − β · Q * P r − γ · d p . (9)</formula><p>Here, the background mask Q is derived from object category map andP r is the contour mask of the proposal P r derived using morphological gradient <ref type="bibr" target="#b32">[33]</ref>. Parameters α, β and γ are empirically set as in <ref type="bibr" target="#b32">[33]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>Implementation details: Throughout our experiments, we fix the training parameters. An initial learning rate of 10 −4 is used for the pre-trained ResNet-50 backbone, while image classification and density branches are trained with an initial learning rate of 0.01. The number of input channels P of 1×1 convolution for each branch is set to P = 1.5×C. A mini-batch size of 16 is used for the SGD optimizer. The momentum is set to 0.9 and weight decay to 10 −4 . Considering high imbalance between non-zero and zero counts in COCO dataset (e.g. 79 negative categories for each positive category), only 10% of samples in the set A are used to train the density branch. Code will be made public upon publication. Datasets: We evaluate common object counting on the PASCAL VOC 2007 <ref type="bibr" target="#b6">[7]</ref> and COCO <ref type="bibr" target="#b16">[17]</ref> datasets. For fair comparison, we employ same splits, named as counttrain, count-val and count-test, as used in the state-of-theart methods <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b3">[4]</ref>. For COCO dataset, the training set is used as count-train, first half of the validation set as the count-val and its second half as the count-test. In Pascal VOC 2007 dataset, we evaluated against the count of nondifficult instances in the count-test as in <ref type="bibr" target="#b13">[14]</ref>. For instance  segmentation, we train and report the results on the PAS-CAL VOC 2012 dataset similar to <ref type="bibr" target="#b32">[33]</ref>. Evaluation Criteria: The predicted countt c is rounded to the nearest integer. We evaluate common object counting, as in <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b13">14]</ref>, using root squared error (RMSE) metric and its three variants namely RMSE non-zero (RMSEnz), relative RMSE (relRMSE) and relative RMSE nonzero (relRMSE-nz). The RM SE c and relRM SE c errors for category c are computed as</p><formula xml:id="formula_12">1 T T i=1 (t ic −t ic ) 2 and, 1 T T i=1 (tic−t ic) 2 tic+1</formula><p>respectively. Here, T is the total number of images in the test set andt ic , t ic are the predicted and ground-truth counts for image i. The errors are then averaged across all categories to obtain the mRMSE and m-relRMSE on a dataset. The above metrics are also evaluated for ground-truth instances with non-zero counts as mRMSE-nz and m-relRMSE-nz. For all error metrics, smaller numbers indicate better performance. We refer to <ref type="bibr" target="#b3">[4]</ref> for more details. For instance segmentation, the performance is evaluated using Average Best Overlap (ABO) <ref type="bibr" target="#b25">[26]</ref> and mAP r , as in <ref type="bibr" target="#b32">[33]</ref>. The mAP r is computed with intersection over union (IoU) thresholds of 0.25, 0.5 and 0.75.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supervision Levels:</head><p>The level of supervision is indicated as SV in Tab. 3 and 4. BB indicates bounding box supervision and PL indicates point-level supervision for each object instance. Image-level supervised methods using only within subitizing range counts are denoted as ILC, while the methods using both within and beyond subitizing range counts are indicated as IC.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Common Object Counting Results</head><p>Ablation Study: We perform an ablation study on the PASCAL VOC 2007 count-test. First, the impact of our two-branch architecture is analyzed by comparing it with two baselines: class-activation <ref type="bibr" target="#b31">[32]</ref> based regression (CAM+regression) and peak-based regression (Peak+regression) using the local-maximum boosting approach of <ref type="bibr" target="#b32">[33]</ref>. Both baselines are obtained by end-to-end training of the network, employing the same backbone, using MSE loss function to directly predict global count. Tab. 1 shows the comparison. Our approach largely outperforms both baseline highlighting the importance of having a twobranch architecture with explicit terms in the loss function to preserve the spatial distribution of objects. Next, we evaluate the contribution of each term in our loss function towards the final count performance. <ref type="figure" target="#fig_2">Fig. 4</ref> shows the systematic improvement in density maps (top row: person and bottom row: bicycle) quality with the incremental addition of (c) spatial L spatial and (d) ranking (L rank ) loss terms to the (b) MSE (L rank ) loss term. Similar to CAM, the density branch trained with MSE loss alone gives coarse location of object instances. However, many background pixels are identified as part of the object (false positives) resulting in inaccurate spatial distribution of object instances. Further, this inclusion of false positives prevents the delineation of multiple object instances. Incorporating the spatial loss term improves the spatial distribution of objects in both density maps. The density maps are further improved by the incorporation of the ranking term that penalizes the under-estimation of count beyond the subitizing range (top row) in the loss function. Moreover, it also helps to reduce the false positives within the subitizing range (bottom row). Tab. 2 shows the systematic improvement, in terms of mRMSE and mRMSE-nz, when integrating different terms in our loss function. The best results are obtained when integrating all three terms (classification, spatial and global) in our loss function. We also evaluate the influence of λ that controls the relative weight of the ranking loss. We observe λ = 0.1 provides the best results and fix it for all datasets.    <ref type="figure">Figure 5</ref>. Object counting examples on the COCO dataset. The ground-truth, point-level supervised counts <ref type="bibr" target="#b13">[14]</ref> and our predictions are shown in black, red and green respectively. Our approach accurately performs counting beyond the subitizing range and on diverse categories (fruits to animals) under heavy occlusions (highlighted by a red arrow in the left image).</p><p>supervision both within and beyond the subitizing range (IC) achieves mRMSE score of 0.50. Our ILC supervised approach considerably outperforms the glance-noft-2L method with a absolute gain of 21% in mRMSE. Furthermore, our approach achieves consistent improvements on all error metrics, compared to state-of-the-art point-level and bounding box based supervised methods. Tab. 4 shows the results on COCO dataset. Among the existing methods, the two BB supervised approaches (Seq-sub-ft-3x3 and ens) yields mRMSE scores of 0.35 and 0.36 respectively. The PL supervised LC-ResFCN approach <ref type="bibr" target="#b13">[14]</ref> achieves mRMSE score of 0.38. The IC supervised glancing approach (glance-noft-2L) obtains mRMSE score of 0.42. Our approach outperforms the glancing approach with an absolute gain of 8% in mRMSE. Furthermore, our approach also provides consistent improvements over the glancing approach in the other three error metrics and is only below the two BB supervised methods (Seqsub-ft3x3 and ens) in m-relRMSE-nz. <ref type="figure">Fig. 5</ref> shows object counting examples using our approach and the point-level Beyond Subitizing Range <ref type="figure">Figure 6</ref>. Counting performance comparison in RMSE, across all categories, at different ground-truth count values on the COCO count-test set. Different methods, including BB and PL supervision, are shown in the legend. Our ILC supervised approach provides superior results compared to the image-level supervised glancing method. Furthermore, our approach performs favourably compared to other methods using instance-level supervision.</p><p>(PL) supervised method <ref type="bibr" target="#b13">[14]</ref>. Our approach performs accurate counting on various categories (fruits to animals) under heavy occlusions. <ref type="figure">Fig. 6</ref> shows counting performance comparison in terms of RMSE, across all categories, on COCO count-test. The x-axis shows different ground-truth count values. We compare with the different IC, BB and PL supervised methods <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b13">14]</ref>. Our approach achieves superior results on all count values compared to glancing method <ref type="bibr" target="#b3">[4]</ref> despite not using the beyond subitizing range annotations during training. Furthermore, we perform favourably compared to other methods using higher supervision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation of density map:</head><p>We employ a standard grid average mean absolute error (GAME) evaluation metric <ref type="bibr" target="#b9">[10]</ref> used in crowd counting to evaluate spatial distribution consistency in the density map. In GAME(n), an image is divided into 4 n non-overlapping grid cells. Mean absolute error (MAE) between the predicted and the ground-truth local counts are reported for n = 0, 1, 2 and 3, as in <ref type="bibr" target="#b9">[10]</ref>. We compare our approach with the state-of-the-art PL supervised counting approach (LCFCN) <ref type="bibr" target="#b13">[14]</ref> on the 20 categories of the PASCAL VOC 2007 count-test set. Furthermore, we also compare with recent crowd counting approach (CSRnet) <ref type="bibr" target="#b15">[16]</ref> on the person category of the PASCAL VOC 2007 by retraining it on the dataset. For the person category, the PL supervised LCFCN and CSRnet approaches achieve scores of 2.80 and 2.44 in GAME(3).The proposed method outperforms LCFCN and CSRnet in GAME (3) with score of 1.83, demonstrating the capabilities of our approach in the precise spatial distribution of object counts. Moreover, our method outperforms LCFCN for all 20 categories. Instance segmentation examples obtained using PRM <ref type="bibr" target="#b32">[33]</ref> and our approach. The proposed approach accurately delineates spatially adjacent multiple object instances of horse and cow categories.  <ref type="table">Table 5</ref>. Image-level supervised instance segmentation results on the PASCAL VOC 2012 val. set in terms of mean average precision (mAP%) and Average Best Overlap(ABO). Our approach ourperforms the state-of-the-art PRM <ref type="bibr" target="#b32">[33]</ref> with a relative gain of 17.8% in terms of ABO.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Image-level supervised Instance segmentation</head><p>Finally, we evaluate the effectiveness of our density map to improve the state-of-the-art image-level supervised instance segmentation approach (PRM) <ref type="bibr" target="#b32">[33]</ref> on the PASCAL VOC 2012 dataset (see Sec. 3.3). In addition to PRM, the image-level supervised object detection methods MELM <ref type="bibr" target="#b26">[27]</ref>, CAM <ref type="bibr" target="#b31">[32]</ref> and SPN <ref type="bibr" target="#b33">[34]</ref> used with MCG mask and reported by <ref type="bibr" target="#b32">[33]</ref> are also included in Tab. 5.</p><p>The proposed method largely outperforms all the baseline approaches and <ref type="bibr" target="#b32">[33]</ref>, in all four evaluation metrics. Even though our approach marginally increases the level of supervision (lower-count information), it improves the state-of-the-art PRM with a relative gain of 17.8% in terms of average best overlap (ABO). Compared to PRM, the gain obtained at lower IoU threshold (0.25) highlights the improved location prediction capabilities of the proposed method. Furthermore, the gain obtained at higher IoU threshold (0.75), indicates the effectiveness of the proposed scoring function in assigning higher scores to the object proposal that has highest overlap with the ground-truth object, as indicated by the improved ABO performance. <ref type="figure">Fig. 7</ref> shows qualitative instance segmentation comparison between our approach and PRM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We proposed an ILC supervised density map estimation approach for common object counting in natural scenes. Different to existing methods, our approach provides both the global object count and the spatial distribution of object instances with the help of a novel loss function. We further demonstrated the applicability of the proposed density map in instance segmentation. Our approach outperforms existing methods for both common object counting and imagelevel supervised instance segmentation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure 2. Instance segmentation examples using the PRM method [33] (b) and our approach (c), on the PASCAL VOC 2012. Top row: The PRM approach [33] fails to delineate spatially adjacent two sheep category instances. Bottom row: single person parts predicted as multiple persons along with inaccurate mask separation results in over-prediction (7 instead of 5). Our approach produces accurate masks by exploiting the spatial distribution of object count in per-category density maps (d). Density map accumulation for each predicted mask is shown inside the contour drawn for clarity. In the top row, density maps for sheep and dog categories are overlaid.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>c</head><label></label><figDesc>to exclude density map D c values at locations where the corresponding B c values are zero. Those density map D c values should also be excluded during the loss computation in Eq. 4 and backpropagation (see Sec. 3.2), due to their risk of introducing false negatives. This is achieved by computing the Hadamard product between the density map D c and B c as,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Progressive improvement in density map quality with the incremental introduction of spatial and ranking loss terms. In both cases (top row: person and bottom row: bicycle), our overall loss function integrating all three terms provides the best density maps. The global object count is accurately predicted (top row: 5 persons and bottom row: 4 bicycles) by accumulation of the respective density map.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Figure 7. Instance segmentation examples obtained using PRM [33] and our approach. The proposed approach accurately delineates spatially adjacent multiple object instances of horse and cow categories.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Counting performance on the Pascal VOC 2007 counttest set using our approach and two baselines. Both baselines are obtained by training the network using the MSE loss function.</figDesc><table><row><cell>Approach</cell><cell cols="5">SV mRMSE mRMSE-nz m-relRMSE m-relRMSE-nz</cell></row><row><cell>CAM+regression</cell><cell>IC</cell><cell>0.45</cell><cell>1.52</cell><cell>0.29</cell><cell>0.64</cell></row><row><cell>Peak+regression</cell><cell>IC</cell><cell>0.64</cell><cell>2.51</cell><cell>0.30</cell><cell>1.06</cell></row><row><cell>Proposed</cell><cell>ILC</cell><cell>0.29</cell><cell>1.14</cell><cell>0.17</cell><cell>0.61</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 .</head><label>2</label><figDesc>Left: Progressive integration of different terms in loss function and its impact on the final counting performance on the PASCAL VOC count-test set. Right: influence of the weight (λ) of ranking loss.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 .</head><label>3</label><figDesc>State-of-the-art counting performance comparison on the Pascal VOC 2007 count-test. Our ILC supervised approach outperforms existing methods.</figDesc><table><row><cell>Approach</cell><cell cols="5">SV mRMSE mRMSE-nz m-relRMSE m-relRMSE-nz</cell></row><row><cell>Aso-sub-ft-3×3 [4]</cell><cell>BB</cell><cell>0.38</cell><cell>2.08</cell><cell>0.24</cell><cell>0.87</cell></row><row><cell>Seq-sub-ft-3×3 [4]</cell><cell>BB</cell><cell>0.35</cell><cell>1.96</cell><cell>0.18</cell><cell>0.82</cell></row><row><cell>ens [4]</cell><cell>BB</cell><cell>0.36</cell><cell>1.98</cell><cell>0.18</cell><cell>0.81</cell></row><row><cell>Fast-RCNN [4]</cell><cell>BB</cell><cell>0.49</cell><cell>2.78</cell><cell>0.20</cell><cell>1.13</cell></row><row><cell>LC-ResFCN [14]</cell><cell>PL</cell><cell>0.38</cell><cell>2.20</cell><cell>0.19</cell><cell>0.99</cell></row><row><cell>glance-ft-2L [4]</cell><cell>IC</cell><cell>0.42</cell><cell>2.25</cell><cell>0.23</cell><cell>0.91</cell></row><row><cell>Proposed</cell><cell>ILC</cell><cell>0.34</cell><cell>1.89</cell><cell>0.18</cell><cell>0.84</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 .</head><label>4</label><figDesc></figDesc><table><row><cell cols="4">State-of-the-art counting performance comparison on the</cell></row><row><cell cols="4">COCO count-test set. Despite using reduced supervision, our ap-</cell></row><row><cell cols="4">proach provides superior results compared to existing methods on</cell></row><row><cell cols="4">three metrics. Compared to the image-level count (IC) supervised</cell></row><row><cell cols="4">approach [4], our method achieves an absolute gain of 8% in terms</cell></row><row><cell>of mRMSE.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>orange: 2, 8 (8)</cell><cell>broccoli: 1, 5 (5) person: 4, 1 (1) carrot: 2, 5 (5) bowl: 0, 1 (1)</cell><cell>zebra: 15, 12 (12)</cell><cell>tv: 1, 1 (1) remote: 2, 1 (1) person: 5, 6 (6)</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Whats the point: Semantic segmentation with point supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bearman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ferrari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">The development of numerical competence: Animal and human models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Boysen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Capaldi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Psychology Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Scale aggregation network for accurate and efficient crowd counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Counting everyday objects in everyday scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chattopadhyay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vedantam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Selvaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Chhavi. k largest(or smallest) elements in an array -added min heap method</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Clements</surname></persName>
		</author>
		<title level="m">Subitizing: What is it? why teach it? Teaching children mathematics</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The pascal visual object classes challenge: A retrospective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Eslami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">C-wsl: Count-guided weakly supervised localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">I</forename><surname>Morariu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ECCV</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fast r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Extremely overlapping vehicle counting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Guerrero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Torre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maldonado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Onoro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IbPRIA</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The role of pattern recognition in children&apos;s exact enumeration of small numbers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Hofman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Straatemeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Van Bers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Raijmakers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">L</forename><surname>Van Der Maas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British Journal of Developmental Psychology</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Analysis and optimization of loss functions for multiclass, top-k, and multilabel classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lapin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<idno>2018. 4</idno>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Where are the blobs: Counting by localization with point supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">H</forename><surname>Laradji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rostamzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">O</forename><surname>Pinheiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vazquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schmidt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ECCV</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning to count objects in images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Csrnet: Dilated convolutional neural networks for understanding the highly congested scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<editor>ECCV. Springer</editor>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Leveraging unlabeled data for crowd counting by learning to rank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Van De Weijer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Bagdanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Subitizing: an analysis of its component processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Mandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Shebo</surname></persName>
		</author>
		<idno>1982. 2</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Convolutional oriented boundaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-K</forename><surname>Maninis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pont-Tuset</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Arbeláez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Fully convolutional crowd counting on highly congested scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kevin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Suzanne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Noele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Is object localization for free?-weakly-supervised learning with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Oquab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Automatic differentiation in pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>De-Vito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Multiscale combinatorial grouping for image segmentation and object proposal generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pont-Tuset</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Arbelaez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Marques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Boosting object proposals: From pascal to coco</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pont-Tuset</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Min-entropy latent model for weakly supervised object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In CVPR</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning fine-grained image similarity with deep ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Philbin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Optimizing connected component labeling algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Otoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shoshani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Imaging 2005: Image Processing</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">5747</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Salient object subitizing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sameki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sclaroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Betke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mech</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Singleimage crowd counting via multi-column convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Learning deep features for discriminative localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Weakly supervised instance segmentation using class peak response</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Soft proposal networks for weakly supervised object localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
