<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Structured Domain Adaptation with Online Relation Regularization for Unsupervised Person Re-ID</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixiao</forename><surname>Ge</surname></persName>
							<email>yxge@link</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Multimedia Laboratory (MMLAB)</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Zhu</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Multimedia Laboratory (MMLAB)</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Multimedia Laboratory (MMLAB)</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
							<email>hsli@ee.cuhk.edu.hk</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Multimedia Laboratory (MMLAB)</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Structured Domain Adaptation with Online Relation Regularization for Unsupervised Person Re-ID</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Unsupervised domain adaptation (UDA) aims at adapting the model trained on a labeled source-domain dataset to an unlabeled target-domain dataset. The task of UDA on open-set person re-identification (re-ID) is even more challenging as the identities (classes) do not overlap between the two domains. One major research direction was based on domain translation <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b2">3]</ref>, which, however, has fallen out of favor in recent years due to inferior performance compared to pseudo-labelbased methods <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b11">12]</ref>. We argue that translation-based methods have great potential on exploiting the valuable source-domain data but they did not provide proper regularization on the translation process. Specifically, these methods only focus on maintaining the identities of the translated images while ignoring the inter-sample relation during translation. To tackle the challenge, we propose an endto-end structured domain adaptation framework with an online relation-consistency regularization term. During training, the person feature encoder is optimized to model inter-sample relations on-the-fly for supervising relation-consistency domain translation, which in turn, improves the encoder with informative translated images. An improved pseudo-label-based encoder can therefore be obtained by jointly training the source-to-target translated images with ground-truth identities and target-domain images with pseudo identities. In the experiments, our proposed framework is shown to outperform state-of-the-art methods on multiple UDA tasks of person re-ID. Code is available at https://github.com/yxgeee/SDA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Person re-identification (re-ID) aims at identifying images of the same person across multiple cameras. Despite great advances of deep learning-based re-ID methods, large domain gaps still pose great challenges on generalizing the trained models from a labeled source domain to an unlabeled target domain. There are two main research directions towards solving the problem of domain adaptive person re-ID, i.e., domain translation-based methods <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b2">3]</ref> and pseudo-label-based methods <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b11">12]</ref>, where the latter ones dominate the current literature with state-of-the-art performance.</p><p>Although domain translation-based methods have fallen out of favor in recent years due to their uncompetitive performance, we argue that they have great potential to make use of valuable sourcedomain data with accurate identities. Translating source-domain images to the target domain to create new training samples with identity labels is at the core of domain translation-based methods. Previous works used identity-based regularization (e.g., classification loss <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b2">3]</ref> or contrastive loss [8]) to preserve the ID-related appearance during translation. However, we observe that their domaintranslated images cannot well maintain inter-sample relations even with such ID-based constraints <ref type="figure">(Figure 1(a)</ref>). We argue that such relation consistency is critical for generating informative training samples as they better capture distributions of source-domain data.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>(a) Existing domain translation-based UDA methods <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b2">3]</ref>.</p><p>(b) Our proposed structured domain translation.  <ref type="bibr" target="#b44">[45]</ref>, SPGAN <ref type="bibr" target="#b35">[36]</ref> and our structured domain-translation method. To tackle this challenge, we propose an end-to-end structured domain adaptation (SDA) framework with a novel online relation-consistency regularization term. It consists of a structured domaintranslation network, a source-domain person image encoder and a pseudo-label-based target-domain encoder. The two domain encoders are coupledly trained to model inter-sample relations on-the-fly for regularizing domain translation, which in turn, boosts the target-domain encoder and its generated pseudo labels with informative source-to-target translated images. The structured domain-translation network adopts the CycleGAN <ref type="bibr" target="#b44">[45]</ref> architecture for translating source-and target-domain images. A novel relation-consistency loss is proposed to regularize the training of source-to-target domain translation for maintaining the original inter-sample relations, which are generated by the sourcedomain encoder on-the-fly ( <ref type="figure" target="#fig_0">Figure 1(b)</ref>). Our relation-consistency loss is different from conventional ID-based constraints in <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b2">3]</ref>, which only apply constant regularization that requires translated images of different classes to be well separated after translation.</p><p>The source-domain encoder is trained with source-domain images and ground-truth identifies. An improved target-domain encoder is trained with both the source-to-target translated images and targetdomain images via a joint cross-domain label system, which is constructed with their associated ground-truth and pseudo labels. In this way, both the target-domain encoder and its generated pseudo labels can be improved with the optimization of the structured domain-translation network.</p><p>The contributions of this paper could be summarized as three-fold. <ref type="bibr" target="#b0">(1)</ref> To properly exploit the valuable source-domain data in domain translation-based UDA methods, we propose a novel online relation-consistency regularization term to better supervise the translation process. <ref type="bibr">(</ref>2) The domaintranslated images can serve as informative training samples to improve the target-domain encoder and help generate more accurate pseudo labels. The domain translation network and target-domain encoder alternately promote each other to achieve optimal re-ID performance. (3) Our framework achieves state-of-the-art performance on multiple domain adaptive person re-ID benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Domain translation-based UDA methods for person re-ID. Domain translation-based methods <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b2">3]</ref> aimed at fine-tuning the target-domain re-ID model with source-to-target translated images and their ground-truth identities. In order to preserve the original identities of the translated images, ID-based regularizations were adopted on either pixel level <ref type="bibr" target="#b35">[36]</ref> or feature level <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b2">3]</ref> via the contrastive loss <ref type="bibr" target="#b7">[8]</ref> or classification loss <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b2">3]</ref>. However, we found that they are too weak to properly maintain the original inter-sample relations and distributions of source-domain data during translation, which are critical for generating informative training samples.</p><p>Pseudo-label-based UDA methods for person re-ID. Pseudo-label-based methods <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b43">44]</ref> achieved state-of-the-art performances by modeling relations between unlabeled targetdomain data with generated pseudo labels, where a clustering-based pipeline was found effective. PUL <ref type="bibr" target="#b10">[11]</ref> first proposed a self-training scheme with clustering labels. SSG <ref type="bibr" target="#b36">[37]</ref>, PAST <ref type="bibr" target="#b38">[39]</ref> and MMT <ref type="bibr" target="#b11">[12]</ref> further extended this type of methods by introducing human part features, progressive training strategy and mutual learning. These methods generally focused on using only the target-domain data, <ref type="figure">Figure 2</ref>. Illustration of our structured domain adaptation (SDA) framework and the novel online relationconsistency regularization term. The domain-translation network and the target-domain encoder alternately promote each other via joint training to achieve optimal re-ID performance. and we found that they could be further improved by properly exploiting the valuable source-domain data with ground-truth identities, where domain translation has great potential.</p><p>Generic UDA methods. Feature-level and pixel-level adaptations were commonly adopted by UDA methods for tackling more general tasks. The feature-level adaptation methods <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b4">5]</ref> aimed at aligning the feature distributions between the source and target domains by learning domaininvariant features with a domain adversarial discriminator <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b33">34]</ref> or reducing the Maximum Mean Discrepancy (MMD) <ref type="bibr" target="#b13">[14]</ref> distance between domains. However, such methods are unable to handle the open-set re-ID problem with disjoint label systems in two domains <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b29">30]</ref>. The other category of pixel-level adaptation methods <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b3">4]</ref> minimized the domain shifts by translating images to the same domain, which has been widely studied in semantic segmentation. However, existing pixel-level adaptation methods still ignored the consistency of inter-sample relations during translation, facing the same challenge as translated-based UDA methods for person re-ID <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b2">3</ref>].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Structured Domain Adaptation for Unsupervised Person Re-ID</head><p>We propose a structured domain adaptation framework with a novel online relation-consistency regularization term to tackle unsupervised domain adaptation (UDA) for person re-ID. The overall framework, as illustrated in <ref type="figure">Figure 2</ref>, consists of a structured domain-translation network and two domain-specific person image encoders, which are jointly optimized and promote each other to learn more discriminative person features. The key innovation of our framework lies in the generation of informative training samples by translating source-domain images into the target domain under the relation-consistency regularization generated by the image encoders on-the-fly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Source-domain Encoder Pre-training</head><p>We pre-train the source-domain person image encoder F s for (1) providing "ground-truth" intersample relations between source-domain images to regularize the proposed structured domain translation, and (2) providing weight initialization for the target-domain person image encoder F t . Once trained, F s is frozen to provide stable regularizations for inter-sample relations.</p><p>Given source-domain samples X s , the encoder F s is trained to transform each sample x s ∈ X s into a feature vector f s = F s (x s ). If the feature vector f s is properly embedded, it could be used to correctly predict its ground-truth identity y s with a learnable classifier C s : f s → {1, · · · , p s }, where p s is the number of identities in the source domain. A cross-entropy classification loss ce and a triplet loss <ref type="bibr" target="#b16">[17]</ref> are adopted jointly for training,</p><formula xml:id="formula_0">L s enc (F s , C s ) = E x s ∼X s [ ce(C s (f s ), y s )] + E x s ∼X s ( f s − f s p + m − f s − f s n ) + ,<label>(1)</label></formula><p>where (·) + = max(0, ·) with a margin m, and the subscripts p , n denote the mini-batch's hardest positive and negative feature indexes for the anchor f s .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Structured Domain Translation with Online Relation Regularization</head><p>We propose a structured domain-translation (SDT) network to generate informative training samples by translating source-domain images X s to the target domain, which focuses not only on image-style transfer but more on how to maintain their original inter-sample relations. We adopt the widely-used CycleGAN <ref type="bibr" target="#b44">[45]</ref> architecture for our translation network, which is trained to translate images along two directions with corresponding generators G s→t and G t→s .</p><p>Conventional cycle generation losses. The general training objective of a CycleGAN <ref type="bibr" target="#b44">[45]</ref> for image-to-image translation consists of the adversarial losses L s adv , L t adv , the cyclic reconstruction loss L cyc and the appearance consistency loss L apr . We adopt the loss function of LSGAN <ref type="bibr" target="#b25">[26]</ref> with two domain discriminators D s and D t as</p><formula xml:id="formula_1">L s adv (G t→s , D s ) = E x s ∼X s D s (x s ) 2 + E x t ∼X t D s (G t→s (x t )) − 1 2 , L t adv (G s→t , D t ) = E x t ∼X t D t (x t ) 2 + E x s ∼X s D t (G s→t (x s )) − 1 2 .<label>(2)</label></formula><p>The cyclic reconstruction loss supervises the pixel-level generation by translating the images twice,</p><formula xml:id="formula_2">Lcyc(G s→t , G t→s ) =E x s ∼X s G t→s (G s→t (x s )) − x s 1 + E x t ∼X t G s→t (G t→s (x t )) − x t 1 . (3)</formula><p>The appearance consistency loss <ref type="bibr" target="#b32">[33]</ref> maintains the general color composition after translation,</p><formula xml:id="formula_3">Lapr(G s→t , G t→s ) =E x s ∼X s G t→s (x s ) − x s 1 + E x t ∼X t G s→t (x t ) − x t 1 .<label>(4)</label></formula><p>Despite the fact that the above loss terms guide the source-domain images to have target-domain image style, the generated images generally fail to maintain their original inter-sample relations and are therefore not accurate enough to optimize the target-domain image encoder.</p><p>Online relation-consistency loss. The appearance consistency loss L apr alone is not enough to maintain accurate inter-sample relations during translation, we propose to use the pre-trained F s to provide relation supervision on-the-fly for regularizing the translation. Intuitively, inter-sample relations can be modeled by the ratio of feature similarities between pairs of images. In person re-ID, triplets with intra-/inter-identity samples are generally most representative and can be used for modeling better inter-sample relations.</p><p>Given a source-domain image x s , its positive sample x s p with the same identity, and its negative sample x s n with a different identity, we can measure their similarity-based inter-sample relations on-the-fly among the triplet with a softmax-like function,</p><formula xml:id="formula_4">R(x s ; F s ) = exp f s , f s p exp f s , f s p + exp f s , f s n ∈ [0, 1],<label>(5)</label></formula><p>where f s , f s p , f s n are the features encoded by the pre-trained source-domain encoder F s on the image samples x s , x s p , x s n , respectively, and ·, · is the inner product between two feature vectors to measure their similarity. Similar to <ref type="bibr" target="#b16">[17]</ref>, we utilize only the most difficult triplet of each sample x s within a batch, i.e., the hardest positive (f s p ) and negative (f s n ) samples for each f s . Note that R(x s ; F s ) is a continuous value in [0, 1] to measure the ratio of pairwise similarities.</p><p>After translating source-domain images to the target domain by G s→t , we obtain the features of the source-to-target translated triplet (f s→t , f s→t p , f s→t n ), which are encoded by the target-domain encoder F t (to be discussed in Section 3.3). Similarly, the continuous similarity ratio in [0, 1] between the translated images can also be measured by a softmax-like function as</p><formula xml:id="formula_5">R(x s ; G s→t , F t ) = exp f s→t , f s→t p exp f s→t , f s→t p + exp f s→t , f s→t n ∈ [0, 1].<label>(6)</label></formula><p>We claim that, if the domain-translation network well preserves the source-domain images' intersample relations, their softmax-triplet responses in [0, 1] should be similar. Based on this assumption, a novel relation-consistency loss is introduced to regularize the inter-sample relations after the translation s → t by a "soft" binary cross-entropy loss as</p><formula xml:id="formula_6">Lrc(G s→t ) = E x s ∼X s bce R(x s ; G s→t , F t ), R(x s ; F s ) ,<label>(7)</label></formula><p>where bce (p, q) = −q log p − (1 − q) log (1 − p) with the soft label q. We use the source-domain inter-sample relations R(x s ; F s ) as soft learning targets for supervising the translated inter-sample relations R(x s ; G s→t , F t ).</p><p>Differences with existing ID-based regularizations. There are two key differences between the proposed relation-consistency loss and existing ID-based regularizations, e.g., classification loss <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b2">3]</ref>, contrastive loss <ref type="bibr" target="#b7">[8]</ref> or triplet loss. (1) Existing ID-based regularizations only require the samples from different classes to be well separated after translation, which is too weak to maintain inter-sample relations. As long as the samples are classified correctly, even if they did not maintain inter-sample relations well, they receive little penalty. In contrast, our proposed regularization tries to maintain continuous and more sensitive relation measurements (Eq. <ref type="formula" target="#formula_4">(5)</ref>) during domain translation.</p><p>(2) Existing regularizations utilize static learning targets (identity labels), while our proposed term generates relation measurements with image encoders on-the-fly to provide adaptive supervisions. In other words, previous ones only acquire knowledge from ground-truth labels, while ours exploits abundant knowledge from both ground-truth labels and the pre-trained source-domain encoder.</p><p>There exist some works <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b40">41]</ref> which leveraged generative models on fully-supervised person re-ID tasks. They focused on preserving person identities with existing ID-based regularizations, which are too weak to maintain inter-sample relations as discussed above.</p><p>Joint training objective. During training, we fix F s and alternately update F t and SDT in each iteration to avoid bias amplification, where the SDT network is optimized with</p><formula xml:id="formula_7">Lsdt(G s→t , G t→s , D s , D t ) =λrcLrc(G s→t ) + λcycLcyc(G s→t , G t→s ) + λadv L s adv (G t→s , D s ) + L t adv (G s→t , D t ) + λaprLapr(G s→t , G t→s ). (8)</formula><p>Here λ rc , λ cyc , λ adv and λ apr are the weighting factors for different loss terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Pseudo-label-based Target-domain Encoder with Translated Images</head><p>For training the target-domain encoder F t in our framework, both the labeled source-to-target translated images X s→t and the pseudo-labeled target-domain images X t serve as informative training samples with non-overlapping real or pseudo identity labels. In this way, we can create a unified training image set X = X s→t ∪ X t with a unified label set to supervise a cross-domain identity classifier C t : f → {1, · · · , p s +p t }. Target-domain data X t 's encoded features {f t } are clustered intop t classes and images within the same cluster are assigned the same label. Note that the clustering-based pseudo label creation is a general pipeline in UDA tasks and is not the focus of our method. Any common clustering algorithms can be adopted here, e.g., k-means, DBSCAN <ref type="bibr" target="#b9">[10]</ref>.</p><p>The target-domain encoder F t can then be trained in a fully-supervised manner. Specifically, each sample x ∈ X is assigned a corresponding label y ∈ {1, · · · , p s +p t }, and F t is optimized with the objective function similar to source-domain encoder learning in Eq. <ref type="formula" target="#formula_0">(1)</ref>,</p><formula xml:id="formula_8">L t enc (F t , C t ) = E x∼X ce(C t (f ), y) + E x∼X ( f − fp + m − f − fn ) + .<label>(9)</label></formula><p>The target-domain encoder F t can therefore take full advantages of (1) the source-to-target images translated by our G s→t , which better maintain their inter-sample relations, and (2) the unified targetdomain label set that consists of both the valuable ground-truth source-domain identity labels and the target-domain pseudo labels. F t trained by this strategy is shown to embed more discriminative features for distinguishing target-domain identities.</p><p>In our overall framework, the source-domain encoder F s is fixed after pre-training, and the structured domain-translation (SDT) network and the target-domain encoder F t alternately promote each other via joint training to achieve optimal re-ID performance. When fixing F t , it measures translated inter-sample relations for regularizing SDT via L rc . When fixing SDT, it generates training samples to optimize F t . Once F t is further trained to achieve better re-ID performance on the target domain, it could in turn generate more accurate pseudo labels and measure more accurate data relations for further improving SDT. After training, only F t is used to encode target-domain samples into features for ranking without extra costs and parameters. The overall algorithm is summarized in Alg. 1. <ref type="table">Table 1</ref>. Unsupervised domain adaptation performances by state-of-the-art methods and our proposed SDA on person re-ID datasets, e.g., DukeMTMC-reID <ref type="bibr" target="#b28">[29]</ref>, Market-1501 <ref type="bibr" target="#b39">[40]</ref> and MSMT17 <ref type="bibr" target="#b35">[36]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>We evaluate our framework on three widely used person re-ID datasets, including DukeMTMC-reID <ref type="bibr" target="#b28">[29]</ref>, Market-1501 <ref type="bibr" target="#b39">[40]</ref> and MSMT17 <ref type="bibr" target="#b35">[36]</ref>. DukeMTMC-reID <ref type="bibr" target="#b28">[29]</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Implementation Details</head><p>Network architecture. We adopt ResNet-50 <ref type="bibr" target="#b15">[16]</ref> as the backbone for the source-domain and target-domain person image encoders, which are initialized with ImageNet-pretrained <ref type="bibr" target="#b6">[7]</ref> weights. The target-domain encoder F t and structured domain-translation network are alternately updated in each iteration to avoid unstable training. Furthermore, we adopt a momentum encoder <ref type="bibr" target="#b14">[15]</ref> (denoted as F t * ) to replace F t in Eq. (6) for measuring more stable triplet relations after domain translation. In particular, we denote the parameters of F t and F t * as θ (T ) and θ Training data organization. Each mini-batch contains 56 source-domain images of 8 ground-truth identities (7 for each identity) and 56 target-domain images of 8 pseudo identities. The pseudo identities are assigned by clustering algorithm and updated before each epoch. All images are resized to 256×128. Randomly erasing <ref type="bibr" target="#b41">[42]</ref>, cropping and flipping are applied to each image.</p><p>Network optimization. ADAM optimizer is adopted to optimize the networks with weighting factors λ rc = 1, λ adv = 1, λ cyc = 10, λ apr = 0.5 and the triplet margin m = 0.3. The initial learning rates (lr) are set to 0.00035 for person image encoders and 0.0002 for the structured domaintranslation (SDT) network. The source-domain pre-training iterates for 30 epochs and the learning rate decreases to 1/10 of its previous value every 10 epochs. The proposed joint training scheme (Alg. 1) iterates for 50 epochs, where the learning rate is constant for the first 25 epochs and then gradually decreases to 0 for another 25 epochs following the formula lr = lr × (1.0 − max(0, epoch − 25)/25).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Comparison with State-of-the-arts</head><p>We compare our proposed SDA framework with state-of-the-art methods on four domain adaptive re-ID tasks in <ref type="table">Table 1</ref>. Our method is plug-and-play with any pseudo-label-based target domain encoder. We tested DBSCAN <ref type="bibr" target="#b9">[10]</ref> in our encoder, namely "Our SDA w/ DBSCAN". It outperforms the best-performing single models, SSG <ref type="bibr" target="#b36">[37]</ref> and PCB-PAST <ref type="bibr" target="#b38">[39]</ref>, that adopted the same clustering algorithm. We adopt the same hyper-parameters of DBSCAN as <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b36">37]</ref> for fair comparison.</p><p>We also tested k-means on SDA with the optimal k value following the state-of-the-art <ref type="bibr" target="#b11">[12]</ref>, i.e., 500 for Duke→Market, 700 for Market→Duke, 1500 for Duke→MSMT and Market→MSMT. Although MMT <ref type="bibr" target="#b11">[12]</ref> shows superior performances over "Ours SDA w/ k-means" by adopting dual networks with two times more parameters and computations for mutual training, our SDA is well compatible with it and can be combined to achieve further improvements, i.e., we add the robust soft pseudo labels introduced by MMT. The combination "Our SDA w/ k-means+MMT <ref type="bibr" target="#b11">[12]</ref>" shows further 4.3% and 5.3% mAP gains on Duke→Market and Market→Duke. Moreover, our SDA is consistently effective without the need of setting k to be close to the actual identity numbers. As shown in <ref type="table" target="#tab_4">Table  2</ref>, even with different k's, our SDA stably improves the already strong baselines, which is trained with only the target-domain samples and clustering-based pseudo labels.</p><p>Note that the focus of our SDA is to generate informative training samples rather than pseudo label refinery as the previous methods <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b11">12]</ref>. The translated images by our SDA are used as additional training samples to further improve the pseudo-label-based encoder. As previous translation-based methods <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b2">3]</ref> did not utilize pseudo labels and therefore cannot be directly compared with, we replace our online relation-consistency regularization with their ID-based constraints (Section 4.4) to show the advantages of our well-designed regularization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Ablation Studies</head><p>We conduct ablation studies on Duke→Market and Market→Duke tasks to analyze the effectiveness of our framework and the importance of the proposed online relation-consistency regularization term.</p><p>Detailed ablation experiments can be found in <ref type="table">Table 4</ref>.</p><p>Compatibility to different target-domain encoders. Our proposed SDA with online relation regularization is general and can benefit different target-domain encoders. We treat the target-domain encoder F t trained with only target-domain images and clustering-based pseudo labels as our baseline model. Our framework significantly outperforms the baseline model by properly exploiting valuable source-domain data (see "Ours (full)" vs. "Baseline" in <ref type="table">Table 4</ref>). A naïve way to use source-domain images is to directly train on both domains' raw images, denoted as "Baseline+raw source-domain data". The performance is even worse than the baseline on Duke→Market due to the large domain gaps, which indicates the necessity of properly leveraging different domains' images.</p><p>Our SDA can also be integrated and benefit state-of-the-art pseudo-label-based method <ref type="bibr" target="#b11">[12]</ref> (see "Our SDA+MMT" vs. "MMT" in <ref type="table">Table 1</ref>). The improvements demonstrate the effectiveness of our structured domain translation on either baseline or state-of-the-art target-domain encoders.</p><p>Comparison with existing ID-based regularizations on translation. Existing translation-based UDA methods <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b2">3]</ref> adopted identity-based losses with static targets to regularize the domain translation, including contrastive loss in SPGAN <ref type="bibr" target="#b7">[8]</ref>, classification loss in eSPGAN <ref type="bibr" target="#b8">[9]</ref> and CR-GAN <ref type="bibr" target="#b2">[3]</ref>, and triplet loss. Generally, the previous losses only require the source-to-target translated images to be correctly classified after translation. Since our pseudo-label-based target-domain encoder shows much better baseline performance than theirs, for fair comparison, we replace the online relation regularization L rc in our framework with the previous methods' regularizations to demonstrate the effectiveness of our regularization.</p><p>The results are reported in <ref type="table">Table 4</ref>. We observe that replacing our proposed L rc with previous regularization (denoted as "Ours w/ L rc → contrastive loss regul. <ref type="bibr" target="#b7">[8]</ref>", "Ours w/ L rc → classification loss regul. <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b2">3]</ref>", "Ours w/ L rc → triplet loss regul.") all lead to worse performances than our method, demonstrating the superiority of our stronger relation regularization term over the weaker regularizations in previous translation-based UDA methods.</p><p>To show the necessity of adopting relation regularization during translation, we also tested totally removing L rc from our framework, dubbed "Ours w/o L rc " in <ref type="table">Table 4</ref>. Significant mAP decreases of 3.4% and 3.8% are observed on Duke→Market and Market→Duke tasks.</p><p>Alternative designs of online relation-consistency regularization. Our SDT applies regularizations on the softmax-triplet relations (Eq. <ref type="formula" target="#formula_6">(7)</ref>). We further explore two alternative forms, predictionconsistency regularization L pc and batch-all relation-consistency regularization L brc <ref type="table">(Table 3)</ref> to verify the effectiveness of our well-designed inter-sample relation constraint.</p><p>Specifically, the prediction-consistency regularization ensures that each individual image in the source domain should maintain the same "soft" class prediction after source-to-target translation. The loss function is formulated as</p><formula xml:id="formula_9">L pc (G s→t ) = E x s ∼X s [−C s (f s ) · log(C t (f s→t ))].</formula><p>As shown in <ref type="table">Table 3</ref>, 3.1% and 2.4% mAP drops are observed on two datasets.</p><p>Our L rc (Eq. <ref type="formula" target="#formula_6">(7)</ref>) aims at preserving relations within hardest triplets, while the alternative batch-all relation-consistency loss L brc tries to preserve all such relations within batches. We model the batch-all inter-sample relations by measuring the similarities R(x s ;</p><formula xml:id="formula_10">F s ) = [ f s , f s 1 , · · · , f s , f s k ]</formula><p>, which consist of pairwise dot products between each sample x s and all other ones in the same batch. The similarity vector is normalized and a soft cross-entropy loss is adopted to regularize all the relations after translation, L brc (G s→t ) = E x s ∼X s [−R(x s ; F s ) · log R(x s ; G s→t , F t )]. 1.8% mAP and 2.1% mAP drops can be observed on the two tasks. The reason might be that batch-all relations contain many easy cases that cannot provide effective supervisions for training.</p><p>Effectiveness of training with the unified label set. We observe that the target-domain encoder also benefits from the unified label set by training the classifier on all the p s +p t classes across the two domains. To show it, we design an experiment with separate classifiers for source-totarget translated images and target-domain images, i.e., C t : f → {1, · · · , p s +p t } is split into C s→t : f s→t → {1, · · · , p s } and C t : f t → {1, · · · ,p t }. We report the performance in <ref type="table">Table 4</ref> as "Ours w/o unified label system". 1.6% and 1.9% mAP drops are observed on the two tasks, which indicate the effectiveness of modeling the relations between two domains.</p><p>Further benefits from the momentum encoder F t * . As described in Section 4.2, we utilize a momentum encoder <ref type="bibr" target="#b14">[15]</ref> for more stable training and better performance. To verify that the main contribution is not from the momentum encoder, we perform an experiment by removing F t * while keeping all other components unchanged. The experimental results are denoted as "Ours w/o momentum encoder <ref type="bibr" target="#b14">[15]</ref>" in <ref type="table">Table 4</ref>. We observe slight drops of 1.1% and 1.4% mAP on two tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion and Conclusion</head><p>In this work, we propose an end-to-end structured domain adaptation framework with a novel online relation-consistency regularization term to tackle the unsupervised domain adaptation (UDA) problem for person re-ID. The structuredly translated images in our method are shown to be informative samples for improving the training of pseudo-label-based encoder. The joint optimization scheme of domain-translation network and re-ID encoder is effective, however, it still has difficulty on handling industrial-scale datasets. Further improvements are called for. Beyond the person re-ID, our proposed inter-sample relation-consistency regularization may benefit other related UDA tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Broader Impact</head><p>The goal of the present work is to tackle the challenge of properly transferring the learned knowledge to a new domain without any manual annotations. The applications of our proposed person re-ID algorithm will greatly contribute to economic and social development. In particular, our method can be applied in the construction of smart cities with annotation-free models covering retail, transportation, as well as security. In addition, our proposed framework is by no means limited to the task of person re-ID. It will deepen our understanding of unsupervised and semi-supervised representation learning when extended to broader research topics.</p><p>The applications of re-ID systems, however, inevitably run the risk of privacy infringement, which calls for careful regulations from relevant authorities. Another issue that may cause concern is the possible results of misidentification, which is why we should always be cautious when adopting the results of re-ID technologies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Comparison with Domain Translation-based UDA Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Domain Translated Examples</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Source images</head><p>CycleGAN <ref type="bibr" target="#b44">[45]</ref> SPGAN <ref type="bibr" target="#b7">[8]</ref> Ours <ref type="figure">Figure 3</ref>. Domain-translated examples of CycleGAN <ref type="bibr" target="#b44">[45]</ref>, SPGAN <ref type="bibr" target="#b7">[8]</ref> and our method. SPGAN adopts ID-based regularizations (i.e., contrastive loss), showing inferior generation results than our method. ID-based regularizations are too weak to preserve inter-sample relations during translation. For instance, the man in the first row appears to be in different colors (e.g., orange, yellow and green) within a tuple after translation by CycleGAN and SPGAN. Other translation-based methods <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b2">3]</ref> did not provide trained models or translated images, thus not be illustrated here. However, we have carefully discussed and compared them with their ID-based regularizations in the ablation studies mentioned above. Best viewed in color. In the original paper's <ref type="table">Table 4</ref>, we evaluated our proposed online relation-consistency regularization by replacing L rc with previous ID-based regularizations <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b2">3]</ref> in our final framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Performance of Target-domain Encoder w/o Pseudo Labels</head><p>To further verify the effectiveness of our structured domain translation for domain adaptation, we evaluate our framework using a target-domain encoder without pseudo labels, which is a common strategy in previous translation-based methods <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b2">3]</ref>, i.e., the target-domain encoder is trained with only source-to-target translated images and their source-domain identities. As shown in <ref type="table" target="#tab_6">Table 5</ref>, our method stably achieves state-of-the-art performances on both Duke→Market and Market→Duke adaptation tasks without generating pseudo labels in the target domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Performance w/o Joint Training of SDT and Target-domain Encoder</head><p>The domain-translation network and target-domain encoder in our framework promote each other via joint training. However, a simpler training scheme would be to first train a source-to-target translation network with the proposed regularization and translate all source-domain images to the target domain. A pseudo-label-based target-domain encoder is then trained with such fixed source-to-target translated images and target-domain images. We evaluate both our framework and existing translation-based methods <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b7">8]</ref> when adopting such separate training strategy and k-means clustering for pseudo label generation. The results in <ref type="table" target="#tab_7">Table 6</ref> show that the informative training samples generated by our proposed structured domaintranslation (SDT) network could effectively improve the already strong baseline even without our joint training scheme, while the source-to-target images generated by CycleGAN and SPGAN might even worsen the performance because their generated images might not well follow the distributions of target-domain data and maintain their original inter-sample relations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>(a) The original inter-sample relations of source-to-target translated images are not maintained by existing domain translation-based methods. (b) Our proposed online relation regularization better preserves the inter-sample relations for improving cross-domain person re-ID. (c) Example triplets by SPGAN [8] and our proposed method. Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>+ ( 1</head><label>1</label><figDesc>− α)θ (T ) , where θ (0) * = θ (0) and α = 0.999 is the momentum coefficient. Intuitively, the momentum encoder could provide more reliable inter-sample relations since it eases the training bias caused by unstable translation results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Algorithm 1 Structured domain adaptation for unsupervised person re-ID Require: Labeled source-domain data X s , unlabeled target-domain data X t ; Require: Weighting factors λrc, λcyc, λadv, λapr for Eq. (8); 1: Pre-train source-domain encoder F s by minimizing Eq. (1) on X s ; 2: for n in [1, num_epochs] do 3: Create pseudo labels by clustering F t (X t ); 4: for each mini-batch B s ⊂ X s , B t ⊂ X t do 5: Translate B s into the target domain as B s→t by G s→t ; 6: Update G s→t , G t→s by minimizing the objective function Eq. (8) with D s , D t fixed, where the inter-sample relations are measured by F s and F t on-the-fly; 7: Update F t by minimizing the objective function Eq. (9) with B s→t ∪ B t ; 8: Update D s , D t by maximizing the objective function Eq. (8) with G s→t , G t→s fixed.</figDesc><table /><note>9: end for 10: end for</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 .</head><label>2</label><figDesc>Comparison with different values of k in our SDA when adopting k-means on Market→Duke.</figDesc><table><row><cell>k value</cell><cell>mAP</cell><cell>Baseline</cell><cell>top-1</cell><cell>mAP</cell><cell>Ours</cell><cell>top-1</cell></row><row><cell>500</cell><cell>46.7</cell><cell></cell><cell>65.9</cell><cell>53.8 (+7.1)</cell><cell></cell><cell>70.6 (+4.7)</cell></row><row><cell>700</cell><cell>50.1</cell><cell></cell><cell>68.2</cell><cell>56.7 (+6.6)</cell><cell></cell><cell>74.0 (+5.8)</cell></row><row><cell>900</cell><cell>48.9</cell><cell></cell><cell>66.6</cell><cell>56.0 (+7.1)</cell><cell></cell><cell>72.9 (+6.3)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 .Table 4 .</head><label>34</label><figDesc>Comparison with the optional relationconsistency regularizations in our SDA with k-means. Ablation studies for our proposed framework (w/ k-means) on individual components.</figDesc><table><row><cell>Regularization</cell><cell cols="2">Duke→Market mAP top-1</cell><cell cols="2">Market→Duke mAP top-1</cell></row><row><cell>Prediction-consistency Lpc</cell><cell>63.3</cell><cell>84.5</cell><cell>54.3</cell><cell>71.1</cell></row><row><cell>Batch-all relations L brc</cell><cell>64.6</cell><cell>86.0</cell><cell>54.6</cell><cell>71.5</cell></row><row><cell>Our Lrc</cell><cell>66.4</cell><cell>86.4</cell><cell>56.7</cell><cell>74.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 .</head><label>5</label><figDesc>Comparison with domain translation-based UDA methods using target-domain encoder without pseudo labels. The performances (%) are reported on DukeMTMC-reID<ref type="bibr" target="#b28">[29]</ref> and Market-1501<ref type="bibr" target="#b39">[40]</ref> datasets.</figDesc><table><row><cell>Methods w/o Pseudo Labels</cell><cell cols="4">DukeMTMC-reID→Market-1501 mAP top-1 top-5 top-10</cell><cell cols="4">Market-1501→DukeMTMC-reID mAP top-1 top-5 top-10</cell></row><row><cell>PTGAN [36] (CVPR'18)</cell><cell>-</cell><cell>38.6</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>27.4</cell><cell>-</cell><cell>-</cell></row><row><cell>SPGAN [8] (CVPR'18)</cell><cell>22.8</cell><cell>51.5</cell><cell>70.1</cell><cell>76.8</cell><cell>22.3</cell><cell>41.1</cell><cell>56.6</cell><cell>63.0</cell></row><row><cell>M2M-GAN [22] (AAAI'19)</cell><cell>26.8</cell><cell>57.5</cell><cell>-</cell><cell>-</cell><cell>26.1</cell><cell>49.6</cell><cell>-</cell><cell>-</cell></row><row><cell>CR-GAN [3] (ICCV'19)</cell><cell>29.6</cell><cell>59.6</cell><cell>-</cell><cell>-</cell><cell>30.0</cell><cell>52.2</cell><cell>-</cell><cell>-</cell></row><row><cell>Our SDA w/o pseudo labels</cell><cell>35.0</cell><cell>64.5</cell><cell>79.5</cell><cell>84.6</cell><cell>34.3</cell><cell>53.1</cell><cell>67.1</cell><cell>72.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 .</head><label>6</label><figDesc>Comparison with domain translation-based UDA methods with pseudo labels (via k-means clustering) but without jointly training the domain-translation network and target-domain encoder. The performances (%) are reported on DukeMTMC-reID<ref type="bibr" target="#b28">[29]</ref> and Market-1501<ref type="bibr" target="#b39">[40]</ref> datasets.</figDesc><table><row><cell>Methods w/o Joint Training</cell><cell cols="4">DukeMTMC-reID→Market-1501 mAP top-1 top-5 top-10</cell><cell cols="4">Market-1501→DukeMTMC-reID mAP top-1 top-5 top-10</cell></row><row><cell>Baseline (target-domain data + pseudo labels)</cell><cell>59.0</cell><cell>80.7</cell><cell>90.5</cell><cell>93.4</cell><cell>50.1</cell><cell>68.2</cell><cell>79.2</cell><cell>82.7</cell></row><row><cell>Base. + source-to-target data by CycleGAN</cell><cell>56.0</cell><cell>79.6</cell><cell>90.6</cell><cell>93.9</cell><cell>51.2</cell><cell>69.5</cell><cell>80.4</cell><cell>83.5</cell></row><row><cell>Base. + source-to-target data by SPGAN [8]</cell><cell>53.4</cell><cell>78.6</cell><cell>90.3</cell><cell>93.1</cell><cell>48.8</cell><cell>66.2</cell><cell>78.5</cell><cell>83.0</cell></row><row><cell>Base. + source-to-target data by our SDT</cell><cell>61.3</cell><cell>83.3</cell><cell>91.8</cell><cell>94.9</cell><cell>54.3</cell><cell>71.6</cell><cell>82.0</cell><cell>85.6</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Domain separation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bousmalis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Trigeorgis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Silberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>NIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Disjoint label space transfer learning with common factorised space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Instance-guided context rendering for cross-domain person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="232" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Crdoco: Pixel-level domain transfer with cross-domain consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1791" to="1800" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Sample-to-sample correspondence for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Engineering Applications of Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="80" to="91" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation using regularized hyper-graph matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICIP. pp</title>
		<imprint>
			<biblScope unit="page" from="3758" to="3762" />
			<date type="published" when="2018" />
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<title level="m">Imagenet: A large-scale hierarchical image database</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Image-image domain adaptation with preserved self-similarity and domain-dissimilarity for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Similarity-preserving image-image domain adaptation for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.10551</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A density-based algorithm for discovering clusters in large spatial databases with noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">P</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In: Kdd</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="226" to="231" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Unsupervised person re-identification: Clustering and fine-tuning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Mutual mean-teaching: Pseudo label refinery for unsupervised domain adaptation on person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Fd-gan: Pose-guided feature distilling gan for robust person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">A kernel method for the two-sampleproblem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Borgwardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rasch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>NIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Leibe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.07737</idno>
		<title level="m">defense of the triplet loss for person re-identification</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<title level="m">Cycada: Cycle-consistent adversarial domain adaptation. ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Cross-dataset person re-identification via unsupervised pose disentanglement and adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">B</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">C F</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Adaptation and re-identification network: An unsupervised deep transfer learning approach to person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">C</forename><surname>Frank Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPRW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Bidirectional learning for domain adaptation of semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6936" to="6945" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">M2m-gan: Many-to-many generative adversarial transfer learning for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">A bottom-up clustering approach to unsupervised person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Pose transferrable person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4099" to="4108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.02791</idno>
		<title level="m">Learning transferable features with deep adaptation networks</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Least squares generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">Y</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Paul Smolley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2794" to="2802" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Open set domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panareda</forename><surname>Busto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="754" to="763" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">A novel unsupervised camera-aware domain adaptation framework for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Performance measures and a data set for multi-target, multi-camera tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ristani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Solera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cucchiara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>ECCVW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Open set domain adaptation by backpropagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ushiku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Harada</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="153" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.11334</idno>
		<title level="m">Unsupervised domain adaptive re-identification: Theory and practice</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Deep coral: Correlation alignment for deep domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="443" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Unsupervised cross-domain image generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Taigman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Polyak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wolf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Adversarial discriminative domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Transferable joint attribute-identity deep learning for unsupervised person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Person transfer gan to bridge domain gap for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Self-similarity grouping: A simple unsupervised cross domain adaptation approach for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yunchao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Guanshuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yuqian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Honghui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Thomas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Unsupervised person re-identification by soft multilabel learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Lai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Self-training with progressive augmentation for unsupervised cross-domain person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>You</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Scalable person re-identification: A benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Joint discriminative and generative learning for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2138" to="2147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.04896</idno>
		<title level="m">Random erasing data augmentation</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Generalizing a person retrieval model hetero-and homogeneously</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Invariance matters: Exemplar memory for domain adaptive person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Unpaired image-to-image translation using cycle-consistent adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2223" to="2232" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
