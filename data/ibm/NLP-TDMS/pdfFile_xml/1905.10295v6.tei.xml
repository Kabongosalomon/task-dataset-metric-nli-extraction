<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning to Learn via Self-Critique</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antreas</forename><surname>Antoniou</surname></persName>
							<email>a.antoniou@sms.ed.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Edinburgh</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amos</forename><surname>Storkey</surname></persName>
							<email>a.storkey@ed.ac.uk</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Edinburgh</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Learning to Learn via Self-Critique</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In few-shot learning, a machine learning system learns from a small set of labelled examples relating to a specific task, such that it can generalize to new examples of the same task. Given the limited availability of labelled examples in such tasks, we wish to make use of all the information we can. Usually a model learns taskspecific information from a small training-set (support-set) to predict on an unlabelled validation set (target-set). The target-set contains additional task-specific information which is not utilized by existing few-shot learning methods. Making use of the target-set examples via transductive learning requires approaches beyond the current methods; at inference time, the target-set contains only unlabelled input data-points, and so discriminative learning cannot be used. In this paper, we propose a framework called Self-Critique and Adapt or SCA, which learns to learn an label-free loss function, parameterized as a neural network. A base-model learns on a support-set using existing methods (e.g. stochastic gradient descent combined with the cross-entropy loss), and then is updated for the incoming target-task using the learnt loss function. The label-free loss function is learned such that the target-set-updated model achieves higher generalization performance. Experiments demonstrate that SCA offers substantially reduced errorrates compared to baselines which only adapt on the support-set, and results in state of the art benchmark performance on Mini-ImageNet and Caltech-UCSD Birds 200.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Humans can learn from a few data-points and generalize very well, but also have the ability to adapt in real-time to information from an incoming task. Given two training images for a two class problem, one with a cat on a white sofa, and one with a dog next to a car, one can come up with two hypothesis as to what each class describes in each case. A test image that presents a dog with a cat would be ambiguous. However, having other unlabelled test images with cats in other contexts and cars in other contexts enables these cases to be disambiguated, and it is possible to learn to focus on features that help this separation. We wish to incorporate this ability to adapt into a meta-learning context.</p><p>Few-shot learning is a learning paradigm where only a handful of samples are available to learn from. It is a setting where deep learning methods previously demonstrated weak generalization performance. In recent years, by framing the problem of few-shot learning as a meta-learning problem <ref type="bibr" target="#b27">(Vinyals et al., 2016)</ref>, we have observed an advent of meta-learning methods that have demonstrated unprecedented performance on a number of few-shot learning benchmarks <ref type="bibr" target="#b24">(Snell et al., 2017;</ref><ref type="bibr" target="#b3">Finn et al., 2017;</ref><ref type="bibr" target="#b20">Rusu et al., 2018)</ref>.</p><p>Most few-shot meta-learning methods have focused on either learning static <ref type="bibr" target="#b3">(Finn et al., 2017;</ref><ref type="bibr" target="#b0">Antoniou et al., 2019;</ref><ref type="bibr" target="#b10">Li and Malik, 2016)</ref> or dynamic parameter initializations <ref type="bibr" target="#b20">(Rusu et al., 2018)</ref>, learning rate schedulers <ref type="bibr" target="#b0">(Antoniou et al., 2019)</ref>, embedding functions <ref type="bibr" target="#b27">Vinyals et al. (2016)</ref>; <ref type="bibr" target="#b24">Snell et al. (2017)</ref>, optimizers <ref type="bibr" target="#b18">Ravi and Larochelle (2016)</ref>   <ref type="figure">Figure 1</ref>: Proposed Method. Starting from the top-left, task-specific knowledge from the support-set is used to train the base model, updating θ 0 to θ N . At this point, standard meta-learning methods return predictions from this learnt model to complete their inference. Instead, we use an unsupervised loss from a critic network C applied to the unlabelled target set to make further updates. To do this we collect a set of features F that summarise the model applied to the target set T ; these features are sent to the critic C, a neural network with parameters W . Using the loss from this critic network, and the model with parameters θ N , we make further updates to get θ N +I . We use the predictions from this model as our predictions for the target set. During training, an outer-loop loss comparing target-set predictions to target set labels is used to update the initial parameters θ 0 and the critic model parameters W .</p><p>these methods explore learning from the labelled support-set, whereas learning (at inference time) from the unlabelled target-set has remained unexplored. 1</p><p>In this paper, we propose a mechanism we call Self-Critique and Adapt or SCA that enables metalearning-based few-shot systems to learn not only from the support-set input-output pairs, but also from the target-set inputs, by learning a label-free loss function, parameterized as a neural network. Doing so grants our models the ability to learn from the target-set input data-points, simply by computing a loss, conditioned on base-model predictions of the target-set. The label-free loss can be used to compute gradients with respect to the model, and the gradients can then be used to update the base-model at inference time, to improve generalization performance. Furthermore, the proposed method can be added on top of any modern meta-learning method, including both methods that utilize gradient updates on the support set, such as MAML <ref type="bibr" target="#b3">(Finn et al., 2017)</ref>, as well as ones that do not use gradient-based updates on the support set, such as Matching Networks <ref type="bibr" target="#b27">(Vinyals et al., 2016)</ref>.</p><p>Self-Critique and Adapt is a transductive learning approach <ref type="bibr" target="#b26">(Vapnik, 2006)</ref>. Transductive learning uses training data and test input data-points to learn a model that is specifically tuned to produce predictions for the given test-set. Transductive learning benefits from unsupervised information from the test example points, and specification by knowing where we need to focus model capability.</p><p>In stark contrast, inductive learning, can be defined as a learning paradigm where given training input-output pairs, a model is learned consisting of general rules, that can then be used on any test-set without refinement to produce predictions. Given that, in a meta-learning context, additional learning needs to be done for each new setting anyway, and given the importance of making the most of every piece of information, transductive learning is a natural learning paradigm for the few-shot learning setting.</p><p>We evaluate the proposed method on the established few-shot learning benchmarks of Mini-ImageNet <ref type="bibr" target="#b18">(Ravi and Larochelle, 2016)</ref> and Caltech-UCSD Birds 200 (CUB) <ref type="bibr" target="#b1">(Chen et al., 2019)</ref>.</p><p>The evaluation results indicate that our method substantially boosts the performance of two separate instances of the MAML++ <ref type="bibr" target="#b0">(Antoniou et al., 2019)</ref> framework, setting a new state-of-the-art performance for all tasks in both benchmarks.</p><p>This paper's contributions are:</p><p>1. An approach that gives state-of-the-art performance in the Mini-Imagenet and Caltech-UCSD Birds 200 (CUB) benchmark tasks by using both support and target set information through a transductive approach.</p><p>2. The ability to learn to learn a flexible parameterized loss function appropriate for a supervised problem but defined on unlabelled data; this loss function can be used to enhance training on semi-supervised data.</p><p>3. A set of ablation studies on different conditioning features for the critic network, revealing which features are most useful to the few-shot learning benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The set-to-set few-shot learning setting <ref type="bibr" target="#b27">(Vinyals et al., 2016)</ref> has been vital in framing few-shot learning as a meta-learning problem. In set-to-set few-shot learning, we have a number of tasks, which a model seeks to learn. Each task is composed of two small sets. A small training-set or support-set used for acquiring task-specific knowledge, and a small validation-set or target-set, which is used to evaluate the model once it has acquired knowledge from the support-set. The tasks are generated dynamically from a larger dataset of input-output pairs. The dataset is split into 3 subsets beforehand, the meta-training, meta-validation and the meta-test sets, used for training, validation and testing respectively.</p><p>Once meta-learning was shown to be very effective in learning to few-shot learn, a multitude of methods showcasing unprecedented performance in few-shot learning surfaced. Matching Networks <ref type="bibr" target="#b27">(Vinyals et al., 2016)</ref>, and their extension Prototypical Networks <ref type="bibr" target="#b24">(Snell et al., 2017)</ref> were some of the first methods to showcase strong few-shot performance, using learnable embedding functions parameterized as neural networks in combination with distance metrics, such as cosine and euclidean distance. Unsupervised and supervised set-based embedding methods were also developed for the few-shot setting <ref type="bibr" target="#b2">(Edwards and Storkey, 2017)</ref>.</p><p>Further advancements were made by gradient-based meta-learning methods that explicitly optimized themselves for fast adaptation with a few data-points. The first of such methods, Meta-Learner LSTM <ref type="bibr" target="#b18">(Ravi and Larochelle, 2016)</ref> attempted to learn a parameter-initialization and an optimizer, parameterized as neural networks for fast adaptation. Subsequently, additional improvements came from Model Agnostic Meta-Learning (MAML) <ref type="bibr" target="#b3">(Finn et al., 2017)</ref> and its improved versions Meta-SGD <ref type="bibr" target="#b11">(Li et al., 2017)</ref> and MAML++ <ref type="bibr" target="#b0">(Antoniou et al., 2019)</ref>, where the authors proposed learning a parameter-initialization for a base-model that is adapted with standard SGD for a number of steps towards a task.</p><p>Furthermore, Relational Networks <ref type="bibr" target="#b22">(Santoro et al., 2017)</ref>, that were originally invented for relational reasoning, demonstrated very strong performance in few-shot learning tasks <ref type="bibr" target="#b23">(Santurkar et al., 2018)</ref>. The effectiveness of relational networks in a large variety of settings made them a module often found in meta-learning systems.</p><p>In the Reinforcement Learning domain, meta-learning has been used to learn an unsupervised loss function for sample-efficient adaptation in <ref type="bibr" target="#b28">(Yu, 2018)</ref>. Their work differs from ours, in that our model adapts a meta-learned initialization by both labelled and unlabelled examples; we do use a learnt unsupervised model, but the combination is critical. Their work is purely unsupervised in the inner loop, using RL as the outer loop, whereas ours consists of both supervised and unsupervised inner loops and a supervised outer loop. Furthermore, in <ref type="bibr" target="#b7">(Houthooft et al., 2018)</ref>, the authors propose a method that learns a state and reward conditional loss function to train a policy network, using RL inner phase and an evolutionary algorithm outer loop. Our work, instead targets a different problem, that is few-shot learning, using a supervised outer loop, and a transductive inner loop (composed by supervised and unsupervised inner loop phases). Furthermore, in <ref type="bibr" target="#b25">(Sung et al., 2017)</ref> the authors propose learning a supervised loss function for few-shot learning, as well as a state and reward conditional loss function for training RL agents.</p><p>Shortly after, substantial progress was made using a hybrid method utilizing embeddings, gradientbased methods and dynamic parameter generation called Latent Embedding Optimization <ref type="bibr" target="#b20">Rusu et al. (2018)</ref>.</p><p>Semi-supervised learning via learning label-free functions were also attempted in Rinu <ref type="bibr" target="#b19">Boney (2018)</ref>. Transductive learning for the few-shot learning setting has previously been attempted by learning to propagate labels . Their work differs from ours in that we learn to transduce using a learned unsupervised loss function whereas they instead learn to generate labels for the test set.</p><p>Algorithm 1 SCA Algorithm combined with MAML 1: Required : Base model function f and initialisation parameters θ, critic network function C and parameters W, a batch of tasks</p><formula xml:id="formula_0">{S B = {x B S , y B S }, T B = {x B T , y B T }} (where B</formula><p>is the number of tasks in our batch) and learning rates α, β, γ 2: L outer = 0 3: for b in range(B) do 4:</p><formula xml:id="formula_1">θ 0 = θ</formula><p>Reset θ 0 to the learned initialization parameters 5:</p><p>for i in range(N) do N indicates total number of inner loop steps wrt support set 6:</p><formula xml:id="formula_2">θ i+1 = θ i − α∇ θi L(f (x b S , θ i ), y b S )</formula><p>(1) Inner loop optimization wrt support set 7:</p><p>for j in range(I) do I indicates total number of inner loop steps wrt target set 8:</p><formula xml:id="formula_3">F = {f (x b T , θ N +j ), θ N + j, g(x S , x n )} (2) Critic feature-set collection 9: θ N +j+1 = θ N +j − γ∇ θ N +j C(F, W )</formula><p>(3) Inner loop optimization wrt target set 10:</p><formula xml:id="formula_4">L outer = L outer + L(f (x b T , θ N +I ), y b T ) 11: θ = θ − β∇ θ L outer</formula><p>(4) Joint outer loop optimization of θ 12: W = W − β∇ W L outer (5) Joint outer loop optimization of W</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Self-Critique and Adapt</head><p>For a model to learn and adapt in a setting where only input data-points are available (e.g. on given task's few-shot target-set), one needs a label-free loss function. For example, many unsupervised learning approaches try to maximize the generative probability, and hence use a negative log-likelihood (or bound thereof) as a loss function. In general though, much of the generative model will be task-irrelevant. In the context of a particular set of tasks there are likely to be more appropriate, specialised choices for a loss function.</p><p>Manually inventing such a loss function is challenging, often only yielding loss functions that might work in one setting but not in another. Understanding the full implications of a choice of lossfunction is not easy. Instead, we propose a Self-Critique and Adapt approach which meta-learns a loss function for a particular set of tasks. It does this by framing the problem using the set-to-set few-shot learning framework and using end-to-end differentiable gradient-based meta-learning as our learning framework.</p><p>SCA is model-agnostic, and can be applied on top of any end-to-end differentiable, gradient-based, meta-learning method that uses the inner-loop optimization process to acquire task-specific information. Many such approaches <ref type="bibr" target="#b18">(Ravi and Larochelle, 2016;</ref><ref type="bibr" target="#b3">Finn et al., 2017;</ref><ref type="bibr" target="#b11">Li et al., 2017;</ref><ref type="bibr" target="#b0">Antoniou et al., 2019;</ref><ref type="bibr" target="#b4">Finn et al., 2018;</ref><ref type="bibr" target="#b17">Qiao et al., 2018;</ref><ref type="bibr" target="#b20">Rusu et al., 2018;</ref><ref type="bibr" target="#b6">Grant et al., 2018)</ref> are currently competing for state-of-the-art in the few-shot learning landscape.</p><p>Self-Critique and Adapt, summarised in <ref type="figure">Figure 1</ref>, takes a base-model, updates it with respect to the support-set with an existing gradient-based meta-learning method (e.g. MAML <ref type="bibr" target="#b3">(Finn et al., 2017)</ref>, MAML++ <ref type="bibr" target="#b0">(Antoniou et al., 2019)</ref> or LEO <ref type="bibr" target="#b20">(Rusu et al., 2018)</ref>), and then infers predictions for the target-set. Once the predictions have been inferred, they are concatenated along with other basemodel related information (e.g. model parameters, a task embedding etc.), and are then passed to a learnable critic loss network, the output of which should be interpreted as a loss value for the given inputs. This critic network computes and returns a loss with respect to the target-set. The basemodel is then updated with any stochastic gradient optimization method (such as SGD) with respect to this critic loss; updates can be done a number of times if necessary. This inner-loop optimization produces a predictive model specific to the support/target set information.</p><p>The inner loop process is used directly at inference time for the task at hand. However, as in other meta-learning settings, we optimize the inner loop using a collection of training tasks (these are different from the test tasks as explained in Section 7). The quality of the inner-loop learned predictive model is assessed using ground truth labels from the training tasks. The outer loop then optimizes the initial parameters and the critic loss to maximize the quality of the inner loop predictions. As with other meta-learning methods, the differentiability of the whole inner loop ensures this outer-loop can be learnt with gradient based methods.</p><p>In this paper we use MAML++ as the base method. We denote the model, which is parameterized as a neural network, by f (·, θ), with parameters θ, and the critic loss C(·, W ), also a neural network with parameters W . We want to learn good parameters θ and W , such that when the model f is optimized a number of steps N with respect to the loss L on the support-set S b = {x S , y S }, and then additionally another I steps towards the target-set T b = {x T }, using the critic loss C, it can achieve good generalization performance on the target-set. Here, b is the index of a particular task in a batch of tasks. The full algorithm is described in Algorithm 1.</p><p>Equation 2 in Algorithm 1 defines a potential set of conditioning features F that summarise the base-model and its behaviour. These features are what the unsupervised critic loss C can use to tune the target set updates. Amongst these possible features, f (θ N , x T ) are the predictions of the base-model f , using parameters θ N (that is parameters updated for N steps on the support-set loss) and g(x S , x n ) is a task embedding, parameterized as a neural network, which is conditional on the support and target input data-points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Example: A Prediction-Conditional Critic Network</head><p>Model Inference and Training: As explained in Sections 3 and 5 our critic network can be given access to a wide variety of conditioning information. Here, we describe a specific variant, which uses the predictions of the base-model on the target-set as the critic network's conditioning information; this simple form enables visualisation of what the critic loss returns.</p><p>In this example, SCA is applied directly to MAML++. Given a support set, S and target set T for a task, and initial model f (·, θ 0 ), five SGD steps are taken to obtain the updated model f (·, θ 5 ) using the support set's loss using Equation 1. The updated model is then applied to the target set to produce target-set predictions f (x T , θ 5 ); these predictions are passed to the critic network, which returns a loss-value for each element of the target set. Aggregated, these loss-values form the critic loss. The base model f (·, θ 5 ) is then updated for 1 step using the gradients with respect to the critic loss using Equation 3 to obtain the final model f (·, θ 6 ). We use gradients of a whole batch of target set images to update the base model since this produces better performance. The results in the paper represent experiments where we used target sets of size 75 to learn the loss function, however one could instead randomly choose the batch size of the target set to train a loss function that generalizes on a wide range of batch sizes. At this stage our final model has learned from both the support and target sets and is ready to produce the final predictions of the target set. These are produced, and, at training time, evaluated against the ground truth. This final error is now the signal for updating the whole process: the choice of initial θ 0 and the critic loss update. The gradients for both the base and critic model parameters can be computed using backpropagation as every module of the system is differentiable.</p><p>Interrogating the Learned Critic Loss: We investigate how the predictions of the base-model change after updates with respect to the critic loss. We generate target-set predictions using the base-model f (·, θ 5 ) and pass those predictions to the learnt critic network to obtain a loss value for each individual prediction. Five steps of SGD are performed with respect to the the individual critic loss. The results are shown in <ref type="figure">Figure 2</ref>.</p><p>Interrogating The Critic <ref type="figure">Figure 2</ref>: The target-set predictions of the base-model before (red lines) and after (green lines) it has been updated wrt the learned critic loss. Starting from the left, the first chart showcases an instance where the probabilities of two classes dominate the rest, with one class having approximately 20% higher probability than the other. The critic network proposes that the dominant class with the lower probability be left as is, whilst the higher probability class be increased. In the second chart, we present an example where two dominant classes have equal probabilities, and are thus considered optimal and left unchanged. In the third case, we present an example where a single class dominates all others. The critic network proposes that the probability of that class is pushed to almost the maximum possible value. Finally, in the fourth case we present a very interesting case where the critic, faced with two dominant classes, which had approximately 10% difference in their probability, proposed that the two classes have their probabilities matched to improve the resulting generalization performance. Note how some top classes change, e.g. in the rightmost chart. The effect of these changes is not in the class-labels alone but also allows better model initialization: training a critic on a pretrained initialization does not provide as much benefit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Choosing Conditioning Information for the Critic Network</head><p>We find that the performance of the critic network C, is unsurprisingly dependent on the quality of critic features it is given access to. In this section, we will outline a set of critic features we used in experiments, from simplest to most complicated; we also discuss the intuition behind their selection. To evaluate the usefulness of each set of critic features we use these in ablation studies in Section 7 and summarize the results in <ref type="table" target="#tab_2">Tables 1 and 2.</ref> Base-Model Predictions: The predictions on the base model indicate the certainty about any input; this can be a powerful driver for an unsupervised loss. As in Section 4, given the model f , the support-set updated weights θ N and some target-set data-points x T , we can generate predictions f (x T , θ N ). These predictions can be passed to our critic model C to compute the loss function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Base-model Parameters:</head><p>Another key source of information about our base-model is the model parameters. In this context, the inner loop optimized parameters θ N are passed to our loss network. For example this might enables it to learn penalty terms, similar to manually invented penalties such as L1 and L2.</p><p>Task Embeddings: Giving the critic model direct access to task information can enable model assessment in the context of a particular task; we find this further improves performance as empirically observed in Tables 1 and 2. To generate a task embedding, we learn an embedding function g, parameterized as a neural network such as a DenseNet. <ref type="bibr">2</ref> The embedding function g receives the support-set images and returns a batch of embedding vectors. Taking the mean of the vectors can serve as a strong task embedding. However, we found that using a relational network to relate all embeddings with each other and then taking the sum of those embeddings produced superior results. Similar embedding functions have previously been used in <ref type="bibr" target="#b20">(Rusu et al., 2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Baselines</head><p>The proposed model is, by virtue of its design, applicable to any few-shot meta-learning system that follows the set-to-set <ref type="bibr" target="#b27">Vinyals et al. (2016)</ref> few-shot learning setting. Thus, to investigate its performance, we require baseline meta-learning systems which inner-loop optimize their parameters only on the support-set. We chose the MAML++ system, for it's simplicity and strong generalization performance.</p><p>To thoroughly evaluate our method, we experimented using two separate instances of the MAML++ framework, each differing only in the neural network architecture serving as its backbone.</p><p>Low-End MAML++: The backbone of our low-end baseline model follows the architecture proposed in <ref type="bibr" target="#b0">Antoniou et al. (2019)</ref>, which consists of a cascade of 4 convolutional layers, each followed by a batch normalization layer and a ReLU activation function. We optimize the entirety of the backbone during the inner loop optimization process. The low-end baseline is chosen to be identical to an existing model (MAML++), such that we could: 1. Confirm that our implementation replicates the results of the original method (i.e. makes sure that our framework does not over/under perform relatively to an existing method, and thus reduces the probability that any improvements in our results are there due to a bug in the data provider or learning framework) and 2. Investigate how our proposed method performs when added adhoc to an existing, non-tuned, architecture, therefore showcasing performance unbiased wrt architecture.</p><p>High-End MAML++: Methods that provide significant performance improvements on lowcapacity models, often fail to provide the same level of improvement on high-capacity models and vice versa. Furthermore, meta-learning methods, have been demonstrated to be very sensitive to neural network architecture changes. Thus, to evaluate both the consistency and sensitivity of our method, we designed a high (generalization) performance MAML++ backbone. It uses a shallow, yet wide DenseNet architecture, with growth-rate 64, utilizing 2 dense-stages each consisting of two bottleneck blocks as described in <ref type="bibr" target="#b9">Huang et al. (2017)</ref> and one transition layer. Before each bottleneck block, we apply squeeze-excite style convolutional attention as described in <ref type="bibr" target="#b8">Hu et al. (2018)</ref>, to further regularize our model. To improve the training speed and generalization performance, we restrict the network components optimized during the inner loop optimization process. In more detail, we choose to share a static copy of majority of the network components at each step, and only optimize the penultimate convolutional layer (including the squeeze excite attentional block preceding it) as well as the final linear layer. An efficient way of sharing components across steps, is to treat them as a feature embedding, whose features are passed to the components that will be inner loop optimized. Recent work <ref type="bibr" target="#b20">(Rusu et al., 2018;</ref><ref type="bibr" target="#b17">Qiao et al., 2018)</ref> followed a similar approach. Motivations behind these design choices can be found in the supplementary materials section 1. 10.</p><p>Critic Network Architecture: The critic network consists of two majour components. First, a selection of conditioning features as described in Section 5, which are then reshaped into a batch of one-dimensional features vectors and concatenated on the feature dimension. Second, an Information Integration network, which consists of a sequence of five one-dimensional dilated convolutions with kernel size 2, and 8 kernels per convolutional layer. Further, we employ an exponentially increasing dilation policy where a given convolutional layer has dilation d = 2 i where i is the index of the convolutional layer in the network, starting from 0 for the first layer and increasing up to 4 for the fifth layer. We use Dense-Net style connectivity for our convolutional layers, more specifically, the inputs for a given layer consist of a concatenation of the output features of all preceding convolutional layers. Finally we apply a sequence of two fully connected layers using ReLU non-linearities before the final linear layer which outputs the loss value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Experiments</head><p>To evaluate the proposed methods we first establish baselines on both the low-end and high-end variants of MAML++ on the Mini-ImageNet and Caltech-UCSD Birds 200 (CUB) 5-way 1/5-shot tasks. Then, we add the proposed critic network, which enables the adaptation of the base-model on a given target-set. To investigate how the selection of conditional information we provide to the critic affect its performance we conduct ablation studies. Due to the large number of combinations possible, we adopt a hierarchical experimentation style, where we first ran experiments with a single source of conditional information, and then tried combinations of the best performing methods.</p><p>Finally, we ran experiments where we combined every proposed conditioning method to the critic, as well as experiments where we combined every conditional method except one. <ref type="table" target="#tab_2">Tables 1 and 2</ref> show ablation and comparative studies on Mini-Imagenet and CUB respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Results</head><p>The results of our experiments showcased that our proposed method was able to substantially improve the performance of both our baselines across all Mini-ImageNet and CUB tasks.</p><p>More specifically, the original MAML++ architecture (i.e. Low-End MAML++), yielded superior performance when we provided additional conditional information such as the task embedding and the model parameters. The only source of information that actually decreased performance were the base-model's parameters themselves. Furthermore, it appears that a very straight-forward strategy that worked the best, was to simply combine all proposed conditioning sources and pass them to the critic network.</p><p>However, in the case of the High-End MAML++ architecture, performance improvements were substantial when using the predictions and the task embedding as the conditioning information. Contrary to the results on MAML++, providing the critic with the matching network and relational comparator features (in addition to the prediction and task embedding features) did not produce additional performance gains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Test Accuracy Mini-Imagenet CUB 1-shot   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>In this paper we propose adapting few-shot models not only on a given support-set, but also on a given target-set by learning a label-free critic model. In our experiments we found that such a critic network can, in fact, improve the performance of two instances of the well established gradientbased meta-learning method MAML. We found that some of the most useful conditional information for the critic model were the base-model's predictions, a relational task embedding and a relational support-target-set network. The performance achieved by the High-End MAML++ with SCA is the current best across all SOTA results. The fact that a model can learn to update itself with respect to an incoming batch of data-points is an intriquing one. Perhaps deep learning models with the ability to adapt themselves in light of new data, might provide a future avenue to flexible, self-updating systems that can utilize incoming data-points to improve their own performance at a given task.</p><p>10 Appendix: High-End Backbone details:</p><p>The motivations behind each of the design choices can be found below.</p><p>1. Using DenseNet as the backbone, which decreases probability of gradient degradation problems and by allowing feature-reuse across all blocksm improves parameter/training efficiency. MAML is highly vulnerable to gradient degradation issues, and thus ensuring that our backbone decreases probability of such issues is of vital importance. 2. Using a shallow, yet wide backbone: Previous works <ref type="bibr" target="#b17">Qiao et al. (2018)</ref>; <ref type="bibr" target="#b20">Rusu et al. (2018)</ref> have demonstrated that using features from the 20th layer of a pretrained ResNet produces superior generalization performance. The authors made the case that using features from shallower parts of the network decreases the probability that the features are too classspecific, and thus allow for better generalization on previously unseen classes. In both <ref type="bibr" target="#b17">Qiao et al. (2018)</ref>; <ref type="bibr" target="#b20">Rusu et al. (2018)</ref> the authors did not train their meta-learning system end-toend, and instead trained the feature backbone and the meta-learning components separately.</p><p>However, in preliminary experiments we found that ResNet and DenseNet backbones tend to overfit very heavily, and in pursuit of a high-generalization end-to-end trainable metalearning system, we experimented with explicit reduction of the effective input region of the layers in a backbone. Doing so, ensures that features learned will be local. We found that keeping the effective input region of the deepest layer to approximately 15x15/20x20 produced the best results for both Mini-ImageNet and CUB. Furthermore, we found that widening the network produced additional generalization improvements. We theorize that this is because of a higher probability for a randomly initialized feature to lie in just the right subspace to produce a highly generalizable feature once optimized. 3. Using bottleneck blocks, preceded by squeeze-excite-styleHu et al. (2018) convolutional attention: We empirically found that this improves generalization performance. 4. Inner-Loop optimize only the last squeeze excite linear layer, as well as the last convolutional layer and the final linear layer, whilst sharing the rest of the backbone across the inner loop steps. This design choice was hinted by the learned per-layer, per-step learning rates learned by MAML++ on the low-end baseline. More specifically, the learned learning rates where close to zero, for all layers, in all steps, except the last convolutional and last linear layers. Thus, we attempted to train a MAML++ instance where only those two layers where optimized in the inner loop, while the rest of the layers where shared across steps.</p><p>In doing so, we found that doing so makes no difference to generalization performance, whilst increasing the training and inference speeds by at least 15 times.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>and other internal components. However all of 33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="12">Inner Loop Optimization wrt Support Set</cell><cell></cell><cell></cell><cell>Target Set Labels (Only for meta-training) { } y T</cell></row><row><cell cols="7">Support Set</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="9">Repeat N Times</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">(Small Training Set)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>S</cell><cell>=</cell><cell cols="2">{ x S</cell><cell>,</cell><cell>y S</cell><cell>}</cell><cell cols="9">Classifier (Base Model)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="8">Update Base Model wrt</cell><cell>S</cell><cell>Compute Outer Loop Loss</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>f</cell><cell cols="2">( x S</cell><cell>,</cell><cell cols="2">i θ</cell><cell>)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">θ i + 1</cell><cell>=</cell><cell>θ i</cell><cell>−</cell><cell>∇ θ i</cell><cell>L</cell><cell>( f</cell><cell>( x S</cell><cell>,</cell><cell>θ i</cell><cell>) ,</cell><cell>y S</cell><cell>)</cell><cell>L o u t</cell><cell>e r</cell><cell>=</cell><cell>L</cell><cell>( f</cell><cell>( x T</cell><cell>,</cell><cell>θ N</cell><cell>+ I</cell><cell>) ,</cell><cell>y T</cell><cell>)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="12">Copy Updated Model</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Final Target Set</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">f</cell><cell>(</cell><cell>⋅</cell><cell>,</cell><cell cols="2">) θ N</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Predictions</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>f</cell><cell>( x T</cell><cell>,</cell><cell>θ N</cell><cell>+ I</cell><cell>)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="13">Inner Loop Optimization</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="8">wrt Target Set</cell><cell></cell><cell></cell></row><row><cell cols="7">Target Set (Small Validation Set)</cell><cell cols="18">Classifier Adapted on Support Set (Base Model) f ( , ) x T θ N + j</cell><cell></cell><cell></cell><cell>F</cell><cell cols="2">=</cell><cell>Featurization f { ( , ) , θ N + j x T</cell><cell>θ N</cell><cell>+ j</cell><cell>}</cell><cell>Copy Final Model f ( ⋅ , ) θ N + I</cell><cell>(Base Model) Classifier Adapted on Support and Target Set</cell></row><row><cell></cell><cell>T</cell><cell>=</cell><cell cols="3">{ } x T</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="6">Repeat Times I</cell><cell></cell><cell>f</cell><cell>( θ N</cell><cell>+ I</cell><cell>)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="13">Update Base Model wrt</cell><cell cols="2">T</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">Label-Free Critic Network</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>θ N</cell><cell cols="2">+ j + 1</cell><cell cols="3">=</cell><cell cols="2">θ N</cell><cell>+ j</cell><cell>−</cell><cell>∇ θ N</cell><cell>+ j</cell><cell>C</cell><cell cols="2">( F</cell><cell>,</cell><cell>W</cell><cell>)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>C</cell><cell>( F</cell><cell>,</cell><cell>W</cell><cell>)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>− 0.38% 77.64 + − 0.40% 70.46 + − 1.18% 85.63 + − 0.66%</figDesc><table><row><cell>5-shot</cell><cell>1-shot</cell><cell>5-shot</cell></row><row><cell>MAML++ (Low-End) MAML++ (Low-End) with SCA(preds) MAML++ (Low-End) with SCA(preds, params) MAML++ (Low-End) with SCA(preds, task-embedding) MAML++ (Low-End) with SCA(preds, task-embedding, params) 54.24 + − 0.99% 71.85 + − 0.53% 52.15 + − 0.26% 68.32 + − 0.44% 52.52 + − 1.13% 70.84 + − 0.34% 52.68 + − 0.93% 69.83 + − 1.18% 54.84 + − 1.24% 70.95 + − 0.17% MAML++ (High-End) 58.37 + − 0.27% 75.50 + − 0.19% MAML++ (High-End) with SCA (preds) 62.86 + − 0.70% 77.07 + − 0.19% MAML++ (High-End) with SCA (preds, task-embedding) 62.29 +</cell><cell>62.19 + − 0.53% 66.13 + − 0.97% -65.56 + − 0.48% -67.48 + − 1.44% 70.33 + − 0.78%</cell><cell>76.08 + − 0.51% 77.62 + − 0.77% -77.69 + − 0.47% -83.80 + − 0.35% 85.47 + − 0.40%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>SCA Ablation Studies on Mini-ImageNet and CUB: All variants utilizing the proposed SCA method perform substantially better than the non-SCA baseline variant. Interestingly, the best type of critic conditioning features varies depending on the backbone architecture. Based on our experiments, the best critic conditioning features for the Low-End MAML++ is the combination of predictions, task-embedding and network parameters, whereas on High-End MAML++, using just the target-set predictions appears to be enough to obtain the highest performance observed in our experiments. − 0.79% 77.64 + − 0.40% 70.46 + − 1.18% 85.63 + − 0.66%</figDesc><table><row><cell>Model</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>Comparative Results on Mini-ImageNet and CUB: The proposed method appears to im- prove the baseline model by over 4 percentage points, allowing it to set a new state-of-the-art result on both the 1/5-way Mini-ImageNet tasks.</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Existing techniques likeMAML Finn et al. (2017)  utilize target-set information by computing means and standard deviations for the batch normalization layers within their base models. However, we don't consider that as explicit learning, but instead, as a minimal adaptation routine.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Here we use a DenseNet, with growth rate 8, and 8 blocks per stage, for a total of 49 layers. The DenseNet is reqularised using dropout after each block (with drop probability of 0.5) and weight decay (with decay rate 2e-05).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Acknowledgements</head><p>We would like to thank our colleagues Elliot Crowley, Paul Micaelli, James Owers and Joseph Mellor for reviewing this work and providing useful suggestions/comments. Furthermore, we'd like to thank Harri Edwards for the useful discussions at the beginning of this project and the review and comments he provided. This work was supported in part by the EPSRC Centre for Doctoral Training in Data Science, funded by the UK Engineering and Physical Sciences Research Council (grant EP/L016427/1) and the University of Edinburgh as well as a Huawei DDMPLab Innovation Research Grant.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">How to train your MAML</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Antoniou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Storkey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A closer look at few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-B</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Towards a neural statistician</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Storkey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.02185</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Model-agnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.03400</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Probabilistic model-agnostic meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="9516" to="9527" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Dynamic few-shot visual learning without forgetting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4367" to="4375" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Recasting gradient-based metalearning as hierarchical bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Griffiths</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.08930</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Evolved policy gradients</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Houthooft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Stadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wolski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5400" to="5409" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Squeeze-and-excitation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7132" to="7141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Learning to optimize</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.01885</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.09835</idno>
		<title level="m">Meta-sgd: Learning to learn quickly for few shot learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1805.10002</idno>
		<title level="m">Transductive propagation network for few-shot learning</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">A simple neural attentive metalearner</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohaninejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.03141</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munkhdalai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.00837</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">Meta networks. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">On first-order meta-learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Achiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.02999</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Tadam: Task dependent adaptive metric for improved few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Oreshkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">R</forename><surname>López</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lacoste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="719" to="729" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Few-shot image recognition by predicting parameters from activations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuille</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7229" to="7238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Optimization as a model for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Semi-supervised few-shot learning with maml</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rinu</forename><surname>Boney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Meta-Learning Workshop</title>
		<imprint>
			<biblScope unit="volume">2018</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sygnowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<idno type="arXiv">arXiv:1807.05960</idno>
		<title level="m">Meta-learning with latent embedding optimization</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A simple neural network module for relational reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Raposo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Malinowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4967" to="4976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">How does batch normalization help optimization?(no, it is not about internal covariate shift)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Santurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tsipras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ilyas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Madry</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.11604</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4077" to="4087" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Learning to learn: Metacritic networks for sample efficient learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
		<idno>abs/1706.09529</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">24 transductive inference and semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3630" to="3638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Towards sample efficient reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
