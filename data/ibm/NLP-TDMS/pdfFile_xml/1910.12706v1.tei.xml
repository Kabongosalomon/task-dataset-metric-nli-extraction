<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">INTERRUPTED AND CASCADED PERMUTATION INVARIANT TRAINING FOR SPEECH SEPARATION</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-10-28">28 Oct 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gene-Ping</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Information Engineering</orgName>
								<orgName type="institution">Nation Taiwan University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Szu-Lin</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Information Engineering</orgName>
								<orgName type="institution">Nation Taiwan University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao-Wen</forename><surname>Mao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Information Engineering</orgName>
								<orgName type="institution">Nation Taiwan University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hung-Yi</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Information Engineering</orgName>
								<orgName type="institution">Nation Taiwan University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin-Shan</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Information Engineering</orgName>
								<orgName type="institution">Nation Taiwan University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">INTERRUPTED AND CASCADED PERMUTATION INVARIANT TRAINING FOR SPEECH SEPARATION</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-10-28">28 Oct 2019</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T12:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Speech Separation</term>
					<term>Cocktail Party Prob- lem</term>
					<term>Permutation Invariant Training</term>
					<term>Label Ambiguity Prob- lem</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Permutation Invariant Training (PIT) has long been a stepping stone method for training speech separation model in handling the label ambiguity problem. With PIT selecting the minimum cost label assignments dynamically, very few studies considered the separation problem to be optimizing both the model parameters and the label assignments, but focused on searching for good model architecture and parameters. In this paper, we investigate instead for a given model architecture the various flexible label assignment strategies for training the model, rather than directly using PIT. Surprisingly, we discover a significant performance boost compared to PIT is possible if the model is trained with fixed label assignments and a good set of labels is chosen. With fixed label training cascaded between two sections of PIT, we achieved the stateof-the-art performance on WSJ0-2mix without changing the model architecture at all.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Speech Separation has always been a very important issue in speech processing specially in real world application scenarios, in which very often the considered speech signal is disturbed by some additional signals coming from other speakers, so needs to be properly separated. For example, when transcribing meeting verbatim, it was found that people usually speak over the discussions of other people.</p><p>Recent advances of deep learning methods have shown outstanding performance on speech separation with good examples including Deep-Clustering based models <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">2,</ref><ref type="bibr" target="#b3">3]</ref> and Conv-Tasnet <ref type="bibr" target="#b4">[4]</ref>. Most of such approaches first transform the time-domain mixture waveform into some feature map, such as the spectrogram or 2-D feature map encoded by 1-D convolution blocks. An often used approach is then to infer a mask for each individual speaker <ref type="bibr" target="#b5">[5,</ref><ref type="bibr" target="#b6">6,</ref><ref type="bibr" target="#b7">7,</ref><ref type="bibr" target="#b8">8,</ref><ref type="bibr" target="#b9">9,</ref><ref type="bibr" target="#b10">10]</ref>, and multiply the masks element-wise with the mixture feature map to obtain the individual feature maps. A recent work integrating different mixture representations and performing cross-domain joint clustering for mask-inference has also shown encouraging improvements <ref type="bibr" target="#b11">[11]</ref>.</p><p>However, these mask-inferring models often suffer from the label ambiguity problem. Suppose there are T mixed utterances in the training set, x i (t), i = 1, ..., T , each consisting of 2 individual signals x i (t) : [s i1 (t), s i2 (t)]. When the machine gives two output signals y i1 (t) and y i2 (t) for x i (t), there are two possible label assignments:</p><formula xml:id="formula_0">[y i1 (t) → s i1 (t), y i2 (t) → s i2 (t)] and [y i1 (t) → s i2 (t), y i2 (t) → s i1 (t)]</formula><p>. For computing the objective function for supervised learning, the label assignments are needed in evaluating the distances between the outputs and the ground truth. This is the label ambiguity problem. There are a total of 2 T permutations of the label assignments for all the T mixtures in the training set, or (N !) T permutations if each mixture includes N signals.</p><p>Although Deep Clustering seemed to have avoided this label ambiguity problem by optimizing the similarities between the embeddings of each t-f bin, it turns out that the mask inference branch achieves significantly better performance than the Deep Clustering branch in Chimera++ network <ref type="bibr" target="#b2">[2]</ref>. Therefore, for better performance the label ambiguity problem seems not avoidable for the moment. The goal of this paper is to find a good solution to this problem.</p><p>Permutation Invariant Training (PIT) has been popularly used to handle the above problem <ref type="bibr" target="#b12">[12,</ref><ref type="bibr" target="#b13">13]</ref>. In this paper we verify experimentally that PIT is not a good solution, because it dynamically assigns the label to each training mixture in an epoch, and such assignments are changed from epoch to epoch. We therefore propose various strategies for more flexible label assignment, and find there can be different ways to do better than PIT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">PERMUTATION INVARIANT TRAINING (PIT) AND ITS PROBLEMS</head><p>Permutation invariant training (PIT) was proposed to handle the label ambiguity problem, in which the loss function for each of the 2 (or N !) label assignments are computed for each mixture signal x i (t) and the one with the minimum loss is chosen. The model parameters may be updated after seeing every M mixtures based on the M loss functions computed from the minimum loss labels for the M mixtures, and the model updated T /M times in each epoch for the total of T mixtures. In the next epoch the minimum loss label as-signment for each mixture will be re-selected again. So PIT adopts dynamically selected rather then fixed label assignment from epoch to epoch.</p><p>There exists inevitable problems with PIT. For example, very often in the early stage of training the relatively poor output signals may make the loss values of the N ! possible label assignments very close in most of the training mixtures <ref type="bibr" target="#b14">[14]</ref>, which means the label assignment may be very random even if they were selected based on the minimum loss criterion. Also, it was found that even after 20 or 30 epochs the minimum loss label assignments for quite high percentage of training mixtures may be reversed in two consecutive epochs, and switched back-and-forth from epoch to epoch, which implies the model parameters may be tuned toward opposite directions repeatedly, or the learning paths may be quite rugged. These observations showed the inadequacy of PIT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">FLEXIBLE LABEL ASSIGNMENT STRATEGIES</head><p>Because of the above problems with the dynamic label assignments in PIT, we propose here to make the label assignment more flexible in various ways. A few example strategies are listed below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Energy-based Label Assignment</head><p>We evaluated the average energy per time frame (with silence automatically detected and deleted) for the two individual signals s i1 (t), s i2 (t) of each mixture x i (t). So we can simply assign the higher-energy ground truth to the first model output channel, and the lower-energy ground truth to the other, and this label assignment is fixed throughout all epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Speaker-embedding-based Label Assignment</head><p>We can also extract speaker embeddings (e.g. d-vector <ref type="bibr" target="#b15">[15]</ref>, ivector <ref type="bibr" target="#b16">[16]</ref> or x-vector <ref type="bibr" target="#b17">[17]</ref>) for each single speaker utterance s i1 (t) or s i2 (t) (assuming N = 2) for all training mixtures x i (t) in the training set with pre-trained speaker verification models. We then perform a constrained clustering to group all these T × 2 speaker embedding vectors for single speaker utterances in the training set into 2 clusters, with the constraint that the single speaker utterances which are mixed into a mixture in the training set must have speaker embedding vectors belonging to different clusters, since they are expected to be observed at the 2 different output channels of the separation model.</p><p>Assume c 1 , c 2 are the two clusters with mean vectors m 1 , m 2 , and s 1 , s 2 are the embedding vectors of two single speaker utterances s i1 (t), s i2 (t) of a training mixture. Let d(s, m) denotes the distance between vectors s and m. The above constraint can be easily realized by as-</p><formula xml:id="formula_1">signing [s 1 → c 1 , s 2 → c 2 ] if d(s 1 , m 1 ) + d(s 2 , m 2 ) &lt; d(s 1 , m 2 ) + d(s 2 , m 1 )</formula><p>, otherwise the other way, and updating the mean vectors after all single speaker utterances in the training set are assigned. This process can be iterated until converged. With the clustering results, we simply assign the single speaker utterances in cluster 1 to the first model output channel, and the other to the second, and this assignment is fixed throughout all epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Fixed Label Assignments Obtained with PIT</head><p>In PIT the label assignment for each mixture can be dynamically changed from epoch to epoch, which may be a source of the problem. Here the huge number of assignment permutations are in fact an additional set of unknown parameters to be learned, and as a result with updated model parameters the label assignments can be changed. So we propose to train a model with PIT for L epochs first, and record the label assignments for each mixture at the L-th epoch. These label assignments can be considered as good enough labels for training model parameters. So we re-initialize the model parameters and train a new separation model, but with the labels fixed as obtained above with L epochs of PIT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Interrupted PIT with Inserted Section of Fixed Label</head><p>Training PIT followed by fixed label training as proposed above in Section 3.3 sounds reasonable, but the set of fixed labels obtained with L epochs of PIT may become inadequate after the model parameters are properly updated by the fixed label training. Therefore, we can perform a new section of PIT again to allow the label assignments to be changed dynamically again after the section of fixed label training. This may solve the poor initialization problem of PIT, that is, during the early stage of training PIT the relatively poor outputs make the label assignments more or less random. This is because here with the fixed label training, the second section of PIT is initialized with a set of much better model parameters, and thus has the potential to further boost the model performance. In this way, the training process actually includes three cascaded sections: (PIT)-(fixed label training)-(PIT), or the PIT process is interrupted after the first section of L epochs and inserted with the second section of fixed label training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental Setup</head><p>We evaluated the proposed approaches on the publicly available dataset WSJ0-2mix <ref type="bibr" target="#b0">[1]</ref>, which was derived from WSJ0 corpus. The training objective is to maximize the signal-todistortion ratio (SDR) <ref type="bibr" target="#b18">[18]</ref> of the predicted separated speechŝ against the ground truth s, SDR(s,ŝ) = 10 log 10 s,ŝ 2</p><formula xml:id="formula_2">s 2 ŝ 2 − s,ŝ 2 ,<label>(1)</label></formula><p>where ·, · represents the dot product and s 2 = s, s denotes the signal power. The results are primarily reported in SDR improvements, SDR i , which is the SDR values compared to those of the mixture signals against the ground truth.</p><p>The goal here is to analyze the training process and label assignments, so we simply utilized the well known second version of Tasnet <ref type="bibr" target="#b4">[4]</ref> previously proposed as the separation model for easier comparison of results. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Label Assignment Switches for PIT</head><p>Here "label assignment switch" refers to the situation that the label assignment of the same mixture was different within two consecutive epochs. We use this to analyze the problems of PIT. We trained a separation model with PIT using the training set. <ref type="figure" target="#fig_0">Fig.1(a)</ref> shows the total number (and percentage) of the label assignment switches out of the T training mixtures on the left scale at every epoch compared to the immediate previous epoch. It can be seen that there can be thousands (or up to 20%) of switches and abrupt jumps before epoch 35, for example between epochs 7 and 20, and epochs 31 and 35. Also shown are the SDR i values achieved with the validation set at each epoch. We can see SDR i drops very often synchronized with jumps in label switches. It was not until epoch 36 did the SDR i values rise stably, and the label assignment switch reduce quickly at the same time.</p><p>This verified those mentioned earlier that inconsistent label assignments caused unstable training, specially in the early stage of training. This is why the various flexible label assignment strategies mentioned above make sense.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Fixed Label Training</head><p>Similar SDR i values obtained with fixed label training with the fixed labels obtained by the energy-based approach men-tioned in Section 3.1 are plotted as curve (a) in <ref type="figure" target="#fig_3">Fig.3</ref>, similarly by the speaker-embedding-based approach mentioned in Section 3.2 as curve (b) in <ref type="figure" target="#fig_3">Fig.3</ref>. Both of them are significantly lower (converged to 14.17 and 15.18 dB respectively) than that obtained with PIT in curve (c) of <ref type="figure" target="#fig_3">Fig.3</ref>, which is exactly the same curve in <ref type="figure" target="#fig_0">Fig.1(a)</ref> converged to 16.17 dB. This shows fixed labels alone were inadequate, and PIT is clearly better even with unstable training due to serious label switches. So we next tested a different way of obtaining the fixed labels, by PIT after L epochs as mentioned in Section 3.3. The results for L = 1, 10, 20, 30, ..., 100 are depicted in <ref type="figure" target="#fig_2">Fig.2</ref>, where the red and blue curves are respectively for validation and test sets, all with 100 epochs of training. We can see as long as L ≥ 10 the training converged to SDR i values significantly higher than the baseline of 16.17 dB achieved by PIT (curve (c) in <ref type="figure" target="#fig_3">Fig.3)</ref>, with best result of 17.66 dB achieved at L = 80, for the validation set. The two curves for validation and test are in general parallel.</p><p>The vertical bars in <ref type="figure" target="#fig_2">Fig.2</ref> are the number of label assignments out of the T training mixtures which were different from that for L = 80. We see for L = 90 or 100 only a small number of labels were different, but these different labels made differences in the finally converged SDR i values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">PIT cascaded with Fixed Label Training</head><p>Curves (d)(e) of <ref type="figure" target="#fig_3">Fig.3</ref> are for fixed label training, with the labels fixed at those obtained with L = 100 and L = 80 epochs of PIT respectively. Here because the first 100 epochs were performed with PIT to obtain the fixed labels, and the next 100 epochs (101 to 200) were performed with fixed label training. This is why this curve (e) is plotted over 101 to 200 epochs and converged to 17.66 dB, which is the value at L = 80 in <ref type="figure" target="#fig_2">Fig.2</ref>. Curve (d) (actually epoch 101 to 200) is plotted over 1 to 100 epochs only for better comparison with those from other methods.</p><p>As mentioned in Section 3.4, we can performed an additional section of PIT at the end of curve (e), allowing the labels to be changed for another 100 epochs, or over epochs 201 to 300. The result is curve (f) of <ref type="figure" target="#fig_3">Fig.3</ref>, converged at 17.99 dB for SDR i . The cascaded three sections of (PIT)-(fixed label training)-(PIT) is actually curves (c)(e)(f) in <ref type="figure" target="#fig_3">Fig.3</ref>  The number (and percentage) of label assignment switches for the third section of PIT, or curve (f) for epochs 201 to 300 in <ref type="figure" target="#fig_3">Fig.3</ref>, are also plotted in <ref type="figure" target="#fig_0">Fig.1(b)</ref>, to be compared with those in <ref type="figure" target="#fig_0">Fig.1(a)</ref> for the first section of PIT, or curve (c) over epochs 1-100 in <ref type="figure" target="#fig_3">Fig.3</ref>, together with the SDR i values in <ref type="figure" target="#fig_3">Fig.3</ref>. Both <ref type="figure" target="#fig_0">Fig.1(a)</ref>(b) are for 100 epochs of PIT, except <ref type="figure" target="#fig_0">Fig.1(a)</ref> started with a very poor model so with large numbers and abrupt jumps of label assignment switches, while <ref type="figure" target="#fig_0">Fig.1(b)</ref> started with a well-trained model, so with well reduced and smoothed label assignment switches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Summary of the Results</head><p>We summarize the different approaches analyzed here in <ref type="table">Table 1</ref>, in which the rows labeled by (a)-(f) correspond to curves (a)-(f) in <ref type="figure" target="#fig_3">Fig.3</ref>. The column of "Labels" indicated whether the label assignments are fixed, dynamic (dyn), or with cascaded (csc) sections of PIT and fixed labels. The SDR i values are those finally converged to for validation and test sets, and the last column are the percentages of labels out of all the T training mixtures for which the fixed labels or finally obtained labels are different from the best results (epoch 300 at the end of curve (f)). We see by cascading with a section of fixed labels the validation SDR i was improved from 16.17 dB of PIT (100 epoch) in row (c) to 17.99 dB of cascade of three sections (300 epoch) in row (f). We also see the high correlation between the SDR i values and percentages of different labels in the last two columns verifying the point here.</p><p>We also compare the results with those of prior works in <ref type="table" target="#tab_3">Table 2</ref>, all data on the test set for comparison, including scale-invariant signal-to-noise ratio improvement (SI-SNR i ) <ref type="bibr" target="#b6">[6]</ref> and SDR i in dB. Row (a) is for the baseline separation model TasNet-v2 <ref type="bibr" target="#b4">[4]</ref> we used throughout this work. Rows (b)(c) are respectively the latest version of TasNet and our implementation using Prob-PIT <ref type="bibr" target="#b14">[14]</ref> with TasNet-v2. Row (d) is for our previous work of cross-domain joint clustering which was not used here at all. Row (e)(f) are for the approaches proposed here, corresponding to curves (e)(f) in <ref type="figure" target="#fig_3">Fig.3</ref>. We <ref type="table">Table 1</ref>: Summary of all approaches analyzed here. Row (a)-(f) corresponds to curves (a)-(f) in <ref type="figure" target="#fig_3">Fig.3</ref>. SDRi are the finally converged values on the validation set. The last column are the percentages of label assignment which are different from that in row (f).  see decent improvement by the proposed approach (cascaded 3 sections) even without using the cross-domain approach in row(d).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Approaches</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSION</head><p>In this paper, we propose to train a separation model by interrupted and cascaded PIT with a fixed label training section inserted in the middle, whose label assignments are obtained by the first section of PIT training. State-of-the-art performance of SDR i = 17.7 dB was achieved on the WSJ0-2mix test set. This verified that the label assignments obtained by PIT are good for fixed label training, and a well trained model is also beneficial for further PIT training.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Number (and percentage) of label assignment switches vs. validation SDR i at each epoch of PIT: (a) PIT with poor model initialization. (b) PIT with good model initialization in the 3 rd section of cascade.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 :</head><label>2</label><figDesc>SDRi achieved on validation/testing sets and number of different label assignments compared to L=80 with fixed label assignments obtained after L epochs of PIT.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 :</head><label>3</label><figDesc>SDRi scores on the validation set at each epoch for different training approaches: (a)(b)(d)(e) fixed labels, (c)(f) dynamic labels (PIT), (e)(f) cascaded 2 nd and 3 rd sections.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>, giving a result 1.82 dB higher than PIT (17.99 − 16.17 = 1.82).</figDesc><table><row><cell></cell><cell>18</cell><cell></cell><cell></cell><cell></cell><cell cols="2">(d)17.31</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">(e)17.66</cell><cell></cell><cell></cell><cell></cell><cell>(f)17.99</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">(c)16.17</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Valid SDRi (dB)</cell><cell>6 9 12 15</cell><cell></cell><cell></cell><cell></cell><cell cols="2">(b)15.18 (a)14.17</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="6">(a) fixed labels, Energy-Based (b) fixed labels, Spk-Emb-Based (d-vector) (c) dynamic labels, PIT (d) fixed labels, from PIT (L=100) (e) 2 nd section : fixed labels, from PIT (L=80) (f) 3 rd section : PIT after the 2 nd section</cell></row><row><cell></cell><cell>3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">(c) (e) (f)</cell><cell cols="4">Cascaded: PIT -fixed -PIT</cell><cell></cell></row><row><cell></cell><cell>0</cell><cell>20</cell><cell>40</cell><cell>60</cell><cell>80</cell><cell>100</cell><cell>120</cell><cell>140</cell><cell>160</cell><cell cols="2">180</cell><cell>200</cell><cell>220</cell><cell>240</cell><cell>260</cell><cell>280</cell><cell>300</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Epoch</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>SI-SNRi and SDRi (in test set) compared to different prior works tested on WSJ0-2mix dataset. "*" indicates our implementation not written in the original paper.</figDesc><table><row><cell></cell><cell>Approaches</cell><cell cols="2">Params SI-SNRi</cell><cell>SDRi</cell></row><row><cell>prior works</cell><cell>(a) TasNet-v2 [4] (b) Conv-TasNet [19] (c) Prob-PIT [14] (d) Yang et al. [11]</cell><cell>8.8M 5.1M 8.8M 10M</cell><cell>14.6 dB 15.3 dB 15.9  *  dB 16.6 dB</cell><cell>15.0 dB 15.6 dB 16.2  *  dB 16.9 dB</cell></row><row><cell cols="2">(e) Cascaded: (PIT)-(fx)</cell><cell>8.8M</cell><cell>17.1 dB</cell><cell>17.4 dB</cell></row><row><cell cols="2">(f) Cascaded: (PIT)-(fx)-(PIT)</cell><cell>8.8M</cell><cell>17.5 dB</cell><cell>17.7 dB</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deep clustering: Discriminative embeddings for segmentation and separation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuo</forename><surname>John R Hershey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">Le</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinji</forename><surname>Roux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Watanabe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech and Signal Processing</title>
		<imprint>
			<publisher>ICASSP</publisher>
			<biblScope unit="page">2016</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="page" from="31" to="35" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Alternative objective functions for deep clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhong-Qiu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">Le</forename><surname>Roux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">R</forename><surname>Hershey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="686" to="690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Deep learning based phase reconstruction for speaker separation: A trigonometric perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhong-Qiu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deliang</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.09010</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Tasnet: Surpassing ideal time-frequency masking for speech separation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nima</forename><surname>Mesgarani</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.07454</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">On training targets for supervised speech separation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arun</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deliang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">speech, and language processing</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1849" to="1858" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Speakerindependent speech separation with deep attractor network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nima</forename><surname>Mesgarani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Speech, and Language Processing</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="787" to="796" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">End-to-end speech separation with unfolded iterative phase reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhong-Qiu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">Le</forename><surname>Roux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deliang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">R</forename><surname>Hershey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.10204</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Tasnet: time-domain audio separation network for real-time, single-channel speech separation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nima</forename><surname>Mesgarani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="696" to="700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Single-channel multi-speaker separation using deep clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuf</forename><surname>Isik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">Le</forename><surname>Roux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinji</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">R</forename><surname>Hershey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.02173</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep attractor network for single-microphone speaker separation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nima</forename><surname>Mesgarani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="246" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Improved Speech Separation with Time-and-Frequency Cross-Domain Joint Embedding and Clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gene-Ping</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-I</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hung-Yi</forename><surname>Tuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shan Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1363" to="1367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Permutation invariant training of deep models for speaker-independent multi-talker speech separation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morten</forename><surname>Kolbaek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng-Hua</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesper</forename><surname>Jensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="241" to="245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Multitalker speech separation with utterance-level permutation invariant training of deep recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morten</forename><surname>Kolbaek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng-Hua</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesper</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morten</forename><surname>Kolbaek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng-Hua</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesper</forename><surname>Jensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on Audio, Speech and Language Processing (TASLP)</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1901" to="1913" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Probabilistic Permutation Invariant Training for Speech Separation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Midia</forename><surname>Yousefi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soheil</forename><surname>Khorram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">H L</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4604" to="4608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Generalized end-to-end loss for speaker verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Papir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ignacio</forename><surname>Lopez-Moreno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4879" to="4883" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Front-end factor analysis for speaker verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dehak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Kenny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dehak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dumouchel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ouellet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Audio, Speech, and Language Processing</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="788" to="798" />
			<date type="published" when="2011-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">X-vectors: Robust dnn embeddings for speaker recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Snyder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Garcia-Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Povey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Khudanpur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<date type="published" when="2018-04" />
			<biblScope unit="page" from="5329" to="5333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Performance measurement in blind audio source separation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emmanuel</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rémi</forename><surname>Gribonval</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cédric</forename><surname>Févotte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on audio, speech, and language processing</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1462" to="1469" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Conv-tasnet: Surpassing ideal time-frequency magnitude masking for speech separation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nima</forename><surname>Mesgarani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Speech, and Language Processing</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1256" to="1266" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
