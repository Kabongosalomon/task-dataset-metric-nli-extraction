<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">IEEE TRANSACTION ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE 1 PAC-Bayesian Meta-learning with Implicit Prior and Posterior</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-07-31">31 Jul 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Cuong</forename><surname>Nguyen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thanh-Toan</forename><surname>Do</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustavo</forename><surname>Carneiro</surname></persName>
						</author>
						<title level="a" type="main">IEEE TRANSACTION ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE 1 PAC-Bayesian Meta-learning with Implicit Prior and Posterior</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2020-07-31">31 Jul 2020</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-PAC Bayes</term>
					<term>meta-learning</term>
					<term>few-shot learning</term>
					<term>transfer learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We introduce a new and rigorously-formulated PAC-Bayes few-shot meta-learning algorithm that implicitly learns a prior distribution of the model of interest. Our proposed method extends the PAC-Bayes framework from a single task setting to the few-shot learning setting to upper-bound generalisation errors on unseen tasks and samples. We also propose a generative-based approach to model the shared prior and the posterior of task-specific model parameters more expressively compared to the usual diagonal Gaussian assumption. We show that the models trained with our proposed meta-learning algorithm are well calibrated and accurate, with state-of-the-art calibration and classification results on few-shot classification (mini-ImageNet and tiered-ImageNet) and regression (multi-modal task-distribution regression) benchmarks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>O NE unique ability of humans is to quickly learn new tasks with only a few training examples. This is due to the fact that humans tend to exploit prior experience to facilitate the learning of new tasks. Such exploitation is markedly different from conventional machine learning approaches, where no prior knowledge (e.g. training from scratch with random initialisation) <ref type="bibr" target="#b16">[15]</ref>, or weak prior knowledge (e.g., fine tuning from pre-trained models) <ref type="bibr" target="#b40">[39]</ref> are employed to learn a new task. This motivates the development of novel learning algorithms that can effectively encode the knowledge learnt from training tasks, and exploit that knowledge to quickly adapt to future tasks <ref type="bibr" target="#b22">[21]</ref>.</p><p>Prior knowledge can be helpful for future learning only if all tasks are assumed to be distributed according to a latent task distribution. Learning this latent distribution is, therefore, useful for solving an unseen task, even if the task contains a limited number of training examples. Many approaches have been proposed and developed to achieve this goal, namely: multi-task learning <ref type="bibr" target="#b9">[9]</ref>, domain adaptation <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b8">8]</ref> and meta-learning <ref type="bibr" target="#b45">[44,</ref><ref type="bibr" target="#b51">50]</ref>. Among these, meta-learning has flourished as one of the most effective methods due to its ability to leverage the knowledge learnt from many training tasks to quickly adapt to unseen tasks.</p><p>Recent advances in meta-learning have produced stateof-the-art results in many benchmarks of few-shot learning data sets <ref type="bibr" target="#b12">[12,</ref><ref type="bibr" target="#b30">29,</ref><ref type="bibr" target="#b38">37,</ref><ref type="bibr" target="#b43">42,</ref><ref type="bibr" target="#b44">43,</ref><ref type="bibr" target="#b47">46,</ref><ref type="bibr" target="#b55">54]</ref>. Learning from a few training examples is often difficult and easily leads to over-fitting, especially when no model uncertainty is taken into account. This issue has been addressed by several recent probabilistic meta-learning approaches that incorporate model uncertainty into prediction, e.g., LLAMA (based on Laplace method) <ref type="bibr" target="#b18">[17]</ref>, or PLATIPUS <ref type="bibr" target="#b12">[12]</ref>, Amortised Bayesian Meta-learner (ABML) <ref type="bibr" target="#b37">[36]</ref> and VERSA <ref type="bibr" target="#b17">[16]</ref> that use variational inference (VI). However, these works have not thoroughly investigated the generalisation errors for unseen tasks and unseen samples, resulting in limited theoretical generalisation guarantees. Moreover, most of these papers are based on variational functions that may not represent well the richness of the underlying distributions. For instance, a common choice for the variational function relies on the diagonal Gaussian distribution, which can potentially worsen the prediction accuracy given its limited representability.</p><p>In this paper, we address the two problems listed above with the following technical novelties: (i) derivation of a rigorous upper-bound for the generalisation errors on unseen tasks and samples of few-shot learning setting based on the PAC-Bayes framework, and (ii) proposal of a novel implicit modelling approach to expressively represent the learning of unseen tasks. Our evaluation shows that the models trained with our proposed meta-learning algorithm is at the same time well calibrated and accurate, with stateof-the-art results in few-shot classification (mini-ImageNet and tiered-ImageNet) and regression (multi-modal taskdistribution regression) benchmarks in terms of accuracy, Expected Calibration Error (ECE) and Maximum Calibration Error (MCE).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Our paper is related to Bayesian few-shot meta-learning techniques that have been developed to incorporate uncertainty into model estimation. LLAMA <ref type="bibr" target="#b18">[17]</ref> employs the Laplace method to extend the deterministic estimation assumed in MAML to a Gaussian distribution. However, the need to estimate and invert the Hessian matrix makes this approach computationally challenging for large-scale models, such as deep neural networks. Variational inference (VI) addresses such scalability issue -remarkable examples of VI-based methods are PLATIPUS <ref type="bibr" target="#b13">[13]</ref>, BMAML <ref type="bibr" target="#b53">[52]</ref>, ABML <ref type="bibr" target="#b37">[36]</ref> and VERSA <ref type="bibr" target="#b17">[16]</ref>. Although these VI-based approaches have demonstrated impressive results in regres-θ w y <ref type="bibr">(t)</ref> x <ref type="bibr">(t)</ref> y <ref type="bibr">(v)</ref> x (v) <ref type="figure" target="#fig_7">Fig. 1</ref>: Meta-learning graphical model with (x (.) , y (.) ) as input and output data of a task, w as the model parameter for that task, and θ as the shared prior of w.</p><p>sion, classification as well as reinforcement learning, they do not provide any theoretical guarantee on generalisation errors for unseen tasks and unseen samples within a task. Moreover, the overly-simplified family of diagonal Gaussian distributions that model task-specific model parameters used in most of these works limits the expressiveness of the variational approximation, resulting in a less accurate prediction.</p><p>Our work is also related to the PAC-Bayes framework used in meta-learning that upper-bounds generalisation errors with certain confidence levels <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b36">35]</ref>. The main difference between these previous works and ours is at the generalisation bounds for unseen queried examples of a task. To obtain this bound, MLAP -a previous workapplied the conventional PAC-Bayes bound on a "tuple of hypothesis" consisting of the shared prior and task-specific parameter, while we derive a different bound without using any hypothesis tuple. In addition, these previous works follow non-Bayesian approaches to learn the shared prior 1 and task-specific model parameters simultaneously. They are, therefore, more applicable for multi-task learning setting <ref type="bibr" target="#b2">[3,</ref><ref type="bibr">Section 4.4]</ref>, in which the learning is carried out on a small number of tasks where each task consists of thousands of training examples. In contrast, we follow the Bayesian approach to formulate meta-learning as an Expectation-Maximisation (EM) algorithm. In the E-step, the shared prior is fixed, and the posterior of task-specific parameter is obtained through variational Bayes inference. In the Mstep, the posterior of task-specific parameter obtained in the E-step is used to optimise the shared prior. Due to the nature of EM that learns in two steps, our proposed method is more suitable for meta-learning, especially few-shot learning, than other PAC-Bayes learning approaches <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b36">35]</ref> in which the learning is performed on millions of training tasks where each task consists of a few training examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODOLOGY</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Few-shot meta-learning</head><p>We use the notation of task environment to describe the unknown distribution p(T ) over a family of tasks <ref type="bibr" target="#b4">[5]</ref>. Each task T i sampled from p(T ) is indexed by i ∈ {1, . . . , T } and associated with a dataset D i consisting of two disjoint data 1. The usage of posterior in this paper does not always follow the Bayesian connotation, but depends on the context. In PAC-Bayes, the posterior and prior does not need to be correlated through the likelihood function as in standard Bayesian inference. subsets: an observable support set D </p><formula xml:id="formula_0">(t) i = {(x (t) ij , y (t) ij )} m (t) i j=1 (x ∈ R d is</formula><formula xml:id="formula_1">(v) i = {(x (v) ij , y (v) ij )} m (v) i j=1 ⊂ D (v)</formula><p>i . The aim of few-shot learning is to accurately predict the output y</p><formula xml:id="formula_2">(v) ij of any queried input x (v) ij sampled from the query set D (v)</formula><p>i , when being given a small support set D (t) i . We rely on a hierarchical model shown in <ref type="figure" target="#fig_7">Figure 1</ref>, where w i represents the model parameter for task T i , and θ denotes the metaparameter shared across all tasks <ref type="bibr" target="#b18">[17]</ref>.</p><p>The objective is to estimate the true posterior of the metaparameter θ defined as:</p><formula xml:id="formula_3">ρ(θ) = E Di∼p(T ) E (x (v) ij ,y (v) ij )∼D (v) i p θ x (t) i,1:m (t) i , y (t) i,1:m (t) i , x (v) i , y (v) i .<label>(1)</label></formula><p>However, the posterior is intractable, and hence, we rely on variational inference -an approximate inference technique -to estimate the posterior. The alternative objective is to find the parameter of a variational distribution q(θ; ψ), parameterised by ψ, which minimises the Kullback-Leibler (KL) divergence between the approximate and the true posterior:</p><formula xml:id="formula_4">min ψ D KL [q(θ; ψ) ρ(θ)] = min ψ E q(θ;ψ) [ln q(θ; ψ) − ln ρ(θ)] .</formula><p>(2) The negative logarithm of the true posterior in (2) can be upper-bounded by Jensen's inequality:</p><formula xml:id="formula_5">− ln ρ(θ) ≤ E Di∼p(T ) E (x (v) ij ,y (v) ij )∼D (v) i − ln p θ x (t) i,1:m (t) i , y (t) i,1:m (t) i , x (v) i , y (v) i .<label>(3)</label></formula><p>Note that the negative log-posterior in the expectation of (3) can be expanded using Bayes' rule:</p><formula xml:id="formula_6">− ln p θ x (t) i,1:m (t) i , y (t) i,1:m (t) i , x (v) i , y (v) i = − ln p y (v) ij x (v) ij , x (t) i,1:m (t) i , y (t) i,1:m (t) i , θ − ln p(θ)− − m (t) i j=1 ln p y (t) i x (t) i , θ + const. w.r.t. θ<label>(4)</label></formula><p>The two negative log-likelihood terms in Eq. (4) can be upper-bounded by Jensen's inequality:</p><formula xml:id="formula_7">− ln p y (v) ij |x (v) ij , x (t) i,1:m (t) i , y (t) i,1:m (t) i , θ ≤ L (v) ij (5) − m (t) i j=1 ln p y (t) i |x (t) i , θ ≤ L (t) i<label>(6)</label></formula><p>where:</p><formula xml:id="formula_8">L (v) ij = E q(w;λi) − ln p(y (v) ij |x (v) ij , w i )<label>(7)</label></formula><formula xml:id="formula_9">L (t) i = D KL [q(w; λ i ) p(w; θ)] − − m (t) i k=1 E q(w;λi) ln p y (t) ik |x (t) ik , w i ,<label>(8)</label></formula><p>and q(w; λ i ) is a variational distribution for p(w|x i,1:m (t) i , y i,1:m (t) i , θ). Given the results in (3), (4), <ref type="bibr" target="#b4">(5)</ref> and <ref type="formula" target="#formula_7">(6)</ref>, we can upperbound the KL divergence in <ref type="bibr" target="#b1">(2)</ref>. Hence, instead of minimising the KL divergence in (2), we minimise its upper-bound, resulting in the following objective function:</p><formula xml:id="formula_10">min ψ E Di∼p(T ) E (x (v) ij ,y (v) ij )∼D (v) i E q(θ;ψ) L (v) ij + L (t) i + + D KL [q(θ; ψ) p(θ)] .<label>(9)</label></formula><p>To evaluate the cost function in <ref type="bibr" target="#b9">(9)</ref>, we need to estimate the variational posterior q(w; λ i ) of the task-specific model parameter w i . The purpose of q(w; λ i ) is to approximate the true posterior of w i given its prior θ and observable data D</p><formula xml:id="formula_11">(t) i , which is p(w|D (t) i , θ). In Bayesian learning, p(w|D (t) i , θ)</formula><p>is obtained through Bayes' rule, and is often intractable, especially when the model used is a deep neural network. Hence, in practice, we use q(w; λ i ) to approximate p(w|D (t) i , θ). One way to obtain q(w; λ i ) is to use VI, which minimises the KL divergence between the two distributions:</p><formula xml:id="formula_12">λ * i = arg min λi D KL q(w; λ i ) p(w i |x (t) i,1:m (t) i , y (t) i,1:m (t) i , θ) = arg min λi L (t) i + m (t) i k=1 ln p(y (t) ik |x (t) ik , θ) const. wrt λi , (10) where L (t) i is defined in Eq. (8).</formula><p>The resulting cost function (excluding the constant term), L (t) i , is often known as the variational free energy (VFE). Exactly minimising VFE in (10) is computationally challenging. We, therefore, rely on the following truncated gradient descent, consisting of a single step optimisation with θ as the initialisation:</p><formula xml:id="formula_13">λ i ← θ − α t ∇ λi L (t) i ,<label>(11)</label></formula><p>where α t is the learning rate and the extension to a larger number of steps is trivial. Given q(w; λ i ) obtained in <ref type="bibr" target="#b10">(10)</ref>, the optimisation in (9) is analogous to the Expectation-Maximisation algorithm: <ref type="bibr" target="#b12">(12)</ref> where:</p><formula xml:id="formula_14">E-step: λ i = arg min λi L (t) i M-step: min ψ E Di∼p(T ) E q(θ;ψ) L (v) i + L (t) i + + D KL [q(θ; ψ) p(θ)] ,</formula><formula xml:id="formula_15">L (v) i = E (x (v) ij ,y (v) ij )∼D (v) i L (v) ij .<label>(13)</label></formula><p>To carry out the EM algorithm in <ref type="bibr" target="#b12">(12)</ref>, we need to evaluate the generalisation errors, denoted as the expectation of L</p><formula xml:id="formula_16">(v) i + L (t) i over unseen tasks D ∼ p(T ), with D / ∈ {D i } T i=1 , and unseen queried examples (x (v) ij , y (v) ij ) ∼ (D (v) i \ D (v) i ).</formula><p>In the following subsection, we present a novel PAC-Bayes bound derived for meta-learning to theoretically guarantee the generalisation errors in the M-step of (12).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">PAC-Bayes generalisation bound</head><p>The novel bound on the generalisation error for the losses in (12) is shown in Theorem 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 1.</head><p>For δ ∈ (0, 1] and τ &gt; 1, the general error of fewshot meta-learning (or, first term in <ref type="bibr" target="#b12">(12)</ref>) can be upper-bounded as:</p><formula xml:id="formula_17">Pr E q(θ;ψ) E Di∼p(T ) L (v) i + L (t) i ≤ ≤ 1 T T i=1 E q(θ;ψ) L (v) i + L (t) i + R i + R 0 ≥ 1 − δ,</formula><p>where:</p><formula xml:id="formula_18">L (v) i = 1 m (v) i m (v) i j=1 L (v) ij<label>(14)</label></formula><formula xml:id="formula_19">R 0 = D KL [q(θ; ψ) p(θ)] + ln τ T δ 2(T − 1)<label>(15)</label></formula><formula xml:id="formula_20">R i = E q(θ;ψ) [D KL [q(w; λ i ) p(w; θ)]] + τ T (τ −1)δ ln m (v) i 2(m (v) i − 1)</formula><p>.</p><p>Proof sketch. The proof is divided into 3 steps. Firstly, we consider a task as a sample and apply the conventional PAC-Bayes bound (shown in Theorem 2 in Supplemental Material A) to obtain a generalisation bound for unseen tasks, resulting in Corollary 1. Secondly, we derive a generalisation bound for the unseen queried examples within each task as shown in Lemma 1. Finally, we combine the two results in steps 1 and 2 to obtain the generalisation bound of interest. Please refer to the Supplemental Material A for details.</p><p>The PAC-Bayes bound in Theorem 1 upper-bounds the true error by three terms: (i) the empirical error on the training subset D (t) i and the query subset D (v) i of the training tasks, (ii) the regularisation R 0 for the generalisation error due to unseen query tasks, and (iii) the regularisation R i for the generalisation error due to unseen queried samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Remark 1. Both Theorem 1 and MLAP [3] -also a meta-learning method based on PAC-Bayes theory -aim to upper-bound the same generalisation error. The main difference between the two methods is at the PAC-Bayes bound derived for unseen queried examples of each single task (Lemma 1 in the Supplemental</head><p>Material A of this paper versus the first step in sub-section A1 of <ref type="bibr" target="#b2">[3]</ref>). To derive the bound for unseen queried examples of a task, MLAP uses a "tuple hypothesis" (θ, w i ) to directly apply the conventional PAC-Bayes bound (Theorem 2 in Supplemental Material A) to obtain the bound. In contrast, we do not use any "tuple hypothesis", but derive a specialised bound for unseen queried as shown in Lemma 1 presented in Supplemental Material A. The main difference between the two bounds is, therefore, at the balance between task regularisation and validation sample size in R i . MLAP includes KL divergence between q(θ; ψ) and p(θ) (corresponding to Q and P if using MLAP's notations) to regularise according to the hyper-prior p(θ). Our derived bound does not include that KL divergence, but has a higher weight on the number of samples in the task-specific validation subset. In practice, the KL divergence between q(θ; ψ) and p(θ) is often very large (in our implementation, it is in the magnitude of 10 5 ). Hence, our proposed bound is practically tighter than MLAP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Remark 2. One limitation of Theorem 1 is the assumption of bounded loss which restricts the loss function within [0, 1].</head><p>Although there are several works that extend PAC-Bayes bound for unbounded losses <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b10">10,</ref><ref type="bibr" target="#b14">14]</ref>, their formulations still require strong assumptions on the moment generating function of the unbounded losses. In this work, our main focus is to provide a theoretical generalisation guarantee for meta-learning using PAC-Bayes theory. Such extension is not necessary since in the implementation our loss is clipped to be within [0, 1].</p><p>Instead of minimising the loss in (12), we minimise its upper-bound shown in Theorem 1. The EM-based objective function in <ref type="bibr" target="#b12">(12)</ref> can, therefore, be changed to:</p><formula xml:id="formula_22">E-step: λ i = arg min λi L (t) i M-step: min ψ 1 T T i=1 E q(θ;ψ) L (v) i + L (t) i + R i + R 0 + + D KL [q(θ; ψ) p(θ)] .<label>(17)</label></formula><p>By employing a gradient-based optimisation in the Estep, we can simplify further the optimisation of the M-step in <ref type="bibr" target="#b18">(17)</ref>. The derivative of L (t) i w.r.t. the meta-parameter ψ can be expressed as:</p><formula xml:id="formula_23">∂L (t) i ∂ψ = ∂L (t) i ∂λ i 0 ∂λ i ∂θ + ∂L (t) i ∂θ ∂θ ∂ψ = ∂L (t) i ∂θ ∂θ ∂ψ .<label>(18)</label></formula><p>Hence, instead of including the whole loss function L (t) i in the M-step, we can include only the terms of L (t) i containing θ. This simplifies the objective function for the EM metalearning, resulting in:</p><formula xml:id="formula_24">E-step: λ i = arg min λi L (t) i M-step: min ψ 1 T T i=1 E q(θ;ψ) L (v) i + D KL [q(w; λ i ) p(w; θ)] + R i + R 0 + D KL [q(θ; ψ) p(θ)] .<label>(19)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Meta-learning algorithms with implicit prior and posterior</head><p>In probabilistic statistics, the shared prior of task-specific model parameter, p(w; θ), represents a modelling assumption, and the variational posterior of task-specific model parameter, q(w; λ i ), is a flexible function that can be adjusted to achieve a good trade-off between performance and complexity. In general, p(w; θ) and q(w; λ i ) can be modelled using two general types of probabilistic models: prescribed and implicit <ref type="bibr" target="#b11">[11]</ref>. For example, ABML <ref type="bibr" target="#b37">[36]</ref> and VAMPIRE <ref type="bibr" target="#b32">[31]</ref> are prescribed approaches where both distributions are assumed to be diagonal Gaussians. Although this modelling approach is simple, and easy to be implemented, it requires to carefully re-weight the "reconstruction" loss and KL loss in the variational free energy L (t)</p><p>i <ref type="bibr" target="#b20">[19]</ref>, potentially resulting in a sub-optimal solution. Another workaround solution is to anneal the weight between these two losses <ref type="bibr" target="#b7">[7]</ref>. Nevertheless, the approximation using diagonal Gaussian distributions is still inexpressive, resulting in a poor estimation. Therefore, in this paper, we present the implicit modelling approach to expressively represent p(w; θ) and q(w; λ i ).</p><p>Both distributions p(w; θ) and q(w; λ i ) are now defined at a more fundamental level whereby data is generated through a stochastic mechanism without specifying parametric distributions. We use a parameterised model (i.e., a generator G represented by a deep neural network) to model the sample generation:</p><formula xml:id="formula_25">w i ∼ p(w; θ) ⇔ w i = G(z; θ), z ∼ p(z|β i ) w i ∼ q(w; λ i ) ⇔ w i = G(z; λ i ), z ∼ p(z|β i ),<label>(20)</label></formula><p>where z ∈ R Z is the latent noise, β i is the parameter of the latent noise distribution p(z|β i ), which is learnt from the unlabelled data x</p><formula xml:id="formula_26">(t) i,1:m (t) i of the support set D (t)</formula><p>i . One of the challenges to model p(z|β i ) is the permutation invariance between training examples of the corresponding task T i . We, therefore, propose to use a pooling encoder <ref type="bibr" target="#b54">[53]</ref> to aggregate the output of unlabelled data:</p><formula xml:id="formula_27">β i = 1 m (t) i m (t) i k=1 FC enc (x (t) ik ; φ enc ),<label>(21)</label></formula><p>where FC enc (.; φ enc ) represents an encoder parameterised by φ enc . In general, p(z|β i ) can be any standard distribution that can be easily sampled from, such as a diagonal Gaussian. However, in our implementation, we observe that as the training task varies, the means and covariances of the Gaussian distribution represented by β i may vary drastically, resulting in a large variation of the latent noise sample z, and potentially, making the training more difficult. To overcome that, we model p(z|β i ) as a Beta distribution 2 , where the sampling procedure produces a latent noise z ∈ [0, 1] Z . This constrains the latent noise space, resulting in a more stable training. Under this modelling, our approach is analogous to VAE-GAN <ref type="bibr" target="#b23">[22]</ref>. Due to the nature of implicit models, the KL divergence term of L (t) i in <ref type="bibr" target="#b8">(8)</ref>, or in particular, the density ratio q(w; λ i )/p(w; θ), cannot be evaluated either analytically or symbolically. We, therefore, propose to employ the probabilistic classification approach [48, Chapter 4] to estimate the KL divergence term. We use a discriminator D, represented by a deep neural network with parameter ω i , as a classifier to distinguish different w i sampled from p(w; θ) (label 1) or q(w; λ i ) (label 0). The objective function to train the discriminator D is: max</p><formula xml:id="formula_28">ωi L disc (ω i ) = E p(z) [ln D (G(z; θ); ω i )] + + E p(z) [ln (1 − D (G(z; λ i ); ω i ))] . (22)</formula><p>The KL divergence term of L (t) i in (8) can, therefore, be estimated as <ref type="bibr" target="#b2">3</ref> :</p><formula xml:id="formula_29">D KL [q(w; λ i ) p(w; θ)] ≈ − 1 L t Lt l=1 V G(z (l) ; λ i ); ω i ,<label>(23)</label></formula><p>2. sampling from a Beta distribution can be done by applying reparameterisation trick <ref type="bibr" target="#b41">[40]</ref> 3. Refer to Supplemental Material B for details where z (l) ∼ p(z|β i ) defined in <ref type="bibr" target="#b21">(20)</ref>, L t is the number of Monte Carlo samples, and V (., ω i ) is the output of the discriminator D without sigmoid activation. The VFE in <ref type="formula" target="#formula_3">(10)</ref> can, therefore, be rewritten as:</p><formula xml:id="formula_30">L (t) i ≈ − 1 L t Lt l=1 V G(z (l) ; λ i ); ω i + + m (t) i k=1 ln p y (t) ik x (t) ik , G(z (l) ; λ i ) .<label>(24)</label></formula><p>One problem that arises when estimating the loss in <ref type="formula" target="#formula_6">(24)</ref> is how to obtain the local optimal parameters ω * i for the discriminator D. One simple approach is to learn a different ω i for each different task T i by training the discriminator from scratch. The downside is the significant increase in training time. We, therefore, propose to meta-learn ω i using MAML <ref type="bibr" target="#b12">[12]</ref> to reduce the training time for the discriminator. In this scenario, we define ω 0 as the meta-parameters (or initialisation) of ω i . Within each task, we initialise ω i at ω 0 and train on the generated w i from (20) until convergence for that task. This approach leads to the proposed algorithm, named SImPa (statistical implicit PAC-Bayes metalearning), which can be visualised in <ref type="figure" target="#fig_1">Figure 2</ref>. The details of the algorithm can be referred to Algorithms 1 and 2 in the Supplemental Material C for training and testing, respectively.</p><p>Another approach to estimate the KL divergence term of L (t) i in <ref type="formula" target="#formula_3">(10)</ref> is to use a lower bound of f-divergence <ref type="bibr" target="#b33">[32,</ref><ref type="bibr" target="#b34">33]</ref> as shown in Lemma 2. There is a difference between the lower bound of KL divergence approach and the probabilistic classification presented in this subsection. In the former approach, the lower bound of the KL divergence is maximised to tighten the bound. In the latter approach, a discriminator is trained to minimise the logistic regression loss to estimate the ratio q(w; λ i )/p(w; θ), and use Monte Carlo sampling to approximate the KL divergence of interest. Despite the difference mentioned above, the implementations of both approaches are quite similar. However, the lower-bound of KL divergence approach, with the computation of an exponential term in the objective function, suffers from numerical instability, especially at the beginning of training. As a result, we decide to use the probabilistic classification approach, where training process is numerically more stable.</p><p>One potential drawback of the implicit modelling approach is the curse of dimensionality, resulting in computationally expensive training process. This is an active research question when dealing with generative models in general. This issue can be addressed by encoding the highdimensional data, such as images, to a feature embedding space by supervised-learning on the same training data set <ref type="bibr" target="#b43">[42]</ref>. This strategy reduces the dimension of the input space, leading to smaller generator and discriminator models. The trade-off lies in the possibility of losing relevant information that can affect the performance on held-out tasks.</p><p>One advantage of our proposed method is the taskawareness due to the conditional latent noise distribution p(z|β i ). While other Bayesian few-shot meta-learning methods, such as PLATIPUS <ref type="bibr" target="#b13">[13]</ref> or ABML <ref type="bibr" target="#b37">[36]</ref>, randomly sample w i from p(w; θ), our proposed SImPa uses unlabelled data</p><formula xml:id="formula_31">x (t) i,1:m (t) i ∼ D (t) i</formula><p>to extract more information about the task T i when generating w i as shown in <ref type="bibr" target="#b21">(20)</ref>, potentially resulting in a better adaptation.</p><p>It is also worth noting that our proposed method is easier to train than prior Bayesian few-shot meta-learning methods <ref type="bibr" target="#b13">[13,</ref><ref type="bibr" target="#b37">36]</ref> because we no longer need to tune the weighting factor of the KL divergence term of L (t) i in <ref type="bibr" target="#b10">(10)</ref>. Although weighting the KL divergence term can be justified by replacing the objective function in (10) by a constrained optimisation as shown in Beta-VAE <ref type="bibr" target="#b20">[19]</ref>, the weighting factor is the corresponding Lagrange multiplier of the constrained optimisation. Thus, simply setting that weighting factor as a tunable hyper-parameter may result in a suboptimal solution for q(w; λ i ). In contrast, our proposed approach follows the standard variational approximation as shown in (10) without weighting the KL divergence term. The trade-off of our approach lies in the need to set the significance level δ, but tuning δ is arguably more intuitive than tuning the correct weighting factor for the KL divergence term.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTAL EVALUATION</head><p>We evaluate SImPa on few-shot regression and classification problems. The loss functions used are mean-squared error and cross-entropy, respectively. Following the assumption of bounded losses made in Section 3.2, the losses in the derived upper-bound in Theorem 1 are clipped to [0, 1]. In addition, for simplicity, we limit our search to a family of diagonal Gaussian: q(θ; ψ) = N (µ θ , σ 2 θ I), where σ θ is a hyper-parameter. This means ψ = µ θ . The meta-parameter θ can, therefore, be sampled from q(θ; ψ) by applying reparameterisation trick. The prior p(θ) is also assumed to be a diagonal Gaussian N (µ 0 1, σ 2 0 I), where µ 0 and σ 0 are hyper-parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Regression</head><p>The experiment in this subsection is a multi-modal task distribution where half of the data is generated from sinusoidal functions, while the other half is from linear functions <ref type="bibr" target="#b13">[13]</ref>. As shown in <ref type="figure" target="#fig_2">Figure 3</ref>, SImPa is able to vary the prediction variance, especially when there is more uncertainty in the training data, while MAML can only output a single value at each data point. For a quantitative comparison, we train many probabilistic meta-learning methods, including PLATIPUS <ref type="bibr" target="#b13">[13]</ref>, BMAML <ref type="bibr" target="#b53">[52]</ref> and ABML <ref type="bibr" target="#b37">[36]</ref>, in the same regression problem. Here, BMAML consists of 10 particles trained without Chaser Loss, and ABML is trained with a uniform hyper-posterior. As shown in <ref type="figure">Figure 4a</ref>, SImPa where training data combined with the meta-parameter θ is used to update the generator to generate an adapted base network that solves the corresponding task. achieves much smaller negative log-likelihood (NLL), comparing to MAML, PLATIPUS and ABML, and comparable NLL to the non-parametric BMAML. To further evaluate the predictive uncertainty, we employ the reliability diagram based on the quantile calibration for regression <ref type="bibr" target="#b48">[47]</ref>. The reliability diagram shows a correlation between predicted and actual probability. A perfectly calibrated model will have its predicted probability equal to the actual probability, and hence, align well with the diagonal y = x. The results in <ref type="figure">Figure 4b</ref> show that the model trained with SImPa achieves the best calibration among all the methods considered. Due to the nature of a deterministic approach, MAML <ref type="bibr" target="#b12">[12]</ref> is represented as a horizontal line, resulting in a poorly calibrated model. The two probabilistic meta-learning methods, PLATIPUS and ABML, perform better than MAML; however, the averaged slopes of their performance curves are quite close to MAML, implying that their diagonal Gaussian posteriors of task-specific model parameters have small covariances. This may be caused by their exclusive reliance on less-expressive diagonal Gaussian variational distributions. The performance of BMAML is slightly better than PLATIPUS and ABML due to its non-parameteric modelling approach. In contrast, SImPa employs a much richer variational distribution for task specific parameters, and therefore, produces a model with better calibration. For another quantitative comparison, we plot the expected calibration error (ECE) <ref type="bibr" target="#b19">[18]</ref>, which is the weighted average of the absolute errors measuring from the diagonal, and the maximum calibration error (MCE) <ref type="bibr" target="#b19">[18]</ref>, which returns the maximum of absolute errors in <ref type="figure">Figure 4c</ref>. Overall, SImPa outperforms all of the state-of-the-art methods in both ECE and MCE.</p><formula xml:id="formula_32">x (t) ij y (t) ij Encoder FC en (.; φ enc ) β i (a) Task encoding in (21) z Generator G(.; λ i ) θ (b) Variational inference in (11) Base network w i x (v) ik y (v) ik</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Few-shot classification</head><p>We evaluate SImPa on the N -way k-shot setting, where a meta learner is trained on many related tasks containing N classes with k examples per class (m (t) i = kN ). The evaluation is carried out by comparing the results of SImPa against the results of state-of-the-art methods on three popular fewshot learning benchmarking data sets: Omniglot <ref type="bibr" target="#b22">[21]</ref>, mini-ImageNet <ref type="bibr" target="#b38">[37,</ref><ref type="bibr" target="#b52">51]</ref> and tiered-ImageNet <ref type="bibr" target="#b39">[38]</ref>.</p><p>Omniglot data set consists of 50 different alphabets with a total of 1623 characters drawn online via Amazon's Mechanical Turk by 20 different people. Hence, Omniglot </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>METHOD</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1-SHOT 5-SHOT</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Omniglot [21] -standard 4-block CNN</head><p>MAML <ref type="bibr" target="#b12">[12]</ref> 97.143 ± 0.005 Prototypical nets <ref type="bibr" target="#b47">[46]</ref> 96.359 ± 0.006 BMAML <ref type="bibr" target="#b53">[52]</ref> 94.104 ± 0.008 ABML <ref type="bibr" target="#b37">[36]</ref> 97.281 ± 0.004 SImPa 98.824 ± 0.004</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mini-ImageNet [37] -standard 4-block CNN</head><p>Matching nets <ref type="bibr" target="#b52">[51]</ref> 43.56 ± 0.84 55.31 ± 0.73 Meta-learner LSTM <ref type="bibr" target="#b38">[37]</ref> 43.44 ± 0.77 60.60 ± 0.71 MAML <ref type="bibr" target="#b12">[12]</ref> 48.70 ± 1.84 63.15 ± 0.91 Prototypical nets <ref type="bibr" target="#b47">[46]</ref>  <ref type="bibr" target="#b3">4</ref> 49.42 ± 0.78 68.20 ± 0.66 LLAMA <ref type="bibr" target="#b18">[17]</ref> 49.40 ± 1.83 PLATIPUS <ref type="bibr" target="#b13">[13]</ref> 50.13 ± 1.86 ABML <ref type="bibr" target="#b37">[36]</ref> 45.00 ± 0.60 SImPa 52.11 ± 0.43 63.87 ± 0.35</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mini-ImageNet [37] -non-standard network</head><p>Relation nets <ref type="bibr" target="#b50">[49]</ref> 50.44 ± 0.82 65.32 ± 0.70 VERSA <ref type="bibr" target="#b17">[16]</ref> 53.40 ± 1.82 67.37 ± 0.86 SNAIL <ref type="bibr" target="#b29">[28]</ref> 55.71 ± 0.99 68.88 ± 0.92 adaResNet <ref type="bibr" target="#b31">[30]</ref> 56.88 ± 0.62 71.94 ± 0.57 TADAM <ref type="bibr" target="#b35">[34]</ref> 58.50 ± 0.30 76.70 ± 0.30 LEO <ref type="bibr" target="#b43">[42]</ref> 61.76 ± 0.08 77.59 ± 0.12 LGM-Net <ref type="bibr" target="#b25">[24]</ref> 69. <ref type="bibr" target="#b13">13</ref>   often considered as a "transposed" MNIST since Omniglot has many classes, but each class has 20 images. We follow the original train-test split where 30 alphabets are used for training, while the other 20 alphabets are used for testing. Note that many meta-learning methods in the literature use non-standard train-test split where characters of all 50 alphabets are mixed, and randomly split. This splitting potentially results in information leakage since knowing a character in an alphabet might help to classify other characters within that same alphabet. Moreover, the mixed and random split is different from evaluation to evaluation, creating difficulty to fairly compare different meta-learning methods. To be consistent with previous evaluations, we pre-process by down-sampling all images to 28-by-28 pixels.</p><p>No data augmentation, such as rotation, is used.</p><p>Mini-ImageNet has 100 classes with each class containing 600 colour images taken from ImageNet <ref type="bibr" target="#b42">[41]</ref>. This data set represents a common benchmark for few-shot learning <ref type="bibr" target="#b52">[51]</ref>. We follow the standard train-test split which uses 64 classes for training, 16 classes for validation, and 20 classes for testing <ref type="bibr" target="#b38">[37]</ref>. The images in the data set are preprocessed by down-sampling to 84-by-84 pixels before any training is carried out.</p><p>Tiered-ImageNet is one of the largest subsets of Ima-geNet, which consists of total 608 classes grouped into 34 high-level categories <ref type="bibr" target="#b39">[38]</ref>. Tiered-ImageNet is often used as a benchmark for large-scaled few-shot learning. We also follow the standard train-test split that consists of 20 categories for training, 6 categories for validation, and 8 categories for testing. In addition, our evaluation is carried out by employing the features extracted from a residual network trained on the data and classes from the training set <ref type="bibr" target="#b43">[42]</ref>.</p><p>Two architectures of the base network have been employed in the experiment: "standard" 4-layer convolutional module network <ref type="bibr" target="#b12">[12,</ref><ref type="bibr" target="#b38">37,</ref><ref type="bibr" target="#b52">51]</ref> when the raw image data is used, and a customised fully connected network when extracted features <ref type="bibr" target="#b43">[42]</ref> are used. Please refer to Supplemental Material E for further details of the network architectures used for the base network, encoder, generator and discriminator, as well as the hyper-parameters.</p><p>We report the classification accuracy of SImPa on these three data sets in <ref type="table" target="#tab_2">Table 1</ref>. For Omniglot, we use the published code to reproduce the results for some common meta-learning methods to fairly compare with SImPa. The accuracy averaged over more than 1 million testing tasks show that the proposed SImPa is on par with many metalearning methods in the literature. For mini-ImageNet, SImPa achieves the best results for the 1-shot setting when the base model is the "standard" CNN, and for the 5-shot setting when a different network architecture is used. SImPa shows the second best results for the 5-shot setting with the 4-layer CNN and the 1-shot setting with the different network architecture. Note that for the 5-shot setting using standard CNN, Prototypical networks need to train with a much higher "way" setting. For tiered-ImageNet, SImPa outperforms the current state-of-the-art on both 1and 5-shot settings. To obtain a fairer comparison, we rerun MAML on the image data of mini-ImageNet using a ResNet10, which has about 5 million parameters (ours has about 8 millions parameters). However, MAML, with and without L2 regularisation, over-fits to training data (our best result was 89% accuracy on train, while only 42% on test). This known issue of overfitting when using larger networks in MAML was mentioned in the MAML's paper <ref type="bibr" target="#b12">[12,</ref><ref type="bibr">Section 5.2]</ref>. We also try a similar model for ABML <ref type="bibr" target="#b37">[36]</ref>, but observed no improvement.</p><p>Similarly to the experiment for regression, we use reliability diagrams <ref type="bibr" target="#b19">[18]</ref> to evaluate the predictive uncertainty. For a fair comparison, we re-implement several probabilistic meta-learning approaches, including MAML <ref type="bibr" target="#b12">[12]</ref>, PLATI-PUS <ref type="bibr" target="#b13">[13]</ref>, BMAML <ref type="bibr" target="#b53">[52]</ref> and ABML <ref type="bibr" target="#b37">[36]</ref>, using the base model of a 4-block CNN, train under the same setting, and plot their reliability chart. The performance curves in the reliability diagram show how well calibrated a model is when testing across many unseen tasks. A perfectly calibrated model will have its values overlapped with the identity function y = x, indicating that the probability associated with the label prediction is the same as the true probability. To ease the visualisation, we normalise the reliability chart by subtracting the predicted accuracy by its corresponding value on the diagonal y = x, as shown in <ref type="figure" target="#fig_4">Figure 5a</ref>. Hence, for the normalised reliability chart, the closer to y = 0, the better the calibration. Visually, the model trained with SImPa shows better calibration than the ones trained with other meta-learning methods. To further evaluate, we compute the expected calibration error (ECE) and maximum calibration error (MCE) <ref type="bibr" target="#b19">[18]</ref> of the models trained with these methods. The results plotted in <ref type="figure" target="#fig_4">Figure 5b</ref> show that the model trained with SImPa achieves the smallest ECE and MCE among all the methods considered in this comparison. The most competitive method to SImPa, regarding ECE and MCE, is ABML, but note that ABML has a worse classification accuracy than SImPa, as shown in <ref type="table" target="#tab_2">Table 1</ref> (Top) -see row "ABML <ref type="bibr" target="#b37">[36]</ref>".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>We introduce and formulate a new probabilistic algorithm for few-shot meta-learning. The proposed algorithm, SImPa, is based on PAC-Bayes framework which theoretically guarantees prediction generalisation on unseen tasks and samples. In addition, the proposed method employs a generative approach that implicitly models the prior of taskspecific model parameter, p(w i ; θ), shared across all tasks, and the task-specific posterior q(w i ; λ i ), resulting in more expressive variational approximation compared to the usual diagonal Gaussian methods, such as PLATIPUS <ref type="bibr" target="#b13">[13]</ref> or ABML <ref type="bibr" target="#b37">[36]</ref>. The uncertainty, in the form of the learnt implicit distributions, can introduce more variability into the decision made by the model, resulting in well-calibrated and highly-accurate prediction. The algorithm can be combined with different base models that are trainable with gradientbased optimisation, and is applicable in regression and classification. We demonstrate that the algorithm has stateof-the-art calibration and prediction results on unseen data in a multi-modal 5-shot learning regression problem, and achieve state-of-the-art calibration and classification results on few-shot 5-way tasks on mini-ImageNet and tiered-ImageNet data sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work was supported by Australian Research Council grants CE140100016 and FT190100525. We also thank the Phoenix High Performance Computing service at the University of Adelaide to provide super-computing resources for this work. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SUPPLEMENTAL MATERIAL A PROOF OF PAC-BAYES FEW-SHOT META-LEARNING BOUND</head><p>The derivation is divided into three steps. The first two steps are to derive the PAC-Bayes bound for the generalisation errors induced by the unseen tasks, and the unseen queried examples within each task. The novel bound is then constructed by combining the results obtained in the first two steps and presented in Theorem 1.</p><p>To prove Theorem 1, we employ the general form of the PAC-Bayes bound for a single-task setting <ref type="bibr" target="#b28">[27]</ref>. In addition, instead of relying on 0-1 loss, we use the bound derived for a more generalised loss function as shown in <ref type="bibr" target="#b46">[45,</ref><ref type="bibr">Theorem 31.1]</ref>.</p><p>Theorem 2. Let D be an arbitrary distribution over an example domain Z. Let H be a hypothesis class, ℓ : H × Z → [0, 1] be a loss function, π be a prior distribution over H, and δ ∈ (0, 1]. If S = {z j } m j=1 is an i.i.d. training set sampled according to D, then for any "posterior" Q over H, the following holds:</p><formula xml:id="formula_33">Pr E zj∼p(z) E q∼Q ℓ(q, z j ) ≤ E zj∼S E q∼Q ℓ(q, z j ) + D KL [Q π] + ln m δ 2(m − 1) ≥ 1 − δ.</formula><p>Theorem 2 indicates that with a high probability, the expected error of an arbitrary posterior Q on data distribution p(z) is upper-bounded by the empirical error plus a complexity regularisation term. These two terms express the trade-off between fitting data (bias) and regularising model complexity (variance).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 PAC-Bayes bound for unseen tasks</head><p>We use Theorem 2 with the following substitutions: the loss function is L</p><formula xml:id="formula_34">(v) i − E q(w;λi) [ln p(w; θ)], where L (v) i</formula><p>is defined in Eq. (13), the i.i.d. sample is the task-specific dataset D i , the hypothesis is the meta-parameter θ, the prior of the hypothesis is p(θ), the posterior is the variational posterior q(θ; ψ). This leads to Corollary 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corollary 1 (PAC-Bayes bound for unseen tasks)</head><p>. In the following subsections, we will upper-bound further the right-hand-side term that contains L (v) i in the probability.</p><formula xml:id="formula_35">Pr E Di∼p(T ) E q(θ;ψ) L (v) i − E q(w;λi) [ln p(w; θ)] ≤ ≤ 1 T T i=1 E q(θ;ψ) L (v) i − E q(w;λi) [ln p(w; θ)] +R 0 ≥ 1 − δ 0 ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 PAC-Bayes bound for queried examples of a single-task</head><p>We prove the following lemma. i , defined in Eqs. <ref type="bibr" target="#b13">(13)</ref> and <ref type="formula" target="#formula_3">(14)</ref>, R i in Eq. <ref type="bibr" target="#b17">(16)</ref>, and for any δ i &gt; 0, the following holds:</p><formula xml:id="formula_36">Pr E q(θ;ψ) L (v) i ≤ E q(θ;ψ) L (v) i +R i ≥ 1 − δ i , where:R i = E q(θ;ψ) [D KL [q(w; λ i ) p(w; θ)]] + ln m (v) i δi 2(m (v) i − 1)</formula><p>. Proof. For convenience, we define the following notations:</p><formula xml:id="formula_37">• ℓ(x (v) ij , y (v) ij , w i ) = − ln p(y (v) ij |x (v) ij , w i ), • L i = E (x (v) ij ,y (v) ij )∼D (v) i ℓ(x (v) ij , y (v) ij , w i ) • L i = E (x (v) ij ,y (v) ij )∼ D (v) i ℓ(x (v) ij , y (v) ij , w i ) = 1 m (v) i m (v) i j=1 ℓ(x (v) ij , y (v) ij , w i ) • ∆(w) = L i − L i .</formula><p>With these notations, L i is fixed for i th task, while L i varies depending on different validation sub-set D (v) i sampled from D i . Therefore, ∆(w) is a function of D (v) i . We then employ Lemma 2 with the following substitutions:</p><formula xml:id="formula_38">• h := w • φ(h) := 2(m (v) i − 1)∆(w i ) 2 • P := p(w; θ) • Q := q(w; λ i ).</formula><p>This results in the following inequality:</p><p>Hence:</p><formula xml:id="formula_39">Pr E q(θ;ψ) ln E p(w;θ) e 2(m (v) i −1)∆(w) 2 ≤ ε ≥ 1 − ln m (v) i ε .<label>(37)</label></formula><p>We can, therefore, utilise the equivalence of probability by adding the expectation of the KL divergence in <ref type="bibr" target="#b30">(29)</ref> inside the probability to obtain the following:</p><formula xml:id="formula_40">Pr E q(θ;ψ) [D KL [q(w; λ i ) p(w; θ)]] + E q(θ;ψ) ln E p(w;θ) e 2(m (v) i −1)∆(w) 2 ≤ ≤ E q(θ;ψ) [D KL [q(w; λ i ) p(w; θ)]] + ε ≥ 1 − ln m (v) i ε .<label>(38)</label></formula><p>We then use the inequality in <ref type="bibr" target="#b30">(29)</ref> to lower-bound the LHS term inside the probability:</p><formula xml:id="formula_41">Pr   E q(θ;ψ) E q(w;λi) [∆(w)] ≤ E q(θ;ψ) [D KL [q(w; λ i ) p(w; θ)]] + ε 2(m (v) i − 1)   ≥ 1 − ln m (v) i ε .<label>(39)</label></formula><p>To make it in the popular form of PAC-Bayes learning, let us define δ i = ln(m</p><formula xml:id="formula_42">(v) i )/ε to obtain: Pr     E q(θ;ψ) E q(w;λi) [∆(w)] ≤ E q(θ;ψ) [D KL [q(w; λ i ) p(w; θ)]] + ln m (v) i δi 2(m (v) i − 1)     ≥ 1 − δ i .<label>(40)</label></formula><p>Note that:</p><formula xml:id="formula_43">L (v) i = E q(w;λ(θ)) L i L (v) i = E q(w;λ(θ)) L i .</formula><p>Hence:</p><formula xml:id="formula_44">Pr     E q(θ;ψ) L (v) i ≤ E q(θ;ψ) L (v) i + E q(θ;ψ) [D KL [q(w; λ i ) p(w; θ)]] + ln m (v) i δi 2(m (v) i − 1)     ≥ 1 − δ i .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 PAC-Bayes bound for meta-learning</head><p>We combine the results in Corollary 1 and Lemma 1 to derive a novel PAC-Bayes bound for the first term in <ref type="bibr" target="#b20">(19)</ref>. For convenience, we restate the PAC-Bayes bound of interest as below.</p><p>Theorem 1. For δ ∈ (0, 1] and τ &gt; 1, the general error of few-shot meta-learning (or, first term in <ref type="bibr" target="#b12">(12)</ref>) can be upper-bounded as:</p><formula xml:id="formula_45">Pr E q(θ;ψ) E Di∼p(T ) L (v) i + L (t) i ≤ ≤ 1 T T i=1 E q(θ;ψ) L (v) i + L (t) i + R i + R 0 ≥ 1 − δ,</formula><p>Proof. First, we extend the bound for the unseen examples of a single-task obtained in Lemma 1 to many tasks. We apply the inequality in Lemma 6 (presented in Supplementary Material F) for Lemma 1 with the following substitution:</p><formula xml:id="formula_46">X i = E q(θ;ψ) L (v) i , Y i = E q(θ;ψ) L (v) i +R i , n = T , δ i = δ i to obtain: Pr T i=1 E q(θ;ψ) L (v) i ≤ T i=1 E q(θ;ψ) L (v) i +R i ≥ 1 − T i=1 δ i .</formula><p>Adding relative entropy between q(w; λ i ) and p(w; θ) for both sides in the probability, and dividing by T give:</p><formula xml:id="formula_47">Pr 1 T T i=1 E q(θ;ψ) L (v) i − E q(w;λi) [ln p(w; θ)] ≤ 1 T T i=1 E q(θ;ψ) L (v) i − E q(w;λi) [ln p(w; θ)] +R i ≥ 1 − T i=1 δ i .<label>(41)</label></formula><p>Given Corollary 1 and the result in (41), we can apply Corallory 2 in Supplemental Material F to obtain:  The dimension of the latent noise is Z = 128. The generator is a 2-layer fully-connected network with 256 and 512 hidden nodes. The discriminator is a 3-layer fully-connected network with 512, 256 and 128 hidden nodes. Different baseand encoder-networks are used in the experiments, depending on the input data.</p><formula xml:id="formula_48">Pr E Di∼p(T ) E q(θ;ψ) L (v) i ≤ 1 T T i=1 E q(θ;ψ) L (v) i +R i +R 0 ≥ 1 − T i=0 δ i .<label>(42)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.1 Standard CNN with input as raw image data</head><p>The base-network, in this case, is a standard 4-CNN-module network <ref type="bibr" target="#b12">[12,</ref><ref type="bibr" target="#b38">37]</ref>. Each CNN-based module consists of a 3-by-3 convolution layer with 32 channels, followed by batch normalisation, ReLU and 2-by-2 max-pooling. The output of the last convolutional module. These nodes are then fully connected to the output layer activated by softmax.</p><p>The encoder network shares a similar architecture, but has 5 modules with 32, 64, 128 and 256 channels in case of Omniglot, and 5 modules with 32, 32, 32, 32 and 64 channels in case of mini-ImageNet. This results in 256-dimensional vector at the output. This vector is then activated by a softplus function, and then split into 2 sub-vectors, each has 128 dimensions, as the parameters of the latent noise Beta distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.2 Customised networks with input as extracted features (mini-and tiered-ImageNet)</head><p>The base network is a fully-connected neural network with 2 hidden layers. These layers consist of 128 and 32 hidden nodes, respectively. ReLU is employed as the activation function without any batch normalisation.</p><p>The encoder is also a fully connected network with 2 hidden layers. Each layer consists of 256 hidden units activated by ReLU. No batch normalisation is employed. The output layer has 256 units, then split into two vectors to parameterised the latent noise Beta distribution.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SUPPLEMENTAL MATERIAL F AUXILIARY LEMMAS</head><p>Lemma 2 (Compression lemma <ref type="bibr" target="#b3">[4]</ref>). For any measurable function φ(h) on a set of predictors under consideration H, and any distributions P and Q on H, the following holds: Lemma 3 (Exercise 31.1 in <ref type="bibr" target="#b46">[45]</ref>). Let X be a non-negative random variable that satisfies: Pr (X ≥ ǫ) ≤ e −2mǫ 2 , ∀ǫ ≥ 0. Prove that: E e 2(m−1)X 2 ≤ m.</p><formula xml:id="formula_49">E Q [φ(h)] − ln E P [exp (φ(h))] ≤ D KL [Q P ] .</formula><p>Proof. We will present the expectation of interest in term of probability of X. For simplicity, let Y = e 2(m−1)X 2 . Since X ∈ [0, +∞), then Y ∈ [1, +∞). According to the layer cake representation <ref type="bibr" target="#b26">[25,</ref><ref type="bibr">Page 26]</ref>:</p><formula xml:id="formula_50">Y = Y 0 dt = +∞ 1 ½ (Y ≥ t) dt,</formula><p>where ½(A) is the indicator function of event A.</p><p>One important property of indicator function is that:</p><formula xml:id="formula_51">E [½ (Y ≥ t)] = Pr (Y ≥ t) .</formula><p>. With the above representation, we can express the expectation of interest as:</p><formula xml:id="formula_52">E [Y ] = E +∞ 1 ½ (Y ≥ t) dt = +∞ 1 E [½ (Y ≥ t)] dt (Fubini's theorem) = +∞ 1</formula><p>Pr (Y ≥ t) dt.</p><p>Or:</p><p>E e 2(m−1)X 2 = +∞ 1</p><p>Pr e 2(m−1)X 2 ≥ x dx.</p><p>We will change the variable from x to ǫ to utilise the given inequality. Let:</p><p>x = e 2(m−1)ǫ 2 , and since ǫ ≥ 0, then: ǫ = ln x 2(m − 1) , and dx = 4(m − 1)ǫe 2(m−1)ǫ 2 dǫ.</p><p>Hence, the expectation of interest can be written in term of the changed variable ǫ as: </p><formula xml:id="formula_53">p n i=1 X i ≤ n i=1 Y i ≥ p n i=1 (X i ≤ Y i ) .</formula><p>Proof. The proof is quite direct:</p><formula xml:id="formula_54">X i ≤ Y i =⇒ n i=1 X i ≤ n i=1 Y i .<label>(43)</label></formula><p>Hence, applying the probability for implication completes the proof.</p><p>Lemma 5. For n events A i with i = 1 : n, the following holds:</p><formula xml:id="formula_55">p n i=1 A i ≥ n i=1 p(A i ) − (n − 1), ∀n ≥ 2.</formula><p>Proof. Proof can be done by induction. For n = 2: p(A 1 ∩ A 2 ) = p(A 1 ) + p(A 2 ) − p(A 1 ∪ A 2 ) ≥ p(A 1 ) + p(A 2 ) − 1.</p><p>Suppose that it is true for case n:</p><formula xml:id="formula_56">p n i=1 A i ≥ n i=1 p(A i ) − (n − 1).</formula><p>We prove that this is also true for case (n + 1):</p><formula xml:id="formula_57">p n+1 i=1 A i = p n i=1 A i + p(A n+1 ) − p n i=1 A i A n+1 ≥ p n i=1 A i + p(A n+1 ) − 1 ≥ n i=1 p(A i ) − (n − 1) + p(A n+1 ) − 1</formula><p>(assumption of induction for case n)</p><formula xml:id="formula_58">≥ n+1 i=1</formula><p>p(A i ) − ((n + 1) − 1) .</p><p>It is, therefore, true for (n + 1), and hence, the proof. Lemma 6. Let X i and Y i are random variables with i = 1 : n. If p(X i ≤ Y i ) ≥ 1 − δ i with δ i ∈ (0, 1], then:</p><formula xml:id="formula_59">p n i=1 X i ≤ n i=1 Y i ≥ 1 − n i=1 δ i .</formula><p>Proof. Applying Lemmas 4 and 5 for the left-hand side term of this lemma gives:</p><formula xml:id="formula_60">p n i=1 X i ≤ n i=1 Y i ≥ p n i=1 (X i ≤ Y i ) (Lemma 4) ≥ n i=1 p ((X i ≤ Y i )) − (n − 1) (Lemma 5) ≥ n i=1 (1 − δ i ) − (n − 1) = 1 − n i=1 δ i .<label>(44)</label></formula><p>Corollary 2. If p(a ≤ b) ≥ 1 − δ 1 and p(b ≤ c) ≥ 1 − δ 2 with δ 1 , δ 2 ∈ (0, 1], then:</p><formula xml:id="formula_61">p(a ≤ c) ≥ 1 − δ 1 − δ 2 .</formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>= 15</head><label>15</label><figDesc>The sinusoidal function used in this experiment is in the form y = A sin(x + Φ) + ε, where A and Φ are uniformly sampled from [0.1, 5] and [0, π], respectively, while the linear function considered is in the form y = ax + b + ε, where a and b are randomly sampled from [−5, 5]. The noise ε is sampled from N (0, 0.3 2 ). The experiment is carried out under the 5-shot setting (m data points. The details of the experimental setup and additional visualisation results are presented in Supplemental Material D.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>The proposed algorithm, SImPa, consists of two phases illustrated in dashed rectangles: (a) task representation encoding, where unlabelled data are encoded using an encoder aggregator, and (b) gradient-based variational inference,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 :</head><label>3</label><figDesc>SImPa and MAML are compared in a regression problem when training is based on multi-modal data -half of the tasks are generated from sinusoidal functions, and the other half are from linear functions. The shaded area is the prediction made by SImPa ± 3× standard deviation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>is 4 .Fig. 4 :</head><label>44</label><figDesc>Trained on 30-way 1-shot setting 5. Use extracted features<ref type="bibr" target="#b43">[42]</ref> as input Quantitative comparison between various probabilistic meta-learning approaches averaged over 1000 unseen tasks shows that SImPa has the smallest NLL and calibration errors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 :</head><label>5</label><figDesc>Calibration of the "standard" 4-block CNN trained with different meta-learning methods on 5-way 1-shot classification tasks on mini-ImageNet.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Cuong</head><label></label><figDesc>Nguyen is currently a PhD student at the University of Adelaide. His research interest is meta-learning or learning how to learn. Thanh-Toan Do is currently a Lecturer with the Department of Computer Science, University of Liverpool, UK. He received the Ph.D. degree in computer science from INRIA, Rennes, France, in 2012. From 2013 to 2016, he was a Research Fellow with the Singapore University of Technology and Design, Singapore. From 2016 to 2018, he was a Research Fellow with the University of Adelaide, Australia. His research interests include computer vision and machine learning. Gustavo Carneiro is a Professor of the School of Computer Science at the University of Adelaide, ARC Future Fellow, and the Director of Medical Machine Learning at the Australian Institute of Machine Learning. He joined the University of Adelaide as a senior lecturer in 2011, has become an associate professor in 2015 and a professor in 2019. In 2014 and 2019, he joined the Technical University of Munich as a visiting professor and a Humboldt fellow. From 2008 to 2011 Dr. Carneiro was a Marie Curie IIF fellow and a visiting assistant professor at the Instituto Superior Tecnico (Lisbon, Portugal) within the Carnegie Mellon University-Portugal program (CMU-Portugal). From 2006 to 2008, Dr. Carneiro was a research scientist at Siemens Corporate Research in Princeton, USA. In 2005, he was a post-doctoral fellow at the the University of British Columbia and at the University of California San Diego. Dr. Carneiro received his Ph.D. in computer science from the University of Toronto in 2004. His main research interest are in the fields of computer vision, medical image analysis and machine learning.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>where δ 0 ∈</head><label>0</label><figDesc>(0, 1], and:R 0 = D KL [q(θ; ψ) p(θ)] + ln T δ0 2(T − 1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Lemma 1 (</head><label>1</label><figDesc>PAC-Bayes bound for unseen queried examples of a task). For the true and empirical validation losses, L</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Setting δ 0</head><label>0</label><figDesc>= δ τ , and δ i = τ −1 τ δ T , where τ &gt; 1 and i ∈ {1, . . . , T } completes the proof.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 6 :</head><label>6</label><figDesc>Additional visualisation for regression experiment with data generated from either a sinusoidal or linear function. The shaded area is the prediction made by SImPa with ± 3 standard deviation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Further, sup φ E</head><label>φ</label><figDesc>Q [φ(h)] − ln E P [exp (φ(h))] = D KL [Q P ] .Proof. Please see<ref type="bibr" target="#b3">[4,</ref> Lemma 1].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>E e 2 (m− 1 )X 2 =0Lemma 4 .</head><label>2124</label><figDesc>+∞Pr e 2(m−1)X 2 ≥ e 2(m−1)ǫ 2 4(m − 1)ǫe 2(m−1)ǫ 2 dǫ = − 1)ǫe −2ǫ 2 dǫ = m. For i = 1 : n, if X i and Y i are random variables, then:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>an observable input and y ∈ Y represents a label) and a hidden query set D</figDesc><table><row><cell>(v) i . Theoretically, D i (v) examples, but in training tasks, we can observe only a finite has infinite</cell></row><row><cell>number of examples D</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE 1 :</head><label>1</label><figDesc>The few-shot 5-way classification accuracy results (in percentage, with 95% confidence interval) of SImPa</figDesc><table /><note>averaged over 1,048,576 tasks on Omniglot (top), and 600 tasks on mini-ImageNet (middle-top and middle-bottom) and tiered-ImageNet (bottom) datasets. Overall, SImPa is competitive, and outperforms the state-of-the-art in some settings.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE 2 :</head><label>2</label><figDesc>Hyper-parameters used in the classification experiments.</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SUPPLEMENTAL MATERIAL B DERIVATION OF KL DIVERGENCE IN</head> <ref type="bibr" target="#b24">(23)</ref> <p>D KL [q(w i ; λ i ) p(w i ; θ)] = E q(wi;λi) ln q(w i ; λ i ) p(w i ; θ) ≈ E q(wi;λi) ln 1 − D(w i ; ω i ) D(w i ; ω i ) .</p><p>Note that:</p><p>and</p><p>The KL divergence can, therefore, be approximated as:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SUPPLEMENTAL MATERIAL C ALGORITHM OF SIMPA</head><p>Algorithm 1 SImPa -train Input: task distribution p(T ) and hyper-parameters:</p><p>Output: hyper-meta-parameters ψ, encoder parameters φ enc and discriminator meta-parameters ω 0 1: initialise ψ, φ enc and ω 0 2: while ψ not converged do <ref type="bibr">3:</ref> sample</p><p>for each θ (k) do <ref type="bibr">6:</ref> for each task T i do 7:</p><p>:</p><p>⊲ Eq. 21 <ref type="bibr">10:</ref> repeat <ref type="bibr">11:</ref> sample z</p><p>: <ref type="bibr">18:</ref> until η times <ref type="bibr">19:</ref> sample z <ref type="formula">(14)</ref> and <ref type="formula">(16)</ref> 22:</p><p>repeat steps 11 and 13 to calculate L Di (ω i ) ⊲ Eq. 22 <ref type="bibr">23:</ref> end for <ref type="bibr">24:</ref> end for <ref type="bibr" target="#b26">25</ref>:</p><p>Algorithm 2 SImPa -test Input: unseen task T T +1 , and parameters ψ, φ enc and ω 0 obtained in the training phase Output: prediction y</p><p>⊲ Eq. 21 <ref type="bibr">6:</ref> repeat <ref type="bibr">7:</ref> sample z</p><p>: <ref type="bibr">15:</ref> until η times <ref type="bibr">16:</ref> sample z</p><p>T +1,j , w i (lv ) ) 20: end for <ref type="bibr">21:</ref> final prediction: p(y</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SUPPLEMENTAL MATERIAL D SETUP OF REGRESSION EXPERIMENT</head><p>The base model used for SImPa in this regression experiment is a two-hidden-layer fully connected neural network, each having 40 nodes followed by ReLU activation. The dimension of the latent noise in <ref type="bibr" target="#b21">(20)</ref> is Z = 40. The encoder FC enc (.; φ enc ) in (21) has the same architecture as the base network with the output layer having 2 × Z units since a Beta distribution has 2 parameters. The output of the encoder is then split into two halves, each assigned to β i1 and β i2 . The generator is a fully connected network with two hidden layers, containing 128 and 512 nodes, respectively. The discriminator is a three-hidden-layer fully connected network consisting of 512, 128, and 40 nodes, respectively. All the hidden layers of both the generator and discriminator are activated by ReLU, except that the output layers of the generator and discriminator are activated by tanh and sigmoid, respectively. The reason that tanh is used to activate the output of the generator is to limit the weights of the base network (similar to weight clipping) to prevent the not-a-number (NAN) error at the very beginning of training due to overflow. In addition, no batch normalisation is used across the base, encoder, generator and discriminator networks.</p><p>In the experiments, the significance level is δ = 10 −2 . The hyper-prior p(θ) is assumed to N (0, 100 × I). The numbers of Monte Carlo samples used to adapt to task and make prediction are L t = L v = 16. The number of samples of the base network weights used for adapting the discriminator is L D = 128. The number of θ sampled from q(θ; ψ) is K = 4. The task-specific variational parameters λ i and discriminator parameters ω i are estimated by performing 5 gradient updates with learning rates α t = 10 −3 and γ t = 10 −4 , respectively. The hyper-meta-parameters of interest ψ, which are the prior of the generator's parameters, the parameters of the encoder φ enc , and the meta-parameters of the discriminator ω 0 are optimised by Adam optimisers <ref type="bibr" target="#b21">[20]</ref> with step sizes α v = 10 −4 for the two formmer, and γ v = 10 −5 for the latter.</p><p>In addition, we provide more visualisations of regression results in <ref type="figure">Figure 6</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SUPPLEMENTAL MATERIAL E SETUP OF CLASSIFICATION EXPERIMENT</head><p>The setup of the N -way k-shot is done with the validation consisting of 15 examples in each class (m (t) i = kN , and m (v) i = 15N ). In addition, we apply label smoothing when training the discriminator by randomly sampling a real label from U[0.95, 1], and setting the fake label such that the sum of real and fake labels are 1. For the optimisation at task-level (or meta level), Adam optimiser is employed to optimise ψ, φ enc and ω 0 . Please refer to <ref type="table">Table 2</ref> for detailed hyper-parameters used.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Simpler pacbayesian bounds for hostile data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Alquier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Guedj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page" from="887" to="902" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">On the properties of variational approximations of gibbs posteriors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Alquier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Ridgway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Chopin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="8374" to="8414" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Meta-learning by adjusting priors based on extended PAC-Bayes theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><surname>Amit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><surname>Meir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="205" to="214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">On bayesian bounds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arindam</forename><surname>Banerjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine learning</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="81" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A model of inductive bias learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Baxter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="149" to="198" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shai</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Wortman</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A theory of learning from different domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vaughan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="151" to="175" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Generating sentences from a continuous space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vilnis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafal</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/K16-1002</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 20th SIGNLL Conference on Computational Natural Language Learning</title>
		<meeting>The 20th SIGNLL Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">2016</biblScope>
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Recnorm: Simultaneous normalisation and classification applied to speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bridle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="page" from="234" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="41" to="75" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Statistical learning theory and stochastic optimization: Ecole d&apos;Eté de Probabilités de Saint-Flour XXXI-2001</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Catoni</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Monte Carlo methods of inference for implicit statistical models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard J</forename><surname>Diggle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gratton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="193" to="212" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Modelagnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1126" to="1135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Probabilistic model-agnostic meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="9537" to="9548" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Lacoste</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Lacoste-Julien</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Pac-bayesian theory meets bayesian inference</title>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1884" to="1892" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Meta-learning probabilistic inference for prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bronskill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Turner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Recasting gradient-based meta-learning as hierarchical bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erin</forename><surname>Grant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">On calibration of modern neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoff</forename><surname>Pleiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Beta-VAE: Learning basic visual concepts with a constrained variational framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irina</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Loic</forename><surname>Matthey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arka</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shakir</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Lerchner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representation</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Human-level concept learning through probabilistic program induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Brenden M Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">350</biblScope>
			<biblScope unit="issue">6266</biblScope>
			<biblScope unit="page" from="1332" to="1338" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Autoencoding beyond pixels using a learned similarity metric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Boesen Lindbo Larsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Søren</forename><forename type="middle">Kaae</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ole</forename><surname>Winther</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1558" to="1566" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Avinash Ravichandran, and Stefano Soatto. Meta-learning with differentiable convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwonjoon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10657" to="10665" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">LGM-Net: Learning to generate matching networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaiyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiming</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chongyang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feiyue</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bao-Gang</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3825" to="3834" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Elliott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Lieb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Loss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Analysis</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<date type="published" when="2001" />
			<publisher>American Mathematical Soc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Transductive propagation network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanbin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juho</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minseop</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saehoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunho</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sung</forename><forename type="middle">Ju</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representation</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">PAC-Bayesian model averaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcallester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Conference on Computational Learning Theory</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="164" to="170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A simple neural attentive meta-learner</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostafa</forename><surname>Rohaninejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsendsuren</forename><surname>Munkhdalai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Yu</surname></persName>
		</author>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Rapid adaptation with conditionally shifted neurons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsendsuren</forename><surname>Munkhdalai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingdi</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soroush</forename><surname>Mehri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3661" to="3670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Uncertainty in model-agnostic meta-learning using variational inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cuong</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thanh-Toan</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustavo</forename><surname>Carneiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Winter Conference on Applications of Computer Vision</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3090" to="3100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Estimating divergence functionals and the likelihood ratio by convex risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanlong</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename><surname>Wainwright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="5847" to="5861" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Training generative neural samplers using variational divergence minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Botond</forename><surname>Cseke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryota</forename><surname>Tomioka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">. F-Gan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="271" to="279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">TADAM: Task dependent adaptive metric for improved few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Boris N Oreshkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pau</forename><surname>Lacoste</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rodriguez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="719" to="729" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A PAC-Bayesian bound for lifelong learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anastasia</forename><surname>Pentina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Lampert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="991" to="999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Amortized bayesian meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Beatson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Optimization as a model for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Meta-learning for semi-supervised few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengye</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleni</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representation</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">To transfer or not to transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zvika</forename><surname>Michael T Rosenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leslie</forename><forename type="middle">Pack</forename><surname>Marx</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">G</forename><surname>Kaelbling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dietterich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS 2005 workshop on transfer learning</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">898</biblScope>
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">The generalized reparameterization gradient</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michalis</forename><surname>Francisco R Ruiz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Titsias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Aueb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="460" to="468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">ImageNet Large Scale Visual Recognition Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Meta-learning with latent embedding optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Andrei A Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakub</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Sygnowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raia</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hadsell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Meta-learning with memory-augmented neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Bartunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1842" to="1850" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Evolutionary principles in selfreferential learning (On learning how to learn: the metameta-... hook). Diploma thesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
		</imprint>
		<respStmt>
			<orgName>Technische Universität München</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Understanding machine learning: From theory to algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shai</forename><surname>Shalev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-</forename><surname>Shwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shai</forename><surname>Ben-David</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4077" to="4087" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Distribution calibration for regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Diethe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meelis</forename><surname>Kull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Flach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">2019</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Density ratio estimation in machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taiji</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takafumi</forename><surname>Kanamori</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Learning to compare: Relation network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Flood</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Learning to learn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorien</forename><surname>Pratt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3630" to="3638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Bayesian model-agnostic meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaesik</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesup</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ousmane</forename><surname>Dia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungwoong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungjin</forename><surname>Ahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="7343" to="7353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Deep sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satwik</forename><surname>Kottur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siamak</forename><surname>Ravanbakhsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barnabas</forename><surname>Poczos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Russ</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3391" to="3401" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">MetaGAN: An adversarial approach to few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruixiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqiu</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="2371" to="2380" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
