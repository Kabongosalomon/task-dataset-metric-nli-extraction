<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Roto-Translation Equivariant Convolutional Networks: Application to Histopathology Image Analysis</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxime</forename><forename type="middle">W</forename><surname>Lafarge</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Biomedical Engineering</orgName>
								<orgName type="institution">Eindhoven University of Technology</orgName>
								<address>
									<settlement>Eindhoven</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><forename type="middle">J</forename><surname>Bekkers</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Mathematics and Computer Science</orgName>
								<orgName type="institution">Eindhoven University of Technology</orgName>
								<address>
									<settlement>Eindhoven</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josien</forename><forename type="middle">P W</forename><surname>Pluim</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Biomedical Engineering</orgName>
								<orgName type="institution">Eindhoven University of Technology</orgName>
								<address>
									<settlement>Eindhoven</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remco</forename><surname>Duits</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Mathematics and Computer Science</orgName>
								<orgName type="institution">Eindhoven University of Technology</orgName>
								<address>
									<settlement>Eindhoven</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitko</forename><surname>Veta</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Biomedical Engineering</orgName>
								<orgName type="institution">Eindhoven University of Technology</orgName>
								<address>
									<settlement>Eindhoven</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Roto-Translation Equivariant Convolutional Networks: Application to Histopathology Image Analysis</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T15:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Rotation-invariance is a desired property of machine-learning models for medical image analysis and in particular for computational pathology applications. We propose a framework to encode the geometric structure of the special Euclidean motion group SE(2) in convolutional networks to yield translation and rotation equivariance via the introduction of SE(2)group convolution layers. This structure enables models to learn feature representations with a discretized orientation dimension that guarantees that their outputs are invariant under a discrete set of rotations.</p><p>Conventional approaches for rotation invariance rely mostly on data augmentation, but this does not guarantee the robustness of the output when the input is rotated. At that, trained conventional CNNs may require test-time rotation augmentation to reach their full capability.</p><p>This study is focused on histopathology image analysis applications for which it is desirable that the arbitrary global orientation information of the imaged tissues is not captured by the machine learning models. The proposed framework is evaluated on three different histopathology image analysis tasks (mitosis detection, nuclei segmentation and tumor classification). We present a comparative analysis for each problem and show that consistent increase of performances can be achieved when using the proposed framework.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Invariance to irrelevant factors of variability is a desirable property of machine learning models, in particular for medical image analysis problems for which models are expected to generalize to unseen shapes, appearances, or to arbitrary orientations. For example, histopathology image analysis problems require processing a digital slide of a stained specimen whose global orientation is strictly arbitrary. Indeed, in the preparation workflow of histology slides, resection of the tissue is done arbitrarily and local structures within the section can have any three-dimensional orientation. In this context, models whose output varies with the orientation of the input constitute a source of uncertainty. The output of such image analysis systems should be rotation invariant, meaning that the output of a model should not change when its input is rotated.</p><p>Convolutional Neural Networks (CNNs) are the method of choice to solve complex image analysis tasks, in part due to the translation co-variance induced by trainable R 2 convolution operators. In theory, this structure allows CNNs to learn features in any orientation given sufficient capacity. For example, if a specific edge detector is a relevant filter for the task at hand, it is expected that the CNN learns this filter in all possible directions. Typical solutions to obtain rotation invariance consist in augmenting the dataset by generating additional randomly rotated samples, with the expectation that the model will learn the relevant features that are artificially observed under these additional orientations. Although data augmentation is a way to induce an invariance prior, such approaches do not guarantee conven-tional CNNs to be rotation-invariant. Furthermore, with such approaches it is common practice to average predictions of the trained model on a set of rotated inputs at test time: this can increase the robustness of the model, however it comes at the cost of a computational overhead.</p><p>We propose to replace convolutions in R 2 by group convolutions using representations of the special Euclidean motion group SE(2) (roto-translation of a kernel) so as to explicitly encode the orientation of the learned features. This structure ensures that the learned representation is covariant/equivariant with the orientation of the input for rotations that lay on the pixel grid and to some extent for rotations that are out of the pixel grid. We achieve orientation encoding at resolution levels higher than 90-degree via bi-linear interpolation of the SE(2) convolution kernels. Finally rotation invariance can be achieved via a projection operation with respect to the encoded orientation of the learned representation.</p><p>Contributions This work builds upon our previous work presented at the MICCAI conference 2018 <ref type="bibr" target="#b5">[Bekkers et al., 2018a]</ref>. In addition to a more detailed description of the proposed framework, we now present a comparative analysis of models with different angular discretization levels of the SE(2)-image representations. Here we focus on three types of histopathology image analysis problems (mitosis detection, nuclei segmentation and tumor classification), for which we conduct experiments on popular and realistic benchmark datasets. With this we also show that the SE(2)image representations can be integrated in other classical CNN architectures such as U-net <ref type="bibr" target="#b43">[Ronneberger et al., 2015]</ref>.</p><p>Roto-Translation Equivariant Convolutional Networks: Application to Histopathology Image Analysis Finally, in a new series of in-depth experimental analyses we show an increased robustness of the proposed G-CNNs compared to standard CNNs with respect to rotational variations in the data. This includes a quantitative and qualitative assessment of rotational invariance of the trained networks, as well as a data regime analysis in which we investigate the effect of increased angular resolution when the data availability is reduced.</p><p>2 Rotation Invariance, Related Work, and Contributions</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Rotation Invariance via G-CNNs</head><p>We distinguish between invariance and equivariance/covariance as follows. An artificial neural network (NN) is invariant with respect to certain transformations when the output of the network does not change under transformations on the input. We call a NN equivariant, or covariant 1 , when the output transforms in a predictable way when the input is transformed (we formalize this statement in Subsec. 3.2). The property of equivariance guarantees that no information is lost when the input is transformed. Standard CNNs are equivariant to translations: if the input is translated the output translates accordingly and we do not need to worry about learning how to deal with translated inputs. It turns out that group convolution layers are the only type of linear NN layers that are guaranteed to be equivariant (see e.g. <ref type="bibr">[Bekkers, 2019, Thm. 1]</ref>) and that the standard convolution layer is a special case that is translation equivariant. In this paper, we construct SE(2) equivariant group convolution layers and with it build G-CNNs with which we solve problems in histopathology that require rotation invariance.</p><p>Nowadays, rotation invariance is often still dealt with via data augmentations. In such an approach the data is rotated during training time while keeping the target label fixed, thereby aiming for the network to learn how to classify input samples regardless of their orientation. Downsides of this approach are that 1) valuable network capacity is spend on learning geometric behavior at the cost of descriptive representation learning, 2) rotation invariance is not guaranteed, and 3) augmentation only captures geometric invariance globally. G-CNNs solve these problems by hard-coding geometric structure into the network architecture such that 1) geometric behavior does not have to be learned, 2) rotation invariance is guaranteed by construction, and 3) each group convolution layer achieves local equivariance on its own, so that global equivariance is still obtained when the layers are stacked.</p><p>The local-to-global equivariance property means that G-CNNs recognize both low-level features (e.g. edges), midlevel features (e.g. individual cells), and high-level features 1 Terminology changes between fields of study (mathematics, physics, machine learning) and often refer to the same. Following custom in machine learning research we will use the term equivariance.</p><p>(e.g. tissue structure) independent of their orientations. In this paper we experimentally show that SE(2) equivariant G-CNNs indeed solve all three aforementioned problems and that in fact the added geometric structures leads to networks that significantly outperform classical CNNs trained with data-augmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Related Work on G-CNNs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">G-CNN Methods</head><p>In the seminal work by <ref type="bibr" target="#b10">Cohen and Welling [2016]</ref> a framework is proposed for group equivariant CNNs. In G-CNNs, the convolution operator is redefined in terms of actions of a transformation group, and by consistent use of the group structure (rules for concatenating transformations) equivariance is ensured. They showed a significant performance gain of G-CNNs over classical CNNs, however, the practical applicability was limited to discrete transformation groups that leave the pixel grid intact (s.a. 90 • rotations and reflections). Subsequent work in the field focused on expanding the class of transformation groups that are suitable for G-CNNs by:</p><p>1. Working with a grid that has more symmetries than the standard Cartesian grid <ref type="bibr" target="#b28">[Hoogeboom et al., 2018]</ref>.</p><p>2. Expanding convolution kernels in a special basis, tailored to the transformation group of interest, that enables to build steerable CNNs <ref type="bibr" target="#b54">[Worrall et al., 2017]</ref> 3. Relying on interpolation methods to transform kernels <ref type="bibr" target="#b5">Bekkers et al. [2018a]</ref>, or relying on analytic basis functions and sample the transformed kernels at arbitrary resolution <ref type="bibr" target="#b48">[Weiler et al., 2017</ref><ref type="bibr" target="#b6">, Bekkers et al., 2018b</ref>.</p><p>Extensions to 3D transformation groups are described in <ref type="bibr" target="#b52">[Worrall and Brostow, 2018</ref><ref type="bibr" target="#b51">, Winkels and Cohen, 2019</ref><ref type="bibr" target="#b49">, Weiler et al., 2018</ref><ref type="bibr" target="#b0">, Andrearczyk et al., 2019</ref>, generalization to equivariance beyond roto-translations are described in <ref type="bibr">[Bekkers, 2019, Worrall and</ref>, extension to spherical data are described in <ref type="bibr" target="#b11">[Cohen et al., 2018a</ref><ref type="bibr" target="#b33">, Kondor and Trivedi, 2018</ref><ref type="bibr" target="#b45">, Thomas et al., 2018</ref><ref type="bibr" target="#b20">, Esteves et al., 2018a</ref>, and additional theoretical results and further generalizations of G-CNNs are described in <ref type="bibr" target="#b12">[Cohen et al., 2018b</ref><ref type="bibr" target="#b33">, Kondor and Trivedi, 2018</ref>. Applications of G-CNN methods in medical image analysis are discussed below in Subsec. 2.2.4. Although the first of the above generalizations elegantly enables an exact implementation of G-CNNs of rototranslations with a finer resolution than the 90 • rotation angles of <ref type="bibr" target="#b10">[Cohen and Welling, 2016]</ref>, it is a very specific approach that does not generalize well to other groups. The second approach does not require to sample transformed kernels at all, but works exclusively by manipulations of basis coefficients in a similar way as standard 2D convolutions (and translations) can be described in the Fourier domain. This approach however requires careful bookkeeping of the coefficients, only optimizes over kernels expressible by the basis, and the choice for non-linear activation functions is limited. In this paper we rely on the third approach. We build upon our previous work <ref type="bibr" target="#b5">[Bekkers et al., 2018a]</ref> and use bi-linear interpolation to efficiently transform (unconstrained) convolution kernels. This allows us to build SE(2) equivariant G-CNNs at arbitrary angular resolutions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Rotation Equivariant Machine Learning</head><p>Prior, and in parallel, to the above discussed G-CNN methods, group convolution methods for pattern recognition have been proposed that, at the time, were not regarded as G-CNNs or not treated in the full generality of (end-to-end) deep learning. E.g., <ref type="bibr" target="#b23">Gens and Domingos [2014]</ref> redefine the convolution operator and construct sparse (approximative) group convolution layers that are used to build what they called deep symmetry networks. Scattering convolution networks, as proposed by <ref type="bibr" target="#b38">Mallat [2012]</ref>, involve a concatenation of separable group convolutions with well-designed handcrafted filters followed by the modulus as activation function. Other examples are orientation score based template matching , cyclic symmetry networks <ref type="bibr" target="#b14">[Dieleman et al., 2016]</ref>, oriented response networks <ref type="bibr" target="#b56">[Zhou et al., 2017]</ref>, and vector field networks <ref type="bibr" target="#b39">[Marcos et al., 2017]</ref>, which can all be considered instances of roto-translation equivariant G-CNNs.</p><p>Other techniques that focus on equivariance properties of CNNs work via transformations on input feature maps, rather than transformations of convolution kernels as in G-CNNs, and are closely related to spatial transformer networks <ref type="bibr" target="#b31">[Jaderberg et al., 2015]</ref>. These methods include warped CNNs <ref type="bibr" target="#b27">[Henriques and Vedaldi, 2017]</ref>, polar transformer networks <ref type="bibr" target="#b21">[Esteves et al., 2018b]</ref>, and equivariant transformer networks <ref type="bibr" target="#b44">[Tai et al., 2019]</ref>. Although these methods describe elegant and efficient ways for achieving (global) equivariance, they often break translation equivariance and local symmetries as the transformations act globally on the whole inputs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Group Theory in Medical Image Analysis</head><p>Equivariance constraints and group theory take a prominent position in the mathematical foundations of classical image analysis, e.g., in scale space and wavelet theory. In medical image analysis, group theoretical algorithms enable to respect natural equivariance constraints and deal with context and the complex geometries that are abundant in medical images. Examples of group theoretical techniques, closely related to G-CNNs, are orientation score <ref type="bibr" target="#b17">[Duits et al., 2007</ref><ref type="bibr" target="#b32">, Janssen et al., 2018</ref> methods such as crossing preserving vessel enhancement based on gauge theory on Lie groups <ref type="bibr" target="#b22">[Franken and Duits, 2009</ref><ref type="bibr" target="#b25">, Hannink et al., 2014</ref><ref type="bibr" target="#b18">, Duits et al., 2016</ref>, vessel and nerve fiber enhancement (in diffusion imaging) via group convolutions with Gaussian (derivative) kernels <ref type="bibr" target="#b16">[Duits and Franken, 2011</ref><ref type="bibr" target="#b55">, Zhang et al., 2015</ref><ref type="bibr" target="#b42">, Portegies et al., 2015</ref>, and anatomical landmark recognition via group convolutions <ref type="bibr" target="#b3">[Bekkers, 2019]</ref>. In other, non-convolutional methods in medical image analysis, group theory provides a powerful tool to deal with symmetries and geometric structure, such as in statistical shape atlases <ref type="bibr" target="#b26">[Hefny et al., 2015]</ref>, shape matching <ref type="bibr" target="#b29">[Hou et al., 2018]</ref>, registration <ref type="bibr" target="#b1">[Arsigny et al., 2006</ref><ref type="bibr" target="#b2">, Ashburner, 2007</ref> and in general in statistics on non-Euclidean data structures <ref type="bibr" target="#b41">[Pennec et al., 2019]</ref>. Following this successful line of geometry driven methods in medical image analysis, we propose in this paper to rely on G-CNNs to solve tasks in histopathology in an end-to-end learning setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.4">G-CNNs in Medical Image Analysis</head><p>For many medical image analysis tasks, the location, reflection or orientation of objects of interest should not affect the output of the developed models. Although typical solutions rely on data augmentation, several studies investigated G-CNNs in the context of medical image analysis to leverage this prior into building equivariant models that outperform classical CNNs.</p><p>In <ref type="bibr">Cohen [2018, 2019]</ref>, <ref type="bibr" target="#b0">Andrearczyk et al. [2019]</ref>, G-CNNs were used to detect pulmonary nodules in CT scans. G-CNNs were also investigated for segmentation tasks in dermoscopy images , retinal images <ref type="bibr" target="#b5">[Bekkers et al., 2018a]</ref> and microscopy images <ref type="bibr" target="#b5">[Bekkers et al., 2018a</ref><ref type="bibr" target="#b7">, Chidester et al., 2019a</ref><ref type="bibr" target="#b24">, Graham et al., 2019</ref>. <ref type="bibr" target="#b8">Chidester et al. [2019b]</ref> proposed a variation of G-CNNs for the classification of sub-cellular protein localization in microscopy images.</p><p>Rotation-equivariant models have shown to be particularly efficient for problems in histopathology images, at cell level for mitosis detection <ref type="bibr" target="#b5">[Bekkers et al., 2018a]</ref>, nuclei segmentation <ref type="bibr" target="#b7">[Chidester et al., 2019a]</ref>, and at higher tissue levels for tumor classification in lymph node sections <ref type="bibr" target="#b46">[Veeling et al., 2018]</ref> and gland-lumen segmentation in colon histology images <ref type="bibr" target="#b24">[Graham et al., 2019]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Material and Methods</head><p>We evaluate the proposed framework on three relevant histopathology image analysis tasks: mitosis detection, nuclei classification, and patch-based tumor classification. In this section, we first describe the benchmark datasets corresponding to the analysis tasks, that we used to train and evaluate the models. We then describe the relationship between the proposed framework and group theory, and our proposed implementation via bi-linear interpolation of rotated convolution kernels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets</head><p>We chose three popular benchmark datasets of hematoxylineosin stained histological slides, in order to assess the performances of the proposed framework and its variants in a controlled and reproducible setup. In these datasets, we activation map that is an image on SE(2). The SE(2) group convolution layer applies a shift-twist convolution via a set of rotated-and-shifted kernels in SE(2) to output a SE(2)-image activation map (red border highlights the kernel transformation, cyan border highlights the output of a SE(2) kernel). The projection layer transforms an input SE(2)-image onto R 2 via a rotation-invariant operation (pixel-wise maximum projection is used here). A 3-channel input is shown for the SE(2) group convolution layer and 1-channel outputs are shown for all the layers: this is done for illustrative purposes but more channels are used in practice. The example images used for the examples are extracted from a trained nuclei segmentation model with a 8-fold discretization of SE(2).</p><p>assume that the orientation of the objects of interest is irrelevant for the classification task. Therefore we hypothesize that any bias in the orientation information captured by a non-rotation-invariant CNN could be reflected in its performance on the selected benchmarks. This hypothesis will be experimentally confirmed in Sect. 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mitosis Detection</head><p>We used the public dataset AMIDA13 <ref type="bibr" target="#b47">[Veta et al., 2015]</ref> that consists of high power-field (HPF) images (resolution ∼0.25µm/px) from 23 breast cancer cases. Eight cases (458 mitotic figures) were used to train the models and four cases (92 mitoses) for validation. Evaluation is performed on a test set of 11 independent cases (533 mitoses), following the evaluation procedure of the AMIDA13 challenge, for details see <ref type="bibr" target="#b47">[Veta et al., 2015]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-Organ Nuclei Segmentation</head><p>We used the subset of the public multi-organ dataset introduced by <ref type="bibr" target="#b34">[Kumar et al., 2017]</ref>, that consists of 24 HPF images (resolution ∼0.25µm/px), selected from WSIs of four different tissue types (Breast, Liver, Kidney and Prostate), provided by The Cancer Genome Atlas <ref type="bibr" target="#b40">[Network et al., 2012]</ref>, associated with mask annotations of nucleus instances. We used the balanced dataset split proposed in <ref type="bibr" target="#b35">[Lafarge et al., 2019]</ref>: 4×3 HPF images for training (7337 nuclei), 4×1 HPF images for validation (1474 nuclei) and 4×2 HPF images for testing (4130 nuclei). Given the high staining variability of the dataset, all the images were stain normalized using the method described in <ref type="bibr" target="#b37">[Macenko et al., 2009]</ref>.</p><p>Patch-Based Tumor Classification We used the public PCam dataset introduced by <ref type="bibr" target="#b46">[Veeling et al., 2018]</ref>, that consists of 327, 680 image patches (resolution ∼1µm/px), selected from WSIs of lymph node sections derived from the Camelyon16 Challenge [Ehteshami <ref type="bibr" target="#b19">Bejnordi et al., 2017]</ref>. The patches are balanced across the two classes (benign or malignant), based on the tumor area provided in <ref type="bibr" target="#b19">[Ehteshami Bejnordi et al., 2017]</ref>, and we used the dataset split proposed by <ref type="bibr" target="#b46">[Veeling et al., 2018]</ref>.</p><p>Data Regime Analysis In order to study the behavior of the compared models when data availability is reduced, we analyzed the performances under different data regimes, by using reduced versions of the training sets. We constructed:</p><p>• Three variations of the mitosis dataset by sequentially removing two cases out of the original eight. • Two variations of the nuclei dataset by sequentially removing one HPF image per organ out of the original three HPF images per organ. • Four variations of the patch-based tumor dataset by randomly removing 25%, 50%, 75% and 90% in each class-subset of the training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Group Representation in CNNs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">The Roto-Translation group SE(2)</head><p>A group is a mathematical structure that consists of a set G, for example a collection of transformations, together with a binary operator · called the group product that satisfies four fundamental properties: Closure: For all h, g ∈ G we have h · g ∈ G; Identiy: There exists an identity element e; Inverse: for each g ∈ G there exists an inverse element g −1 ∈ G such that g −1 · g = g · g −1 = e; and Associativity:</p><formula xml:id="formula_0">For each g, h, i ∈ G we have (g · h) · i = g · (h · i).</formula><p>The group product essentially describes how two consecutive transformations, e.g. by g, h ∈ G, result in a single net transformation (g · h) ∈ G. Here, we consider the group of roto-translations, denoted 2 by SE(2) = R 2 SO(2), which consists of the set of all planar translations (in R 2 ) and rotations (in (SO <ref type="formula" target="#formula_5">(2)</ref>), together with the group product given by</p><formula xml:id="formula_1">g · g = (x, R θ ) · (x , R θ ) = (R θ x + x, R θ+θ ),<label>(1)</label></formula><p>with group elements g = (x, θ), g = (x , θ ) ∈ SE(2), with translations x, x and planar rotations by θ, θ . The group acts on the space of positions and orientations R 2 × S 1 via</p><formula xml:id="formula_2">g · (x , θ ) = (R θ x + x, θ + θ ).</formula><p>Since (x, R θ ) · (0, 0) = (x, θ), we can identify the group SE(2) with the space of positions and orientations R 2 × S 1 .</p><p>As such we will often write g = (x, θ), instead of (x, R θ ).</p><formula xml:id="formula_3">Note that g −1 = (−R −1 θ x, −θ) since g·g −1 = g −1 ·g = (0, 0).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Group representations</head><p>The structure of the group can be mapped to other mathematical objects (such as 2D images) via representations.</p><p>Representations of a group G are linear transformations R g : L 2 (X) → L 2 (X), parameterized by group elements g ∈ G that transform vectors, e.g. signals/images f ∈ L 2 (X) on a space X, and which share the group structure via</p><formula xml:id="formula_4">(R g • R h )(f ) = R g·h (f ), with g, h ∈ G.</formula><p>We use different symbols for the representations of SE(2) on different type of data structures. In particular, we write R = U for the left-regular representation of SE(2) on 2D images f ∈ L 2 (R 2 ), and it is given by</p><formula xml:id="formula_5">(U g f )(x ) = f (R −1 θ (x − x)),<label>(2)</label></formula><p>with g = (x, θ) ∈ SE(2), x ∈ R 2 . It corresponds to a rototranslation of the image. We write R = L for the left-regular representation on functions F ∈ L 2 (SE(2)) on SE <ref type="formula" target="#formula_5">(2)</ref>, which we refer to as SE(2)-images, and it is given by</p><formula xml:id="formula_6">(L g F )(g ) = F (g −1 · g ) = F (R −1 θ (x − x), θ − θ),<label>(3)</label></formula><p>with g = (x, θ), g = (x , θ ) ∈ SE(2). In Sec. 3.3 we define the G-CNN layers in terms of these representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Equivariance</head><p>Given the above definitions, we can formalize the notation of equivariance. An operator Φ :</p><formula xml:id="formula_7">L 2 (X) → L 2 (Y ) is equiv- ariant with respect to a group G if Φ(R g (f )) = R g (Φ(f )),<label>(4)</label></formula><p>with R g and R g representations of G on respectively functions the domains X and Y . I.e., if we transform the input by R g , then we know that the output transforms via R g .</p><p>To ensure that we maintain the equivariance property (4) of linear operators Φ it is required that we define such Φ in terms of representations of G, that is, via group convolutions (see e.g. <ref type="bibr">[Bekkers, 2019, Thm. 1]</ref>, <ref type="bibr">[Duits, 2005, Thm. 21]</ref>, or <ref type="bibr">[Cohen et al., 2018b, Thm. 6</ref>.1]).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">SE(2) Group Convolutional Network Layers</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Notation and 2D Convolution Layers</head><p>In the following we denote the space of multi-channel feature maps on a domain X by (L 2 (X)) N , with N the number of channels. The feature maps themselves are denoted by f = (f 1 , . . . , f N ), with each channel f i ∈ L 2 (X). The inner product between such feature maps on X is denoted by</p><formula xml:id="formula_8">(k, f ) (L2(X)) N := N c=1 (k c , f c ) L2(X)</formula><p>with (k, f ) L2(X) = X k(x )f (x )dx the standard inner product between real-valued functions on X. Then, with these notations we note that the classical 2D crosscorrelation 3 operator can defined in terms of inner products of input feature map f with translated convolution kernels k via</p><formula xml:id="formula_9">(k R 2 f )(x) : = (T x k, f ) (L2(R 2 )) N (5) = N c=1 R 2 k c (x − x)f c (x )dx ,</formula><p>with T x the translation operator, the left-regular representation of the translation group (R 2 , +). It is well known that convolution layers Φ, mapping between 2D feature maps (i.e. functions on X = Y = R 2 ), are equivariant with respect to translations. I.e. in Eq. (4) we let R g = R g = T x be the left-regular representation of the translation group with g = (x) ∈ R 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Roto-Translation Equivariant Convolution Layers</head><p>Next we define two types of convolution layers that are equivariant with respect to roto-translations. We do so simply by replacing the translation operator in Eq. (5) with a representation of SE <ref type="formula" target="#formula_5">(2)</ref>. When the input is a 2D feature map f ∈ (L 2 (R 2 )) N we need to rely on the representation U g of SE(2) on 2D images, and define the lifting correlation:</p><formula xml:id="formula_10">(k˜ f )(g) : = (U g k, f ) (L2(R 2 )) N (6) = N c=1 R 2 k c (R −1 θ (x − x))f c (x ) dx .</formula><p>These correlations lift 2D image data to data that lives on the 3D position orientation space R 2 × S 1 ≡ SE(2) by matching convolution kernels under all possible translations and rotations. We define the lifting layer , recall <ref type="figure" target="#fig_0">Fig. 1</ref>, as an operator Φ (l) : (L 2 (R 2 )) N l−1 → (L 2 (SE(2)) N l that maps a 2D feature map f (l−1) ∈ (L 2 (R 2 )) N l−1 with N l−1 channels to an SE(2) feature map F l ∈ (L 2 (SE(2)) N l with N l channels via lifting correlations with a collection of N l kernels, denoted with k (l) := (k</p><formula xml:id="formula_11">(l) 1 , . . . , k (l) N l ), each kernel with N l−1 channels, via F (l) =Φ (l) (f (l−1) ) := k (l)˜ f (l−1) ,<label>(7)</label></formula><p>where we overload the˜ symbol defined in Eq. (6) to also denote the lifting correlation between a set of convolution kernels and a vector valued feature map via k</p><formula xml:id="formula_12">(l)˜ f (l−1) := k (l) 1˜ f (l−1) , . . . , k<label>(l)</label></formula><p>N l˜ f (l−1) . Note that such operators are equivariant with respect to roto-translations when in (4) we let T g = U g and T g = L g be the representations of SE(2) given respectively in <ref type="formula" target="#formula_5">(2)</ref> and <ref type="formula" target="#formula_6">(3)</ref>, indeed Φ (l) (U g f (l−1) ) = L gΦ (l) (f (l−1) ).</p><p>The lifting layer thus generates higher-dimensional feature maps on the space of roto-translations. An SE(2) equivariant layer that takes such feature maps as input is then again obtained by taking inner products of the input feature map F with (3D) roto-translated convolution kernels K, where the kernels are transformed by application of the representation L g of SE(2) on L 2 (SE <ref type="formula" target="#formula_5">(2)</ref>). Group correlations are then defined as</p><formula xml:id="formula_13">(K F )(g) : = Nc c=1 (L g K c , F c ) L2(SE(2)) (8) = Nc c=1 SE(2) K c (g −1 · g )F c (g )dg .</formula><p>Note here, that a rotation of an SE(2) convolution kernel is obtained via a shift-twist, a planar rotation and shift along the θ-axis, see Eq.</p><p>(3) and <ref type="figure" target="#fig_0">Fig. 1</ref>. The convolution kernels K are 3-dimensional and they assign weights to activations at positions and orientations relative to a central position and orientation (relative to g ∈ SE <ref type="formula" target="#formula_5">(2)</ref>). A set of SE(2) kernels K (l) := (K (l) 1 , . . . , K</p><p>N l ) then defines a group convolution layer , which we denote with Φ (l) , and which maps from SE(2) feature maps F (l−1) at layer l−1, with N l−1 channels, to SE(2)-feature maps F (l) at layer l, with N l channels, via</p><formula xml:id="formula_15">F (l) = Φ (l) (F (l−1) ) := K (l) F (l−1) ,<label>(9)</label></formula><p>where we overload the group correlation symbol , defined in (8), to also denote correlation between a set of convolution kernels and a vector valued feature map on SE(2) via K (l)</p><formula xml:id="formula_16">F (l−1) := K (l) 1 F (l−1) , . . . , K (l) N l F (l−1)</formula><p>. Finally, we define the projection layer as the operator that projects a multi-channel SE(2) feature map back to R 2 via f (l) (x) = P(F (l) )(x) := mean</p><formula xml:id="formula_17">θ∈[0,2π) F (l) (x, θ).<label>(10)</label></formula><p>Here we define the projection layer as taking the mean over the orientation axis, however, we note that any permutation invariant operator (on the θ-axis) could be used to ensure local rotation invariance, such as e.g. the commonly used max operator <ref type="bibr">Welling, 2016, Bekkers et al., 2018a</ref>].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Discretized SE(2,N) Group Convolutional Network</head><p>Discretized 2D images are supported on a bounded subset of Z 2 ⊂ R 2 and the kernels live on a spatially rectangular grid of size n × n in Z 2 , with n the kernel size. We discretize the group SE(2, N ) := R 2 SO(2, N ), with the space of 2D rotations in SO(2) sampled with N rotation angles θ i = 2π N i, with i = 0, . . . , N − 1.</p><p>The discrete lifting kernels k (l) at layer l, are used to map a 2D input image with N l−1 channels to an SE(2, N )-image with N l channels, and thus have a shape of n×n×N l−1 ×N l (the discretization of k (l) is illustrated in <ref type="figure" target="#fig_0">Fig.1</ref> as a set of n rotated R 2 kernels, distributed on a circle). Likewise, the SE(2, N ) kernels K (l) have a shape of n×n×N ×N l−1 ×N l .</p><p>The lifting and group convolution layers require rotating the spatial part of the kernels and shift along the θ-axis for the SE(2)-kernels. We obtain the rotated spatial parts of each kernel via bi-linear interpolation. The discretization of a single lifting kernel k (l) i,j and its N rotated versions is illustrated in the top-left part of <ref type="figure" target="#fig_0">Fig.1</ref>. The discretization of a single group correlation kernel K (l) i,j and its N rotated and θ-shifted versions is illustrated in the bottom part of <ref type="figure" target="#fig_0">Fig.1</ref>.</p><p>In order to construct the rotated sets of effective kernels k (l) or K (l) we rely on bi-linear interpolation. We first define a set of vectors containing base weights that are used to generate rotated versions of the same 2D kernel via bi-linear interpolation (that we implemented with a sparse matrix multiplication). Although these sets of rotated kernels are used in the computational pipeline, only the base weights are updated during the network optimization. By construction, the effective kernels are differentiable with respect to their base weight, enabling their update in back-propagation of gradients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we present the G-CNN architectures that we build using the layers defined in Sec. 3.3 and we describe the experiments that we used to analyze and validate them. In the construction of the G-CNNs we adhere to the following principle of group equivariant architecture design.</p><p>G-CNN design principle A sequence of layers starting with a lifting layer (Eq. (7)) and followed by one or more group convolution layers (Eq. (9)), possibly intertwined with point-wise non-linearities, results in the encoding of rototranslation equivariant feature maps. If such a block is followed by a projection layer (Eq. (10)) then the entire block results in a encoding of features that is guaranteed to be rotationally invariant. Our implementation of the G-CNN layers is available at https://github.com/tueimage/se2cnn.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Applications and Model Architectures</head><p>For each task introduced in Sect. 3.1 we conducted two experiments: first, we trained a set of variations of a baseline CNN, by changing the orientation sampling level N of their SE(2,N) layers, while keeping the total number of weights of each model approximately the same. Second, we trained each model with the reduced data regime counterparts of the training sets introduced in Sect. 3.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mitosis Detection</head><p>We used the mitosis classification model originally described in <ref type="bibr" target="#b5">Bekkers et al. [2018a]</ref> as a baseline: a 6-layer CNN with three down-sampling steps, such that the overall receptive field is of size 68 × 68.</p><p>We designed the G-CNN variants of this baseline described in <ref type="table" target="#tab_0">Table 1</ref>, by replacing the first convolution layer by a lifting layer, replacing the following convolution layers by group convolution layers and inserting a projection layer before the last fully connected layer. The models were trained with batches of size 64 balanced across classes. Non-mitosis class patches were sampled based on a hard negative mining procedure <ref type="bibr" target="#b9">[Cireşan et al., 2013]</ref> using a first baseline model trained with random negative patches. The models were trained to minimize the cross-entropy of the binary-class predictions.</p><p>Nuclei Segmentation For the nuclei segmentation task, we opted for a 7-layer U-net that corresponds to two spatial down/up-sampling operations with an overall receptive field of size 44 × 44. The sequence of operations defining this G-CNN architecture is given in the first column of <ref type="table" target="#tab_1">Table 2</ref>.</p><p>The label associated with each input image is a 3-class mask corresponding to the foreground, background and border of the nuclei it contains (these masks can then be used to retrieve an individual nucleus using a segmentation procedure such as described in Sect. 5).</p><p>The models were trained with batches of size 16 balanced across patients, to minimize the class-weighted cross-entropy of the softmax activated output maps corresponding to the three target masks.</p><p>Tumor Classification The baseline architecture we used for the tumor classification model is a 6-layer CNN with three down-sampling steps, such that the overall receptive field is of size 88 × 88 (see <ref type="table" target="#tab_2">Table 3</ref> for the detailed architecture).</p><p>The models were trained with batches of size 64 balanced across classes. We refined both classes by running a hard negative mining procedure <ref type="bibr" target="#b9">[Cireşan et al., 2013]</ref> using a first baseline model trained with the original dataset of the benchmark. The models were trained to minimize the crossentropy of the binary-class predictions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Implementation details</head><p>For all three baseline architectures, convolution kernels are of size 5 × 5 with circular masking and fully connected layers are implemented as convolutional layers with kernels of shape 1×1 to enable dense application (the resulting models can efficiently be applied on larger input sizes). Batch Normalization <ref type="bibr" target="#b30">[Ioffe and Szegedy, 2015]</ref> is used throughout the networks. Batch statistics are normally computed across batch and spatial dimensions of the activations, but we also included the orientation-axis of the SE(2,N)image activation maps in the statistic computation to ensure their invariance with respect to the orientation of the input.</p><p>All models were trained with Stochastic Gradient Descent with momentum (learning rate 0.01, momentum 0.9) and a epoch-wise learning rate decay using a factor of 0.5 was applied. Training was stopped after convergence of the loss computed on the validation sets. All models were regularized with decoupled weight decay (coefficient 5 × 10 −4 ). Baseline augmentation transformations were applied to the training image patches (random spatial transposition, random 90-degree-wise rotation, random channel-wise brightness shifting).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Experiment: Orientation Sampling</head><p>In order to assess the effect of using the proposed SE(2,N) G-CNN structure on the benchmark performances, we trained every model with N ∈ {1, 4, 8, 16}. In order to allow fair comparison we adjusted the number of channels in every layer involving SE(2,N)-image representation such that the total number of weights in the models stay close to the count of the corresponding baselines. The detailed distributions of the weights are shown in Tables 1, 2 and 3: for each SE(2,N) group, the dimensions of the output of the layers are shown with the format N ×Height×W idth×C, with C the number of output channels in the layer. Each model was trained three times with random initialization seeds. We report the mean and standard deviation of the performances across three random intializations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Experiment: Data Regime Experiments</head><p>In order to assess the effect of using the proposed SE(2,N) with varying sampling factor N when data is availability is reduced, we trained each model on the data-regime subsets presented in Sect. 3.1. Likewise, each model was trained three times with random initialization seeds so as to report the variability of the performances.  <ref type="figure">Figure 2</ref>: Example of mitosis-centered image patches selected from the test set. Below each, polar plots show model predictions (distance from origin) as a function of the orientation of the input (angle coordinate) using steps of π/8 rad. An ideal model would then produce a circle with maximum radius. Selected models are indicated with colors, and correspond to the best obtained models that were trained without reduced data regime over repeats (based on their F 1 -score).</p><formula xml:id="formula_18">+ π 8 − π 8 (a) (b) (c) (d) (e) (f) (g) (h) (i) (j)</formula><p>baseline SE(2,4) <ref type="figure">Figure 3</ref>: Example of image patches selected from the test set of the PCam benchmark, for which pixels in the center area were classified as tumor tissue. Below each, polar plots show model predictions (distance from origin) as a function of the orientation of the input (angle coordinate) using steps of π/8 rad. Selected models are indicated with colors, and correspond to the best obtained models that were trained without reduced data regime over repeats (based on their accuracy).</p><formula xml:id="formula_19">SE(2,8) p=0 p=1 0 + π 8 − π 8 (a) (b) (c) (d) (e) (f) (g) (h) (i) (j)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>This section summarizes the qualitative and quantitative results of the experiments we conducted. Each trained model was evaluated on the test set of its corresponding benchmark dataset based on standard performance metrics.</p><p>Mitosis Detection For the mitosis detection task, models were densely applied on test images, followed by a smoothing operation before extracting all local maxima to be considered candidate detections. We computed the F 1score of the set of detections using an operating point that is optimized on the validation set, as described in the scoring protocol used in <ref type="bibr" target="#b47">[Veta et al., 2015]</ref>.</p><p>Nuclei Segmentation To quantify the performances of the nuclei segmentation model, generation of segmented candidate objects is obtained by following the protocol used in <ref type="bibr" target="#b34">[Kumar et al., 2017</ref><ref type="bibr" target="#b35">, Lafarge et al., 2019</ref>. First, marker seeds are derived from thresholded foreground and background predictions, border predictions are used as the watershed energy landscape. Then, candidate objects that overlap the nuclei ground-truth masks by at least 50% of their area are considered hits, enabling object-level detection quantification to be calculated using the F 1 -score. Thresholds to generate marker seeds were selected such that the F 1 -score is maximized on the validation set.</p><p>Patch-based tumor classification To evaluate the tumor classification model, we computed the class probability of every patch of the test dataset and calculated the accuracy of the model given the ground-truth labels as in <ref type="bibr" target="#b46">Veeling et al. [2018]</ref> after selection of the operating point that maximizes the accuracy on the validation set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Qualitative Results</head><p>We qualitatively investigated the robustness of the prediction of different models to controlled rotations of the input. We see that the model predictions can be very inconsistent for our best baseline model, in comparison to G-CNN models (see <ref type="figure">Fig. 2, Fig. 4 and 3</ref>) in particular for cell or tissue morphologies that are typically asymmetric. For example, the mitotic figures (h) and (i) shown in <ref type="figure">Fig. 2</ref> are in telophase (directed separation of the pair of chromosomes) and the variance of the prediction of the baseline model is higher for these cases (green curve) compared to the G-CNN models (blue and red curves). We also observe that for the SE(2,4) model, predictions that are obtained for an input image rotated with an angle below π/2rad also produce some variance, but present a π/2rad-period cyclic pattern.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Quantitative Results</head><p>The performances of the trained models for both orientation sampling experiments and data regime experiments are summarized in the box plots of <ref type="figure" target="#fig_2">Fig. 5, 6</ref>   <ref type="figure">Figure 4</ref>: Example of image patches selected from the test set of the nuclei segmentation benchmark (column 1-2: breast tissue, column 3-4: prostate tissue, column 5: kidney tissue, column 6: liver). For each image, and a selection of models, the raw predictions of the nucleus boundary class were computed and stored for the set of rotated inputs using steps of π/8 rad. Predictions were re-aligned and their means were mapped to gray-scale and the standard deviations of the predictions were mapped to a white-to-red color scale. The overlap of these statistics is shown below each original image. Selected models are the best obtained models that were trained without reduced data regime over repeats (based on their F 1 -score).  Effect of orientation sampling For all three studied tasks, we observed an increase of performance with the number of sampled orientations from N = 1 to N = 8. For the full data regime of the mitosis detection experiments, the use of a SE(2,8) G-CNN improves the F 1 -score to 0.626±0.015 on average compared to 0.556±0.016 for the baseline model without test-time rotation augmentation (see <ref type="figure" target="#fig_2">Fig. 5</ref>). A similar increase of performances is observed for the nuclei segmentation experiments with an improvement of the F 1score from 0.754±0.006 to 0.771±0.06 (see <ref type="figure">Fig. 6</ref>), and for the tumor classification experiments with an improvement of the accuracy from 0.863±0.003 to 0.892±0.004 (see <ref type="figure">Fig.  7</ref>). We remark that the performances of the SE(2,4) G-CNN models are better than the baseline with test-time rotation augmentation as was previously reported in literature for similar tasks <ref type="bibr" target="#b5">[Bekkers et al., 2018a</ref><ref type="bibr" target="#b46">, Veeling et al., 2018</ref>. We also report that for all three tasks, SE(2,16) G-CNN models perform worse than the SE(2,8) G-CNN models.</p><p>Effect of reduced data regime with orientation sampling For all three tasks, we see a global consistent decrease of performances when less training data is available. In <ref type="figure">Fig. 7</ref>, the performances of the SE(2,4) and SE(2,8) G-CNN models trained with the 25%, 50% and 75% data regimes, are higher than for the baseline model at full data regime using test-time rotation augmentation. This reveals that under experimental conditions, data availability is not the only reason for limited performances since this experiment shows that the SE(2,N) G-CNN models enable achieving higher performances than the baseline models, even if less data is available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion and Conclusions</head><p>The presented study investigated the effects of embedding the SE(2) group structure in CNNs, in the context of histopathology image analysis, across multiple controlled experimental setups.</p><p>The comparative analysis we conducted shows a consistent increase of performances for three different histopathology image analysis tasks when using the proposed SE(2,N) G-CNN architecture compared to conventional CNNs acting in R 2 evaluated with test-time rotation augmentation. This is in line with previously reported results when using G-CNNs with groups that lay on the pixel grid (p4, p4m) <ref type="bibr">Welling, 2016, Veeling et al., 2018]</ref>, but we also show that these performances can be surpassed when using groups with higher discretization levels of SE(2).</p><p>This confirms that conventional R 2 CNNs struggle to learn a rotation equivariant representation based on data solely and that enforcing equivariant representation learning enables reaching higher performances. G-CNNs with SE(2,N) structure have the advantage to guarantee higher robustness to input orientation without requiring trainingtime or test-time rotation augmentation. Furthermore, the slight computational overhead for computing rotated convolutional operators and their gradient, at training time, can be canceled at test-time by computing and fixing all final oriented SE(2,N) kernels, resulting in a model that is computationally equivalent to conventional R 2 CNNs.</p><p>We show that these performances can be surpassed when using representations with higher angular resolution levels, as shown with experiments involving SE(2,8) G-CNNs and when the training data is of sufficient amount. This conclusion corroborates the results we reported on other medical image analysis tasks <ref type="bibr" target="#b5">[Bekkers et al., 2018a]</ref> and in studies that investigated models with rotated operators that lay outside of the pixel grid <ref type="bibr" target="#b28">[Hoogeboom et al., 2018]</ref>.</p><p>However, we also identified consistent lower performances for SE(2,16) G-CNNs compared to SE(2,8) G-CNNs at full data regime. We assume that this phenomenon is in part related to the model architectures we chose to enforce fixed model capacity, resulting in a number of channels in the representation of the SE(2,N) models being reduced when N increases. This reduced number of channels might affect the diversity of the features learned by the models, to the point that this limits their overall performances. Therefore, it appears there is a trade-off between performances and angular resolution at fixed capacity, further work would be necessary to confirm this hypothesis. For the tumor classification task, we observed that the performances of the baseline models (with or without testtime rotation augmentation) reached a plateau, whatever the regime of available training data was among 25%, 50%, 75% or 100%. This indicates that in the conditions of the PCam dataset, the amount of available training data does not significantly influence the performances. However, the rotation-equivariant models were able to achieve better performances with increased data regime.</p><p>This behavior was not evidenced for the mitosis detection and nuclei segmentation experiments. We assume this result may be task-dependent or might be due to the fact that the plateau of performances observed for the tumor classification models was not reached yet for the two other tasks.</p><p>We qualitatively showed that in some cases, the predictions of conventional CNNs are inconsistent when inputs are rotated, whereas SE(2) G-CNNs show better stability in that sense. This suggests that the anisotropic learned features of conventional models only get activated when the input is observed in a specific orientation. On the shown examples (Sect. 5.1), the SE(2) models are more robust to the input orientation since their SE(2) structure guarantees the features to be expressed in multiple orientations. We also see that SE(2) models with a limited angular resolution can yet produce some variance for rotation angles lower than this resolution. This is also supported by the fact that higher performances were obtained for the experiments that compare SE(2,4) models to SE(2,8) models.</p><p>Still, variation of performances for these models was also observed when the input was rotated out of the pixel grid. We explain this limit from the approximation errors caused by two of the operators we used, and that have a weaker rotation equivariance property. First, the interpolation-based computation of the rotated kernels can cause small variations in the output when the input is rotated. Second, the pooling operators are not rotation equivariant by construction (since they lay on fixed down-sampled versions of the pixel grid), and so are another source of error.</p><p>In conclusion, we proposed a framework for SE(2) group-convolutional network and showed its advantages for histopathology image analysis tasks. This framework enables the learned models to be invariant to the natural rototranslational symmetry of histology images. We showed that G-CNNs models whose representation have a SE(2) structure yield better performances than conventional CNNs and our experiments suggest the ability of G-CNNs models to fully exploit the data amount of large datasets. Our results suggest the existence of a trade-off between network capacity and the chosen angular resolution of the SE(2,N) operators. Directions for future work include further analysis of the relationship between the newly introduced architecturerelated hyper-parameters and their effect on model performances, as well as studying other prior structures that can improve model stability to other families of input transformations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Illustration of the three types of layers investigated in our G-CNNs. The lifting layer uses a set of rotated kernels in R 2 to output an</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Mean and Standard Deviation plots summarizing the F</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Architecture of the investigated G-CNN models for mitosis detection. The left-most column indicates the operations applied in each layer. Max. Proj. indicates the projection operation on R 2 , achieved via maximum intensity projection along the orientations.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">SE(2,N) Groups</cell><cell></cell></row><row><cell>Layers</cell><cell cols="2">N=1 (R 2 ) N=4 (p4)</cell><cell>N=8</cell><cell>N=16</cell></row><row><cell>Input</cell><cell></cell><cell cols="2">68×68×3</cell><cell></cell></row><row><cell>Lifting Layer</cell><cell>1×42×42×16</cell><cell>4×42×42×10</cell><cell>8×42×42×8</cell><cell>16×42×42×6</cell></row><row><cell>BN + ReLU</cell><cell>(1040)</cell><cell>(650)</cell><cell>(520)</cell><cell>(390)</cell></row><row><cell>MaxPool(2×2)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Group Conv.</cell><cell>1×14×14×16</cell><cell>4×14×14×10</cell><cell>8×14×14×8</cell><cell>16×14×14×6</cell></row><row><cell>BN + ReLU</cell><cell>(5408)</cell><cell>(8420)</cell><cell>(10768)</cell><cell>(12108)</cell></row><row><cell>MaxPool(2×2)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Group Conv.</cell><cell>1×5×5×16</cell><cell>4×5×5×10</cell><cell>8×5×5×8</cell><cell>16×5×5×6</cell></row><row><cell>BN + ReLU</cell><cell>(5408)</cell><cell>(8420)</cell><cell>(10768)</cell><cell>(12108)</cell></row><row><cell>MaxPool(2×2)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Group Conv.</cell><cell>1×1×1×64</cell><cell>4×1×1×16</cell><cell>8×1×1×8</cell><cell>16×1×1×4</cell></row><row><cell>BN + ReLU</cell><cell>(21632)</cell><cell>(13472)</cell><cell>(10768)</cell><cell>(8072)</cell></row><row><cell>Group Conv.</cell><cell>1×1×1×16</cell><cell>4×1×1×16</cell><cell>8×1×1×16</cell><cell>16×1×1×16</cell></row><row><cell>BN + ReLU</cell><cell>(1056)</cell><cell>(1056)</cell><cell>(1056)</cell><cell>(1056)</cell></row><row><cell>Max. Proj.</cell><cell></cell><cell>1×1×16</cell><cell></cell><cell></cell></row><row><cell>FC Layer</cell><cell></cell><cell cols="2">1×1×1 (17)</cell><cell></cell></row><row><cell>Sigmoid</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Total</cell><cell>34561</cell><cell>32035</cell><cell>33897</cell><cell>33751</cell></row><row><cell>Weights</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Architecture and weight counting of the G-CNN models for patch-based tumor classification. The left-most column indicates the operations in each layer. Concat(HL.x) indicates the characteristic skip operation of the U-net architecture that consist in concatenating a centered crop of the output activation of the x th layer of the network. Max. Proj. indicates the projection operation on R 2 , achieved via maximum intensity projection along the orientations.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">SE(2,N) Groups</cell><cell></cell></row><row><cell>Layers</cell><cell cols="2">N=1 (R 2 ) N=4 (p4)</cell><cell>N=8</cell><cell>N=16</cell></row><row><cell>Input</cell><cell></cell><cell cols="2">60×60×3</cell><cell></cell></row><row><cell>Lifting Layer</cell><cell>1×28×28×16</cell><cell>4×28×28×10</cell><cell>8×28×28×8</cell><cell>16×28×28×6</cell></row><row><cell>BN + ReLU</cell><cell>(1040)</cell><cell>(650)</cell><cell>(520)</cell><cell>(390)</cell></row><row><cell>MaxPool(2×2)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Group Conv.</cell><cell>1×12×12×16</cell><cell>4×12×12×10</cell><cell>8×12×12×8</cell><cell>16×12×12×6</cell></row><row><cell>BN + ReLU</cell><cell>(5408)</cell><cell>(8420)</cell><cell>(10768)</cell><cell>(12108)</cell></row><row><cell>MaxPool(2×2)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Group Conv.</cell><cell>1×8×8×16</cell><cell>4×8×8×10</cell><cell>8×8×8×8</cell><cell>16×8×8×6</cell></row><row><cell>BN + ReLU</cell><cell>(5408)</cell><cell>(8420)</cell><cell>(10768)</cell><cell>(12108)</cell></row><row><cell>Up-sampling</cell><cell>1×12×12×16</cell><cell>4×12×12×10</cell><cell>8×12×12×8</cell><cell>16×12×12×6</cell></row><row><cell>Concat(HL.2)</cell><cell>(10784)</cell><cell>(16820)</cell><cell>(21520)</cell><cell>(24204)</cell></row><row><cell>Group Conv.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>BN + ReLU</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Up-sampling</cell><cell>1×20×20×64</cell><cell>4×20×20×16</cell><cell>8×20×20×8</cell><cell>16×20×20×4</cell></row><row><cell>Concat(HL.1)</cell><cell>(43136)</cell><cell>(26912)</cell><cell>(21520)</cell><cell>(16136)</cell></row><row><cell>Group Conv.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>BN + ReLU</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Group Conv.</cell><cell>1×20×20×16</cell><cell>4×20×20×16</cell><cell>8×20×20×16</cell><cell>16×20×20×16</cell></row><row><cell>BN + ReLU</cell><cell>(1056)</cell><cell>(1056)</cell><cell>(1056)</cell><cell>(1056)</cell></row><row><cell>Max. Proj.</cell><cell></cell><cell cols="2">20×20×16</cell><cell></cell></row><row><cell>FC Layer</cell><cell></cell><cell cols="2">20×20×3 (54)</cell><cell></cell></row><row><cell>Softmax</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Total</cell><cell>66886</cell><cell>62332</cell><cell>66206</cell><cell>66056</cell></row><row><cell>Weights</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Architecture and weight counting of the G-CNN models for patch-based tumor classification. The left-most column indicates the operations in each layer. Mean. Proj. indicates the projection operation on R 2 , achieved via mean intensity projection along the orientations.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">SE(2,N) Groups</cell><cell></cell></row><row><cell>Layers</cell><cell cols="2">N=1 (R 2 ) N=4 (p4)</cell><cell>N=8</cell><cell>N=16</cell></row><row><cell>Input</cell><cell></cell><cell cols="2">88×88×3</cell><cell></cell></row><row><cell>Lifting Layer</cell><cell>1×42×42×32</cell><cell>4×42×42×19</cell><cell>8×42×42×14</cell><cell>16×42×42×10</cell></row><row><cell>BN + ReLU</cell><cell>(2080)</cell><cell>(1235)</cell><cell>(910)</cell><cell>(650)</cell></row><row><cell>MaxPool(2×2)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Group Conv.</cell><cell>1×19×19×32</cell><cell>4×19×19×19</cell><cell>8×19×19×14</cell><cell>16×19×19×10</cell></row><row><cell>BN + ReLU</cell><cell>(21568)</cell><cell>(30362)</cell><cell>(32956)</cell><cell>(33620)</cell></row><row><cell>MaxPool(2×2)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Group Conv.</cell><cell>1×5×5×32</cell><cell>4×5×5×19</cell><cell>8×5×5×14</cell><cell>16×5×5×10</cell></row><row><cell>BN + ReLU</cell><cell>(21568)</cell><cell>(30362)</cell><cell>(32956)</cell><cell>(33620)</cell></row><row><cell>MaxPool(3×3)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Group Conv.</cell><cell>1×1×1×64</cell><cell>4×1×1×16</cell><cell>8×1×1×8</cell><cell>16×1×1×4</cell></row><row><cell>BN + ReLU</cell><cell>(43136)</cell><cell>(25568)</cell><cell>(18832)</cell><cell>(13448)</cell></row><row><cell>Group Conv.</cell><cell>1×1×1×16</cell><cell>4×1×1×16</cell><cell>8×1×1×16</cell><cell>16×1×1×16</cell></row><row><cell>BN + ReLU</cell><cell>(1056)</cell><cell>(1056)</cell><cell>(1056)</cell><cell>(1056)</cell></row><row><cell>Mean Proj.</cell><cell></cell><cell>1×1×16</cell><cell></cell><cell></cell></row><row><cell>FC Layer</cell><cell></cell><cell cols="2">1×1×1 (17)</cell><cell></cell></row><row><cell>Sigmoid</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Total</cell><cell>89425</cell><cell>88600</cell><cell>86727</cell><cell>82411</cell></row><row><cell>Weights</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">It is the semi-direct product (denoted by ) of the group of planar translations R 2 and rotations SO(2), i.e., it is not the direct product since the rotation part acts on the translations in (1) in the group product of SE(2).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">In CNNs one can take a convolution or a cross-correlation viewpoint and since these operators simply relate via a kernel reflection, the terminology is often used interchangeably. We take the second viewpoint, our G-CNNs are implemented using cross-correlations.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Exploring local rotation invariance in 3d cnns with steerable filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Andrearczyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fageot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Oreiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Montet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Depeursinge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MIDL</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="15" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A log-euclidean framework for statistics on diffeomorphisms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Arsigny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Commowick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Pennec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ayache</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="924" to="931" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A fast diffeomorphic image registration algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ashburner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="95" to="113" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Bekkers</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.12057</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">B-Spline CNNs on Lie groups. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Training of Templates for Object Recognition in Invertible Orientation Scores: Application to Optic Nerve Head Detection in Retinal Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Bekkers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Duits</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Loog</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Energy Minimization Methods in Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">8932</biblScope>
			<biblScope unit="page" from="464" to="477" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Roto-translation covariant convolutional networks for medical image analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Bekkers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Lafarge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Veta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Eppenhof</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Pluim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Duits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="440" to="448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Bekkers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Loog</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Ter Haar Romeny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Duits</surname></persName>
		</author>
		<title level="m">Template matching via densities on the rototranslation group. tPAMI</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="452" to="466" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Enhanced rotation-equivariant u-net for nuclear segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chidester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-V</forename><surname>Ton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Do</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshops</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Rotation equivariant and invariant neural networks for microscopy image analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chidester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="530" to="537" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Mitosis detection in breast cancer histology images with deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Cireşan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Giusti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="411" to="418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Group equivariant convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2990" to="2999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Khler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<title level="m">Spherical cnns. In ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Weiler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.02017</idno>
		<title level="m">A General Theory of Equivariant CNNs on Homogeneous Spaces</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Gauge equivariant convolutional networks and the icosahedral cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Weiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kicanaoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">De</forename><surname>Fauw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.02660</idno>
		<title level="m">Exploiting cyclic symmetry in convolutional neural networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Perceptual organization in image analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Duits</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
		<respStmt>
			<orgName>Eindhoven University of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
	<note>the Netherlands</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Left-invariant diffusions on the space of positions and orientations and their application to crossing-preserving smoothing of HARDI images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Duits</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Franken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page" from="231" to="264" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Image analysis and reconstruction using a wavelet transform constructed from a reducible representation of the Euclidean motion group</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Duits</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Felsberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Granlund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ter Haar Romeny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="79" to="102" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Locally Adaptive Frames in the Roto-Translation Group and Their Applications in Medical Imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Duits</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H J</forename><surname>Janssen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hannink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">R</forename><surname>Sanguinetti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Imaging and Vision</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="367" to="402" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">and the CAMELYON16 Consortium. Diagnostic Assessment of Deep Learning Algorithms for Detection of Lymph Node Metastases in Women With Breast Cancer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">Ehteshami</forename><surname>Bejnordi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Veta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Johannes Van Diest</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Ginneken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Karssemeijer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Litjens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A W M</forename><surname>Van Der Laak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Jama</title>
		<imprint>
			<biblScope unit="volume">318</biblScope>
			<biblScope unit="page" from="2199" to="2210" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning SO(3) Equivariant Representations with Spherical CNNs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Esteves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Allen-Blanchette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Makadia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Polar Transformer Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Esteves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Allen-Blanchette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Crossing-preserving coherenceenhancing diffusion on invertible orientation scores</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Franken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Duits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page">253</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep symmetry networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Domingos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2537" to="2545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Rota-net: Rotation equivariant network for simultaneous gland and lumen segmentation in colon histology images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rajpoot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECDP</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="109" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Crossing-Preserving Multi-scale Vesselness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hannink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Duits</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Bekkers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="603" to="610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A liver atlas using the special euclidean group</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Hefny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Okada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Ellis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="238" to="245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Warped convolutions: Efficient invariance to spatial transformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1461" to="1469" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hoogeboom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W T</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hexaconv. In ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Computing CNN Loss and Gradients for Pose Estimation with Riemannian Geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Miolane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Khanal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alansary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mcdonagh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">V</forename><surname>Hajnal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Glocker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kainz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="756" to="764" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Spatial transformer networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jaderberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2017" to="2025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Design and Processing of Invertible Orientation Scores of 3d Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M H J</forename><surname>Janssen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J E M</forename><surname>Janssen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Bekkers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Olivn</forename><surname>Bescs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Duits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Imaging and Vision</title>
		<imprint>
			<biblScope unit="page" from="1" to="32" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">On the Generalization of Equivariance and Convolution in Neural Networks to the Action of Compact Groups</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kondor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2747" to="2755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A dataset and a technique for generalized nuclear segmentation for computational pathology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bhargava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vahadane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sethi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1550" to="1560" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning domain-invariant representations of histological images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lafarge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pluim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Eppenhof</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Veta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Medicine</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">162</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Deeply supervised rotation equivariant network for lesion segmentation in dermoscopy images. In OR 2.0 Context-Aware Operating Theaters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-W</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-A</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Clinical Image-Based Procedures, and Skin Image Analysis</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="235" to="243" />
		</imprint>
		<respStmt>
			<orgName>Computer Assisted Robotic Endoscopy</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A method for normalizing histology slides for quantitative analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Macenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Niethammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Marron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Borland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Woosley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">E</forename><surname>Thomas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISBI</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1107" to="1110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Group invariant scattering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mallat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications on Pure and Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="1331" to="1398" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Rotation Equivariant Vector Field Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Marcos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Volpi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tuia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5048" to="5057" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Comprehensive molecular portraits of human breast tumours</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G A</forename><surname>Network</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">490</biblScope>
			<biblScope unit="page" from="61" to="70" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Riemannian Geometric Statistics in Medical Image Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Pennec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sommer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Fletcher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Improving fiber alignment in HARDI by combining contextual PDE flow with constrained spherical deconvolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Portegies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H J</forename><surname>Fick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">R</forename><surname>Sanguinetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Meesters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Girard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Duits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">S</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bailis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Valiant</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.11399</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">Equivariant Transformer Networks. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Smidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kearnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kohlhoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Riley</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.08219</idno>
		<title level="m">Tensor Field Networks: Rotation-and Translation-Equivariant Neural Networks for 3d Point Clouds</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Rotation equivariant cnns for digital pathology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">S</forename><surname>Veeling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Linmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Winkens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="210" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Assessment of algorithms for mitosis detection in breast cancer histopathology images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Veta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Van Diest</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Willems</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Image Analysis</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="237" to="248" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Learning steerable filters for rotation equivariant cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Weiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">A</forename><surname>Hamprecht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Storath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Cohen. 3d steerable cnns: Learning rotationally equivariant features in volumetric data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Weiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Boomsma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="10381" to="10392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">3d g-cnns for pulmonary nodule detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Winkels</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MIDL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Pulmonary nodule detection in ct scans with equivariant cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Winkels</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Image Analysis</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="15" to="26" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Cubenet: Equivariance to 3d rotation and translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Worrall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Brostow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="567" to="584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Worrall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.11697</idno>
		<title level="m">Deep Scale-spaces: Equivariance Over Scale</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Harmonic networks: Deep translation and rotation equivariance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Worrall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Garbin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Turmukhambetov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Brostow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5028" to="5037" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Robust and Fast Vessel Segmentation via Gaussian Derivatives in Orientation Scores</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Bekkers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Abbasi-Sureshjani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dashtbozorg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Ter Haar Romeny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICIAP</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="537" to="547" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Oriented response networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4961" to="4970" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
