<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Dependency-Guided LSTM-CRF for Named Entity Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-09-23">23 Sep 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanming</forename><surname>Jie</surname></persName>
							<email>zhanmingjie@mymail.sutd.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="laboratory">StatNLP Research Group</orgName>
								<orgName type="institution">Singapore University of Technology and Design</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
							<email>luwei@sutd.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="laboratory">StatNLP Research Group</orgName>
								<orgName type="institution">Singapore University of Technology and Design</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Dependency-Guided LSTM-CRF for Named Entity Recognition</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-09-23">23 Sep 2019</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T11:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Dependency tree structures capture longdistance and syntactic relationships between words in a sentence. The syntactic relations (e.g., nominal subject, object) can potentially infer the existence of certain named entities. In addition, the performance of a named entity recognizer could benefit from the longdistance dependencies between the words in dependency trees. In this work, we propose a simple yet effective dependency-guided LSTM-CRF model to encode the complete dependency trees and capture the above properties for the task of named entity recognition (NER). The data statistics show strong correlations between the entity types and dependency relations. We conduct extensive experiments on several standard datasets and demonstrate the effectiveness of the proposed model in improving NER and achieving state-of-theart performance. Our analysis reveals that the significant improvements mainly result from the dependency relations and long-distance interactions provided by dependency trees.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Named entity recognition (NER) is one of the most important and fundamental tasks in natural language processing (NLP). Named entities capture useful semantic information which was shown helpful for downstream NLP tasks such as coreference resolution <ref type="bibr" target="#b24">(Lee et al., 2017)</ref>, relation extraction <ref type="bibr" target="#b31">(Miwa and Bansal, 2016)</ref> and semantic parsing <ref type="bibr" target="#b10">(Dong and Lapata, 2018)</ref>. On the other hand, dependency trees also capture useful semantic information within natural language sentences. Currently, research efforts have derived useful discrete features from dependency structures <ref type="bibr" target="#b43">(Sasano and Kurohashi, 2008;</ref><ref type="bibr" target="#b6">Cucchiarelli and Velardi, 2001;</ref><ref type="bibr" target="#b26">Ling and Weld, 2012)</ref> or structural constraints (Jie Accepted as a long paper in EMNLP 2019 (Conference on Empirical Methods in Natural Language Processing). et al., 2017) to help the NER task. However, how to make good use of the rich relational information as well as complex long-distance interactions among words as conveyed by the complete dependency structures for improved NER remains a research question to be answered. The first example in <ref type="figure" target="#fig_0">Figure 1</ref> illustrates the relationship between a dependency structure and a named entity. Specifically, the word "premises", which is a named entity of type LOC (location), is characterized by the incoming arc with label "pobj" (prepositional object). This arc reveals a certain level of the semantic role that the word "premises" plays in the sentence. Similarly, the two words "Hong Kong" in the second example that form an entity of type GPE are also characterized by a similar dependency arc towards them.</p><p>The long-distance dependencies capturing nonlocal structural information can also be very helpful for the NER task <ref type="bibr" target="#b12">(Finkel et al., 2005)</ref>. In the second example of <ref type="figure" target="#fig_0">Figure 1</ref>, the long-distance dependency from "held" to "seminar" indicates a direct relation "nsubjpass" (passive subject) between them, which can be used to characterize the existence of an entity. However, existing NER models based on linear-chain structures would have difficulties in capturing such long-distance relations (i.e., non-local structures).</p><p>One interesting property, as highlighted in the work of <ref type="bibr" target="#b19">Jie et al. (2017)</ref>, is that most of the entities form subtrees under their corresponding dependency trees. In the example of the EVENT entity in <ref type="figure" target="#fig_0">Figure 1</ref>, the entity itself forms a subtree and the words inside have rich complex dependencies among themselves. Exploiting such dependency edges within the subtrees allows a model to capture non-trivial semantic-level interactions between words within long entities. For example, "practice" is the prepositional object (pobj) of "on" which is a preposition (prep) of "seminar" in the EVENT entity. Modeling these grandchild dependencies (GD) <ref type="bibr" target="#b21">(Koo and Collins, 2010)</ref> requires the model to capture some higher-order long-distance interactions among different words in a sentence. Inspired by the above characteristics of dependency structures, in this work, we propose a simple yet effective dependency-guided model for NER. Our neural network based model is able to capture both contextual information and rich long-distance interactions between words for the NER task. Through extensive experiments on several datasets on different languages, we demonstrate the effectiveness of our model, which achieves the state-of-the-art performance. To the best of our knowledge, this is the first work that leverages the complete dependency graphs for NER. We make our code publicly available at http://www.statnlp.org/research/ information-extraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>NER has been a long-standing task in the field of NLP. While many recent works <ref type="bibr" target="#b33">(Peters et al., 2018a;</ref><ref type="bibr" target="#b0">Akbik et al., 2018;</ref><ref type="bibr" target="#b9">Devlin et al., 2019)</ref> focus on finding good contextualized word representations for improving NER, our work is mostly related to the literature that focuses on employing dependency trees for improving NER. <ref type="bibr" target="#b43">Sasano and Kurohashi (2008)</ref> exploited the syntactic dependency features for Japanese NER and achieved improved performance with a support vector machine (SVM) <ref type="bibr" target="#b4">(Cortes and Vapnik, 1995)</ref> classifier. Similarly, <ref type="bibr" target="#b26">Ling and Weld (2012)</ref> included the head word in a dependency edge as features for fine-grained entity recognition. Their approach is a pipeline where they extract the entity mentions with linear-chain conditional random fields (CRF) <ref type="bibr" target="#b22">(Lafferty et al., 2001)</ref> and used a classifier to predict the entity type. <ref type="bibr" target="#b27">Liu et al. (2010)</ref> proposed to link the words that are associated with selected typed dependencies (e.g., "nn", "prep") using a skip-chain CRF <ref type="bibr">(Sutton and Mc-Callum, 2004)</ref> model. They showed that some specific relations between the words can be exploited for improved NER. <ref type="bibr" target="#b6">Cucchiarelli and Velardi (2001)</ref> applied a dependency parser to obtain the syntactic relations for the purpose of unsupervised NER. The resulting relation information serves as the features for potential existence of named entities. <ref type="bibr" target="#b19">Jie et al. (2017)</ref> proposed an efficient dependency-guided model based on the semi-Markov CRF <ref type="bibr" target="#b42">(Sarawagi and Cohen, 2004)</ref> for NER. The purpose is to reduce time complexity while maintaining the non-Markovian features. They observed certain relationships between the dependency edges and the named entities. Such relationships are able to define a reduced search space for their model. While these previous approaches do not make full use of the dependency tree structures, we focus on exploring neural architectures to exploit the complete structural information conveyed by the dependency trees.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model</head><p>Our dependency-guided model is based on the state-of-the-art BiLSTM-CRF model proposed by <ref type="bibr" target="#b23">Lample et al. (2016)</ref>. We first briefly present their model as background and next present our dependency-guided model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Background: BiLSTM-CRF</head><p>In the task of named entity recognition, we aim to predict the label sequence y = {y 1 , y 2 , · · · , y n } given the input sentence x = {x 1 , x 2 , · · · , x n } where n is the number of words. The labels in y are defined by a label set with the standard IOBES 1 labeling scheme <ref type="bibr" target="#b38">(Ramshaw and Marcus, 1999;</ref><ref type="bibr" target="#b39">Ratinov and Roth, 2009</ref>). The CRF <ref type="bibr" target="#b22">(Lafferty et al., 2001)</ref> layer defines the probability of the label sequence y given x:</p><formula xml:id="formula_0">P (y|x) = exp(score(x, y)) y ′ exp(score(x, y ′ ))<label>(1)</label></formula><p>Following <ref type="bibr" target="#b23">Lample et al. (2016)</ref>, the score is defined as the sum of transitions and emissions from the bidirectional LSTM (BiLSTM):</p><formula xml:id="formula_1">score(x, y) = n i=0 A y i ,y i+1 + n i=1 F x,y i<label>(2)</label></formula><p>where A is a transition matrix in which A y i ,y i+1 is the transition parameter from the label y i to the label y i+1 2 . F x is an emission matrix where F x,y i represents the scores of the label y i at the i-th position. Such scores are provided by the parameterized LSTM <ref type="bibr" target="#b17">(Hochreiter and Schmidhuber, 1997)</ref> networks. During training, we minimize the negative log-likelihood to obtain the model parameters including both LSTM and transition parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Dependency-Guided LSTM-CRF</head><p>Input Representations The word representation w in the BiLSTM-CRF <ref type="bibr" target="#b23">(Lample et al., 2016;</ref><ref type="bibr" target="#b28">Ma and Hovy, 2016;</ref><ref type="bibr" target="#b41">Reimers and Gurevych, 2017)</ref> model consists of the concatenation of the word embedding as well as the corresponding character-based representation. Inspired by the fact that each word (except the root) in a sentence has exactly one head (i.e., parent) word in the dependency structure, we can enhance the word representations with such dependency information. Similar to the work by <ref type="bibr" target="#b31">Miwa and Bansal (2016)</ref>, we concatenate the word representation together with the corresponding head word representation and dependency relation embedding as the input representation. Specifically, given a dependency edge (x h , x i , r) with x h as parent, x i as child and r as dependency relation, the representation at position i can be denoted as:</p><formula xml:id="formula_2">u i = [w i ; w h ; v r ] , x h = parent(x i ) (3)</formula><p>where w i and w h are the word representations of the word x i and its parent x h , respectively. We take the final hidden state of character-level BiL-STM as the character-based representation <ref type="bibr" target="#b23">(Lample et al., 2016)</ref>. v r is the embedding for the dependency relation r. These relation embeddings are randomly initialized and fine-tuned during training. The above representation allows us to capture the direct long-distance interactions at the input layer. For the word that is a root of the dependency tree, we treat its parent as itself 3 and create a root relation embedding. Additionally, contextualized word representations (e.g., ELMo) can also be concatenated into u.</p><p>Neural Architecture Given the dependencyencoded input representation u, we apply the LSTM to capture the contextual information and  <ref type="figure">Figure 2</ref>: Dependency-guided LSTM-CRF with 2 LSTM Layers. Dashed connections mimic the dependency edges. "g(·)" represents the interaction function.</p><formula xml:id="formula_3">u 1 u 2 u 3 u 4 u 5 u 6 LSTM LSTM LSTM LSTM LSTM LSTM g(·) g(·) g(·) g(·) g(·) g(·) LSTM LSTM LSTM LSTM LSTM LSTM S-PER O O O O S-GPE</formula><p>model the interactions between the words and their corresponding parents in the dependency trees. <ref type="figure">Figure 2</ref> shows the proposed dependency-guided LSTM-CRF (DGLSTM-CRF) with 2 LSTM layers for the example sentence "Abramov had an accident in Moscow" and its dependency structure. The corresponding label sequence is {S-PER, O, O, O, O, S-GPE}. Followed by the first BiLSTM, the hidden states at each position will propagate to the next BiLSTM layer and its child along the dependency trees. For example, the hidden state of the word "had", h</p><p>2 , will propagate to its child "Abramov" at the first position. For the word that is root, the hidden state at that specific position will propagate to itself. We use an interaction function g(h i , h p i ) to capture the interaction between the child and its parent in a dependency. Such an interaction function can be concatenation, addition or a multilayer perceptron (MLP). We further apply another BiLSTM layer on top of the interaction functions to produce the context representation for the final CRF layer.</p><p>The architecture shown in <ref type="figure">Figure 2</ref> with a 2layer BiLSTM can effectively encode the grandchild dependencies because the input representations encode the parent information and the interaction function further propagate the grandparent information. Such propagations allow the model to capture the indirect long-distance interactions from the grandchild dependencies between the words in the sentence as mentioned in Section 1. In general, we can stack more interaction functions and BiLSTMs to enable deeper reasoning over the dependency trees. Specifically, the hid- den states of the (l + 1)-th layer H (l+1) can be calculated from the hidden state of the previous layer H (l) :</p><formula xml:id="formula_5">Interaction Function g(h i , h pi ) Self connection h i Concatenation h i h pi Addition h i + h pi MLP ReLU W 1 h i +W 2 h pi</formula><formula xml:id="formula_6">H (l+1) = BiLSTM f H (l) H (l) = h (l) 1 , h (l) 2 , · · · , h (l) n f H (l) = g(h (l) 1 , h (l) p 1 ), · · · , g(h (l) n , h (l) pn )</formula><p>where p i indicates the parent index of the word</p><formula xml:id="formula_7">x i . g(h (l) i , h<label>(l)</label></formula><p>p i ) represents the interaction functions between the hidden state at the i-th and p ith positions under the dependency edges (x p i , x i ). The number of layers L can be chosen according to the performance on the development set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Interaction Function</head><p>The interaction function between the parent and child representations can be defined in various ways. <ref type="table" target="#tab_1">Table 1</ref> shows the list of interaction function considered in our experiments. The first one returns the hidden state itself, which is equivalent to stacking the LSTM layers. The concatenation and addition involve no parameter, which are straightforward ways to model the interactions. The last one applies an MLP to model the interaction between parent and child representations. With the rectified linear unit (ReLU) as activation function, the g(h i , h p i ) function is analogous to a graph convolutional network (GCN) (Kipf and Welling, 2017) formulation. In such a graph, each node has a self connection (i.e., h i ) and a dependency connection with parent (i.e., h p i ). Similar to the work by <ref type="bibr" target="#b30">Marcheggiani and Titov (2017)</ref>, we adopt different parameters W 1 and W 2 for self and dependency connections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>Datasets The main experiments are conducted on the large-scale OntoNotes 5.0 <ref type="bibr">(Weischedel et al., 2013)</ref> English and Chinese datasets. We chose these datasets because they contain both constituency tree and named entity annotations. There are 18 types of entities defined in the OntoNotes dataset. We convert the constituency   <ref type="bibr">(Recasens et al., 2010) 7</ref> . The SemEval-2010 task was originally designed for the task of coreference resolution in multiple languages. Again, we chose these corpora primarily because they contain both dependency and named entity annotations. Following Finkel and Manning (2009) and <ref type="bibr" target="#b19">Jie et al. (2017)</ref>, we select the most dominant three entity types and merge the rest into one general a entity type "misc". <ref type="table" target="#tab_3">Table  2</ref> shows the statistics of the datasets used in main experiments. To further evaluate the effectiveness of the dependency structures, we also conduct additional experiments under a low-resource setting for NER <ref type="bibr" target="#b5">(Cotterell and Duh, 2017)</ref>.</p><p>The last two columns of <ref type="table" target="#tab_3">Table 2</ref> show the relationships between the dependency trees and named entities with length larger than 2 for the complete dataset. Specifically, the penultimate column shows the percentage of entities that can form a complete subtree (ST) under their dependency tree structures. Apparently, most of the entities form subtrees, especially for the Catalan and Spanish datasets where 100% entities form subtrees. This observation is consistent with the findings reported in <ref type="bibr" target="#b19">Jie et al. (2017)</ref>. The last column in <ref type="table" target="#tab_3">Table 2</ref> shows the percentage of the grandchild dependencies <ref type="bibr" target="#b21">(Koo and Collins, 2010)</ref> (GD) that exist in these subtrees (i.e., entities). Such grandchild dependencies could be useful for detecting certain named entities, especially for long entities.</p><formula xml:id="formula_8">D G Y P R G D P R G F R Q M G H S G H W G R E M Q Q Q V X E M Q X P Q X P E H U S R E M S R V V S U H S S X Q F W T X D Q WP R G WP R G &amp;$5',</formula><p>As we will see later in Section 5, the performance of long entities can be significantly improved with our dependency-guide model. The heatmap table in <ref type="figure">Figure 3</ref> shows the correlation between the entity types and the dependency relations in the OntoNotes English dataset. Specifically, each entry denotes the percentage of the entities that have a parent dependency with a specific dependency relation. For example, at the row with GPE entity, 37% of the entity words 8 have a dependency edge whose label is "pobj". When looking at column of "pobj" and "nn", we can see that most of the entities relate to the prepositional object (pobj) and noun compound modifier (nn) dependencies. Especially for the NORP (i.e., nationalities or religious or political groups) and ORDINAL (e.g., "first", "second") entities, more than 60% of the entity words have the dependency with adjectival modifier (amod) relation. Furthermore, every entity type (i.e., row) has a most related dependency relation (with more than 17% occurrences). Such observations present useful information that can be used to categorize named entities with different types.</p><p>Baselines We implemented the state-of-the-art NER model BiLSTM-CRF <ref type="bibr" target="#b23">(Lample et al., 2016)</ref> as the first baseline with different number of LSTM layers (L = {0, 1, 2, 3}). L = 0 indi-8 The words that are annotated with entity labels.</p><p>cates the model only relies on the input representation. Following , the complete dependency trees are considered bidirectional and encoded with a contextualized GCN (BiLSTM-GCN). We further add the relation-specific parameters <ref type="bibr" target="#b30">(Marcheggiani and Titov, 2017</ref>) and a CRF layer for the NER task. The resulting baseline is BiLSTM-GCN-CRF 9 . We use the bootstrapping paired t-test <ref type="bibr" target="#b1">(Berg-Kirkpatrick et al., 2012)</ref> for significance test when comparing the results of different models.</p><p>Experimental Setup We choose MLP as the interaction function in our DGLSTM-CRF according to performance on the development set. The hidden size of all models (i.e., LSTM, GCN) is set to 200. We use the Glove <ref type="bibr" target="#b32">(Pennington et al., 2014)</ref> 100-d word embeddings, which was shown to be effective in English NER task <ref type="bibr" target="#b28">(Ma and Hovy, 2016;</ref><ref type="bibr" target="#b33">Peters et al., 2018a)</ref>. We use the publicly available FastText <ref type="bibr" target="#b16">(Grave et al., 2018)</ref> word embeddings for Chinese, Catalan and Spanish. The ELMo <ref type="bibr" target="#b33">(Peters et al., 2018a)</ref>, deep contextualized word representations 10 are used for all languages in our experiments since <ref type="bibr" target="#b2">Che et al. (2018)</ref> provides ELMo for many other languages 11 , including Chinese, Catalan and Spanish. We use the average weights over all layers of the ELMo representations and concatenate them with the input representation u. Our models are optimized by mini-batch stochastic gradient descent (SGD) with learning rate 0.01 and batch size 10. The L 2 regularization parameter is 1e-8. The hyperparameters are selected according to the performance on the OntoNotes English development set. <ref type="table" target="#tab_6">Table 3</ref> shows the performance comparison between our work and previous work on the OntoNotes English dataset. Without the LSTM layers (i.e., L = 0), the proposed model with dependency information significantly improves the NER performance with more than 2 points in F 1 compared to the baseline BiLSTM-CRF (L = 0), which demonstrate the effective-  ness of dependencies for the NER task. Our best performing BiLSTM-CRF baseline (with Glove) achieves a F 1 score of 87.78 which is better than or on par with previous works <ref type="bibr" target="#b3">(Chiu and Nichols, 2016;</ref><ref type="bibr" target="#b25">Li et al., 2017;</ref><ref type="bibr" target="#b15">Ghaddar and Langlais, 2018)</ref> with extra features. This baseline also outperforms the CNN-based models <ref type="bibr" target="#b44">(Strubell et al., 2017;</ref><ref type="bibr" target="#b25">Li et al., 2017)</ref>. The BiLSTM-GCN-CRF model outperforms the BiLSTM-CRF model but achieves inferior performance compared to the proposed DGLSTM-CRF model. We believe it is challenging to preserve the surrounding context information with stacking GCN layers while contextual information is important for NER <ref type="bibr" target="#b34">(Peters et al., 2018b)</ref>. Overall, the 2-layer DGLSTM-CRF model significantly (with p &lt; 0.01) outperforms the best BiLSTM-CRF baseline and the BiLSTM-GCN-CRF model. As we can see from the table, increasing the number of layers (e.g., L = 3) does not give us further improvements for both BiLSTM-CRF and DGLSTM-CRF because such third-order information (e.g., the relationship among a words parent, its grandparent, and greatgrandparent) does not play an important role in indicating the presence of named entities.  We further compare the performance of all models with ELMo <ref type="bibr" target="#b33">(Peters et al., 2018a)</ref> representations to investigate whether the effect of dependency would be diminished by the contextualized word representations. With L = 0, the ELMo representations largely improve the performance of BiLSTM-CRF compared to the BiLSTM-CRF model with word embeddings only but is still 1 point below our DGLSTM-CRF model. The 2layer DGLSTM-CRF model outperforms the best BilSTM-CRF baseline with 0.9 points in F 1 (p &lt; 0.001). Empirically, we found that among the entities that are correctly predicted by DGLSTM-CRF but wrongly predicted by BiLSTM-CRF, 47% of them are with length more than 2. Our finding shows the 2-layer DGLSTM-CRF model is able to accurately recognize long entities, which can lead to a higher precision. In addition, 51.9% of the entities that are correctly retrieved by DGLSTM-CRF have the dependency relations "pobj", "nn" and "nsubj", which have strong correlations with certain named entity types <ref type="figure">(Figure 3)</ref>. Such a result demonstrates the effectiveness of dependency relations in improving the recall of NER. <ref type="table" target="#tab_8">Table 4</ref> shows the performance comparison on the Chinese datasets. We compare our models against the state-of-the-art  NER model on this dataset, Lattice LSTM <ref type="bibr" target="#b47">(Zhang and Yang, 2018)</ref> 12 . Our implementation of the strong BiLSTM-CRF baseline achieves comparable performance against the Lattice LSTM. Similar to the English dataset, our model with L = 0 significantly improves the performance compared to the BiLSTM-CRF (L = 0) model. Our DGLSTM-CRF model achieves the best performance with L = 2 and is consistently better (p &lt; 0.02) than the strong BiLSTM-CRF baselines. As we can see from the table, the improvements of the DGLSTM-CRF model mainly come from recall (p &lt; 0.001) compared to the BiLSTM model, especially in the scenario with word embeddings only. Empirically, we also found that those correctly retrieved entities of the DGLSTM-CRF (compared against the baseline) mostly correlate with the following dependency relations: "nn", "nsubj", "nummod". However, DGLSTM-CRF achieves lower precisions against BiLSTM-CRF, which indicates that the DGLSTM-CRF model makes more false-positive predictions. The reason could be the relatively lower ratio of ST(%) 13 as shown in <ref type="table" target="#tab_3">Table 2</ref>, which means some of the entities do not form subtrees under the complete dependency trees. In such a scenario, the model may not correctly identify the boundary of the entities, which results in lower precision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Main Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>OntoNotes English</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>OntoNotes Chinese</head><p>SemEval-2010 <ref type="table" target="#tab_10">Table 5</ref> shows the results of our models on the SemEval-2010 Task 1 datasets. Overall, we observe substantial improvements of the DGLSTM-CRF on the Catalan and Spanish datasets (with p &lt; 0.001 marked in bold against the best performing BiLSTM-CRF baseline), especially for DGLSTM-CRF with ELMo and L larger than 1. With word embeddings, the best DGLSTM-CRF model outperforms the best performing BiLSTM-CRF baseline with more than 10 and 9 points in F 1 on the Catalan and Spanish datasets, respectively. The BiLSTM-GCN-CRF model also performs much better than the BiLSTM-CRF baselines but is worse than the DGLSTM-CRF model with L ≥ 2. Both precision and recall significantly improve with a large margin compared to the best performing BiLSTM-CRF, especially for the recall (with more than 10 points improvement) on these two datasets. With ELMo, the best performing DGLSTM-CRF model outperforms the BiLSTM-CRF baseline with about 6 and 7 points in F 1 on these two datasets, respectively. The substantial improvements show that the structural dependency information is extremely helpful for these two datasets.</p><p>With ELMo representations, we observe about 2 and 3 points improvements in F 1 compared with the 1-layer DGLSTM-CRF model on these two datasets, respectively. Empirically, more than 50% of the entities that are correctly predicted by the   2-layer model but not the 1-layer model are with length larger than 2. Also, most of these entities contain the grandchild dependencies "(sn, sn)" and "(spec, sn)" where sn represents noun phrase and spec represents specifier (e.g., determiner, quantifier) in both datasets. Such a finding shows that the 2-layer model is able to capture the interactions given by the grandchild dependencies. <ref type="table" target="#tab_11">Table 6</ref> shows the performance on the CoNLL-2003 English dataset. The dependencies are predicted from Spacy <ref type="bibr">(Honnibal and Montani, 2017)</ref>. With the contextualized word representations, DGLSTM-CRF outperforms BiLSTM-CRF with 0.2 points in F 1 (p &lt; 0.09). The improvement is not significant due to the relatively lower equality of the dependency trees. To further study the effect of the dependencies, we modified the predicted dependencies to ensure each entity form a subtree in the complete dataset. Such modification improves the F 1 to 92.7, which is significantly better (p &lt; 0.05) than the BiLSTM-CRF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Additional Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CoNLL-2003 English</head><p>Low-Resource NER Following <ref type="bibr" target="#b5">Cotterell and Duh (2017)</ref>, we emulate truly low-resource condition with 100 sentences for training. We assume that the contextualized word representations are not available and dependencies are predicted. <ref type="table" target="#tab_12">Table 7</ref> shows the NER performance on the SemEval-2010 Task 1 datasets under the lowresource setting. With limited amount of training data, BiLSTM-CRF suffers from low recall and the DGLSTM-CRF largely improves it on these two datasets. Using gold dependencies further significantly improves the precision and recall.   Effect of Dependency Quality To evaluate how the quality of dependency trees affect the performance, we train a state-of-the-art dependency parser <ref type="bibr" target="#b11">(Dozat and Manning, 2017)</ref> using our training set and make prediction on the development/test set. We implemented the dependency parser using the AllenNLP package <ref type="bibr" target="#b14">(Gardner et al., 2017)</ref>. <ref type="table" target="#tab_14">Table 8</ref> shows the performance (LAS) of the dependency parser on four languages (i.e., OntoNotes English, OntoNotes Chinese, Catalan and Spanish) and the performance of DGLSTM-CRF against the best performing BiLSTM-CRF with ELMo. DGLSTM-CRF even with predicted dependencies is able to consistently outperform the BiLSTM-CRF on four languages. However, the performance is still worse than the DGLSTM-CRF with gold dependencies, especially on the Catalan and Spanish. Such results suggest that it is essential to have high-quality dependency annotations available for the proposed model. <ref type="table" target="#tab_15">Table 9</ref> shows the ablation study of the 2-layer DGLSTM-CRF model on the OntoNotes English dataset. With self connection as interaction function, the F 1 drops 0.3 points. The model achieves comparable performance with concatenation as interaction function but F 1 drops about 0.4 points with the addition interaction function. We believe that the addition potentially leads to certain information loss. Without the depen-  dency relation embedding v r in the input representation, the F 1 drops about 0.4 points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ablation Study</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Effectiveness of Dependency Relations</head><p>To demonstrate whether the model benefits from the dependency relations, we first select the entities that are correctly predicted by the 2-layer DGLSTM-CRF model but not by the best performing baseline 2-layer BiLSTM-CRF on the OntoNotes English dataset. We draw the heatmap in <ref type="figure" target="#fig_2">Figure 4</ref> based on these entities. Comparing <ref type="figure">Figure 3</ref> and 4, we can see that they are similar in terms of the density. Both of them show consistent relationships between the entity types and the dependency relations. The comparison shows that the improvements partially result from the effect of dependency relations. We also found from our model's predictions that some entity types have strong correlations with the relation pairs on grandchild dependencies 14 . <ref type="table" target="#tab_1">Table 10</ref> shows the performance comparison with different entity lengths on all datasets. As mentioned earlier, the dependencies as well as the grandchild relations allow our models to capture the long-distance interactions between the words. As shown in the table, the performance of entities with lengths more than 1 consistently improves with DGLSTM-CRF for all languages except Chinese. As we pointed out in the dataset statistics <ref type="table" target="#tab_3">(Table 2)</ref>, the number of entities that form subtrees in OntoNotes Chinese is relatively smaller compared to other datasets. The performance gain is more significant for entities with longer length on <ref type="bibr">14</ref> The corresponding heatmap visualization is provided in supplementary material.  the other three languages. We found that, among the improvements of entities with length larger than 2 in English, 85% of them have long-distance dependencies and 30% of them have grandchild dependencies within the entity boundary. The analysis shows that our model that exploits the dependency tree structures is helpful for recognizing long entities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Entity with Different Lengths</head><formula xml:id="formula_9">D G Y P R G D P R G F F R P S F R Q M G H S G H W G R E M Q Q Q V X E M Q V X E MS D V V Q X P Q X P E H U S F R P S S R E M S R V V S R V V H V V LY H S U H S S X Q F W T X D Q WP R G U R R W WP R G &amp;</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions and Future Work</head><p>Motivated by the relationships between the dependency trees and named entities, we propose a dependency-guided LSTM-CRF model to encode the complete dependency tree and capture such relationships for the NER task. Through extensive experiments on several datasets, we demonstrate the effectiveness of the proposed model in improving the NER performance. Our analysis shows that NER benefits from the dependency relations and long-distance dependencies, which are able to capture the non-local interactions between the words. As statistics shows that most of the entities form subtrees under the dependency trees, future work includes building a model for joint NER and dependency parsing which regards each entity as a single unit in a dependency tree.  the i-th word and the j-th word. Such formulation uses the relation to weight the adjacent hidden states in the dependencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Implementation Details</head><p>We implemented all the models with PyTorch (?). For both BiLSTM-CRF and DGLSTM-CRF model, we train them on all datasets with 100 epochs and take the model that perform the best on the development set. For BiLSTM-GCN-CRF, we train for 300 epochs with a clipping rate of 3. <ref type="figure" target="#fig_5">Figure 6</ref> visualized the correlations between the entities and the grandchild dependency relation pairs on the OntoNotes English dataset. As mentioned in the paper, such entities are correctly predicted by our models but not the BiLSTM-CRF baseline. As we can see from the figure, most of these entities correlate to the "(nn, nn)" and "(nn, pobj)" relation pairs on the grandchild dependencies. Such correlations also show that the relation pair information on the grandchild dependencies can be helpful for detecting certain entities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Relation Pairs on Grandchild Dependencies</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Using Predicted Dependency</head><p>We train a BERT-based <ref type="bibr" target="#b9">(Devlin et al., 2019)</ref> dependency parser <ref type="bibr" target="#b11">(Dozat and Manning, 2017)</ref> using the training set for each of four languages. Specifically, we adopt the bert-base-uncased model for English, bert-base-multilingual-cased for Catalan and Spanish and bert-base-chinese for Chinese. Because the Chinese BERT model is based on characters but not Chinese words which are segmented. We   further incorporate a span extractor layer right after BERT encoder for Chinese. We following <ref type="bibr" target="#b24">Lee et al. (2017)</ref> to design the span extractor layer. Our code for dependency parser is available at https://github.com/allanj/bidaf_ dependency_parsing</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>the actual practice of tax reform was held in Hong Kong Example sentences annotated with named entiteis and dependencies in the OntoNotes 5.0 dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>+ ELMo (L = 2) 92.2 92.5 92.4</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Correlations between the correctly predicted entities and the dependency relations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>BiLSTM-GCN-CRF. Dashed connections mimic the dependency edges.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Correlations between the entity types and the dependency relation pairs on the grandchild dependencies.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>List of interaction functions.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>English 59,924 81,828 8,528 11,066 8,262 11,057 098.5 41.1 OntoNotes 5.0 -Chinese 36,487 62,543 6,083 09,104 4,472 07,494 092.9 49.1 SemEval2010T1 -Catalan 08,709 15,278 1,445 02,431 1,698 02,910 100.0 28.6 SemEval2010T1 -Spanish 09,022 17,297 1,419 02,615 1,705 03,046 100.0 29.8</figDesc><table><row><cell>Dataset</cell><cell>Train</cell><cell>Dev</cell><cell>Test</cell><cell>ST GD</cell></row><row><cell></cell><cell cols="4"># Sent. # Entity # Sent. # Entity # Sent. # Entity (%) (%)</cell></row><row><cell>OntoNotes 5.0 -</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Dataset statistics. "ST" is the ratio of entities that form subtrees. "GD" is the ratio of entities that have grandchild dependencies within their subtrees.</figDesc><table><row><cell>trees into the Stanford dependency (De Marn-</cell></row><row><cell>effe and Manning, 2008) trees using the rule-</cell></row><row><cell>based tool (De Marneffe et al., 2006) by Stanford</cell></row><row><cell>CoreNLP (Manning et al., 2014). For English,</cell></row><row><cell>Pradhan et al. (2013) provided the train/dev/test</cell></row><row><cell>split 4 and the split has been used by several pre-</cell></row><row><cell>vious works (Chiu and Nichols, 2016; Li et al.,</cell></row><row><cell>2017; Ghaddar and Langlais, 2018). For Chinese,</cell></row><row><cell>we use the official splits provided by Pradhan et al.</cell></row><row><cell>(2012) 5 .</cell></row><row><cell>Besides, we also conduct experiments on the</cell></row><row><cell>Catalan and Spanish datasets from the SemEval-</cell></row><row><cell>2010 Task 1 6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table /><note>Performance comparison on the OntoNotes 5.0 English dataset.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table /><note>Performance comparison on the OntoNotes 5.0 Chinese Dataset.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>BiLSTM-CRF (L = 0) 65.91 49.90 56.80 65.97 52.63 58.55 BiLSTM-CRF (L = 1) 76.83 63.47 69.51 78.33 69.89 73.87 BiLSTM-CRF (L = 2) 73.79 67.63 70.58 77.73 70.91 74.16 BiLSTM-CRF (L = 3) 74.75 67.35 70.86 76.41 72.95 74.64 BiLSTM-GCN-CRF 81.25 75.22 78.12 84.10 79.88 81.93</figDesc><table><row><cell>Model</cell><cell>Catalan Prec. Rec.</cell><cell>F 1</cell><cell>Spanish Prec. Rec.</cell><cell>F 1</cell></row><row><cell>DGLSTM-CRF (L = 0)</cell><cell cols="4">73.42 61.79 67.10 74.90 61.21 67.38</cell></row><row><cell>DGLSTM-CRF (L = 1)</cell><cell cols="4">81.87 79.28 80.55 83.21 81.19 82.19</cell></row><row><cell>DGLSTM-CRF (L = 2)</cell><cell cols="4">83.35 80.00 81.64 84.05 82.90 83.47</cell></row><row><cell>DGLSTM-CRF (L = 3)</cell><cell cols="4">81.87 80.21 81.03 84.12 83.45 83.78</cell></row><row><cell cols="2">Contextualized Word Representation</cell><cell></cell><cell></cell><cell></cell></row><row><cell>BiLSTM-CRF (L = 0) + ELMo</cell><cell cols="4">67.53 64.47 65.96 73.16 69.01 71.03</cell></row><row><cell>BiLSTM-CRF (L = 1) + ELMo</cell><cell cols="4">77.85 76.22 77.03 81.72 79.09 80.38</cell></row><row><cell>BiLSTM-CRF(L = 2) + ELMo</cell><cell cols="4">78.61 78.32 78.46 80.89 80.30 80.59</cell></row><row><cell>BiLSTM-CRF(L = 3) + ELMo</cell><cell cols="4">79.11 77.32 78.21 80.48 79.45 79.96</cell></row><row><cell>BiLSTM-GCN-CRF + ELMo</cell><cell cols="4">83.68 83.16 83.42 85.31 85.19 85.25</cell></row><row><cell cols="5">DGLSTM-CRF (L = 0) + ELMo 70.87 65.81 68.25 75.96 72.52 74.20</cell></row><row><cell cols="5">DGLSTM-CRF (L = 1) + ELMo 82.29 82.37 82.33 84.05 84.77 84.41</cell></row><row><cell cols="5">DGLSTM-CRF (L = 2) + ELMo 84.71 83.75 84.22 87.79 87.33 87.56</cell></row><row><cell cols="5">DGLSTM-CRF (L = 3) + ELMo 84.50 83.92 84.21 86.74 86.57 86.66</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table /><note>Results on the SemEval-2010 Task 1 datasets.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 6 :</head><label>6</label><figDesc>Performance on the CoNLL-2003 English dataset. = 1) 47.71 31.55 37.98 49.39 31.91 38.77 -with gold dependency 52.13 33.26 40.61 52.14 35.59 42.30</figDesc><table><row><cell>Model</cell><cell>Catalan Prec. Rec.</cell><cell>F 1</cell><cell>Spanish Prec. Rec.</cell><cell>F 1</cell></row><row><cell>BiLSTM-CRF (L = 1)</cell><cell cols="4">47.88 18.59 26.78 40.77 19.01 25.93</cell></row><row><cell>DGLSTM-CRF (L</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 7 :</head><label>7</label><figDesc>Low-resource NER performance on the SemEval-2010 Task 1 datasets.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 8 :</head><label>8</label><figDesc>F 1 performance of DGLSTM-CRF with predicted dependencies against the best performing BiLSTM-CRF. †: LAS is label attachment score which is the metric for dependency evaluation.</figDesc><table><row><cell>Model</cell><cell>Prec. Rec.</cell><cell>F 1</cell></row><row><cell>BiLSTM-CRF + ELMo (L = 2)</cell><cell cols="2">89.14 88.59 88.87</cell></row><row><cell cols="3">DGLSTM-CRF + ELMo (L = 2) 89.59 90.17 89.88</cell></row><row><cell>-g(·) = self connection</cell><cell cols="2">89.17 90.08 89.62</cell></row><row><cell>-g(·) = Concatenation</cell><cell cols="2">89.43 90.09 89.76</cell></row><row><cell>-g(·) = Addition</cell><cell cols="2">89.24 89.78 89.50</cell></row><row><cell>-w/o dependency relation</cell><cell cols="2">88.92 89.99 89.46</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 9 :</head><label>9</label><figDesc>Ablation study of the DGLSTM-CRF model on the OntoNotes English dataset.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head></head><label></label><figDesc>73.1 62.8 70.3 57.5 DGLSTM-CRF 82.2 75.5 71.8 64.1 58.5 41.1</figDesc><table><row><cell cols="2">Dataset Model</cell><cell>1</cell><cell>2</cell><cell>Entity Length 3 4</cell><cell>5</cell><cell>≥6</cell></row><row><cell>English</cell><cell cols="6">BiLSTM-CRF DGLSTM-CRF 91.8 90.1 85.4 87.0 80.8 78.7 91.8 88.5 83.4 84.0 75.4 76.0</cell></row><row><cell cols="7">Chinese 81.2 74.3 Catalan BiLSTM-CRF BiLSTM-CRF 80.5 81.0 75.8 56.1 45.0 38.4 DGLSTM-CRF 85.4 85.1 84.1 78.9 60.9 59.3</cell></row><row><cell>Spanish</cell><cell cols="6">BiLSTM-CRF DGLSTM-CRF 89.3 87.4 90.8 74.1 67.7 64.4 84.2 81.1 81.0 53.3 53.3 37.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 10 :</head><label>10</label><figDesc>Performance of entities with different lengths on the four datasets: OntoNotes (English), OntoNotes Chinese, Catalan and Spanish.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">"S-" indicates the entity with a single word and "E-" indicates the end of an entity.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">y0 and yn+1 are start and end labels.3  We also tried using a root word embedding but the performance is similar.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">http://cemantix.org/data/ontonotes.html 5 http://conll.cemantix.org/2012/data.html 6 http://stel.ub.edu/semeval2010-coref/download 7 This dataset also has English portion but it is a subset of the OntoNotes English.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9">Detailed description of this baseline can also be found in the supplementary material.10  We also tried BERT<ref type="bibr" target="#b9">(Devlin et al., 2019)</ref> in preliminary experiments and obtained similar performance as ELMo. The NER performance using BERT without fine-tuning reported in<ref type="bibr" target="#b35">Peters et al. (2019)</ref> is consistent with the one reported by ELMo<ref type="bibr" target="#b33">(Peters et al., 2018a)</ref>.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12">We run their code on the OntoNotes 5.0 Chinese dataset.13  Percentage of entities that can form a subtree.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15">Aij = Aji for symmetric matrix.16  The bias vector is ignore for brevity.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ackowledgements</head><p>We would like to thank the anonymous reviewers for their constructive comments on this work. We would also like to thank Zhijiang Guo and Yan Zhang for the fruitul discussion. This work is supported by Singapore Ministry of Education Academic Research Fund (AcRF) Tier 2 Project MOE2017-T2-1-156.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Baseline Systems</head><p>We implemented the BiLSTM-CRF <ref type="bibr" target="#b23">(Lample et al., 2016)</ref> and BiLSTM-GCN-CRF models based on the contextualized GCN implementation by . The implementation of BiLSTM-CRF is exactly same as <ref type="bibr" target="#b23">Lample et al. (2016)</ref>. We presents the neural architecture for the BiLSTM-GCN-CRF model.</p><p>A.1 BiLSTM-GCN-CRF <ref type="figure">Figure 5</ref> shows the neural architecture for the BiLSTM-GCN-CRF model. Following , the input representation at each position w i is the word representation which consists of the pre-trained word embeddings and its character representation. To capture contextual information, we stack a BiLSTM layer before the GCN. Secondly, the GCN captures the dependency tree structure as shown in <ref type="figure">Figure 5</ref>. Following , we treat the dependency trees as undirected and build a symmetric adjacency matrix during the GCN update:</p><p>where A is the adjacency matrix. A ij = 1 indicates there is a dependency edge between the i-th word and the j-th word 15 . h <ref type="bibr">(l)</ref> i is the hidden state at the i-th position in the l-th layer. We can stack J layers of GCN in the model. In our experiments, we set the number of GCN layers J = 1 as we did not observe significant improvements by increasing J. In fact, we might obtain harmful performance for a larger J as deeper GCN layers will diminish the effect of the contextual information, which is important for the task of NER.</p><p>However, Equation 4 does not include the dependency relation information. As mentioned in the main paper, such relations have strong correlations with the entity types. We modify the Equation 4 and include the dependency relation parameter <ref type="bibr">16</ref> :</p><p>where w r ij is the dependency relation weight that parameterize the dependency relation r between</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Contextual string embeddings for sequence labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Akbik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duncan</forename><surname>Blythe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Vollgraf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
		<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An empirical investigation of statistical significance in nlp</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Burkett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-CoNLL</title>
		<meeting>EMNLP-CoNLL</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Towards better UD parsing: Deep contextualized word embeddings, ensemble, and treebank concatenation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yijia</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
		<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Named entity recognition with bidirectional lstm-cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Jason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nichols</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions of the Association of Computational Linguistics</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="357" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Support--vector networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corinna</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="297" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Low-resource named entity recognition with cross-lingual, character-level neural conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCNLP</title>
		<meeting>IJCNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Unsupervised named entity recognition using syntactic and semantic contextual evidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Cucchiarelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paola</forename><surname>Velardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="123" to="131" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Generating typed dependency parses from phrase structure parses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine De</forename><surname>Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Maccartney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC</title>
		<meeting>LREC</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Stanford typed dependencies manual</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Catherine De</forename><surname>Marneffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Coarse-to-fine decoding for neural semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep biaffine attention for neural dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Dozat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Incorporating non-local information into information extraction systems by gibbs sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><forename type="middle">Rose</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trond</forename><surname>Grenager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Joint parsing and named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><forename type="middle">Rose</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Allennlp: A deep semantic natural language processing platform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Grus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oyvind</forename><surname>Tafjord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pradeep</forename><surname>Dasigi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nelson</forename><forename type="middle">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Schmitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><forename type="middle">S</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Workshop for NLP-OSS</title>
		<meeting>Workshop for NLP-OSS</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Robust lexical features for improved neural network named-entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abbas</forename><surname>Ghaddar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillippe</forename><surname>Langlais</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COL-ING</title>
		<meeting>COL-ING</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning word vectors for 157 languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prakhar</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC</title>
		<meeting>LREC</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="DOI">https:/www.mitpressjournals.org/doi/pdfplus/10.1162/neco.1997.9.8.1735</idno>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">2017. spaCy 2: Natural language understanding with bloom embeddings, convolutional neural networks and incremental parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Honnibal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ines</forename><surname>Montani</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Efficient dependency-guided named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanming</forename><surname>Jie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aldrian</forename><surname>Obaja Muis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Efficient third-order dependency parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Collins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Neural architectures for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandeep</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuya</forename><surname>Kawakami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">End-to-end neural coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Leveraging linguistic structures for named entity recognition with bidirectional recursive neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Peng-Hsuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruo-Ping</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Siang</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ju-Chieh</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Yun</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ma</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>In Proceedings of EMNLP</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Fine-grained entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daniel S Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI</title>
		<meeting>AAAI</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Recognizing biomedical named entities using skip-chain conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingchen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyan</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on BioNLP</title>
		<meeting>the Workshop on BioNLP</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">End-to-end sequence labeling via bi-directional lstm-cnns-crf</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The stanford corenlp natural language processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL: System Demonstrations</title>
		<meeting>ACL: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Encoding sentences with graph convolutional networks for semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Marcheggiani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">End-to-end relation extraction using lstms on sequences and tree structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makoto</forename><surname>Miwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Deep contextualized word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Dissecting contextual word embeddings: Architecture and representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">To tune or not to tune? adapting pretrained representations to diverse tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Smith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.05987</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Towards robust linguistic analysis using ontonotes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sameer Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee Tou</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Björkelund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchen</forename><surname>Uryupina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL</title>
		<meeting>CoNLL</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Conll-2012 shared task: Modeling multilingual unrestricted coreference in ontonotes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sameer Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchen</forename><surname>Uryupina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Joint EMNLP-CoNLL: Shared Task</title>
		<meeting>Joint EMNLP-CoNLL: Shared Task</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Text chunking using transformation-based learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lance</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell P</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Marcus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Third Workshop on Very Large Corpora</title>
		<meeting>Third Workshop on Very Large Corpora</meeting>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Design challenges and misconceptions in named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL</title>
		<meeting>CoNLL</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Semeval-2010 task 1: Coreference resolution in multiple languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><surname>Recasens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lluís</forename><surname>Màrquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emili</forename><surname>Sapena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antònia</forename><surname>Martí</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariona</forename><surname>Taulé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Véronique</forename><surname>Hoste</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Poesio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannick</forename><surname>Versley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Workshop on Semantic Evaluation</title>
		<meeting>the 5th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Reporting score distributions makes a difference: Performance study of lstm-networks for sequence tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Semimarkov conditional random fields for information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunita</forename><surname>Sarawagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>William W Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NeurIPS</title>
		<meeting>NeurIPS</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Japanese named entity recognition using structural natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryohei</forename><surname>Sasano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCNLP</title>
		<meeting>IJCNLP</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Fast and accurate entity recognition with iterated dilated convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emma</forename><surname>Strubell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Verga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Belanger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Collective segmentation and labeling of distant entities in information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ICML Workshop on Statistical Relational Learning and Its Connections to Other Fields</title>
		<meeting>the ICML Workshop on Statistical Relational Learning and Its Connections to Other Fields</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Weischedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lance</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michelle</forename><surname>Franchini</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>et al. 2013. Ontonotes release 5.0 ldc2013t19. Linguistic Data Consortium</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Chinese ner using lattice lstm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Graph convolution over pruned dependency trees improves relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
