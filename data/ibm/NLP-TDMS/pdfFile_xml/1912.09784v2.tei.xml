<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Triple Generative Adversarial Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="20151">AUGUST 2015 1</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Journal Of L A T E X Class</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Files</surname></persName>
						</author>
						<title level="a" type="main">Triple Generative Adversarial Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">14</biblScope>
							<biblScope unit="issue">8</biblScope>
							<date type="published" when="20151">AUGUST 2015 1</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T18:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose a unified game-theoretical framework to perform classification and conditional image generation given limited supervision. It is formulated as a three-player minimax game consisting of a generator, a classifier and a discriminator, and therefore is referred to as Triple Generative Adversarial Network (Triple-GAN). The generator and the classifier characterize the conditional distributions between images and labels to perform conditional generation and classification, respectively. The discriminator solely focuses on identifying fake image-label pairs. Under a nonparametric assumption, we prove the unique equilibrium of the game is that the distributions characterized by the generator and the classifier converge to the data distribution. As a byproduct of the three-player mechanism, Triple-GAN is flexible to incorporate different semi-supervised classifiers and GAN architectures. We evaluate Triple-GAN in two challenging settings, namely, semi-supervised learning and the extreme low data regime. In both settings, Triple-GAN can achieve excellent classification results and generate meaningful samples in a specific class simultaneously. In particular, using a commonly adopted 13-layer CNN classifier, Triple-GAN outperforms extensive semi-supervised learning methods substantially on more than 10 benchmarks no matter data augmentation is applied or not.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>G ENERATIVE adversarial networks (GANs) <ref type="bibr" target="#b0">[1]</ref> have made significant progress in generating realistic images <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref> and learning representations <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref> in an unsupervised manner, which makes GANs popular in many applications <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>. The paradigm of GAN is a two-player game, where a generator G takes a random noise z as input and produces a fake data sample and a binary discriminator D identifies whether a certain sample is true or fake. The learning objective of G is to fool D. Formally, it can be formulated as follows: min G max D E p(x) [log(D(x))] + E pz(z) [log(1 − D(G(z)))], <ref type="bibr" target="#b0">(1)</ref> where p(x) and p z (z) are the data distribution and the prior distribution of the random noise z, respectively. Theoretically, such a two-player game is sufficient for unsupervised learning. Indeed, the distribution defined by G will converge to the data distribution in the equilibrium of the game, under a nonparametric assumption <ref type="bibr" target="#b0">[1]</ref>.</p><p>Though promising and appealing, the representations learned by purely unsupervised GANs are not sufficiently good in some down-stream tasks such as classification and conditional generation with disentangled factors, which are of general interests <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>. In fact, on one hand, the representations learned by unsupervised deep generative models (DGMs) (including GANs) can be less discriminative than those learned by supervised deep neural networks (DNNs) and the predictions made based on the representations are not sufficiently accurate <ref type="bibr" target="#b20">[21]</ref>. On the other hand, unsupervised learning disentangled factors of clear physical meaning and generating samples according to • C. <ref type="bibr">Li</ref>  <ref type="figure" target="#fig_2">Fig. 1</ref>. The left panel illustrates a representative prior work <ref type="bibr" target="#b23">[24]</ref>. D is the initialized model in the hypothesis space H D . C * is the optimal classifier and D * is the optimal discriminator when pg(x) = p(x). D will converge to a solutionD that depends on the trade-off between classification and generation. The right panel illustrates our approach where C and D are optimized in two separated hypothesis spaces H C and H D , respectively. C and D will converge to the corresponding optimum under a nonparametric assumption <ref type="bibr" target="#b0">[1]</ref> (See Sec. 3.2 for the proof).</p><formula xml:id="formula_0">ℋ ! ℋ " ℋ !</formula><p>the given factors are challenging and highly depend on the inductive biases of the model <ref type="bibr" target="#b21">[22]</ref>. A natural way to address these issues is to incorporate label information into GANs <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref>. Because supervision can be rare in many scenarios <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b29">[30]</ref>, we investigate the ones where only a small number of labels are accessible in this paper. In particular, we consider two closely related yet challenging settings. The first one is semisupervised learning <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>, where a large amount of unlabeled data is available and can be explored to boost the classification performance (as well as the conditional generation performance in DGMs <ref type="bibr" target="#b28">[29]</ref>). The second one is the more challenging extreme low data regime <ref type="bibr" target="#b27">[28]</ref>, where no unlabeled data is available.</p><p>Several methods <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b27">[28]</ref> are proposed to solve the classification task by introducing a categorical discriminator, which also serves as a classifier, under the two-player game formulation in Eqn. <ref type="bibr" target="#b0">(1)</ref>. The discriminator is trained to identify fake samples and predict labels simultaneously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>arXiv:1912.09784v2 [cs.LG] 14 Sep 2020</head><p>Though obtaining a substantial improvement over DNNs in classification, these methods lack a theoretical analysis of the equilibrium of the game. We take CatGAN <ref type="bibr" target="#b23">[24]</ref> as a representative example (See <ref type="figure" target="#fig_2">Fig. 1</ref> for an illustration). The discriminator in CatGAN maximizes the predictive entropy of a fake sample and minimizes that of a real sample. Assume that p g (x), the distribution defined by G, converges to the data distribution p(x) and we have x ∼ p g (x) = p(x). On one hand, when G converges, the optimal discriminator D * cannot distinguish whether x is real or fake <ref type="bibr" target="#b0">[1]</ref> and therefore has high predictive entropy. On the other hand, the optimal classifier C * should classify x correctly and has low predictive entropy. Thus, generally, C * and D * are different points in the same hypothesis space and the discriminator will converge to a solution depending on the trade-off between classification and generation. The empirical results in Improved-GAN <ref type="bibr" target="#b25">[26]</ref> well support our analysis. In fact, Improved-GAN proposes two alternative training objective functions. The first feature matching objective works well in classification but fails to generate indistinguishable samples. The second minibatch discrimination objective is good at image generation with full labels but cannot perform classification accurately <ref type="bibr" target="#b25">[26]</ref>. Therefore, we argue that the two-player formulation may lead to a sub-optimal classifier.</p><p>As for the class-conditional generation task, conditional GAN <ref type="bibr" target="#b22">[23]</ref> and its variants <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b30">[31]</ref> can train a conditional generator given fully labeled data (See details in Sec. 2). However, how to leverage unlabeled data in the conditional generation task is highly nontrivial due to the presence of missing labels in semi-supervised learning. In fact, to our best knowledge, none of the existing GANs <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref> can exploit partially labeled data to generate samples in a specific class. Again, we believe that the problem is intrinsically caused by the two-player formulation. Specifically, the discriminators in these methods estimate a single data instead of a data-label pair and the label information is totally ignored. Therefore, the generators will not receive any learning signal regarding the label information from the discriminators and hence cannot control the semantics of the generated samples, which is not satisfactory.</p><p>In this paper, we propose the triple generative adversarial network (Triple-GAN) framework for both classification and class-conditional image generation with limited supervision. Specifically, we introduce two conditional networks-a classifier and a generator to generate fake labels given real data and fake data given real labels, which will perform the classification and class-conditional generation tasks respectively. To jointly justify the quality of the samples from the conditional networks, we define a discriminator network which has the sole role of distinguishing whether a data-label pair is from the real labeled dataset or not. The resulting model is called Triple-GAN because we consider three networks as well as three joint distributions, i.e. the true data-label distribution and the distributions defined by the two conditional networks. Directly motivated by the desirable equilibrium, we carefully design compatible objective functions, including adversarial losses and crossentropy losses, for the three players. The objective functions are optimized by alternative stochastic gradient descent <ref type="bibr" target="#b0">[1]</ref>.</p><p>Theoretically, we prove that the unique equilibrium of Triple-GAN is that the distributions defined by both the generator and the classifier converge to the data distribution under a nonparametric assumption <ref type="bibr" target="#b0">[1]</ref>. This equilibrium implies that the classifier of Triple-GAN can potentially converge to a better solution than existing work <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b30">[31]</ref>. Though our implementation does not rigorously follow the theoretical analysis, it does provide valuable insights. Besides, the discriminator can access the label information of the unlabeled data from the classifier and then force the generator to generate correct image-label pairs, which solves the class-conditional generation task.</p><p>Empirically, we notice that recent advances in semisupervised classification <ref type="bibr" target="#b31">[32]</ref> and GANs <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b33">[34]</ref> are built upon very different network architectures and loss functions. As a byproduct of decoupling the hypothesis spaces of the classifier and discriminator, it is convenient to adopt these advances simultaneously in Triple-GAN without considering the trade-off between classification and generation. In fact, we implement two instances, called as Triple-GAN-V1 and Triple-GAN-V2 respectively. In Triple-GAN-V1, for a fair comparison, we use models that are comparable to the GANbased methods <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b27">[28]</ref> to validate our motivation and theoretical results. In Triple-GAN-V2, we employ a mean teacher classifier <ref type="bibr" target="#b31">[32]</ref> and a projection discriminator <ref type="bibr" target="#b33">[34]</ref> with spectral normalization <ref type="bibr" target="#b32">[33]</ref>, to compete against a large family of strong baselines. Both instances can achieve excellent classification results and generate meaningful samples in a specific class simultaneously, evaluated on the widely adopted SVHN <ref type="bibr" target="#b34">[35]</ref>, CIFAR10 <ref type="bibr" target="#b35">[36]</ref> and Tiny ImageNet 1 datasets in semi-supervised learning and the extreme low data regime. In particular, using a commonly adopted 13layer CNN classifier, Triple-GAN outperforms extensive semi-supervised learning methods <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b43">[44]</ref> substantially on more than 10 benchmarks no matter data augmentation is applied or not. Besides, with only 8% labels, it achieves comparable Inception Score (IS) <ref type="bibr" target="#b25">[26]</ref> and Fréchet Inception Distance (FID) <ref type="bibr" target="#b44">[45]</ref> to the strong baseline CGAN-PD <ref type="bibr" target="#b33">[34]</ref> trained with full labels on the CIFAR10 dataset.</p><p>Overall, our main contributions are: 1) We propose a unified GAN-based framework consisting of three players (thus named Triple-GAN) to perform classification and conditional generation given limited supervision; 2) We prove that, with carefully designed objective functions, Triple-GAN leads to a unique desirable equilibrium under a nonparametric assumption <ref type="bibr" target="#b0">[1]</ref>; 3) We show that Triple-GAN can significantly outperform a large number of recent semi-supervised learning methods on more than 10 benchmarks using a commonly adopted 13-layer CNN classifier; 4) We demonstrate that, given partially labeled data, Triple-GAN is able to disentangle category from style features and get samples of comparable quality to the strong baseline <ref type="bibr" target="#b33">[34]</ref> with full labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND</head><p>In this section, we present several discriminative semisupervised learning methods adopted in Triple-GAN and existing GAN variants with supervision. We will discuss other related work comprehensively in Sec. 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Discriminative semi-supervised learning methods</head><p>There are extensive discriminative approaches in semisupervised learning. Such methods define different regularization terms on the unlabeled data. Entropy regularization. Entropy regularization <ref type="bibr" target="#b45">[46]</ref> minimizes the predictive entropy of the unlabeled data, which is defined as follows:</p><formula xml:id="formula_1">R U = −E p(x) E pc(y|x) [log p c (y|x)].<label>(2)</label></formula><p>Consistency regularization. Consistency regularization <ref type="bibr" target="#b36">[37]</ref> minimizes the mean square error (MSE) between two predictions of the same unlabeled data given different noises like dropout masks. Formally, it is defined as follows:</p><formula xml:id="formula_2">R U = E p(x) ||p c (y|x, ) − p c (y|x, )|| 2 ,<label>(3)</label></formula><p>where || · || 2 is the square of the l 2 -norm and and denote two different random noises. We note that there are other optional loss functions such as the KL-divergence in Eqn. (3). However, according to the empirical study in prior work <ref type="bibr" target="#b31">[32]</ref>, MSE performs best. Though the exact reason is not clear, intuitively, MSE may avoid over-confident predictions in the consistency loss compared to the KL divergence. Mean teacher. Mean teacher <ref type="bibr" target="#b31">[32]</ref> maintains an exponential moving average of the classifier as a teacher and enforces the predictions made by the classifier and the teacher on the same data to be the same. Formally, it is formulated as:</p><formula xml:id="formula_3">R U = E p(x) ||p c (y|x, ) − p t (y|x, )|| 2 ,<label>(4)</label></formula><p>where and denote two different random noises and p t (y|x, ) denotes the prediction of the teacher model. The reason of using the MSE instead of the KL divergence is the same as in Eqn. <ref type="bibr" target="#b2">(3)</ref>. Mean teacher is a strong baseline and many recent methods <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b43">[44]</ref> are built upon it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">GANs with supervision</head><p>Existing GANs with supervision adopt a similar two-player formulation and lacks a theoretical analysis of the equilibrium.</p><p>CatGAN. CatGAN <ref type="bibr" target="#b23">[24]</ref> extends the original GAN to semisupervised learning by employing a categorical discriminator, which also serves as a classifier. The learning problem of CatGAN is formulated as:</p><formula xml:id="formula_4">min G max D λE p(x,y) [log p c (y|x)] + E p(x) E pc(y|x) [log p c (y|x)] − E pz(z) E pc(y|G(z)) [log p c (y|G(z))],<label>(5)</label></formula><p>where p c (y|x) is the predictive distribution defined by the classifier and λ is a hyperparameter. The first term is the traditional cross-entropy loss on the labeled data for classification. The second term is the entropy regularization <ref type="bibr" target="#b45">[46]</ref> presented in Eqn. 2. The last term is the generalized adversarial losses on fake data generated from G.</p><p>Improved-GAN. Improved-GAN <ref type="bibr" target="#b25">[26]</ref> shares the same settings with CatGAN <ref type="bibr" target="#b23">[24]</ref> but uses a categorical discriminator that has one extra class that corresponds to the fake samples. The learning problem for the discriminator is:</p><formula xml:id="formula_5">max D E p(x,y) [log p c (y|x, y &lt; K + 1)] +E pz(z) [log p c (y = K + 1|G(z))] +E p(x) [log(1 − p c (y = K + 1|x))],<label>(6)</label></formula><p>where K is the number of real classes and the (K + 1)-th class corresponds to the fake samples. The generator does not directly fool the discriminator but has two alternative objective functions. In this paper, we mainly compare to feature matching, which enforces G to produce samples that have similar features (extracted by a neural network) to the real samples, which is formulated as:</p><formula xml:id="formula_6">min G ||E p(x) [f (x)] − E pz(z) [f (G(z))]|| 2 2 ,<label>(7)</label></formula><p>where f (x) is the activation of certain layer in the discriminator given input x and || · || 2 is the l 2 norm. DADA. DADA <ref type="bibr" target="#b27">[28]</ref> considers a more challenging extreme low data regime setting, where only a small number of labeled data is available. DADA also employs a two-player formulation and extends the discriminator to 2K classes, where the first K classes are real and the last K classes are fake. DADA proposes a two-phase training schedule. In the first phase, the learning objective of the discriminator is: <ref type="bibr" target="#b7">(8)</ref> and the learning objective of the generator is: <ref type="bibr" target="#b1">2</ref> 2 , (9) where the last term is a conditional variant of the feature matching loss in Eqn. <ref type="bibr" target="#b6">(7)</ref> and λ is a hyperparameter. In the second phase, the generator is fixed as a data provider and the classifier is trained for classification based on both the real data and fake data.</p><formula xml:id="formula_7">max D E p(x,y) [log p c (y|x, y &lt; K + 1)] +E pz(z)p(y) [log p c (y|G(z, y), K &lt; y &lt; 2K + 1)],</formula><formula xml:id="formula_8">min G −E p(x,y) [log p c (y − K|x, K &lt; y &lt; 2K + 1)] +λ||E p(x,y) [f (x|y)] − E pz(z)p(y) [f (G(z, y)|y)]||</formula><p>The two-player framework in prior methods <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b27">[28]</ref> for semi-supervised learning and extreme low data regime can potentially learn a sub-optimal classifier because of the trade-off between classification and generation (See <ref type="figure" target="#fig_2">Fig. 1</ref> for illustration and <ref type="bibr" target="#b25">[26]</ref> for empirical evidence).</p><p>CGAN. The conditional GAN (CGAN) <ref type="bibr" target="#b22">[23]</ref> and its variants <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b33">[34]</ref> aim to learn a conditional generator p g (x|y) to approximate p(x|y). CGAN is very similar to GAN but incorporates label information in both the generator and the discriminator. The learning problem is defined as:</p><formula xml:id="formula_9">min G max D E p(x,y) [log D(x, y)] +E pz(z)p(y) [log(1 − D(G(y, z), y))].<label>(10)</label></formula><p>Recent work <ref type="bibr" target="#b33">[34]</ref> improves CGAN by using a projection discriminator with spectral normalization <ref type="bibr" target="#b32">[33]</ref>, and obtains impressive generation results. However, it can be seen that CGAN-based methods require fully labeled data to train a conditional generator in a "discriminative" way and it is non-trivial to leverage unlabeled data by extending CGAN. Besides, existing semi-supervised methods <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref> lack the ability of conditional generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHOD</head><p>As discussed above, prior GANs with limited supervision <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b27">[28]</ref> are not problemless: (1) they will converge to a tradeoff solution (between classification and generation) which lacks theoretical analysis; and (2) the learned generators cannot control the semantics of the generated samples. Therefore, we argue that the classification and conditional generation tasks given limited supervision are still largely open. To this end, we proposed a unified game-theoretical framework triple generative adversarial network (Triple-GAN), which intrinsically avoid the problems in existing methods.</p><p>In particular, we consider two closely related yet challenging learning settings in this paper. The first one is semisupervised learning <ref type="bibr" target="#b45">[46]</ref>, where we have a labeled dataset of small size and an unlabeled one of large size. The second one is the extreme low data regime <ref type="bibr" target="#b27">[28]</ref>, where we only have a labeled dataset of small size. In both settings, we want to predict a label y for an input x (i.e., perform classification) as well as to generate a new sample x conditioned on a label y (i.e., generate samples in a given class).</p><p>Triple-GAN is based on the insight that the joint distribution can be factorized in two ways, namely, p(x, y) = p(x)p(y|x) and p(x, y) = p(y)p(x|y), and that the conditional distributions p(y|x) and p(x|y) are of interests for classification and class-conditional generation, respectively. To jointly estimate these conditional distributions, which are characterized by a classifier network and a class-conditional generator network, we define a discriminator network which has the sole role of distinguishing whether a input-label pair is from the true data distribution or the models. Hence, we naturally extend GAN to Triple-GAN, a three-player game to characterize the process of classification and class-conditional generation with limited supervision, as detailed below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">A game with three players</head><p>Triple-GAN consists of three components: (1) a classifier C that (approximately) characterizes the conditional distribution p c (y|x) ≈ p(y|x); (2) a class-conditional generator G that (approximately) characterizes the conditional distribution in the other direction p g (x|y) ≈ p(x|y); and (3) a discriminator D that distinguishes whether a pair of data (x, y) comes from the true distribution p(x, y). All the components are parameterized as neural networks. Our desired equilibrium is that the joint distributions defined by the generator and the classifier both converge to the true data distribution. To achieve it, we design a game with compatible objective functions for the three players as follows.</p><p>We make a mild assumption that the samples from both p(x) and p(y) can be easily obtained. <ref type="bibr" target="#b1">2</ref> In the game, after a sample x is drawn from p(x), C produces a fake label y given x following the conditional distribution p c (y|x). Hence, the fake input-label pair is a sample from the joint distribution p c (x, y) = p(x)p c (y|x). Similarly, a fake input-label pair can be sampled from G by first drawing y ∼ p(y) and then drawing x|y ∼ p g (x|y), hence from the joint distribution p g (x, y) = p(y)p g (x|y). For p g (x|y), we assume that x is transformed by the latent style variables z given the label 2. In semi-supervised learning, p(y) is assumed same to the distribution of labels on the labeled data, which is uniform in our experiment. y, namely, x = G(y, z), z ∼ p z (z), where p z (z) is a simple distribution (e.g., uniform or standard normal). Then, the fake input-label pairs (x, y) generated by both C and G are sent to the discriminator D. D can also access the input-label pairs from the true data distribution as positive samples. We refer the objective functions in the process as adversarial losses, which can be formulated as:</p><formula xml:id="formula_10">min C,G max D E p(x,y) [log D(x, y)] + αE pc(x,y) [log(1 − D(x, y))] +(1 − α)E pg(x,y) [log(1 − D(G(y, z), y))],<label>(11)</label></formula><p>where α ∈ (0, 1) is a constant that controls the relative importance of classification and generation, and we focus on the balance case by fixing it as 1/2 throughout the paper. The game defined in Eqn. <ref type="bibr" target="#b10">(11)</ref> achieves its equilibrium if and only if p(x, y) = (1−α)p g (x, y)+αp c (x, y) (See proof in Sec. 3.2). Intuitively, it means that the discriminator balances between the true data distribution and a mixture distribution defined by the generator and the classifier. Further, the equilibrium indicates that if one of C and G tends to the data distribution, the other will also go towards the data distribution, which avoids the incompatible convergence problem as in previous work <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b27">[28]</ref>.</p><p>However, the adversarial losses defined in Eqn. (11) cannot guarantee that p(x, y) = p g (x, y) = p c (x, y) is the unique equilibrium, which is unsatisfactory. A natural solution to the problem is to introduce additional losses to encourage two of the three distributions to be the same. In fact, we consider to minimize D KL (p c (x, y)||p(x, y)) and D KL (p c (x, y)||p g (x, y)) 3 , where D KL (·||·) denotes the KL divergence. An advantage of the KL divergence over other divergences is that it has an equivalent form of the crossentropy loss, which is efficient in computation and effective for classification. Formally, we introduce the cross-entropy loss on the labeled data to C as follows:</p><formula xml:id="formula_11">R C = E p(x,y) [− log p c (y|x)],<label>(12)</label></formula><p>to minimize D KL (p c (x, y)||p(x, y)), and a pseudo discriminative loss on the generated data to C as follows:</p><formula xml:id="formula_12">R P = E pg(x,y) [− log p c (y|x)].<label>(13)</label></formula><p>Theoretically, we prove that optimizing Eqn. <ref type="bibr" target="#b12">(13)</ref> with respect to the parameters in C is equivalent to minimizing</p><formula xml:id="formula_13">D KL (p c (x, y)||p g (x, y)) (See proof in Appendix A). Note that D KL (p c (x, y)||p g (x, y)</formula><p>) cannot be optimized directly because its computation involves the unknown likelihood ratio p g (x, y)/p c (x, y). Intuitively, Eqn. (13) treats the samples generated from G as extra labeled data for C, which will boost the predictive performance given extremely insufficient supervision. Further, we empirically show that the generated data have a different patterns from the randomly augmented data (e.g., shifted and flipped ones) and provide complementary learning signals (See Sec. 5 for the empirical evidence). Finally, the game with the cross-entropy loss and the pseudo discriminative loss is defined as:</p><formula xml:id="formula_14">min C,G max D E p(x,y) [log D(x, y)] + αE pc(x,y) [log(1 − D(x, y))] +(1−α)E pg(x,y) [log(1 − D(G(y, z), y))]+R C +α P R P ,<label>(14)</label></formula><p>3. The KL divergence between p(x, y) and pg(x, y) is less efficient to compute. Therefore, we omit it here.</p><p>where α P &gt; 0 is a hyperparameter. For simplicity, we denote the objective function in Eqn. <ref type="bibr" target="#b10">(11)</ref> as U (C, G, D) and that in Eqn. <ref type="bibr" target="#b13">(14)</ref> asŨ (C, G, D). It will be proven that the game defined byŨ (C, G, D) has a unique equilibrium that both p c (x, y) and p g (x, y) converge to p(x, y) in Sec. 3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Theoretical Analysis</head><p>We now provide a formal theoretical analysis of Triple-GAN under a nonparametric assumption <ref type="bibr" target="#b0">[1]</ref>. For clarity of the main text, we only present the main results here and defer the proof details to Appendix A.</p><p>First, we would like to show that in the game defined by U (C, G, D), the optimal D given C and G balances between the true data distribution and a mixture distribution of p c (x, y) and p g (x, y), as summarized in Lemma 3.1. Lemma 3.1. For any fixed C and G, the optimal D of the game defined by the objective function U (C, G, D) is:</p><formula xml:id="formula_15">D * C,G (x, y) = p(x, y) p(x, y) + p α (x, y) ,<label>(15)</label></formula><p>where</p><formula xml:id="formula_16">p α (x, y) := (1 − α)p g (x, y) + αp c (x, y) is a mixture distribution for α ∈ (0, 1).</formula><p>Given D * C,G , we can omit D and reformulate the minimax game with the objective function U (C, G, D) as:</p><formula xml:id="formula_17">V (C, G) = max D U (C, G, D), whose minimum is summarized as in Lemma 3.2. Lemma 3.2. The global minimum of V (C, G) is achieved if and only if p(x, y) = p α (x, y).</formula><p>The lemma shows that the adversarial losses ensure that if one of p c (x, y) and p g (x, y) gets closer to the data distribution after convergence, the other one will also be closer to the data distribution.</p><p>We can further show that C and G can at least capture the marginal distributions of data, especially for p g (x), even there may exist multiple global equilibria, as summarized in Corollary 3.2.1. Given the above result that p(x, y) = p α (x, y), C and G do not compete as in the two-player based formulation and it is easy to verify that p(x, y) = p c (x, y) = p g (x, y) is a global equilibrium point. However, it may not be unique and we should minimize an additional objective to ensure the uniqueness. In fact, this is true for the objective functioñ U (C, G, D) in problem <ref type="bibr" target="#b13">(14)</ref>, as stated below. The conclusion essentially motivates our design of Triple-GAN, as we can ensure that both p g (x, y) and p c (x, y) will converge to the true data distribution if the model has been trained to achieve the optimum.</p><p>We can further show another nice property ofŨ , which allows us to regularize our model for a more stable and better convergence in practice without changing the global equilibrium, as summarized below. Corollary 3.3.1. Adding any divergence (e.g. the KL divergence) between any two of the joint distributions or the conditional distributions or the marginal distributions, toŨ as an additional regularization to be minimized, will not change the global equilibrium ofŨ .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Instances and Optimization</head><p>Thanks to decoupling the hypothesis spaces of the classifier and discriminator, it is convenient to adopt recent techniques (e.g., architectures and loss functions) of semi-supervised classification and GANs simultaneously in Triple-GAN. In particular, we implement two instances, called Triple-GAN-V1 and Triple-GAN-V2, for different goals.</p><p>Triple-GAN-V1. Our preliminary goal of Triple-GAN-V1 is to validate our motivation and theory by comparing to the generative approaches <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b46">[47]</ref>. Therefore, we use the same classifier and generator architectures as the prior work <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b27">[28]</ref> for a fair comparison. Since properly leveraging the unlabeled data is key to success in semi-supervised learning, it is necessary to regularize C heuristically as in many existing generative methods <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b46">[47]</ref>, <ref type="bibr" target="#b47">[48]</ref> to make more accurate predictions. Similary, we use the entropy minimization loss in Eqn. (2) on the MNIST and SVHN datasets and the consistency loss in Eqn. (3) on the CIFAR10 and Tiny ImageNet datasets.</p><p>Triple-GAN-V2. We further introduce Triple-GAN-V2 to compare with the state-of-the-art methods in discriminative semi-supervised learning <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b43">[44]</ref> and conditional generation <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b48">[49]</ref>. For a fair and direct comparison, on one hand, we use the exact same classifier in the representative mean teacher method <ref type="bibr" target="#b31">[32]</ref> (See the loss function in Eqn. <ref type="formula" target="#formula_3">(4)</ref>). On the other hand, as for GANs, we adopt the network architectures used in <ref type="bibr" target="#b33">[34]</ref> and a projection discriminator <ref type="bibr" target="#b33">[34]</ref> with spectral normalization <ref type="bibr" target="#b32">[33]</ref>.</p><p>We mention that adding the extra unlabeled data losses in Sec. 2.1 to C may introduce some bias to Triple-GAN. However, in practice, we observed that they won't hurt but help the convergence of G. This is because the losses only affect C directly and if C can make more accurate predictions (i.e. p c (x, y) gets closer to p(x, y)), then G will become better according to Lemma 3.2. Though our implementation does not rigorously follow the theoretical analysis, it does provide valuable insights and explain the good results in some sense.</p><p>Optimization. Given the objective functions, we optimize the three networks alternatively by stochastic gradient descent (SGD) based methods. Let θ c , θ d and θ g denote the trainable parameters in C, D and G, respectively. We need to compute the gradients with respect to all the parameters. The gradients with respect to θ d and θ g can be easily obtained. However, the computation of the gradients of E p(x) E pc(y|x) [log(1 − D(x, y))] with respect to θ c involves a summation over a discrete random variable y, i.e. the class label. Note that directly applying the Monte Carlo method is not feasible because the feedback of the discriminator is not differentiable with respect to θ c . Therefore, we directly integrate out the class label and the gradients are as follows: • Update D by ascending along its stochastic gradient according to Eqn. <ref type="formula" target="#formula_3">(14)</ref>:</p><formula xml:id="formula_18">E p(x)   ∇ θc y∈Y p c (y|x) log(1 − D(x, y))   ,<label>(16)</label></formula><formula xml:id="formula_19">∇ θ d   1 m d ( (x d ,y d ) log D(x d , y d )) + α m c (xc,yc) log(1 − D(x c , y c )) + 1 − α m g (xg,yg) log(1 − D(x g , y g ))   .</formula><p>• Compute the unbiased estimatorsR C andR P in Eqn. <ref type="bibr" target="#b11">(12)</ref> of R C and R P in Eqn. <ref type="bibr" target="#b12">(13)</ref> respectively:</p><formula xml:id="formula_20">R C = − 1 m d (x d ,y d ) log p c (y d |x d ),R P = − 1 m g (xg,yg) log p c (y g |x g ).</formula><p>• Compute the unbiased estimatorR U of R U according to Eqn. (2), Eqn. <ref type="formula" target="#formula_2">(3)</ref> or Eqn. (4) if required.</p><p>• Update C by descending along its stochastic gradient according to Eqn. <ref type="formula" target="#formula_3">(14)</ref>:</p><formula xml:id="formula_21">∇ θc   α m c xc y∈Y p c (y|x c ) log(1 − D(x c , y)) +R C + α PRP + α URU   .</formula><p>• Update G by descending along its stochastic gradient according to Eqn. <ref type="formula" target="#formula_3">(14)</ref>:</p><formula xml:id="formula_22">∇ θg   1 − α m g (xg,yg) log(1 − D(x g , y g ))   . end for</formula><p>where Y is the set of all possible categories. Note that the calculation in Eqn. <ref type="bibr" target="#b15">(16)</ref> only requires one forward pass of D when using the projection discriminator <ref type="bibr" target="#b33">[34]</ref>. The Algorithm 1 presents the whole training procedure. We refer the readers to Appendix B for an illustration of Triple-GAN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RELATED WORK</head><p>Various approaches have been developed to learn directed DGMs, including variational autoencoders (VAEs) <ref type="bibr" target="#b49">[50]</ref>, <ref type="bibr" target="#b50">[51]</ref>, generative moment matching networks (GMMNs) <ref type="bibr" target="#b51">[52]</ref>, <ref type="bibr" target="#b52">[53]</ref>, generative adversarial nets (GANs) <ref type="bibr" target="#b0">[1]</ref> and autoregressive models <ref type="bibr" target="#b53">[54]</ref>, <ref type="bibr" target="#b54">[55]</ref>. These learning criteria are systematically compared in <ref type="bibr" target="#b55">[56]</ref> and among them, GANs have proven effective on generating realistic samples <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref> and becomes popular in applications <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>. Recent work has introduced inference networks in GANs for representation learning. In ALI <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, the inference network approximates the posterior distribution of latent variables given true data in an unsupervised manner. AL-ICE <ref type="bibr" target="#b56">[57]</ref> enhances ALI by introducing conditional entropy regularization in the perspective of joint distribution matching. JointGAN <ref type="bibr" target="#b57">[58]</ref> extends ALI to multiple domains and achieves excellent results. Triple-GAN also has an inference network (classifier) as in these work but there exist two important differences in the global equilibria and the objective functions between them: (1) Triple-GAN matches both the distributions defined by the generator and classifier to true data distribution while ALI only ensures that the distributions defined by the generator and the inference network to be the same; (2) the discriminator will reject the samples from the classifier in Triple-GAN while the discriminator will accept the samples from the inference network in ALI, which leads to different update rules for the discriminator and inference network. These differences naturally arise because Triple-GAN is proposed to solve the problems of GANs with limited supervision as analyzed in Sec. 1. Indeed, ALI <ref type="bibr" target="#b7">[8]</ref> uses the same approach as Improved-GAN <ref type="bibr" target="#b25">[26]</ref> to deal with partially labeled data and hence it still suffers from the same problems (See results in Tab. 1). Following ALI, InfoGAN <ref type="bibr" target="#b18">[19]</ref> and Graphical-GAN <ref type="bibr" target="#b19">[20]</ref> disentangle explainable factors from other latent features in a purely unsupervised manner. However, such methods highly depend on proper inductive biases of the model and the data <ref type="bibr" target="#b21">[22]</ref>. Besides, the meaning of the disentangled factors cannot be predefined. In comparison, Triple-GAN can avoid the issues under the help of the given supervision.</p><p>DGMs can be naturally extended to handle partially labeled data. For instance, the conditional VAE <ref type="bibr" target="#b28">[29]</ref> and its variants <ref type="bibr" target="#b46">[47]</ref>, <ref type="bibr" target="#b58">[59]</ref> treat the missing labels as latent variables and infer them for the unlabeled data. Apart from the work mentioned in Sec. 1, BadGAN <ref type="bibr" target="#b26">[27]</ref> is another semisupervised GAN-based approach, which is based on the same observation that the objective functions in existing semi-supervised GANs are incompatible. However, BadGAN focuses on the classification problem and trains the generator to attack the decision boundary of the classifier instead of to match the data distribution. Therefore, BadGAN achieves comparable classification results with Triple-GAN but leave the generation problem unsolved. Triangle-GAN <ref type="bibr" target="#b37">[38]</ref> extends our conference version <ref type="bibr" target="#b59">[60]</ref> by minimizing the Jensen Shannon divergence between every two joint distributions and demonstrating the effectiveness in applications such as the image to image translation.</p><p>Despite the DGMs, there are extensive discriminative approaches for semi-supervised classification <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b43">[44]</ref>. Such methods define different regularization terms on the unlabeled data and often outperform generative approaches using a comparable classifier. Among them, mean teacher <ref type="bibr" target="#b31">[32]</ref> is a competitive method and many recent methods <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b43">[44]</ref> are built upon it. Our Triple-GAN-V2 also employs the mean teacher classifier <ref type="bibr" target="#b31">[32]</ref> and we directly compare with it in Sec. 5. We mention that there are some concurrent work <ref type="bibr" target="#b60">[61]</ref>, <ref type="bibr" target="#b61">[62]</ref>, <ref type="bibr" target="#b62">[63]</ref>, <ref type="bibr" target="#b63">[64]</ref> using more sophisticated classifiers based on the mixup training <ref type="bibr" target="#b64">[65]</ref> and fine-tuned data augmentation strategy. In principle, such methods can be incorporated in Triple-GAN to further improve the performance potentially, which is left as our future work.</p><p>Some preliminary results were published in <ref type="bibr" target="#b59">[60]</ref>. We extend the original version by presenting the framework in a more coherent and detailed way, extending it to the challenging extreme low data regime, proposing an enhanced version (i.e., Triple-GAN-V2), comparing to a large family of stronger classification (with or without standard data augmentation) and generation baselines, and presenting new results on the Tiny ImageNet dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>In this section, we first present the datasets and the experimental settings briefly. Then, we show the classification and conditional generation results in both semi-supervised learning and the extreme low data regime.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets and Settings</head><p>We evaluate Triple-GAN on the widely adopted MNIST <ref type="bibr" target="#b65">[66]</ref>, SVHN <ref type="bibr" target="#b34">[35]</ref>, and CIFAR10 <ref type="bibr" target="#b35">[36]</ref> and Tiny ImageNet datasets. MNIST consists of 50,000 training samples, 10,000 validation samples and 10,000 testing samples of handwritten digits of size 28 × 28. SVHN consists of 73,257 training samples and 26,032 testing samples and each is a colored image of size 32 × 32, containing a sequence of digits with various backgrounds. CIFAR10 consists of colored images distributed across 10 general classes-airplane, automobile, bird, cat, deer, dog, frog, horse, ship and truck. There are 50,000 training samples and 10,000 testing samples of size 32×32 in CIFAR10. We split 5,000 training data of SVHN and CIFAR10 for validation if needed. On CIFAR10, we follow <ref type="bibr" target="#b36">[37]</ref> to perform ZCA for the input of C but still generate and discriminate the raw images using G and D, respectively. The Tiny ImageNet dataset consists of natural images of size 64 × 64. We select 10 classes, including lion, snow mountain, coffee, teddy bear, penguin, cat, tower, butterfly, car and cabin, out of the 200 classes and downscale the images to 32 × 32 (the dataset will be released with the source code). Each class consists of 500 training samples and 50 testing samples with diverse visual appearance. We randomly split ten percent of the training samples as the validation set if required.</p><p>We implement our method based on Theano <ref type="bibr" target="#b66">[67]</ref> and PyTorch <ref type="bibr" target="#b67">[68]</ref>. We briefly summarize our experimental settings. <ref type="bibr" target="#b3">4</ref> For a fair comparison, all the classification results of the baselines are from the corresponding papers or obtained <ref type="bibr" target="#b3">4</ref>. Our code is available at https://github.com/zhenxuan00/triplegan (Theano) and https://github.com/taufikxu/Triple-GAN (PyTorch). based on the implementation released by the corresponding authors. The generator and classifier of Triple-GAN-V1 and Triple-GAN-V2 have comparable architectures to those of the baselines <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b33">[34]</ref> in the corresponding settings (See details in Appendix E). Besides, we average the classification results of Triple-GAN by multiple runs with different random initialization and splits of the training data and report the mean error rates with the standard deviations following existing work <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b27">[28]</ref>. In our experiments, we find that the training techniques for the original two-player GANs <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b68">[69]</ref> are sufficient to stabilize the optimization of Triple-GAN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Semi-Supervised Learning</head><p>In semi-supervised learning, we first show that Triple-GAN can make predictions accurately and control the semantics of the generated samples as a unified model. Further, we will demonstrate that Triple-GAN can effectively utilize the large amount of unlabeled data and obtain superior or comparable classification and generation results to strong baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Classification</head><p>Results without Data Augmentation. In Tab. 1, we compare our method with a large body of approaches without any data augmentation on the MNIST, SVHN, CIFAR10 and Tiny ImageNet datasets, respectively. The results of Triple-GAN-V1 has been published in our conference version <ref type="bibr" target="#b59">[60]</ref>. On all of the datasets, Triple-GAN-V1 outperforms the most direct competitor (i.e. Improved-GAN) substantially and consistently with the same classifier, which demonstrate the benefit of our compatible learning objective functions. In this paper, we add an enhanced Triple-GAN-V2 to compare against recent discriminative semi-supervised learning methods <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b43">[44]</ref>. Triple-GAN-V2 is built upon a mean teacher (MT) classifier <ref type="bibr" target="#b31">[32]</ref>, and a projection discriminator <ref type="bibr" target="#b33">[34]</ref> with spectral normalization <ref type="bibr" target="#b32">[33]</ref>. Note that decoupling the hypothesis spaces of the classifier and discriminator as in Triple-GAN is necessary to adopt such advances simultaneously because they employ very different architectures and loss functions. In the last two rows of Tab. 1, we can see that Triple-GAN-V2 outperforms MT significantly, especially when the number of labeled data is extremely restricted. For instance, Triple-GAN-V2 reduces more than 10% error rate on CIFAR10 given 1,000 labels. This is because the pseudo discriminative loss can provide relatively more supervision in such cases. Further, Triple-GAN-V2 is better than a large number of recent methods with comparable architectures, showing its effectiveness.</p><p>Results with Data Augmentation. Recent discriminative methods <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b43">[44]</ref> on semisupervised learning often obtain a much better results with data augmentation. Therefore, we investigate whether Triple-GAN-V2 can still improve the MT baseline when standard data augmentation <ref type="bibr" target="#b31">[32]</ref> is applied. The quantitative results are summarized in Tab. 2. Though the gap between Triple-GAN-V2 and MT is slightly reduced compared to Tab. 1, the main conclusion that Triple-GAN-V2 can significantly outperform the baselines with comparable architectures still holds. Besides, Triple-GAN-V2 can benefit from the data augmentation technique as well. These results suggest that <ref type="bibr">TABLE 1</ref> Benchmark results (error rates %) without data augmentation. The methods with † use a similar 13-layer CNN classifier. The results with § are trained with more than 500,000 extra unlabeled data on SVHN. All baseline results are from the corresponding references unless mentioned. As suggested by <ref type="bibr" target="#b39">[40]</ref>, we implement the most direct baselines <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b31">[32]</ref> in our code base for a fair comparison. Our results are averaged by 3 runs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE 2</head><p>Benchmark results (error rates %) with standard data augmentation using a similar 13-layer CNN classifier. All results are from the corresponding references unless specified. As suggested by <ref type="bibr" target="#b39">[40]</ref>, we implement <ref type="bibr" target="#b31">[32]</ref> in our code base for a fair comparison. Our results are averaged by 3 runs.   <ref type="bibr" target="#b16">[17]</ref> classifier with the ShakeShake regularization <ref type="bibr" target="#b69">[70]</ref>.</p><p>All results are implemented in our code base and averaged by 3 runs. the generated data may have very different patterns from the randomly augmented ones and hence can provide complementary learning signals to the classifier. In addition, we qualitatively compare the generated data and the augmented ones in <ref type="figure" target="#fig_3">Fig. 2</ref>. These results strengthen the motivation of using GANs when data augmentation is applicable. We provide preliminary results on CIFAR10 using a 26- The diversity of the generated data is higher than the augmented ones and the patterns of the two types of data are different.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Number of labels</head><p>layer ResNet classifier <ref type="bibr" target="#b31">[32]</ref> in Tab. 3. Triple-GAN-V2 obtains a significant improvement (compared to the measurement variance) over MT given 1,000 labels. The results of 4,000  <ref type="bibr" target="#b31">[32]</ref> and ER refers to the entropy regularized classifier <ref type="bibr" target="#b45">[46]</ref>. For fairness, we implement all methods in our code base. labels indicates that the generator used in Triple-GAN-V2 cannot provide useful learning signals to a classifier with a 6.61% error rate. The result is reasonable and we believe it can be improved by using better GANs. We also notice that some concurrent work <ref type="bibr" target="#b60">[61]</ref>, <ref type="bibr" target="#b61">[62]</ref>, <ref type="bibr" target="#b62">[63]</ref>, <ref type="bibr" target="#b63">[64]</ref> adopts the mixup training <ref type="bibr" target="#b64">[65]</ref> based on the 26-layer ResNet classifier and fine-tuned data augmentation strategies. In principle, such methods can be incorporated in Triple-GAN to further improve the performance potentially, which is left as our future work. Ablation Study. We provide a systematical ablation study of Triple-GAN-V2 in Tab. 4. Firstly, we investigate the effect of α P . Simply setting α P = 0 will lead to a significant drop of accuracy, indicating the importance of the pseudo discriminative loss in Triple-GAN. The result of α P = 3.0 is the best while those of other values still outperform the baseline significantly. Secondly, we change the unlabeled data loss and the data augmentation strategy. We can see that no matter which loss is used and whether the data augmentation is applied or not, Triple-GAN-V2 is superior to the corresponding baseline. We provide more results on the ablation study and the convergence speed of Triple-GAN-V1 in Appendix C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Generation</head><p>We demonstrate that Triple-GAN can learn good G and C simultaneously by quantitatively and qualitatively evaluating the samples generated from the exact models used in Sec. 5.2.1. For a fair comparison, the generative model and the number of labels are the same as the corresponding baselines <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b33">[34]</ref>.</p><p>Quantitative Results. In Tab. 5, we quantitatively compare to existing methods in terms of the Inception Score (IS) <ref type="bibr" target="#b25">[26]</ref> and Fréchet Inception Distance (FID) <ref type="bibr" target="#b44">[45]</ref> on the widely adopted CIFAR10 dataset. Firstly, we note that Triple-GAN-V2 trained with only 8% labels achieves a comparable  <ref type="bibr" target="#b25">[26]</ref> and FID <ref type="bibr" target="#b44">[45]</ref> on CIFAR10. Results with § , † ‡ and † † are trained with fully unlabeled data, partially labeled data (4,000 labels), fully labeled data, and a small subset of fully labeled data (4,000 samples), respectively. The baseline results are from the corresponding references unless specified. For a fair comparison, we use the same protocol and Inception models as in CGAN-PD <ref type="bibr" target="#b33">[34]</ref> for evaluation. result to the strongest baseline (i.e., CGAN with a projection discriminator (CGAN-PD) <ref type="bibr" target="#b33">[34]</ref>) trained with full labels. Secondly, we can see that Triple-GAN-V2 outperforms the CGAN-PD trained on 4,000 labeled data and the spectral normalized GAN (SNGAN) <ref type="bibr" target="#b32">[33]</ref> trained on 50,000 unlabeled data substantially. Such results suggest that Triple-GAN can exploit the large amount of unlabeled data and the small amount of labels to generate high quality samples, which strongly motivates Triple-GAN given partially labeled data. Qualitative Results. We show the ability of Triple-GAN to disentangle category and latent style features in <ref type="figure" target="#fig_5">Fig. 3</ref>. It can be seen that most of the samples have correct semantics and the latent features in Triple-GAN encode meaningful physical factors, including the scale, intensity, orientation, color and so on. Some GANs <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b30">[31]</ref> can generate data class-conditionally given full labels, while Triple-GAN can do the same thing given much less label information. We provide more conditional sample results and latent space interpolation results in Appendix D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Metrics</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">The Extreme Low Data Regime</head><p>We evaluate Triple-GAN on a small subset of the SVHN, CIFAR10 and Tiny ImageNet datasets to show the ability of classification and generation in the extreme low data regime. We remove the losses on the unlabeled data as presented in Sec. 3.3 and keep all the networks the same as those in semi-supervised learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Classification</head><p>We compare Triple-GAN-V1 with two baselines. The main competitor to Triple-GAN-V1 is DADA <ref type="bibr" target="#b27">[28]</ref>, which is a conditional variant of Improved-GAN for the extreme low data regime setting. The CNN baseline denotes a classifier that shares the same architecture as that in Triple-GAN-V1 but is trained without any deep generative models. We compare Triple-GAN-V2 to the mean teacher (MT) classifier <ref type="bibr" target="#b31">[32]</ref> in cases with and without data augmentation.  Tab. 6 show the quantitative results on the SVHN, CIFAR10 and Tiny ImageNet datasets. Both Triple-GAN-V1 and Triple-GAN-V2 achieves better averaged results than the corresponding baselines. We note that the improvement of Triple-GAN is smaller than that in semi-supervised learning and sometimes is not significant, mainly because it is hard to generate high quality images given such a limited amount of data (See <ref type="figure" target="#fig_6">Fig. 4)</ref>. A potential improvement of Triple- Preliminary results (error rates %) using a similar 13-layer CNN classifier. The results with † are from the corresponding references. The classifiers in methods with § are trained with standard data augmentation and the ones in others are trained without any data augmentation. As suggested by <ref type="bibr" target="#b39">[40]</ref>, we implement the CNN and MT <ref type="bibr" target="#b31">[32]</ref> baselines in our code base for a fair comparison. Our results are averaged by 3 runs.  GAN is to adopt more recent GAN training techniques such as <ref type="bibr" target="#b70">[71]</ref>. Nevertheless, in many cases, Triple-GAN outperforms the baselines significantly compared to the measurement variance and is at least comparable to the baselines in the other cases. <ref type="figure" target="#fig_6">Fig. 4</ref> presents the conditional samples generated from Triple-GAN-V2 in the extreme low data regime on the CIFAR10 and Tiny ImageNet datasets. Compared to the results in semi-supervised learning <ref type="figure" target="#fig_5">(Fig. 3)</ref>, the quality and the diversity of the samples are worse because there is no unlabeled data available in the extreme low data regime. In fact, the FID of Triple-GAN-V2 on CIFAR10 (4,000 samples) is 42.3 5 , which is significantly worse than 17.9 in semisupervised learning. Nevertheless, Triple-GAN-V2 is still able to generate meaningful samples with correct semantics in most of the cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.2">Generation</head><p>In summary, the extreme low data regime setting is much more challenging than semi-supervised learning according to our preliminary experiments. We hope the promising results of Triple-GAN can motivate future research in this setting. <ref type="bibr" target="#b4">5</ref>. This is the same as the result of CGAN-PD † † <ref type="bibr" target="#b33">[34]</ref> in Tab. 5 because no additional unlabeled data is available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>We present Triple-GAN, a unified framework for classification and class-conditional generation in both semi-supervised learning and the extreme low data regime. Triple-GAN is formulated as a three-player minimax game between a classifier, a generator and a discriminator. Thanks to the theoretical insights, Triple-GAN is empirically effective and flexible to incorporate new techniques. The enhanced Triple-GAN-V2 proposed in this paper significantly outperforms the original Triple-GAN-V1, showing the promise to further boost the performance by adopting the future advances in both semi-supervised classification and GANs. Following the baselines, we focus on images of size 32 × 32 in this paper and leave the extension on larger datasets like real ImageNet as our future work.</p><p>Following the proof in GAN, the V (C, G) can be rewritten as</p><formula xml:id="formula_23">V (C, G) = − log 4 + 2D JS (p(x, y)||p α (x, y)),<label>(18)</label></formula><p>where D JS is the Jensen-Shannon divergence, which is always non-negative and the unique optimum is achieved if and only if p(x, y) = p α (x, y) = (1 − α)p g (x, y) + αp c (x, y). Similarly, it can be shown that p g (x) = p(x) = p c (x) by taking integral with respect to y. We can rewrite R C as:</p><formula xml:id="formula_24">R C =E p(x,y) [− log p c (y|x)] =E p(x,y) [log p(x, y) p c (x, y) ] − E p(x,y) [log p(y|x)] =D(p(x, y)||p c (x, y)) + E p(x) [H[p(y|x)]] ,</formula><p>where D(·||·) denotes the KL-divergence and H[·] denotes the differential entropy. Because the second term is determined by the data distribution, minimizing R C is equivalent to minimizing D(p(x, y)||p c (x, y)). We now prove the equivalence of minimizing the pseudo discriminative loss R P and the KL-divergence D(p g (x, y)||p c (x, y)) as follows:</p><formula xml:id="formula_25">D(p g (x, y)||p c (x, y)) + E pg(x) [H[p g (y|x)]] − D(p g (x)||p(x)) = p g (x, y) log p g (x, y) p c (x, y) + p g (x, y) log 1 p g (y|x) dxdy − p g (x) log p g (x) p(x) dx = p g (x, y) log p g (x, y)p(x) p c (x, y)p g (y|x)p g (x) dxdy =E pg(x,y) [− log p c (y|x)] = R P .</formula><p>Note that E pg(x) [H[p g (y|x)]] − D(p g (x)||p(x)) is a constant with respective to θ c . Therefore, if we only optimize the parameters in C, these two losses are equivalent. The two KL divergences are always non-negative and zero if and only if p(x, y) = p c (x, y) and p g (x, y) = p c (x, y), respectively. Note that the previous lemmas can also be applied toŨ (C, G, D), which indicates that p(x, y) = p α (x, y) at the global equilibrium and concludes the proof. Corollary 3.3.1. Adding any divergence (e.g. the KL divergence) between any two of the joint distributions or the conditional distributions or the marginal distributions toŨ as an additional regularization to be minimized, will not change the global equilibrium ofŨ .</p><p>Proof. This conclusion can be straightforwardly obtained by the global equilibrium point ofŨ and the definition of a statistical divergence between two distributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX B ILLUSTRATION OF TRIPLE-GAN</head><p>We illustrate the training protocol of Triple-GAN in <ref type="figure" target="#fig_9">Fig. 5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX C MORE CLASSIFICATION RESULTS OF TRIPLE-GAN-V1 IN SEMI-SUPERVISED LEARNING</head><p>Convergence Speed. Though Triple-GAN-V1 has one more network, its convergence speed is at least comparable to that of Improved-GAN, as presented in <ref type="figure" target="#fig_10">Fig. 6</ref>. Both the models are trained on the SVHN dataset with the default settings and Triple-GAN-V1 can get good results in tens of epochs. The reason that the learning curve of Triple-GAN-V1 is oscillatory may be the larger variance of the gradients due to the presence of discrete variables. Also note that we apply the pseudo discriminative loss at the 200-th epoch and then the test error is reduced significantly in next 100 epochs.</p><p>Ablation Study. We investigate the reasons for the outstanding performance of Triple-GAN-V1. we focus on the comparison with Improved-GAN <ref type="bibr" target="#b25">[26]</ref> because we use the exact same classifier, data split and code base, to ensure fairness as suggested by <ref type="bibr" target="#b39">[40]</ref>. We train a single semi-supervised classifier without G and D on SVHN as the baseline and get a result of more than 10% error rate, which shows that G is important for semi-supervised learning even though the classifier can leverage unlabeled data directly. On CIFAR10, the baseline (a simple version of Π model <ref type="bibr" target="#b36">[37]</ref>) achieves 17.7% error rate. The smaller improvement is reasonable as CIFAR10 consists of complex natural images and hence G is not as good as that on SVHN. In addition, we evaluate Triple-GAN-V1 without the pseudo discriminative loss on SVHN and it achieves about 7.8% error rate, which shows the advantages of the compatible objective functions (better than the 8.11% error rate of Improved-GAN) and the importance of the pseudo discriminative loss (worse than the complete Triple-GAN-V1 by 2%).</p><p>Effect of the numbers of labeled and unlabeled data. We systematically analyze the effect of the numbers of labeled and unlabeled data on the SVHN dataset in <ref type="figure" target="#fig_11">Fig 7.</ref> As the number of labels increases, the performance of Triple-GAN-V1 is better and has a lower variance. However, if given a sufficient number of unlabeled data, i.e. more than 20,000, then the performance of Triple-GAN-V1 won't get hurt too much by reducing the number of labels from 2,000 to 500. The results suggest the importance of unlabeled data to the final performance of the classifier in semi-supervised learning.  <ref type="bibr" target="#b23">[24]</ref>. In CatGAN, the discriminator not only classifies the input but also estimates whether the input is real or fake. Besides, CatGAN focuses on the marginal distribution of images without considering label information. In Triple-GAN, the generator and the classifier approximate two conditional distributions respectively and the discriminator solely identifies the label-data pairs. Triple-GAN ensures that pc(x, y) = pg(x, y) = p(x, y) after convergence.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX D MORE GENERATION RESULTS OF TRIPLE-GAN-V1 IN SEMI-SUPERVISED LEARNING</head><p>Sample Quality Comparison to Improved-GAN. In <ref type="figure" target="#fig_12">Fig. 8</ref>, we first compare the quality of the samples generated by Triple-GAN-V1 and Improved-GAN trained with feature matching <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b5">6</ref> which works well for semi-supervised classification. We can see that Triple-GAN-V1 outperforms the baseline by generating fewer meaningless samples and clearer digits. Further, the baseline generates the same strange sample four times, labeled with the red rectangles in <ref type="figure" target="#fig_12">Fig. 8</ref>. Class-conditional Generation. We illustrate images generated by Triple-GAN-V1 in specific classes on CIFAR10 in <ref type="figure" target="#fig_13">Fig. 9</ref>. In most cases, Triple-GAN-V1 is able to generate meaningful images with correct semantics. <ref type="bibr" target="#b5">6</ref>. Though the Improved-GAN trained with minibatch discrimination <ref type="bibr" target="#b25">[26]</ref> can generate good samples, it fails to predict labels accurately.  Latent Space Interpolation. We demonstrate the generalization capability of our Triple-GAN-V1 via class-conditional latent space interpolation. As presented in <ref type="figure" target="#fig_2">Fig. 10</ref>, Triple-GAN-V1 can transit smoothly from one sample to another with totally different visual factors without losing label semantics, which proves that Triple-GANs can learn mean-ingful latent spaces class-conditionally instead of overfitting to the training data, especially labeled data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX E TRAINING DETAILS</head><p>We present the training details in both semi-supervised learning and the extreme low data regime.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.1 Semi-supervised learning</head><p>In semi-supervised learning, we augment the labeled data in the training of D. In particular, we generate pseudo labels through C for some unlabeled data and use these pairs as positive samples for D to accept. Via this trick, D will access samples beyond the empirical distribution of the small-size labeled data and encourage G to generate diverse samples. The cost of the trick is on introducing some bias to the target distribution of D, which is a mixture of p c (x, y) and p(x, y) instead of the pure p(x, y). However, this is acceptable as C converges quickly and p c (x, y) and p(x, y) are close.</p><p>Triple-GAN-V1. The pseudo discriminative loss is not applied until the number of epochs reaches a threshold that the generator could generate meaningful data. We search the threshold in {200, 300}, α P in {0.1, 0.03} and the global learning rate in {0.0003, 0.001} based on the validation performance on each dataset. All of the other hyperparameters including relative weights and parameters in Adam <ref type="bibr" target="#b71">[72]</ref> are fixed according to <ref type="bibr" target="#b25">[26]</ref> across all of the experiments. We list the detailed architectures of Triple-GAN-V1 on the MNIST, SVHN and CIFAR10 datasets in Tab. 7, Tab. 8 and Tab. 9, respectively. On Tiny ImageNet, we use the same architectures as on CIFAR10.</p><p>Triple-GAN-V2. We use the exact same classifier architecture, data augmentation protocol and hyperparameters as in the baseline <ref type="bibr" target="#b31">[32]</ref> unless specified. In particular, the coefficient α U and learning rate have a ramp-up period of 40,000 iterations from the beginning and they ramped up from 0 to the maximum values (50.0 for α U and 0.001 for the learning rate), using a sigmoid-shaped function e −5(1−x) <ref type="bibr" target="#b1">2</ref> , where x ∈ [0, 1]. On Tiny ImageNet, Triple-GAN-V2 is trained by 100,000 iterations in total and the first 10,000 iterations are for pretraining of the classifier. On other datasets, Triple-GAN-V2 is trained by 220,000 iterations in total and the first 20,000 iterations are for pretraining of the classifier. The pseudo discriminative loss is not applied until 50, 000 iterations on SVHN and CIFAR10 and 30, 000 iterations on Tiny ImageNet. We also add a ramp-up period of 20,000 iterations steps for α P and it ramped up from 0 to 3.0, using the same ramp-up function as α U . We use a projection discriminator <ref type="bibr" target="#b33">[34]</ref> with spectral normalization <ref type="bibr" target="#b32">[33]</ref>. All of the other hyperparameters including relative weights and parameters in Adam <ref type="bibr" target="#b71">[72]</ref> are fixed according to <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b33">[34]</ref> across all of the experiments. We list the detailed architectures of Triple-GAN-V2 and Triple-GAN-V2 with a 26-layer ResNet classifier in Tab. 10 and Tab. 11, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.2 Extreme low data regime</head><p>All architectures are the same in both semi-supervised learning and the extreme low data regime on the same dataset.</p><p>Triple-GAN-V2 is trained by 100,000/150,000/100,000 iterations in total with the maximum value of α P to be 0.01/0.3/0.01 on SVHN, CIFAR10 and Tiny ImageNet. Other hyperparameters are kept the same as in the semi-supervised learning. We also add the balanced consistency regularization on GANs <ref type="bibr" target="#b72">[73]</ref> to relieve the mode collapse and the related hyperparameters are set exactly the same as the original paper. See more details in our source code.       <ref type="figure" target="#fig_2">Fig. 10</ref>. Class-conditional latent space interpolation. We first sample two random vectors in the latent space and interpolate linearly from one to another. Then, we map these vectors to the data level given a fixed label for each class. Totally, 20 images are shown for each class. We select two endpoints with clear semantics on the CIFAR10 dataset for better illustration.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Corollary 3 . 2 . 1 .</head><label>321</label><figDesc>Given p(x, y) = p α (x, y), the marginal distributions of p(x, y), p c (x, y) and p g (x, y) are the same, i.e. p(x) = p g (x) = p c (x) and p(y) = p g (y) = p c (y).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Theorem 3 . 3 .</head><label>33</label><figDesc>The equilibrium ofŨ (C, G, D) is achieved if and only if p(x, y) = p g (x, y) = p c (x, y).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Algorithm 1</head><label>1</label><figDesc>Minibatch stochastic gradient descent training of Triple-GAN. for number of training iterations do • Sample a batch of pairs (x g , y g ) ∼ p g (x, y) of size m g , a batch of pairs (x c , y c ) ∼ p c (x, y) of size m c and a batch of the labeled data (x d , y d ) ∼ p(x, y) of size m d .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2 .</head><label>2</label><figDesc>Comparison between the generated data and augmented data. The first row shows the data generated from Triple-GAN-V2. The second row shows the corresponding nearest neighbours in the training data of the same class. The last three rows show the randomly augmented data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 3 .</head><label>3</label><figDesc>Samples of Triple-GAN in semi-supervised learning. On MNIST and SVHN, the samples are from Triple-GAN-V1. On CIFAR10 and Tiny ImageNet, the samples are from Triple-GAN-V2. In the figures, each row shares the same label and each column shares the same latent variables.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 4 .</head><label>4</label><figDesc>Conditional samples of Triple-GAN-V2 in the extreme low data regime. In the figures, Each row shares the same label.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Corollary 3 . 2 . 1 .</head><label>321</label><figDesc>Given p(x, y) = p α (x, y), the marginal distributions of p(x, y), p c (x, y) and p g (x, y) are the same, i.e. p(x) = p g (x) = p c (x) and p(y) = p g (y) = p c (y). Proof. Remember that p g (x, y) = p(y)p g (x|y) and p c (x, y) = p(x)p c (y|x). Take integral with respect to x on both sides of p(x, y) = p α (x, y) to get p(x, y)dx = (1 − α) p g (x, y)dx + α p c (x, y)dx, which indicates that p(y) = (1 − α)p(y) + αp c (y), i.e. p c (y) = p(y) = p g (y).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Theorem 3 . 3 .</head><label>33</label><figDesc>The equilibrium ofŨ (C, G, D) is achieved if and only if p(x, y) = p g (x, y) = p c (x, y). Proof. According to the definition, we haveŨ (C, G, D) = U (C, G, D) + R C + α P P P , where R C = E p(x,y) [− log p c (y|x)], and P P = E pg(x,y) [− log p c (y|x)].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 5 .</head><label>5</label><figDesc>Comparison between Triple-GAN (right panel) and a representative prior work (left panel), i.e. CatGAN</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 6 .</head><label>6</label><figDesc>The convergence speeds of Improved-GAN and Triple-GAN-V1 on SVHN.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 7 .</head><label>7</label><figDesc>Error rates (%) on the partially labeled SVHN dataset with different numbers of labeled and unlabeled data. The results are averaged by 9 runs with different random selections of labeled and unlabeled data. We plot the mean and error bars of one standard deviation in each curve.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 8 .</head><label>8</label><figDesc>Comparison between samples from Improved-GAN trained with feature matching and Triple-GAN-V1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 9 .</head><label>9</label><figDesc>Samples of Triple-GAN-V1 in specific classes on the CIFAR10 dataset. The semantics of the samples are clear and correct in most of the cases.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE 3</head><label>3</label><figDesc>Preliminary results on CIFAR-10 with standard data augmentation using a 26-layer ResNet</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE 4</head><label>4</label><figDesc>Ablation study of the main factors in Triple-GAN-V2. MT refers to the mean teacher classifier</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE 5 IS</head><label>5</label><figDesc></figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>TABLE 6</head><label>6</label><figDesc></figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>TABLE 7 Triple-GAN-V1 on MNIST</head><label>7</label><figDesc></figDesc><table><row><cell>Classifier C</cell><cell>Discriminator D</cell><cell>Generator G</cell></row><row><cell>Input 28×28 Gray Image</cell><cell>Input 28×28 Gray Image, Ont-hot Class representation</cell><cell>Input Class y, Noise z</cell></row><row><cell>5×5 conv. 32 ReLU</cell><cell>MLP 1000 units, lReLU, gaussian noise, weight norm</cell><cell>MLP 500 units,</cell></row><row><cell>2×2 max-pooling, 0.5 dropout</cell><cell>MLP 500 units, lReLU, gaussian noise, weight norm</cell><cell>softplus, batch norm</cell></row><row><cell>3×3 conv. 64 ReLU</cell><cell>MLP 250 units, lReLU, gaussian noise, weight norm</cell><cell></cell></row><row><cell>3×3 conv. 64 ReLU</cell><cell>MLP 250 units, lReLU, gaussian noise, weight norm</cell><cell>MLP 500 units,</cell></row><row><cell>2×2 max-pooling, 0.5 dropout</cell><cell>MLP 250 units, lReLU, gaussian noise, weight norm</cell><cell>softplus, batch norm</cell></row><row><cell>3×3 conv. 128 ReLU</cell><cell>MLP 1 unit, sigmoid, gaussian noise, weight norm</cell><cell></cell></row><row><cell>3×3 conv. 128 ReLU</cell><cell></cell><cell>MLP 784 units, sigmoid</cell></row><row><cell>Global pool</cell><cell></cell><cell></cell></row><row><cell>10-class Softmax</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>TABLE 8 Triple-GAN-V1 on SVHN</head><label>8</label><figDesc></figDesc><table><row><cell>Classifier C</cell><cell>Discriminator D</cell><cell>Generator G</cell></row><row><cell>Input: 32×32 Colored Image</cell><cell>Input: 32×32 colored image, class y</cell><cell>Input: Class y, Noise z</cell></row><row><cell>0.2 dropout</cell><cell>0.2 dropout</cell><cell>MP 8192 units,</cell></row><row><cell>3×3 conv. 128 lReLU, batch norm</cell><cell>3×3 conv. 32, lReLU, weight norm</cell><cell>ReLU, batch norm</cell></row><row><cell>3×3 conv. 128 lReLU, batch norm</cell><cell>3×3 conv. 32, lReLU, weight norm, stride 2</cell><cell>Reshape 512×4×4</cell></row><row><cell>3×3 conv. 128 lReLU, batch norm</cell><cell></cell><cell>5×5 deconv. 256. stride 2,</cell></row><row><cell>2×2 max-pooling, 0.5 dropout</cell><cell>0.2 dropout</cell><cell>ReLU, batch norm</cell></row><row><cell>3×3 conv. 256 lReLU, batch norm</cell><cell>3×3 conv. 64, lReLU, weight norm</cell><cell></cell></row><row><cell>3×3 conv. 256 lReLU, batch norm</cell><cell>3×3 conv. 64, lReLU, weight norm, stride 2</cell><cell></cell></row><row><cell>3×3 conv. 256 lReLU, batch norm</cell><cell></cell><cell>5×5 deconv. 128. stride 2,</cell></row><row><cell>2×2 max-pooling, 0.5 dropout</cell><cell>0.2 dropout</cell><cell>ReLU, batch norm</cell></row><row><cell>3×3 conv. 512 lReLU, batch norm</cell><cell>3×3 conv. 128, lReLU, weight norm</cell><cell></cell></row><row><cell>NIN, 256 lReLU, batch norm</cell><cell>3×3 conv. 128, lReLU, weight norm</cell><cell></cell></row><row><cell>NIN, 128 lReLU, batch norm</cell><cell></cell><cell></cell></row><row><cell>Global pool</cell><cell>Global pool</cell><cell>5×5 deconv. 3. stride 2,</cell></row><row><cell>10-class Softmax, batch norm</cell><cell>MLP 1 unit, sigmoid</cell><cell>sigmoid, weight norm</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>TABLE 9 Triple-GAN-V1 on CIFAR10</head><label>9</label><figDesc></figDesc><table><row><cell>Classifier C</cell><cell>Discriminator D</cell><cell>Generator G</cell></row><row><cell>Input: 32×32 Colored Image</cell><cell>Input: 32×32 colored image, class y</cell><cell>Input: Class y, Noise z</cell></row><row><cell>Gaussian noise</cell><cell>0.2 dropout</cell><cell>MLP 8192 units,</cell></row><row><cell>3×3 conv. 128 lReLU, weight norm</cell><cell>3×3 conv. 32, lReLU, weight norm</cell><cell>ReLU, batch norm</cell></row><row><cell>3×3 conv. 128 lReLU, weight norm</cell><cell>3×3 conv. 32, lReLU, weight norm, stride 2</cell><cell>Reshape 512×4×4</cell></row><row><cell>3×3 conv. 128 lReLU, weight norm</cell><cell></cell><cell>5×5 deconv. 256.stride 2</cell></row><row><cell>2×2 max-pooling, 0.5 dropout</cell><cell>0.2 dropout</cell><cell>ReLU, batch norm</cell></row><row><cell>3×3 conv. 256 lReLU, weight norm</cell><cell>3×3 conv. 64, lReLU, weight norm</cell><cell></cell></row><row><cell>3×3 conv. 256 lReLU, weight norm</cell><cell>3×3 conv. 64, lReLU, weight norm, stride 2</cell><cell></cell></row><row><cell>3×3 conv. 256 lReLU, weight norm</cell><cell></cell><cell>5×5 deconv. 128. stride 2</cell></row><row><cell>2×2 max-pooling, 0.5 dropout</cell><cell>0.2 dropout</cell><cell>ReLU, batch norm</cell></row><row><cell>3×3 conv. 512 lReLU, weight norm</cell><cell>3, ×3 conv. 128 lReLU, weight norm</cell><cell></cell></row><row><cell>NIN, 256 lReLU, weight norm</cell><cell>3×3 conv. 128, lReLU, weight norm</cell><cell></cell></row><row><cell>NIN, 128 lReLU, weight norm</cell><cell></cell><cell></cell></row><row><cell>Global pool</cell><cell>Global pool</cell><cell>5×5 deconv. 3. stride 2</cell></row><row><cell>10-class Softmax with weight norm</cell><cell>MLP 1 unit, sigmoid, weight norm</cell><cell>tanh, weight norm</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>TABLE 10 Triple-GAN-V2 on SVHN, CIFAR10 and Tiny ImageNet</head><label>10</label><figDesc></figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX A DETAILED THEORETICAL ANALYSIS</head><p>where p α (x, y) := (1 − α)p g (x, y) + αp c (x, y) is a mixture distribution for α ∈ (0, 1).</p><p>Proof. Given the classifier and generator, the objective function can be rewritten as  Proof. Given D * C,G , we can reformulate the minimax game with value function U as:  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Generative adversarial nets,&quot; in NIPS</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06434</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Wasserstein gan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.07875</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Progressive growing of gans for improved quality, stability, and variation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lehtinen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10196</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">A style-based generator architecture for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.04948</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Large scale gan training for high fidelity natural image synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.11096</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Adversarial feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Krähenbühl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.09782</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Adversarially learned inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Belghazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Mastropietro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.00704</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Large scale adversarial representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jeff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.02544</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Image-to-image translation with conditional adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1125" to="1134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Unpaired image-toimage translation using cycle-consistent adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2223" to="2232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">N</forename><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5907" to="5915" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Photorealistic single image super-resolution using a generative adversarial network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ledig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Huszár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Acosta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Aitken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Totz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4681" to="4690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Weakly-supervised disentangling with recurrent transformations for 3d view synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">InfoGAN: Interpretable representation learning by information maximizing generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Houthooft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Graphical generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Max-margin deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1837" to="1845" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Challenging common assumptions in the unsupervised learning of disentangled representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Locatello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lucic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Raetsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bachem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">international conference on machine learning</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4114" to="4124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1411.1784</idno>
		<title level="m">Conditional generative adversarial nets</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Unsupervised and semi-supervised learning with categorical generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Springenberg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06390</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Semi-supervised learning with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Odena</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.01583</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Improved techniques for training GANs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Good semi-supervised learning that requires a bad gan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6510" to="6520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Dada: Deep adversarial data augmentation for extremely low data regime classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.00981</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Semisupervised learning with deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Human-level concept learning through probabilistic program induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">350</biblScope>
			<biblScope unit="issue">6266</biblScope>
			<biblScope unit="page" from="1332" to="1338" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Conditional image synthesis with auxiliary classifier gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.09585</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Valpola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1195" to="1204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kataoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yoshida</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.05957</idno>
		<title level="m">Spectral normalization for generative adversarial networks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">cgans with projection discriminator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Koyama</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.05637</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Reading digits in natural images with unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS workshop on deep learning and unsupervised feature learning</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Citeseer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Temporal ensembling for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.02242</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Triangle generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Carin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5247" to="5256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Smooth neighbors on teacher graphs for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8896" to="8905" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Realistic evaluation of deep semi-supervised learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3235" to="3246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on challenges in representation learning, ICML</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Virtual adversarial training: a regularization method for supervised and semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ishii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="1979" to="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Label propagation for deep semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Iscen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tolias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Avrithis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Chum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5070" to="5079" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">There are many consistent explanations of unlabeled data: Why you should average</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Athiwaratkun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Finzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Izmailov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Wilson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.05594</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Gans trained by a two time-scale update rule converge to a local nash equilibrium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Heusel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ramsauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Nessler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6626" to="6637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Semi-supervised learning by entropy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Grandvalet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004-01" />
			<biblScope unit="volume">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Max-margin deep generative models for (semi-) supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="2762" to="2775" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Semi-supervised learning with ladder networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rasmus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Berglund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Honkala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Valpola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Raiko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Improved training of wasserstein gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5767" to="5777" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Auto-encoding variational Bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Stochastic backpropagation and approximate inference in deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1401.4082</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Generative moment matching networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Training generative neural networks via maximum mean discrepancy optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">K</forename><surname>Dziugaite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.03906</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Deep autoregressive networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1310.8499</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Conditional image generation with pixelcnn decoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4790" to="4798" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">A note on the evaluation of generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bethge</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.01844</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Alice: Towards understanding adversarial learning for joint distribution matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Henao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Carin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5495" to="5503" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Jointgan: Multi-domain joint distribution learning with generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Henao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Carin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.02978</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Maaløe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Winther</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.05473</idno>
		<title level="m">Auxiliary deep generative models</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Triple generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chongxuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4088" to="4098" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Interpolation consistency training for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kannala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.03825</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Fixmatch: Simplifying semi-supervised learning with consistency and confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.07685</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Remixmatch: Semi-supervised learning with distribution alignment and augmentation anchoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.09785</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Mixmatch: A holistic approach to semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5049" to="5059" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.09412</idno>
		<title level="m">mixup: Beyond empirical risk minimization</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Theano: A Python framework for fast computation of mathematical expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theano</forename><surname>Development Team</surname></persName>
		</author>
		<idno>abs/1605.02688</idno>
		<ptr target="http://arxiv.org/abs/1605.02688" />
		<imprint>
			<date type="published" when="2016-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8026" to="8037" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Deep generative image models using a Laplacian pyramid of adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">L</forename><surname>Denton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Shake-shake regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gastaldi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.07485</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Training generative adversarial networks with limited data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Aittala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hellsten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lehtinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.06676</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Improved consistency regularization for gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.04724</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">32×32 Colored Image Input: 32×32 colored image, class y Input: Class y, Noise z Randomly {∆x, ∆y} ∈ [−2, 2] Randomly Flip with p = 0.5 (except on SVHN) Gaussian noise 3×3 2-layer residual block. 2048. stride 2 MLP 8×256×4 units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Classifier C Discriminator D Generator</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Input</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>3×3 conv. 128 lReLU. weight norm ReLU, spectral norm Reshape 2048×2×2</note>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">3×3 2-layer residual block. 2048. stride 2 3×3 conv. 128 lReLU, weight norm 2×2 max-pooling, 0.5 dropout ReLU, spectral norm ReLU, batch norm 3×3 conv. 256 lReLU, weight norm 3×3 2-layer residual block. 2048. stride 2 3×3 2-layer residual block. 1024.stride 2 3×3 conv. 256 lReLU, weight norm ReLU, spectral norm ReLU</title>
		<idno>3×3 conv. 128</idno>
	</analytic>
	<monogr>
		<title level="m">lReLU, weight norm 3×3 2-layer residual block. 2048. stride</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note>batch norm 3×3 conv. 256 lReLU. weight norm 3×3 2-layer residual block. 2048. stride 2 3×3 2-layer residual block. 512. stride 2 2×2 max-pooling, 0.5 dropout ReLU, spectral norm ReLU. batch norm</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
