<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PREPRINT MANUSCRIPT OF IEEE/ACM TRANSACTIONS ON AUDIO, SPEECH AND LANGUAGE PROCESSING 1 Utterance-to-Utterance Interactive Matching Network for Multi-Turn Response Selection in Retrieval-Based Chatbots</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Chen</forename><surname>Gu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Senior Member, IEEE</roleName><forename type="first">Zhen-Hua</forename><surname>Ling</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Liu</surname></persName>
						</author>
						<title level="a" type="main">PREPRINT MANUSCRIPT OF IEEE/ACM TRANSACTIONS ON AUDIO, SPEECH AND LANGUAGE PROCESSING 1 Utterance-to-Utterance Interactive Matching Network for Multi-Turn Response Selection in Retrieval-Based Chatbots</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T08:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-dialogue</term>
					<term>response selection</term>
					<term>interactive match- ing network</term>
					<term>utterance-to-utterance</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper proposes an utterance-to-utterance interactive matching network (U2U-IMN) for multi-turn response selection in retrieval-based chatbots. Different from previous methods following context-to-response matching or utterance-toresponse matching frameworks, this model treats both contexts and responses as sequences of utterances when calculating the matching degrees between them. For a context-response pair, the U2U-IMN model first encodes each utterance separately using recurrent and self-attention layers. Then, a global and bidirectional interaction between the context and the response is conducted using the attention mechanism to collect the matching information between them. The distances between context and response utterances are employed as a prior component when calculating the attention weights. Finally, sentence-level aggregation and context-response-level aggregation are executed in turn to obtain the feature vector for matching degree prediction. Experiments on four public datasets showed that our proposed method outperformed baseline methods on all metrics, achieving a new state-of-the-art performance and demonstrating compatibility across domains for multi-turn response selection.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>B UILDING a chatbot that can converse naturally with humans on open-domain topics is a challenging yet intriguing problem in artificial intelligence. Recently, humancomputer conversation has attracted increasing attention due to its promising potential and commercial value <ref type="bibr" target="#b1">[2]</ref>- <ref type="bibr" target="#b3">[4]</ref>. Existing approaches to building chatbots include generationbased methods <ref type="bibr" target="#b4">[5]</ref>- <ref type="bibr" target="#b5">[7]</ref> and retrieval-based methods <ref type="bibr" target="#b6">[8]</ref>- <ref type="bibr" target="#b13">[14]</ref>. Response selection, which aims to select the best-matched response from a set of candidates given the context of a conversation, is the key technique for building retrieval-based chatbots.</p><p>In recent years, neural networks have been adopted to calculate the matching degrees between a context and its response candidates for response selection. Existing studies on neural network-based multi-turn response selection follow either context-to-response matching or utterance-to-response matching frameworks. The former adopts a coarse granularity This paper is the extended version of a short paper <ref type="bibr" target="#b0">[1]</ref> that has been accepted by the ACM CIKM 2019 conference.</p><p>J.-C. <ref type="bibr">Gu</ref>   for both contexts and responses that concatenates all utterances in a context or in a response into a single word sequence for matching degree calculation <ref type="bibr" target="#b6">[8]</ref>- <ref type="bibr" target="#b9">[10]</ref>. The latter adopts a fine granularity for contexts that separates a context into utterances but still concatenates all utterances in a response <ref type="bibr" target="#b10">[11]</ref>- <ref type="bibr" target="#b12">[13]</ref>. However, both contexts and responses may contain multiple utterances in the response selection task, as illustrated in <ref type="table" target="#tab_1">Table I</ref>. Both frameworks mentioned above neglect the relationships among the utterances in a response. Therefore, this paper proposes a neural network model named the utterance-to-utterance interactive matching network (U2U-IMN) for multi-turn response selection in retrieval-based chatbots. This model follows a new utteranceto-utterance (U2U) matching framework in order to deal with the situation in which both contexts and responses may contain multiple utterances. Different from the context-to-response matching and utterance-to-response matching frameworks, the U2U matching framework treats both contexts and responses as sequences of utterances when calculating the matching degrees between them. Therefore, the U2U-IMN model first encodes each utterance separately for a context-response pair. A previous study on natural language inference (NLI) <ref type="bibr" target="#b14">[15]</ref> found that performing interactions between sentence pairs can provide useful matching information. Inspired by this, an attention-based interaction between the context and the response is conducted to collect the matching information between them. Here, the interaction is global (i.e., crossing utterance boundaries) and bidirectional (i.e., considering both context-to-response and response-to-context arXiv:1911.06940v1 [cs.CL] 16 Nov 2019 directions) in order to enrich the relevance representations of contexts and responses. The distances between context and response utterances are employed as a prior component when calculating the attention weights in order to distinguish the semantic contributions of different utterances in a context. Finally, sentence-level aggregation and context-response-level aggregation are executed in turn to obtain the feature vector for matching degree prediction.</p><p>Our proposed methods were evaluated on two English datasets, the Ubuntu Dialogue Corpus V1 <ref type="bibr" target="#b6">[8]</ref> and Ubuntu Dialogue Corpus V2 <ref type="bibr" target="#b9">[10]</ref>, along with two Chinese datasets, the Douban Conversation Corpus <ref type="bibr" target="#b10">[11]</ref> and E-commerce Dialogue Corpus <ref type="bibr" target="#b12">[13]</ref>, which are all public datasets widely used in studies on multi-turn conversation. The results showed that our proposed method outperformed baseline methods on all metrics, achieved a new state-of-the-art performance, and demonstrated compatibility across domains for multi-turn response selection.</p><p>In summary, the main contributions of this paper are twofold. First, this paper proposes a neural network model named U2U-IMN to deal with the situation in which both contexts and responses may contain multiple utterances. In this model, a matching module with attention-based global and bidirectional interactions is designed to collect the matching information between context and response utterances. Second, experimental results demonstrate that our proposed method achieves a new state-of-the-art performance on four public datasets for multi-turn response selection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>Chatbots aim to engage users in human-computer conversations in the open domain and are currently receiving increasing attention because they can target unstructured dialogue without a priori logical representation of the information exchanged during the conversation. Existing work on building chatbots includes generation-based methods <ref type="bibr" target="#b4">[5]</ref>- <ref type="bibr" target="#b5">[7]</ref>, <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref> and retrieval-based methods <ref type="bibr" target="#b6">[8]</ref>- <ref type="bibr" target="#b12">[13]</ref>. Generation-based models maximize the probability of generating a response given the previous dialogue. This approach enables the incorporation of rich context when mapping between consecutive dialogue turns. Retrieval-based chatbots have the advantage of generating informative and fluent responses because they select a proper response for the current conversation from a repository by means of response selection algorithms.</p><p>Early studies on retrieval-based chatbots focused on singleturn conversation <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref>. Recently, researchers have extended their attention to multi-turn conversation, which is more practical for real applications. A straightforward approach to multi-turn conversation is to match a response with the literal concatenation of context utterances <ref type="bibr" target="#b6">[8]</ref>- <ref type="bibr" target="#b9">[10]</ref>. Then, a multi-view model <ref type="bibr" target="#b19">[20]</ref>, including an utterance view and a word view, was studied. Wu et al. <ref type="bibr" target="#b10">[11]</ref> proposed the sequential matching network (SMN), which first matched the response with each context utterance and then accumulated the matching information using a recurrent neural network (RNN). Zhang et al. <ref type="bibr" target="#b12">[13]</ref> employed self-matching attention to route the vital information in each utterance based on SMN. The method of constructed representations at different granularities with stacked self-attention <ref type="bibr" target="#b11">[12]</ref> has also been presented.</p><p>Our proposed U2U-IMN model has three main differences from the studies mentioned above. (1) U2U-IMN adopts a more fine-grained utterance-to-utterance (U2U) matching framework, while previous studies followed the framework of either context-to-response matching or utterance-to-response matching. (2) U2U-IMN derives the matching information between contexts and responses through global and bidirectional interactions, while the interactions used in previous studies were usually local and unidirectional <ref type="bibr" target="#b10">[11]</ref>. (3) U2U-IMN employs the distances between context and response utterances as a prior component for calculating the attention weights in the interactive matching module.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. UTTERANCE-TO-UTTERANCE INTERACTIVE MATCHING NETWORK A. Model Overview</head><p>Given a dialogue dataset D, an example of the dataset can be represented as (c, r, y). Specifically, c = {u c 1 , u c 2 , ..., u c nc } represents a context with {u c m } nc m=1 as its utterances and n c as its utterance number. Similarly, r = {u r 1 , u r 2 , ..., u r nr } represents a response candidate with {u r n } nr n=1 as its utterances and n r as its utterance number. Here, both the context and the response may be composed of multiple utterances, and the utterances in c and r are both chronologically ordered. y ∈ {0, 1} denotes a label. y = 1 indicates that r is a proper response for c; otherwise, y = 0. Our goal is to learn a matching model g(c, r) from D. For any context-response pair (c, r), g(c, r) measures the matching degree between c and r. We learn g(c, r) by minimizing the sigmoid cross-entropy on D. Let Θ denote the set of model parameters. Then, the objective function L(D, Θ) of learning can be formulated as</p><formula xml:id="formula_0">L(D, Θ) = − (c,r,y)∈D [ylog(g(c, r)) + (1 − y)log(1 − g(c, r))].<label>(1)</label></formula><p>The U2U-IMN model is designed to calculate the matching degree g(c, r) for a context-response pair. It is composed of a word representation module, a sentence encoding module, an interactive matching module, an aggregation module and a prediction module, as shown in <ref type="figure" target="#fig_1">Fig. 1</ref>. Details about each module are provided in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Word Representation Module</head><p>One challenge of word representation for dialogue is the large number of out-of-vocabulary (OOV) words. To address this issue, we combine the general pretrained word embeddings with those estimated on a task-specific training set <ref type="bibr" target="#b20">[21]</ref>. To further enhance the word embeddings, a convolutional neural network (CNN) is employed to model the morphology information at the character-level <ref type="bibr" target="#b21">[22]</ref>.</p><p>Formally, the word embeddings of the m-th utterance in a context and the n-th utterance in a response candidate are denoted  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Sentence Encoding Module</head><p>First, each utterance in a context or in a response candidate is encoded by a bidirectional long short-term memory network (BiLSTM) <ref type="bibr" target="#b22">[23]</ref>. We denote the calculations as follows:</p><formula xml:id="formula_1">u c m,i = BiLSTM(U c m , i), i ∈ {1, ..., l u c m }, (2) u r n,j = BiLSTM(U r n , j), j ∈ {1, ..., l u r n }.<label>(3)</label></formula><p>The parameters in these two BiLSTMs are shared in our implementation.</p><p>To consider long-term dependency and highlight the semantic influences among adjacent words at the same time, a self-attention layer <ref type="bibr" target="#b23">[24]</ref> with a Gaussian prior <ref type="bibr" target="#b24">[25]</ref> is employed to enhance the performance of BiLSTM-based sentence encoding. For a word in a context utterance, its representation after self-attention is calculated as</p><formula xml:id="formula_2">u c m,i = j Softmax(−|wd 2 i,j + b| +ū c m,i ·ū c m,j )ū c m,j ,<label>(4)</label></formula><p>where d i,j is the word-level distance between the i-th word and the j-th word, and w and b are scalar parameters estimated by model training. Similarly, for each word in a response utterance, we havẽ</p><formula xml:id="formula_3">u r n,j = i Softmax(−|wd 2 i,j + b| +ū r n,i ·ū r n,j )ū r n,i . (5)</formula><p>Finally, the outputs of the sentence encoding module are</p><formula xml:id="formula_4">U c m = {ũ c m,i } l u c m i=1 , m ∈ {1, .</formula><p>.., n c } for context utterances and U r n = {ũ r n,j } l u r n j=1 , n ∈ {1, ..., n r } for response utterances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Interactive Matching Module</head><p>Interactions between the context and the response provide useful information for determining the matching degree between them. Unlike previous work <ref type="bibr" target="#b10">[11]</ref>- <ref type="bibr" target="#b12">[13]</ref>, which matched the response to each utterance in the context separately, the U2U-IMN model matches the whole response with the whole context in a global and bidirectional way. Both the context and the response are treated as single word sequences, and attention weights are calculated between every word in the context and every word in the response. Then, the relevance representations are derived along both the context-toresponse and response-to-context directions. This global and bidirectional strategy is expected to help neglect the irrelevant utterances and enrich the relevance representations between the context and the response. Furthermore, considering that the context utterances adjacent to the response may contribute more in response selection than the distant ones, we propose to introduce an exponential prior based on the distance between context and response utterances when calculating the attention weights.</p><p>First, the context representation C = [c 1 , ...,c lc ] is formed by concatenating all context utterance representations { U c m } nc m=1 , where l c = nc m=1 l u c m is the total number of words in the context. Similarly, we obtain R = [r 1 , ...,r lr ] and l r = nr n=1 l u r n for the response. Then, an attention-based alignment is employed to collect relevance information between these two sequences by computing the attention weight between each pair of {c i ,r j } as 1</p><formula xml:id="formula_5">e ij ∝ φ(D i,j ) · exp(c i ·r j ),<label>(6)</label></formula><p>where D i,j is the sentence-level distance between these two words, and φ(D) = e −W D+B is an exponential prior with decay constant W and initial value e B . Here, W and B are model parameters that need to be estimated. Next, the attention weights e ij computed above are used to bidirectionally obtain the local relevance between a context and a response. For a word in the context, its context-toresponse relevance representation carried by the response is composed using e ij aŝ</p><formula xml:id="formula_6">c i = j e ijrj = j Softmax(−W D i,j + B +c i ·r j )r j ,<label>(7)</label></formula><p>where the contents in {r j } lr j=1 relevant toc i are selected to formĉ i . The same calculation is also performed for each word in the response to form the response-to-context representation asr</p><formula xml:id="formula_7">j = i e ijci = i Softmax(−W D i,j + B +c i ·r j )c i .<label>(8)</label></formula><p>For the whole context and the whole response, we have</p><formula xml:id="formula_8">C = {ĉ i } lc i=1 and R = {r j } lr j=1</formula><p>. Following a previous study on interactive matching for NLI <ref type="bibr" target="#b14">[15]</ref>, we compute the differences and the element-wise products between { C, C} and between { R, R}. The differences and the element-wise products are then concatenated with the original vectors to obtain the enhanced representations as follows:</p><formula xml:id="formula_9">C mat = [ C, C, C − C, C C],<label>(9)</label></formula><formula xml:id="formula_10">R mat = [ R, R, R − R, R R].<label>(10)</label></formula><p>Thus far, the relevant information between the context and the response has been collected, which is further converted back to the matching matrices of separated utterances as</p><formula xml:id="formula_11">{U c,mat m } nc m=1 = Separate(C mat ), (11) {U r,mat n } nr n=1 = Separate(R mat ),<label>(12)</label></formula><p>where the Separate operation is conducted by segmenting the whole sequences of relevant information according to utterance length.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Aggregation Module</head><p>The aggregation module converts the matching matrices of separated utterances into a final matching vector. Previous studies <ref type="bibr" target="#b10">[11]</ref>- <ref type="bibr" target="#b12">[13]</ref> adopted the utterance-to-response matching framework and only aggregated the matching matrices of utterances in a context. In contrast, the U2U-IMN model needs to conduct the aggregation operation for both the context and the response.</p><p>First, the matching matrix U c,mat m or U r,mat n for each utterance is processed by a BiLSTM and aggregated by max pooling and last-hidden-state pooling operations. For the matching matrix U c,mat m of each context utterance, the calculations are as follows:</p><formula xml:id="formula_12">u c,utr m,i = BiLSTM(U c,mat m , i), i ∈ {1, ..., l u c m },<label>(13)</label></formula><formula xml:id="formula_13">u c,agr m = [u c,utr m,max ; u c,utr m,l u c m ], m ∈ {1, ..., n c },<label>(14)</label></formula><p>where u c,utr m,max and u c,utr m,l u c m denote the results of max pooling and last-hidden-state pooling for the sequence of u c,utr m,i . The same calculations are also performed for the matching matrix U r,mat n of each response utterance as follows:</p><formula xml:id="formula_14">u r,utr n,j = BiLSTM(U r,mat n , j), j ∈ {1, ..., l u r n },<label>(15)</label></formula><p>u r,agr n = [u r,utr n,max ; u r,utr n,l u r n ], n ∈ {1, ..., n r }.</p><p>The weights for these two BiLSTMs are shared in our implementation. Thus far, we have obtained two sets of utterance embeddings U c,agr = {u c,agr m } nc m=1 and U r,agr = {u r,agr n } nr n=1 for the context and the response, respectively. The next step is to convert them into aggregated context and response embeddings.</p><p>The embedding vector of the context is derived in a way similar to the utterance-level aggregation method mentioned above. The utterance embeddings in U c,agr are sent into another BiLSTM following the chronological order of utterances in the context. Combined max pooling and last-hidden-state pooling operations are also performed to obtain the context embedding vector as</p><formula xml:id="formula_16">u c,ctx m = BiLSTM(U c,agr , m), m ∈ {1, ..., n c },<label>(17)</label></formula><formula xml:id="formula_17">c agr = [u c,ctx max ; u c,ctx nc ].<label>(18)</label></formula><p>For the response, two aggregation strategies are designed in this paper.</p><p>1) RNN Aggregation: This is identical to the context aggregation in which the chronological relationships among utterances in the response are modelled. The operations can be written as</p><formula xml:id="formula_18">u r,res n = BiLSTM(U r,agr , n), n ∈ {1, ..., n r },<label>(19)</label></formula><formula xml:id="formula_19">r agr = [u r,res max ; u r,res nr ].<label>(20)</label></formula><p>2) Attention Aggregation: Different from contexts that usually contain approximately ten utterances, a response is composed of much fewer utterances (see <ref type="figure" target="#fig_2">Fig. 2</ref> in the next section for detailed statistics). We suppose that chronological relationships in short sequences are not as important as those in long sequences. Therefore, attention aggregation is designed to replace the RNN aggregation for deriving the response embedding vector. Mathematically, we have</p><formula xml:id="formula_20">r agr = nr n=1 w nr n u r,agr n ,<label>(21)</label></formula><p>where w nr n denotes softmax-normalized position-dependent utterance weights. During model training, the maximum number of utterances in a response n max r is set manually. For each n r ∈ {1, ..., n max r }, a group of weights {w nr 1 , ..., w nr nr } is estimated with the constraint nr n=1 w nr n = 1. The final matching feature vector is the concatenation of the context embedding vector and the response embedding vector:</p><formula xml:id="formula_21">m = [c agr ; r agr ].<label>(22)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Prediction Module</head><p>The matching feature vector m is then sent into a multi-layer perceptron (MLP) classifier. An MLP is a feedforward neural network estimated in a supervised manner using examples of features together with known labels. Here, the MLP is designed to predict whether a context-response pair matches appropriately according to the matching feature vector m. Finally, the MLP returns a score to denote the degree of matching.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Datasets</head><p>Two English public multi-turn response selection datasets, the Ubuntu Dialogue Corpus V1 <ref type="bibr" target="#b6">[8]</ref> and Ubuntu Dialogue Corpus V2 <ref type="bibr" target="#b9">[10]</ref>, and two Chinese datasets, the Douban Conversation Corpus <ref type="bibr" target="#b10">[11]</ref> and E-commerce Dialogue Corpus <ref type="bibr" target="#b12">[13]</ref>, were adopted to evaluate our proposed methods. In our experiments, we followed the splits of training, validation, and test sets provided by the original authors of the four datasets. The Ubuntu Dialogue Corpus V1 and V2 contain multi-turn dialogues about Ubuntu system troubleshooting in English. Here, we adopted the version of the Ubuntu Dialogue Corpus V1 shared by Xu et al. <ref type="bibr" target="#b25">[26]</ref>, in which numbers, paths and URLs were replaced by placeholders. Compared with the Ubuntu Dialogue Corpus V1, the training, validation and test dialogues in the V2 dataset were generated in different periods without overlap. Moreover, the V2 dataset discriminated between the end of an utterance ( eou ) and the end of a turn ( eot ). In both of the Ubuntu corpora, the positive responses are true responses from humans, and the negative responses are randomly sampled. The Douban Conversation Corpus was crawled from a Chinese social network on open-domain topics. It was constructed in a similar way to the Ubuntu corpus. The Douban Conversation Corpus collected responses via a small inverted-index system, and labels were manually annotated. The E-commerce Dialogue Corpus collected realworld conversations between customers and customer service staff from the largest e-commerce platform in China. Some statistics of these datasets are provided in <ref type="table" target="#tab_1">Table II</ref>.</p><p>It is worth noting that the Ubuntu Dialogue Corpus V2 was the only dataset in our experiments that explicitly segmented utterances in responses. Specifically, approximately 30% of the responses in this dataset consisted of multiple utterances, as shown in <ref type="figure" target="#fig_2">Fig. 2</ref>, which made this dataset a very suitable one for evaluating our proposed U2U matching framework. The U2U-IMN model can also be applied to the other three datasets by considering a whole response as a single utterance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Evaluation Metrics</head><p>The evaluation metrics used in previous work <ref type="bibr" target="#b6">[8]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b12">[13]</ref> were adopted in our experiments. Each model was tasked with selecting the k best-matched responses from n available candidates for the given conversation context c. We calculated the recall of the true positive replies among the k selected responses, denoted R n @k, as the main evaluation metric. The mean average precision (MAP) <ref type="bibr" target="#b26">[27]</ref> was also adopted for reference since previous work did not list their results in terms of MAP on the Ubuntu V1, Ubuntu V2 and E-commerce datasets. In addition to R n @k and MAP, we also adopted the mean reciprocal rank (MRR) <ref type="bibr" target="#b27">[28]</ref> and precisionat-one (P@1) metrics for the Douban corpus, following the settings of previous work <ref type="bibr" target="#b10">[11]</ref>. The reason was that the Douban Conversation Corpus was different from the other three datasets in that it included multiple correct candidates for a context in the test set, which may lead to low R n @k.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Training Details</head><p>The Adam method <ref type="bibr" target="#b36">[36]</ref> was employed for optimization, with a batch size of 128. The initial learning rate was 0.001 and was exponentially decayed by 0.96 every 5000 steps. Dropout <ref type="bibr" target="#b37">[37]</ref> with a rate of 0.2 was applied to the word embeddings and all hidden layers.</p><p>The word representations for the English datasets were concatenations of the 300-dimensional GloVe embeddings <ref type="bibr" target="#b38">[38]</ref>, the 100-dimensional embeddings estimated on the training set using the Word2Vec algorithm <ref type="bibr" target="#b39">[39]</ref> and the 150-dimensional character-level embeddings with window sizes of {3, 4, 5}, each consisting of 50 filters. The word embeddings for the Chinese datasets were concatenations of the 200-dimensional embeddings from previous work <ref type="bibr" target="#b40">[40]</ref> and the 200-dimensional embeddings estimated on the training set using the Word2Vec algorithm. Character-level embeddings were not employed for the two Chinese datasets due to the large number of Chinese characters. The word embeddings were not updated during training.</p><p>All hidden states of LSTMs had 200 dimensions. The MLP of the prediction module had a hidden unit size of   <ref type="bibr" target="#b41">[41]</ref> activation. The maximum word length, the maximum utterance length, the maximum number of utterances in a context, and the maximum number of utterances in a response were set as 18, 50, 10 and 3 respectively. We padded with zeros if the number of utterances in a context was less than 10 and the number of utterances in a response was less than 3. Otherwise, the last 10 utterances in the context or the last 3 utterances in the response were kept. The development set was used to select the best model for testing. All codes were implemented in the TensorFlow framework <ref type="bibr" target="#b42">[42]</ref> and have been published to help replicate our results 2 . <ref type="table" target="#tab_1">Table III and Table IV</ref> present the evaluation results of U2U-IMN and previous methods 3 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Experimental Results</head><p>All the results except ours are copied from the existing literature. For each dataset, all results listed in <ref type="table" target="#tab_1">Table III or  Table IV</ref> are comparable with each other since they used the same training, validation and test data. Here, the U2U-IMN models adopted the attention aggregation strategy introduced in Section III-E. It can be observed from these two tables that U2U-IMN outperformed the other models on all metrics and datasets, which demonstrates its ability to select the correct response and its compatibility across domains (e.g., the domains of system troubleshooting, social networks and e-commerce covered by these datasets).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. ANALYSIS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Effectiveness of U2U matching</head><p>To further verify the effectiveness of our proposed U2U matching framework, we split the test set of the Ubuntu Dialogue Corpus V2 dataset according to the number of utterances in their correct responses. Then, the performances on these subsets of the U2U-IMN model were compared with those of the model (denoted U2R-IMN) that considered each response as a single utterance, as shown in <ref type="table" target="#tab_5">Table V</ref>. As demonstrated, the U2U framework can help improve the performance by exploiting the relationships among the utterances in a response. We can see that the advantage of the U2U-IMN model over the U2R-IMN model became larger when the correct responses were composed of more utterances. This was consistent with the motivation of the U2U matching framework. Considering that only 30% of responses in the Ubuntu Dialogue Corpus V2 dataset consisted of multiple utterances, a larger overall improvement may be achieved when applying our proposed U2U models to datasets containing more responses with multiple utterances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Response aggregation strategies</head><p>One key characteristic of the U2U matching framework is the response aggregation step that generates a single embedding vector based on the embedding vectors of response utterances. <ref type="table" target="#tab_1">Table VI</ref> shows the evaluation results of the two response aggregation strategies introduced in Section III-E, where the RNN suffix indicates the U2U-IMN model using the RNN aggregation strategy instead of the attention aggregation. We can see than the U2U-IMN model with the default attention strategy for response aggregation achieved slightly better performance than that with RNN aggregation, which supported our assumption that the chronological relationships among utterances in short sequences may not be essential in the aggregation module. Some further analysis on these two aggregation strategies are given in the following.  eou ; U 3 : i don't know how to do it though :-lrb-eou }, and U 1 was the most informative one. From <ref type="figure">Fig.3</ref>, we can see that the input gates had larger values for U 1 than for the other two utterances. This means that more information from this utterance was preserved when aggregating the three utterances to form the embedding vector of the whole response.</p><p>2) Attention Aggregation: The maximum number of utterances in a response, i.e., n max r in Section III-E, was tuned on the validation set, and the optimal one for the U2U-IMN model was n max r = 3, as shown in <ref type="figure" target="#fig_4">Fig. 4</ref>. The estimated attention weights w nr n of the U2U-IMN model with n max r = 3 are shown in <ref type="table" target="#tab_1">Table VII</ref>. We can see that when n r &gt; 1, each utterance in the response contributed to forming the final response embeddings, and the first utterance contributed more than the last one. As we can see from the first row of <ref type="table" target="#tab_1">Table VII</ref> and Eq. (21), if there was only one utterance in a response, then the U2U-IMN model degenerated to follow the conventional utterance-to-response matching framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Bidirectional and global interactive matching</head><p>The bidirectional and global interactive matching between the context and the response in the U2U-IMN model is expected to help collect matching information and make matching decisions. Ablation tests and visualizations of attention weights were performed to demonstrate the effectiveness of both the bidirectional matching and the global matching.</p><p>1) Bidirectional Matching: The bidirectional context-toresponse and response-to-context representations in the U2U-IMN model were ablated. Specifically, when the context-toresponse representation was ablated, the context representation given by the sentence encoding module { U c m } nc m=1 was sent to  <ref type="table" target="#tab_1">Table VIII</ref>. We can see that ablation of either the context-to-response or response-tocontext representations resulted in a performance degradation, which indicates the effectiveness of the bidirectional matching between contexts and responses in the interactive matching module. A serious performance degradation can be observed when ablating the matching representations of both directions.</p><p>A case study was further conducted by visualizing the bidirectional context-to-response and response-to-context attention weights for a test sample of the Ubuntu Dialogue Corpus V2. The context of the sample contained three utterances:  <ref type="figure" target="#fig_5">Fig. 5</ref>. We can see that some important words, such as "connect", "router" and "ethernet", in the context selected the relevant words in the response, and some unimportant words, such as "grateful", "help"   between each utterance in the context and each utterance in the response. Thus, we obtained a set of matching representations for each utterance in the context and each utterance in the response. Then, an additional pooling operation was performed over the set of representations to obtain the final matching representation for each utterance in the context and each utterance in the response. The pooling outputs were sent into the aggregation module for the following procedures. The results of the ablation test are shown in <ref type="table" target="#tab_1">Table IX</ref>, and the performance degradation demonstrated the superiority of our proposed global context-response matching to the local utterance-utterance matching in the interactive matching module.</p><formula xml:id="formula_22">•</formula><p>Furthermore, a case study was conducted by visualizing the context-to-utterance and response-to-utterance attention weights. The sample was the same as that used in <ref type="figure" target="#fig_5">Fig. 5</ref>. The results are shown in <ref type="figure">Fig. 6</ref> and <ref type="figure">Fig. 7</ref>, where the interactive matching was performed between the whole context and separated response utterances or between the whole response and separated context utterances. Comparing <ref type="figure" target="#fig_5">Fig. 5 (a)</ref> with <ref type="figure">Fig. 6 (b)</ref>, we can see that the second response utterance "I have to go now. I am grateful for your help eou " was less informative and occupies small weights in our proposed global context-response matching but occupies large weights in the context-to-utterance manner. The small weights of less informative utterances can help filter out irrelevant information in responses for deriving context representations. Similarly, comparing <ref type="figure" target="#fig_5">Fig. 5 (b)</ref> with <ref type="figure">Fig. 7 (a)</ref>, we can find the same phenomenon for the first context utterance "Have you tried using different channels eou eot ?". These results verified the effectiveness of the global context-response interactive matching in our proposed U2U-IMN model. The exponential prior based on sentence-level distances in Eq. (6) of the interactive matching module was ablated, and the results on the test set of the four datasets are shown in <ref type="table" target="#tab_10">Table X</ref>. We can see that the performance decreased on most metrics. Meanwhile, we can see that this distance-based prior provided larger improvements on the two Chinese datasets than on the two English datasets. The estimated prior function Φ(D) = e −0.536D−0.00001 in Eq. <ref type="bibr" target="#b5">(7)</ref> for the E-commerce Corpus is drawn in <ref type="figure" target="#fig_6">Fig. 8</ref>. We can see that larger weights were assigned to the utterances closer to the response.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Distance-based prior for interactive matching</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>In this paper, we propose an utterance-to-utterance interactive matching network (U2U-IMN) for the multi-turn response selection task. Our proposed model first attempts to simultaneously explore the relationships among utterances in a context and those in a response. Then, U2U-IMN explores the matching information between contexts and responses through the global and bidirectional interactions between them. Meanwhile, distances are introduced into the interactions to distinguish the semantic contributions of utterances in a context according to their distances to the response. Experimental results show that our proposed model outperforms the baseline models on all metrics, achieving a new state-of-the-art performance and demonstrating compatibility across domains for multi-turn response selection in retrieval-based chatbots. Our future work includes (1) improving this proposed method to integrate more information, such as persona descriptions, for response selection, (2) applying the U2U framework to other matching scenes to further verify its effectiveness, and (3) employing pretrained models as effective resources for multi-turn response selection.</p><p>Quan Liu received a B.E. degree in electronic information engineering from Hohai University, Nanjing, China, in 2012, and a Ph.D. degree in signal and information processing from the University of Science and Technology of China, Hefei, China, in 2017. He is currently a postdoctoral researcher with University of Science and Technology of China, and iFLYTEK CO., LTD., Hefei, China. His research interests include machine learning for natural language processing.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>U c m = {u c m,i } l u c m i=1 and U r n = {u r n,j } l u r n j=1 , respectively, where l u c m and l u r n are utterance lengths. Each u c m,i or u r n,j ∈ R d is an embedding vector of d dimensions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>The overall architecture of our proposed U2U-IMN model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Distribution of responses in the Ubuntu Dialogue Corpus V2 across the number of utterances in a response.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>1 )Fig. 3 .</head><label>13</label><figDesc>RNN Aggregation: To investigate how RNN aggregation identifies important utterances in a response, the input gate values of the LSTM in Eq. (19) for a response example were visualized, as shown in Fig.3. The response was composed of three utterances, {U 1 : not as vboxnet0 though, windows names them local area connection # 1,2,3 ... eou ; U 2 : exactly! The input gate values of the LSTM in Eq. (19) of the U2U-IMN model for a response example in the test set of the Ubuntu Dialogue Corpus V2. The darker units correspond to larger values.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>R 10 @1 of U2U-IMN models with different n max r tuned on the validation set of the Ubuntu Dialogue Corpus V2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Visualizations of the (a) context-to-response and (b) response-tocontext attention weights in the interactive matching module for a test sample of the Ubuntu Dialogue Corpus V2. The darker units correspond to larger values.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 8 .</head><label>8</label><figDesc>The estimated prior function Φ(D) = e −0.536D−0.00001 in Eq.<ref type="bibr" target="#b5">(7)</ref> for the E-commerce Corpus.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>and Z.-H. Ling are with the National Engineering Laboratory for Speech and Language Information Processing, University of Science and Technology of China, Hefei 230027, China (e-mail: gujc@mail.ustc.edu.cn; zhling@ustc.edu.cn). Q. Liu is with the State Key Laboratory of Cognitive Intelligence, iFLYTEK Company, Ltd., Hefei 230088, China (e-mail: quanliu@iflytek.com).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I AN</head><label>I</label><figDesc>EXAMPLE OF A CONVERSATION IN THE UBUNTU V2 DATASET WHOSE RESPONSE IS COMPOSED OF MULTIPLE UTTERANCES. " EOU " DENOTES END-OF-UTTERANCE, AND " EOT " DENOTES END-OF-TURN.</figDesc><table /><note>Conversation Speaker A: How do I put myself in desktop in CUI? eou Speaker A: I mean CLI. eou eot Speaker B: cd˜/ desktop. eou eot Speaker A: Is that the right code? cd / desktop? eou eot Response Candidates Speaker B: No. read it again. eou Are you root? eou That's why new Ubuntu man's method will work for you. eou " Speaker B: sebdc is talking nonsense. eou You do not need cpufreqd. eou %</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE II STATISTICS</head><label>II</label><figDesc>OF THE DATASETS FOR EVALUATING OUR PROPOSED METHODS.</figDesc><table><row><cell>Dataset</cell><cell cols="2">Ubuntu V1 Train Valid</cell><cell>Test</cell><cell cols="2">Ubuntu V2 Train Valid</cell><cell>Test</cell><cell cols="2">Douban Train Valid</cell><cell>Test</cell><cell cols="3">E-commerce Train Valid Test</cell></row><row><cell>pairs</cell><cell>1M</cell><cell cols="2">0.5M 0.5M</cell><cell>1M</cell><cell>195k</cell><cell>189k</cell><cell>1M</cell><cell>50k</cell><cell>10k</cell><cell>1M</cell><cell>10k</cell><cell>10k</cell></row><row><cell>positive:negative</cell><cell>1: 1</cell><cell>1: 9</cell><cell>1: 9</cell><cell>1: 1</cell><cell>1: 9</cell><cell>1: 9</cell><cell>1: 1</cell><cell>1: 1</cell><cell>1: 9</cell><cell>1: 1</cell><cell>1: 1</cell><cell>1: 9</cell></row><row><cell>positive/context</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1.18</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>turns/context</cell><cell>8.44</cell><cell>2.66</cell><cell>2.65</cell><cell>6.29</cell><cell>5.86</cell><cell>6.03</cell><cell>6.69</cell><cell>6.75</cell><cell>5.95</cell><cell>5.51</cell><cell>5.48</cell><cell>5.64</cell></row><row><cell>words/utterance</cell><cell cols="9">20.38 21.16 21.17 14.06 15.28 15.28 18.56 18.50 20.74</cell><cell>7.02</cell><cell>6.99</cell><cell>7.11</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE III EVALUATION</head><label>III</label><figDesc>RESULTS OF U2U-IMN AND PREVIOUS METHODS ON THE UBUNTU DIALOGUE CORPUS V1 AND V2.</figDesc><table><row><cell></cell><cell></cell><cell cols="3">Ubuntu Corpus V1</cell><cell></cell><cell></cell><cell cols="3">Ubuntu Corpus V2</cell><cell></cell></row><row><cell></cell><cell cols="10">MAP R2@1 R10@1 R10@2 R10@5 MAP R2@1 R10@1 R10@2 R10@5</cell></row><row><cell>TF-IDF [8], [10]</cell><cell>-</cell><cell>0.659</cell><cell>0.410</cell><cell>0.545</cell><cell>0.708</cell><cell>-</cell><cell>0.749</cell><cell>0.488</cell><cell>0.587</cell><cell>0.763</cell></row><row><cell>RNN [8], [10]</cell><cell>-</cell><cell>0.768</cell><cell>0.403</cell><cell>0.547</cell><cell>0.819</cell><cell>-</cell><cell>0.777</cell><cell>0.379</cell><cell>0.561</cell><cell>0.836</cell></row><row><cell>LSTM [8], [10]</cell><cell>-</cell><cell>0.878</cell><cell>0.604</cell><cell>0.745</cell><cell>0.926</cell><cell>-</cell><cell>0.869</cell><cell>0.552</cell><cell>0.721</cell><cell>0.924</cell></row><row><cell>DL2R [29]</cell><cell>-</cell><cell>0.899</cell><cell>0.626</cell><cell>0.783</cell><cell>0.944</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Match-LSTM [30]</cell><cell>-</cell><cell>0.904</cell><cell>0.653</cell><cell>0.799</cell><cell>0.944</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>MV-LSTM [31]</cell><cell>-</cell><cell>0.906</cell><cell>0.653</cell><cell>0.804</cell><cell>0.946</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Multi-View [20]</cell><cell>-</cell><cell>0.908</cell><cell>0.662</cell><cell>0.801</cell><cell>0.951</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>RNN-CNN [32]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.911</cell><cell>0.672</cell><cell>0.809</cell><cell>0.956</cell></row><row><cell>CompAgg [33]</cell><cell>-</cell><cell>0.884</cell><cell>0.631</cell><cell>0.753</cell><cell>0.927</cell><cell>-</cell><cell>0.895</cell><cell>0.641</cell><cell>0.776</cell><cell>0.937</cell></row><row><cell>BiMPM [34]</cell><cell>-</cell><cell>0.897</cell><cell>0.665</cell><cell>0.786</cell><cell>0.938</cell><cell>-</cell><cell>0.877</cell><cell>0.611</cell><cell>0.747</cell><cell>0.921</cell></row><row><cell>HRDE-LTC [35]</cell><cell>-</cell><cell>0.916</cell><cell>0.684</cell><cell>0.822</cell><cell>0.960</cell><cell>-</cell><cell>0.915</cell><cell>0.652</cell><cell>0.815</cell><cell>0.966</cell></row><row><cell>SMN [11]</cell><cell>-</cell><cell>0.926</cell><cell>0.726</cell><cell>0.847</cell><cell>0.961</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>DUA [13]</cell><cell>-</cell><cell>-</cell><cell>0.752</cell><cell>0.868</cell><cell>0.962</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>DAM [12]</cell><cell>-</cell><cell>0.938</cell><cell>0.767</cell><cell>0.874</cell><cell>0.969</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>U2U-IMN</cell><cell cols="2">0.866 0.945</cell><cell>0.790</cell><cell>0.886</cell><cell>0.973</cell><cell cols="2">0.852 0.943</cell><cell>0.762</cell><cell>0.877</cell><cell>0.975</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE IV EVALUATION</head><label>IV</label><figDesc>RESULTS OF U2U-IMN AND PREVIOUS METHODS ON THE DOUBAN CONVERSATION CORPUS AND THE E-COMMERCE CORPUS. ALL THE RESULTS EXCEPT OURS ARE COPIED FROM<ref type="bibr" target="#b10">[11]</ref>-<ref type="bibr" target="#b12">[13]</ref>.</figDesc><table><row><cell></cell><cell cols="3">Douban Conversation Corpus</cell><cell></cell><cell></cell><cell cols="2">E-commerce Corpus</cell><cell></cell></row><row><cell></cell><cell cols="8">MAP MRR P@1 R10@1 R10@2 R10@5 MAP R10@1 R10@2 R10@5</cell></row><row><cell>TF-IDF</cell><cell>0.331 0.359 0.180</cell><cell>0.096</cell><cell>0.172</cell><cell>0.405</cell><cell>-</cell><cell>0.159</cell><cell>0.256</cell><cell>0.477</cell></row><row><cell>RNN</cell><cell>0.390 0.422 0.208</cell><cell>0.118</cell><cell>0.223</cell><cell>0.589</cell><cell>-</cell><cell>0.325</cell><cell>0.463</cell><cell>0.775</cell></row><row><cell>LSTM</cell><cell>0.485 0.527 0.320</cell><cell>0.187</cell><cell>0.343</cell><cell>0.720</cell><cell>-</cell><cell>0.365</cell><cell>0.536</cell><cell>0.828</cell></row><row><cell>Multi-View</cell><cell>0.505 0.543 0.342</cell><cell>0.202</cell><cell>0.350</cell><cell>0.729</cell><cell>-</cell><cell>0.421</cell><cell>0.601</cell><cell>0.861</cell></row><row><cell>DL2R</cell><cell>0.488 0.527 0.330</cell><cell>0.193</cell><cell>0.342</cell><cell>0.705</cell><cell>-</cell><cell>0.399</cell><cell>0.571</cell><cell>0.842</cell></row><row><cell>MV-LSTM</cell><cell>0.498 0.538 0.348</cell><cell>0.202</cell><cell>0.351</cell><cell>0.710</cell><cell>-</cell><cell>0.412</cell><cell>0.591</cell><cell>0.857</cell></row><row><cell cols="2">Match-LSTM 0.500 0.537 0.345</cell><cell>0.202</cell><cell>0.348</cell><cell>0.720</cell><cell>-</cell><cell>0.410</cell><cell>0.590</cell><cell>0.858</cell></row><row><cell>SMN</cell><cell>0.529 0.569 0.397</cell><cell>0.233</cell><cell>0.396</cell><cell>0.724</cell><cell>-</cell><cell>0.453</cell><cell>0.654</cell><cell>0.886</cell></row><row><cell>DUA</cell><cell>0.551 0.599 0.421</cell><cell>0.243</cell><cell>0.421</cell><cell>0.780</cell><cell>-</cell><cell>0.501</cell><cell>0.700</cell><cell>0.921</cell></row><row><cell>DAM</cell><cell>0.550 0.601 0.427</cell><cell>0.254</cell><cell>0.410</cell><cell>0.757</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>U2U-IMN</cell><cell>0.564 0.611 0.429</cell><cell>0.259</cell><cell>0.430</cell><cell>0.791</cell><cell>0.759</cell><cell>0.616</cell><cell>0.806</cell><cell>0.966</cell></row><row><cell>256 with ReLU</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE V COMPARISONS</head><label>V</label><figDesc>BETWEEN U2R-IMN AND U2U-IMN MODELS ON SEVERAL SUBSETS OF THE TEST SET OF THE UBUNTU DIALOGUE CORPUS V2. U2R-IMN DENOTES THE MODEL WITH CONCATENATION OF THE UTTERANCES IN A RESPONSE. IN EACH SUBSET, THE CORRECT RESPONSES ARE COMPOSED OF 1, 2, OR 3 UTTERANCES.</figDesc><table><row><cell>Model</cell><cell cols="5">Subset R2@1 R10@1 R10@2 R10@5</cell></row><row><cell>U2R-IMN</cell><cell>1 utt.</cell><cell>0.936</cell><cell>0.733</cell><cell>0.863</cell><cell>0.974</cell></row><row><cell>U2U-IMN</cell><cell>1 utt.</cell><cell>0.937</cell><cell>0.737</cell><cell>0.863</cell><cell>0.972</cell></row><row><cell>U2R-IMN</cell><cell>2 utt.</cell><cell>0.952</cell><cell>0.823</cell><cell>0.904</cell><cell>0.979</cell></row><row><cell>U2U-IMN</cell><cell>2 utt.</cell><cell>0.956</cell><cell>0.831</cell><cell>0.911</cell><cell>0.984</cell></row><row><cell>U2R-IMN</cell><cell>3 utt.</cell><cell>0.965</cell><cell>0.873</cell><cell>0.923</cell><cell>0.982</cell></row><row><cell>U2U-IMN</cell><cell>3 utt.</cell><cell>0.976</cell><cell>0.904</cell><cell>0.955</cell><cell>0.994</cell></row><row><cell></cell><cell></cell><cell cols="2">TABLE VI</cell><cell></cell><cell></cell></row><row><cell cols="6">EVALUATION RESULTS OF OUR PROPOSED U2U MATCHING FRAMEWORK</cell></row><row><cell cols="6">ON THE TEST SET OF THE UBUNTU DIALOGUE CORPUS V2. THE RNN</cell></row><row><cell cols="6">SUFFIX OF THE U2U MODEL DENOTES REPLACING THE ATTENTION</cell></row><row><cell cols="6">AGGREGATION WITH THE RNN AGGREGATION IN THE AGGREGATION</cell></row><row><cell></cell><cell></cell><cell cols="2">MODULE.</cell><cell></cell><cell></cell></row><row><cell>Model</cell><cell></cell><cell cols="4">R2@1 R10@1 R10@2 R10@5</cell></row><row><cell>U2U-IMN</cell><cell></cell><cell>0.943</cell><cell>0.762</cell><cell>0.877</cell><cell>0.975</cell></row><row><cell cols="2">U2U-IMNRNN</cell><cell>0.942</cell><cell>0.758</cell><cell>0.875</cell><cell>0.974</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE VII ATTENTION</head><label>VII</label><figDesc>WEIGHTS w nr n OF THE U2U-IMN MODEL WITH n max r = 3 ESTIMATED ON THE TRAINING SET OF THE UBUNTU DIALOGUE CORPUS V2.</figDesc><table><row><cell cols="2">nr</cell><cell>w nr 1</cell><cell>w nr 2</cell><cell>w nr 3</cell></row><row><cell>1</cell><cell></cell><cell>1.0</cell><cell>-</cell><cell>-</cell></row><row><cell>2</cell><cell></cell><cell cols="2">0.5986 0.4014</cell><cell>-</cell></row><row><cell>3</cell><cell></cell><cell cols="3">0.4495 0.3014 0.2491</cell></row><row><cell></cell><cell></cell><cell cols="2">TABLE VIII</cell><cell></cell></row><row><cell cols="6">ABLATION TESTS OF THE CONTEXT-TO-RESPONSE (C2R) AND</cell></row><row><cell cols="6">RESPONSE-TO-CONTEXT (R2C) REPRESENTATIONS IN THE U2U-IMN</cell></row><row><cell cols="5">MODEL ON THE FOUR DATASETS.</cell></row><row><cell>Dataset</cell><cell></cell><cell>Model</cell><cell cols="3">R10@1 R10@2 R10@5</cell></row><row><cell cols="3">U2U-IMN</cell><cell>0.790</cell><cell>0.886</cell><cell>0.973</cell></row><row><cell>Ubuntu V1</cell><cell cols="2">-C2R -R2C</cell><cell>0.774 0.780</cell><cell>0.876 0.880</cell><cell>0.968 0.971</cell></row><row><cell></cell><cell cols="2">-C2R&amp;R2C</cell><cell>0.650</cell><cell>0.806</cell><cell>0.954</cell></row><row><cell cols="3">U2U-IMN</cell><cell>0.762</cell><cell>0.877</cell><cell>0.975</cell></row><row><cell>Ubuntu V2</cell><cell cols="2">-C2R -R2C</cell><cell>0.738 0.749</cell><cell>0.866 0.871</cell><cell>0.972 0.972</cell></row><row><cell></cell><cell cols="2">-C2R&amp;R2C</cell><cell>0.608</cell><cell>0.786</cell><cell>0.956</cell></row><row><cell cols="3">U2U-IMN</cell><cell>0.259</cell><cell>0.430</cell><cell>0.791</cell></row><row><cell>Douban</cell><cell cols="2">-C2R -R2C</cell><cell>0.251 0.250</cell><cell>0.424 0.429</cell><cell>0.784 0.785</cell></row><row><cell></cell><cell cols="2">-C2R&amp;R2C</cell><cell>0.188</cell><cell>0.352</cell><cell>0.744</cell></row><row><cell cols="3">U2U-IMN</cell><cell>0.616</cell><cell>0.806</cell><cell>0.966</cell></row><row><cell>E-commerce</cell><cell cols="2">-C2R -R2C</cell><cell>0.575 0.567</cell><cell>0.774 0.766</cell><cell>0.957 0.961</cell></row><row><cell></cell><cell cols="2">-C2R&amp;R2C</cell><cell>0.538</cell><cell>0.751</cell><cell>0.938</cell></row><row><cell cols="6">the aggregation module directly, and only the response repre-sentation { U r n } nr n=1 was enhanced by the interactive matching module to obtain {U r,mat n } nr n=1 before aggregation. Similar</cell></row><row><cell cols="6">operations were conducted to ablate the response-to-context</cell></row><row><cell cols="4">representation. The results are shown in</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>Have you tried using different channels ? eou eot • No, how do I do that ? eou eot • Can you connect to router via ethernet cable and check the settings ? eou eotThe response was composed of two utterances:</figDesc><table /><note>• I can connect to the router via ethernet, yes What settings should I check ? eou• I have to go now. I am grateful for your help eou The results are shown in</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>TABLE IX ABLATION</head><label>IX</label><figDesc>To demonstrate the superiority of the global context-response matching used by the U2U-IMN model, an ablation test was conducted by replacing it with local utterance-utterance matching. In the ablated model, the interactions introduced in Section III-D were performed Visualizations of attention weights between the context and each response utterance in the interactive matching module for a test sample of the Ubuntu Dialogue Corpus V2. The darker units correspond to larger values. Visualizations of attention weights between the response and each context utterance in the interactive matching module for a test sample of the Ubuntu Dialogue Corpus V2. The darker units correspond to larger values.</figDesc><table><row><cell>TESTS OF REPLACING THE GLOBAL CONTEXT-RESPONSE MATCHING WITH LOCAL UTTERANCE-UTTERANCE MATCHING ON THE FOUR DATASETS. Dataset Model R10@1 R10@2 R10@5 Ubuntu V1 U2U-IMN 0.790 0.886 0.973 -Global 0.786 0.885 0.972 Ubuntu V2 U2U-IMN 0.762 0.877 0.975 -Global 0.754 0.873 0.975 Douban U2U-IMN 0.259 0.430 0.791 -Global 0.254 0.424 0.785 E-commerce U2U-IMN 0.616 0.806 0.966 -Global 0.586 0.792 0.961 and "the", in the response occupied small weights when forming the context-to-response representations. Identically, some important words in the response also selected the relevant words in the context, and some unimportant words in the context were also neglected when forming the response-to-context representations. 2) Global Matching: Have you tried using different channels __eou__ __eot__ ? No , how do I do that ? __eou__ __eot__ Can you connect to router via ethernet cable and check the settings ? __eou__ __eot__ context I can connect to the router via ethernet , yes . What settings should I check ? __eou__ response (a) Context to first response utterance Have you tried using different channels __eou__ __eot__ ? No , how do I do that ? __eou__ __eot__ Can you connect to router via ethernet cable and check the settings ? __eou__ __eot__ context I have to go now . I am grateful for your help __eou__ response (b) Context to second response utterance Fig. 6. Have you tried using different channels __eou__ __eot__ ? context I can connect to the router via ethernet , yes . What settings should I check ? __eou__ I have to go now . I am grateful for your help __eou__ response (a) Response to 1st context utterance No , how do I do that ? __eou__ __eot__ context I can connect to the router via ethernet , yes . What settings should I check ? __eou__ I have to go now . I am grateful for your help __eou__ response (b) Response to 2nd context utterance Can you connect to router via ethernet cable and check the settings ? __eou__ __eot__ context I can connect to the router via ethernet , yes . What settings should I check ? __eou__ I have to go now . I am grateful for your help __eou__ response (c) Response to 3rd context utterance Fig. 7.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>TABLE X ABLATION</head><label>X</label><figDesc>TESTS OF THE DISTANCE-BASED PRIOR FOR INTERACTIVE MATCHING ON THE FOUR DATASETS.</figDesc><table><row><cell>Dataset</cell><cell>Model</cell><cell cols="3">R10@1 R10@2 R10@5</cell></row><row><cell>Ubuntu V1</cell><cell>U2U-IMN -Prior</cell><cell>0.790 0.787</cell><cell>0.886 0.884</cell><cell>0.973 0.973</cell></row><row><cell>Ubuntu V2</cell><cell>U2U-IMN -Prior</cell><cell>0.762 0.761</cell><cell>0.877 0.874</cell><cell>0.975 0.976</cell></row><row><cell>Douban</cell><cell>U2U-IMN -Prior</cell><cell>0.259 0.251</cell><cell>0.430 0.431</cell><cell>0.791 0.782</cell></row><row><cell>E-commerce</cell><cell>U2U-IMN -Prior</cell><cell>0.616 0.600</cell><cell>0.806 0.795</cell><cell>0.966 0.968</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Actually, the attention weights for context-to-response alignment and response-to-context alignment are different because of different normalization terms. Here, we use the same symbol e ij , and the normalization term is not shown in Eq. (6) for simplification.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://github.com/JasonForJoy/U2U-IMN<ref type="bibr" target="#b2">3</ref> In our previous conference paper, IMN employed an attentive hierarchical recurrent encoder (AHRE) as its sentence encoder, which aggregated multilayer RNNs through attentive pooling. However, since the sentence encoder is not the key point of this paper, we replaced AHRE with a single-layer RNN for sentence encoding in U2U-IMN in order to simplify the model structure and focus on how to perform interactions between contexts and responses.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Interactive matching network for multi-turn response selection in retrieval-based chatbots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-C</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-H</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">http:/doi.acm.org/10.1145/3357384.3358140</idno>
		<ptr target="http://doi.acm.org/10.1145/3357384.3358140" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM International Conference on Information and Knowledge Management, ser. CIKM &apos;19</title>
		<meeting>the 28th ACM International Conference on Information and Knowledge Management, ser. CIKM &apos;19</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2321" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A survey on dialogue systems: Recent advances and new frontiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<idno type="DOI">10.1145/3166054.3166058</idno>
		<ptr target="https://doi.org/10.1145/3166054.3166058" />
	</analytic>
	<monogr>
		<title level="j">SIGKDD Explorations</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="25" to="35" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Augmenting end-to-end dialogue systems with commonsense knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Chaturvedi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Biswas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
		<ptr target="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16573" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18)</title>
		<meeting>the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18)<address><addrLine>New Orleans, Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4970" to="4977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Building sequential inference models for end-to-end response selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<idno>abs/1812.00686</idno>
		<ptr target="http://arxiv.org/abs/1812.00686" />
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Building end-to-end dialogue systems using generative hierarchical neural network models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">V</forename><surname>Li ; I</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sordoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pineau</surname></persName>
		</author>
		<ptr target="http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/11957" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing<address><addrLine>Beijing, China; Phoenix, Arizona, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2015-02-12" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3776" to="3784" />
		</imprint>
	</monogr>
	<note>Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Neural personalized response generation as domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11280-018-0598-6</idno>
		<ptr target="https://doi.org/10.1007/s11280-018-0598-6" />
	</analytic>
	<monogr>
		<title level="j">World Wide Web</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1427" to="1446" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Pow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue</title>
		<meeting><address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-09-04" />
			<biblScope unit="page" from="285" to="294" />
		</imprint>
	</monogr>
	<note>Proceedings of the SIGDIAL 2015 Conference</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<ptr target="http://aclweb.org/anthology/W/W15/W15-4640.pdf" />
		<title level="m">Available</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Improved deep learning baselines for ubuntu corpus dialogs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kadlec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kleindienst</surname></persName>
		</author>
		<idno>abs/1510.03753</idno>
		<ptr target="http://arxiv.org/abs/1510.03753" />
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Training end-to-end dialogue systems with the ubuntu dialogue corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Pow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">V</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pineau</surname></persName>
		</author>
		<ptr target="http://dad.uni-bielefeld.de/index.php/dad/article/view/3698" />
	</analytic>
	<monogr>
		<title level="j">D&amp;D</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="31" to="65" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Sequential matching network: A new architecture for multi-turn response selection in retrieval-based chatbots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1046</idno>
		<ptr target="https://doi.org/10.18653/v1/P17-1046" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017-07-30" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="496" to="505" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multi-turn response selection for chatbots with deep attention matching network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-07-15" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1118" to="1127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Modeling multi-turn conversation with deep utterance aggregation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="https://aclanthology.info/papers/C18-1317/c18-1317" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics, COLING 2018</title>
		<meeting>the 27th International Conference on Computational Linguistics, COLING 2018<address><addrLine>Santa Fe, New Mexico, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3740" to="3752" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Dually interactive matching network for personalized response selection in retrieval-based chatbots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-C</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-H</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/D19-1193" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-11" />
			<biblScope unit="page" from="1845" to="1854" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Enhanced LSTM for natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Inkpen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1152</idno>
		<ptr target="https://doi.org/10.18653/v1/P17-1152" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017-07-30" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1657" to="1668" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Retrieval-enhanced adversarial training for neural response generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/P19-1366/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019</title>
		<meeting>the 57th Conference of the Association for Computational Linguistics, ACL 2019<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-08-02" />
			<biblScope unit="page" from="3763" to="3773" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Exploiting persona information for diverse generation of conversational responses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2019/721</idno>
		<ptr target="https://doi.org/10.24963/ijcai.2019/721" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI 2019</title>
		<meeting>the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI 2019<address><addrLine>Macao, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5190" to="5196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A dataset for research on short-text conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/D/D13/D13-1096.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Grand Hyatt Seattle, Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-10-21" />
			<biblScope unit="volume">2013</biblScope>
			<biblScope unit="page" from="935" to="945" />
		</imprint>
	</monogr>
	<note>A meeting of SIGDAT, a Special Interest Group of the ACL</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An information retrieval approach to short text conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<idno>abs/1408.6988</idno>
		<ptr target="http://arxiv.org/abs/1408.6988" />
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Multi-view response selection for human-computer conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/D/D16/D16-1036.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-11-01" />
			<biblScope unit="page" from="372" to="381" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Enhance word representation for out-ofvocabulary on ubuntu dialogue corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<idno>abs/1802.02614</idno>
		<ptr target="http://arxiv.org/abs/1802.02614" />
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">End-to-end neural coreference resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<ptr target="https://aclanthology.info/papers/D17-1018/d17-1018" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-09-09" />
			<biblScope unit="page" from="188" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="DOI">10.1162/neco.1997.9.8.1735</idno>
		<ptr target="https://doi.org/10.1162/neco.1997.9.8.1735" />
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Qanet: Combining local convolution with global selfattention for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-04-30" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Gaussian transformer: a lightweight approach for natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Incorporating loosestructured knowledge into LSTM with recall gate for conversation modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<idno>abs/1605.05110</idno>
		<ptr target="http://arxiv.org/abs/1605.05110" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Baeza-Yates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Ribeiro-Neto</surname></persName>
		</author>
		<ptr target="http://www.dcc.ufmg.br/irbook/" />
		<title level="m">Modern Information Retrieval</title>
		<imprint>
			<publisher>ACM Press / Addison-Wesley</publisher>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The TREC-8 question answering track report</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Eighth Text REtrieval Conference, TREC 1999</title>
		<meeting>The Eighth Text REtrieval Conference, TREC 1999<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<ptr target="http://trec.nist.gov/pubs/trec8/papers/qareport.pdf" />
		<title level="m">Available</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning to respond with deep neural networks for retrieval-based human-computer conversation system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<idno type="DOI">10.1145/2911451.2911542</idno>
		<ptr target="https://doi.org/10.1145/2911451.2911542" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval, SIGIR 2016</title>
		<meeting>the 39th International ACM SIGIR conference on Research and Development in Information Retrieval, SIGIR 2016<address><addrLine>Pisa, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="55" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning natural language inference with LSTM</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/N/N16/N16-1170.pdf" />
	</analytic>
	<monogr>
		<title level="m">The 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting><address><addrLine>San Diego California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1442" to="1451" />
		</imprint>
	</monogr>
	<note>NAACL HLT 2016</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Match-srnn: Modeling the recursive matching structure with spatial RNN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
		<ptr target="http://www.ijcai.org/Abstract/16/415" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence, IJCAI 2016</title>
		<meeting>the Twenty-Fifth International Joint Conference on Artificial Intelligence, IJCAI 2016<address><addrLine>New York, NY, USA, 9</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-07-15" />
			<biblScope unit="page" from="2922" to="2928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Sentence pair scoring: Towards unified framework for text comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Baudis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sedivý</surname></persName>
		</author>
		<idno>abs/1603.06127</idno>
		<ptr target="http://arxiv.org/abs/1603.06127" />
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A compare-aggregate model for matching text sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<idno>abs/1611.01747</idno>
		<ptr target="http://arxiv.org/abs/1611.01747" />
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Bilateral multi-perspective matching for natural language sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hamza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Florian</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2017/579</idno>
		<ptr target="https://doi.org/10.24963/ijcai.2017/579" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Sixth International Joint Conference on Artificial Intelligence<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-08-19" />
			<biblScope unit="page" from="4144" to="4150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning to rank question-answer pairs using hierarchical recurrent encoder with latent topic clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Jung</surname></persName>
		</author>
		<ptr target="https://aclanthology.info/papers/N18-1142/n18-1142" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the NAACL-HLT</title>
		<meeting>the 2018 Conference of the NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1575" to="1584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno>abs/1412.6980</idno>
		<ptr target="http://arxiv.org/abs/1412.6980" />
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<ptr target="http://dl.acm.org/citation.cfm?id=2670313" />
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/D/D14/D14-1162.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-10-25" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
	<note>A meeting of SIGDAT, a Special Interest Group of the ACL</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Directional skip-gram: Explicitly distinguishing left and right context for word embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<ptr target="https://aclanthology.info/papers/N18-2028/n18-2028" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the NAACL-HLT</title>
		<meeting>the 2018 Conference of the NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="175" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<ptr target="http://www.icml2010.org/papers/432.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Machine Learning (ICML-10)</title>
		<meeting>the 27th International Conference on Machine Learning (ICML-10)<address><addrLine>Haifa, Israel</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="807" to="814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Tensorflow: A system for large-scale machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kudlur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Levenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Warden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wicke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th USENIX Symposium on Operating Systems Design and Implementation</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">He is currently working towards a Ph.D. degree in signal and information processing at the University of Science and Technology of China</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jia-Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<pubPlace>Nanjing, China; Hefei, China</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Gu received a B.S. degree in communication engineering from Hohai University</orgName>
		</respStmt>
	</monogr>
	<note>His research interests include natural language understanding and deep learning</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">His research interests include speech processing, speech synthesis, voice conversion, and natural language processing. He was the recipient of the IEEE Signal Processing Society Young Author Best Paper Award in 2010</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">K</forename><surname>Edinburgh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>From</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Zhen-Hua Ling (M&apos; 10) received a B.E. degree in electronic information engineering and M.S. and Ph.D. degrees in signal and information processing from the University of Science and Technology of China</title>
		<meeting><address><addrLine>Hefei, China; Ltd., Hefei, China; Seattle, WA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
		<respStmt>
			<orgName>University of Edinburgh</orgName>
		</respStmt>
	</monogr>
	<note>He is currently an Associate Professor with the University of Science and Technology of China. He also worked at the University of Washington. He is currently an Associate Editor of IEEE/ACM TRANSACTIONS ON AUDIO, SPEECH, AND LANGUAGE PROCESSING</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
