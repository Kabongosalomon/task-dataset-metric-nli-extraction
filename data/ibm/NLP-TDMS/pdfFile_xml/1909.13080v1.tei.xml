<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">On Generalizing Detection Models for Unconstrained Environments</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prajjwal</forename><surname>Bhargava</surname></persName>
							<email>prajjwalin@protonmail.com</email>
						</author>
						<title level="a" type="main">On Generalizing Detection Models for Unconstrained Environments</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T17:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Object detection has seen tremendous progress in recent years. However, current algorithms don't generalize well when tested on diverse data distributions. We address the problem of incremental learning in object detection on the India Driving Dataset (IDD). Our approach involves using multiple domain-specific classifiers and effective transfer learning techniques focussed on avoiding catastrophic forgetting. We evaluate our approach on the IDD and BDD100K dataset. Results show the effectiveness of our domain adaptive approach in the case of domain shifts in environments.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Object detection has been a widely studied task in computer vision. It is focussed upon classifying objects present in an image and then regressing bounding boxes over the localized proposals. We have seen remarkable results with CNN based models <ref type="bibr" target="#b15">[16]</ref> on the COCO dataset <ref type="bibr" target="#b19">[20]</ref> [23] <ref type="bibr" target="#b5">[6]</ref> [18] <ref type="bibr" target="#b1">[2]</ref>. Recently, <ref type="bibr" target="#b4">[5]</ref> showed that when commonly used detectors are evaluated on nonstandard settings of objects in an environment, they tend to provide unusual predictions. This is also applicable for autonomous navigation systems operating in unstructured environments (e.g drivable areas except roads etc.) as well. Current detection methods don't generalize well when they encounter diverse environmental conditions.</p><p>We witness variety of environmental conditions when it comes to driving such as weather changes, dynamic changes in the surrounding environment, etc. Current detectors have been tested on data obtained from structured environments which are often not representative of real-world conditions. As a result of which, the need for data obtained from nonstandard sources is felt the most for data-driven algorithms to improve and test their generalizing capabilities.</p><p>Autonomous navigation algorithms must perform well on multiple domains especially the ones with corner cases for safety purposes. Most importantly, we want to be able to learn from a large standard data distribution to efficiently learn features in an embedding space and learn progres- <ref type="figure">Figure 1</ref>: Illustration of datasets for autonomous driving used in this work: Leftmost image is taken from: BDD100K <ref type="bibr" target="#b2">[3]</ref> and the other two are from IDD <ref type="bibr" target="#b26">[27]</ref>. Even though datasets for autonomous navigation aim to include diverse features such as illumination, various styles etc. IDD is very different in regards to vehicle density,road boundaries,diverse ambient conditions. sively from domain-specific data without having access to earlier used data.</p><p>In this paper, we address the problem of incremental learning and domain adaptation to some extent for object detectors to improve generalizing capabilities. Specifically, we tackle the problem of adapting from a standard data distribution to data obtained from the unstructured environment. We also provide baseline results on IDD and BDD100K for object detection task to compare our proposed methods. <ref type="bibr" target="#b0">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Object Detection: Region proposal based methods introduced in <ref type="bibr" target="#b8">[9]</ref> have been widely used as object detectors. It made use of selective search to reduce the number of bounding boxes. Spatial Pyramid Pooling Nets <ref type="bibr" target="#b10">[11]</ref> could generate a fixed-length representation in a dynamic manner irrespective of image scale. Fast RCNNs <ref type="bibr" target="#b7">[8]</ref> made use of regression for bounding box predictions. <ref type="bibr" target="#b21">[22]</ref> made use of RPNs and introduced anchor boxes to deal with different aspect ratios and scales. SSD <ref type="bibr" target="#b20">[21]</ref> method runs a CNN on input image only once and calculates a feature map that doesn't require proposal generation steps. Stereo RCNNs <ref type="bibr" target="#b16">[17]</ref> extends the use of Faster RCNN with stereo images for 2D and 3D bounding box predictions. It is a region proposal based network that works without the need for point clouds. Our approach can also be extended for 3D object detection similarly but we still lack the diversified ground truth data (such as 3D bounding box coordinates or Lidar point clouds obtained from unconstrained environments) for 3D detections.</p><p>Learning from multiple distributions: The concept of making generalizable deep learning models has been widely studied. This often involves retaining what the model has learned in the past and performing incremental learning on multiple domains. <ref type="bibr" target="#b27">[28]</ref> used a GAN <ref type="bibr" target="#b9">[10]</ref> to approximate the feature distribution in the source domain. <ref type="bibr" target="#b18">[19]</ref> [1] addressed the task of incremental learning with architectures that inhibit loss of learned knowledge. <ref type="bibr" target="#b12">[13]</ref> made use of a larger network to train a smaller network to generate close predictions. <ref type="bibr" target="#b3">[4]</ref> treated the task of domain adaptation as an optimal transport problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Preliminaries</head><p>Faster RCNN: It takes an RGB image as an input. The model consists of a feature extractor followed by a feature pyramid network (FPN) and region proposal network (RPN) for generating region proposals which are then used to detect objects. RPNs are more efficient than selective search. They perform a ranking of anchor boxes to reduce their number and propose those which most likely contain an object. Image features are generated by a backbone network which is then fed to an RPN along with images and targets for generating proposals. After RPN, we get proposed regions with different sizes. Region of Interest (ROI) classifier predicts the category label obtained by using ROI Pooling. RPN can output differently sized regions. ROI Pooling can simplify the problem by reducing the feature maps into the same size. The loss is the sum of classification and regression loss defined as: We refer readers to <ref type="bibr" target="#b21">[22]</ref> for further details about model architecture.</p><formula xml:id="formula_0">L det = L cls + L reg<label>(1)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Baseline Model</head><p>We use a region proposal based approach for the baseline model. For feature extraction which is used by RPN, we use ResNet50 <ref type="bibr" target="#b11">[12]</ref> followed by FPN pretrained on COCO. Linear layers after ROI Head were adjusted as per the number of classes. Our RPN generates 5 x 3 anchors per spatial location with 5 different sizes and 3 different aspect ratios. We used random horizontal flipping for augmenting the input data. Our baseline model is trained on a non HQ image set from IDD with batch size set to 4 for 5 epochs per camera orientation. It was optimized using SGD <ref type="bibr" target="#b25">[26]</ref> with momentum and weight decay set to 0.9 and 0.00004 respectively. The learning rate was initially set to 0.001 with the Cyclical learning rate scheduler <ref type="bibr" target="#b23">[24]</ref>. We use the same process for performing training on BDD100K. Results are shown in <ref type="table" target="#tab_1">Table 1 and Table 2</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Incremental Learning</head><p>The following section contains a description of training methodology and proposed transfer learning techniques aimed at minimizing catastrophic learning while adapting to target T data distribution.</p><p>Our task is to perform incremental learning on multiple diverse data distributions. The network initially learns the weights from a standard data distribution and the proposed techniques help in performing domain adaptation while remaining consistent with the already learned information. Once trained on one distribution, we don't require already used data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Domain specific heads</head><p>We make use of two ROI heads which are combined with the common backbone and RPN for generating domainspecific predictions. We can also have more than two ROI heads depending upon the number of target domains we want to adapt to. The weights of RPN and feature extractor are shared across all domain-specific classifiers. Weight sharing allows the network to learn common features with the proposed techniques across all domains without any increment in the number of parameters. Domain-specific heads also help in cases where classes don't overlap in both distributions, as in this case.</p><p>After the addition of ROI Head to the baseline model, we train the head on T to learn domain-specific weights. This is followed by progressive training of other components of the network to avoid catastrophic forgetting as proposed in <ref type="bibr" target="#b13">[14]</ref> to learn domain invariant features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Discriminative finetuning</head><p>We use different learning rates to train different layers of our network. As shown in <ref type="bibr" target="#b28">[29]</ref>, different layers of the network are responsible for capturing different types of information. Discriminative finetuning allows us to set the rate at which these different components of the network learn. Since the weights of the backbone and RPN are being shared for all tasks, we want to inhibit the loss of learned information. We use a higher learning rate for domainspecific components and a lower learning rate for components whose weights are being shared. Specifically, we require a lower learning rate for the backbone and RPN since feature extraction and generation of region proposals are common tasks across all domains and a higher learning rate for domain-specific ROI Heads. A general SGD update of a model's parameters θ at time step t looks like:</p><formula xml:id="formula_1">θ t = θ t−1 − η · ∇ θ J(θ)<label>(2)</label></formula><p>where η denotes learning rate and ∇ θ J(θ) denotes gradient with respect to model's objective function. We split model's parameters θ into θ 1 , . . . , θ L where θ l contains parameters of the model at the l-th layer and L denotes the total number of layers of our network. The SGD update then becomes:</p><formula xml:id="formula_2">θ l t = θ l t−1 − η l · ∇ θ l J(θ)<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Gradual unfreezing</head><p>Training the entire model on a different domain at once leads to catastrophic forgetting, which means the model adapts itself to the target domain on which it is being tuned compromising the performance on source domain on which it was trained. We overcome this issue by gradually unfreezing the components of the network with discriminative finetuning. We freeze all the components initially and unfreeze the domain ROI T Head which is fine-tuned until convergence followed by progressive unfreezing and finetuning of FPN and RPN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Cyclical Learning Rate</head><p>We optimize our network using the Cyclical learning rate (CLR) as proposed in <ref type="bibr" target="#b24">[25]</ref>. Instead of having a gradually decreasing learning rate, as the training converges, we use CLR which cycles the learning rate between lower and upper bound. CLR helps in oscillating towards a higher learning rate wherever necessary. It prevents the network from converging at some poor local minima in loss landscape. We make use of triangular variation for our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Experiments</head><p>In this section, we evaluate our proposed approach on two diverse datasets. One dataset denotes structured environments and the other one denotes unstructured and unconstrained environments to which we want to adapt. The later one simulates high traffic density, rural areas with no proper roads, classes usually not seen in other datasets posing a much harder task for current object detection models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Datasets</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IDD:</head><p>We use IDD for target adaptation tasks. It provides data for object detection in two resolutions. The non HQ set consists of 27072 images taken from 5 different orientations of the camera with two resolutions 964x1280 and 1080x1920. The HQ set consists of 14722 images with two resolutions 720x1280 and 1080x1920. There are 15 classes for this task. Note that we only perform training and evaluation on the non HQ set of IDD. Results can be further improved if high res images from the HQ set are used to train the components of the network. The validation set consists of 10,225 high-resolution images.</p><p>Berkeley Deep Drive: We use BDD100K <ref type="bibr" target="#b29">[30]</ref> to denote data distribution obtained from structured environments. We only use the images and their respective ground truths for the detection task. There are 69863 images in train and 10000 in the validation set. We trained our proposed model over 12 classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Training methodology</head><p>The proposed architecture has been shown in <ref type="figure" target="#fig_1">Figure 3</ref>. This architecture is based on Faster RCNN. The backbone is a ResNet50 pretrained on COCO. We use a batch size of 16. We use the same baseline model with an additional ROI Head. We obtain four feature maps from the batch of images obtained by intermediate layers of backbone to perform multi-scale ROI aligning. These feature maps are shared across all components. The obtained feature maps are then fed to an RPN for generating region proposals fol-lowed by domain-specific ROI pooling and prediction layers. While training and inference, only the designated ROI Head is used for the respective domain. This model is trained in an end to end strategy and inference can be performed in a regular manner with learned weights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Results</head><p>In the following section, we evaluate the effects of each of the mentioned techniques along with the effect of varying learning rates. As per convention, we use BDD→IDD to denote BDD100K as S and IDD as T . Since we have more data collected from structured environments <ref type="bibr" target="#b14">[15]</ref> [30] <ref type="bibr" target="#b6">[7]</ref> , the results simulate learning from already existing data distributions to adapt to unstructured environment.</p><p>Adding domain specific head Here we use the same baseline model for BDD. We add a domain-specific head as proposed in <ref type="figure" target="#fig_1">Figure 3</ref>. In this case, we only perform finetuning of this head on T . Apart from the domain-specific head, the rest of the components of the network are kept frozen.</p><p>By introducing the domain-specific head and training it for 5 epochs, we see a considerable performance on T without any performance decrement on S. BDD→IDD indicates that we use the baseline model trained on BDD100K with the specified method. While reporting for IDD→BDD, we only change the domain-specific head, the rest of the network stays the same. The same model can achieve an mAP of 24.3% on IDD and 45.7% on BDD. Results are shown in <ref type="table" target="#tab_3">Table 3</ref> Discriminative finetuning and Gradual unfreezing We use the same network and weights as in the previous step. Here, we introduce both techniques. In <ref type="table" target="#tab_3">Table 3</ref>, active components denote those components of the network whose weights are being updated during the training process. We experiment with different learning rates with progressive addition of active components with different bounds of learning rate during each step.</p><p>Learning rate plays a very crucial role in determining the performance increment on T and retention of learned information. Domain-specific components require a higher learning rate as compared to shared components. The learning rate range plays a crucial role since it determines the rate at which weights change in all active components. In our experiments, we found this range 0.0001-0.006 for the learning rate to work well. As experimental results show, with a little decrement in performance on S, our model retains near similar performance on S after being trained on T . In some cases, we saw an increment in performance on T while maintaining the same performance on S. This shows that these transfer learning techniques complement each other and are effective in inhibiting information loss while adapting to diverse target distributions.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Discussion</head><p>In this paper, we use an incremental learning approach and demonstrate the effectiveness of our method on data obtained from unconstrained environments. The main motivation behind this work is to demonstrate the effectiveness of our approach and encourage further research into building detection systems that generalize well on uncommon data distributions which are well representative of diverse real-world conditions. These proposed approaches can also be extended to other computer vision tasks as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Acknowledgement</head><p>The author would like to thank Intel AI for providing access to AI Devcloud as part of the Student ambassador program.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Sample of predictions from our baseline model trained on non HQ image set from IDD. As evident, images in IDD are highly diverse. In some cases, environments are highly unstructured, while in some cases objects of interest are occluded or far off.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Overview of our architecture We use multiple classifier heads to perform domain-specific predictions. Rest of the network shares the same weights to learn common representations</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Quantitative results from baseline model reported on validation set of BDD100K</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>S and T</head><label>and</label><figDesc>Epoch Active components (with LR) LR Range mAP (%) at specified epochs</figDesc><table><row><cell>BDD→IDD</cell><cell>5</cell><cell>+ROI Head(1e-3)</cell><cell>1e-3, 6e-3</cell><cell>24.3</cell></row><row><cell>IDD→BDD</cell><cell>Eval</cell><cell></cell><cell>-</cell><cell>45.7</cell></row><row><cell>BDD→IDD</cell><cell>5,9</cell><cell>+RPN (1e-4)</cell><cell>1e-4, 6e-4</cell><cell>24.7, 24.9</cell></row><row><cell>IDD→BDD</cell><cell>Eval</cell><cell>+ROI head (1e-3)</cell><cell>-</cell><cell>45.3, 45.0</cell></row><row><cell cols="2">BDD→IDD 1,5,6,7</cell><cell>+RPN (1e-4)</cell><cell>1e-4, 6e-3</cell><cell>24.3, 24.9, 24.9, 25.0</cell></row><row><cell>IDD→BDD</cell><cell>Eval</cell><cell>+ROI head (1e-3)</cell><cell>-</cell><cell>45.7, 44.8, 44.7, 44.7</cell></row><row><cell cols="2">BDD→IDD 1,5,10</cell><cell>+ROI head (1e-3)</cell><cell>1e-4, 6e-3</cell><cell>24.9, 25.4, 25.9</cell></row><row><cell>IDD→BDD</cell><cell>Eval</cell><cell>+RPN (4e-4) +FPN(2e-4)</cell><cell>-</cell><cell>45.2, 43.9, 43.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Change in mAP with varying learning rates for different active components. Results reported on validation sets of T (IoU=0.5)</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Incremental learning in person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bhargava</surname></persName>
		</author>
		<idno>abs/1808.06281</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Gcnet: Nonlocal networks meet squeeze-excitation networks and beyond. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1904" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The cityscapes dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Scharwächter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshop on The Future of Datasets in Vision</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Optimal transport for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Courty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Flamary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tuia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rakotomamonjy</surname></persName>
		</author>
		<idno>abs/1507.00504</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Does object recognition work for everyone? CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1906" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Centernet: Keypoint triplets for object detection. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1904" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Are we ready for autonomous driving? the kitti vision benchmark suite</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R-Cnn</forename><surname>Fast</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Corr</surname></persName>
		</author>
		<idno>abs/1504.08083</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Rich feature hierarchies for accurate object detection and semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<idno>abs/1311.2524</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger, editors</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Spatial pyramid pooling in deep convolutional networks for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<idno>abs/1406.4729</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<idno>abs/1512.03385</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Deep Learning and Representation Learning Workshop</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Universal language model fine-tuning for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.06146</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">The apolloscape dataset for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yang</surname></persName>
		</author>
		<idno>abs/1803.06184</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Stereo R-CNN based 3d object detection for autonomous driving. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1902" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Scale-aware trident networks for object detection. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1892" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Learning without forgetting. CoRR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hoiem</surname></persName>
		</author>
		<idno>abs/1606.09282</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">D</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Microsoft COCO: common objects in context. CoRR, abs/1405.0312</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">SSD: single shot multibox detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<idno>abs/1512.02325</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">SNIPER: efficient multi-scale training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Najibi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
		<idno>abs/1805.09300</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">No more pesky learning rate guessing games. CoRR, abs/1506.01186</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">N</forename><surname>Smith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Cyclical learning rates for training neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">N</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Winter Conference on Applications of Computer Vision (WACV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="464" to="472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">On the importance of initialization and momentum in deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<idno>III-1139-III-1147. JMLR.org</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference on International Conference on Machine Learning</title>
		<meeting>the 30th International Conference on International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">28</biblScope>
		</imprint>
	</monogr>
	<note>ICML&apos;13</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">IDD: A dataset for exploring problems of autonomous navigation in unconstrained environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Varma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Namboodiri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chandraker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">V</forename><surname>Jawahar</surname></persName>
		</author>
		<idno>abs/1811.10200</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Incremental adversarial domain adaptation for continually changing environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wulfmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bewley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Posner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018-05" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">How transferable are features in deep neural networks?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yosinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Clune</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lipson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="3320" to="3328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">BDD100K: A diverse driving video database with scalable annotation tooling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Madhavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<idno>abs/1805.04687</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
