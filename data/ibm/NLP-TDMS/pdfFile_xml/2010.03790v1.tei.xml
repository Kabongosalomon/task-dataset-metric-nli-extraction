<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Text-based RL Agents with Commonsense Knowledge: New Challenges, Environments and Baselines</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keerthiram</forename><surname>Murugesan</surname></persName>
							<email>keerthiram.murugesan@ibm.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">IBM Research</orgName>
								<orgName type="institution" key="instit2">Yorktown Heights</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mattia</forename><surname>Atzeni</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">IBM Research</orgName>
								<address>
									<settlement>Zurich</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavan</forename><surname>Kapanipathi</surname></persName>
							<email>kapanipa@us.ibm.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">IBM Research</orgName>
								<orgName type="institution" key="instit2">Yorktown Heights</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushkar</forename><surname>Shukla</surname></persName>
							<email>pushkarshukla@ttic.edu</email>
							<affiliation key="aff2">
								<orgName type="institution">TTI</orgName>
								<address>
									<settlement>Chicago 4 ETH Zurich</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadhana</forename><surname>Kumaravel</surname></persName>
							<email>sadhana.kumaravel1@ibm.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">IBM Research</orgName>
								<orgName type="institution" key="instit2">Yorktown Heights</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerald</forename><surname>Tesauro</surname></persName>
							<email>gtesauro@us.ibm.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">IBM Research</orgName>
								<orgName type="institution" key="instit2">Yorktown Heights</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kartik</forename><surname>Talamadupula</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">IBM Research</orgName>
								<orgName type="institution" key="instit2">Yorktown Heights</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mrinmaya</forename><surname>Sachan</surname></persName>
							<email>mrinmaya.sachan@inf.ethz.ch</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Murray</forename><surname>Campbell</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">IBM Research</orgName>
								<orgName type="institution" key="instit2">Yorktown Heights</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Text-based RL Agents with Commonsense Knowledge: New Challenges, Environments and Baselines</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T18:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Text-based games have emerged as an important test-bed for Reinforcement Learning (RL) research, requiring RL agents to combine grounded language understanding with sequential decision making. In this paper, we examine the problem of infusing RL agents with commonsense knowledge. Such knowledge would allow agents to efficiently act in the world by pruning out implausible actions, and to perform lookahead planning to determine how current actions might affect future world states. We design a new text-based gaming environment called TextWorld Commonsense (TWC) for training and evaluating RL agents with a specific kind of commonsense knowledge about objects, their attributes, and affordances. We also introduce several baseline RL agents which track the sequential context and dynamically retrieve the relevant commonsense knowledge from ConceptNet. We show that agents which incorporate commonsense knowledge in TWC perform better, while acting more efficiently. We conduct user-studies to estimate human performance on TWC and show that there is ample room for future improvement.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Over the years, simulation environments have been used extensively to drive advances in reinforcement learning <ref type="bibr">(RL)</ref>. A recent framework that has received much attention is TextWorld (TW) <ref type="bibr" target="#b8">(Côté et al. 2018)</ref>, where an agent must interact with an external environment to achieve a given goal using only the modality of text. TextWorld and similar textbased environments seek to bring advances in grounded language understanding to a sequential decision making setup.</p><p>While existing text-based games are valuable for RL research, they fail to test a key aspect of human intelligence: common sense. Humans capitalize on commonsense (background) knowledge about entities -properties, spatial relations, events, causes and effects, and other social conventions -while interacting with the world <ref type="bibr" target="#b26">(Mccarthy 1960;</ref><ref type="bibr" target="#b38">Winograd 1972;</ref><ref type="bibr" target="#b9">Davis and Marcus 2015)</ref>. Motivated by this, we propose a novel text-based environment called TextWorld Commonsense (or TWC), where the agent is expected to use commonsense knowledge stored in knowledge bases such as ConceptNet <ref type="bibr" target="#b22">(Liu and Singh 2004;</ref><ref type="bibr" target="#b34">Speer, Chin, and Havasi 2017)</ref> to act efficiently. TWC is a sandbox environment similar to TextWorld where the agent has <ref type="bibr">Copyright © 2021.</ref> Code and data can be found at https:// github.com/IBM/commonsense-rl to clean up a house. Achieving goals in this environment requires commonsense knowledge about objects, their properties, locations, and affordances. Efficient use of commonsense knowledge would allow the agent to select correct and applicable actions at each step: i.e., improve sample efficiency by reducing exploration. Moreover, commonsense knowledge would help the agent to perform look-ahead planning and determine how current actions might affect future world states <ref type="bibr" target="#b15">(Juba 2016)</ref>. <ref type="figure" target="#fig_0">Fig 1 presents</ref> a running example from TWC that illustrates how the agent can leverage a commonsense knowledge base <ref type="bibr">(KB)</ref>.</p><p>Validating such environments is challenging, and requires: (1) verifying the information used in the games; (2) evaluating baseline agents that are capable of utilizing external commonsense knowledge against counterparts that do not; and (3) providing empirical evidence to show that the environment can drive future research. In this work, we address each of these by first performing human annotations to validate the correctness and completeness of the TWC environment. Next, we design a framework of agents that combine text-based agents with commonsense knowledge. The agents can dynamically retrieve relevant knowledge from a commonsense KB. Finally, based on human performance on the generated games and manual selection of commonsense knowledge, we discuss and justify the importance of such an environment in driving future research. Contributions: The main contributions of this paper are the following: (1) we propose an novel environment called TWC to evaluate the use of commonsense knowledge by RL agents; (2) we introduce baselines that use commonsense knowledge from ConceptNet and show that common sense indeed helps in decision making; (3) whereas our model with common sense performs well, we show a pronounced gap in performance between automated agents and humans in the TWC environment. This substantiates our claim that TWC provides a challenging test-bed for RL agents and can act as a spur to further research in this area.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">TextWorld Commonsense (TWC)</head><p>Existing text-based games <ref type="bibr" target="#b0">(Adhikari et al. 2020;</ref><ref type="bibr" target="#b8">Côté et al. 2018</ref>) severely restrict the amount and variety of commonsense knowledge that an agent needs to know and exploit. Thus, in this paper, we create and present a new domain -TextWorld Commonsense (TWC) -by reusing the TextWorld <ref type="bibr" target="#b8">(Côté et al. 2018</ref>) engine in order to generate textbased environments where RL agents need to effectively retrieve and use commonsense knowledge. Commonsense can be defined very broadly and in various ways <ref type="bibr" target="#b11">(Fulda et al. 2017)</ref>. In this paper, we mainly focus on commonsense knowledge that pertains to objects, their attributes, and affordances 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Constructing TWC</head><p>We built the TWC domain as a house clean-up environment where the agent is required to obtain knowledge about typical objects in the house, their properties, and expected location from a commonsense knowledge base. The environment is initialized with random placement of objects in various locations. The agent's high level goal is to tidy up the house by putting objects in their commonsense locations. This high level goal may consist of multiple sub-goals requiring commonsense knowledge. For example, for the sub-goal: put the apple inside the refrigerator, commonsense knowledge from ConceptNet such as (Apple → AtLocation → Refrigerator) can assist the agent. Goal Sources: While our main objective was to create environments that require commonsense, we did not want to bias TWC towards any of the existing knowledge bases. We additionally wanted to rule out the possibility of data leaks in situations where both the environment as well as the external knowledge came from the same part of a specific commonsense knowledge base (KB) like ConceptNet. For the construction of the TWC goal instances, we picked sources of information that were orthogonal to existing commonsense KBs. Specifically, we used: (1) the picture dictionary from 7ESL 2 ; (2) the British Council's vocabulary learning page 3 ; (3) the English At Home vocabulary learning page 4 ; and (4) ESOL courses 5 . We collected vocabulary terms from 1 Gibson in his seminal work <ref type="bibr" target="#b13">(Gibson 1978)</ref>    these sources and manually aggregated this content in order to build a dataset that lists several kinds of objects that are typically found in a house environment. For each object, the dataset specifies a list of plausible and coherent locations. Instance Construction: A TWC instance is sampled from this dataset, which includes a configuration of 8 room types and a total of more than 900 entities <ref type="table" target="#tab_1">(Table 1</ref>). The environment includes three main kinds of entities: objects, supporters, and containers. Objects are entities that can be carried by the agent, whereas supporters and containers are furniture where those objects can be placed. Let o represent the object or entity in the house; r represent the room that the entity is typically found in; and l represent the location inside that room where the entity is typically placed. In our running example, o:apple is an entity, l:refrigerator is the container, and r:kitchen is the room. Via a manual verification process (which we elucidate next in Section 2.2) we ensure that the associations between entities, supporters/containers, and rooms reflect commonsense. As shown in <ref type="table" target="#tab_1">Table 1</ref>, we collected a total of 190 objects from the aforementioned resources. We further expanded this list by manually annotating the objects with qualifying properties, which are usually adjectives from a predefined set (e.g., a shirt may have a color and a specific texture). This allows increasing the cardinality of the total pool of objects for generating TWC environments to more than 800.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Verifying TWC</head><p>In order to ensure that TWC reflects commonsense knowledge, we set up two annotation tasks to verify the environment goals (i.e., goal triples of the form o, r, l , where o denotes the object, r denotes a room, and l a location within that room, as defined in Section 2.1). The first task is meant to verify the correctness of the goals and evaluate whether the goal o, r, l triples make sense to humans. The second task is aimed at verifying completeness, i.e. that other triples in the environment do not make sense to humans.</p><p>Verifying Correctness: To test the correctness of our environments, we asked our human annotators to determine whether they would consider a given room-location combination in the goal o, r, l to be a reasonable place for the object o. If so, the instance was labeled as positive, and as negative otherwise. We collected annotations from 10 annotators, across a total of 205 unique o, r, l triples. Each annotator labeled 70 of these triples, and each triple was as-  Verifying Completeness: Similar to the above annotation exercise, we also asked human annotators to determine if a non-goal o, r, l triple made sense to them. In addition to the 70 triples mentioned above, each of the M = 10 annotators were asked to label as either positive or negative a set of 30 non-goal triples. In order to provide annotators with an informative set of non-goal o, r, l triples, we used GloVe <ref type="bibr" target="#b30">(Pennington, Socher, and Manning 2014)</ref> to compute embeddings for each location in TWC. For a given object o, a non-goal location l' was then selected among those most similar to the goal location l, according to the cosine similarity between the embeddings of l and l'. As before, each non-goal triple was assigned to at least 3 annotators from a set that comprises a total of 97 triples. As we see in <ref type="table" target="#tab_2">Table  2</ref>, the annotators seldom find a hypothesized non-goal o, r, l triple as commonsensical.</p><p>Annotator Reliability: For our overall annotation exercise, we can report inter-annotator agreement statistics, as the overall annotation is no longer imbalanced in terms of label marginals. We report a Krippendorff's alpha <ref type="bibr" target="#b18">(Krippendorff 2018</ref>) α κ = 0.74. This number is over the accepted range for agreement and shows that our annotators have strong agreement when rating the triples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Generating TWC Games</head><p>We used the TextWorld engine to build a set of text-based games where the goal is to tidy up a house by putting objects in the goal locations specified in the aforementioned TWC dataset. The games are grouped into three difficulty levels (easy, medium, and hard) depending on the total number of objects in the game, the number of objects that the agent needs to find (the remaining ones are already carried by the agent at the beginning of the game) and the number of rooms to explore. The values of these properties are randomly sampled from the ones listed in <ref type="table" target="#tab_4">Table 3</ref>. For each difficulty level, we provide a training set and two test sets. The training sets were built out of 2 3 of the unique objects reported in <ref type="table" target="#tab_1">Table 1</ref>. For the first test set, we used the same set of objects as the training games. We call this set the in distribution test set. For the second test set, we employed the remaining 1 3 objects to create the evaluation games. We call this set the out of distribution test set. This allows us to investigate not only the capability of the agents to generalize within the same distribution of the training data, but also their ability to achieve generalization to unseen entities. Figure 2 shows a game walkthrough for a specific game in the medium difficulty level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Benchmarking Human Performance</head><p>To complete our benchmarking of the TWC domain, we conducted yet another human annotation task, focusing on the performance of human game-players. Such an experiment is essential to establishing the performance of human players, who are generally regarded as proficient at exploiting commonsense knowledge. We set up an interactive interface to TWC via a Jupyter notebook, which was then used by players to interact with the same games that we evaluated all the other RL agents on. We recorded all moves (steps) made by players, as well as the reward collected. At each step, the players were shown the current context of the game in text format, and given a drop-down box with the full list of pos-sible actions. Once the player picked an action, it was executed; and this process repeated until all possible goals in the game had been accomplished. A total of 16 annotators played 104 instances of TWC games, spread across the easy, medium, and hard levels. Each difficulty level had 5 games, each from the train and test distributions, for a total of 30 unique games. Each unique game was annotated by a minimum of 3 annotators. The results are presented in <ref type="table" target="#tab_5">Table 4</ref>, along with the experimental results in Section 4, to allow for direct comparison with the TWC agents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">TWC Agents</head><p>Text-based games can be seen as partially observable Markov decision processes (POMDP) <ref type="bibr" target="#b16">(Kaelbling, Littman, and Cassandra 1998)</ref> where the system dynamics are determined by an MDP, but the agent cannot directly observe the underlying state. The agent receives a reward at every time step and its goal is to maximize the expected discounted sum of rewards. The TWC games allow the agent to perceive and interact with the environment via text. Thus, the observation at time step t, o t , is presented as a sequence of</p><formula xml:id="formula_0">tokens (o t = {o 1 t , . . . o N t }).</formula><p>Similarly, each action a is also denoted as a sequence of tokens {a 1 , . . . , a M }. The goal of this project is to test RL agents with commonsense. Hence, the agents also have access to a commonsense knowledge base; and are allowed to use it while selecting actions. To model TWC, we design a framework that can: (a) learn representations of various actions; (b) learn from sequential context; (c) dynamically retrieve the relevant commonsense knowledge; (d) integrate the retrieved commonsense knowledge with the context; and (e) predict next action. A block diagram of the framework is shown in <ref type="figure" target="#fig_1">Fig 3.</ref> We describe the various components of our framework below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Action and Observation Encoder</head><p>We learn representations of observations and actions by feeding them to a recurrent network. Given the current observation o t , we use pre-trained word embeddings to represent o t as a sequence of d-dimensional vectors x 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Context Encoder</head><p>A key challenge for our RL agent is in modeling context, i.e. the history of observations. We model the context using another recurrent encoder over the observation representations o t . We use a GRU network to encode the sequence of previous observations up to o t into a vector s t = GRU(s t−1 , o t ).</p><p>We refer to s t as the state vector, or the context encoding. The context encoding will be used in addition to the commonsense knowledge in the final action prediction. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Dynamic Commonsense Subgraph</head><p>Our model retrieves commonsense knowledge from Con-ceptNet in the form of a graph. The graph G t C is updated dynamically at each time step t. G t C is constructed by mapping the textual observation o t at time t to ConceptNet and combining it with the graph at previous time step G t−1 C . We used spaCy (https://spacy.io) to extract noun chunks, and then performed a max sub-string match with all the concepts in ConceptNet. This results in a set of entities e t for the observation o t at time t. We then combine the concepts from G t−1 C and e t to get E t . E t consists of all the concepts observed by the agent until time step t, including the description of the room, the current observation, and the objects in the inventory. Given E t , we describe three different techniques to automatically extract the commonsense graph G t from external knowledge.</p><p>(1) Direct Connections: This is the baseline approach to construct G t C . We fetch direct links between each of the concepts in E t from ConceptNet.</p><p>(2) Contextual Direct Connections: Since the goal of the agent is to clean up the house by putting objects into its appropriate containers such as apple ⇒ refrigerator, , we hypothesize that adding links only between objects and containers may benefit the agent instead of links between all concepts as done by Direct Connections, as we might overwhelm the agent with noise. To accomplish this goal, we split the entities E t into objects and containers. Since we know the entities from the inventory in E t constitutes objects, no explicit labelling is needed as we consider the remaining entities as containers. We retain only the edges between objects and containers from ConceptNet.</p><p>(3) Neighborhood: Previous techniques only focus on connecting links between observed concepts E t from external knowledge. In addition to the direct relations, it may be beneficial to include concepts from external knowledge that is related to E t but has not been directly observed from the game. Therefore, for each concept in E t , we include all its neighboring concepts and associated links.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Knowledge Integration</head><p>We enhance the text-based RL agent by allowing it to jointly contextualize information from both the commonsense subgraph and the observation representation. We call this step knowledge integration. We encode the commonsense graph using a graph encoder followed by a co-attention layer. Graph encoder: The graph G t C is encoded as follows: First, we use pretrained KG embeddings (Numberbatch) to map the set of nodes V t to a feature matrix [e 1 t , . . . , e</p><formula xml:id="formula_1">|V t | t ] ∈ R f ×|V t * | . Here, e i t ∈ R f is the (averaged) embedding of words in node i ∈ V t * .</formula><p>Following <ref type="bibr" target="#b23">(Lu et al. 2017)</ref>, we also add a sentinel vector to allow the attention modules to not attend to any specific nodes in the subgraph. These node embeddings are updated at each time step by message passing between the nodes of G t c with Graph Attention Networks (GATs) <ref type="bibr" target="#b36">(Veličković et al. 2018</ref></p><formula xml:id="formula_2">) to get {z 1 t , z 2 t · · · z |V t |</formula><p>t } using multi-head graph attention, resulting in a final graph representation that better captures the conceptual relations between the nodes in the subgraph. Co-Attention: In order to combine the observational context and the retrieved commonsense graph, we consider a bidirectional attention flow layer between these representations to re-contextualize the graph for the current state of the game <ref type="bibr" target="#b33">(Seo et al. 2016;</ref><ref type="bibr" target="#b39">Yu et al. 2018</ref>). Similar to <ref type="bibr" target="#b39">(Yu et al. 2018)</ref>, we compute a similarity matrix S ∈ R N×|V t C | between the context and entities in the extracted common sense subgraph using a trilinear function. In particular, the similarity between j th token's context encoding h j t and i th node encoding z i t in the commonsense subgraph is computed as:</p><formula xml:id="formula_3">S i j = W T 0 [z i t ; h j t ; z i t • h j t ]</formula><p>where • denotes elementwise product, ; denotes concatenation and W 0 is a learnable parameter. We use the softmax function to normalize the rows (columns) of S and get the similarity function for the common-sense knowledge graphS G (context representation S O ). The commonsense-to-context attention is calculated as</p><formula xml:id="formula_4">A =S T G · O and the context-to-common sense attention is calculated as B =S GS T O · G, where G = [z 1 t , z 2 t , · · · z |V t C | t ] and O = [h 1 t , h 2 t · · · h N t ]</formula><p>are the commonsense graph and observation encodings. The attention vectors are then combined together and the final graph encoding vectors G are calcu-</p><formula xml:id="formula_5">lated as W [G; A; G • A; G • B]</formula><p>where W is the learnable parameter. Finally, we get the commonsense graph encoding g t i for each action a i ∈ A t by applying a general attention over the nodes using the state vector and the action encoding [s t ; a t i ] <ref type="bibr" target="#b24">(Luong, Pham, and Manning 2015)</ref>. The attention score for each node is computed as α i = [s t ; a t i ]W g G, and the commonsense graph encoding for action a t i is given as</p><formula xml:id="formula_6">g t i = α i G.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Action Selection</head><p>The action score for each actionâ t i is computed based on the context encoding s t , the commonsense graph encoding g t i and the action encoding a t i . We concatenate these encoding vectors into a single vector r t i = [s t ; g t i ; a t i ]. Then, we compute probability score for each action</p><formula xml:id="formula_7">a i ∈ A t as p t = so f tmax(W 1 · ReLU(W 2 · r t + b 2 ) + b 1 ); where W 1 ,W 2 , b 1 ,</formula><p>and b 2 are learnable parameters of the model. The final action chosen by the agent is then given by the one with the maximum probability score, namelyâ t = arg max i p t,i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we report the results of our experiments on the TWC games. Given that the quality (correctness and completeness) of TWC has already been evaluated (c.f. Section 2.2), these experiments primarily focus on showing that:</p><p>(1) agents that utilize commonsense knowledge can achieve better performance on TWC than their text-based counterparts; (2) TWC can aid research in the use of commonsense knowledge because of the gap between human performance and the commonsense knowledge agents. Experimental Setup: We measure the performance of the various agents using: (1) the normalized score (score achieved ÷ maximum achievable score); and (2) the number of steps taken. Each agent is trained for 100 episodes and the results are averaged over 10 runs. Following the winning strategy in the FirstTextWorld Competition (Adolphs and Hofmann 2019), we use the Advantage Actor-Critic framework  to train the agents using reward signals from the training games.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">RL Agents in TWC</head><p>We evaluate our framework on the TWC cleanup games (as described in Section 2.3). For comparison, we consider a random agent that randomly picks an action at each time step. We consider two types of experiment settings based on the type of information available to the RL agents: (1) Text-based RL agents have access to the textual description (observation) of the current state of the game provided by the TWC environment; and (2) Commonsense-based RL agents have access to both the observation and Concept-Net. Text-only Baseline Agents: As baselines, we picked various SOTA text-based agents that utilize observation only: (1) LM-NSP uses language models such as BERT <ref type="bibr" target="#b10">(Devlin et al. 2019</ref>) and GPT2 <ref type="bibr" target="#b31">(Radford et al. 2019)</ref> with the observation and the action pair as a Next Sentence Prediction (NSP) task; (2) LSTM-A2C <ref type="bibr" target="#b29">(Narasimhan, Kulkarni, and Barzilay 2015)</ref> uses the observed text to select the next action; baselines, we use GloVe <ref type="bibr" target="#b30">(Pennington, Socher, and Manning 2014)</ref> embeddings for text. The results on these baselines are reported in <ref type="table" target="#tab_5">Table 4</ref>. For each difficulty level, we report: the agents' performance; the optimal number of steps to solve the game 6 ; and the human performance. The performance of GPT2-NSP and BERT-NSP shows that even powerful pretrained models if not tuned to this task have difficulty in these commonsense RL games, as they do not capture commonsense relationships between entities. Baselines such as LSTM-A2C, DRRN, and KG-A2C have a competitive advantage over the LM-NSP baselines, as they effectively adapt to the sequential interaction with the environment to improve performance. Among these baselines, DRRN and KG-A2C perform better than LSTM-A2C as they utilize the structure of the state and action spaces for efficient exploration of the environment. Commonsense-based agents: We introduce commonsense knowledge in two ways. The first is (Text + Numberbatch) by replacing GloVE embeddings in the LSTM-A2C agent with Numberbatch (Nb) embeddings <ref type="bibr" target="#b34">(Speer, Chin, and Havasi 2017)</ref> which were trained on text and ConceptNet. This is the naive approach to augment text information with commonsense knowledge. The results in <ref type="table" target="#tab_5">Table 4</ref> show that introducing Nb embeddings allows achieving a noticeable gain (an average of 3 steps in easy and 7 steps in medium level games) over GloVe embeddings.</p><p>In order to explicitly use commonsense knowledge, we experiment with the three different mechanisms outlined in Section 3.2 for retrieving relevant information from Con-ceptNet: (DC, CDC and NG). These methods retrieve both the concepts and structure in the relevant sub-graphs from Con-ceptNet, which are leveraged by our co-attention mechanism (Section 3.4). The comparison of the agents' performance with different retrieving mechanisms is shown in <ref type="figure" target="#fig_3">Fig 5.</ref> The results show that CDC performs the best among other mechanisms, particularly compared to DC. Unlike DC that includes all the links between observed concepts from ConceptNet, CDC restricts links to those between observed objects and containers. This selection of relevant links from Concept-Net improves the performance of the agent.</p><p>Given that CDC performs best, we compare results on text-based models with CDC-augmented commonsense knowledge to other baselines. <ref type="table" target="#tab_5">Table 4</ref> shows results for textbased agents initialized with GloVe or Nb embeddings, and augmented with commonsense knowledge. We see that the commonsense-based RL agents perform better than textbased RL agents in the easy and medium level games. This is not surprising, as these instances mostly involve picking an object and placing it in a container in the same room. Both the text-based and commonsense RL agents struggle in the hard level, as these games have more than one room and multiple objects and containers. We also notice that the average number of steps taken by the commonsense-based RL agents are noticeably lower than the other agents as it efficiently uses commonsense knowledge to rule out implausible actions. This proves that TWC is a promising test-bed where commonsense knowledge helps.</p><p>Our results show that TWC still has much room for improvement in terms of retrieving and combining knowledge with observations and feedback from the environment in a sample-efficient manner. As a starting point for showing that there is headroom, we switched the retrieval mechanism to manually selected information from ConceptNet. We manually retrieved the relevant commonsense knowledge by extracting the commonsensical paths between entities in ConceptNet, corresponding to objects in the TWC games and their goal locations. The manual subgraph includes all the relevant shortest paths between an object and its location, within a 2-hop neighborhood expansion of both nodes. Since the extracted subgraph can be very large even for the easy games, further pruning was performed to remove noise. We emphasize that the manual annotation can be error-prone or result in manual subgraphs that lack potentially useful information. Thus, the manual graphs should not be taken as a gold standard. However, we are exploring other manual retrieval process to understand if better commonsense retrieval approaches can bring improvements in the future. In <ref type="table" target="#tab_5">Table 4</ref>, agents that are augmented with the manual graph perform better than the other automated retrieval mechanisms (average reduction of 2 − 5 steps on easy and medium). <ref type="figure" target="#fig_2">Fig 4 shows</ref> training curves for the Textonly, Text+Commonsense and Text+Manual agents on the three difficulty levels. We notice that infusing commonsense knowledge allows achieving faster convergence both in terms of the number of steps taken by the agents and the final score. We found that the extracted manual subgraphs is not perfect as can be seen in the training curves for medium and hard levels. Human Performance on TWC: We also present the results of human performance in TWC (outlined in Section 2.4). The O and H columns in <ref type="table" target="#tab_5">Table 4</ref> (two per condition) present these results. A quick comparison of these numbers reveals two major results: (1) human performance H is very close to the optimal number of steps O in all 3 conditions; and <ref type="formula">(2)</ref> there is significant headroom between H and all of the other agents in the table, include the ones with the manual graph. This confirms that there is still much progress to be made in retrieving and encoding the commonsense knowledge effectively to solve such problems; and that TWC can spur further research.  . O represents optimal # steps needed to accomplish the goals. H represents human level performance. All agents were restricted to a maximum of 50 steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Generalization</head><p>(2016) proposed Deep Symbolic RL, which combines aspects of symbolic AI with neural networks and RL as a way to introduce commonsense priors. There has also been work on policy transfer <ref type="bibr" target="#b4">(Bianchi et al. 2015)</ref>, which studies how knowledge acquired in one environment can be re-used in another one; and experience replay <ref type="bibr" target="#b37">(Wang et al. 2016;</ref><ref type="bibr" target="#b20">Lin 1992</ref><ref type="bibr" target="#b21">Lin , 1993</ref> which studies how an agent's previous experiences can be stored and then later reused. In this paper, we use commonsense knowledge as a way to improve sample efficiency in text-based RL agents. To the best of our knowledge, there is no prior work that practically explores how commonsense can be used to make RL agents more efficient. The most relevant prior work is by <ref type="bibr" target="#b25">Martin, Sood, and Riedl (2018)</ref>, who use commonsense rules to build agents that can play tabletop role-playing games. However, unlike our work, the commonsense rules in this work are manually engineered.</p><p>Leveraging Commonsense: Recently, there has been a lot of work in NLP to utilize commonsense for QA, NLI, etc. <ref type="bibr" target="#b32">(Sap et al. 2019;</ref><ref type="bibr" target="#b35">Talmor et al. 2018)</ref>. Many of these approaches seek to effectively utilize ConceptNet by reducing the noise retrieved from it <ref type="bibr" target="#b19">(Lin et al. 2019;</ref><ref type="bibr" target="#b17">Kapanipathi et al. 2020)</ref>. This is also a key challenge in TWC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We created a novel environment (TWC) to evaluate the performance on RL agents on text-based games requiring commonsense knowledge. We introduced a framework of agents which tracks the state of the world; uses the sequential context to dynamically retrieve relevant commonsense knowledge from a knowledge graph; and learns to combine the two different modalities. Our agents equipped with common sense achieve their goals with greater efficiency and less exploration when compared to a text-only model, thus showing the value of our new environments and models. There-fore, we believe that our TWC environment provides interesting challenges and can be effectively used to fuel further research in this area.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reproducibility</head><p>To ensure the wide and unrestricted usage of the TWC environment, we release the TWC environment (with anonymized human annotations), code to generate text-based games and the sample agents used in this paper here: https: //github.com/IBM/commonsense-rl.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Overlap between TWC and ConceptNet</head><p>There is definitely some overlap between the resources used to build TWC and ConceptNet. However, as we discuss below, the overlap is limited and it is non-trivial for the agents to explore the knowledge graph and retrieve relevant commonsense knowledge. Indeed, only 12.2% of the goal entitylocation pairs defined in the TWC dataset can be directly matched to a single triplet in ConceptNet. Hence, we can state that it is fair and challenging to use ConceptNet as an external source of information. At the same time, we claim that external commonsense knowledge sources can be actually useful in solving text-based games. We submit that 85.9% of the unique entities in TWC match exactly one node in ConceptNet. Moreover, 66.1% of the time, the goal location of a given entity is in its 3-hop neighborhood in ConceptNet (42.7% for a 2-hop neighborhood). This shows that an external source of commonsense like ConceptNet can help to reduce exploration while solving the games, but needs to be explored effectively. As an example, with reference to <ref type="figure">Figure 8</ref>, the relation between the entity cap and the goal location hat_rack can be derived from ConceptNet by following the path: cap → relatedTo → head → relatedTo → hat → atLocation → hat_rack.</p><p>-= Laundry Room =-You find yourself in a laundry room. An usual one. Okay, just remember what you're here to do, and everything will go great.</p><p>You make out a washing machine. But the thing is empty. What a horrible day! You make out a clothes drier. The clothes drier is empty! This is the worst thing that could possibly happen, ever! You scan the room, seeing a suspended shelf. Unfortunately, there isn't a thing on it. You see a work table. On the work table you can see a pair of dirty gray underpants. You make out a bench. Looks like someone's already been here and taken everything off it, though. Aw, here you were, all excited for there to be things on it! You are carrying nothing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&gt; take the dirty gray underpants from the work table</head><p>You take the dirty gray underpants from the work table.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&gt; insert the dirty gray underpants into the washing machine</head><p>You put the dirty gray underpants into the washing machine.</p><p>Your score has just gone up by one point. <ref type="figure">Figure 6</ref>: Example of a game walkthrough belonging to the easy difficulty level. Best viewed in colors. Highlights are not available to the agents and are shown for illustrative purpose only.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Sample TWC games</head><p>In this section, we show and analyze an example of a TWC game instance from each difficulty level. <ref type="figure" target="#fig_5">Figures 6, 2, and  7</ref> provide such examples together with the optimal solution to each of the analyzed games. In all figures, we highlight all objects (in red), their candidate locations (in green) and the actions taken by the agent (in blue). Note that this information is not available to the agent and is only used for illustrative purposes. <ref type="figure">Figure 6</ref> shows a walk-through of an easy game. This game has only 1 room and 1 object. We recall that this holds for all the games in the easy difficulty level. The game takes place in the Laundry Room, and the goal of the agent is to identify the correct location for the only object, in this case the dirty gray underpants. As all the easy games, the agent can reach the goal with a sequence of steps consisting of only two actions. The first action is used by the agent to take the object, and then the second action is aimed at putting the object in its goal location. In general, the goal location is not unique, but in the example shown in <ref type="figure">Figure  6</ref>, there is only one correct location, namely the washing machine. Commonsense knowledge is required in the second step in order to detect the correct location among all the possible candidates.</p><p>The relatively large number of possible locations makes the easy games more challenging than they might look like. In our example, the locations that are not considered commonsensical for the dirty gray underpants are the following: clothes drier, shelf, work table and bench. Note that the clothes drier could have been a commonsensical location for the entity gray underpants, but the attribute dirty plays a key role. This shows that incorporating only knowledge in the form of single facts extracted from the knowledge graph is not sufficient to solve the games. On the contrary, the agent needs to aggregate commonsense knowledge from multiple triples in the knowledge graph, as previously discussed in Section A. <ref type="figure">Figure 2</ref> shows an example of a more complex game belonging to the medium difficulty level. This game is the same that the graphs in <ref type="figure">Figure 8</ref> refer to. All medium-level games have only 1 room and either 2 or 3 objects. The game shown in <ref type="figure">Figure 2</ref> has 3 objects, namely a pair of climbing shoes, a brown cap and a white cap. The goal locations for these objects are shown in <ref type="figure">Figure 8a</ref> and need to be selected from a pool of 5 candidate locations. However, please notice that candidate locations and objects are not provided explicitly to the agent and need to be extracted from the natural language observations. A total of 6 steps is required to solve the game in the optimal case. These actions are reported in <ref type="figure">Figure 2</ref>. We can see that, similarly to what we have seen for the easy games, 2 steps for each object are needed. Every time that an object is placed in its goal location, the agent receives a reward, but no reward is given for the action of taking an object. Hence, the maximum final score that the agent can achieve is always equal to the number of objects, in this case 3.</p><p>Finally, <ref type="figure" target="#fig_5">Figure 7</ref> shows an example of the most complex games in TWC, namely the hard games. The game includes two rooms (Kitchen and Backyard) and the agent needs to place a total of 7 objects in the corresponding goal location. At the beginning of the game, the agent is already carrying an object (some milk), so it only needs to find 6 of the remaining objects. Since the game has more than 1 room, reaching the final goal may require more than 2 steps for each object. This happens because some objects may need to be carried across rooms and the in this case the agent has to visit back the initial room. In this examples, the wet azure skirt in the Kitchen has to be carried back to the the Backyard and placed in the clothesline. The provided optimal solution to the analysed game consists of the 15 actions reported in <ref type="figure" target="#fig_5">Figure 7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Visualizing Attention Over the Commonsense Subgraph</head><p>Our approach integrates commonsense knowledge dynamically with the context information through an attention mechanism. We can visualize the attention weights (from the general attention in the last layer) by the Text + Com- There is an open sliding patio door leading west.</p><p>You are carrying: some milk &gt; take the wet white jumper from the patio chair You can see a fridge. The fridge is empty! This is the worst thing that could possibly happen, ever! As if things weren't amazing enough already, you can even see a kitchen cupboard. There is an open sliding patio door leading east.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&gt; insert the milk into the fridge</head><p>You put the milk into the fridge.</p><p>Your score has just gone up by one point.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&gt; insert the spoon into the cutlery drawer</head><p>You put the spoon into the cutlery drawer.</p><p>Your score has just gone up by one point.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&gt; insert the clean pot into the cupboard</head><p>You put the clean pot into the cupboard.</p><p>Your score has just gone up by one point.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&gt; take the dirty pot from the dining table</head><p>You take the dirty pot from the dining table.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&gt; insert the dirty pot into the dishwasher</head><p>You put the dirty pot into the dishwasher.</p><p>Your score has just gone up by one point.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&gt; take the wet azure skirt from the chair</head><p>You take the wet azure skirt from the chair.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&gt; take the can opener from the counter</head><p>You take the can opener from the counter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&gt; insert the can opener into the cupboard</head><p>You put the can opener into the cupboard.</p><p>Your score has just gone up by one point. There is an open sliding patio door leading west.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&gt; put wet azure skirt on clothesline</head><p>You put the wet azure skirt on the clothesline.</p><p>Your score has just gone up by one point. monsense agent on the commonsense graph to show how the agent is using the commonsense knowledge while interacting with TWC games. We show the visuals for a specific game where the goal of the agent is to put the climbing shoes in the shoe cabinet, and the brown and white caps in the hat rack (see <ref type="figure">Figure 8a</ref>). The full game corresponding to this visualization was outlined in <ref type="figure">Figure 2</ref>. The attention maps for this instance are shown in <ref type="figure">Figure 8b</ref>. We observe that the model pays attention to relevant concepts such as "shoe", "hat", "hat rack", "hat stand", etc. This figure thus offers a qualitative illustration of how commonsense knowledge is used by the Text + Commonsense agent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Kitchen Cleanup Task: Full vs Evolve Commonsense Subgraph</head><p>Unlike in the previous works <ref type="bibr" target="#b0">(Adhikari et al. 2020</ref>; Ammanabrolu and Hausknecht 2020), we do not assume that the entities used in the games are known beforehand. This poses an interesting question: does the commonsense-based agents would benefit from (1) having access to the full commonsense subgraph extracted at the beginning of the game using the aforementioned entities list or building the extracted commonsense subgraph sequentially (evolve) based on the entities seen so far in the game. In this section, we demonstrate a very simple experiment to show why we choose evolve setting for extracting the relevant commonsense subgraph. We used the TextWorld <ref type="bibr" target="#b8">(Côté et al. 2018</ref>) environment to generate a specific game instance similar to those in TWC but used information directly from ConceptNet, and has been manually generated by an expert. We call it Kitchen Cleanup. We generate the game with 10 objects relevant to the game, and 5 distractor objects spread across the room. As before, the goal of the agent is to tidy the room (kitchen) by putting the objects in the right place. We create a set of realistic kitchen cleanup goals for the agent: for instance, take apple from the table and put apple inside the refrigerator. Since information on concepts that map to the objects in the room is explicitly provided in ConceptNet (Apple → AtLocation → Refrigerator), the main hypothesis underlying the creation of this game is that leveraging the commonsense knowledge will let the agent achieve a higher reward while reducing the number of interactions with the environment.</p><p>The agent is presented with the textual description of a kitchen, consisting of the location of different objects in the kitchen and their spatial relationship to the other objects. The agent uses this information to select the next action to perform in the environment. Whenever the agent takes an object and puts it in the target location, it receives a reward and its total score goes up by one point. The maximum score that can be achieved by the agent in this kitchen cleanup task is equal to 10. In addition to the textual description, we use the commonsense knowledge subgraph extracted from ConceptNet relevant to the text description (Full vs Evolve setting).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1 Results on Kitchen Cleanup</head><p>As explained earlier, we consider two different knowledgeaware agents based on how/when we extract the commonsense subgraph. We consider that the first commonsense agent has access to the entities used in Kitchen cleanup game. Given the entities list, the agent generates a full commonsense subgraph before the start of the game. We call this model KG_Full. Our original model (Text+Commonsense in the main paper) is called KG_Evolve to point that the commonsense subgraph is generated at each time step and evolves over time based on the exploration.</p><p>As before, we compare our knowledge-aware RL agents (KG_Full and KG_Evolve) against two baselines for performance comparison: Random, where the agent chooses an action randomly at each step; and Simple (Text-only), where the agent chooses the next action using the text description only and ignores the commonsense knowledge graph. The knowledge-aware RL agents, on the other hand, use the commonsense knowledge graph to choose the next action. The graph is provided in either full-graph setting where all the commonsense relationships between the objects are given at the beginning of the game (KG_Full); or evolvegraph setting where only the commonsense relationship between the objects seen/interacted by the agent until the current steps are revealed (KG_Evolve). We record the average score achieved by each agent and the average number of interactions (moves) with the environment as our evaluation metrics. <ref type="figure" target="#fig_6">Figure 9</ref> shows the results for the kitchen cleanup task averaged over 5 runs, with 500 episodes per run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 Discussion</head><p>As expected, we see that agents that use the textual description and additionally the commonsense knowledge outperform the baseline random agent. We are also able to demonstrate clearly that the knowledge-aware agent outperforms the simple agent with the help of commonsense knowledge. The knowledge-aware agent with the evolve-graph setting outperforms both the simple agent as well as the agent with the full-graph setting. We believe that when an agent has access to the full commonsense knowledge graph at the beginning of the game, the agent gets overwhelmed by the amount of knowledge given; and is prone to making noisy explorations in the environment. On the other hand, feeding the commonsense knowledge gradually during the agent's learning process provides more focus to the exploration, and drives it toward the concepts related to the rest of the goals. These results can also be seen as an RL-centric agent-based validation of similar results shown in the broader NLP literature . We refer the reader to (Murugesan et al. 2020) on further discussion on this topic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Hyperparameters and Complexity</head><p>In addition to the hyperparameters reported in the paper, we used the following settings:</p><p>Hyperparameter Setting Batchsize 1 Hidden dimension 300 Max. # Steps 50 Discount Factor (γ) 0.9  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Illustration of a TWC game. The agent is given an initial observation (top left) and has to produce the list of actions (bottom right) that are necessary to achieve the goal (bottom center) using relevant commonsense knowledge from ConceptNet (bottom left).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Overview of our framework's decision making at any given time step. The framework comprises of the following components (visually shown in color): (a) action encoder which encodes all admissible actions a ∈ A , (b) observation encoder which encodes the observation o t , (c) context encoder, which encodes the dynamic context C t , (d) a dynamic common sense subgraph of ConceptNet G t C extracted by the agent, (e) a knowledge integration component, which combines the information from textual observations and the extracted common sense subgraph, and (f) an action selection module. ⊕ denotes the concatenation operator.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>(3) DRRN<ref type="bibr" target="#b14">(He et al. 2016)</ref> utilizes the relevance between the observation and action spaces for better convergence; and (4) KG-A2C (Ammanabrolu and Hausknecht 2020) uses knowledge of the game environment generated from the observation to guide the agent's exploration. For these Performance evaluation (showing mean and standard deviation averaged over 10 runs) for the three difficulty levels: Easy (left), Medium (middle), Hard (right) using normalized score and the number of steps taken.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Performance for the medium level (train-set) games (showing mean and standard deviation averaged over 3 runs) with the different techniques for the commonsense sub-graph extraction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>You take the wet white jumper from the patio chair.&gt; put the wet white jumper on the clotheslineYou put the wet white jumper on the clothesline.Your score has just gone up by one point. &gt; take the spoon from the BBQ You take the spoon from the BBQ. &gt; take the clean pot from the workbench You take the clean pot from the workbench. You find yourself in a kitchen. A normal kind of place. The room is well lit.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Example of a game walkthrough belonging to the hard difficulty level. Best viewed in colors. Highlights are not available to the agents and are shown for illustrative purpose only. A graph describing the goal state of a TWC game (a) and a visualization of the attention weights over the ConceptNet subgraph extracted at a specific timestep of the same game instance (b)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 9 :</head><label>9</label><figDesc>Simple = "Text model", "KG_evolve = Text+Commonsense" in main paper. Comparison of agents for the Kitchen Cleanup task with and without commonsense knowledge (ConceptNet) with average scores and average moves (averaged over 10 runs).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Statistics on the number of entities, supporters/containers, and rooms in the TWC domain.</figDesc><table><row><cell></cell><cell cols="2">Correctness Completeness</cell></row><row><cell>Rated Commonsense</cell><cell>669</cell><cell>47</cell></row><row><cell>Rated NOT Commonsense</cell><cell>31</cell><cell>253</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Statistics from the human annotations to verify TWC</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Figure 2 :</head><label>2</label><figDesc>Sample game walkthrough for a game with medium difficulty level. Best viewed in colors. Highlights are not available to the agents and are shown for illustrative purpose only.</figDesc><table><row><cell cols="4">signed to at least 3 distinct annotators. The annotators were</cell></row><row><cell cols="4">not given any other biasing information, and all annotators</cell></row><row><cell cols="4">worked independently. We show the overall agreement of</cell></row><row><cell cols="4">the annotators with TWC's goals in Table 2. The high agree-</cell></row><row><cell cols="4">ment from the annotators demonstrates that the goal o, r,</cell></row><row><cell cols="4">l triples reflect human commonsense knowledge.</cell></row><row><cell></cell><cell cols="3">#objects #Objects to find #Rooms</cell></row><row><cell>Easy</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell cols="2">Medium 2, 3</cell><cell>1, 2, 3</cell><cell>1</cell></row><row><cell>Hard</cell><cell>6, 7</cell><cell>5, 6, 7</cell><cell>1, 2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Specification of TWC games</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4</head><label>4</label><figDesc>± 0.00 0.36 ± 0.00 BERT-NSP 25.20 ± 0.00 0.76 ± 0.00 34.72 ± 0.00 0.88 ± 0.00 50.00 ± 0.00 0.52 ± 0.00 LSTM-A2C 17.59 ± 3.11 0.86 ± 0.04 37.99 ± 6.03 0.74 ± 0.11 49.21 ± 0.58 0.54 ± 0.04 DRRN . 18.88 ± 2.69 0.81 ± 0.08 33.41 ± 2.81 0.73 ± 0.06 46.20 ± 4.86 0.44 ± 0.01 KG-A2C 17.65 ± 3.62 0.85 ± 0.07 37.18 ± 4.86 0.72 ± 0.07 49.36 ± 7.50 0.46 ± 0.10 Text +Commonsense 14.18 ± 6.47 0.89 ± 0.10 34.67 ± 6.65 0.78 ± 0.07 48.45 ± 2.50 0.51 ± 0.10</figDesc><table><row><cell>),</cell></row></table><note>reports the results both for test games that be- long to the same distribution used at training time (INThe commonsense-enhanced agent outperforms the text- only agent in all cases. However, all agents including those that utilize commonsense knowledge show similar drop in performance from IN to OUT distribution. This is in con- trast to the use of the knowledge graphs in other NLP tasks such as textual entailment where knowledge graphs have shown to be robust to changes in the underlying (training and testing) environment (Kapanipathi et al. 2020; Chen et al. 2018). The task of designing knowledge-enabled agents that are robust to such changes is another open challenge for the community that can be evaluated by TWC. Results Summary: Our results establish that TWC isExternal Knowledge for Efficient RL: There have been few attempts on adding prior or external knowledge to RL approaches. Notably, Garnelo, Arulkumaran, and Shanahan</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table /><note>Generalization results for within distribution (IN) and out-of-distribution (OUT) games</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>BBQ. The BBQ is recent. On the BBQ you make out a wooden spoon. You see a clothesline. The clothesline is typical. But the thing is empty. Hm. Oh well, what's that over there? It looks like it's a patio chair. On the patio chair you can see a wet white jumper. You see a patio table. The patio table is stylish. The patio table appears to be empty. Hey, want to see a workbench? Look over there, a workbench. On the workbench you see a clean pot. Something scurries by right in the corner of your eye. Probably nothing.</figDesc><table><row><cell>-= Backyard =-</cell></row><row><cell>You've entered a backyard.</cell></row><row><cell>You see a</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>BBQ. The BBQ is recent. But there isn't a thing on it. Hm. Oh well You see a clothesline. The clothesline is typical. On the clothesline you can see a wet white jumper. What's that over there? It looks like it's a patio chair. Now why would someone leave that there? Unfortunately, there isn't a thing on it. You see a patio table. The patio table is stylish. The patio table appears to be empty. Hey, want to see a workbench? Look over there, a workbench. But oh no! there's nothing on this piece of junk.</figDesc><table><row><cell>&gt; go east</cell></row><row><cell>-= Backyard =-</cell></row><row><cell>You've entered a backyard.</cell></row><row><cell>You see a</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 5 :</head><label>5</label><figDesc>Hyperparameters used by the agentsThe agents were trained in parallel on two machines with the following specifications:</figDesc><table><row><cell cols="2">Resource Setting</cell></row><row><cell>CPU</cell><cell>Intel(R) Xeon(R) CPU E5-2690 v4 @ 2.60GHz</cell></row><row><cell>Memory</cell><cell>128GB</cell></row><row><cell>GPUs</cell><cell>2 x NVIDIA Tesla V100 16 GB</cell></row><row><cell>Disk1</cell><cell>100GB</cell></row><row><cell>Disk2</cell><cell>600GB</cell></row><row><cell>OS</cell><cell>Ubuntu 18.04-64 Minimal for VSI.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 6 :</head><label>6</label><figDesc>Resources used by the agentsEach agent was trained on a single GPU for approximately 12 hours for the Text agent and 16 hours for the Text + Commonsense agent for each run.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">t , . . . , x N t ,where each x k t ∈ R d is the word embedding of the k-th observed token o k t , k = 1, . . . , N. Then, a (bidirectional) GRU encoder<ref type="bibr" target="#b7">(Cho et al. 2014</ref>) is used to process the sequence x 1 t , . . . , x N t to get the representation of the current observa-tion: o t = h N t , where h k t = GRU(h k−1 t ,x k t ), for k = 1, . . . , N. In a similar way, given the set A t of admissible actions at time step t, we learn representations of each action a ∈ A t .</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">The optimal number of steps were computed by considering the objects already in the agent's possession, the number of objects to "put" (goals), and the number of rooms in the instance.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Adhikari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-A</forename><surname>Côté</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zelinka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-A</forename><surname>Rondeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Laroche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Poupart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.09127</idno>
		<title level="m">Learning Dynamic Knowledge Graphs to Generalize on Text-Based Games</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">LeDeepChef: Deep Reinforcement Learning Agent for Families of Text-Based Games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Adolphs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
		<idno>ArXiv abs/1909.01646</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Graph Constrained Reinforcement Learning for Natural Language Action Spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ammanabrolu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hausknecht</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=B1x6w0EtwH" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Playing Text-Adventure Games with Graph-Based Deep Reinforcement Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ammanabrolu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Long and Short Papers</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3557" to="3565" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Transferring knowledge as heuristics in reinforcement learning: A case-based approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Bianchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Celiberto</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Matsuura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>De Mantaras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">226</biblScope>
			<biblScope unit="page" from="102" to="121" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning to win by reading manuals in a monte-carlo framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="661" to="704" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Neural natural language inference models enhanced with external knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-H</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Inkpen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ç</forename><surname>Gülçehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/d14-1179</idno>
		<ptr target="https://doi.org/10.3115/v1/d14-1179" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>Moschitti, A.</editor>
		<editor>Pang, B.</editor>
		<editor>and Daelemans, W.</editor>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-10-25" />
		</imprint>
	</monogr>
	<note>A meeting of SIGDAT, a Special Interest Group of the ACL</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">TextWorld: A Learning Environment for Text-based Games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-A</forename><surname>Côté</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kádár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kybartas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Fine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hausknecht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">E</forename><surname>Asri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Adada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Trischler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>CoRR abs/1806.11532</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Commonsense reasoning and commonsense knowledge in artificial intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Marcus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="92" to="103" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/N19-1423/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019</title>
		<editor>Burstein, J.</editor>
		<editor>Doran, C.</editor>
		<editor>and Solorio, T.</editor>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06-02" />
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">What Can You Do with a Rock? Affordance Extraction Viaword Embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Fulda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ricks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Murdoch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wingate</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>AAAI Press</publisher>
			<biblScope unit="volume">9780999241103</biblScope>
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Garnelo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Arulkumaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shanahan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.05518</idno>
		<title level="m">Towards deep symbolic reinforcement learning</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The ecological approach to the visual perception of pictures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Gibson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Leonardo</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="227" to="235" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep Reinforcement Learning with a Natural Language Action Space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ostendorf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1621" to="1630" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Integrated common sense learning and planning in POMDPs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Juba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3276" to="3312" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Planning and acting in partially observable stochastic domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">P</forename><surname>Kaelbling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Littman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Cassandra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial intelligence</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="99" to="134" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Infusing Knowledge into the Textual Entailment Task Using Graph Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kapanipathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Thost</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Whitehead</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Abdelaziz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fadnis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gunasekara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Makni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mattei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Talamadupula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fokoue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)</title>
		<meeting>the AAAI Conference on Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Content analysis: An introduction to its methodology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Krippendorff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>Sage publications</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.02151</idno>
		<title level="m">Kagnet: Knowledge-aware graph networks for commonsense reasoning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Self-improving reactive agents based on reinforcement learning, planning and teaching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="293" to="321" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Reinforcement learning for robots using neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
		<respStmt>
			<orgName>Carnegie-Mellon Univ Pittsburgh PA School of Computer Science</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">ConceptNet-a practical commonsense reasoning tool-kit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BT technology journal</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="211" to="226" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Knowing when to look: Adaptive attention via a visual sentinel for image captioning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="375" to="383" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Effective Approaches to Attention-based Neural Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D15-1166</idno>
		<ptr target="https://www.aclweb.org/anthology/D15-1166" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1412" to="1421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Dungeons and DQNs: Toward Reinforcement Learning Agents that Play Tabletop Roleplaying Games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riedl</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-2321/paper4.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Workshop on Intelligent Narrative Technologies and Workshop on Intelligent Cinematography and Editing co-located with 14th AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment, INTWICED@AIIDE 2018</title>
		<editor>Wu, H.</editor>
		<editor>Si, M.</editor>
		<editor>and Jhala, A.</editor>
		<meeting>the Joint Workshop on Intelligent Narrative Technologies and Workshop on Intelligent Cinematography and Editing co-located with 14th AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment, INTWICED@AIIDE 2018<address><addrLine>Alberta, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-11-13" />
			<biblScope unit="volume">2321</biblScope>
		</imprint>
	</monogr>
	<note>CEUR Workshop Proceedings</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Programs with common sense</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Mccarthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Teddington Conference on the Mechanization of Thought Processes</title>
		<imprint>
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Asynchronous methods for deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Badia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Harley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In International conference on machine learning</title>
		<imprint>
			<biblScope unit="page" from="1928" to="1937" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murugesan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Atzeni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shukla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sachan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kapanipathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Talamadupula</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.00811</idno>
		<title level="m">Enhancing Textbased Reinforcement Learning Agents with Commonsense Knowledge</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Language understanding for text-based games using deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.08941</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Glove: Global Vectors for Word Representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/d14-1162</idno>
		<ptr target="https://doi.org/10.3115/v1/d14-1162" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>Moschitti, A.</editor>
		<editor>Pang, B.</editor>
		<editor>and Daelemans, W.</editor>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-10-25" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
	<note>A meeting of SIGDAT, a Special Interest Group of the ACL</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Language Models are Unsupervised Multitask Learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Atomic: An atlas of machine commonsense for if-then reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Le Bras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Allaway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lourie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rashkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Roof</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="3027" to="3035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Bidirectional attention flow for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kembhavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01603</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">ConceptNet 5.5: An Open Multilingual Graph of General Knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Speer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Havasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4444" to="4451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Herzig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lourie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.00937</idno>
		<title level="m">Commonsenseqa: A question answering challenge targeting commonsense knowledge</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Graph Attention Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=rJXMpikCZ" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Sample efficient actor-critic with experience replay</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Bapst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Heess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Munos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Freitas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01224</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Understanding natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Winograd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive psychology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="191" />
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Qanet: Combining local convolution with global self-attention for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.09541</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
