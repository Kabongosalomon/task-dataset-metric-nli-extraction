<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">EEG SIGNAL DIMENSIONALITY REDUCTION AND CLASSIFICATION USING TENSOR DECOMPOSITION AND DEEP CONVOLUTIONAL NEURAL NETWORKS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019">2019. OCT. 13-16, 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mojtaba</forename><surname>Taherisadr</surname></persName>
							<email>s:taherisadr@knights</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical &amp; Computer Engineering</orgName>
								<orgName type="institution">University of Central Florida</orgName>
								<address>
									<settlement>Orlando</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohsen</forename><surname>Joneidi</surname></persName>
							<email>joneidi@ece</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical &amp; Computer Engineering</orgName>
								<orgName type="institution">University of Central Florida</orgName>
								<address>
									<settlement>Orlando</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nazanin</forename><surname>Rahnavard</surname></persName>
							<email>nazanin@ece.ucf.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical &amp; Computer Engineering</orgName>
								<orgName type="institution">University of Central Florida</orgName>
								<address>
									<settlement>Orlando</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">EEG SIGNAL DIMENSIONALITY REDUCTION AND CLASSIFICATION USING TENSOR DECOMPOSITION AND DEEP CONVOLUTIONAL NEURAL NETWORKS</title>
					</analytic>
					<monogr>
						<title level="j" type="main">IEEE INTERNATIONAL WORKSHOP ON MACHINE LEARNING FOR SIGNAL PROCESSING</title>
						<meeting> <address><addrLine>PITTSBURGH, PA, USA</addrLine></address>
						</meeting>
						<imprint>
							<date type="published" when="2019">2019. OCT. 13-16, 2019</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T11:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-EEG</term>
					<term>Convolutional Neural Networks</term>
					<term>Time-frequency</term>
					<term>Tensor Data Analysis</term>
					<term>Dimensionality Re- duction</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A new deep learning-based electroencephalography (EEG) signal analysis framework is proposed. While deep neural networks, specifically convolutional neural networks (CNNs), have gained remarkable attention recently, they still suffer from high dimensionality of the training data. Two-dimensional input images of CNNs are more vulnerable to be redundant versus one-dimensional input time-series of conventional neural networks. In this study, we propose a new dimensionality reduction framework for reducing the dimension of CNN inputs based on the tensor decomposition of the time-frequency representation of EEG signals. The proposed tensor decomposition-based dimensionality reduction algorithm transforms a large set of slices of the input tensor to a concise set of slices which are called super-slices. Employing super-slices not only handles the artifacts and redundancies of the EEG data but also reduces the dimension of the CNNs training inputs. We also consider different timefrequency representation methods for EEG image generation and provide a comprehensive comparison among them. We test our proposed framework on HCB-MIT data and as results show our approach outperforms other previous studies.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Electroencephalography (EEG) as a diagnostic tool has been widely used in a wide variety of applications <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">2]</ref>. Acquiring and analyzing EEG signals are challenging. Various algorithms have been developed to efficiently process the EEG data, such as frequency analysis <ref type="bibr" target="#b3">[3]</ref>, wavelet transform <ref type="bibr" target="#b4">[4]</ref>, filter banks <ref type="bibr" target="#b5">[5]</ref>, hidden Markov models <ref type="bibr" target="#b6">[6]</ref>, support vector machines <ref type="bibr" target="#b7">[7]</ref>, and artificial neural networks <ref type="bibr" target="#b8">[8]</ref>.</p><p>All the stated methods involve extraction of hand-crafted features from EEG signals. Such hand-crafted feature extraction techniques are ad hoc, time-consuming and may not give the optimal representation of signals. Moreover, for feature extraction one requires a deep domain knowledge This material is based upon work supported by the National Science Foundation under Grant No. <ref type="bibr">CCF-1718195.</ref> to extract effective features. Moreover, the impact of noise interference and particularly artifacts (e.g, eye blink) on data makes the task of extracting relevant and robust features very challenging <ref type="bibr" target="#b9">[9]</ref>. Recently, deep learning approaches, especially CNNs, have gained significant attention in the field of EEG signal analysis due to their remarkable performances <ref type="bibr" target="#b10">[10,</ref><ref type="bibr" target="#b11">11]</ref>. CNNs handle the ad-hoc feature extraction process. They also combine the feature extraction and classification steps together. Although CNNs outperform other EEG signal processing methods, they still suffer from the curse of dimensionality of the input training data. Converting each one-dimensional (1D) EEG vector to a two-dimensional (2D) time-frequency (TF) image increases the dimension of the training data, which in turn, increases the required storage space significantly. The challenge of high dimensionality of the CNN model's training data is still open and has to be addressed to improve CNNs' efficiency in terms of storage space and running time.</p><p>Tensor decomposition is a powerful tool for analysis of high-dimensional data. The collection of TF representations of EEG channels generates a three-way tensor over time, frequency, and channel. This tensor is able to capture temporal and spectral correlations in addition to dependencies of different channels over its third way <ref type="bibr" target="#b12">[12]</ref>. EEG signals are very sensitive to noise. However, sensing long time series from a large number of channels facilitates utilization of dimensionality reduction techniques in which the impact of noise is diminished in the low-dimensional representation <ref type="bibr" target="#b13">[13]</ref>.</p><p>In this paper, we propose an algorithm based on low-rank decomposition of tensors to reduce the size of TF representations of EEG data. Low-rank assumption is a realistic side information for many scenarios in signal processing and communication systems <ref type="bibr" target="#b14">[14,</ref><ref type="bibr" target="#b15">15,</ref><ref type="bibr" target="#b16">16]</ref>. Firstly, a set of super-slices, which are robust superposition of all slices, is computed. Each slice of the input tensor corresponds to one channel. Then, the reduced-dimension super-slices are fed to a CNN in order to find the most efficient features and perform classification automatically. Our contributions in this study cab be summarized as following: tensor decomposition, and feeding the reduced data to a CNN to increase the model's efficiency and decrease its training complexity.</p><p>• Handling noise, artifacts, and redundancies of EEG signals by tensor decomposition-based dimensionality reduction. • Providing a comprehensive comparison and evaluation of different TF representation approaches for CNNbased EEG signal analysis.</p><p>Notations: Hereafter, vectors, matrices, and tensors are denoted by bold lowercase, bold uppercase, and bold underlined uppercase letters, respectively. A fiber is defined by fixing every index of a tensor but one. For example, for T ∈ R N ×M ×K , T :,j,k is a vector of length N , also known as the mode-1 fiber of T . T 1 , T 2 , and T 3 are unfolded matrices whose columns are fibers of the first, second and third dimensions of T , respectively. Slices are two-dimensional sections of a tensor, defined by fixing all but two indices. Moreover, • denotes the outer product. The n-mode product of a tensor X with a proper sized transformation matrix U is a tensor and denoted by X × n U . It transfers each fiber of the n th mode of tensor to the corresponding fiber in the final tensor. Mathematically, Y = X × n U ↔ Y n = U X n , in which X n and Y n are unfolded replicas of tensor X and Y w.r.t. different dimensions. If the vector, u is used instead of the transfer matrix, the result of the n-mode product will be a matrix which is called cotradication of tensor X w.r.t. vector u.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">TENSOR-BASED TIME-FREQUENCY DIMENSIONALITY REDUCTION OF EEG SIGNALS</head><p>In this section, we explain the steps of our proposed framework, as depicted in <ref type="figure" target="#fig_0">Fig. 1</ref>. Popularity of CNN has recently increased due to the fact that they outperform classic machine learning approaches. CNN requires 2D images as its input. For this purpose, EEG signals are segmented to equal chunks to then be converted to images using TF representation methods. Each TF method affects the overall performance of the system differently. Therefore, we consider different state-ofthe-art TF algorithms to not only optimize performance of our system, but also provide a comprehensive comparison on TF representations of EEG signals. On one hand, more training TF images improve the performance of the CNN models, but on the other hand, it adversely adds to the complexity of the computation. Hence, to reduce the dimensionality of the generated TF images, we employ the tensor decomposition technique. Collecting TF representation of EEG segments over K channels, we generate a 3-way tensor over time, frequency, and channel. Tensor decomposition is capable of alleviating artifacts' effects and additionally is able to capture spectrotemporal correlations and dependencies of different channels of EEG signals on its third way. Therefore, as tensor is able to handle artifacts and redundancies of EEG data, we reduce the dimension of the decomposed tensor in its third way which is associated with EEG channels. After reducing the third dimension of the tensor to R (R &lt;&lt; K), we feed it to CNN to train the model for further predictions. Each step of our proposed algorithm is elaborated in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Time-frequency representation</head><p>Time-frequency (TF) analysis of an EEG signal is calculating the spectrum at regular time intervals to identify the time at which different frequency components present. TF is a suitable representation for non-stationary and multi-component EEG signals because of its ability to describe the energy distribution of the signals over time and frequency simultaneously. Previous studies have applied a large number of TF approaches to select a proper methodology for their application, helping to improve the resolution, robustness, precision, or performance. Based on the previous studies, the suitability of a TF approach is data-and application-oriented <ref type="bibr" target="#b17">[17]</ref>. A review of the recent methods for TF representation reveals that they can be categorized in six groups as follows: Gaussian kernel (GK), Wigner-Ville (WV), spectrogram (SPEC), modified-B (MB), smoothed-WV (SWV), and separable kernel (SPEK). Reduced interference approaches such as Smoothed-WV are capable of improving the quality of the representation. This is because decreasing the interference results in a reduction in the effect of cross-terms <ref type="bibr" target="#b18">[18]</ref>. Our aim is to assess the mentioned state-of-the-art approaches to determine their performance regarding our specific application in this study (i.e., CNN-based EEG classification).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Tensor-based Dimensionality Reduction</head><p>As shown in <ref type="figure" target="#fig_0">Fig. 1</ref>, the time series of each EEG channel is transformed to a TF representation. An efficient dimensionality reduction framework is necessary for processing a large set of 2D images generated from 1D EEG data using TF representation. Let the matrix X ∈ R T ×K denote the collection of all time series from K channels and the tensor X ∈ R T ×F ×K denote the collection of TF representations of the channels. Since time series of different channels are highly correlated, this matrix and the corresponding tensor can be approximated by their low-rank representations. In the matrix format, temporal correlation and correlation between channels can be captured via dimensionality reduction techniques such as principle component analysis (PCA). However, for the tensor representation there exist three types of correlation. Efficient dimensionality reduction of tensors implies employing tensor rank decomposition. It should be noted that, performing PCA on data structured in tensors requires matricization of tensors. After matricization of a tensor, correlation over the unfolded way of the tensor will be neglected. A dimensionality reduction framework that preserves the intrinsic structure of tensors and exploits low-rank tensor decomposition provides a more concise and robust low-dimensional representation. The CAN-DECOMP/PARAFAC (CP) decomposition of the tensor X into R rank-one tensors is given by  <ref type="formula" target="#formula_0">(1)</ref> holds is called the rank of X. <ref type="figure">Fig. 2</ref> shows the decomposition of a rank-R tensor into a summation of R rank-1 tensors. Definition of rank for tensors is similar to its definition for matrices, however, there are several fundamental differences between matrix rank decomposition (SVD) and tensor rank decomposition (CP) <ref type="bibr" target="#b20">[20]</ref>. These fundamental differences encourage us to keep the multi-way structure of the underlying tensor and perform dimensionality reduction utilizing tensor CP decomposition. Let z denote a mode-3 fiber of X. Linear combination of columns of matrix C is able to generate z. The representation of any fiber in the third way of X in terms of columns of C can be found by solving the problem ofz = argmiñ z z − Cz 2 2 . The closed-form solution w.r.t.</p><formula xml:id="formula_0">X = R r=1 a r • b r • c r ,<label>(1)</label></formula><p>z is equal to (C T C) −1 C T z. Transformation matrix from the original K-dimensional space to the reduced R-dimension representation is defined by P = (C T C) −1 C T . According to this transformation matrix, the original tensor can be reduced asX = X ×3 P . Here,X is the low-dimensional representation of X which is a set of super-slices. Mathematically speaking Here, P r,: indicates the r th row of P . Each super-slice is the contradiction of the original tensor w.r.t. the corresponding row of P . <ref type="figure" target="#fig_4">Fig. 3</ref> shows the relation between super-slices and the slices of the given tensor. Each row of matrix P indicates the weights for generating the corresponding superslice. Please note that we only reduced the dimension of the third way and the first and second dimensions are preserved in order to extract spectro-temporal patterns using CNN. Using this framework, number of EEG channels is reduced from K to only R super slices (K &gt;&gt; R).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Deep Convolutional Neural Networks (DCNN)</head><p>With CNNs we seek a general-purpose tool for brain-signal decoding capable of extracting a comprehensive set of features without the need for expert knowledge. Therefore, we developed a fully supervised CNN model for EEG data analysis. The model takes a super-slice ofX (an image) and generates a prediction probability of belonging to different classes (seizure or non-seizure). We train the model using labeled super-slices to minimize a Sof tM ax loss function with respect to network parameters such as weights and biases using a gradient descent method and network parameters are updated using back propagation. We used four main building blocks in the CNN model including convolution, pooling, rectified linear unit (ReLU), and fully connected layer. The primary purpose of convolution layer is to extract features from the input image. Convolution layer preserves the spatial relationship between pixels by learning image features using small squares of input data. The convolution layer performs convolution of input with a set of predefined filters.</p><p>Spatial pooling reduces the dimensionality of each feature map but retains the most important information. It can be of different types such as maximum and average. In case of Max pooling, we define a spatial neighborhood (for example, a 2 × 2 window) and take the largest element from the rectified feature map within that window. In practice, Max Pooling has been shown to work better <ref type="bibr" target="#b26">[26]</ref>.</p><p>The ReLU is a non-linear activation function that introduces the non-linearity when applied to the feature map. ReLU leaves the size of its input unchanged and it only maps the non-negative values to zero. An additional ReLU has been used after every convolution layer. In fully connected layer each neuron in one layer is connected to all neurons in the next layer. As the output from the convolutional and pooling layers represent high-level features of the input image, we utlize the fully connected layer to use these features for classifying the input image into various classes based on the training dataset <ref type="bibr" target="#b26">[26]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">FRAMEWORK EVALUATION AND RESULT ANALYSIS</head><p>We evaluate our proposed method on the CHB-MIT dataset <ref type="bibr" target="#b27">[27]</ref>. Different types of epileptic seizures and the diversity of patients contained in this dataset make it ideal for assessing the performance of our framework in realistic settings. In this study, for cross-patient detection, the goal is to detect whether a 30 second segment of signal contains a seizure or not, as annotated in the dataset. Different TF methods, as discussed in Section 2.1, have been considered to generate TF images from EEG segments. Parameters for GKD and MBD have been chosen as α = 0.8 and β = 0.02, respectively. These values have been selected based on the previous research studies and investigations on theoretical and practical applications of TF representation of EEG signal using GKD and MBD approaches <ref type="bibr" target="#b23">[23]</ref> (Sections 7.4 and 15.5). A Hanning window is chosen for SPEC and SWVD, with length F s/4 samples, where F s = 256. <ref type="figure" target="#fig_5">Fig. 4</ref> illustrates TF representations of a one second interval of EEG signal from one channel using different methods and abovementioned parameters. Next, Tensor composition has been generated by collecting TF representation of the previous step across all channels. The normalized error of CP decomposition is defined by</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Time (S)</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A)</head><formula xml:id="formula_1">normalized error = X − r a r • b r • c r F X F ,<label>(2)</label></formula><p>where, . F is the Frobenius norm. <ref type="figure" target="#fig_6">Fig. 5</ref> presents the normalized error of CP decomposition for EEG tensor data. As <ref type="figure" target="#fig_6">Fig. 5</ref> demonstrates, increasing the rank of CP decomposition (number of super-slices) results in a lower normalized error. As <ref type="figure" target="#fig_6">Fig. 5</ref> shows tioned in <ref type="bibr" target="#b24">[24]</ref> were followed. The designed model consists of several layers including (CONV, ReLU, POOL) and one fully connected layer as shown in <ref type="figure" target="#fig_7">Fig. 6</ref>. Two filter sizes including 2 × 2 and 3 × 3 were tested. ReLU activation layers were used across the CNN after each convolution and pooling pair to bring in element-wise non-linearity. In order to estimate the generalization accuracy of the predictive models on the unseen data, 10-fold cross validation (10-CV) was used. 10-CV divides the total input data of n samples into ten equal parts. There is no overlap between the test sample set (10% of data) with the validation and training sample set (90% of data). The latter set is further divided into 4:1 ratio of training and validation data samples. The sets were permuted over 10 iterations to generate an overall estimate of the generalization accuracy. The CNN model was trained using the training set and validation set and tested independently with the testing set. <ref type="table" target="#tab_1">Table 1</ref> reports the selected parameters to train the CNN model. Then, after defining the parameters of TF representation and CNN model we tested the performance of the designed framework. <ref type="figure">Fig. 7</ref>    proposed framework associated with different CNN parameters and TF approaches. F S indicates filter size and SPEK, GK, SWV, WV, MB, and SPEC are TF methods. Seven architectures with different number of layers from 6 to 12, and two filter sizes of 2 × 2 and 3 × 3 are considered. As results present, 10 layers of CNN, filter size of 3 × 3, and SWV TF method outperform other sizes and methods. We use these hereafter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Comparison with Other State-of-the-art and baseline algorithms</head><p>In this section we compare our proposed framework with other 1D and 2D baselines. First we consider 1D wavelet transformation as a 1D baseline and then we compare our framework with PCA as a 2D dimensionality reduction baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1.">Wavelet Transformation</head><p>We extract a set of features from the sub-bands of discrete wavelet transform (DWT). Low-and high-pass filters are repeatedly applied to the signal, followed by decimation by 2, to produce the sub-band tree decomposition to some desired level. DWT of 5 levels was applied to the EEG to reach the approximate frequency ranges of the α, β, δ, and θ sub-bands <ref type="bibr" target="#b25">[25]</ref>. After decomposing the signal in each window, features including average power, mean, and standard deviation of the coefficients were extracted from the sub-bands. Then we feed extracted features to 3 predictive models including complex decision tree (CDT), support vector machine (SVM), and K-nearest neighborhood (KNN). The choice of predictive methods was made based on different and complementary properties among them <ref type="bibr" target="#b30">[30]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">Principal component analysis</head><p>We applied PCA to 2D TF data to reduce the dimension and provide the results to compare with our proposed approach. We employed PCA to the TF data and analyzed the resulting principal components (PCs) in order to detect the most descriptive bases of artifacts data. Since the PC space is orthonormal, we can simply remove the dimensions without affecting others. Based on the results of PCA component contributions, we realized that most of the contribution to the variance of the data (&gt; 85%) was summarized in the first 15 principal components (PCs). Therefore, we kept the first 15 components of the data for the subsequent predictive model training. <ref type="figure" target="#fig_8">Fig. 8</ref> summarizes the results of the comparison between 1D and 2D methods considered in this study. It illustrates box plots of 10 iterations of 10-CV algorithm. For 1D analysis, as results show, wavelet transform using SVM outperforms others including KNN and CDT. The figure also provides comparison between PCA and the Tensor-based dimensionality reduction schemes and confirms that the tensor-based outperforms the PCA-based dimensionality reduction (callsification accuracy of 89.63% vs. 86.17%). Tensor considers all of the channels together and is capable of capturing temporal and spectral correlations in addition to dependencies of different channels over its third way. While PCA works on each TF image separately and it is prone to ignoring the correlations between different channels. Moreover, as <ref type="figure" target="#fig_8">Fig. 8</ref> shows, the tensor-based dimensionality reduction (TF-tenosr-CNN) framework, due to its capability of reducing the redundancies and handling artifacts, outperforms the TF-CNN framework without dimensionality reduction.</p><p>Comparing our result (89% of accuracy) with previous studies (less than 86% accuracy), our algorithm has improved the results of cross-patient seizures detection in CHB-MIT dataset <ref type="bibr" target="#b28">[28,</ref><ref type="bibr" target="#b29">29]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">CONCLUSION</head><p>In this study, we proposed a new tensor-based framework to enhance the classification accuracy and efficiency of the deep learning models, specifically convolutional neural networks (CNNs), for EEG signals. We proposed a tensor decomposition-based dimentionality reduction of timefrequency (TF) inputs of CNN model to improve its performance in terms of storage space and running time. Our proposed method transforms a large set of slices of the input tensor to a concise set of super-slices, which is capable of not only handling the artifacts and redundancies of the EEG data but also reducing the dimension of the CNNs training inputs. We also considered different TF approaches and evaluated their performances to provide a comprehensive comparison of different TF methods for this classification problem. We implemented our proposed method on a publicly available dataset (CHB-MIT). Our results showed the superiority of our scheme compared to the state-of-the-art methods and </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Flow chart of the proposed framework. First step visualizes the data acquisition and preprocessing of EEG. In the next step, each segment of the EEG is represented in time-frequency domain as the slices of a 3-way tensor. Finally, tensor decomposition-based technique reduces the tensor to a set of super-slices which is fed to a CNN to train the model and make the decision.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>in which, a r , b r and c r are called CP factors. Collection of all a r 's in columns of a matrix results in the matrix A and similarly we define B and C matrices. Mode-1 fibers are linear combination of columns of A and similarly mode-2 and mode-3 fibers are linear combination of columns of B and C, respectively. The minimum integer R for which</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>1 …Fig. 2 .</head><label>12</label><figDesc>Schematic of decomposition of a rank-R tensor to a summation of R rank-1 tensors.X :,:,r r th super-slice = X × 3 P r,: .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>The input tensor as a collection of slices is transformed to a set of super-slices. Each super-slice is a superposition of all slices and weights are driven from Matrix P = (C T C) −1 C T . For example, the first super-slice is summation of all slices weighted by the first row of P .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 .</head><label>4</label><figDesc>TF representations of a 1 second EEG signal using: A) SWV, B) GK, C) WV, D) SPEC, E) MB, and F) SPEK approaches.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 .</head><label>5</label><figDesc>, the rank around 15 falls into the interval of normalized error of [0.2, 0.3], which is acceptable for our application.For the DCNN model, the architecture guidelines as men-Normalized error of CP decomposition versus assumed rank of decomposition.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 6 .</head><label>6</label><figDesc>The CNN architecture proposed in this study. This structure has 10 layers and input image size is 256*256.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8 .</head><label>8</label><figDesc>Comparison of the classification accuracy of cross-patient seizure detection on CHB-MIT EEG dataset. Each box plot shows 10 iterations of 10 cross validation of the predictive model for the associated method. recent studies.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>depicts the classification accuracy of the</figDesc><table><row><cell>Inputs 3@256*256</cell><cell>Feature maps</cell><cell cols="2">Feature maps</cell><cell cols="2">Feature maps</cell><cell cols="2">Feature maps</cell><cell cols="2">Feature maps</cell><cell>Feature maps</cell><cell>Feature maps</cell><cell>Feature maps</cell><cell>Hidden units 100</cell><cell>Outputs 2</cell></row><row><cell></cell><cell cols="2">Conv+ReLU</cell><cell cols="2">Max-pool</cell><cell cols="2">Conv+ReLU</cell><cell cols="2">Max-pool</cell><cell cols="3">Conv+ReLU Max-pool Conv+ReLU</cell><cell>Flatten</cell><cell>connected Fully</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>CNN predefined parameters</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Parameter</cell><cell>Values</cell></row><row><cell></cell><cell></cell><cell cols="2">Learning Rate</cell><cell>0.001</cell></row><row><cell></cell><cell></cell><cell cols="3">Momentum Coefficient</cell><cell>0.9</cell></row><row><cell></cell><cell></cell><cell cols="2">No. of Feature Maps</cell><cell>32, 64</cell></row><row><cell></cell><cell></cell><cell cols="3">No. of Neurons in Fully Connected Layer</cell><cell>64</cell></row><row><cell></cell><cell></cell><cell cols="2">Batch Size</cell><cell>40</cell></row><row><cell></cell><cell></cell><cell cols="2">Epoch Number</cell><cell>19</cell></row><row><cell></cell><cell>100</cell><cell></cell><cell></cell></row><row><cell></cell><cell>80</cell><cell></cell><cell></cell></row><row><cell>Accuracy (%)</cell><cell>0 20 40 60</cell><cell cols="3">FS 2 FS 3 FS 2 FS 3 FS 2 FS 3 FS 2 FS 3 FS 2 FS 3 FS 2 FS 3 SPEK SPEK SWV SWV GK GK MB MB SPEC SPEC WV WV</cell></row><row><cell></cell><cell></cell><cell>12 layers</cell><cell>11 layers</cell><cell>10 layers</cell><cell>9 layers</cell></row><row><cell></cell><cell></cell><cell>8 layers</cell><cell>7 layers</cell><cell>6 layers</cell></row><row><cell cols="5">Fig. 7. Accuracy of EEG signal classification for different TF meth-</cell></row><row><cell cols="5">ods and different CNN parameters. Parameters are different number</cell></row><row><cell cols="5">of layers, and filter sizes are 2 × 2 (FS 2) and 3 × 3 (FS 3). SPEK,</cell></row><row><cell cols="5">SWV, GK, MB, SPEC, and WV indicate different TF representation</cell></row><row><cell cols="3">methods.</cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">EEG-Based Driver Distraction Detection via Game-Theoretic-Based Channel Selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Taherisadr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Dehzangi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Body Area Networks I</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="93" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cham</forename><surname>Springer</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">EEG Based Driver Inattention Identification via Feature Profiling and Dimensionality Reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Dehzangi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Taherisadr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Body Area Networks I</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="107" to="121" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Spectral information of EEG signals with respect to epilepsy classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Tsipouras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EURASIP Journal on Advances in Signal Processing</title>
		<imprint>
			<biblScope unit="volume">2019</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Single channel EEG artifact identification using twodimensional multi-resolution analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mojtaba</forename><surname>Taherisadr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omid</forename><surname>Dehzangi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hossein</forename><surname>Parsaei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">2895</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Focal EEG signal detection based on constant-bandwidth TQWT filter-banks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vipin</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anurag</forename><surname>Nishad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ram</forename><forename type="middle">Bilas</forename><surname>Pachori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Bioinformatics and Biomedicine (BIBM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Sensorimotor Cortex EEG signal classification using Hidden Markov Models and Wavelet Decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maheen</forename><surname>Mumtaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubashira</forename><surname>Afzal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleem</forename><surname>Mushtaq</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Symposium on Signal Processing and Information Technology (ISSPIT)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">A Comprehensive Analysis of 2D &amp; 3D Video Watching of EEG Signals by Increasing PLSR and SVM Classification Results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Negin</forename><surname>Manshouri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Temel</forename><surname>Kayikcioglu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.05636</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Neural network classification of EEG signal for the detection of seizure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaguftha</forename><surname>Yasmeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maya</forename><forename type="middle">V</forename><surname>Karki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd IEEE International Conference on Recent Trends in Electronics, Information &amp; Communication Technology (RTE-ICT)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Automatic EEG Blink Detection Using Dynamic Time Warping Score Clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Dehzangi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Melville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Taherisadr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Body Area Networks I</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="49" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep learning for Electroencephalogram (EEG) classification tasks: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Craik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongtian</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose Luis Pepe Contreras-</forename><surname>Vidal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of neural engineering</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Deep learning-based electroencephalography analysis: a systematic review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Yannick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.05498</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Tensor decomposition of EEG signals: a brief review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">D</forename><surname>Kuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">F</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Astikainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ristaniemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of neuroscience methods</title>
		<imprint>
			<biblScope unit="volume">248</biblScope>
			<date type="published" when="2015-06-15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Eye blink artifact removal in EEG using tensor decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Triantafyllopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Megalooikonomou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">InIFIP International Conference on Artificial Intelligence Applications and Innovations</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014-09-19" />
			<biblScope unit="page" from="155" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Union of low-rank subspaces detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Joneidi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ahmadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sadeghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rahnavard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IET Signal Processing</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="62" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">AIenabled Blockchain: An Outlier-aware Consensus Protocol for Blockchain-based IoT Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salimitari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Joneidi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chatterjee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.08177</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Global Communications Conference (GLOBECOM) 2019. arXiv preprint is available online</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Fast methods for recovering sparse parameters in linear low rank models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Esmaeili</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Amini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Marvasti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Global Conference on Signal and Information Processing (GlobalSIP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016-12" />
			<biblScope unit="page" from="1403" to="1407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Resolution measure criteria for the objective assessment of the performance of quadratic time-frequency distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boualem</forename><surname>Boashash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Sucic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Joint time frequency analysis in digital signal processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Flemming</forename><surname>Pedersen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Time-frequency signal analysis and processing: a comprehensive reference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boualem</forename><surname>Boashash</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>Academic Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Tensor decompositions and applications. SIAM review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">G</forename><surname>Kolda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">W</forename><surname>Bader</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009-08-05" />
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="455" to="500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Cs231n: Convolutional neural networks for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural networks</title>
		<imprint>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Sensor orientation invariant mobile gait biometrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunbin</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics (IJCB)</title>
		<imprint>
			<date type="published" when="2014" />
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
	<note>IEEE</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Time-frequency signal analysis and processing: a comprehensive reference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boualem</forename><surname>Boashash</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>Academic Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">IMUbased gait recognition using convolutional neural networks and multi-sensor fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Dehzangi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Taherisadr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Changalvala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">2735</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Automatic recognition of alertness level from EEG by using neural network and Wavelet coefficients</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdulhamit</forename><surname>Subasi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="701" to="711" />
		</imprint>
	</monogr>
	<note>Expert systems with applications 28</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Deep learning. nature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="page">436</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Amaral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Glass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Hausdorff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Ivanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Mietus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">B</forename><surname>Moody</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">E</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Physiobank</surname></persName>
		</author>
		<title level="m">PhysioToolkit, and PhysioNet: components of a new research resource for complex physiologic signals. Circulation</title>
		<imprint>
			<date type="published" when="2000-06-13" />
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="215" to="235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Automated epileptic seizure detection methods: a review study. InEpilepsyhistological, electroencephalographic and psychological aspects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">T</forename><surname>Tzallas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Tsipouras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Tsalikakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">C</forename><surname>Karvounis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Astrakas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Konitsiotis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tzaphlidou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012-02-29" />
		</imprint>
	</monogr>
	<note>IntechOpen</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Learning robust features using deep learning for automatic seizure detection. InMachine learning for healthcare conference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Thodoroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016-12-10" />
			<biblScope unit="page" from="178" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Combining pattern classifiers: methods and algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludmila</forename><forename type="middle">I</forename><surname>Kuncheva</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>John Wiley , Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
