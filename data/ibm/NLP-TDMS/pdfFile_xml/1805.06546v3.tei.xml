<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">THIS ARTICLE HAS BEEN PUBLISHED IN IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING 1 Joint Classification and Prediction CNN Framework for Automatic Sleep Stage Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-02-02">2 Feb 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huy</forename><surname>Phan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Fernando</forename><surname>Andreotti</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Navin</forename><surname>Cooray</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Student Member, IEEE</roleName><forename type="first">Oliver</forename><forename type="middle">Y</forename><surname>Ch√©n</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Student Member, IEEE</roleName><forename type="first">Maarten</forename><surname>De Vos</surname></persName>
						</author>
						<title level="a" type="main">THIS ARTICLE HAS BEEN PUBLISHED IN IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING 1 Joint Classification and Prediction CNN Framework for Automatic Sleep Stage Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2019-02-02">2 Feb 2019</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1109/TBME.2018.2872652</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T20:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-sleep stage classification</term>
					<term>joint classification and prediction</term>
					<term>convolutional neural network</term>
					<term>multi-task</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Correctly identifying sleep stages is important in diagnosing and treating sleep disorders. This work proposes a joint classification-and-prediction framework based on convolutional neural networks (CNNs) for automatic sleep staging, and, subsequently, introduces a simple yet efficient CNN architecture to power the framework 1 . Given a single input epoch, the novel framework jointly determines its label (classification) and its neighboring epochs' labels (prediction) in the contextual output. While the proposed framework is orthogonal to the widely adopted classification schemes, which take one or multiple epochs as contextual inputs and produce a single classification decision on the target epoch, we demonstrate its advantages in several ways. First, it leverages the dependency among consecutive sleep epochs while surpassing the problems experienced with the common classification schemes. Second, even with a single model, the framework has the capacity to produce multiple decisions, which are essential in obtaining a good performance as in ensemble-of-models methods, with very little induced computational overhead. Probabilistic aggregation techniques are then proposed to leverage the availability of multiple decisions. To illustrate the efficacy of the proposed framework, we conducted experiments on two public datasets: Sleep-EDF Expanded (Sleep-EDF), which consists of 20 subjects, and Montreal Archive of Sleep Studies (MASS) dataset, which consists of 200 subjects. The proposed framework yields an overall classification accuracy of 82.3% and 83.6%, respectively. We also show that the proposed framework not only is superior to the baselines based on the common classification schemes but also outperforms existing deep-learning approaches. To our knowledge, this is the first work going beyond the standard single-output classification to consider multitask neural networks for automatic sleep staging. This framework provides avenues for further studies of different neural-network architectures for automatic sleep staging.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Identifying the sleep stages from overnight Polysomnography (PSG) recordings plays an important role in diagnosing and treating sleep disorders, which affects millions of people <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>. Traditionally, this task has been done manually by experts via visual inspection which is tedious, time-consuming, and is prone to subjective error. Automatic sleep stage classification <ref type="bibr" target="#b2">[3]</ref>, that performs as well as manual scoring, can help to ease this task tremendously, therefore facilitating home monitoring of sleep disorders <ref type="bibr" target="#b3">[4]</ref>. <ref type="bibr">H</ref>   <ref type="figure">Figure 1</ref>: Illustration of (a) the standard classification approach, (b) the common classification approach with the contextual input of three epochs, and (c) the joint classification and prediction with the contextual output of three epochs proposed in this work.</p><p>The guiding principle of automatic sleep staging is to split the signal into a sequence of epochs, each of which is usually 30 seconds long, and the classification is then performed epoch-by-epoch. In order to uncover a sleep stage at each epoch, proper features need to be derived from the signal, such as electroencephalography (EEG). Traditionally, many features have been designed based on prior knowledge of sleep. These hand-crafted features range from time-domain features <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref> to frequency-domain features <ref type="bibr" target="#b5">[6]</ref>- <ref type="bibr" target="#b8">[9]</ref>, via features derived from nonlinear processes <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b9">[10]</ref>- <ref type="bibr" target="#b11">[12]</ref>. Using these features, the classification goal is often accomplished by conventional machine learning algorithms, such as Support Vector Machine (SVM) <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b12">[13]</ref>, k-nearest neighbors (k-NN) <ref type="bibr" target="#b6">[7]</ref>, Random Forests <ref type="bibr" target="#b13">[14]</ref>- <ref type="bibr" target="#b15">[16]</ref>.</p><p>The advent of deep learning and its astonishing progress in numerous domains have stimulated interest in applying them for automatic sleep staging. The power of deep networks lies in their great capability of automatic feature learning from data, thus avoiding the reliance on hand-crafted features. Significant progress on results obtained from different sleep staging benchmark using various deep learning techniques have been reported <ref type="bibr" target="#b16">[17]</ref>- <ref type="bibr" target="#b24">[25]</ref>, mirroring a relentless trend where learned features ultimately outperform and displace long-used hand-crafted features. CNN <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref>, the cornerstone of deep learning techniques, has been frequently employed for the task <ref type="bibr" target="#b17">[18]</ref>- <ref type="bibr" target="#b19">[20]</ref>. The weight sharing mechanism at the convolutional layers forces the shift-invariance of the learned features and greatly reduces the model's complexity, consequently leading to improvement of the model's generalization <ref type="bibr" target="#b25">[26]</ref>. Other network variants, such as Deep Belief Networks (DBNs) <ref type="bibr" target="#b27">[28]</ref>, Auto-encoder <ref type="bibr" target="#b20">[21]</ref>, Deep Neural Networks (DNNs) <ref type="bibr" target="#b22">[23]</ref>, have also been explored. Moreover, Recurrent Neural Networks (RNNs), e.g. Long Short-Term Memory (LTSM) <ref type="bibr" target="#b28">[29]</ref>, which are capable of sequential modelling, have been found efficient in capturing long-term sleep stage transition and are usually utilized to complement other network types, such as CNNs <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b21">[22]</ref> and DNNs <ref type="bibr" target="#b22">[23]</ref>. Standalone RNNs have also been exploited for learning sequential features of sleep <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b30">[31]</ref>. The classification is usually performed therein by the networks in an end-to-end fashion <ref type="bibr" target="#b17">[18]</ref>- <ref type="bibr" target="#b19">[20]</ref>; a separate classifier, such as SVM, can be used alternatively <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b31">[32]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. MOTIVATION AND CONTRIBUTIONS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Motivation</head><p>Sleep is a temporal process with slow stage transitions, implying continuity of sleep stages and strong dependency between consecutive epochs <ref type="bibr" target="#b32">[33]</ref>- <ref type="bibr" target="#b34">[35]</ref>. For instance, out of 228,870 epochs in the entire MASS dataset <ref type="bibr" target="#b35">[36]</ref> used in this work, 83.3% pairs of adjacent epochs have the same label. The ratio is still as high as 79.3%, when two epochs are separated by one epoch. This nature of sleep has inspired a widely adopted practice in neural-network-based sleep staging systems, namely the use of contextual input that augments a target epoch by its surrounding epochs (many-to-one) in the classification task <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b21">[22]</ref>. Common input context size is of three and five epochs <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b36">[37]</ref>. This classification scheme can also be interpreted as an extension of the standard classification setup, i.e. determining the sleep stage corresponding to a single epoch of input signals (oneto-one) <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b37">[38]</ref>. <ref type="figure">Figure 1</ref> (b) provides a schematic presentation of contextual input of three epochs in comparison with the standard one-to-one classification approach in Figure 1 (a). While multiple-epoch input does not always provide performance gains, as shown in our experiments, it poses a problem of inherent modelling ambiguity. That is, when training a network with contextual input, such as three epochs illustrated in <ref type="figure">Figure 1</ref> (b), it remains unclear whether the network is truly modelling the class distribution of the target epoch at the center or that of the left and right neighbor. In our experiment, such a network (i.e. the many-to-one baseline in Section V-C) achieves an accuracy of 82.1% in determining the labels of the center epochs. However, when aligning the network output with those labels of the left and right neighbor, the accuracy is just marginally lower, reaching 81.1% and 80.8%, respectively. Last but not least, the contextual input causes the network's computational complexity increase at a linear scale due to the enlarged input size.</p><p>In this work, we formulate sleep staging as a joint classification and prediction problem. In other words, this is equivalent to a one-to-many problem, which is an extension of the standard one-to-one classification scheme while being orthogonal to the common many-to-one classification scheme. With this new formulation, given a single target epoch as input, our objective is to simultaneously determine its label (classification) and its neighboring epochs' labels (prediction) in the contextual output, as demonstrated in <ref type="figure">Figure 1</ref> (c). By classification, we mean determining the label of an epoch given its information. In contrast, prediction implies determining the label of an epoch without knowing its information. The rationale behind this idea is that, given the strong dependency of consecutive epochs, using information of an epoch, we should be able to infer the label of its neighbors. The major benefit of the joint classification and prediction formulation are two-fold. First, with the single-epoch input, the employed model does not experience the modelling ambiguity and the computational overhead induced by the large contextual input as previously discussed. Second, the employed model can produce an ensemble of decisions, which is the key in our obtained state-of-the-art performance, with a negligible induced computational cost. Ensemble of models <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b39">[40]</ref>, a well-established method to improve the performance of a machine learning algorithm, has been found generalizable to automatic sleep staging, evidenced by conventional methods <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b40">[41]</ref> and recently developed deep neural networks <ref type="bibr" target="#b16">[17]</ref>. However, building many different models on the same data for model fusion is cumbersome and costly. Opposing to ensemble of models <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b40">[41]</ref>, in our joint classification and prediction formulation, the ensemble of decisions is produced with a single multi-task model. Afterwards, an aggregation method can be used to fuse the ensemble of decisions to produce a reliable final decision.</p><p>We further proposed a CNN framework to deal with the joint problem. Although the proposed framework is generic in the sense that any CNN can fit in, we employ a simple CNN architecture with time-frequency image input. The efficiency of this architecture for automatic sleep staging was demonstrated in our previous work <ref type="bibr" target="#b23">[24]</ref>. To suit the task of joint classification and prediction, we replace the CNN's canonical softmax layer with a multi-task softmax layer and introduce the multi-task loss function for network training. Without confusion, we will refer to the proposed framework as multi-task framework, joint classification and prediction framework, and one-to-many framework interchangeably throughout this article.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Contributions</head><p>The main contributions of this work are as follows.</p><p>(i) We formulate automatic sleep staging as a joint classification and prediction problem. The new formulation avoids the shortcomings of the common classification scheme while improving modelling performance.</p><p>(ii) A CNN framework is then proposed for the joint problem. To that end, we present and employ a simple and efficient CNN coupled with a multi-task softmax layer and the multi-task loss function to conduct joint classification and prediction.</p><p>(iii) We further propose two probabilistic aggregation methods, namely additive and multiplicative voting, to leverage ensemble of decisions available in the proposed framework. (iv) Performance-wise, we demonstrate experimentally good performance on two publicly available datasets: Sleep-EDF <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref> with 20 subjects and MASS <ref type="bibr" target="#b35">[36]</ref>, a large sleep dataset with 200 subjects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. EVALUATION DATASETS</head><p>We used two public datasets: Sleep-EDF Expanded (Sleep-EDF) and Montreal Archive of Sleep Studies (MASS) in this work and conducted analyses under both unimodal (i.e. singlechannel EEG) and multimodal conditions (i.e combinations of EEG, EOG, and EMG channels). It should be noted that even though we selected the typical EEG, EOG, and EMG channels in our analyses, the proposed framework, however, can be used straightforwardly to study other signal modalities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Sleep-EDF Expanded (Sleep-EDF)</head><p>Sleep-EDF dataset <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref> consists of two subsets: (1) Sleep Cassette (SC) subset consisting of 20 subjects aged 25-34 aiming at studying the age effects on sleep in healthy subjects and (2) Sleep Telemetry (ST) subject consisting of 22 Caucasian subjects for study temazepam effects on sleep. We adopted the SC subset in this study. PSG recordings, sampled at 100 Hz, of two subsequent day-night periods are available for each subject, except for one subject (subject 13) who has only one-night data. Each 30-second epoch of the recordings was manually labelled by sleep experts according to the R&amp;K standard <ref type="bibr" target="#b43">[44]</ref> into one of eight categories {W, N1, N2, N3, N4, REM, MOVEMENT, UNKNOWN}. Similar to previous works <ref type="bibr" target="#b19">[20]</ref>- <ref type="bibr" target="#b21">[22]</ref>, N3 and N4 stages were merged into a single stage N3. MOVEMENT and UNKNOWN were excluded. Since full EMG recordings are not available, we only used the Fpz-Cz EEG and the EOG (horizontal) channels in our experiments. Only the in-bed parts (from lights off time to lights on time) of the recordings were included as recommended in <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b44">[45]</ref>, <ref type="bibr" target="#b45">[46]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Montreal Archive of Sleep Studies (MASS)</head><p>MASS comprises whole-night recordings from 200 subjects (97 males and 103 females with an age range of 18-76 years). These recordings were pooled from different hospital-based sleep laboratories. The available cohort 1 was divided into five subsets of recordings, SS1 -SS5. As stated in the seminal work <ref type="bibr" target="#b35">[36]</ref>, heterogeneity between subsets is expected. Opposing to the majority of previous works which targeted only one homogeneous subset of the cohort <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>, we experimented with all five subsets. Each epoch of the recordings was manually labelled by experts according to the AASM standard <ref type="bibr" target="#b32">[33]</ref> (SS1 and SS3) and the R&amp;K standard <ref type="bibr" target="#b43">[44]</ref> (SS2, SS4, and SS5). We converted them into five sleep stage {W, N1, N2, N3, and REM} as suggested in <ref type="bibr" target="#b44">[45]</ref>, <ref type="bibr" target="#b45">[46]</ref>. Those recordings with 20-second epochs were converted into 30-second ones by including 5-second segments before and after each epoch. We adopted and studied combinations of the C4-A1 EEG, an average EOG (ROC-LOC), and an average EMG (CHIN1-CHIN2) channels in our experiments. The signals, originally sampled at 256 Hz, were downsampled to 100 Hz.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. JOINT CLASSIFICATION AND PREDICTION CNN FRAMEWORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Overview</head><p>The proposed framework, with a schematic illustration shown in <ref type="figure" target="#fig_1">Figure 2</ref>, can be described in a stage-wise fashion. The raw signals of a certain epoch index n are first transformed into log-power spectra. The spectra are then preprocessed for frequency smoothing and dimension reduction using frequency-domain filter banks. The resulting channelspecific images are then stacked to form a multi-channel timefrequency image, denoted as X n . Subsequently, a multi-task CNN is exercised on the multi-channel time-frequency image for joint classification and context prediction. The former task is to maximize the conditional probability P (y n | X n ) which characterizes the likelihood of a sleep stage y n ‚àà L = {1, 2, . . . , Y }, where L denotes the label set of Y sleep stages. The latter one is to maximize the conditional probabilities (P (y n‚àíœÑ | X n ), . . . , P (y n‚àí1 | X n ), P (y n+1 | X n ), . . . , P (y n+œÑ | X n )) of the neighboring epochs in the output context size of 2œÑ + 1. The labels of the epochs in the output context, where (y n‚àíœÑ , . . . , y n , . . . , y n+œÑ ), can be obtained by probability maximization.</p><p>Formally, under this joint classification and prediction formulation, the CNN performs the one-to-many mappinƒù F : X n ‚Üí (y n‚àíœÑ , . . . , y n , . . . , y n+œÑ ) ‚àà L 2œÑ +1 .</p><p>(1)</p><p>Note that the order of the epochs in the neighborhood is encoded by the order of the output labels. This formulation is orthogonal to the common classification one with contextual input of size 2œÑ + 1, in which a network performs the manyto-one mapping</p><formula xml:id="formula_0">F : (X n‚àíœÑ , . . . , X n , . . . , X n+œÑ ) ‚Üí y n ‚àà L.<label>(2)</label></formula><p>Both formulations <ref type="formula">(1)</ref> and <ref type="formula" target="#formula_0">(2)</ref> can be interpreted as different extensions of the standard one-to-one classification scheme <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b37">[38]</ref>. They will reduce to the standard one when œÑ = 0. However, with our joint classification and prediction formulation, at a certain epoch index n there exists an ensemble of exact 2œÑ + 1 decisions, wherein one classification decision made by itself (i.e. X n ) and 2œÑ prediction decisions made by its neighbors (X n‚àíœÑ , . . . , X n‚àí1 , X n+1 , . . . , X n+œÑ ). These decisions can be aggregated to form the final decision that is generally better that any individual ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Time-Frequency Image Representation</head><p>Given a 30-second signal epoch (i.e. EEG, EOG, or EMG), we firstly transform it into a power spectrum using shorttime Fourier transform (STFT) with a window size of two seconds and 50% overlap. Hamming window and 256-point Fast Fourier Transform (FFT) are used. The spectrum is then converted to logarithm scale to produce a log-power spectrum image of size F √ó T , where F = 129 and T = 29.</p><p>For frequency smoothing and dimension reduction, the spectrum is filtered by a frequency-domain filter bank. Any frequency-domain filter bank, such as the regular triangular one <ref type="bibr" target="#b23">[24]</ref>, could serve this purpose. However, it is more favorable to learn the filter bank specifically for the task at hand. Our recent works in <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref> demonstrated that a filter bank learned by a DNN in a discriminative fashion is more competent than the regular one in automatic sleep staging. The learned filter bank is expected to emphasize the subbands that are more important for the task and attenuate those less important. Hence, we use the filter bank pretrained with a DNN for preprocessing here. One such filter bank with M = 20 filters is learned for each EEG, EOG, and EMG channel. Filtering the log-power spectrum image reduces its size to M √ó T . When multiple channels are used, we obtain one such time-frequency image for each channel. For generalization, we denote the time-frequency image as X ‚àà R P √óM√óT where P denotes the number of channels. P = 1, 2, 3 is equivalent to the cases when {EEG}, {EEG, EOG}, and {EEG, EOG, EMG} are employed, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Multi-Task CNN for Joint Classification and Prediction</head><p>Our recent work <ref type="bibr" target="#b23">[24]</ref> presented a simple CNN architecture that was shown efficient for sleep staging. We adapt this architecture here by tailoring the last layer, i.e. the multi-task softmax layer, to perform joint classification and prediction. The proposed CNN architecture is illustrated in <ref type="figure" target="#fig_2">Figure 3</ref>. Opposing to typical deep CNNs <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b21">[22]</ref>, the proposed CNN consists of only three layers: one over-time convolutional layer, one pooling layer, and one multi-task softmax layer. This simple architecture has three main characteristics. First, similar to those in <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b46">[47]</ref>, <ref type="bibr" target="#b47">[48]</ref>, its convolutional layer simultaneously accommodates convolutional kernels with varying sizes, and is therefore able to learn features at different resolutions. Second, the exploited 1-max pooling strategy at the pooling layer is more suitable for capturing the shift-invariance property of temporal signals than the common subsampling pooling since a particular feature P-channel time-freq. image</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Convolutional layer 1-max pooling layer</head><p>Multitask softmax layer could occur at any temporal position rather than in a local region of the input signal <ref type="bibr" target="#b46">[47]</ref>- <ref type="bibr" target="#b48">[49]</ref>. Third, opposing to the canonical softmax, the multi-task softmax layer is adapted to suit the joint classification and prediction. Furthermore, the multi-task loss is introduced for network training. Assume that we obtain a training set We use this training set to train the multi-task CNN for joint classification and context prediction.</p><formula xml:id="formula_1">T M P P√óM√ó3 ‚àà R w P√óM√ó5 ‚àà R w . . . . . . subtask i subtask j subtask k</formula><formula xml:id="formula_2">S = X (i) ni , (y (i) ni‚àíœÑ , . . . , y (i) ni , . . . , y (i) ni+œÑ ) N i=1 of size N</formula><p>1) Over-Time Convolutional Layer: Each 3-dimensional filter w ‚àà R P √óM√ów of the convolutional layer has the temporal size of w &lt; T while the frequency and channel size entirely cover the frequency and channel dimension of a multichannel time-frequency image input. The filter is convolved with the input image over time with a stride of 1. ReLU activation <ref type="bibr" target="#b49">[50]</ref> is then applied to the feature map.</p><p>The CNN is designed to have R filter sets with different temporal widths w to capture features at multiple temporal resolutions. Each filter consists of Q different filters of the same temporal width to allow the CNN to learn multiple complementary features. As a result, the total number of filters is Q √ó R.</p><p>2) 1-Max Pooling Layer: We employ 1-max pooling function <ref type="bibr" target="#b47">[48]</ref>, <ref type="bibr" target="#b48">[49]</ref> on a feature map produced by convolving a <ref type="figure">Figure 4</ref>: Ensemble of decisions available at the epoch index n made by the epochs</p><formula xml:id="formula_3">) | ( œÑ + n n P X y ) | ( œÑ + n P X œÑ + n y ) | ( œÑ + n P X œÑ +2 n y ... ... ... ... ... ... ... ... ) | ( n P X œÑ + n y ) | ( n n P X y ) | ( n P X œÑ ‚àí n y ) | ( œÑ ‚àí n n P X y ) | ( œÑ ‚àí n P X œÑ ‚àí n y ) | ( œÑ ‚àí n P X œÑ ‚àí2 n y</formula><formula xml:id="formula_4">X i in the neighborhood [n ‚àí œÑ, n + œÑ ], i.e. n ‚àí œÑ ‚â§ i ‚â§ n + œÑ .</formula><p>filter over an input image to retain the most prominent feature. Pooling all feature maps of Q √ó R filters results in a feature vector of size Q √ó R.</p><p>With the over-time convolution layer coupled with the 1max pooling layer, the CNN functions as a template learning and matching algorithm. The convolutional filters play the role of time-frequency templates that are tuned for the task at hand. Convolving a filter through time can be interpreted as template matching operation, resulting in a feature map that indicates how well the template is matched to different parts of the input image. In turn, 1-max pooling retains a single maximum value, i.e. the maximum matching score, of the feature map as the final feature.</p><p>3) Multi-Task Softmax Layer: Opposing to a classification network that typically uses the canonical softmax layer for classification, we propose a multi-task softmax layer to suit joint classification and prediction. The idea is that the network should be penalized for both misclassification and misprediction on a training example. The classification and prediction errors on a training example i is computed as the sum of the cross-entropy errors on the individual subtasks:</p><formula xml:id="formula_5">E (i) (Œ∏) = ni+œÑ n=ni‚àíœÑ y (i) n log ≈∑ (i) n (Œ∏) ,<label>(3)</label></formula><p>where Œ∏ and≈∑ denote the network parameters and the probability distribution outputted by the CNN, respectively. The network is trained to minimize the multi-task crossentropy error over N training samples:</p><formula xml:id="formula_6">E(Œ∏) = ‚àí 1 N N i=1 E (i) (Œ∏) + Œª 2 Œ∏ 2 2 .<label>(4)</label></formula><p>Here, Œª denotes the hyper-parameter that trades off the error terms and the ‚Ñì 2 -norm regularization term. For further regularization, dropout <ref type="bibr" target="#b50">[51]</ref> is also employed. The network training is performed using the Adam optimizer <ref type="bibr" target="#b51">[52]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Ensemble of Decisions and Aggregation</head><p>As previously mentioned, one major advantage of the proposed framework is the capacity to produce multiple decisions on a certain epoch even with a single model (the multi-task CNN in this case). Practically, the classification and prediction outputs on a certain epoch may be inconsistent as in ensembleof-models methods <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b39">[40]</ref>; aggregation of these multi-view decisions is necessary to derive a more reliable one. To that end, we study two probabilistic aggregation schemes: additive and multiplicative voting.</p><p>Let P (y n | X i ) denote the estimated probability output on the sleep stage y n ‚àà L at the epoch index n given the epoch X i in the neighborhood [n ‚àí œÑ, n + œÑ ], i.e. n ‚àí œÑ ‚â§ i ‚â§ n + œÑ , as illustrated in <ref type="figure">Figure 4</ref>. The likelihood P (y n ) obtained by additive and multiplicative voting is given by</p><formula xml:id="formula_7">P (y n ) = 1 2œÑ + 1 n+œÑ i=n‚àíœÑ P (y n | X i ),<label>(5)</label></formula><formula xml:id="formula_8">P (y n ) = 1 2œÑ + 1 n+œÑ i=n‚àíœÑ P (y n | X i ),<label>(6)</label></formula><p>respectively. Eventually, the predicted label≈∑ n is determined by likelihood maximization:</p><p>y n = arg max yn P (y n ), for y n ‚àà L.</p><p>Between the two aggregation schemes, the multiplicative one favors likelihoods of categories with consistent decisions and suppresses likelihoods of those categories with diverged decisions stronger than the additive counterpart <ref type="bibr" target="#b52">[53]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTS</head><p>We aim at achieving several goals in the conducted experiments. Firstly, we prove empirically the feasibility of predicting labels of the neighboring epochs in the output context concurrently with classifying the current one. Secondly, we demonstrate the advantages of the joint classification and prediction (i.e. many-to-one) formulation over the commonly adopted many-to-one scheme as well as the standard one-toone classification scheme. Thirdly, we provide performance comparison with various developed baseline systems as well as other deep-learning approaches recently proposed for sleep staging to illustrate the proposed framework's efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Experimental Setup</head><p>For Sleep-EDF, we conducted leave-one-subject-out cross validation. At each iteration, 19 training subjects were further divided into 15 subjects for training and 4 subject for validation. For MASS, we performed 20-fold cross validation on the MASS dataset. At each iteration, 200 subjects were split into training, validation, and test set with 180, 10, and 10 subjects, respectively. The sleep staging performance over 20 folds will be reported for both datasets.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Parameters</head><p>The parameters associated with the proposed CNN are given in <ref type="table" target="#tab_1">Table I</ref>. We varied the number of convolutional filters Q of the CNN in the set {100, 200, 300, 400, 500, 1000} to investigate its influence. Furthermore, we experimented with the output context size of 3 (equivalent to œÑ = 1). Influence of this parameter will be further discussed in Section VI.</p><p>The network implementation was based on Tensorflow framework <ref type="bibr" target="#b53">[54]</ref>. Graphic card NVIDIA GTX 1080 Ti was used for network training. The network was trained for 200 epochs with a batch size of 200. The learning rate was set to 10 ‚àí4 for the Adam optimizer. During training, the network that yielded the best overall accuracy on the validation set was retained for evaluation. Furthermore, we always randomly generated a data batch to have an equal number of samples for all sleep stages to mitigate the class imbalance issue commonly seen in sleep data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Baseline Systems</head><p>To manifest the advantages offered by the proposed frameworks, we constructed two baseline frameworks for comparison:</p><p>‚Ä¢ One-to-one: this baseline complies with the standard classification setup, taking a single epoch as input and producing a single decision on its label.</p><p>‚Ä¢ Many-to-one: this baseline conforms to the commonly adopted scheme with contextual input and outputs a single decision on a target epoch. We fixed the contextual input size to 3, i.e. we augmented a target epoch with two nearest neighbors on its left-and right-hand side. Both baseline frameworks were designed to maintain common experimental settings as those of the proposed oneto-many framework, i.e. the CNN architecture, the learned filter bank, etc. However, it is necessary to use the canonical softmax layer and the standard cross-entropy loss for their classification-only purpose.</p><p>We also developed and repeated the experiments with a typical deep CNN architecture as an alternative to the proposed CNN described in Section IV-C. This deep CNN baseline consists of 6 layers (2 convolutional layers, 2 subsampling layers, and 2 fully connected layers) with their parameters characterized in <ref type="table" target="#tab_1">Table II</ref>. For simplicity, we refer to our proposed CNN as 1-max CNN to distinguish from the deep CNN baseline. With these experiments, our goal is to show the generalizability of the proposed framework regardless the network base as well as the efficacy of the 1-max CNN in comparison to a typical deep CNN architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Classification vs prediction accuracy:</head><p>In this experiment, we seek to empirically validate the proposed framework by demonstrating the feasibility of context prediction. Since we employed the output context size of 3, without confusion, let us refer to the network's subtasks as classification, left prediction, and right prediction, which correspond to decisions on the input epoch, its left neighbor, and its right neighbor.</p><p>We show in <ref type="figure" target="#fig_5">Figure 5</ref> the accuracy rates of classification, left prediction, and right prediction subtasks obtained by the 1-max CNN (with varying number of convolutional filters Q) and the deep CNN baseline with the different number of input modalities P . Unlike the classification subtask, the CNNs do not have access to the signal information of the left and right neighboring epochs. As a result, inference for their labels relies solely on their dependency with the input epoch. It can be expected that the accuracy rates of the left and right prediction subtasks are lower than that of the classification subtask in most of the cases. Nevertheless, overall both CNNs maintain a good accuracy level in prediction relative to the classification accuracy, especially in multimodal cases (e.g. P = 2 for Sleep-EDF and P = 3 for MASS). More specifically, averaging over all Q and P , the left and right prediction accuracies of the 1-max CNN are only 2.9% and 1.4% lower than the classification accuracy on Sleep-EDF whereas the respective gaps of 2.2% and 1.3% are seen in MASS. Similar patterns can also be seen with the deep CNN baseline with the graceful degradation of 4.0% and 2.5% in Sleep-EDF and 3.3% and 2.2% in MASS correspondingly. These results strengthen the assumption about the dependency between neighboring PSG epochs and consolidate the feasibility of joint classification and prediction modelling.</p><p>2) Advantages of the joint classification and prediction: <ref type="figure" target="#fig_5">Figure 5</ref> also highlights the performance improvements obtained by the joint classification and prediction framework after the aggregation step in comparison to individual subtasks. Averaging over all P and Q, the 1-max CNN with additive voting leads to 2.8% and 4.5% absolute accuracy gains over the classification subtask's accuracy on Sleep-EDF and MASS, respectively. The gains yielded by the multiplicative voting are even better, reaching 3.0% and 4.7%, respectively. Accordingly, the deep CNN baseline produces 2.2% and 2.5% absolute gains with additive voting and 2.6% and 2.8% with multiplicative voting on the two datasets. Between two voting schemes, the performance gain of the multiplicative one is slightly better than that of the additive counterpart with a difference around 0.2 ‚àí 0.3% on both Sleep-EDF and MASS.   To demonstrate the advantages of the proposed framework over the common classification schemes, we further compare its performance and computational complexity with the oneto-one and many-to-one baseline schemes described in Section V-C. For simplicity, we utilized all available modalities (i.e. P = 3) in this experiment and made use of multiplicativevoting aggregation in the proposed framework. Additionally, we set the number of convolutional filters Q = 1000 when the 1-max CNN was employed. <ref type="figure" target="#fig_6">Figure 6</ref> depicts the overall accuracy obtained by the three frameworks and their computational complexity in terms of the training time. Note that we only included the training time of the first cross-validation fold as a representative here and the training time was expected to scale linearly with the amount of training data. Four important points should be noticed from the figure. Firstly, contextual input does not always help as the many-to-one baseline with the 1-max CNN experiences a performance drop of 0.6% absolute compared to the one-to-one on MASS compared to the one-to-one on MASS although it improves accuracy rates in other cases. Secondly, the proposed one-to-many framework consistently outperforms its counterparts. Adopting the 1-max CNN as the base, our framework outperforms the one-to-one and manyto-one opponents with 2.5% and 0.2% absolute in Sleep-EDF and 1.0% and 1.6% absolute in MASS, respectively. Similar gains of 2.5% and 1.0% in Sleep-EDF; 1.7% and 0.3% in MASS are achieved when the deep CNN baseline is used. Thirdly, between the network bases, the 1-max CNN surpasses the deep CNN baseline with an improvement of 2.6% absolute in Sleep-EDF and 0.9% absolute in MASS although its architecture is much simpler. Fourthly, concerning the computational complexity, three times larger input of the many-to-one baseline roughly triples the training time compared to that of the one-to-one. For instance, 4.0 hours versus 1.36 hours in MASS can be seen with the 1-max CNN. Differently, with the training time of 1.6 hours. Using the same network, the proposed framework only increases computing time by as small as 0.2 hours. The training time of the deep CNN baseline also exposes similar patterns. <ref type="table" target="#tab_1">Table III</ref> provides a comprehensive performance comparison on the experimental dataset using different metrics, including overall accuracy, kappa index Œ∫, average specificity, average sensitivity, and average macro F1-score (MF1). The comparison covers all combinations of different frameworks (i.e. the proposed and the baselines) and network bases (i.e. the proposed 1-max CNN   and the deep CNN baseline). As can be seen, the proposed one-to-many framework powered by the 1-max CNN (one-tomany + 1-max CNN) outperforms other combinatorial sys- <ref type="bibr" target="#b1">2</ref> Our implementation. Source code is also available at http://github.com/pquochuy/MultitaskSleepNet tems presented in this work on both datasets and over different combinations of modalities. There are occasional exceptions where using the 1-max CNN in the baseline frameworks yields marginally better average MF1 and Sensitivity than one-tomany + 1-max CNN, such as on MASS with P = 3; however, one-to-many + 1-max CNN remains optimal on other metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) Performance comparison:</head><p>To see an overall picture, in Tables IV and V we relate the proposed method's accuracy to those reported by previous works on the two datasets. With this comprehensive comparison, we also aim at providing a benchmark for future work.</p><p>As can be seen from <ref type="table" target="#tab_1">Table IV</ref>, the results on Sleep-EDF vary noticeably due to the lack of standardization in experimental setup. We observe two factors that greatly affects performance on this dataset: (1) independent/dependent testing and (2) whether or not using only in-bed parts of the recordings as recommended in <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b45">[46]</ref>. Dependent testing happens when data of a test subject is also involved in training, such as in Aboalayon et al. <ref type="bibr" target="#b2">[3]</ref>, and biases the evaluation results. In addition to in-bed parts (i.e. from lights off time to lights on time <ref type="bibr" target="#b45">[46]</ref>), many previous studies also included other parts, such as in Supratak et al. <ref type="bibr" target="#b21">[22]</ref>, or even entire recordings, such as in Dimitriadis et al. <ref type="bibr" target="#b54">[55]</ref> and in Alickovic &amp; Subasi <ref type="bibr" target="#b12">[13]</ref>, into their experiments. These addon data, which are mainly Wake epochs, often boost the performance as Wake, in general, is easier to be recognized than other sleep stages. Therefore, the performance comparison is improper unless two methods use a similar experimental setup. With respect to this, the proposed method outperforms other competitors that commonly used independent testing and inbed data only. It should be noted that these results do not cover a large body of studies on the early version of Sleep-EDF dataset <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref> which consists of only 8 PSG recordings.</p><p>A few recent attempts has evaluated automatic sleep staging on a subset <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b36">[37]</ref> rather than the entire 200 subjects of the MASS dataset. The discrepancy in data makes a direct comparison between their results and ours inappropriate. To avoid possible mismatch in experimental setup, we reimplemented DeepSleepNet <ref type="bibr" target="#b21">[22]</ref> and the deep CNN architecture proposed by Chambon et al. <ref type="bibr" target="#b36">[37]</ref>, both of which recently reported the state-of-the-art results on the MASS subset SS3, for a compatible comparison. Note that we experimented with DeepSleepNet1 (CNN) in <ref type="bibr" target="#b21">[22]</ref> here, and will leave DeepSleepNet2 (CNN combined with RNN for longterm context modelling) for future work. In addition, we also implemented the deep CNN proposed by Tsinalis et al. <ref type="bibr" target="#b19">[20]</ref> which demonstrated good performance on Sleep-EDF. While our developed baselines (cf <ref type="table" target="#tab_1">. Table III</ref>) are more efficient than these networks under the common experimental setup used in this work, the improvements by the proposed multitask 1-max CNN are most prominent, as can be seen from <ref type="table" target="#tab_5">Table V</ref>. More specifically, compared to the best opponent, DeepSleepNet <ref type="bibr" target="#b21">[22]</ref>, a margin of 2.9% on overall accuracy is obtained when all three adopted channels (P = 3) were used.</p><p>For completeness, we show in <ref type="table" target="#tab_1">Table VI</ref> the confusion matrices and class-wise performance in terms of sensitivity and selectivity <ref type="bibr" target="#b44">[45]</ref> obtained by the proposed one-to-many framework with the 1-max CNN base. Particularly, one may notice modest performance on N1 stage, which has been proven challenging to be correctly recognized <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref> due to its similarities with other stages and its infrequency. Possibilities for improvement would be to over-sample the under-present class during training and to explore weighting schemes for a network's loss <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b58">[59]</ref> so that the network is penalized stronger if making errors on this infrequent class than other ones. We further provide alignment of ground-truth and system-output hypnograms for one subject of the MASS dataset in <ref type="figure" target="#fig_7">Figure 7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. DISCUSSION</head><p>In this section, we investigate the causes of the proposed framework's performance improvement over the baseline ones. Furthermore, the proposed framework encompasses several influential factors, such as the number of convolutional filters Q of the 1-max CNN, the number of input modalities P , and the output context size. We will discuss and elucidate their effects on the framework's performance. The multitask framework will also be contrasted against an equivalent ensemble method to shed light on their similar behaviour.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Investigating the Causes of Improvement</head><p>To accomplish this goal, we divided the dataset into a non-transition and transition set and explored how different frameworks perform on them. Considering MASS for this investigation, the former set is the major one (83.4% epochs in total) consisting of epochs with the same label as their left and right neighbors. The latter, which is the minor set (16.6% epochs in total), comprises those epochs at stage transitions, i.e. their labels differ from those of their left/right neighbors or both.</p><p>The overall accuracy on these sets are shown in <ref type="table" target="#tab_1">Table VII</ref>. On one hand, the downgrading accuracy on the transition set reflects the fact that manual labelling of sleep stages if of low accuracy near stage transitions <ref type="bibr" target="#b59">[60]</ref>. Since a 30-second epoch likely contains the signal information of two transitioning stages while only one label is assigned to such an epoch, up to half of the epoch may not match the assigned label. More often than not, the labels assigned to these epochs are subjective to the scorer. The accuracy of the one-to-one baseline framework on this small subset, which is above the chance level, is likely due to the bias towards the scorer's subjectivity. The chance-level accuracy of the many-to-one and one-to-many frameworks, on the other hand, can be explained by the fact that taking into account the left and right neighboring epochs has balanced the contribution of the two transitioning stages.</p><p>Disregarding the ambiguous transition set, the cause of performance improvement turns out to be depending upon the accuracy on the major non-transition set. As can be seen, the proposed framework outperforms the other two with a gap of 2.7% and 1.3% on this set, respectively. Further investigation on this set reveals a substantial level of label agreement between the proposed framework and the one-to-one baseline, up to 91.0%. However, for the remaining 9.0% epochs on which their labels disagree, the proposed framework yields an accuracy of 60.4%, roughly doubling that obtained by the baseline (30.5%). Analogously, in comparison with the many-to-one baseline, the label agreement is as high as 92.0% whereas an accuracy gap of 15.2% is seen on the dissenting subset with 52.4% of the proposed framework compared to 37.2% of the baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Influence of the Number of Convolutional Filters</head><p>In general, more features can be learned by the proposed 1-max CNN with the increasing number of convolutional filters Q and one can expect improvement on the performance. However, influence of Q on the framework's performance is very modest as can be seen from <ref type="figure">Figure 4</ref>. For instance, on Sleep-EDF, fixing P = 2 and multiplicative voting, using Q = 1000 only brings up 0.5% absolute accuracy gain over the case of Q = 100 even though the number of filters is ten times larger. A similar finding can also be drawn for MASS (P = 3) with a modest improvement of 0.4%. The slight influence of the number of filters Q suggests that we can maintain a very good performance even with a much smaller network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Benefits of Multimodal Input</head><p>Single-channel EEG has been found prevalent in literature <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b60">[61]</ref> mainly due to its simplicity. However, apart from brain activities, sleep also involves eye movements and muscular activities at different levels. For instance Rapid Eye Movement (REM) stage usually associates with rapid eye movements and high muscular activities are usually seen during the Awake stage. As a result, EOG and EMG are valuable additional sources, complementing EEG in multimodal automatic sleep staging systems <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b61">[62]</ref>, <ref type="bibr" target="#b62">[63]</ref>, not to mention their importance in manual scoring rules <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b43">[44]</ref>. <ref type="figure">Figure 4</ref> reveals and demonstrates the benefit of using EOG and EMG to complement EEG in the proposed framework. Consistent improvements on overall accuracy can be seen on both Sleep-EDF and MASS. Taking MASS for example, averaging over spectrum of Q, as compared to the singlechannel EEG, coupling EEG and EOG leads to an absolute gain of 4.1% and is further boosted by another 1.1% with the compound of EEG, EOG, and EMG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. The Trade-off Problem with the Output Context Size</head><p>It is straightforward to extend the output context in the proposed framework. Doing so, we are able to increase the number of decisions in an ensemble, which is expected to enhance the classification performance <ref type="bibr" target="#b38">[39]</ref>. However, extending the output context confronts us with a trade-off problem. A large context weakens the link between the input epoch and the far-away neighbors in the output context. Oftentimes, this deteriorates the prediction decisions on these epochs and, as a consequence, reduces the quality of individual decisions in the ensemble. The low quality of these prediction decisions may outweigh the benefits of the increased cardinality, worsening the performance instead collectively.</p><p>To support our argument, we increased the output context size to 5 (i.e. œÑ = 2) and repeated the experiment in which we set Q = 1000 for the 1-max CNN and used P = 2 for Sleep-EDF and P = 3 for MASS. <ref type="figure" target="#fig_8">Figure 8</ref> shows the obtained performance alongside those obtained with the output context size of {1, 3} (i.e. œÑ = {0, 1}). Note that, with the context size of 1, the framework is reduced to the one-to-one baseline framework described in Section V-C. With the context size of 5 the proposed framework still maintains its superiority over the standard classification setup, however, a graceful degradation compared to the context size of 3 can be observed. Specifically, the accuracy rates obtained by both additive and multiplicative voting schemes slightly decline by 0.1% on Sleep-EDF while the respective accuracy losses of 0.3% and 0.2% can be seen on MASS.</p><p>To remedy the weak links between the input epoch and faraway epochs, one possibility is to combine multiple epochs into the input to form the contextual input. In addition, it would be worth exploring incorporation of long-term context (i.e. in order of dozens of epochs), for example using RNNs as in <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b21">[22]</ref>. However, a detailed study of the proposed frame work in these many-to-many settings is out of the scope of this article and is left for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Multitask vs Ensemble</head><p>To examine the comparability between the proposed multitask framework with its ensemble equivalence, we repeated the experiments with the ensemble consisting of three separate CNNs for individual subtasks: left prediction, classification, and right prediction. We studied both the 1-max CNN and the deep CNN baseline here. Again, we set Q = 1000, and P = 2 for Sleep-EDF and P = 3 for MASS when 1-max CNN was used. The results obtained with the ensemble models and the proposed multitask models are contrasted vis-√†-vis in <ref type="figure" target="#fig_10">Figure 9</ref>.</p><p>Our analyses show that the separate CNNs of an ensemble model perform better than its corresponding multitask model on the individual subtasks. This is due to the fact that the multitask model needs to deal with a harder modelling task which combines all the subtasks as a whole. However, after aggregation, their differences become negligible as can be seen over all CNN architectures and datasets. More importantly, on both datasets, the proposed multitask 1-max CNN outperforms the deep CNN baseline in its both forms, namely multitask and ensemble.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSIONS</head><p>This work introduced a joint classification and prediction formulation wherein a multi-task CNN framework is proposed for automatic sleep staging. Motivated by the dependency nature of sleep epochs, the framework's purpose is to jointly perform classification of an input epoch and prediction of the labels of its neighbors in the context output. While being orthogonal to the widely adopted many-to-one classification scheme relying on contextual input, we argued that the proposed framework avoids the shortcomings experienced by the   many-to-one approach, such as the inherent modelling ambiguity and the induced computational overhead due to large contextual input. More importantly, due to multitasking, the framework is able to conveniently produce multiple decisions on a certain epoch thereby forming the reliable final decision via aggregation. We demonstrated the generalizability of the framework on two public datasets, Sleep-EDF and MASS.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Overview of the proposed joint classification and prediction framework.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Illustration of the proposed multi-task CNN architecture. The convolution layer of the CNN consists of two filter sets with temporal widths w = 3 and w = 5. Each filter set has two individual filters. The colors of the output layer indicate different subtasks jointly modelled by the network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>from the training data. An epoch i is represented by the multi-channel time-frequency image X (i) ni ‚àà R P √óM√óT as described in IV-B and n i denotes the corresponding index of the epoch in the original signal. Each epoch i is associated with the sequence of one-hot encoding vectors (y (i) ni‚àíœÑ , . . . , y (i) ni , . . . , y (i) ni+œÑ ) which represent the sleep stages of the epochs in the context [n i ‚àí œÑ, n i + œÑ ] of size 2œÑ + 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Accuracies of the left prediction subtask, classification subtask, right prediction subtask, multi-task with additive (add.) voting, and multi-task with multiplicative (mul.) voting obtained with an output context size of 3 (œÑ = 1) and different number of modalities P . (a) Sleep-EDF and (b) MASS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>The overall classification accuracy (a)-(c) and the amount of training time (b)-(d) of the proposed framework in comparison with those of the one-to-one, and many-to-one schemes on the first cross-validation fold. We commonly set Q = 1000 while P = 2 for Sleep-EDF and P = 3 for MASS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Hypnogram of one subject of the MASS dataset (subject 22 of the subset SS1<ref type="bibr" target="#b35">[36]</ref>): (a) ground-truth, (b) the one-toone baseline framework's output, (c) the many-to-one baseline framework's output, (d) the proposed one-to-many framework's output. 1-max CNN was commonly used with Q = 100 and P = 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 :</head><label>8</label><figDesc>Influence of the output context size to the overall accuracy of the proposed framework. The results obtained with a common Q = 1000, in addition, P = 2 (Sleep-EDF) and P = 3 (MASS).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 9 :</head><label>9</label><figDesc>Performance comparison of the proposed multitask 1-max CNN with its equivalent ensemble model. The results are obtained with Q = 1000, P = 2 with Sleep-EDF and P = 3 for MASS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>. Phan, F. Andreotti, N. Cooray, O. Y. Ch√©n, and M. De Vos are with the Institute of Biomedical Engineering, University of Oxford, Oxford OX3 7DQ, United Kingdom.</figDesc><table><row><cell>(a)</cell><cell cols="2">.</cell><cell cols="3">. .</cell><cell>y</cell><cell>n-1</cell><cell>y</cell><cell>n+1</cell><cell>.</cell><cell>. .</cell></row><row><cell></cell><cell cols="4">.</cell><cell>. .</cell><cell>X X</cell><cell></cell><cell cols="2">X X</cell><cell>n+1 n+1</cell><cell>.</cell><cell>. .</cell></row><row><cell>(b)</cell><cell>.</cell><cell cols="4">. .</cell><cell>y</cell><cell>n-1</cell><cell>y</cell><cell>n+1</cell><cell>.</cell><cell>. .</cell></row><row><cell></cell><cell cols="3">.</cell><cell cols="2">. .</cell><cell></cell><cell></cell><cell></cell><cell>.</cell><cell>. .</cell></row><row><cell>(c)</cell><cell cols="5">... . . .</cell><cell>X X</cell><cell></cell><cell>X X</cell><cell>n+1 n+1</cell><cell>... . . .</cell></row></table><note>* Corresponding author: huy.phan@eng.ox.ac.uk1 The source code and the relevant experimental setup are available at http://github.com/pquochuy/MultitaskSleepNet for reproducibility.DOI: 10.1109/TBME.2018.2872652</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table I :</head><label>I</label><figDesc>Parameters of the proposed CNN.</figDesc><table><row><cell>Parameter</cell><cell>Value</cell></row><row><cell>Filter width w</cell><cell>{3, 5, 7}</cell></row><row><cell>Number of filters Q</cell><cell>varied</cell></row><row><cell>Output context size</cell><cell>3</cell></row><row><cell>Dropout</cell><cell>0.2</cell></row><row><cell>Œª for regularization</cell><cell>10 ‚àí3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table II :</head><label>II</label><figDesc>The parameters of the deep CNN baseline.</figDesc><table><row><cell>Layer</cell><cell>Size</cell><cell cols="2">#Fmap Activation</cell><cell>Dropout</cell></row><row><cell>conv1</cell><cell>3 √ó 3</cell><cell>96</cell><cell>ReLU</cell><cell>-</cell></row><row><cell>pool1</cell><cell>2 √ó 1</cell><cell>-</cell><cell>-</cell><cell>0.2</cell></row><row><cell>conv2</cell><cell>3 √ó 3</cell><cell>96</cell><cell>ReLU</cell><cell>-</cell></row><row><cell>pool2</cell><cell>2 √ó 2</cell><cell>-</cell><cell>-</cell><cell>0.2</cell></row><row><cell>fc1</cell><cell>1024</cell><cell>-</cell><cell>ReLU</cell><cell>0.2</cell></row><row><cell>fc2</cell><cell>1024</cell><cell>-</cell><cell>ReLU</cell><cell>0.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table III :</head><label>III</label><figDesc>Performance comparison of different systems developed in this work. We marked in bold the figures where the combination of the one-to-many framework and 1-max CNN outperforms all other opponents.One-to-many + 1-max CNN 81.9 0.74 73.8 73.9 95.0 82.3 0.75 74.7 74.3 95.1 One-to-one + 1-max CNN 79.8 0.72 72.0 72.4 94.6 79.7 0.72 72.2 72.8 94.6 One-to-many + deep CNN baseline 79.3 0.71 69.7 70.2 94.2 79.7 0.71 71.2 70.9 94.3 One-to-one + deep CNN baseline 76.7 0.67 67.6 68.6 93.7 77.1 0.68 69.3 69.8 93.8 Many-to-one + deep CNN baseline 78.3 0.69 70.7 71.1 94.1 78.7 0.70 71.8 72.4 94.2</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">P = 1 (EEG only)</cell><cell cols="2">P = 2 (EEG + EOG)</cell><cell>P = 3 (EEG + EOG + EMG)</cell></row><row><cell></cell><cell></cell><cell>Acc.</cell><cell>Œ∫</cell><cell>MF1 Sens. Spec. Acc.</cell><cell>Œ∫</cell><cell cols="2">MF1 Sens. Spec. Acc.</cell><cell>Œ∫</cell><cell>MF1 Sens. Spec.</cell></row><row><cell>Sleep-EDF</cell><cell>Many-to-one + 1-max CNN</cell><cell cols="5">80.9 0.73 73.6 74.2 94.9 82.1 0.75 75.4 75.4 95.1</cell></row><row><cell></cell><cell>One-to-many + 1-max CNN</cell><cell cols="6">78.6 0.70 70.6 71.2 94.1 82.5 0.75 76.1 75.8 95.0 83.6 0.77 77.9 77.4 95.3</cell></row><row><cell>MASS</cell><cell cols="7">One-to-one + 1-max CNN Many-to-one + 1-max CNN One-to-many + deep CNN baseline 78.0 0.69 69.8 70.1 93.8 81.9 0.74 75.2 74.7 94.8 82.7 0.75 76.9 76.3 95.0 75.9 0.67 69.6 71.1 93.7 80.7 0.73 74.9 75.5 94.8 82.7 0.75 77.6 77.8 95.1 76.3 0.67 69.8 71.3 93.8 80.9 0.73 75.1 75.5 94.8 82.1 0.75 76.6 76.9 95.0</cell></row><row><cell></cell><cell cols="7">One-to-one + deep CNN baseline 74.5 0.65 68.4 70.0 93.4 79.2 0.71 73.5 74.3 94.4 81.0 0.73 76.4 77.4 94.9</cell></row><row><cell></cell><cell cols="7">Many-to-one + deep CNN baseline 77.4 0.68 71.6 72.8 94.0 81.2 0.73 76.0 76.4 94.8 82.4 0.75 78.2 78.9 95.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table IV :</head><label>IV</label><figDesc>Performances of the proposed method compared to previous methods on the Sleep-EDF dataset. Notice the large variation in the accuracy rate due to the differences in experimental setup. Top accuracy rates, such as in Aboalayon et al.<ref type="bibr" target="#b2">[3]</ref>, Alickovic &amp; Subasi<ref type="bibr" target="#b12">[13]</ref>, and Dimitriadis et al.<ref type="bibr" target="#b54">[55]</ref>, are likely biased by nonindependent testing and usage of entire recordings rather than only in-bed data (cf. V-D3 for further detail).</figDesc><table><row><cell></cell><cell>Method</cell><cell>Input channel</cell><cell>Feature type</cell><cell>Subjects</cell><cell>Independent testing</cell><cell>In-bed data only</cell><cell>Overall accuracy</cell></row><row><cell>This work</cell><cell cols="3">Multitask 1-max CNN Fpz-Cz + hor. EOG learned</cell><cell>20 SC</cell><cell>yes</cell><cell>yes</cell><cell>82.3</cell></row><row><cell>This work</cell><cell cols="2">Multitask 1-max CNN Fpz-Cz</cell><cell>learned</cell><cell>20 SC</cell><cell>yes</cell><cell>yes</cell><cell>81.9</cell></row><row><cell>Phan et al. [24]</cell><cell>1-max CNN</cell><cell>Fpz-Cz</cell><cell>learned</cell><cell>20 SC</cell><cell>yes</cell><cell>yes</cell><cell>79.8</cell></row><row><cell>Phan et al. [25]</cell><cell>Attentional RNN</cell><cell>Fpz-Cz</cell><cell>learned</cell><cell>20 SC</cell><cell>yes</cell><cell>yes</cell><cell>79.1</cell></row><row><cell>Andreotti et al. [38]</cell><cell>ResNet</cell><cell cols="2">Fpz-Cz + hor. EOG learned</cell><cell>20 SC</cell><cell>yes</cell><cell>yes</cell><cell>76.8</cell></row><row><cell>Tsinalis et al. [21]</cell><cell>Deep auto-encoder</cell><cell>Fpz-Cz</cell><cell>hand-crafted</cell><cell>20 SC</cell><cell>yes</cell><cell>yes</cell><cell>78.9</cell></row><row><cell>Tsinalis et al. [20]</cell><cell>Deep CNN</cell><cell>Fpz-Cz</cell><cell>learned</cell><cell>20 SC</cell><cell>yes</cell><cell>yes</cell><cell>74.8</cell></row><row><cell>Supratak et al. [22]</cell><cell>Deep CNN + RNN</cell><cell>Fpz-Cz</cell><cell>learned</cell><cell>20 SC</cell><cell>yes</cell><cell>no</cell><cell>82.0</cell></row><row><cell>Alickovic &amp; Subasi [13]</cell><cell>Ensemble SVM</cell><cell>Pz-Oz</cell><cell cols="2">hand-crafted 10 SC + 10 ST</cell><cell>yes</cell><cell>no</cell><cell>91.1</cell></row><row><cell>Sanders et al. [56]</cell><cell>Decision trees</cell><cell>Fpz-Cz</cell><cell>hand-crafted</cell><cell>10 ST</cell><cell>yes</cell><cell>no</cell><cell>75.0</cell></row><row><cell>Dimitriadis et al. [55]</cell><cell>k-NN</cell><cell>Fpz-Cz</cell><cell>hand-crafted</cell><cell>20 SC</cell><cell>yes</cell><cell>no</cell><cell>94.4</cell></row><row><cell>Mikkelsen &amp; De Vos [18]</cell><cell>Deep CNN</cell><cell cols="2">Fpz-Cz + hor. EOG learned</cell><cell>20 SC</cell><cell>no</cell><cell>yes</cell><cell>84.0</cell></row><row><cell>Imtiaz et al. [16]</cell><cell>Ensemble SVM</cell><cell>Fpz-Cz + Pz-Oz</cell><cell cols="2">hand-crafted 20 SC + 22 ST</cell><cell>no</cell><cell>yes</cell><cell>78.9</cell></row><row><cell>Munk et al. [57]</cell><cell>GMM</cell><cell>Pz-Oz</cell><cell>hand-crafted</cell><cell>19 SC</cell><cell>no</cell><cell>no</cell><cell>73.2</cell></row><row><cell>Rodr√≠guez-Sotelo et al. [58]</cell><cell>k-NN</cell><cell>Fpz-Cz + Pz-Oz</cell><cell>hand-crafted</cell><cell>20 SC</cell><cell>no</cell><cell>no</cell><cell>80.0</cell></row><row><cell>Aboalayon et al. [3]</cell><cell>Decision trees</cell><cell>Fpz-Cz + Pz-Oz</cell><cell>hand-crafted</cell><cell>20 SC</cell><cell>no</cell><cell>no</cell><cell>93.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table V :</head><label>V</label><figDesc>Performances of the proposed method compared to previous methods on the MASS dataset.</figDesc><table><row><cell></cell><cell>Method</cell><cell>Input channel</cell><cell>Feature type</cell><cell>Subjects</cell><cell>Independent testing</cell><cell>Overall accuracy</cell></row><row><cell>This work</cell><cell cols="3">Multitask 1-max CNN C4-A1 + ROC-LOC + CHIN1-CHIN2 learned</cell><cell>200</cell><cell>yes</cell><cell>83.6</cell></row><row><cell>This work</cell><cell cols="2">Multitask 1-max CNN C4-A1 + ROC-LOC</cell><cell>learned</cell><cell>200</cell><cell>yes</cell><cell>82.5</cell></row><row><cell>This work</cell><cell cols="2">Multitask 1-max CNN C4-A1</cell><cell>learned</cell><cell>200</cell><cell>yes</cell><cell>78.6</cell></row><row><cell cols="2">Chambon et al. 2 [37] Deep CNN</cell><cell cols="2">C4-A1 + ROC-LOC + CHIN1-CHIN2 learned</cell><cell>200</cell><cell>yes</cell><cell>79.9</cell></row><row><cell cols="2">DeepSleepNet1 2 [22] Deep CNN</cell><cell cols="2">C4-A1 + ROC-LOC + CHIN1-CHIN2 learned</cell><cell>200</cell><cell>yes</cell><cell>80.7</cell></row><row><cell>Tsinalis et al. 2 [20]</cell><cell>Deep CNN</cell><cell cols="2">C4-A1 + ROC-LOC + CHIN1-CHIN2 learned</cell><cell>200</cell><cell>yes</cell><cell>77.9</cell></row><row><cell>Andreotti et al. [38]</cell><cell>ResNet</cell><cell cols="2">C4-A1 + ROC-LOC + CHIN1-CHIN2 learned</cell><cell>200</cell><cell>yes</cell><cell>79.4</cell></row><row><cell>Chambon et al. [37]</cell><cell>Deep CNN</cell><cell>6 EEG + 2 EOG + 3 EMG</cell><cell>learned</cell><cell>61 (SS3 only)</cell><cell>yes</cell><cell>83.0</cell></row><row><cell>Supratak et al. [22]</cell><cell>Deep CNN</cell><cell>F4-EOG (left)</cell><cell>learned</cell><cell>62 (SS3 only)</cell><cell>yes</cell><cell>81.5</cell></row><row><cell>Dong et al. [23]</cell><cell>DNN</cell><cell>F4-EOG (left)</cell><cell>learned</cell><cell>62 (SS3 only)</cell><cell>yes</cell><cell>81.4</cell></row><row><cell>Dong et al. [23]</cell><cell>Random Forests</cell><cell>F4-EOG (left)</cell><cell cols="2">hand-crafted 62 (SS3 only)</cell><cell>yes</cell><cell>81.7</cell></row><row><cell>Dong et al. [23]</cell><cell>SVM</cell><cell>F4-EOG (left)</cell><cell cols="2">hand-crafted 62 (SS3 only)</cell><cell>yes</cell><cell>79.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table VI :</head><label>VI</label><figDesc>Confusion matrices and class-wise performance (sensitivity and selectivity) obtained by the proposed one-tomany framework with the 1-max CNN base.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Groundtruth</cell><cell></cell><cell>Sen.</cell><cell>Sel.</cell></row><row><cell></cell><cell></cell><cell></cell><cell>W</cell><cell>N1</cell><cell>N2</cell><cell>N3</cell><cell>REM</cell><cell>(%)</cell><cell>(%)</cell></row><row><cell>Sleep-EDF</cell><cell>Output</cell><cell cols="2">W N1 N2 N3 REM 154 3403 441 230 65</cell><cell cols="3">322 880 263 15263 795 230 32 725 9 0 658 4850 114 457 3</cell><cell>522 707 1026 86.8 88.1 75.5 79.3 31.9 55.7 18 86.7 85.3 6983 90.6 75.4</cell></row><row><cell></cell><cell></cell><cell cols="4">W 26261 2148 1450</cell><cell>72</cell><cell>1112 84.6 86.3</cell></row><row><cell>MASS</cell><cell>Output</cell><cell>N1 N2 N3</cell><cell cols="5">2924 7948 5498 759 3429 95486 4849 3395 88.5 86.9 22 2965 41.1 55.2 30 13 6098 24223 18 79.7 83.0</cell></row><row><cell></cell><cell></cell><cell cols="2">REM 466</cell><cell>872</cell><cell>1353</cell><cell>6</cell><cell>37473 93.3 83.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table VII :</head><label>VII</label><figDesc>The overall accuracy of different frameworks on MASS's transition and non-transition subsets. The results are obtained by 1-max CNN base with Q = 1000 and P = 3.</figDesc><table><row><cell></cell><cell>Non-transition</cell><cell>Transition</cell></row><row><cell></cell><cell>(Size 83.4%)</cell><cell>(Size 16.6%)</cell></row><row><cell>One-to-many</cell><cell>89.5</cell><cell>53.3</cell></row><row><cell>One-to-one</cell><cell>86.8</cell><cell>62.0</cell></row><row><cell>Many-to-one</cell><cell>88.2</cell><cell>51.1</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Social and Economic Dimensions of Sleep Disorders, An Issue of Sleep Medicine Clinics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Krieger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Cardiorespiratory-based sleep staging in subjects with obstructive sleep apnea</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Redmond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Heneghan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="485" to="496" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Sleep stage classification using EEG signal analysis: A comprehensive survey and new investigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A I</forename><surname>Aboalayon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Faezipour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Almuhammadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moslehpour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Entropy</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">272</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Recent developments in home sleep-monitoring devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Strecker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Bianchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISRN Neurology</title>
		<imprint>
			<biblScope unit="volume">2012</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Automatic sleep scoring: A search for an optimal combination of measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krakovsk√°</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mezeiov√°</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence in Medicine</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="25" to="33" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">An ensemble system for automatic sleep stage classification using single channel EEG signal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Koley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers in Biology and Medicine</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1186" to="95" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Metric learning for automatic sleep stage classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-L</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-L</forename><surname>Vu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMBC</title>
		<meeting>EMBC</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="5025" to="5028" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Discrimination ability of individual measures used in sleep stages classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Susmakova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krakovska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence in Medicine</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="261" to="277" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Discrimination of sleep stages: a comparison between spectral and nonlinear eeg measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Roschke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schaffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electroencephalography and Clinical Neurophysiology</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="401" to="411" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An estimation of the first positive Lyapunov exponent of the EEG in patients with schizophrenia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Chae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Go</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">H</forename><surname>Paik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">S K</forename><surname>Ks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychiatry Research</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="177" to="89" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Detrended fluctuation analysis of EEG in sleep apnea using MIT/BIH polysomnography data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">I</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers in Biology and Medicine</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="37" to="47" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">EEG complexity as a measure of depth of anesthesia for patients</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">W</forename><surname>Jensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1424" to="1433" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Ensemble SVM method for automatic sleep stage classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Alickovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Subasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Instrum. Meas</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A novel multi-class EEG-based sleep stage classification system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Memar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Faradji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Systems and Rehabilitation Engineering</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="84" to="95" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A comparative review on sleep stage classification methods in patients and healthy individuals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Boostania</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Karimzadeha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Methods Programs Biomed</title>
		<imprint>
			<biblScope unit="page" from="77" to="91" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Automatic sleep staging using state machine-controlled decision trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Imtiaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rodriguez-Villegas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMBC</title>
		<meeting>EMBC</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Stephansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ambati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Leary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">E</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Carrillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hogl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Stefani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pizza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Plazzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Antelmi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Perrin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Kuna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Schweitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kushida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Peppard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Jennum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">B D</forename><surname>Sorensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Mignot</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.02094</idno>
		<title level="m">The use of neural networks in the analysis of sleep stages and the diagnosis of narcolepsy</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Personalizing deep learning models for automatic sleep staging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mikkelsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">De</forename><surname>Vos</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.02645</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A new method for automatic sleep stage classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Biomedical Circuits and Systems</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1097" to="1110" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Automatic sleep stage scoring with single-channel EEG using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Tsinalis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.01683</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Automatic sleep stage scoring using time-frequency analysis and stacked sparse autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Tsinalis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1587" to="1597" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deepsleepnet: A model for automatic sleep stage scoring based on raw single-channel eeg</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Supratak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Syst. Rehabil. Eng</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">11</biblScope>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Mixed neural network approach for temporal sleep stage classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Supratak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Syst. Rehabil. Eng</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">DNN filter bank improves 1-max pooling cnn for single-channel EEG automatic sleep stage classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Andreotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cooray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">Y</forename><surname>Ch√©n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">De</forename><surname>Vos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMBC</title>
		<meeting>EMBC</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Automatic sleep stage classification using single-channel EEG: Learning sequential features with attention-based recurrent neural networks</title>
	</analytic>
	<monogr>
		<title level="m">Proc. EMBC</title>
		<meeting>EMBC</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<title level="m">Generalization and network design strategies</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="1989" />
		</imprint>
	</monogr>
	<note>Connectionism in perspective</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Sleep stage classification using unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>L√§ngkvist</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Karlsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Loutfi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Artificial Neural Systems</title>
		<imprint>
			<biblScope unit="volume">2012</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Recurrent neural network based early prediction of future hand movements</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Katzberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mertins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMBC</title>
		<meeting>EMBC</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Recurrent neural networks with weighting loss for early prediction of hand movements</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Katzberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mazur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mertins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EUSIPCO</title>
		<meeting>EUSIPCO</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Neonatal seizure detection using deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">H</forename><surname>Ansari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Cherian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Caicedo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Naulaers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">De</forename><surname>Vos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Van Huffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Neural Systems</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page">1850011</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">The AASM manual for the scoring of sleep and associated events: Rules, terminology and technical specifications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Iber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ancoli-Israel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Chesson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">F</forename><surname>Quan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>American Academy of Sleep Medicine</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A rule-based automatic sleep staging method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-F</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-E</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-S</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EBMC</title>
		<meeting>EBMC</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="6067" to="6070" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A twostep automatic sleep stage classification method with dubious range detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sousa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cruz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Khalighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pires</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Nunes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers in Biology and Medicine</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="42" to="53" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Montreal archive of sleep studies: An open-access resource for instrument benchmarking &amp; exploratory research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>O&amp;apos;reilly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gosselin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carrier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nielsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Sleep Research</title>
		<imprint>
			<biblScope unit="page" from="628" to="635" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A deep learning architecture for temporal sleep stage classification using multivariate and multimodal time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chambon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Galtier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Arnal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wainrib</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Neural Systems and Rehabilitation Engineering</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="758" to="769" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Multichannel sleep stage classification and transfer learning using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Andreotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cooray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T M</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">De</forename><surname>Vos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMBC</title>
		<meeting>EMBC</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Ensemble methods in machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">G</forename><surname>Dietterich</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
	<note>Multiple classifier systems</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Automatic sleep scoring using statistical features in the EMD domain and ensemble methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I H</forename><surname>Bhuiyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biocybern. Biomed. Eng</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="248" to="255" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Analysis of a sleep-dependent neuronal feedback loop: the slow-wave microcontinuity of the EEG</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kemp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">H</forename><surname>Zwinderman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A C</forename><surname>Kamphuisen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J L</forename><surname>Oberye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1185" to="1194" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A N</forename><surname>Amaral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Glass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Hausdorff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Ivanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Mietus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">B</forename><surname>Moody</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-K</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">E</forename><surname>Stanley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Physiobank, physiotoolkit, and physionet: Components of a new research resource for complex physiologic signals</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="215" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A manual of standardized terminology, techniques and scoring system for sleep stages of human subjects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Hobson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electroencephalography and Clinical Neurophysiology</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">644</biblScope>
			<date type="published" when="1969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Recommendations for performance assessment of automatic sleep staging algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Imtiaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rodriguez-Villegas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMBC</title>
		<meeting>EMBC</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="5044" to="5047" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">An open-source toolbox for standardized use of PhysioNet Sleep EDF Expanded Database</title>
	</analytic>
	<monogr>
		<title level="m">Proc. EMBC</title>
		<meeting>EMBC</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="6014" to="6017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Improved audio scene classification based on label-tree embeddings and convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hertel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mazur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mertins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Trans. on Audio, Speech, and Language Processing</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1278" to="1290" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Robust audio event recognition with 1-max pooling convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hertel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mertins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. INTERSPEECH</title>
		<meeting>INTERSPEECH</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3653" to="3657" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1746" to="1751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted boltzmann machine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML 2010</title>
		<meeting>ICML 2010</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="807" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research (JMLR)</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Adam: a method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Audio scene classification with deep recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Katzberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mazur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mertins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. INTERSPEECH</title>
		<meeting>INTERSPEECH</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3043" to="3047" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Tensorflow: Large-scale machine learning on heterogeneous distributed systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.04467</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A novel, fast and efficient single-sensor automatic sleep-stage classification based on complementary cross-frequency coupling estimates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">I</forename><surname>Dimitriadis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Salis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Linden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clinical Neurophysiology</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="815" to="828" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Sleep stage classification with cross frequency coupling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Sanders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mccurry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Clements</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMBC</title>
		<meeting>EMBC</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Semisupervised sleep-stage scoring based on single channel EEG</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Munk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">V</forename><surname>Olesen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Gangstad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">K</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2551" to="2555" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Automatic sleep stages classification using eeg entropy features and unsupervised pattern analysis techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Rodr√≠guez-Sotelo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Osorio-Forero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jim√©nez-Rodr√≠guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cuesta-Frau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cirugeda-Rold√°n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Peluffo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Entropy</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="6573" to="6589" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Weighted and multi-task loss for rare audio event detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Krawczyk-Becker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gerkmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mertins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="336" to="340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">The american academy of sleep medicine inter-scorer reliability program: Respiratory events</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Van Hout</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Clinical Sleep Medicine</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="447" to="454" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Automatic stage scoring of single-channel sleep EEG based on multiscale permutation entropy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-E</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-F</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. BioCAS</title>
		<meeting>BioCAS</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="448" to="451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Learning machines and sleeping brains: Automatic sleep stage classification using decision-tree multi-class support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lajnef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chaibi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ruby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Aguera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Eichenlaub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Samet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kachouri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Jerbi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neurosci. Methods</title>
		<imprint>
			<biblScope unit="volume">250</biblScope>
			<biblScope unit="page" from="94" to="105" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Knowledge-based identification of sleep stages based on two forehead electroencephalogram channels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">W</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">P</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">T</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Neuroscience</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">263</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
