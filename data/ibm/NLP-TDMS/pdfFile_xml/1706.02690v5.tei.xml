<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ENHANCING THE RELIABILITY OF OUT-OF-DISTRIBUTION IMAGE DETECTION IN NEURAL NETWORKS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Liang</surname></persName>
							<email>sliang26@illinois.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Coordinated Science Lab</orgName>
								<orgName type="department" key="dep2">Department of ECE</orgName>
								<orgName type="institution">University of Illinois at Urbana-Champaign</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixuan</forename><surname>Li</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Wisconsin-Madison *</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Srikant</surname></persName>
							<email>rsrikant@illinois.edu</email>
							<affiliation key="aff2">
								<orgName type="department">Department of ECE University of Illinois at Urbana-Champaign</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">ENHANCING THE RELIABILITY OF OUT-OF-DISTRIBUTION IMAGE DETECTION IN NEURAL NETWORKS</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Published as a conference paper at ICLR 2018</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T18:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We consider the problem of detecting out-of-distribution images in neural networks. We propose ODIN, a simple and effective method that does not require any change to a pre-trained neural network. Our method is based on the observation that using temperature scaling and adding small perturbations to the input can separate the softmax score distributions between in-and out-of-distribution images, allowing for more effective detection. We show in a series of experiments that ODIN is compatible with diverse network architectures and datasets. It consistently outperforms the baseline approach (Hendrycks &amp; Gimpel, 2017) by a large margin, establishing a new state-of-the-art performance on this task. For example, ODIN reduces the false positive rate from the baseline 34.7% to 4.3% on the DenseNet (applied to CIFAR-10 and Tiny-ImageNet) when the true positive rate is 95%.</p><p>A seemingly straightforward approach of detecting out-of-distribution images is to enlarge the training set of both in-and out-of-distribution examples. However, the number of out-of-distribution examples can be infinitely many, making the re-training approach computationally expensive and intractable. Moreover, to ensure that a neural network accurately classifies in-distribution samples into correct classes while correctly detecting out-of-distribution samples, one might need to employ exceedingly large neural network architectures, which further complicates the training process.</p><p>Hendrycks &amp; Gimpel proposed a baseline method to detect out-of-distribution examples without further re-training networks. The method is based on an observation that a well-trained neural network tends to assign higher softmax scores to in-distribution examples than out-of-distribution * Work done while at Cornell University.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Modern neural networks are known to generalize well when the training and testing data are sampled from the same distribution <ref type="bibr" target="#b21">(Krizhevsky et al., 2012;</ref><ref type="bibr" target="#b30">Simonyan &amp; Zisserman, 2015;</ref><ref type="bibr" target="#b14">He et al., 2016;</ref><ref type="bibr" target="#b2">Cho et al., 2014;</ref><ref type="bibr" target="#b40">Zhang et al., 2017)</ref>. However, when deploying neural networks in real-world applications, there is often very little control over the testing data distribution. Recent works have shown that neural networks tend to make high confidence predictions even for completely unrecognizable <ref type="bibr" target="#b24">(Nguyen et al., 2015)</ref> or irrelevant inputs <ref type="bibr" target="#b15">(Hendrycks &amp; Gimpel, 2017;</ref><ref type="bibr" target="#b33">Szegedy et al., 2014;</ref><ref type="bibr" target="#b23">Moosavi-Dezfooli et al., 2017)</ref>. It has been well documented <ref type="bibr" target="#b0">(Amodei et al., 2016)</ref> that it is important for classifiers to be aware of uncertainty when shown new kinds of inputs, i.e., out-ofdistribution examples. Therefore, being able to accurately detect out-of-distribution examples can be practically important for visual recognition tasks <ref type="bibr" target="#b21">(Krizhevsky et al., 2012;</ref><ref type="bibr" target="#b8">Farabet et al., 2013;</ref><ref type="bibr" target="#b18">Ji et al., 2013)</ref>. examples. In this paper, we go further. We observe that after using temperature scaling in the softmax function <ref type="bibr" target="#b16">(Hinton et al., 2015;</ref><ref type="bibr" target="#b25">Pereyra et al., 2017)</ref> and adding small controlled perturbations to inputs, the softmax score gap between in -and out-of-distribution examples is further enlarged. We show that the combination of these two techniques (temperature scaling and input perturbation) can lead to better detection performance. For example, provided with a pre-trained DenseNet <ref type="bibr" target="#b17">(Huang et al., 2016)</ref> on CIFAR-10 dataset (positive samples), we test against images from TinyImageNet dataset (negative samples). Our method reduces the False Positive Rate (FPR), i.e., the fraction of misclassified out-of-distribution samples, from 34.7% to 4.3%, when 95% of in-distribution images are correctly classified. We summarize the main contributions of this paper as the following:</p><p>• We propose a simple and effective method, ODIN (Out-of-DIstribution detector for Neural networks), for detecting out-of-distribution examples in neural networks. Our method does not require re-training the neural network and is easily implementable on any modern neural architecture. • We test ODIN on state-of-the-art network architectures (e.g., DenseNet <ref type="bibr" target="#b17">(Huang et al., 2016)</ref> and</p><p>Wide ResNet <ref type="bibr" target="#b39">(Zagoruyko &amp; Komodakis, 2016)</ref>) under a diverse set of in-and out-distribution dataset pairs. We show ODIN can significantly improve the detection performance, and consistently outperforms the baseline method <ref type="bibr" target="#b15">(Hendrycks &amp; Gimpel, 2017</ref>) by a large margin. • We empirically analyze how parameter settings affect the performance, and further provide simple analysis that provides some intuition behind our method.</p><p>The outline of this paper is as follows. In Section 2, we present the necessary definitions and the problem statement. In Section 3, we introduce ODIN and present performance results in Section 4. We experimentally analyze the proposed method and provide some justification for our method in Section 5. We summarize the related works and future directions in Section 6 and conclude the paper in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PROBLEM STATEMENT</head><p>In this paper, we consider the problem of distinguishing in-and out-of-distribution images on a pretrained neural network. Let P X and Q X denote two distinct data distributions defined on the image space X . Assume that a neural network f is trained on a dataset drawn from the distribution P X . We call P X the in-distribution and Q X the out-distribution, respectively. In testing, we draw new images from a mixture distribution P X×Z defined on X × {0, 1}, where the conditional probability distributions P X|Z=0 = P X and P X|Z=1 = Q X denote in-and out-distribution respectively. We consider the following problem: Given an image X drawn from the mixture distribution P X×Z , can we distinguish whether the image is from in-distribution P X or not?</p><p>In this paper, we focus on detecting out-of-distribution images. However, it is equally important to correctly classify an image into the right class if it is an in-distribution image. But this can be easily done: once it has been detected that an image is in-distribution, we can simply use the original image and run it through the neural network to classify it. Thus, we do not change the predictions of the neural network for in-distribution images and only focus on improving the detection performance for out-of-distribution images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">ODIN: OUT-OF-DISTRIBUTION DETECTOR</head><p>In this section, we present our method, ODIN, for detecting out-of-distribution samples. The detector is built on two components: temperature scaling and input preprocessing. We describe the details of both components below. Temperature Scaling. Assume that the neural network f = (f 1 , ..., f N ) is trained to classify N classes. For each input x, the neural network assigns a labelŷ(x) = arg max i S i (x; T ) by computing the softmax output for each class. Specifically,</p><formula xml:id="formula_0">S i (x; T ) = exp (f i (x)/T ) N j=1 exp (f j (x)/T ) ,<label>(1)</label></formula><p>where T ∈ R + is the temperature scaling parameter and set to 1 during the training. For a given input x, we call the maximum softmax probability, i.e., Sŷ(x; T ) = max i S i (x; T ) the softmax score. In this paper, we use notations Sŷ(x; T ) and S(x; T ) interchangeably. Prior works have established the use of temperature scaling to distill the knowledge in neural networks <ref type="bibr" target="#b16">(Hinton et al., 2015)</ref> and calibrate the prediction confidence in classification tasks <ref type="bibr" target="#b13">(Guo et al., 2017)</ref>. As we shall see, using temperature scaling can separate the softmax scores between in-and out-of-distribution images, making out-of-distribution detection effective. Input Preprocessing. In addition to temperature scaling, we preprocess the input by adding small perturbations:</p><formula xml:id="formula_1">x = x − εsign(−∇ x log Sŷ(x; T )),<label>(2)</label></formula><p>where the parameter ε is the perturbation magnitude. The method is inspired by the idea of adversarial examples <ref type="bibr" target="#b11">(Goodfellow et al., 2015)</ref>, where small perturbations are added to decrease the softmax score for the true label and force the neural network to make a wrong prediction. Here, our goal and setting are the opposite: we aim to increase the softmax score of any given input, without the need for a class label at all. As we shall see later, the perturbation can have stronger effect on the indistribution images than that on out-of-distribution images, making them more separable. Note that the perturbations can be easily computed by back-propagating the gradient of the cross-entropy loss w.r.t the input.</p><p>Out-of-distribution Detector. The detector combines the two components described above. For each image x, we first calculate the preprocessed imagex according to the equation <ref type="formula" target="#formula_1">(2)</ref>. Next, we feed the preprocessed imagex into the neural network, calculate its calibrated softmax score S(x; T ) and compare the score to the threshold δ. An image x is classified as in-distribution if the softmax score is greater than the threshold and vice versa. Mathematically, the out-of-distribution detector can be described as</p><formula xml:id="formula_2">g(x; δ, T, ε) = 1 if max i p(x; T ) ≤ δ, 0 if max i p(x; T ) &gt; δ.</formula><p>The parameters T, ε and δ are chosen so that the true positive rate (i.e., the fraction of in-distribution images correctly classified as in-distribution images) is 95%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>In this section, we demonstrate the effectiveness of ODIN on several computer vision benchmark datasets. We run all experiments with PyTorch 1 and we release the code to reproduce all experimental results 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">TRAINING SETUP</head><p>Architectures and training configurations. We adopt two state-of-the-art neural network architectures, including DenseNet <ref type="bibr" target="#b17">(Huang et al., 2016)</ref> and Wide ResNet <ref type="bibr" target="#b39">(Zagoruyko &amp; Komodakis, 2016)</ref>.</p><p>For DenseNet, our model follows the same setup as in <ref type="bibr" target="#b17">(Huang et al., 2016)</ref>, with depth L = 100, growth rate k = 12 (Dense-BC) and dropout rate 0. In addition, we evaluate the method on a Wide ResNet, with depth 28, width 10 (WRN-28-10) and dropout rate 0. The hyper-parameters of neural networks are set identical to the original Wide ResNet <ref type="bibr" target="#b39">(Zagoruyko &amp; Komodakis, 2016)</ref> and DenseNet <ref type="bibr" target="#b17">(Huang et al., 2016)</ref> implementations. All neural networks are trained with stochastic gradient descent with Nesterov momentum <ref type="bibr" target="#b7">(Duchi et al., 2011;</ref><ref type="bibr" target="#b19">Kingma &amp; Ba, 2014)</ref>. Specifically, we train Dense-BC for 300 epochs with batch size 64 and momentum 0.9; and Wide ResNet for 200 epochs with batch size 128 and momentum 0.9. The learning rate starts at 0.1, and is dropped by a factor of 10 at 50% and 75% of the training progress, respectively.</p><p>Architecture C-10 C-100</p><p>Dense-BC 4.81 22.37 WRN-28-10 3.71</p><p>19.86 <ref type="table">Table 1</ref>: Test error rates on CIFAR-10 and CIFAR-100 datasets.</p><p>Accuracy of pre-trained networks. Each neural network architecture is trained on CIFAR-10 (C-10) and CIFAR-100 (C-100) datasets <ref type="bibr" target="#b20">(Krizhevsky &amp; Hinton, 2009</ref>), respectively. CIFAR-10 and CIFAR-100 images are drawn from 10 and 100 classes, respectively. Both datasets consist of 50,000 training images and 10,000 test images. The test error on CIFAR datasets are given in <ref type="table">Table 1</ref>.  percentages. ↑ indicates larger value is better, and ↓ indicates lower value is better. We use T = 1000 for all experiments. The noise magnitude ε was selected on a separate validation dataset, which is different from the out-of-distribution test sets. On CIFAR-10 pretrained model, we use ε = 0.0014 for all OOD test datasets; and ε = 0.002 for CIFAR-100 pretrained model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">OUT-OF-DISTRIBUTION DATASETS</head><p>At test time, the test images from CIFAR-10 (CIFAR-100) datasets can be viewed as the in-distribution (positive) examples. For out-of-distribution (negative) examples, we follow the setting in <ref type="bibr" target="#b15">(Hendrycks &amp; Gimpel, 2017)</ref> and test on several different natural image datasets and synthetic noise datasets. We consider the following out-of-distribution test datasets.</p><p>(1) TinyImageNet. The Tiny ImageNet dataset 3 consists of a subset of ImageNet images <ref type="bibr" target="#b5">(Deng et al., 2009</ref>). It contains 10,000 test images from 200 different classes. We construct two datasets, TinyImageNet (crop) and TinyImageNet (resize), by either randomly cropping image patches of size 32 × 32 or downsampling each image to size 32 × 32.</p><p>(2) LSUN. The Large-scale Scene UNderstanding dataset (LSUN) has a testing set of 10,000 images of 10 different scenes categories such as bedroom, kitchen room, living room, etc. <ref type="bibr" target="#b38">(Yu et al., 2015)</ref>. Similar to TinyImageNet, we construct two datasets, LSUN (crop) and LSUN (resize), by randomly cropping and downsampling the LSUN testing set, respectively. (3) Gaussian Noise. The synthetic Gaussian noise dataset consists of 10,000 random 2D Gaussian noise images, where each RGB value of every pixel is sampled from an i.i.d Gaussian distribution with mean 0.5 and unit variance. We further clip each pixel value into the range [0, 1]. (4) Uniform Noise. The synthetic uniform noise dataset consists of 10,000 images where each RGB value of every pixel is independently and identically sampled from a uniform distribution on [0, 1].</p><p>For hyperparameter tuning, we use a separate validation dataset iSUN <ref type="bibr" target="#b37">(Xu et al., 2015)</ref>, which is independent from the OOD test datasets. iSUN <ref type="bibr" target="#b37">(Xu et al., 2015)</ref> consists of natural scene images. We include the entire collection of 8925 images in iSUN and downsample each image to size 32 by 32.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">EVALUATION METRICS</head><p>We adopt the following four different metrics to measure the effectiveness of a neural network in distinguishing in-and out-of-distribution images.</p><p>(1) FPR at 95% TPR can be interpreted as the probability that a negative (out-of-distribution) example is misclassified as positive (in-distribution) when the true positive rate (TPR) is as high as 95%.</p><p>(2) Detection Error, i.e., P e measures the misclassification probability when TPR is 95%. The definition of P e is given by P e = 0.5(1 − TPR) + 0.5FPR, where we assume that both positive and negative examples have the equal probability of appearing in the test set.</p><p>(3) AUROC is the Area Under the Receiver Operating Characteristic curve, which is also a thresholdindependent metric <ref type="bibr" target="#b4">(Davis &amp; Goadrich, 2006)</ref>. The ROC curve depicts the relationship between TPR and FPR. The AUROC can be interpreted as the probability that a positive example is assigned a higher detection score than a negative example <ref type="bibr" target="#b9">(Fawcett, 2006)</ref>. A perfect detector corresponds to an AUROC score of 100%. (4) AUPR is the Area under the Precision-Recall curve, which is another threshold independent metric <ref type="bibr" target="#b22">(Manning et al., 1999;</ref><ref type="bibr" target="#b28">Saito &amp; Rehmsmeier, 2015)</ref>. The PR curve is a graph showing the precision=TP/(TP+FP) and recall=TP/(TP+FN) against each other. The metric AUPR-In and AUPR-Out in <ref type="table" target="#tab_1">Table 2 denote</ref>  Comparison with baseline. In <ref type="figure">Figure 1</ref>, we show the ROC curves when DenseNet-BC-100 is evaluated on CIFAR-10 (positive) images against TinyImageNet (negative) test examples. The red curve corresponds to the ROC curve when using baseline method <ref type="bibr" target="#b15">(Hendrycks &amp; Gimpel, 2017)</ref>, whereas the blue curve corresponds to ODIN. We observe a strikingly large gap between the blue and red ROC curves. For example, when TPR= 95%, the FPR can be reduced from 34% to 4.2% by using our approach. Hyperparameters. We use a separate OOD validation dataset for hyperparameter selection, which is independent from the OOD test datasets. For temperature T , we select among 1, 2, 5, 10, 20, 50, 100, 200, 500, 1000; and for perturbation magnitude ε we choose from 21 evenly spaced numbers starting from 0 and ending at 0.004. The optimal parameters are chosen to minimize the FPR at TPR 95% on the validation OOD dataset.</p><p>Main results. The main results are summarized in <ref type="table" target="#tab_1">Table 2</ref>, where we use iSUN <ref type="bibr" target="#b37">(Xu et al., 2015)</ref> as validation set. We use T = 1000 for all settings. For DenseNet, we use ε = 0.0014 for CIFAR-10 and ε = 0.002 for CIFAR-100. We provide additional details on the effect of parameters in Section 5. For each in-and out-of-distribution dataset pair, we report both the performance of the baseline <ref type="bibr" target="#b15">(Hendrycks &amp; Gimpel, 2017)</ref> and ODIN. In <ref type="table" target="#tab_1">Table 2</ref>, we observe significant performance improvement across all dataset pairs. Parameter transferability. In <ref type="table">Table 3</ref>, we show how the parameters tuned on one validation set can generalize across datasets. Specifically, we tune the parameters using one validation dataset and then evaluated on the remaining OOD test datasets. The results are very similar across different validation sets, which suggests the insensitivity of our method w.r.t the tuning set.  <ref type="table">Table 3</ref>: Detection performance using different validation OOD datasets. The hyperparameters are tuned using one validation dataset and then evaluate on the remaining OOD test datasets. The neural network is pre-trained on CIFAR-10.</p><p>Data distributional distance vs. detection performance. To measure the statistical distance between in-and out-of-distribution datasets, we adopt a commonly used metric, maximum mean discrep- ancy (MMD) with Gaussian RBF kernel <ref type="bibr" target="#b31">(Sriperumbudur et al., 2010;</ref><ref type="bibr" target="#b12">Gretton et al., 2012;</ref><ref type="bibr" target="#b32">Sutherland et al., 2016)</ref>. Specifically, given two image sets, V = {v 1 , ..., v m } and W = {w 1 , ..., w m }, the maximum mean discrepancy between V and Q is defined as</p><formula xml:id="formula_3">MMD 2 (V, W ) = 1 m 2 i =j k(v i , v j ) + 1 m 2 i =j k(w i , w j ) − 2 m 2 i =j k(v i , w j ),</formula><p>where k(·, ·) is the Gaussian RBF kernel, i.e., k(x, x ) = exp −</p><p>x−x 2 2 2σ 2</p><p>. We use the same method used by <ref type="bibr" target="#b32">Sutherland et al. (2016)</ref> to choose σ, where 2σ 2 is set to the median of all Euclidean distances between all images in the aggregate set V ∪ W .</p><p>In <ref type="figure">Figure 2</ref> (a)(b), we show how the performance of ODIN varies against the MMD distances between in-and out-of-distribution datasets. The datasets (on x-axis) are ranked in the descending order of MMD distances with CIFAR-100. There are two interesting observations can be drawn from these figures. First, we find that the MMD distances between the cropped datasets and CIFAR-100 tend to be larger. This is likely due to the fact that cropped images only contain local image context and are therefore more distinct from CIFAR-100 images, while resized images contain global patterns and are thus similar to images in CIFAR-100. Second, we observe that the MMD distance tends to be negatively correlated with the detection performance. This suggests that the detection task becomes harder as in-and out-of-distribution images are more similar to each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DISCUSSIONS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">ANALYSIS ON TEMPERATURE SCALING</head><p>In this subsection, we analyze the effectiveness of the temperature scaling method. As shown in <ref type="figure" target="#fig_2">Figure 3</ref> (a) and (b), we observe that a sufficiently large temperature yields better detection performance although the effects diminish when T is too large. To gain insight, we can use the Taylor expansion of the softmax score (details provided in Appendix B). When T is sufficiently large, we have</p><formula xml:id="formula_4">Sŷ(x; T ) ≈ 1 N − 1 T i [fŷ(x) − f i (x)] + 1 2T 2 i [fŷ(x) − f i (x)] 2 ,<label>(3)</label></formula><p>by omitting the third and higher orders. For simplicity of notation, we define</p><formula xml:id="formula_5">U 1 (x) = 1 N − 1 i =ŷ [fŷ(x) − f i (x)] and U 2 (x) = 1 N − 1 i =ŷ [fŷ(x) − f i (x)] 2 .<label>(4)</label></formula><p>Interpretations of U 1 and U 2 . By definition, U 1 measures the extent to which the largest unnormalized output of the neural network deviates from the remaining outputs; while U 2 measures the extent to which the remaining smaller outputs deviate from each other. We provide formal mathematical derivations in Appendix D. In <ref type="figure" target="#fig_4">Figure 5(a)</ref>, we show the distribution of U 1 for each out-of-distribution dataset vs. the in-distribution dataset (in red). We observe that the largest outputs of the neural All networks are trained on CIFAR-10 (in-distribution). Effects of perturbation magnitude of ε on Wide-ResNet-28-10 when T is large (e.g., T = 1000). All networks are trained on CIFAR-10.</p><p>network on in-distribution images deviate more from the remaining outputs. This is likely due to the fact that neural networks tend to make more confident predictions on in-distribution images.</p><p>Further, we show in <ref type="figure" target="#fig_4">Figure 5</ref>(b) the expectation of U 2 conditioned on U 1 , i.e., E[U 2 |U 1 ], for each dataset. The red curve (in-distribution images) has overall higher expectation. This indicates that, when two images have similar values on U 1 , the in-distribution image tends to have a much higher value of U 2 than the out-of-distribution image. In other words, for in-distribution images, the remaining outputs (excluding the largest output) tend to be more separated from each other compared to out-of-distribution datasets. This may happen when some classes in the in-distribution dataset share common features while others differ significantly. To illustrate this, in <ref type="figure" target="#fig_4">Figure 5</ref> (f)(g), we show the outputs of each class using a DenseNet (trained on CIFAR-10) on a dog image from CIFAR-10, and another image from TinyImageNet (crop). For the image of dog, we can observe that the largest output for the label dog is close to the output for the label cat but is quite separated from the outputs for the label car and truck. This is likely due to the fact that, in CIFAR-10, images of dogs are very similar to the images of cats but are quite distinct from images of car and truck. For the image from TinyImageNet (crop), despite having one large output, the remaining outputs are close to each other and thus have a smaller deviation.</p><p>The effects of T . To see the usefulness of adopting a large T , we can first rewrite the softmax score function in Equation <ref type="formula" target="#formula_4">(3)</ref> as S ∝ (U 1 − U 2 /2T )/T . Hence the softmax score is largely determined by U 1 and U 2 /2T . As noted earlier, U 1 makes in-distribution images produce larger softmax scores than out-of-distribution images since S ∝ U 1 , while U 2 has the exact opposite effect since S ∝ −U 2 . Therefore, by choosing a sufficiently large temperature, we can compensate the negative impacts of U 2 /2T on the detection performance, making the softmax scores between in-and out-of-distribution images more separable. Eventually, when T is sufficiently large, the distribution of softmax score is almost dominated by the distribution of U 1 and thus increasing the temperature further is no longer effective. This explains why we see in <ref type="figure" target="#fig_2">Figure 3</ref> (a)(b) that the performance does not change when T is too large (e.g., T &gt; 100). In Appendix C, we provide a formal proof showing that the detection error eventually converges to a constant number when T goes to infinity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">ANALYSIS ON INPUT PREPROCESSING</head><p>As noted previously, using the temperature scaling method by itself can be effective in improving the detection performance. However, the effectiveness quickly diminishes as T becomes very large. In order to make further improvement, we complement temperature scaling with input preprocessing. This has already been seen in <ref type="figure" target="#fig_3">Figure 4</ref>, where the detection performance is improved by a large margin on most datasets when T = 1000, provided with an appropriate perturbation magnitude ε is chosen. In this subsection, we provide some intuition behind this.</p><p>To explain, we can look into the first order Taylor expansion of the log-softmax function for the perturbed imagex, which is given by The effects of gradient. In <ref type="figure" target="#fig_4">Figure 5 (c)</ref>, we present the distribution of ∇ x log S(x; T ) 1 -the 1-norm of gradient of log-softmax with respect to the input x -for all datasets. A salient observation is that CIFAR-10 images (in-distribution) tend to have larger values on the norm of gradient than most out-of-distribution images. To further see the effects of the norm of gradient on the softmax score, we provide in <ref type="figure" target="#fig_4">Figures 5 (d)</ref> the conditional expectation E[ ∇ x log S(x; T ) 1 |S]. We can observe that, when an indistribution image and an out-of-distribution image have the same softmax score, the value of ∇ x log S(x; T ) 1 for in-distribution image tends to be larger.</p><p>We illustrate the effects of the norm of gradient in <ref type="figure" target="#fig_5">Figure 6</ref>. Suppose that an in-distribution image x 1 (blue) and an out-of-distribution image x 2 (red) have similar softmax scores, i.e., S(x 1 ) ≈ S(x 2 ). After input processing, the in-distribution image can have a much larger softmax score than the out-of-distribution image x 2 since x 1 results in a much larger value on the norm of softmax gradient than that of x 2 . Therefore, in-and out-of-distribution images are more separable from each other after input preprocessing 4 . The effect of ε. When the magnitude ε is sufficiently small, adding perturbations does not change the predictions of the neural network, i.e.,ŷ(x) =ŷ(x). However, when ε is not negligible, the gap of softmax scores between in-and out-of-distribution images can be affected by ∇ x log S(x; T ) 1 . Our observation is consistent with that in <ref type="bibr" target="#b33">(Szegedy et al., 2014;</ref><ref type="bibr" target="#b11">Goodfellow et al., 2015;</ref><ref type="bibr" target="#b23">Moosavi-Dezfooli et al., 2017)</ref>, which show that the softmax scores tend to change significantly if small perturbations are added to the in-distribution images. It is also worth noting that using a very large ε can lead to performance degradation, as seen in <ref type="figure" target="#fig_3">Figure 4</ref>. This is likely due to the fact that the second and higher order terms in the Taylor expansion are no longer insignificant when the perturbation magnitude is too large.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">RELATED WORKS AND FUTURE DIRECTIONS</head><p>The problem of detecting out-of-distribution examples in low-dimensional space has been well-studied in various contexts (see the survey by Pimentel et al. <ref type="formula" target="#formula_0">(2014)</ref>). Conventional methods such as density estimation, nearest neighbor and clustering analysis are widely used in detecting low-dimensional outof-distribution examples <ref type="bibr" target="#b3">(Chow, 1970;</ref><ref type="bibr" target="#b35">Vincent &amp; Bengio, 2003;</ref><ref type="bibr" target="#b10">Ghoting et al., 2008;</ref><ref type="bibr" target="#b6">Devroye et al., 2013)</ref>, . The density estimation approach uses probabilistic models to estimate the in-distribution density and declares a test example to be out-of-distribution if it locates in the low-density areas.</p><p>The clustering method is based on the statistical distance, and declares an example to be out-ofdistribution if it locates far from its neighborhood. Despite various applications in low-dimensional spaces, unfortunately, these methods are known to be unreliable in high-dimensional space such as image space <ref type="bibr" target="#b36">(Wasserman, 2006;</ref><ref type="bibr" target="#b34">Theis et al., 2015)</ref>. In recent years, out-of-distribution detectors based on deep models have been proposed. <ref type="bibr" target="#b29">Schlegl et al. (2017)</ref> train a generative adversarial networks to detect out-of-distribution examples in clinical scenario. <ref type="bibr" target="#b27">Sabokrou et al. (2016)</ref> train a convolutional network to detect anomaly in scenes. <ref type="bibr" target="#b1">Andrews et al. (2016)</ref> adopt transfer representation-learning for anomaly detection. All these works require enlarging or modifying the neural networks. In a more recent work, <ref type="bibr" target="#b15">Hendrycks &amp; Gimpel (2017)</ref> found that pre-trained neural networks can be overconfident to out-of-distribution example, limiting the effectiveness of detection. Our paper aims to improve the performance of detecting out-of-distribution examples, without requiring any change to an existing well-trained model.</p><p>Our approach leverages the following two interesting observations to help better distinguish between in-and out-of-distribution examples: (1) On in-distribution images, modern neural networks tend to produce outputs with larger variance across class labels, and (2) neural networks have larger norm of gradient of log-softmax scores when applied on in-distribution images. We believe that having a better understanding of these phenomenon can lead to further insights into this problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSIONS</head><p>In this paper, we propose a simple and effective method to detect out-of-distribution data samples in neural networks. Our method does not require retraining the neural network and significantly improves on the baseline method <ref type="bibr" target="#b15">Hendrycks &amp; Gimpel (2017)</ref> on different neural architectures across various in and out-distribution dataset pairs. We empirically analyze the method under different parameter settings, and provide some insights behind the approach. Future work involves exploring our method in other applications such as speech recognition and natural language processing.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B TAYLOR EXPANSION</head><p>In this section, we present the Taylor expansion of the soft-max score function:</p><formula xml:id="formula_6">Sŷ(x; T ) = exp (fŷ(x)/T ) N i=1 exp(f i (x)/T ) = 1 N i=1 exp fi(x)−fŷ(x) T = 1 N i=1 1 + fi(x)−fŷ(x) T + 1 2! (fi(x)−fŷ(x)) 2 T 2 + o 1 T 2 by Taylor expansion ≈ 1 N − 1 T N i=1 [fŷ(x) − f i (x)] + 1 2T 2 N i=1 [f i (x) − fŷ(x)] 2 C PROPOSITION 1</formula><p>The following proposition 1 shows that the detection error P e (T, 0) ≈ c if T is sufficiently large. Thus, increasing the temperature further can only slightly improve the detection performance. Proposition 1. There exists a constant c only depending on function U 1 , in-distribution P X and out-of-distribution Q X such that lim T →∞ P e (T, ε) = c, when ε = 0 (i.e., no input preprocessing).</p><p>Proof. Since</p><formula xml:id="formula_7">Sŷ(X; T ) = exp(fŷ(X)/T ) N i=1 exp(f i (X)/T ) = 1 1 + i =ŷ exp([f i (X) − fŷ(X)]/T ) Therefore, for any X, lim T →∞ T − 1 Sŷ(X; T ) + N = lim T →∞ i =ŷ T 1 − exp f i (X) − fŷ(X) T = i =ŷ [fŷ(X) − f i (X)] = (N − 1)U 1 (X)</formula><p>This indicates that the random variable</p><formula xml:id="formula_8">T − 1 Sŷ(X; T ) + N → (N − 1)U 1 (X) a.s.</formula><p>as T → ∞. This means that for a specific α &gt; 0, choosing the threshold δ T = 1/(N − α/T ), then the false positive rate</p><formula xml:id="formula_9">FPR(T ) = Q X (Sŷ(X; T ) &gt; 1/(N − α/T )) = Q X T N − 1 Sŷ(X; T ) &gt; α T →∞ − −−− → Q X ((N − 1)U 1 (X) &gt; α) ,</formula><p>and the true positive rate</p><formula xml:id="formula_10">TPR(T ) = P X (Sŷ(X; T ) &gt; 1/(N − α/T )) = P X T N − 1 Sŷ(X; T ) &gt; α T →∞ − −−− → P X ((N − 1)U 1 (X) &gt; α) .</formula><p>Choosing α * such that P X ((N − 1)U 1 (X) &gt; α * ) = 0.95, then TPR(T ) → 0.95 as T → ∞ and at the same time FPR(T ) → Q X ((N − 1)U 1 (X) &gt; α * ) as T → ∞. There exists a constant c depending on U 1 , P X , Q X and P Z , such that lim T →∞ P e (T, 0) = 0.05P (Z = 0) + P (Z = 1)Q X ((N − 1)U 1 (X) &gt; α * ) = c.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D ANALYSIS OF TEMPERATURE</head><p>For simplicity of the notations, let ∆ i = fŷ − f i and thus ∆ = {∆ i } i =ŷ . Besides, let∆ denote the mean of the set ∆. Therefore,</p><formula xml:id="formula_11">∆ = 1 N − 1 i =ŷ ∆ i = 1 N − 1 i =ŷ [fŷ − f i ] = U 1 .</formula><p>Equivalently, U 1 = Mean(∆).</p><p>Next, we will show</p><formula xml:id="formula_12">U 2 = 1 N − 1 i =ŷ [fŷ − f i ] 2 = Variance 2 (∆) 1 N − 1 i =ŷ [∆ i −∆] 2 + Mean 2 (∆) ∆ 2 . Since U 2 = 1 N − 1 i =ŷ ∆ 2 i by∆ i = fŷ − f i = 1 N − 1 i =ŷ (∆ i −∆ +∆) 2 = 1 N − 1 i =ŷ [(∆ i −∆) 2 − 2(∆ i −∆)∆ +∆ 2 ] = 1 N − 1 i =ŷ [∆ i −∆] 2 Variance 2 (∆) − 2∆ N − 1 i =ŷ (∆ i −∆) =0 +∆ 2 Mean 2 (∆) then U 2 = Variance 2 (∆) + Mean 2 (∆)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E ADDITIONAL RESULTS ON DISTANCE MEASUREMENT</head><p>Apart from the Maximum Mean Discrepancy, we also calculate the Energy distance between in-and out-of-distribution datasets. Let P and Q denote two different distributions. Then the energy distance between distributions P and Q is defined as</p><formula xml:id="formula_13">D 2 energy (P, Q) = 2E V ∼P,W ∼Q X − Y − E V,V ∼P X − X − E W,W ∼Q Y − Y .</formula><p>Therefore, the energy distance between two datasets</p><formula xml:id="formula_14">V = {V 1 , ..., V m } iid ∼ P and W = {W 1 , ..., W m } iid ∼ Q is defined as D energy 2 (P, Q) = 2 m 2 m i=1 m j=1 V i − W j − 1 m 2 i =j V i − V j − 1 m 2 i =j W i − W j .</formula><p>In the experiment, we use the 2-norm · 2 .</p><p>In-distribution  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F ADDITIONAL DISCUSSIONS</head><p>In this section, we present additional discussion on the proposed method. We first empirically show how the threshold δ affects the detection performance. We next show how the proposed method performs when the parameters are tuned on a certain out-of-distribution dataset and are evaluated on other out-of-distribution datasets. Effects of the threshold. We analyze how the threshold affects the following metrics: (1) FPR, i.e., the fraction of out-of-distribution images misclassified as in-distribution images; (2) TPR, i.e, the fraction of in-distribution images correctly classified as in-distribution images. In <ref type="figure">Figure 10</ref>, we show how the thresholds affect FPR and TPR when the temperature and perturbation magnitude are chosen optimally (i.e., T = 1, 000, ε = 0.0014). From the figure, we can observe that the threshold corresponding to 95% TPR can produce small FPRs on all out-of-distribution datasets.</p><p>Difficult-to-classify images and difficult-to-detect images. We analyze the correlation between the images that tend to be out-of-distribution and images on which the neural network tend to make incorrect predictions. To understand the correlation, we devise the following experiment. For the fixed temperature T and perturbation magnitude ε, we first set δ to the softmax score threshold corresponding to a certain true positive rate. Next, we calculate the test accuracy on the images with softmax scores above δ and the test accuracy on the images with softmax score below δ, respectively. We report the results in <ref type="figure">Figure 11</ref>(a) and (b). From these two figures, we can observe that the images that are difficult to detect are more likely to be the images that are difficult to classify. For example, the DenseNet can achieve up to 98.5% test accuracy on the images having softmax scores above the threshold corresponding to 80% TPR, but can only achieve around 82% test accuracy on the images having softmax scores below the threshold corresponding to 80% TPR.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>the area under the precision-recall curve where in-distribution and out-of-distribution images are specified as positives, respectively. on CIFAR-10 FPR reduced from 34.7% to 4.3% (a) ROC Curves Baseline Method Our Method (T = 1000, ε = 0.0012) Figure 1: (a) ROC curves of baseline (red) and our method (blue) on DenseNet-BC-100 network, where CIFAR-10 and TinyImageNet (crop) are in-and out-of-distribution dataset, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>(a)-(b) Performance of our method vs. MMD between in-and out-of-distribution datasets. Neural networks are trained on CIFAR-100. The out-of-distribution datasets are 1: LSUN (cop), 2: TinyImageNet (crop), 3: LSUN (resize), 4: is iSUN (resize), 5: TinyImageNet (resize).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>(a)(b) Effects of temperature T when ε = 0. (c)(d) Effects of perturbation magnitude ε when T = 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>(a)(b) Effects of perturbation magnitude ε on DenseNet when T is large (e.g., T = 1000). (c)(d)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>CIFAR-10 (Dog) fr o g d e e r tr u ck c a t b ir d sh ip d o g p la n e h o rs e c a (a) Probability density of U1 under different datasets on DenseNet. (b) Expectations of U2 conditioned on U1 on DenseNet. (c) Probability density of the norm of gradient on DenseNet under temperature 1, 000. (c)(d) Expectation of the norm of gradient conditioned on the softmax scores on DenseNet under temperature T = 1000 and T = 1, respectively. (f)(g) Outputs of DenseNet on each class for an image of dog from CIFAR-10 and an image from TinyImageNet (crop). The DenseNet is trained on CIFAR-10. Additional results on other architectures are provided in Appendix A.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>logFigure 6 :</head><label>6</label><figDesc>Sŷ(x; T ) = log Sŷ(x; T ) + ε ∇ x log Sŷ(x; T ) 1 + o(ε), where x is the original input. Illustration of effects of the input preprocessing.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :Figure 8 :Figure 9 :</head><label>789</label><figDesc>Expectation of the second order term U2 conditioned on the first order term U1 under DenseNet, Wide-ResNet-28-10 and Wide ResNet-40-4. All networks are trained on CIFAR-10. Expectation of gradient norms conditioned on the softmax scores under DenseNet, Wide-ResNet-28-10 and Wide ResNet-40-4, where the temperature scaling is not used. All networks are trained on CIFAR-10. Expectation of gradient norms conditioned on the softmax scores under DenseNet, Wide-ResNet-28-</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 10 :Figure 11</head><label>1011</label><figDesc>False positive rate (FPR) and true positive rate (TPR) under different thresholds (δ) when the temperature (T ) is set to 1, 000 and the perturbation magnitude (ε) is set to 0.0014. The DenseNet is trained on CIFAR: (a) The test accuracy on the images having softmax scores above the threshold corresponding to a certain true positive rate. (b) The test accuracy on the images having softmax scores below the threshold corresponding to a certain true positive rate. All networks are trained on CIFAR-10.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Distinguishing in-and out-of-distribution test set data for image classification. All values are</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://pytorch.org 2 https://github.com/facebookresearch/odin</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://tiny-imagenet.herokuapp.com</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Similar observation can be seen when T = 1, where we present the conditional expectation of the norm of softmax gradient in Figure 5 (e).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10">and Wide ResNet-40-4, where the optimal temperature is used, i.e., T = 1000. All networks are trained on CIFAR-10.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>The research reported here was supported by NSF Grant CPS ECCS 1739189.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Steinhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Christiano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Mané</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.06565</idno>
		<title level="m">Concrete problems in ai safety</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Transfer representationlearning for anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jerone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><forename type="middle">J</forename><surname>Tanay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lewis</forename><forename type="middle">D</forename><surname>Morton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Griffin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">On optimum recognition error and reject tradeoff</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on information theory</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="41" to="46" />
			<date type="published" when="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The relationship between precision-recall and roc curves</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Goadrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML. ACM</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">A probabilistic theory of pattern recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Devroye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">László</forename><surname>Györfi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gábor</forename><surname>Lugosi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Springer Science &amp; Business Media</publisher>
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2121" to="2159" />
			<date type="published" when="2011-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning hierarchical features for scene labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clement</forename><surname>Farabet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Camille</forename><surname>Couprie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Najman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="1915" to="1929" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">An introduction to roc analysis. Pattern recognition letters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Fawcett</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fast mining of distance-based outliers in high-dimensional datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amol</forename><surname>Ghoting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinivasan</forename><surname>Parthasarathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">Eric</forename><surname>Otey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="349" to="364" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Explaining and harnessing adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Szegedy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A kernel two-sample test</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Karsten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Borgwardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Rasch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="723" to="773" />
			<date type="published" when="2012-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoff</forename><surname>Pleiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian Q</forename><surname>Weinberger</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.04599</idno>
		<title level="m">On calibration of modern neural networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">A baseline for detecting misclassified and out-of-distribution examples in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian Q</forename><surname>Weinberger</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.06993</idno>
		<title level="m">Densely connected convolutional networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">3d convolutional neural networks for human action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuiwang</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="221" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Foundations of statistical natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schütze</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<publisher>MIT Press</publisher>
			<biblScope unit="volume">999</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Universal adversarial perturbations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alhussein</forename><surname>Seyed-Mohsen Moosavi-Dezfooli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omar</forename><surname>Fawzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fawzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Frossard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Deep neural networks are easily fooled: High confidence predictions for unrecognizable images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anh</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Yosinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Clune</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Regularizing neural networks by penalizing confident output distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Pereyra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Chorowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A review of novelty detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">F</forename><surname>Marco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">A</forename><surname>Pimentel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Clifton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lionel</forename><surname>Clifton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tarassenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Processing</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="215" to="249" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Fully convolutional neural network for fast anomaly detection in crowded scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Sabokrou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohsen</forename><surname>Fayyaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahmood</forename><surname>Fathy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.00866</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The precision-recall plot is more informative than the roc plot when evaluating binary classifiers on imbalanced datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takaya</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Rehmsmeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">118432</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Unsupervised anomaly detection with generative adversarial networks to guide marker discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Schlegl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Seeböck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ursula</forename><surname>Sebastian M Waldstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Schmidt-Erfurth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Langs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Information Processing in Medical Imaging</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="146" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Hilbert space embeddings and metrics on probability measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bharath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Sriperumbudur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Fukumizu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gert Rg</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lanckriet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1517" to="1561" />
			<date type="published" when="2010-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Generative models and model criticism via optimized maximum mean discrepancy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dougal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsiao-Yu</forename><surname>Sutherland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heiko</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumyajit</forename><surname>Strathmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaditya</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Ramdas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gretton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Intriguing properties of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Aäron van den Oord, and Matthias Bethge. A note on the evaluation of generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Theis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Manifold parzen windows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="849" to="856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">All of Nonparametric Statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Wasserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pingmei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krista</forename><forename type="middle">A</forename><surname>Ehinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinda</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Finkelstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sanjeev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxiong</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xiao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1504.06755</idno>
		<title level="m">Turkergaze: Crowdsourcing saliency with webcam based eye tracking</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinda</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuran</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Seff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxiong</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lsun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.03365</idno>
		<title level="m">Construction of a largescale image dataset using deep learning with humans in the loop</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.07146</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">Wide residual networks. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Understanding deep learning requires rethinking generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moritz</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
